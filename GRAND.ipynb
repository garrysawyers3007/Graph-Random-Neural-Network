{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRAND.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj37A4mvjTwQ"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.nn import init\n",
        "\n",
        "import sys\n",
        "\n",
        "import pickle as pkl\n",
        "\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieZkOztcjjfy"
      },
      "source": [
        "class MLPLayer(Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(MLPLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.normal_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.normal_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = torch.mm(input, self.weight)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8MOGIxlkNWM"
      },
      "source": [
        "class GraphConvolution(Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.normal_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.normal_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8PAoT8sjogt"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, input_droprate, hidden_droprate, use_bn=False):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.input_droprate = input_droprate\n",
        "        self.hidden_droprate = hidden_droprate\n",
        "        self.bn1 = nn.BatchNorm1d(nfeat)\n",
        "        self.bn2 = nn.BatchNorm1d(nhid)\n",
        "        self.use_bn = use_bn\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "\n",
        "        if self.use_bn:\n",
        "            x = self.bn1(x)\n",
        "        x = F.dropout(x, self.input_droprate, training=self.training)\n",
        "        \n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        if self.use_bn:\n",
        "            x = self.bn2(x)\n",
        "        x = F.dropout(x, self.hidden_droprate, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oLtsOyzkFlV"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, input_droprate, hidden_droprate, is_cuda=True, use_bn =False):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.layer1 = MLPLayer(nfeat, nhid)\n",
        "        self.layer2 = MLPLayer(nhid, nclass)\n",
        "\n",
        "        self.input_droprate = input_droprate\n",
        "        self.hidden_droprate = hidden_droprate\n",
        "        self.is_cuda = is_cuda\n",
        "        self.bn1 = nn.BatchNorm1d(nfeat)\n",
        "        self.bn2 = nn.BatchNorm1d(nhid)\n",
        "        self.use_bn = use_bn\n",
        "        \n",
        "    def forward(self, x):\n",
        "         \n",
        "        if self.use_bn: \n",
        "            x = self.bn1(x)\n",
        "        x = F.dropout(x, self.input_droprate, training=self.training)\n",
        "        x = F.relu(self.layer1(x))\n",
        "        if self.use_bn:\n",
        "            x = self.bn2(x)\n",
        "        x = F.dropout(x, self.hidden_droprate, training=self.training)\n",
        "        x = self.layer2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIUXmcHhlFFO"
      },
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOq8FmJjkPrb"
      },
      "source": [
        "def load_data(dataset_str = 'cora'):\n",
        "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"/content/drive/MyDrive/GRAND_data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"/content/drive/MyDrive/GRAND_data/ind.{}.test.index\".format(dataset_str))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset_str == 'citeseer':\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "        ty = ty_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    features = normalize(features)\n",
        "    graph = nx.from_dict_of_lists(graph)\n",
        "    adj = nx.adjacency_matrix(graph)\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    \n",
        "    adj = adj + sp.eye(adj.shape[0])\n",
        "    D1_ = np.array(adj.sum(axis=1))**(-0.5)\n",
        "    D2_ = np.array(adj.sum(axis=0))**(-0.5)\n",
        "    D1_ = sp.diags(D1_[:,0], format='csr')\n",
        "    D2_ = sp.diags(D2_[0,:], format='csr')\n",
        "    A_ = adj.dot(D1_)\n",
        "    A_ = D2_.dot(A_)\n",
        "    \n",
        "    \n",
        "    D1 = np.array(adj.sum(axis=1))**(-0.5)\n",
        "    D2 = np.array(adj.sum(axis=0))**(-0.5)\n",
        "    D1 = sp.diags(D1[:,0], format='csr')\n",
        "    D2 = sp.diags(D2[0,:], format='csr')\n",
        "    \n",
        "    A = adj.dot(D1)\n",
        "    A = D2.dot(A)\n",
        "\n",
        "\n",
        "    labels = np.vstack((ally, ty))\n",
        "    labels[test_idx_reorder, :] = labels[test_idx_range, :]     # onehot\n",
        "\n",
        "    idx_train = range(len(y))\n",
        "    idx_val = range(len(y), len(y)+500)\n",
        "    idx_test = test_idx_range.tolist()\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.argmax(labels, -1))\n",
        "    A = sparse_mx_to_torch_sparse_tensor(A)\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return A, adj, features, labels, idx_train, idx_val, idx_test, graph.edges()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z01M5c5olSrI"
      },
      "source": [
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "def normalize(mx):\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIKg_zp4lWrS"
      },
      "source": [
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def label_vector_generator(adj, label_vector, index = [], order=1, shuffle=False, style=0):\n",
        "    label_vectors = []\n",
        "    lv = torch.zeros(label_vector.shape)\n",
        "    lv[index, :] = label_vector[index, :]\n",
        "    for i in range(order):\n",
        "        label_vectors.append(lv)\n",
        "        if i!= (order-1):\n",
        "            lv = torch.spmm(adj, lv)\n",
        "    if style == 0:\n",
        "        return sum(label_vectors)*1.0/order\n",
        "    return torch.cat(label_vectors, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTBs5w3hlacb"
      },
      "source": [
        "def feature_generator(adj, features, order=0):\n",
        "    n = features.shape[0]\n",
        "    index = np.random.permutation(n)\n",
        "    index_1 = index[: n//2]\n",
        "    index_2 = index[n//2 :]\n",
        "    mask_1 = torch.zeros(n,1)\n",
        "    mask_2 = torch.zeros(n,1)\n",
        "    mask_1[index_1] = 1\n",
        "    mask_2[index_2] = 1\n",
        "\n",
        "    features_1 = [mask_1.cuda() * features]\n",
        "    features_2 = [mask_2.cuda() * features]\n",
        "\n",
        "    alpha = 1\n",
        "    for i in range(order):\n",
        "        features_1.append(alpha*torch.spmm(adj, features_1[-1]) + (1-alpha)*features_1[0])\n",
        "    for i in range(order):\n",
        "        features_2.append(alpha*torch.spmm(adj, features_2[-1]) + (1-alpha)*features_2[0])\n",
        "\n",
        "    return sum(features_1)*1./(order+1), sum(features_2)*1./(order+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUpy7A2zlfhZ"
      },
      "source": [
        "def MMD(x, y, alpha=0.5):\n",
        "    n_x, n_y = x.size(0), y.size(0)\n",
        "\n",
        "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
        "\n",
        "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
        "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
        "\n",
        "    rrx = (xx.diag().unsqueeze(1).expand(n_x, n_y))\n",
        "    rry = (yy.diag().unsqueeze(0).expand(n_x, n_y))\n",
        "\n",
        "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
        "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
        "    P = torch.exp(- alpha * (rrx + rry - 2*zz))\n",
        "\n",
        "    loss = 1./(n_x*(n_x-1)) * torch.sum(K) + 1./(n_y*(n_y-1)) * torch.sum(L) - (2./(n_x*n_y)) * torch.sum(P)\n",
        "\n",
        "    return 0.5*loss\n",
        "\n",
        "def MMD_same(x, y, alpha=0.5):\n",
        "    n_x, n_y = x.size(0), y.size(0)\n",
        "\n",
        "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
        "\n",
        "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
        "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
        "\n",
        "    K = torch.exp(- alpha * (rx.t() + rx - 2*xx))\n",
        "    L = torch.exp(- alpha * (ry.t() + ry - 2*yy))\n",
        "    P = torch.exp(- alpha * (rx.t() + ry - 2*zz))\n",
        "\n",
        "    loss = 1./(n_x*(n_x-1)) * torch.sum(K) + 1./(n_y*(n_y-1)) * torch.sum(L) - (2./(n_x*n_y)) * torch.sum(P)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4tthMR0s4zC"
      },
      "source": [
        "args = {\n",
        "    'cuda': True,\n",
        "    'fastmode': False,\n",
        "    'seed': 42,\n",
        "    'epochs': 5000,\n",
        "    'lr': 0.01,\n",
        "    'weight_decay': 5e-4,\n",
        "    'hidden': 32,\n",
        "    'input_droprate': 0.5,\n",
        "    'hidden_droprate': 0.5,\n",
        "    'dropnode_rate': 0.5,\n",
        "    'patience': 100,\n",
        "    'order': 5,\n",
        "    'sample': 4,\n",
        "    'tem': 0.5,\n",
        "    'lam': 1.,\n",
        "    'dataset': 'pubmed',\n",
        "    'use_bn': False,\n",
        "    'dropout': 0.5\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnMh90GS1ZTZ"
      },
      "source": [
        "#cora\n",
        "args['lam'] = 1.0 \n",
        "args['tem'] = 0.5 \n",
        "args['order'] = 8 \n",
        "args['sample'] = 4 \n",
        "args['dataset'] = 'cora' \n",
        "args['input_droprate'] = 0.5 \n",
        "args['hidden_droprate'] = 0.5 \n",
        "args['hidden'] = 32 \n",
        "args['lr'] = 0.01 \n",
        "args['patience'] = 200\n",
        "args['seed'] = 100 \n",
        "args['dropnode_rate'] = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn1KUjR72MLn"
      },
      "source": [
        "#pubmed\n",
        "args['lam'] = 1.0 \n",
        "args['tem'] = 0.2 \n",
        "args['order'] = 5\n",
        "args['sample'] = 4 \n",
        "args['dataset'] = 'pubmed' \n",
        "args['input_droprate'] = 0.6 \n",
        "args['hidden_droprate'] = 0.8 \n",
        "args['hidden'] = 32 \n",
        "args['lr'] = 0.2 \n",
        "args['patience'] = 100 \n",
        "args['dropnode_rate'] = 0.5\n",
        "args['use_bn'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XB2Gmy03AwS"
      },
      "source": [
        "#citeseer\n",
        "args['lam'] = 0.7 \n",
        "args['tem'] = 0.3 \n",
        "args['order'] = 2\n",
        "args['sample'] = 2 \n",
        "args['dataset'] = 'citeseer' \n",
        "args['input_droprate'] = 0.0 \n",
        "args['hidden_droprate'] = 0.2 \n",
        "args['hidden'] = 32 \n",
        "args['lr'] = 0.01 \n",
        "args['patience'] = 200 \n",
        "args['dropnode_rate'] = 0.5\n",
        "args['seed'] = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OyOL2i0lmX4",
        "outputId": "332551fe-5113-48c4-92de-d969c68672dc"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "dataset = args['dataset']\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if args['cuda']:\n",
        "  torch.cuda.manual_seed(args['seed'])\n",
        "\n",
        "# Load data\n",
        "A, adj, features, labels, idx_train, idx_val, idx_test, edges = load_data(dataset)\n",
        "idx_unlabel = torch.range(idx_train.shape[0], labels.shape[0]-1, dtype=int)\n",
        "\n",
        "# Model and optimizer\n",
        "model = MLP(nfeat=features.shape[1],\n",
        "            nhid=args['hidden'],\n",
        "            nclass=labels.max().item() + 1,\n",
        "            input_droprate=args['input_droprate'],\n",
        "            hidden_droprate=args['hidden_droprate'],\n",
        "            use_bn = args['use_bn'])\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "    features = features.cuda()\n",
        "    A = A.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "    idx_unlabel = idx_unlabel.cuda()\n",
        "\n",
        "def propagate(feature, A, order):\n",
        "    #feature = F.dropout(feature, args.dropout, training=training)\n",
        "    x = feature\n",
        "    y = feature\n",
        "    for i in range(order):\n",
        "        x = torch.spmm(A, x).detach_()\n",
        "        #print(y.add_(x))\n",
        "        y.add_(x)\n",
        "        \n",
        "    return y.div_(order+1.0).detach_()\n",
        "\n",
        "def rand_prop(features, training, order = args['order']):\n",
        "    n = features.shape[0]\n",
        "    drop_rate = args['dropnode_rate']\n",
        "    drop_rates = torch.FloatTensor(np.ones(n) * drop_rate)\n",
        "    \n",
        "    if training:\n",
        "            \n",
        "        masks = torch.bernoulli(1. - drop_rates).unsqueeze(1)\n",
        "\n",
        "        features = masks.cuda() * features\n",
        "            \n",
        "    else:\n",
        "            \n",
        "        features = features * (1. - drop_rate)\n",
        "    features = propagate(features, A, order)    \n",
        "    return features\n",
        "\n",
        "def consis_loss(logps, temp=args['tem'], lam = args['lam']):\n",
        "    ps = [torch.exp(p) for p in logps]\n",
        "    sum_p = 0.\n",
        "    for p in ps:\n",
        "        sum_p = sum_p + p\n",
        "    avg_p = sum_p/len(ps)\n",
        "    #p2 = torch.exp(logp2)\n",
        "    \n",
        "    sharp_p = (torch.pow(avg_p, 1./temp) / torch.sum(torch.pow(avg_p, 1./temp), dim=1, keepdim=True)).detach()\n",
        "    loss = 0.\n",
        "    for p in ps:\n",
        "        loss += torch.mean((p-sharp_p).pow(2).sum(1))\n",
        "    loss = loss/len(ps)\n",
        "    return lam * loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in power\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Y7-GPiJTIO",
        "outputId": "8055c3cf-5830-481b-b16f-ce356e794fd4"
      },
      "source": [
        "#Dropedge/Dropout\n",
        "scaler = StandardScaler()\n",
        "dataset = args['dataset']\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if args['cuda']:\n",
        "  torch.cuda.manual_seed(args['seed'])\n",
        "# Load data\n",
        "A, adj, features, labels, idx_train, idx_val, idx_test, edges = load_data(dataset)\n",
        "idx_unlabel = torch.range(idx_train.shape[0], labels.shape[0]-1, dtype=int)\n",
        "# Model and optimizer\n",
        "model = MLP(nfeat=features.shape[1],\n",
        "            nhid=args['hidden'],\n",
        "            nclass=labels.max().item() + 1,\n",
        "            input_droprate=args['input_droprate'],\n",
        "            hidden_droprate=args['hidden_droprate'],\n",
        "            use_bn = args['use_bn'])\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "    idx_unlabel = idx_unlabel.cuda()\n",
        "    A = A.cuda()\n",
        "\n",
        "def propagate(feature, a, order):\n",
        "    #feature = F.dropout(feature, args['dropout'], training=training)\n",
        "    #x = feature\n",
        "    y = torch.spmm(a,feature).detach_()\n",
        "    x = y\n",
        "    for i in range(order):\n",
        "        if i ==0:\n",
        "            x = torch.spmm(a, x).detach_()\n",
        "        else:\n",
        "            x = torch.spmm(a, x).detach_()\n",
        "        #print(y.add_(x))\n",
        "        y.add_(x)\n",
        "        #y= x\n",
        "    return y.div_(order+1.0).detach_()\n",
        "def sparse_dropout(a, training, dropedge_rate):\n",
        "    indice = a._indices()\n",
        "    values = a._values() \n",
        "    values = F.dropout(values, p=dropedge_rate, training=training)\n",
        "    size = a.size()\n",
        "    a = torch.sparse.FloatTensor(indice, values, size)\n",
        "    #d1 = torch.diag(a.sum(dim=1)**(-0.5))\n",
        "    #d2 = torch.diag(a.sum(dim=0)**(-0.5))\n",
        "    \n",
        "    return a\n",
        "def preprocess(a):\n",
        "    #d1 = np.array(a.sum(axis-1))**(-0.5)\n",
        "    #d2 = np.array(a.sum(axis=0))**(-0.5)\n",
        "    D1_ = np.array(a.sum(axis=1))**(-0.5)\n",
        "    D2_ = np.array(a.sum(axis=0))**(-0.5)\n",
        "    D1_ = sp.diags(D1_[:,0], format='csr')\n",
        "    D2_ = sp.diags(D2_[0,:], format='csr')\n",
        "    A_ = a.dot(D1_)\n",
        "    A_ = D2_.dot(A_)\n",
        "    A_ = sparse_mx_to_torch_sparse_tensor(A_) \n",
        "    if args['cuda']:\n",
        "        A_ = A_.cuda()\n",
        "    return A_    \n",
        "\n",
        "\n",
        "def random_edge_sample(edges, droprate):\n",
        "    edges = list(edges)\n",
        "    n = features.shape[0]\n",
        "    m = len(edges)\n",
        "    index = np.random.permutation(m)\n",
        "    percent = 1. - droprate\n",
        "    preserve_num = int(m * percent)\n",
        "     \n",
        "    index_ = index[:preserve_num]\n",
        "    sample_row = [edges[x][0] for x in index_]\n",
        "    sample_col = [edges[x][1] for x in index_]\n",
        "    sample_adj = sp.csr_matrix((np.ones(preserve_num), (sample_row, sample_col)), shape=(n,n))\n",
        "    sample_adj = sample_adj + sample_adj.T.multiply(sample_adj.T>sample_adj) - sample_adj.multiply(sample_adj.T>sample_adj) + sp.eye(n)\n",
        "    sample_adj = preprocess(sample_adj)\n",
        "    return sample_adj                          \n",
        "    \n",
        "    \n",
        "def rand_prop(features, training, order = args['order']):\n",
        "    n = features.shape[0]\n",
        "    drop_rate = args['dropnode_rate']\n",
        "    #drop_rates = torch.FloatTensor(np.ones(n) * drop_rate)\n",
        "    if training: \n",
        "        #a = random_edge_sample(edges, drop_rate)\n",
        "        a = sparse_dropout(A, training, drop_rate)\n",
        "    else:\n",
        "        a = A#preprocess(adj)\n",
        "    features = propagate(features, a, order)    \n",
        "    return features\n",
        "\n",
        "def consis_loss(logps, temp=args['tem'], lam = args['lam']):\n",
        "    ps = [torch.exp(p) for p in logps]\n",
        "    sum_p = 0.\n",
        "    for p in ps:\n",
        "        sum_p = sum_p + p\n",
        "    avg_p = sum_p/len(ps)\n",
        "    #p2 = torch.exp(logp2)\n",
        "    \n",
        "    sharp_p = (torch.pow(avg_p, 1./temp) / torch.sum(torch.pow(avg_p, 1./temp), dim=1, keepdim=True)).detach()\n",
        "    loss = 0.\n",
        "    for p in ps:\n",
        "        loss += torch.mean((p-sharp_p).pow(2).sum(1))\n",
        "    loss = loss/len(ps)\n",
        "    return lam * loss\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gJMCVLwsHW"
      },
      "source": [
        "def train(epoch, order=args['order'], lam=args['order'], sample = args['sample']):\n",
        "    t = time.time()\n",
        "    \n",
        "    X = features\n",
        "    \n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    X_list = []\n",
        "    K = sample\n",
        "    for k in range(K):\n",
        "        X_list.append(rand_prop(X, training=True, order=order))\n",
        "\n",
        "    output_list = []\n",
        "    for k in range(K):\n",
        "        output_list.append(torch.log_softmax(model(X_list[k]), dim=-1))\n",
        "\n",
        "    \n",
        "    loss_train = 0.\n",
        "    for k in range(K):\n",
        "        loss_train += F.nll_loss(output_list[k][idx_train], labels[idx_train])\n",
        "     \n",
        "        \n",
        "    loss_train = loss_train/K\n",
        "    #loss_train = F.nll_loss(output_1[idx_train], labels[idx_train]) + F.nll_loss(output_1[idx_train], labels[idx_train])\n",
        "    #loss_js = js_loss(output_1[idx_unlabel], output_2[idx_unlabel])\n",
        "    #loss_en = entropy_loss(output_1[idx_unlabel]) + entropy_loss(output_2[idx_unlabel])\n",
        "    loss_consis = consis_loss(output_list, lam=lam)\n",
        "\n",
        "    loss_train = loss_train + loss_consis\n",
        "    acc_train = accuracy(output_list[0][idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if not args['fastmode']:\n",
        "        model.eval()\n",
        "        X = rand_prop(X,training=False, order=order)\n",
        "        output = model(X)\n",
        "        output = torch.log_softmax(output, dim=-1)\n",
        "        \n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val]) \n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "    return loss_val.item(), acc_val.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-6kCpDHxL-q"
      },
      "source": [
        "def Train(order = args['order'], lam = args['lam'], sample = args['sample']):\n",
        "    # Train model\n",
        "    t_total = time.time()\n",
        "    loss_values = []\n",
        "    acc_values = []\n",
        "    bad_counter = 0\n",
        "    # best = args.epochs + 1\n",
        "    loss_best = np.inf\n",
        "    acc_best = 0.0\n",
        "\n",
        "    loss_mn = np.inf\n",
        "    acc_mx = 0.0\n",
        "\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(args['epochs']):\n",
        "        # if epoch < 200:\n",
        "        #   l, a = train(epoch, True)\n",
        "        #   loss_values.append(l)\n",
        "        #   acc_values.append(a)\n",
        "        #   continue\n",
        "\n",
        "        l, a = train(epoch, order, lam, sample)\n",
        "        loss_values.append(l)\n",
        "        acc_values.append(a)\n",
        "\n",
        "        print(bad_counter)\n",
        "\n",
        "        if loss_values[-1] <= loss_mn or acc_values[-1] >= acc_mx:# or epoch < 400:\n",
        "            if loss_values[-1] <= loss_best: #and acc_values[-1] >= acc_best:\n",
        "                loss_best = loss_values[-1]\n",
        "                acc_best = acc_values[-1]\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), dataset +'.pkl')\n",
        "\n",
        "            loss_mn = np.min((loss_values[-1], loss_mn))\n",
        "            acc_mx = np.max((acc_values[-1], acc_mx))\n",
        "            bad_counter = 0\n",
        "        else:\n",
        "            bad_counter += 1\n",
        "\n",
        "        # print(bad_counter, loss_mn, acc_mx, loss_best, acc_best, best_epoch)\n",
        "        if bad_counter == args['patience']:\n",
        "            print('Early stop! Min loss: ', loss_mn, ', Max accuracy: ', acc_mx)\n",
        "            print('Early stop model validation loss: ', loss_best, ', accuracy: ', acc_best)\n",
        "            break\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "    # Restore best model\n",
        "    print('Loading {}th epoch'.format(best_epoch))\n",
        "    model.load_state_dict(torch.load(dataset +'.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKmesl-pxetZ"
      },
      "source": [
        "def test(order = args['order']):\n",
        "    model.eval()\n",
        "    X = features\n",
        "    X = rand_prop(X, training=False, order=order)\n",
        "    output = model(X)\n",
        "    output = torch.log_softmax(output, dim=-1)\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "    return acc_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di5RTtL_0m4f",
        "outputId": "baacc71d-cfbe-4b64-a3d7-df2e24158be5"
      },
      "source": [
        "Train() #cora\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.0150 acc_train: 0.1429 loss_val: 1.9731 acc_val: 0.1140 time: 0.0522s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.0125 acc_train: 0.1429 loss_val: 1.9696 acc_val: 0.1140 time: 0.0462s\n",
            "0\n",
            "Epoch: 0003 loss_train: 2.0017 acc_train: 0.1429 loss_val: 1.9666 acc_val: 0.1140 time: 0.0459s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.9969 acc_train: 0.1429 loss_val: 1.9632 acc_val: 0.1140 time: 0.0456s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.9914 acc_train: 0.1429 loss_val: 1.9606 acc_val: 0.1140 time: 0.0470s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.9847 acc_train: 0.1357 loss_val: 1.9582 acc_val: 0.1140 time: 0.0442s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.9810 acc_train: 0.1429 loss_val: 1.9564 acc_val: 0.1140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.9742 acc_train: 0.1357 loss_val: 1.9549 acc_val: 0.1140 time: 0.0470s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.9686 acc_train: 0.1286 loss_val: 1.9537 acc_val: 0.1140 time: 0.0460s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.9608 acc_train: 0.1714 loss_val: 1.9526 acc_val: 0.1140 time: 0.0459s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.9624 acc_train: 0.1857 loss_val: 1.9519 acc_val: 0.1140 time: 0.0447s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.9605 acc_train: 0.2000 loss_val: 1.9509 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.9586 acc_train: 0.1643 loss_val: 1.9495 acc_val: 0.1140 time: 0.0440s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.9579 acc_train: 0.1643 loss_val: 1.9483 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.9510 acc_train: 0.1714 loss_val: 1.9470 acc_val: 0.1140 time: 0.0513s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.9501 acc_train: 0.1571 loss_val: 1.9454 acc_val: 0.1140 time: 0.0446s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.9477 acc_train: 0.1643 loss_val: 1.9438 acc_val: 0.1140 time: 0.0440s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.9482 acc_train: 0.1643 loss_val: 1.9426 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.9465 acc_train: 0.1786 loss_val: 1.9421 acc_val: 0.1140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.9428 acc_train: 0.2143 loss_val: 1.9418 acc_val: 0.1140 time: 0.0457s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.9364 acc_train: 0.1929 loss_val: 1.9416 acc_val: 0.1140 time: 0.0447s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.9317 acc_train: 0.2071 loss_val: 1.9413 acc_val: 0.1140 time: 0.0453s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.9372 acc_train: 0.1643 loss_val: 1.9410 acc_val: 0.1140 time: 0.0444s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.9398 acc_train: 0.1286 loss_val: 1.9409 acc_val: 0.1140 time: 0.0468s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.9380 acc_train: 0.1429 loss_val: 1.9409 acc_val: 0.1140 time: 0.0456s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.9335 acc_train: 0.1929 loss_val: 1.9410 acc_val: 0.1160 time: 0.0442s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.9248 acc_train: 0.1929 loss_val: 1.9398 acc_val: 0.1240 time: 0.0463s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.9266 acc_train: 0.2857 loss_val: 1.9377 acc_val: 0.1540 time: 0.0450s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.9255 acc_train: 0.2357 loss_val: 1.9350 acc_val: 0.2040 time: 0.0467s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.9239 acc_train: 0.2071 loss_val: 1.9318 acc_val: 0.2440 time: 0.0434s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.9230 acc_train: 0.2071 loss_val: 1.9279 acc_val: 0.2720 time: 0.0435s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.9125 acc_train: 0.1929 loss_val: 1.9249 acc_val: 0.2860 time: 0.0435s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.9169 acc_train: 0.1857 loss_val: 1.9218 acc_val: 0.2900 time: 0.0436s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.9051 acc_train: 0.1786 loss_val: 1.9190 acc_val: 0.2760 time: 0.0453s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.9019 acc_train: 0.2500 loss_val: 1.9169 acc_val: 0.2740 time: 0.0435s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.9000 acc_train: 0.2429 loss_val: 1.9151 acc_val: 0.2820 time: 0.0435s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.9027 acc_train: 0.2214 loss_val: 1.9126 acc_val: 0.3160 time: 0.0436s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.8869 acc_train: 0.3143 loss_val: 1.9089 acc_val: 0.3720 time: 0.0443s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.8909 acc_train: 0.2929 loss_val: 1.9049 acc_val: 0.4220 time: 0.0461s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.8864 acc_train: 0.2786 loss_val: 1.9014 acc_val: 0.4620 time: 0.0457s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.8772 acc_train: 0.3071 loss_val: 1.8975 acc_val: 0.5100 time: 0.0434s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.8826 acc_train: 0.3214 loss_val: 1.8932 acc_val: 0.5480 time: 0.0449s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.8758 acc_train: 0.3000 loss_val: 1.8888 acc_val: 0.6320 time: 0.0439s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.8739 acc_train: 0.3786 loss_val: 1.8852 acc_val: 0.6500 time: 0.0445s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.8564 acc_train: 0.3571 loss_val: 1.8812 acc_val: 0.6020 time: 0.0464s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.8657 acc_train: 0.3357 loss_val: 1.8771 acc_val: 0.5860 time: 0.0441s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.8560 acc_train: 0.3429 loss_val: 1.8728 acc_val: 0.5880 time: 0.0438s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.8437 acc_train: 0.3857 loss_val: 1.8680 acc_val: 0.6020 time: 0.0435s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.8396 acc_train: 0.3714 loss_val: 1.8644 acc_val: 0.6020 time: 0.0442s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.8410 acc_train: 0.4000 loss_val: 1.8607 acc_val: 0.6340 time: 0.0437s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.8447 acc_train: 0.3857 loss_val: 1.8570 acc_val: 0.6960 time: 0.0436s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.8239 acc_train: 0.4500 loss_val: 1.8520 acc_val: 0.7460 time: 0.0438s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.8178 acc_train: 0.4071 loss_val: 1.8462 acc_val: 0.7540 time: 0.0453s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.8210 acc_train: 0.4071 loss_val: 1.8410 acc_val: 0.7560 time: 0.0460s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.8054 acc_train: 0.4857 loss_val: 1.8360 acc_val: 0.7440 time: 0.0438s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.7953 acc_train: 0.4000 loss_val: 1.8320 acc_val: 0.7280 time: 0.0438s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.7868 acc_train: 0.4429 loss_val: 1.8287 acc_val: 0.7140 time: 0.0437s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.7895 acc_train: 0.4214 loss_val: 1.8247 acc_val: 0.7240 time: 0.0437s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.7795 acc_train: 0.5286 loss_val: 1.8202 acc_val: 0.7380 time: 0.0488s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.7700 acc_train: 0.4214 loss_val: 1.8149 acc_val: 0.7480 time: 0.0448s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.7594 acc_train: 0.4286 loss_val: 1.8095 acc_val: 0.7300 time: 0.0446s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.7657 acc_train: 0.5071 loss_val: 1.8030 acc_val: 0.7200 time: 0.0444s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.7558 acc_train: 0.4357 loss_val: 1.7949 acc_val: 0.7240 time: 0.0464s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.7310 acc_train: 0.5143 loss_val: 1.7859 acc_val: 0.7280 time: 0.0438s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.7296 acc_train: 0.4429 loss_val: 1.7782 acc_val: 0.7500 time: 0.0435s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.7299 acc_train: 0.5429 loss_val: 1.7701 acc_val: 0.7520 time: 0.0445s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.7183 acc_train: 0.5286 loss_val: 1.7616 acc_val: 0.7720 time: 0.0440s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.7089 acc_train: 0.5071 loss_val: 1.7530 acc_val: 0.7680 time: 0.0445s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.6971 acc_train: 0.5214 loss_val: 1.7445 acc_val: 0.7740 time: 0.0437s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.7048 acc_train: 0.4000 loss_val: 1.7369 acc_val: 0.7740 time: 0.0436s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.6788 acc_train: 0.5071 loss_val: 1.7305 acc_val: 0.7800 time: 0.0456s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.6781 acc_train: 0.4929 loss_val: 1.7231 acc_val: 0.7760 time: 0.0440s\n",
            "0\n",
            "Epoch: 0073 loss_train: 1.6571 acc_train: 0.5571 loss_val: 1.7157 acc_val: 0.7800 time: 0.0447s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.6681 acc_train: 0.5929 loss_val: 1.7077 acc_val: 0.7860 time: 0.0436s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.6335 acc_train: 0.5143 loss_val: 1.6986 acc_val: 0.7740 time: 0.0434s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.6546 acc_train: 0.4571 loss_val: 1.6876 acc_val: 0.7800 time: 0.0439s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.6237 acc_train: 0.5786 loss_val: 1.6778 acc_val: 0.7780 time: 0.0436s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.6369 acc_train: 0.4857 loss_val: 1.6711 acc_val: 0.7900 time: 0.0444s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.6149 acc_train: 0.5143 loss_val: 1.6661 acc_val: 0.7880 time: 0.0463s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.6050 acc_train: 0.5500 loss_val: 1.6638 acc_val: 0.7820 time: 0.0452s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.5963 acc_train: 0.5500 loss_val: 1.6607 acc_val: 0.7720 time: 0.0444s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.5886 acc_train: 0.6143 loss_val: 1.6554 acc_val: 0.7340 time: 0.0437s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.5954 acc_train: 0.5286 loss_val: 1.6472 acc_val: 0.7240 time: 0.0462s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.5588 acc_train: 0.5857 loss_val: 1.6366 acc_val: 0.7440 time: 0.0445s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.6029 acc_train: 0.6000 loss_val: 1.6220 acc_val: 0.7780 time: 0.0437s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.5679 acc_train: 0.5143 loss_val: 1.6077 acc_val: 0.7880 time: 0.0436s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.5717 acc_train: 0.5571 loss_val: 1.5946 acc_val: 0.8020 time: 0.0437s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.5703 acc_train: 0.5857 loss_val: 1.5854 acc_val: 0.8000 time: 0.0459s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.5481 acc_train: 0.5714 loss_val: 1.5787 acc_val: 0.7980 time: 0.0439s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.5273 acc_train: 0.5929 loss_val: 1.5734 acc_val: 0.7980 time: 0.0445s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.5523 acc_train: 0.4857 loss_val: 1.5702 acc_val: 0.8020 time: 0.0450s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.5199 acc_train: 0.5571 loss_val: 1.5669 acc_val: 0.7880 time: 0.0450s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.5161 acc_train: 0.5714 loss_val: 1.5636 acc_val: 0.7820 time: 0.0470s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.5322 acc_train: 0.5214 loss_val: 1.5613 acc_val: 0.7680 time: 0.0441s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.4804 acc_train: 0.4857 loss_val: 1.5553 acc_val: 0.7680 time: 0.0443s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.4918 acc_train: 0.6286 loss_val: 1.5436 acc_val: 0.7720 time: 0.0437s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.4927 acc_train: 0.5929 loss_val: 1.5273 acc_val: 0.7820 time: 0.0439s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.4855 acc_train: 0.5357 loss_val: 1.5093 acc_val: 0.7880 time: 0.0447s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.4889 acc_train: 0.5714 loss_val: 1.4980 acc_val: 0.8020 time: 0.0436s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.4681 acc_train: 0.6357 loss_val: 1.4894 acc_val: 0.7980 time: 0.0439s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.4404 acc_train: 0.5714 loss_val: 1.4838 acc_val: 0.8000 time: 0.0438s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.4632 acc_train: 0.5643 loss_val: 1.4827 acc_val: 0.7960 time: 0.0433s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.4599 acc_train: 0.6000 loss_val: 1.4821 acc_val: 0.7880 time: 0.0450s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.4324 acc_train: 0.6071 loss_val: 1.4821 acc_val: 0.7820 time: 0.0463s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.4397 acc_train: 0.6214 loss_val: 1.4827 acc_val: 0.7740 time: 0.0442s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.4338 acc_train: 0.5571 loss_val: 1.4795 acc_val: 0.7800 time: 0.0447s\n",
            "1\n",
            "Epoch: 0107 loss_train: 1.4398 acc_train: 0.6429 loss_val: 1.4711 acc_val: 0.7780 time: 0.0460s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.4423 acc_train: 0.4929 loss_val: 1.4563 acc_val: 0.7880 time: 0.0442s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.4074 acc_train: 0.6500 loss_val: 1.4387 acc_val: 0.7980 time: 0.0439s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.3824 acc_train: 0.6286 loss_val: 1.4227 acc_val: 0.7960 time: 0.0437s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.4427 acc_train: 0.5214 loss_val: 1.4110 acc_val: 0.7980 time: 0.0436s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.4109 acc_train: 0.6214 loss_val: 1.4019 acc_val: 0.7980 time: 0.0450s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.3964 acc_train: 0.6857 loss_val: 1.3967 acc_val: 0.8020 time: 0.0457s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.3635 acc_train: 0.6643 loss_val: 1.3937 acc_val: 0.7980 time: 0.0433s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.3814 acc_train: 0.6214 loss_val: 1.3936 acc_val: 0.7920 time: 0.0435s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.3886 acc_train: 0.5500 loss_val: 1.3932 acc_val: 0.7940 time: 0.0437s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.3325 acc_train: 0.7000 loss_val: 1.3894 acc_val: 0.7880 time: 0.0433s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.3345 acc_train: 0.6643 loss_val: 1.3837 acc_val: 0.7860 time: 0.0471s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.3835 acc_train: 0.6571 loss_val: 1.3755 acc_val: 0.7860 time: 0.0448s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.3489 acc_train: 0.6500 loss_val: 1.3663 acc_val: 0.8000 time: 0.0445s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.3493 acc_train: 0.5571 loss_val: 1.3566 acc_val: 0.8000 time: 0.0439s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.3348 acc_train: 0.7071 loss_val: 1.3482 acc_val: 0.8000 time: 0.0438s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.3667 acc_train: 0.6286 loss_val: 1.3411 acc_val: 0.8000 time: 0.0462s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.3680 acc_train: 0.5500 loss_val: 1.3368 acc_val: 0.8000 time: 0.0452s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.3193 acc_train: 0.6714 loss_val: 1.3334 acc_val: 0.7980 time: 0.0462s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.3306 acc_train: 0.6571 loss_val: 1.3307 acc_val: 0.7960 time: 0.0436s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.3089 acc_train: 0.6286 loss_val: 1.3243 acc_val: 0.7940 time: 0.0438s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.3591 acc_train: 0.6357 loss_val: 1.3179 acc_val: 0.7940 time: 0.0443s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.3037 acc_train: 0.6214 loss_val: 1.3133 acc_val: 0.7980 time: 0.0437s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.3158 acc_train: 0.6714 loss_val: 1.3086 acc_val: 0.7980 time: 0.0457s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.3340 acc_train: 0.6643 loss_val: 1.3033 acc_val: 0.7980 time: 0.0437s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.2839 acc_train: 0.6286 loss_val: 1.2991 acc_val: 0.8060 time: 0.0440s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.3196 acc_train: 0.5643 loss_val: 1.2955 acc_val: 0.8000 time: 0.0448s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.2827 acc_train: 0.6429 loss_val: 1.2928 acc_val: 0.7980 time: 0.0438s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.3046 acc_train: 0.6429 loss_val: 1.2879 acc_val: 0.8020 time: 0.0439s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.2691 acc_train: 0.6714 loss_val: 1.2826 acc_val: 0.8000 time: 0.0437s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.3026 acc_train: 0.6357 loss_val: 1.2772 acc_val: 0.7960 time: 0.0437s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.2692 acc_train: 0.6286 loss_val: 1.2681 acc_val: 0.7920 time: 0.0456s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.2707 acc_train: 0.6786 loss_val: 1.2579 acc_val: 0.7940 time: 0.0447s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.2691 acc_train: 0.7000 loss_val: 1.2489 acc_val: 0.7960 time: 0.0444s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.2588 acc_train: 0.7214 loss_val: 1.2430 acc_val: 0.7960 time: 0.0442s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.2225 acc_train: 0.6857 loss_val: 1.2399 acc_val: 0.8020 time: 0.0451s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.2757 acc_train: 0.6500 loss_val: 1.2388 acc_val: 0.8020 time: 0.0448s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.2640 acc_train: 0.6929 loss_val: 1.2370 acc_val: 0.8060 time: 0.0439s\n",
            "0\n",
            "Epoch: 0145 loss_train: 1.2467 acc_train: 0.6714 loss_val: 1.2356 acc_val: 0.7980 time: 0.0470s\n",
            "0\n",
            "Epoch: 0146 loss_train: 1.2150 acc_train: 0.7286 loss_val: 1.2329 acc_val: 0.8060 time: 0.0437s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.2850 acc_train: 0.7071 loss_val: 1.2308 acc_val: 0.8020 time: 0.0459s\n",
            "0\n",
            "Epoch: 0148 loss_train: 1.2371 acc_train: 0.7429 loss_val: 1.2291 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.2726 acc_train: 0.6786 loss_val: 1.2232 acc_val: 0.8040 time: 0.0436s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.1931 acc_train: 0.7000 loss_val: 1.2171 acc_val: 0.8120 time: 0.0438s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.2363 acc_train: 0.7000 loss_val: 1.2100 acc_val: 0.8040 time: 0.0439s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.2174 acc_train: 0.7000 loss_val: 1.2026 acc_val: 0.8040 time: 0.0441s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.2030 acc_train: 0.7214 loss_val: 1.1958 acc_val: 0.8080 time: 0.0454s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.2123 acc_train: 0.7357 loss_val: 1.1890 acc_val: 0.8060 time: 0.0449s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.1986 acc_train: 0.7857 loss_val: 1.1846 acc_val: 0.8040 time: 0.0451s\n",
            "0\n",
            "Epoch: 0156 loss_train: 1.2247 acc_train: 0.6786 loss_val: 1.1817 acc_val: 0.8040 time: 0.0437s\n",
            "0\n",
            "Epoch: 0157 loss_train: 1.2175 acc_train: 0.7714 loss_val: 1.1805 acc_val: 0.7980 time: 0.0439s\n",
            "0\n",
            "Epoch: 0158 loss_train: 1.2327 acc_train: 0.6643 loss_val: 1.1779 acc_val: 0.8000 time: 0.0435s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.2113 acc_train: 0.6643 loss_val: 1.1783 acc_val: 0.8000 time: 0.0433s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.2341 acc_train: 0.7214 loss_val: 1.1795 acc_val: 0.8020 time: 0.0453s\n",
            "1\n",
            "Epoch: 0161 loss_train: 1.2137 acc_train: 0.6571 loss_val: 1.1797 acc_val: 0.8060 time: 0.0458s\n",
            "2\n",
            "Epoch: 0162 loss_train: 1.1664 acc_train: 0.7286 loss_val: 1.1740 acc_val: 0.8040 time: 0.0468s\n",
            "3\n",
            "Epoch: 0163 loss_train: 1.1729 acc_train: 0.7214 loss_val: 1.1638 acc_val: 0.8060 time: 0.0436s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.2097 acc_train: 0.6714 loss_val: 1.1535 acc_val: 0.8080 time: 0.0434s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.1750 acc_train: 0.6857 loss_val: 1.1430 acc_val: 0.8120 time: 0.0434s\n",
            "0\n",
            "Epoch: 0166 loss_train: 1.1846 acc_train: 0.6643 loss_val: 1.1378 acc_val: 0.8100 time: 0.0452s\n",
            "0\n",
            "Epoch: 0167 loss_train: 1.2013 acc_train: 0.6500 loss_val: 1.1368 acc_val: 0.8100 time: 0.0447s\n",
            "0\n",
            "Epoch: 0168 loss_train: 1.1541 acc_train: 0.7000 loss_val: 1.1356 acc_val: 0.8080 time: 0.0440s\n",
            "0\n",
            "Epoch: 0169 loss_train: 1.2000 acc_train: 0.6214 loss_val: 1.1340 acc_val: 0.8080 time: 0.0436s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.1606 acc_train: 0.6929 loss_val: 1.1325 acc_val: 0.8000 time: 0.0435s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.1767 acc_train: 0.6429 loss_val: 1.1311 acc_val: 0.8020 time: 0.0434s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.1621 acc_train: 0.7071 loss_val: 1.1287 acc_val: 0.8080 time: 0.0446s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.2262 acc_train: 0.7000 loss_val: 1.1229 acc_val: 0.8100 time: 0.0434s\n",
            "0\n",
            "Epoch: 0174 loss_train: 1.1650 acc_train: 0.7000 loss_val: 1.1177 acc_val: 0.8160 time: 0.0439s\n",
            "0\n",
            "Epoch: 0175 loss_train: 1.1703 acc_train: 0.6786 loss_val: 1.1150 acc_val: 0.8180 time: 0.0435s\n",
            "0\n",
            "Epoch: 0176 loss_train: 1.1832 acc_train: 0.7143 loss_val: 1.1144 acc_val: 0.8160 time: 0.0438s\n",
            "0\n",
            "Epoch: 0177 loss_train: 1.1528 acc_train: 0.7000 loss_val: 1.1083 acc_val: 0.8200 time: 0.0447s\n",
            "0\n",
            "Epoch: 0178 loss_train: 1.1811 acc_train: 0.6857 loss_val: 1.1023 acc_val: 0.8140 time: 0.0442s\n",
            "0\n",
            "Epoch: 0179 loss_train: 1.1050 acc_train: 0.8071 loss_val: 1.0988 acc_val: 0.8220 time: 0.0442s\n",
            "0\n",
            "Epoch: 0180 loss_train: 1.1658 acc_train: 0.7571 loss_val: 1.0958 acc_val: 0.8140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0181 loss_train: 1.1336 acc_train: 0.7143 loss_val: 1.0940 acc_val: 0.8180 time: 0.0439s\n",
            "0\n",
            "Epoch: 0182 loss_train: 1.1850 acc_train: 0.6929 loss_val: 1.0930 acc_val: 0.8140 time: 0.0452s\n",
            "0\n",
            "Epoch: 0183 loss_train: 1.1408 acc_train: 0.7071 loss_val: 1.0896 acc_val: 0.8100 time: 0.0437s\n",
            "0\n",
            "Epoch: 0184 loss_train: 1.1703 acc_train: 0.6786 loss_val: 1.0852 acc_val: 0.8120 time: 0.0447s\n",
            "0\n",
            "Epoch: 0185 loss_train: 1.1166 acc_train: 0.7643 loss_val: 1.0799 acc_val: 0.8160 time: 0.0439s\n",
            "0\n",
            "Epoch: 0186 loss_train: 1.1671 acc_train: 0.6929 loss_val: 1.0787 acc_val: 0.8140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.1503 acc_train: 0.7500 loss_val: 1.0800 acc_val: 0.8160 time: 0.0474s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.1417 acc_train: 0.6929 loss_val: 1.0843 acc_val: 0.8180 time: 0.0440s\n",
            "1\n",
            "Epoch: 0189 loss_train: 1.1380 acc_train: 0.6643 loss_val: 1.0851 acc_val: 0.8200 time: 0.0448s\n",
            "2\n",
            "Epoch: 0190 loss_train: 1.1717 acc_train: 0.6714 loss_val: 1.0836 acc_val: 0.8140 time: 0.0443s\n",
            "3\n",
            "Epoch: 0191 loss_train: 1.1243 acc_train: 0.7071 loss_val: 1.0781 acc_val: 0.8140 time: 0.0446s\n",
            "4\n",
            "Epoch: 0192 loss_train: 1.1478 acc_train: 0.6929 loss_val: 1.0720 acc_val: 0.8140 time: 0.0459s\n",
            "0\n",
            "Epoch: 0193 loss_train: 1.1187 acc_train: 0.7143 loss_val: 1.0664 acc_val: 0.8120 time: 0.0438s\n",
            "0\n",
            "Epoch: 0194 loss_train: 1.1173 acc_train: 0.7357 loss_val: 1.0616 acc_val: 0.8180 time: 0.0436s\n",
            "0\n",
            "Epoch: 0195 loss_train: 1.0983 acc_train: 0.7000 loss_val: 1.0537 acc_val: 0.8180 time: 0.0436s\n",
            "0\n",
            "Epoch: 0196 loss_train: 1.1122 acc_train: 0.7143 loss_val: 1.0475 acc_val: 0.8180 time: 0.0435s\n",
            "0\n",
            "Epoch: 0197 loss_train: 1.1393 acc_train: 0.6929 loss_val: 1.0400 acc_val: 0.8160 time: 0.0484s\n",
            "0\n",
            "Epoch: 0198 loss_train: 1.1626 acc_train: 0.6714 loss_val: 1.0364 acc_val: 0.8180 time: 0.0437s\n",
            "0\n",
            "Epoch: 0199 loss_train: 1.1128 acc_train: 0.7143 loss_val: 1.0372 acc_val: 0.8140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.1381 acc_train: 0.7000 loss_val: 1.0406 acc_val: 0.8160 time: 0.0437s\n",
            "1\n",
            "Epoch: 0201 loss_train: 1.1681 acc_train: 0.7071 loss_val: 1.0424 acc_val: 0.8140 time: 0.0450s\n",
            "2\n",
            "Epoch: 0202 loss_train: 1.0983 acc_train: 0.7500 loss_val: 1.0436 acc_val: 0.8140 time: 0.0449s\n",
            "3\n",
            "Epoch: 0203 loss_train: 1.1394 acc_train: 0.6929 loss_val: 1.0434 acc_val: 0.8160 time: 0.0440s\n",
            "4\n",
            "Epoch: 0204 loss_train: 1.1077 acc_train: 0.8000 loss_val: 1.0390 acc_val: 0.8160 time: 0.0477s\n",
            "5\n",
            "Epoch: 0205 loss_train: 1.1535 acc_train: 0.6929 loss_val: 1.0354 acc_val: 0.8140 time: 0.0455s\n",
            "6\n",
            "Epoch: 0206 loss_train: 1.1247 acc_train: 0.7000 loss_val: 1.0317 acc_val: 0.8160 time: 0.0438s\n",
            "0\n",
            "Epoch: 0207 loss_train: 1.0906 acc_train: 0.7500 loss_val: 1.0263 acc_val: 0.8180 time: 0.0445s\n",
            "0\n",
            "Epoch: 0208 loss_train: 1.1548 acc_train: 0.6786 loss_val: 1.0238 acc_val: 0.8160 time: 0.0452s\n",
            "0\n",
            "Epoch: 0209 loss_train: 1.1093 acc_train: 0.7500 loss_val: 1.0242 acc_val: 0.8180 time: 0.0435s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.0801 acc_train: 0.7429 loss_val: 1.0258 acc_val: 0.8140 time: 0.0454s\n",
            "1\n",
            "Epoch: 0211 loss_train: 1.1049 acc_train: 0.7714 loss_val: 1.0225 acc_val: 0.8140 time: 0.0439s\n",
            "2\n",
            "Epoch: 0212 loss_train: 1.1379 acc_train: 0.6571 loss_val: 1.0196 acc_val: 0.8200 time: 0.0463s\n",
            "0\n",
            "Epoch: 0213 loss_train: 1.1099 acc_train: 0.7214 loss_val: 1.0151 acc_val: 0.8180 time: 0.0456s\n",
            "0\n",
            "Epoch: 0214 loss_train: 1.0957 acc_train: 0.6786 loss_val: 1.0122 acc_val: 0.8160 time: 0.0447s\n",
            "0\n",
            "Epoch: 0215 loss_train: 1.0674 acc_train: 0.7643 loss_val: 1.0106 acc_val: 0.8160 time: 0.0445s\n",
            "0\n",
            "Epoch: 0216 loss_train: 1.1497 acc_train: 0.7357 loss_val: 1.0147 acc_val: 0.8200 time: 0.0435s\n",
            "0\n",
            "Epoch: 0217 loss_train: 1.1289 acc_train: 0.6714 loss_val: 1.0148 acc_val: 0.8220 time: 0.0449s\n",
            "1\n",
            "Epoch: 0218 loss_train: 1.0877 acc_train: 0.7071 loss_val: 1.0143 acc_val: 0.8160 time: 0.0439s\n",
            "0\n",
            "Epoch: 0219 loss_train: 1.1005 acc_train: 0.7571 loss_val: 1.0130 acc_val: 0.8140 time: 0.0442s\n",
            "1\n",
            "Epoch: 0220 loss_train: 1.0645 acc_train: 0.7786 loss_val: 1.0058 acc_val: 0.8140 time: 0.0437s\n",
            "2\n",
            "Epoch: 0221 loss_train: 1.0715 acc_train: 0.7643 loss_val: 0.9991 acc_val: 0.8140 time: 0.0435s\n",
            "0\n",
            "Epoch: 0222 loss_train: 1.0517 acc_train: 0.7857 loss_val: 0.9936 acc_val: 0.8120 time: 0.0447s\n",
            "0\n",
            "Epoch: 0223 loss_train: 1.0848 acc_train: 0.7214 loss_val: 0.9899 acc_val: 0.8120 time: 0.0459s\n",
            "0\n",
            "Epoch: 0224 loss_train: 1.0828 acc_train: 0.6857 loss_val: 0.9865 acc_val: 0.8160 time: 0.0436s\n",
            "0\n",
            "Epoch: 0225 loss_train: 1.0795 acc_train: 0.7071 loss_val: 0.9848 acc_val: 0.8180 time: 0.0438s\n",
            "0\n",
            "Epoch: 0226 loss_train: 1.0327 acc_train: 0.7929 loss_val: 0.9823 acc_val: 0.8160 time: 0.0434s\n",
            "0\n",
            "Epoch: 0227 loss_train: 1.0964 acc_train: 0.7071 loss_val: 0.9829 acc_val: 0.8140 time: 0.0446s\n",
            "0\n",
            "Epoch: 0228 loss_train: 1.1111 acc_train: 0.7643 loss_val: 0.9888 acc_val: 0.8120 time: 0.0476s\n",
            "1\n",
            "Epoch: 0229 loss_train: 1.0815 acc_train: 0.7643 loss_val: 0.9964 acc_val: 0.8140 time: 0.0464s\n",
            "2\n",
            "Epoch: 0230 loss_train: 1.0543 acc_train: 0.6857 loss_val: 0.9977 acc_val: 0.8160 time: 0.0453s\n",
            "3\n",
            "Epoch: 0231 loss_train: 1.1036 acc_train: 0.7786 loss_val: 0.9975 acc_val: 0.8160 time: 0.0447s\n",
            "4\n",
            "Epoch: 0232 loss_train: 1.0600 acc_train: 0.7857 loss_val: 0.9929 acc_val: 0.8200 time: 0.0461s\n",
            "5\n",
            "Epoch: 0233 loss_train: 0.9976 acc_train: 0.7786 loss_val: 0.9860 acc_val: 0.8260 time: 0.0447s\n",
            "6\n",
            "Epoch: 0234 loss_train: 1.0611 acc_train: 0.7786 loss_val: 0.9805 acc_val: 0.8240 time: 0.0439s\n",
            "0\n",
            "Epoch: 0235 loss_train: 1.0689 acc_train: 0.7357 loss_val: 0.9757 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0236 loss_train: 1.0366 acc_train: 0.7714 loss_val: 0.9714 acc_val: 0.8260 time: 0.0456s\n",
            "0\n",
            "Epoch: 0237 loss_train: 1.0688 acc_train: 0.7071 loss_val: 0.9704 acc_val: 0.8200 time: 0.0454s\n",
            "0\n",
            "Epoch: 0238 loss_train: 1.1030 acc_train: 0.7214 loss_val: 0.9736 acc_val: 0.8200 time: 0.0436s\n",
            "0\n",
            "Epoch: 0239 loss_train: 1.0865 acc_train: 0.7143 loss_val: 0.9775 acc_val: 0.8140 time: 0.0450s\n",
            "1\n",
            "Epoch: 0240 loss_train: 1.0839 acc_train: 0.7286 loss_val: 0.9774 acc_val: 0.8120 time: 0.0450s\n",
            "2\n",
            "Epoch: 0241 loss_train: 1.0396 acc_train: 0.7643 loss_val: 0.9755 acc_val: 0.8080 time: 0.0453s\n",
            "3\n",
            "Epoch: 0242 loss_train: 1.0439 acc_train: 0.7143 loss_val: 0.9689 acc_val: 0.8140 time: 0.0463s\n",
            "4\n",
            "Epoch: 0243 loss_train: 1.0314 acc_train: 0.7429 loss_val: 0.9614 acc_val: 0.8200 time: 0.0438s\n",
            "0\n",
            "Epoch: 0244 loss_train: 1.0156 acc_train: 0.7571 loss_val: 0.9539 acc_val: 0.8240 time: 0.0435s\n",
            "0\n",
            "Epoch: 0245 loss_train: 1.0726 acc_train: 0.7429 loss_val: 0.9498 acc_val: 0.8260 time: 0.0439s\n",
            "0\n",
            "Epoch: 0246 loss_train: 1.0220 acc_train: 0.7714 loss_val: 0.9479 acc_val: 0.8260 time: 0.0436s\n",
            "0\n",
            "Epoch: 0247 loss_train: 1.0104 acc_train: 0.8071 loss_val: 0.9508 acc_val: 0.8220 time: 0.0451s\n",
            "0\n",
            "Epoch: 0248 loss_train: 1.0498 acc_train: 0.6714 loss_val: 0.9597 acc_val: 0.8160 time: 0.0444s\n",
            "1\n",
            "Epoch: 0249 loss_train: 1.0696 acc_train: 0.7857 loss_val: 0.9660 acc_val: 0.8120 time: 0.0444s\n",
            "2\n",
            "Epoch: 0250 loss_train: 1.0481 acc_train: 0.7643 loss_val: 0.9697 acc_val: 0.8060 time: 0.0461s\n",
            "3\n",
            "Epoch: 0251 loss_train: 1.0960 acc_train: 0.7571 loss_val: 0.9694 acc_val: 0.8080 time: 0.0456s\n",
            "4\n",
            "Epoch: 0252 loss_train: 1.0360 acc_train: 0.7357 loss_val: 0.9637 acc_val: 0.8100 time: 0.0462s\n",
            "5\n",
            "Epoch: 0253 loss_train: 1.0519 acc_train: 0.7143 loss_val: 0.9528 acc_val: 0.8200 time: 0.0452s\n",
            "6\n",
            "Epoch: 0254 loss_train: 1.0431 acc_train: 0.7643 loss_val: 0.9453 acc_val: 0.8200 time: 0.0442s\n",
            "7\n",
            "Epoch: 0255 loss_train: 1.0268 acc_train: 0.7643 loss_val: 0.9384 acc_val: 0.8260 time: 0.0435s\n",
            "0\n",
            "Epoch: 0256 loss_train: 1.0714 acc_train: 0.7714 loss_val: 0.9351 acc_val: 0.8200 time: 0.0437s\n",
            "0\n",
            "Epoch: 0257 loss_train: 1.0706 acc_train: 0.7429 loss_val: 0.9344 acc_val: 0.8200 time: 0.0457s\n",
            "0\n",
            "Epoch: 0258 loss_train: 1.0691 acc_train: 0.7786 loss_val: 0.9350 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0259 loss_train: 1.0624 acc_train: 0.7714 loss_val: 0.9378 acc_val: 0.8220 time: 0.0461s\n",
            "0\n",
            "Epoch: 0260 loss_train: 1.0172 acc_train: 0.7714 loss_val: 0.9441 acc_val: 0.8160 time: 0.0451s\n",
            "1\n",
            "Epoch: 0261 loss_train: 1.0164 acc_train: 0.8000 loss_val: 0.9479 acc_val: 0.8140 time: 0.0449s\n",
            "2\n",
            "Epoch: 0262 loss_train: 1.0335 acc_train: 0.7714 loss_val: 0.9480 acc_val: 0.8080 time: 0.0451s\n",
            "3\n",
            "Epoch: 0263 loss_train: 0.9869 acc_train: 0.7357 loss_val: 0.9397 acc_val: 0.8100 time: 0.0438s\n",
            "4\n",
            "Epoch: 0264 loss_train: 1.0437 acc_train: 0.7500 loss_val: 0.9300 acc_val: 0.8140 time: 0.0438s\n",
            "5\n",
            "Epoch: 0265 loss_train: 1.0297 acc_train: 0.7714 loss_val: 0.9213 acc_val: 0.8120 time: 0.0439s\n",
            "0\n",
            "Epoch: 0266 loss_train: 1.0360 acc_train: 0.7571 loss_val: 0.9162 acc_val: 0.8180 time: 0.0485s\n",
            "0\n",
            "Epoch: 0267 loss_train: 1.0041 acc_train: 0.7929 loss_val: 0.9175 acc_val: 0.8160 time: 0.0456s\n",
            "0\n",
            "Epoch: 0268 loss_train: 1.0206 acc_train: 0.7000 loss_val: 0.9237 acc_val: 0.8200 time: 0.0443s\n",
            "1\n",
            "Epoch: 0269 loss_train: 1.0293 acc_train: 0.7786 loss_val: 0.9303 acc_val: 0.8260 time: 0.0444s\n",
            "2\n",
            "Epoch: 0270 loss_train: 1.0150 acc_train: 0.7286 loss_val: 0.9339 acc_val: 0.8180 time: 0.0446s\n",
            "3\n",
            "Epoch: 0271 loss_train: 0.9867 acc_train: 0.8000 loss_val: 0.9323 acc_val: 0.8200 time: 0.0447s\n",
            "4\n",
            "Epoch: 0272 loss_train: 0.9790 acc_train: 0.8429 loss_val: 0.9276 acc_val: 0.8200 time: 0.0472s\n",
            "5\n",
            "Epoch: 0273 loss_train: 1.0072 acc_train: 0.8429 loss_val: 0.9193 acc_val: 0.8200 time: 0.0451s\n",
            "6\n",
            "Epoch: 0274 loss_train: 1.0611 acc_train: 0.6786 loss_val: 0.9136 acc_val: 0.8200 time: 0.0442s\n",
            "7\n",
            "Epoch: 0275 loss_train: 1.0216 acc_train: 0.7214 loss_val: 0.9110 acc_val: 0.8180 time: 0.0435s\n",
            "0\n",
            "Epoch: 0276 loss_train: 1.0193 acc_train: 0.7071 loss_val: 0.9118 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0277 loss_train: 0.9496 acc_train: 0.8500 loss_val: 0.9143 acc_val: 0.8220 time: 0.0452s\n",
            "1\n",
            "Epoch: 0278 loss_train: 1.0098 acc_train: 0.7143 loss_val: 0.9179 acc_val: 0.8220 time: 0.0443s\n",
            "2\n",
            "Epoch: 0279 loss_train: 1.0405 acc_train: 0.7857 loss_val: 0.9201 acc_val: 0.8220 time: 0.0456s\n",
            "3\n",
            "Epoch: 0280 loss_train: 0.9928 acc_train: 0.7714 loss_val: 0.9170 acc_val: 0.8180 time: 0.0439s\n",
            "4\n",
            "Epoch: 0281 loss_train: 1.0458 acc_train: 0.7500 loss_val: 0.9135 acc_val: 0.8180 time: 0.0449s\n",
            "5\n",
            "Epoch: 0282 loss_train: 1.0023 acc_train: 0.7571 loss_val: 0.9059 acc_val: 0.8200 time: 0.0449s\n",
            "6\n",
            "Epoch: 0283 loss_train: 0.9934 acc_train: 0.7571 loss_val: 0.8993 acc_val: 0.8200 time: 0.0434s\n",
            "0\n",
            "Epoch: 0284 loss_train: 1.0448 acc_train: 0.7143 loss_val: 0.8989 acc_val: 0.8180 time: 0.0435s\n",
            "0\n",
            "Epoch: 0285 loss_train: 0.9948 acc_train: 0.7857 loss_val: 0.9018 acc_val: 0.8220 time: 0.0443s\n",
            "0\n",
            "Epoch: 0286 loss_train: 0.9816 acc_train: 0.7929 loss_val: 0.9018 acc_val: 0.8220 time: 0.0441s\n",
            "1\n",
            "Epoch: 0287 loss_train: 1.0333 acc_train: 0.7571 loss_val: 0.9018 acc_val: 0.8260 time: 0.0455s\n",
            "2\n",
            "Epoch: 0288 loss_train: 1.0013 acc_train: 0.8429 loss_val: 0.8998 acc_val: 0.8260 time: 0.0450s\n",
            "3\n",
            "Epoch: 0289 loss_train: 1.0076 acc_train: 0.7643 loss_val: 0.8996 acc_val: 0.8240 time: 0.0438s\n",
            "4\n",
            "Epoch: 0290 loss_train: 1.0015 acc_train: 0.8000 loss_val: 0.8999 acc_val: 0.8280 time: 0.0446s\n",
            "5\n",
            "Epoch: 0291 loss_train: 0.9867 acc_train: 0.8214 loss_val: 0.8993 acc_val: 0.8220 time: 0.0453s\n",
            "0\n",
            "Epoch: 0292 loss_train: 1.0026 acc_train: 0.8071 loss_val: 0.8988 acc_val: 0.8240 time: 0.0460s\n",
            "1\n",
            "Epoch: 0293 loss_train: 0.9655 acc_train: 0.7643 loss_val: 0.8989 acc_val: 0.8280 time: 0.0466s\n",
            "0\n",
            "Epoch: 0294 loss_train: 1.0316 acc_train: 0.7571 loss_val: 0.9000 acc_val: 0.8280 time: 0.0457s\n",
            "0\n",
            "Epoch: 0295 loss_train: 0.9964 acc_train: 0.7429 loss_val: 0.8973 acc_val: 0.8240 time: 0.0448s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.9834 acc_train: 0.7714 loss_val: 0.8943 acc_val: 0.8240 time: 0.0452s\n",
            "0\n",
            "Epoch: 0297 loss_train: 1.0006 acc_train: 0.7643 loss_val: 0.8904 acc_val: 0.8200 time: 0.0470s\n",
            "0\n",
            "Epoch: 0298 loss_train: 0.9890 acc_train: 0.7500 loss_val: 0.8889 acc_val: 0.8240 time: 0.0439s\n",
            "0\n",
            "Epoch: 0299 loss_train: 1.0229 acc_train: 0.7643 loss_val: 0.8876 acc_val: 0.8200 time: 0.0438s\n",
            "0\n",
            "Epoch: 0300 loss_train: 1.0047 acc_train: 0.7429 loss_val: 0.8863 acc_val: 0.8240 time: 0.0439s\n",
            "0\n",
            "Epoch: 0301 loss_train: 0.9626 acc_train: 0.7714 loss_val: 0.8860 acc_val: 0.8220 time: 0.0436s\n",
            "0\n",
            "Epoch: 0302 loss_train: 0.9839 acc_train: 0.7714 loss_val: 0.8863 acc_val: 0.8240 time: 0.0459s\n",
            "0\n",
            "Epoch: 0303 loss_train: 0.9401 acc_train: 0.8071 loss_val: 0.8892 acc_val: 0.8260 time: 0.0439s\n",
            "1\n",
            "Epoch: 0304 loss_train: 0.9704 acc_train: 0.7643 loss_val: 0.8893 acc_val: 0.8340 time: 0.0447s\n",
            "2\n",
            "Epoch: 0305 loss_train: 0.9772 acc_train: 0.7929 loss_val: 0.8871 acc_val: 0.8260 time: 0.0458s\n",
            "0\n",
            "Epoch: 0306 loss_train: 1.0018 acc_train: 0.7429 loss_val: 0.8815 acc_val: 0.8280 time: 0.0443s\n",
            "1\n",
            "Epoch: 0307 loss_train: 0.9879 acc_train: 0.7786 loss_val: 0.8765 acc_val: 0.8240 time: 0.0460s\n",
            "0\n",
            "Epoch: 0308 loss_train: 0.9972 acc_train: 0.7500 loss_val: 0.8736 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0309 loss_train: 0.9727 acc_train: 0.7500 loss_val: 0.8715 acc_val: 0.8280 time: 0.0440s\n",
            "0\n",
            "Epoch: 0310 loss_train: 1.0187 acc_train: 0.7643 loss_val: 0.8711 acc_val: 0.8260 time: 0.0437s\n",
            "0\n",
            "Epoch: 0311 loss_train: 0.9933 acc_train: 0.8000 loss_val: 0.8775 acc_val: 0.8260 time: 0.0434s\n",
            "0\n",
            "Epoch: 0312 loss_train: 1.0060 acc_train: 0.8000 loss_val: 0.8829 acc_val: 0.8260 time: 0.0455s\n",
            "1\n",
            "Epoch: 0313 loss_train: 0.9455 acc_train: 0.7357 loss_val: 0.8866 acc_val: 0.8220 time: 0.0440s\n",
            "2\n",
            "Epoch: 0314 loss_train: 1.0009 acc_train: 0.7714 loss_val: 0.8881 acc_val: 0.8140 time: 0.0476s\n",
            "3\n",
            "Epoch: 0315 loss_train: 0.9539 acc_train: 0.7929 loss_val: 0.8875 acc_val: 0.8160 time: 0.0466s\n",
            "4\n",
            "Epoch: 0316 loss_train: 1.0201 acc_train: 0.7429 loss_val: 0.8812 acc_val: 0.8240 time: 0.0439s\n",
            "5\n",
            "Epoch: 0317 loss_train: 0.9829 acc_train: 0.7786 loss_val: 0.8739 acc_val: 0.8260 time: 0.0455s\n",
            "6\n",
            "Epoch: 0318 loss_train: 0.9610 acc_train: 0.8357 loss_val: 0.8695 acc_val: 0.8280 time: 0.0474s\n",
            "7\n",
            "Epoch: 0319 loss_train: 0.9938 acc_train: 0.8000 loss_val: 0.8689 acc_val: 0.8340 time: 0.0448s\n",
            "0\n",
            "Epoch: 0320 loss_train: 0.9527 acc_train: 0.7714 loss_val: 0.8699 acc_val: 0.8380 time: 0.0439s\n",
            "0\n",
            "Epoch: 0321 loss_train: 0.9781 acc_train: 0.7643 loss_val: 0.8733 acc_val: 0.8260 time: 0.0439s\n",
            "0\n",
            "Epoch: 0322 loss_train: 0.9972 acc_train: 0.7214 loss_val: 0.8798 acc_val: 0.8220 time: 0.0455s\n",
            "1\n",
            "Epoch: 0323 loss_train: 1.0216 acc_train: 0.7714 loss_val: 0.8856 acc_val: 0.8220 time: 0.0461s\n",
            "2\n",
            "Epoch: 0324 loss_train: 0.9792 acc_train: 0.7571 loss_val: 0.8898 acc_val: 0.8140 time: 0.0441s\n",
            "3\n",
            "Epoch: 0325 loss_train: 0.9208 acc_train: 0.8071 loss_val: 0.8868 acc_val: 0.8160 time: 0.0438s\n",
            "4\n",
            "Epoch: 0326 loss_train: 0.9874 acc_train: 0.8286 loss_val: 0.8792 acc_val: 0.8180 time: 0.0453s\n",
            "5\n",
            "Epoch: 0327 loss_train: 0.9766 acc_train: 0.7786 loss_val: 0.8683 acc_val: 0.8260 time: 0.0453s\n",
            "6\n",
            "Epoch: 0328 loss_train: 0.9949 acc_train: 0.7857 loss_val: 0.8610 acc_val: 0.8280 time: 0.0437s\n",
            "0\n",
            "Epoch: 0329 loss_train: 0.9722 acc_train: 0.7929 loss_val: 0.8577 acc_val: 0.8300 time: 0.0447s\n",
            "0\n",
            "Epoch: 0330 loss_train: 0.9434 acc_train: 0.7857 loss_val: 0.8574 acc_val: 0.8280 time: 0.0445s\n",
            "0\n",
            "Epoch: 0331 loss_train: 0.9631 acc_train: 0.7643 loss_val: 0.8626 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0332 loss_train: 0.9685 acc_train: 0.7571 loss_val: 0.8707 acc_val: 0.8260 time: 0.0460s\n",
            "1\n",
            "Epoch: 0333 loss_train: 1.0113 acc_train: 0.7571 loss_val: 0.8749 acc_val: 0.8260 time: 0.0448s\n",
            "2\n",
            "Epoch: 0334 loss_train: 0.9656 acc_train: 0.7286 loss_val: 0.8780 acc_val: 0.8140 time: 0.0443s\n",
            "3\n",
            "Epoch: 0335 loss_train: 0.9673 acc_train: 0.8000 loss_val: 0.8762 acc_val: 0.8100 time: 0.0461s\n",
            "4\n",
            "Epoch: 0336 loss_train: 0.9717 acc_train: 0.7143 loss_val: 0.8731 acc_val: 0.8140 time: 0.0442s\n",
            "5\n",
            "Epoch: 0337 loss_train: 1.0085 acc_train: 0.7286 loss_val: 0.8691 acc_val: 0.8200 time: 0.0448s\n",
            "6\n",
            "Epoch: 0338 loss_train: 0.9461 acc_train: 0.7500 loss_val: 0.8640 acc_val: 0.8240 time: 0.0438s\n",
            "7\n",
            "Epoch: 0339 loss_train: 1.0252 acc_train: 0.7214 loss_val: 0.8609 acc_val: 0.8280 time: 0.0438s\n",
            "8\n",
            "Epoch: 0340 loss_train: 1.0123 acc_train: 0.7429 loss_val: 0.8606 acc_val: 0.8280 time: 0.0436s\n",
            "9\n",
            "Epoch: 0341 loss_train: 0.9718 acc_train: 0.7643 loss_val: 0.8607 acc_val: 0.8260 time: 0.0439s\n",
            "10\n",
            "Epoch: 0342 loss_train: 0.9923 acc_train: 0.7714 loss_val: 0.8630 acc_val: 0.8280 time: 0.0457s\n",
            "11\n",
            "Epoch: 0343 loss_train: 0.9651 acc_train: 0.8071 loss_val: 0.8638 acc_val: 0.8300 time: 0.0486s\n",
            "12\n",
            "Epoch: 0344 loss_train: 0.9802 acc_train: 0.7929 loss_val: 0.8624 acc_val: 0.8280 time: 0.0450s\n",
            "13\n",
            "Epoch: 0345 loss_train: 0.9642 acc_train: 0.7929 loss_val: 0.8576 acc_val: 0.8260 time: 0.0438s\n",
            "14\n",
            "Epoch: 0346 loss_train: 1.0037 acc_train: 0.7357 loss_val: 0.8547 acc_val: 0.8300 time: 0.0441s\n",
            "15\n",
            "Epoch: 0347 loss_train: 0.9622 acc_train: 0.7857 loss_val: 0.8541 acc_val: 0.8280 time: 0.0448s\n",
            "0\n",
            "Epoch: 0348 loss_train: 0.9384 acc_train: 0.8143 loss_val: 0.8517 acc_val: 0.8320 time: 0.0453s\n",
            "0\n",
            "Epoch: 0349 loss_train: 0.9838 acc_train: 0.7500 loss_val: 0.8517 acc_val: 0.8340 time: 0.0444s\n",
            "0\n",
            "Epoch: 0350 loss_train: 1.0065 acc_train: 0.7143 loss_val: 0.8550 acc_val: 0.8180 time: 0.0443s\n",
            "0\n",
            "Epoch: 0351 loss_train: 0.9791 acc_train: 0.7929 loss_val: 0.8594 acc_val: 0.8120 time: 0.0440s\n",
            "1\n",
            "Epoch: 0352 loss_train: 0.9868 acc_train: 0.7500 loss_val: 0.8622 acc_val: 0.8120 time: 0.0449s\n",
            "2\n",
            "Epoch: 0353 loss_train: 1.0016 acc_train: 0.7714 loss_val: 0.8649 acc_val: 0.8200 time: 0.0439s\n",
            "3\n",
            "Epoch: 0354 loss_train: 0.9456 acc_train: 0.7857 loss_val: 0.8637 acc_val: 0.8240 time: 0.0442s\n",
            "4\n",
            "Epoch: 0355 loss_train: 0.9513 acc_train: 0.7357 loss_val: 0.8600 acc_val: 0.8220 time: 0.0438s\n",
            "5\n",
            "Epoch: 0356 loss_train: 0.9529 acc_train: 0.8000 loss_val: 0.8542 acc_val: 0.8240 time: 0.0448s\n",
            "6\n",
            "Epoch: 0357 loss_train: 0.9581 acc_train: 0.8071 loss_val: 0.8503 acc_val: 0.8320 time: 0.0470s\n",
            "7\n",
            "Epoch: 0358 loss_train: 0.9689 acc_train: 0.7643 loss_val: 0.8455 acc_val: 0.8300 time: 0.0435s\n",
            "0\n",
            "Epoch: 0359 loss_train: 0.9827 acc_train: 0.8143 loss_val: 0.8430 acc_val: 0.8240 time: 0.0437s\n",
            "0\n",
            "Epoch: 0360 loss_train: 0.9865 acc_train: 0.7714 loss_val: 0.8443 acc_val: 0.8180 time: 0.0439s\n",
            "0\n",
            "Epoch: 0361 loss_train: 0.9309 acc_train: 0.8143 loss_val: 0.8466 acc_val: 0.8200 time: 0.0439s\n",
            "1\n",
            "Epoch: 0362 loss_train: 0.9518 acc_train: 0.7286 loss_val: 0.8508 acc_val: 0.8160 time: 0.0480s\n",
            "2\n",
            "Epoch: 0363 loss_train: 1.0203 acc_train: 0.7357 loss_val: 0.8554 acc_val: 0.8140 time: 0.0442s\n",
            "3\n",
            "Epoch: 0364 loss_train: 0.9408 acc_train: 0.8571 loss_val: 0.8597 acc_val: 0.8160 time: 0.0440s\n",
            "4\n",
            "Epoch: 0365 loss_train: 0.9263 acc_train: 0.8000 loss_val: 0.8642 acc_val: 0.8180 time: 0.0438s\n",
            "5\n",
            "Epoch: 0366 loss_train: 0.9305 acc_train: 0.7714 loss_val: 0.8640 acc_val: 0.8200 time: 0.0439s\n",
            "6\n",
            "Epoch: 0367 loss_train: 1.0196 acc_train: 0.7786 loss_val: 0.8645 acc_val: 0.8220 time: 0.0464s\n",
            "7\n",
            "Epoch: 0368 loss_train: 0.9584 acc_train: 0.7786 loss_val: 0.8607 acc_val: 0.8240 time: 0.0452s\n",
            "8\n",
            "Epoch: 0369 loss_train: 0.9845 acc_train: 0.7429 loss_val: 0.8573 acc_val: 0.8200 time: 0.0442s\n",
            "9\n",
            "Epoch: 0370 loss_train: 1.0076 acc_train: 0.7857 loss_val: 0.8519 acc_val: 0.8180 time: 0.0438s\n",
            "10\n",
            "Epoch: 0371 loss_train: 0.9629 acc_train: 0.8071 loss_val: 0.8460 acc_val: 0.8220 time: 0.0441s\n",
            "11\n",
            "Epoch: 0372 loss_train: 0.9797 acc_train: 0.7857 loss_val: 0.8408 acc_val: 0.8220 time: 0.0449s\n",
            "12\n",
            "Epoch: 0373 loss_train: 0.9794 acc_train: 0.7929 loss_val: 0.8405 acc_val: 0.8220 time: 0.0434s\n",
            "0\n",
            "Epoch: 0374 loss_train: 1.0212 acc_train: 0.7571 loss_val: 0.8464 acc_val: 0.8180 time: 0.0436s\n",
            "0\n",
            "Epoch: 0375 loss_train: 0.9578 acc_train: 0.7643 loss_val: 0.8554 acc_val: 0.8200 time: 0.0441s\n",
            "1\n",
            "Epoch: 0376 loss_train: 0.9457 acc_train: 0.7857 loss_val: 0.8597 acc_val: 0.8200 time: 0.0439s\n",
            "2\n",
            "Epoch: 0377 loss_train: 0.9943 acc_train: 0.8071 loss_val: 0.8583 acc_val: 0.8200 time: 0.0455s\n",
            "3\n",
            "Epoch: 0378 loss_train: 0.9506 acc_train: 0.7857 loss_val: 0.8534 acc_val: 0.8220 time: 0.0451s\n",
            "4\n",
            "Epoch: 0379 loss_train: 1.0004 acc_train: 0.7714 loss_val: 0.8472 acc_val: 0.8200 time: 0.0438s\n",
            "5\n",
            "Epoch: 0380 loss_train: 0.9709 acc_train: 0.7714 loss_val: 0.8438 acc_val: 0.8180 time: 0.0449s\n",
            "6\n",
            "Epoch: 0381 loss_train: 0.9614 acc_train: 0.8357 loss_val: 0.8436 acc_val: 0.8200 time: 0.0437s\n",
            "7\n",
            "Epoch: 0382 loss_train: 0.9679 acc_train: 0.7857 loss_val: 0.8459 acc_val: 0.8200 time: 0.0487s\n",
            "8\n",
            "Epoch: 0383 loss_train: 0.9566 acc_train: 0.7929 loss_val: 0.8444 acc_val: 0.8200 time: 0.0453s\n",
            "9\n",
            "Epoch: 0384 loss_train: 0.9731 acc_train: 0.7643 loss_val: 0.8454 acc_val: 0.8220 time: 0.0453s\n",
            "10\n",
            "Epoch: 0385 loss_train: 0.9992 acc_train: 0.7786 loss_val: 0.8482 acc_val: 0.8240 time: 0.0453s\n",
            "11\n",
            "Epoch: 0386 loss_train: 0.9516 acc_train: 0.7286 loss_val: 0.8532 acc_val: 0.8240 time: 0.0436s\n",
            "12\n",
            "Epoch: 0387 loss_train: 0.9680 acc_train: 0.7857 loss_val: 0.8544 acc_val: 0.8240 time: 0.0459s\n",
            "13\n",
            "Epoch: 0388 loss_train: 0.9435 acc_train: 0.8000 loss_val: 0.8487 acc_val: 0.8260 time: 0.0453s\n",
            "14\n",
            "Epoch: 0389 loss_train: 0.9730 acc_train: 0.7714 loss_val: 0.8438 acc_val: 0.8220 time: 0.0438s\n",
            "15\n",
            "Epoch: 0390 loss_train: 0.9658 acc_train: 0.7929 loss_val: 0.8417 acc_val: 0.8200 time: 0.0439s\n",
            "16\n",
            "Epoch: 0391 loss_train: 0.9747 acc_train: 0.7500 loss_val: 0.8404 acc_val: 0.8240 time: 0.0450s\n",
            "17\n",
            "Epoch: 0392 loss_train: 0.9366 acc_train: 0.7643 loss_val: 0.8396 acc_val: 0.8220 time: 0.0459s\n",
            "0\n",
            "Epoch: 0393 loss_train: 0.9478 acc_train: 0.7786 loss_val: 0.8379 acc_val: 0.8220 time: 0.0448s\n",
            "0\n",
            "Epoch: 0394 loss_train: 0.9696 acc_train: 0.7714 loss_val: 0.8384 acc_val: 0.8260 time: 0.0445s\n",
            "0\n",
            "Epoch: 0395 loss_train: 0.9578 acc_train: 0.7286 loss_val: 0.8411 acc_val: 0.8220 time: 0.0441s\n",
            "1\n",
            "Epoch: 0396 loss_train: 0.9555 acc_train: 0.7714 loss_val: 0.8440 acc_val: 0.8240 time: 0.0442s\n",
            "2\n",
            "Epoch: 0397 loss_train: 0.9805 acc_train: 0.7857 loss_val: 0.8480 acc_val: 0.8200 time: 0.0452s\n",
            "3\n",
            "Epoch: 0398 loss_train: 0.9517 acc_train: 0.7714 loss_val: 0.8464 acc_val: 0.8160 time: 0.0461s\n",
            "4\n",
            "Epoch: 0399 loss_train: 0.9110 acc_train: 0.7857 loss_val: 0.8420 acc_val: 0.8220 time: 0.0460s\n",
            "5\n",
            "Epoch: 0400 loss_train: 0.9541 acc_train: 0.8000 loss_val: 0.8393 acc_val: 0.8260 time: 0.0461s\n",
            "6\n",
            "Epoch: 0401 loss_train: 0.9594 acc_train: 0.7857 loss_val: 0.8403 acc_val: 0.8260 time: 0.0442s\n",
            "7\n",
            "Epoch: 0402 loss_train: 0.9658 acc_train: 0.8143 loss_val: 0.8415 acc_val: 0.8240 time: 0.0446s\n",
            "8\n",
            "Epoch: 0403 loss_train: 0.9385 acc_train: 0.7857 loss_val: 0.8418 acc_val: 0.8200 time: 0.0442s\n",
            "9\n",
            "Epoch: 0404 loss_train: 0.9153 acc_train: 0.8571 loss_val: 0.8419 acc_val: 0.8220 time: 0.0448s\n",
            "10\n",
            "Epoch: 0405 loss_train: 0.9228 acc_train: 0.9071 loss_val: 0.8393 acc_val: 0.8180 time: 0.0441s\n",
            "11\n",
            "Epoch: 0406 loss_train: 0.9326 acc_train: 0.8143 loss_val: 0.8364 acc_val: 0.8200 time: 0.0444s\n",
            "12\n",
            "Epoch: 0407 loss_train: 0.9387 acc_train: 0.7714 loss_val: 0.8350 acc_val: 0.8260 time: 0.0470s\n",
            "0\n",
            "Epoch: 0408 loss_train: 0.9014 acc_train: 0.7500 loss_val: 0.8331 acc_val: 0.8260 time: 0.0444s\n",
            "0\n",
            "Epoch: 0409 loss_train: 0.9591 acc_train: 0.7714 loss_val: 0.8302 acc_val: 0.8260 time: 0.0438s\n",
            "0\n",
            "Epoch: 0410 loss_train: 0.9698 acc_train: 0.7571 loss_val: 0.8271 acc_val: 0.8240 time: 0.0433s\n",
            "0\n",
            "Epoch: 0411 loss_train: 0.9070 acc_train: 0.8071 loss_val: 0.8268 acc_val: 0.8220 time: 0.0435s\n",
            "0\n",
            "Epoch: 0412 loss_train: 0.9412 acc_train: 0.7786 loss_val: 0.8316 acc_val: 0.8260 time: 0.0444s\n",
            "0\n",
            "Epoch: 0413 loss_train: 0.9276 acc_train: 0.7571 loss_val: 0.8406 acc_val: 0.8260 time: 0.0440s\n",
            "1\n",
            "Epoch: 0414 loss_train: 0.9902 acc_train: 0.7214 loss_val: 0.8536 acc_val: 0.8180 time: 0.0442s\n",
            "2\n",
            "Epoch: 0415 loss_train: 0.9386 acc_train: 0.8214 loss_val: 0.8604 acc_val: 0.8160 time: 0.0439s\n",
            "3\n",
            "Epoch: 0416 loss_train: 0.9270 acc_train: 0.7929 loss_val: 0.8603 acc_val: 0.8180 time: 0.0435s\n",
            "4\n",
            "Epoch: 0417 loss_train: 0.8975 acc_train: 0.8071 loss_val: 0.8512 acc_val: 0.8160 time: 0.0446s\n",
            "5\n",
            "Epoch: 0418 loss_train: 0.9189 acc_train: 0.8500 loss_val: 0.8382 acc_val: 0.8240 time: 0.0448s\n",
            "6\n",
            "Epoch: 0419 loss_train: 0.9386 acc_train: 0.8357 loss_val: 0.8268 acc_val: 0.8320 time: 0.0437s\n",
            "7\n",
            "Epoch: 0420 loss_train: 0.9717 acc_train: 0.7500 loss_val: 0.8214 acc_val: 0.8280 time: 0.0444s\n",
            "8\n",
            "Epoch: 0421 loss_train: 0.9524 acc_train: 0.7714 loss_val: 0.8166 acc_val: 0.8260 time: 0.0451s\n",
            "0\n",
            "Epoch: 0422 loss_train: 0.9668 acc_train: 0.7357 loss_val: 0.8178 acc_val: 0.8200 time: 0.0444s\n",
            "0\n",
            "Epoch: 0423 loss_train: 0.9756 acc_train: 0.7929 loss_val: 0.8223 acc_val: 0.8200 time: 0.0436s\n",
            "1\n",
            "Epoch: 0424 loss_train: 0.9788 acc_train: 0.7500 loss_val: 0.8298 acc_val: 0.8160 time: 0.0439s\n",
            "2\n",
            "Epoch: 0425 loss_train: 0.9603 acc_train: 0.7714 loss_val: 0.8414 acc_val: 0.8160 time: 0.0446s\n",
            "3\n",
            "Epoch: 0426 loss_train: 0.9443 acc_train: 0.7429 loss_val: 0.8495 acc_val: 0.8100 time: 0.0441s\n",
            "4\n",
            "Epoch: 0427 loss_train: 0.9271 acc_train: 0.8571 loss_val: 0.8521 acc_val: 0.8160 time: 0.0449s\n",
            "5\n",
            "Epoch: 0428 loss_train: 0.9181 acc_train: 0.8643 loss_val: 0.8502 acc_val: 0.8180 time: 0.0445s\n",
            "6\n",
            "Epoch: 0429 loss_train: 0.9252 acc_train: 0.8286 loss_val: 0.8446 acc_val: 0.8140 time: 0.0480s\n",
            "7\n",
            "Epoch: 0430 loss_train: 0.9223 acc_train: 0.7929 loss_val: 0.8362 acc_val: 0.8180 time: 0.0447s\n",
            "8\n",
            "Epoch: 0431 loss_train: 0.9113 acc_train: 0.7714 loss_val: 0.8276 acc_val: 0.8200 time: 0.0448s\n",
            "9\n",
            "Epoch: 0432 loss_train: 0.9205 acc_train: 0.7929 loss_val: 0.8201 acc_val: 0.8200 time: 0.0452s\n",
            "10\n",
            "Epoch: 0433 loss_train: 0.9309 acc_train: 0.7571 loss_val: 0.8172 acc_val: 0.8240 time: 0.0439s\n",
            "11\n",
            "Epoch: 0434 loss_train: 0.9461 acc_train: 0.7500 loss_val: 0.8184 acc_val: 0.8260 time: 0.0449s\n",
            "12\n",
            "Epoch: 0435 loss_train: 0.9269 acc_train: 0.7786 loss_val: 0.8262 acc_val: 0.8200 time: 0.0449s\n",
            "13\n",
            "Epoch: 0436 loss_train: 0.9676 acc_train: 0.8214 loss_val: 0.8368 acc_val: 0.8220 time: 0.0441s\n",
            "14\n",
            "Epoch: 0437 loss_train: 0.9577 acc_train: 0.8143 loss_val: 0.8440 acc_val: 0.8180 time: 0.0450s\n",
            "15\n",
            "Epoch: 0438 loss_train: 0.9078 acc_train: 0.7643 loss_val: 0.8450 acc_val: 0.8160 time: 0.0439s\n",
            "16\n",
            "Epoch: 0439 loss_train: 0.9623 acc_train: 0.8000 loss_val: 0.8400 acc_val: 0.8180 time: 0.0441s\n",
            "17\n",
            "Epoch: 0440 loss_train: 0.9719 acc_train: 0.7571 loss_val: 0.8344 acc_val: 0.8140 time: 0.0441s\n",
            "18\n",
            "Epoch: 0441 loss_train: 0.9735 acc_train: 0.7643 loss_val: 0.8294 acc_val: 0.8160 time: 0.0441s\n",
            "19\n",
            "Epoch: 0442 loss_train: 0.9227 acc_train: 0.7786 loss_val: 0.8241 acc_val: 0.8160 time: 0.0488s\n",
            "20\n",
            "Epoch: 0443 loss_train: 0.9724 acc_train: 0.8071 loss_val: 0.8240 acc_val: 0.8180 time: 0.0471s\n",
            "21\n",
            "Epoch: 0444 loss_train: 0.8831 acc_train: 0.8500 loss_val: 0.8244 acc_val: 0.8180 time: 0.0453s\n",
            "22\n",
            "Epoch: 0445 loss_train: 0.9707 acc_train: 0.8214 loss_val: 0.8277 acc_val: 0.8180 time: 0.0450s\n",
            "23\n",
            "Epoch: 0446 loss_train: 0.8869 acc_train: 0.7714 loss_val: 0.8286 acc_val: 0.8180 time: 0.0444s\n",
            "24\n",
            "Epoch: 0447 loss_train: 0.9230 acc_train: 0.7929 loss_val: 0.8299 acc_val: 0.8180 time: 0.0456s\n",
            "25\n",
            "Epoch: 0448 loss_train: 0.9999 acc_train: 0.7500 loss_val: 0.8298 acc_val: 0.8180 time: 0.0437s\n",
            "26\n",
            "Epoch: 0449 loss_train: 0.9369 acc_train: 0.8071 loss_val: 0.8249 acc_val: 0.8160 time: 0.0439s\n",
            "27\n",
            "Epoch: 0450 loss_train: 0.9487 acc_train: 0.8286 loss_val: 0.8190 acc_val: 0.8220 time: 0.0436s\n",
            "28\n",
            "Epoch: 0451 loss_train: 0.9493 acc_train: 0.8000 loss_val: 0.8195 acc_val: 0.8220 time: 0.0449s\n",
            "29\n",
            "Epoch: 0452 loss_train: 0.9710 acc_train: 0.7929 loss_val: 0.8245 acc_val: 0.8220 time: 0.0450s\n",
            "30\n",
            "Epoch: 0453 loss_train: 0.9048 acc_train: 0.8143 loss_val: 0.8288 acc_val: 0.8180 time: 0.0441s\n",
            "31\n",
            "Epoch: 0454 loss_train: 0.9331 acc_train: 0.8071 loss_val: 0.8266 acc_val: 0.8240 time: 0.0441s\n",
            "32\n",
            "Epoch: 0455 loss_train: 0.9592 acc_train: 0.7714 loss_val: 0.8264 acc_val: 0.8200 time: 0.0437s\n",
            "33\n",
            "Epoch: 0456 loss_train: 0.9077 acc_train: 0.8000 loss_val: 0.8223 acc_val: 0.8160 time: 0.0438s\n",
            "34\n",
            "Epoch: 0457 loss_train: 0.9975 acc_train: 0.7500 loss_val: 0.8205 acc_val: 0.8220 time: 0.0448s\n",
            "35\n",
            "Epoch: 0458 loss_train: 0.9271 acc_train: 0.8143 loss_val: 0.8207 acc_val: 0.8240 time: 0.0438s\n",
            "36\n",
            "Epoch: 0459 loss_train: 0.9453 acc_train: 0.7643 loss_val: 0.8202 acc_val: 0.8220 time: 0.0438s\n",
            "37\n",
            "Epoch: 0460 loss_train: 0.9442 acc_train: 0.8571 loss_val: 0.8206 acc_val: 0.8180 time: 0.0441s\n",
            "38\n",
            "Epoch: 0461 loss_train: 0.9293 acc_train: 0.7643 loss_val: 0.8225 acc_val: 0.8220 time: 0.0464s\n",
            "39\n",
            "Epoch: 0462 loss_train: 0.9720 acc_train: 0.7786 loss_val: 0.8260 acc_val: 0.8220 time: 0.0467s\n",
            "40\n",
            "Epoch: 0463 loss_train: 0.8846 acc_train: 0.8429 loss_val: 0.8300 acc_val: 0.8100 time: 0.0465s\n",
            "41\n",
            "Epoch: 0464 loss_train: 0.9371 acc_train: 0.7643 loss_val: 0.8305 acc_val: 0.8100 time: 0.0457s\n",
            "42\n",
            "Epoch: 0465 loss_train: 0.9457 acc_train: 0.7714 loss_val: 0.8255 acc_val: 0.8180 time: 0.0439s\n",
            "43\n",
            "Epoch: 0466 loss_train: 0.9205 acc_train: 0.8571 loss_val: 0.8199 acc_val: 0.8180 time: 0.0438s\n",
            "44\n",
            "Epoch: 0467 loss_train: 0.9195 acc_train: 0.7857 loss_val: 0.8155 acc_val: 0.8220 time: 0.0448s\n",
            "45\n",
            "Epoch: 0468 loss_train: 0.9556 acc_train: 0.7929 loss_val: 0.8122 acc_val: 0.8200 time: 0.0442s\n",
            "0\n",
            "Epoch: 0469 loss_train: 0.9577 acc_train: 0.7857 loss_val: 0.8129 acc_val: 0.8220 time: 0.0445s\n",
            "0\n",
            "Epoch: 0470 loss_train: 0.9711 acc_train: 0.7571 loss_val: 0.8171 acc_val: 0.8220 time: 0.0459s\n",
            "1\n",
            "Epoch: 0471 loss_train: 0.9553 acc_train: 0.8143 loss_val: 0.8206 acc_val: 0.8220 time: 0.0444s\n",
            "2\n",
            "Epoch: 0472 loss_train: 0.9622 acc_train: 0.7929 loss_val: 0.8241 acc_val: 0.8200 time: 0.0456s\n",
            "3\n",
            "Epoch: 0473 loss_train: 0.9504 acc_train: 0.8214 loss_val: 0.8290 acc_val: 0.8180 time: 0.0452s\n",
            "4\n",
            "Epoch: 0474 loss_train: 0.8804 acc_train: 0.8786 loss_val: 0.8307 acc_val: 0.8160 time: 0.0441s\n",
            "5\n",
            "Epoch: 0475 loss_train: 0.9370 acc_train: 0.7714 loss_val: 0.8282 acc_val: 0.8180 time: 0.0441s\n",
            "6\n",
            "Epoch: 0476 loss_train: 0.9536 acc_train: 0.8143 loss_val: 0.8227 acc_val: 0.8180 time: 0.0451s\n",
            "7\n",
            "Epoch: 0477 loss_train: 0.9009 acc_train: 0.8429 loss_val: 0.8186 acc_val: 0.8180 time: 0.0450s\n",
            "8\n",
            "Epoch: 0478 loss_train: 0.9184 acc_train: 0.7714 loss_val: 0.8163 acc_val: 0.8180 time: 0.0442s\n",
            "9\n",
            "Epoch: 0479 loss_train: 0.9306 acc_train: 0.8143 loss_val: 0.8155 acc_val: 0.8260 time: 0.0437s\n",
            "10\n",
            "Epoch: 0480 loss_train: 0.9796 acc_train: 0.7857 loss_val: 0.8141 acc_val: 0.8220 time: 0.0438s\n",
            "11\n",
            "Epoch: 0481 loss_train: 0.9506 acc_train: 0.7143 loss_val: 0.8123 acc_val: 0.8240 time: 0.0434s\n",
            "12\n",
            "Epoch: 0482 loss_train: 0.9276 acc_train: 0.7786 loss_val: 0.8141 acc_val: 0.8220 time: 0.0455s\n",
            "13\n",
            "Epoch: 0483 loss_train: 0.9050 acc_train: 0.8429 loss_val: 0.8157 acc_val: 0.8220 time: 0.0452s\n",
            "14\n",
            "Epoch: 0484 loss_train: 0.8941 acc_train: 0.8714 loss_val: 0.8151 acc_val: 0.8180 time: 0.0450s\n",
            "15\n",
            "Epoch: 0485 loss_train: 0.9201 acc_train: 0.8000 loss_val: 0.8129 acc_val: 0.8180 time: 0.0507s\n",
            "16\n",
            "Epoch: 0486 loss_train: 0.9600 acc_train: 0.7929 loss_val: 0.8131 acc_val: 0.8180 time: 0.0454s\n",
            "17\n",
            "Epoch: 0487 loss_train: 0.9170 acc_train: 0.8429 loss_val: 0.8152 acc_val: 0.8140 time: 0.0457s\n",
            "18\n",
            "Epoch: 0488 loss_train: 0.9591 acc_train: 0.8000 loss_val: 0.8183 acc_val: 0.8160 time: 0.0438s\n",
            "19\n",
            "Epoch: 0489 loss_train: 0.8895 acc_train: 0.7714 loss_val: 0.8243 acc_val: 0.8180 time: 0.0443s\n",
            "20\n",
            "Epoch: 0490 loss_train: 0.9454 acc_train: 0.7643 loss_val: 0.8322 acc_val: 0.8180 time: 0.0442s\n",
            "21\n",
            "Epoch: 0491 loss_train: 0.9456 acc_train: 0.7786 loss_val: 0.8334 acc_val: 0.8180 time: 0.0437s\n",
            "22\n",
            "Epoch: 0492 loss_train: 0.9626 acc_train: 0.8429 loss_val: 0.8310 acc_val: 0.8200 time: 0.0468s\n",
            "23\n",
            "Epoch: 0493 loss_train: 0.9507 acc_train: 0.7429 loss_val: 0.8260 acc_val: 0.8180 time: 0.0451s\n",
            "24\n",
            "Epoch: 0494 loss_train: 0.8966 acc_train: 0.7929 loss_val: 0.8183 acc_val: 0.8180 time: 0.0441s\n",
            "25\n",
            "Epoch: 0495 loss_train: 0.9602 acc_train: 0.8071 loss_val: 0.8113 acc_val: 0.8180 time: 0.0447s\n",
            "26\n",
            "Epoch: 0496 loss_train: 0.9507 acc_train: 0.8000 loss_val: 0.8103 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0497 loss_train: 0.9584 acc_train: 0.7143 loss_val: 0.8106 acc_val: 0.8160 time: 0.0448s\n",
            "0\n",
            "Epoch: 0498 loss_train: 0.9662 acc_train: 0.7786 loss_val: 0.8130 acc_val: 0.8140 time: 0.0439s\n",
            "1\n",
            "Epoch: 0499 loss_train: 0.9619 acc_train: 0.8143 loss_val: 0.8191 acc_val: 0.8200 time: 0.0439s\n",
            "2\n",
            "Epoch: 0500 loss_train: 0.9201 acc_train: 0.8429 loss_val: 0.8251 acc_val: 0.8200 time: 0.0451s\n",
            "3\n",
            "Epoch: 0501 loss_train: 0.9220 acc_train: 0.8143 loss_val: 0.8265 acc_val: 0.8200 time: 0.0439s\n",
            "4\n",
            "Epoch: 0502 loss_train: 0.8883 acc_train: 0.8143 loss_val: 0.8230 acc_val: 0.8240 time: 0.0446s\n",
            "5\n",
            "Epoch: 0503 loss_train: 0.9014 acc_train: 0.8214 loss_val: 0.8172 acc_val: 0.8180 time: 0.0442s\n",
            "6\n",
            "Epoch: 0504 loss_train: 0.9188 acc_train: 0.8071 loss_val: 0.8146 acc_val: 0.8240 time: 0.0441s\n",
            "7\n",
            "Epoch: 0505 loss_train: 0.9444 acc_train: 0.7500 loss_val: 0.8130 acc_val: 0.8200 time: 0.0453s\n",
            "8\n",
            "Epoch: 0506 loss_train: 0.9155 acc_train: 0.7929 loss_val: 0.8103 acc_val: 0.8160 time: 0.0442s\n",
            "9\n",
            "Epoch: 0507 loss_train: 0.9388 acc_train: 0.8000 loss_val: 0.8078 acc_val: 0.8140 time: 0.0482s\n",
            "10\n",
            "Epoch: 0508 loss_train: 0.9664 acc_train: 0.7643 loss_val: 0.8096 acc_val: 0.8180 time: 0.0438s\n",
            "0\n",
            "Epoch: 0509 loss_train: 0.9726 acc_train: 0.7286 loss_val: 0.8185 acc_val: 0.8140 time: 0.0443s\n",
            "1\n",
            "Epoch: 0510 loss_train: 0.9266 acc_train: 0.7857 loss_val: 0.8317 acc_val: 0.8180 time: 0.0440s\n",
            "2\n",
            "Epoch: 0511 loss_train: 0.9940 acc_train: 0.7000 loss_val: 0.8399 acc_val: 0.8160 time: 0.0442s\n",
            "3\n",
            "Epoch: 0512 loss_train: 0.9598 acc_train: 0.7929 loss_val: 0.8435 acc_val: 0.8120 time: 0.0445s\n",
            "4\n",
            "Epoch: 0513 loss_train: 0.8997 acc_train: 0.7857 loss_val: 0.8375 acc_val: 0.8140 time: 0.0438s\n",
            "5\n",
            "Epoch: 0514 loss_train: 0.9029 acc_train: 0.8643 loss_val: 0.8253 acc_val: 0.8180 time: 0.0438s\n",
            "6\n",
            "Epoch: 0515 loss_train: 0.9510 acc_train: 0.7857 loss_val: 0.8157 acc_val: 0.8160 time: 0.0455s\n",
            "7\n",
            "Epoch: 0516 loss_train: 0.9215 acc_train: 0.7857 loss_val: 0.8100 acc_val: 0.8180 time: 0.0439s\n",
            "8\n",
            "Epoch: 0517 loss_train: 0.9568 acc_train: 0.7000 loss_val: 0.8095 acc_val: 0.8160 time: 0.0447s\n",
            "9\n",
            "Epoch: 0518 loss_train: 0.9685 acc_train: 0.7357 loss_val: 0.8127 acc_val: 0.8180 time: 0.0466s\n",
            "10\n",
            "Epoch: 0519 loss_train: 0.9491 acc_train: 0.8143 loss_val: 0.8161 acc_val: 0.8180 time: 0.0453s\n",
            "11\n",
            "Epoch: 0520 loss_train: 0.9412 acc_train: 0.7571 loss_val: 0.8214 acc_val: 0.8200 time: 0.0455s\n",
            "12\n",
            "Epoch: 0521 loss_train: 0.9406 acc_train: 0.7714 loss_val: 0.8262 acc_val: 0.8140 time: 0.0446s\n",
            "13\n",
            "Epoch: 0522 loss_train: 0.9007 acc_train: 0.8357 loss_val: 0.8249 acc_val: 0.8120 time: 0.0460s\n",
            "14\n",
            "Epoch: 0523 loss_train: 0.9413 acc_train: 0.8000 loss_val: 0.8197 acc_val: 0.8120 time: 0.0443s\n",
            "15\n",
            "Epoch: 0524 loss_train: 0.9338 acc_train: 0.8214 loss_val: 0.8155 acc_val: 0.8140 time: 0.0445s\n",
            "16\n",
            "Epoch: 0525 loss_train: 0.9420 acc_train: 0.8000 loss_val: 0.8143 acc_val: 0.8140 time: 0.0443s\n",
            "17\n",
            "Epoch: 0526 loss_train: 0.9322 acc_train: 0.7786 loss_val: 0.8149 acc_val: 0.8160 time: 0.0447s\n",
            "18\n",
            "Epoch: 0527 loss_train: 0.9316 acc_train: 0.7357 loss_val: 0.8142 acc_val: 0.8220 time: 0.0465s\n",
            "19\n",
            "Epoch: 0528 loss_train: 0.8823 acc_train: 0.8286 loss_val: 0.8133 acc_val: 0.8180 time: 0.0482s\n",
            "20\n",
            "Epoch: 0529 loss_train: 0.9393 acc_train: 0.7929 loss_val: 0.8141 acc_val: 0.8160 time: 0.0444s\n",
            "21\n",
            "Epoch: 0530 loss_train: 0.9022 acc_train: 0.8071 loss_val: 0.8187 acc_val: 0.8180 time: 0.0443s\n",
            "22\n",
            "Epoch: 0531 loss_train: 0.9348 acc_train: 0.7857 loss_val: 0.8221 acc_val: 0.8200 time: 0.0446s\n",
            "23\n",
            "Epoch: 0532 loss_train: 0.9470 acc_train: 0.7500 loss_val: 0.8280 acc_val: 0.8140 time: 0.0455s\n",
            "24\n",
            "Epoch: 0533 loss_train: 0.8983 acc_train: 0.7929 loss_val: 0.8267 acc_val: 0.8160 time: 0.0437s\n",
            "25\n",
            "Epoch: 0534 loss_train: 0.9127 acc_train: 0.8143 loss_val: 0.8213 acc_val: 0.8180 time: 0.0438s\n",
            "26\n",
            "Epoch: 0535 loss_train: 0.9313 acc_train: 0.7929 loss_val: 0.8176 acc_val: 0.8180 time: 0.0467s\n",
            "27\n",
            "Epoch: 0536 loss_train: 0.9019 acc_train: 0.8071 loss_val: 0.8141 acc_val: 0.8160 time: 0.0440s\n",
            "28\n",
            "Epoch: 0537 loss_train: 0.8748 acc_train: 0.8214 loss_val: 0.8082 acc_val: 0.8200 time: 0.0458s\n",
            "29\n",
            "Epoch: 0538 loss_train: 0.9320 acc_train: 0.7857 loss_val: 0.8047 acc_val: 0.8260 time: 0.0450s\n",
            "30\n",
            "Epoch: 0539 loss_train: 0.9275 acc_train: 0.7929 loss_val: 0.8031 acc_val: 0.8160 time: 0.0457s\n",
            "0\n",
            "Epoch: 0540 loss_train: 0.9381 acc_train: 0.7357 loss_val: 0.8037 acc_val: 0.8120 time: 0.0448s\n",
            "0\n",
            "Epoch: 0541 loss_train: 0.9608 acc_train: 0.8357 loss_val: 0.8094 acc_val: 0.8140 time: 0.0445s\n",
            "1\n",
            "Epoch: 0542 loss_train: 0.9213 acc_train: 0.8071 loss_val: 0.8168 acc_val: 0.8140 time: 0.0455s\n",
            "2\n",
            "Epoch: 0543 loss_train: 0.9328 acc_train: 0.8000 loss_val: 0.8241 acc_val: 0.8140 time: 0.0442s\n",
            "3\n",
            "Epoch: 0544 loss_train: 0.9270 acc_train: 0.8500 loss_val: 0.8252 acc_val: 0.8200 time: 0.0441s\n",
            "4\n",
            "Epoch: 0545 loss_train: 0.9451 acc_train: 0.8000 loss_val: 0.8216 acc_val: 0.8160 time: 0.0460s\n",
            "5\n",
            "Epoch: 0546 loss_train: 0.9496 acc_train: 0.7429 loss_val: 0.8184 acc_val: 0.8160 time: 0.0448s\n",
            "6\n",
            "Epoch: 0547 loss_train: 0.9960 acc_train: 0.7500 loss_val: 0.8143 acc_val: 0.8160 time: 0.0473s\n",
            "7\n",
            "Epoch: 0548 loss_train: 0.9659 acc_train: 0.7786 loss_val: 0.8121 acc_val: 0.8180 time: 0.0466s\n",
            "8\n",
            "Epoch: 0549 loss_train: 0.9247 acc_train: 0.8071 loss_val: 0.8091 acc_val: 0.8220 time: 0.0484s\n",
            "9\n",
            "Epoch: 0550 loss_train: 0.9237 acc_train: 0.8143 loss_val: 0.8061 acc_val: 0.8220 time: 0.0458s\n",
            "10\n",
            "Epoch: 0551 loss_train: 0.9766 acc_train: 0.7571 loss_val: 0.8070 acc_val: 0.8220 time: 0.0445s\n",
            "11\n",
            "Epoch: 0552 loss_train: 0.8919 acc_train: 0.7929 loss_val: 0.8096 acc_val: 0.8200 time: 0.0450s\n",
            "12\n",
            "Epoch: 0553 loss_train: 0.9129 acc_train: 0.8286 loss_val: 0.8169 acc_val: 0.8140 time: 0.0439s\n",
            "13\n",
            "Epoch: 0554 loss_train: 0.9122 acc_train: 0.8071 loss_val: 0.8257 acc_val: 0.8120 time: 0.0438s\n",
            "14\n",
            "Epoch: 0555 loss_train: 0.9147 acc_train: 0.7714 loss_val: 0.8304 acc_val: 0.8160 time: 0.0490s\n",
            "15\n",
            "Epoch: 0556 loss_train: 0.9238 acc_train: 0.7714 loss_val: 0.8309 acc_val: 0.8100 time: 0.0461s\n",
            "16\n",
            "Epoch: 0557 loss_train: 0.9363 acc_train: 0.7786 loss_val: 0.8258 acc_val: 0.8160 time: 0.0450s\n",
            "17\n",
            "Epoch: 0558 loss_train: 0.9430 acc_train: 0.8000 loss_val: 0.8200 acc_val: 0.8220 time: 0.0441s\n",
            "18\n",
            "Epoch: 0559 loss_train: 0.9359 acc_train: 0.7929 loss_val: 0.8135 acc_val: 0.8180 time: 0.0451s\n",
            "19\n",
            "Epoch: 0560 loss_train: 0.8872 acc_train: 0.7786 loss_val: 0.8074 acc_val: 0.8280 time: 0.0447s\n",
            "20\n",
            "Epoch: 0561 loss_train: 0.9531 acc_train: 0.7786 loss_val: 0.8044 acc_val: 0.8300 time: 0.0448s\n",
            "21\n",
            "Epoch: 0562 loss_train: 0.9647 acc_train: 0.7857 loss_val: 0.8040 acc_val: 0.8320 time: 0.0450s\n",
            "22\n",
            "Epoch: 0563 loss_train: 0.9119 acc_train: 0.8143 loss_val: 0.8064 acc_val: 0.8300 time: 0.0438s\n",
            "23\n",
            "Epoch: 0564 loss_train: 0.9231 acc_train: 0.8214 loss_val: 0.8104 acc_val: 0.8200 time: 0.0443s\n",
            "24\n",
            "Epoch: 0565 loss_train: 0.9759 acc_train: 0.7643 loss_val: 0.8145 acc_val: 0.8220 time: 0.0439s\n",
            "25\n",
            "Epoch: 0566 loss_train: 0.9179 acc_train: 0.8000 loss_val: 0.8180 acc_val: 0.8160 time: 0.0441s\n",
            "26\n",
            "Epoch: 0567 loss_train: 0.9420 acc_train: 0.8143 loss_val: 0.8180 acc_val: 0.8160 time: 0.0449s\n",
            "27\n",
            "Epoch: 0568 loss_train: 0.9344 acc_train: 0.7929 loss_val: 0.8151 acc_val: 0.8220 time: 0.0442s\n",
            "28\n",
            "Epoch: 0569 loss_train: 0.9332 acc_train: 0.7929 loss_val: 0.8111 acc_val: 0.8220 time: 0.0447s\n",
            "29\n",
            "Epoch: 0570 loss_train: 0.8985 acc_train: 0.8071 loss_val: 0.8082 acc_val: 0.8240 time: 0.0451s\n",
            "30\n",
            "Epoch: 0571 loss_train: 0.9299 acc_train: 0.8286 loss_val: 0.8045 acc_val: 0.8240 time: 0.0456s\n",
            "31\n",
            "Epoch: 0572 loss_train: 0.9084 acc_train: 0.8143 loss_val: 0.8018 acc_val: 0.8240 time: 0.0453s\n",
            "32\n",
            "Epoch: 0573 loss_train: 0.9815 acc_train: 0.7857 loss_val: 0.8047 acc_val: 0.8180 time: 0.0433s\n",
            "0\n",
            "Epoch: 0574 loss_train: 0.9417 acc_train: 0.7571 loss_val: 0.8094 acc_val: 0.8160 time: 0.0450s\n",
            "1\n",
            "Epoch: 0575 loss_train: 0.9328 acc_train: 0.7429 loss_val: 0.8106 acc_val: 0.8200 time: 0.0455s\n",
            "2\n",
            "Epoch: 0576 loss_train: 0.8999 acc_train: 0.8143 loss_val: 0.8103 acc_val: 0.8160 time: 0.0439s\n",
            "3\n",
            "Epoch: 0577 loss_train: 0.9075 acc_train: 0.7786 loss_val: 0.8093 acc_val: 0.8180 time: 0.0476s\n",
            "4\n",
            "Epoch: 0578 loss_train: 0.9444 acc_train: 0.8000 loss_val: 0.8089 acc_val: 0.8200 time: 0.0475s\n",
            "5\n",
            "Epoch: 0579 loss_train: 0.9336 acc_train: 0.8071 loss_val: 0.8097 acc_val: 0.8260 time: 0.0449s\n",
            "6\n",
            "Epoch: 0580 loss_train: 0.9103 acc_train: 0.8000 loss_val: 0.8120 acc_val: 0.8280 time: 0.0439s\n",
            "7\n",
            "Epoch: 0581 loss_train: 0.9129 acc_train: 0.8357 loss_val: 0.8150 acc_val: 0.8280 time: 0.0439s\n",
            "8\n",
            "Epoch: 0582 loss_train: 0.9356 acc_train: 0.8286 loss_val: 0.8146 acc_val: 0.8300 time: 0.0459s\n",
            "9\n",
            "Epoch: 0583 loss_train: 0.9536 acc_train: 0.7929 loss_val: 0.8136 acc_val: 0.8280 time: 0.0447s\n",
            "10\n",
            "Epoch: 0584 loss_train: 0.9116 acc_train: 0.7786 loss_val: 0.8139 acc_val: 0.8220 time: 0.0458s\n",
            "11\n",
            "Epoch: 0585 loss_train: 0.9133 acc_train: 0.8214 loss_val: 0.8129 acc_val: 0.8200 time: 0.0449s\n",
            "12\n",
            "Epoch: 0586 loss_train: 0.9575 acc_train: 0.7357 loss_val: 0.8107 acc_val: 0.8200 time: 0.0449s\n",
            "13\n",
            "Epoch: 0587 loss_train: 0.9561 acc_train: 0.7500 loss_val: 0.8092 acc_val: 0.8160 time: 0.0458s\n",
            "14\n",
            "Epoch: 0588 loss_train: 0.9296 acc_train: 0.7857 loss_val: 0.8059 acc_val: 0.8160 time: 0.0450s\n",
            "15\n",
            "Epoch: 0589 loss_train: 0.9292 acc_train: 0.7500 loss_val: 0.8038 acc_val: 0.8200 time: 0.0444s\n",
            "16\n",
            "Epoch: 0590 loss_train: 0.9124 acc_train: 0.7500 loss_val: 0.8039 acc_val: 0.8260 time: 0.0440s\n",
            "17\n",
            "Epoch: 0591 loss_train: 0.9172 acc_train: 0.8143 loss_val: 0.8056 acc_val: 0.8260 time: 0.0444s\n",
            "18\n",
            "Epoch: 0592 loss_train: 0.9196 acc_train: 0.7571 loss_val: 0.8100 acc_val: 0.8220 time: 0.0477s\n",
            "19\n",
            "Epoch: 0593 loss_train: 0.9510 acc_train: 0.7857 loss_val: 0.8147 acc_val: 0.8200 time: 0.0446s\n",
            "20\n",
            "Epoch: 0594 loss_train: 0.9047 acc_train: 0.7500 loss_val: 0.8161 acc_val: 0.8200 time: 0.0446s\n",
            "21\n",
            "Epoch: 0595 loss_train: 0.9347 acc_train: 0.7929 loss_val: 0.8130 acc_val: 0.8280 time: 0.0439s\n",
            "22\n",
            "Epoch: 0596 loss_train: 0.9152 acc_train: 0.7857 loss_val: 0.8070 acc_val: 0.8300 time: 0.0441s\n",
            "23\n",
            "Epoch: 0597 loss_train: 0.9723 acc_train: 0.8143 loss_val: 0.8024 acc_val: 0.8180 time: 0.0451s\n",
            "24\n",
            "Epoch: 0598 loss_train: 0.9071 acc_train: 0.8071 loss_val: 0.7988 acc_val: 0.8200 time: 0.0438s\n",
            "25\n",
            "Epoch: 0599 loss_train: 0.9194 acc_train: 0.8143 loss_val: 0.7976 acc_val: 0.8200 time: 0.0437s\n",
            "0\n",
            "Epoch: 0600 loss_train: 0.9752 acc_train: 0.8000 loss_val: 0.7998 acc_val: 0.8260 time: 0.0437s\n",
            "0\n",
            "Epoch: 0601 loss_train: 0.9160 acc_train: 0.7786 loss_val: 0.8031 acc_val: 0.8220 time: 0.0438s\n",
            "1\n",
            "Epoch: 0602 loss_train: 0.9078 acc_train: 0.8571 loss_val: 0.8083 acc_val: 0.8200 time: 0.0450s\n",
            "2\n",
            "Epoch: 0603 loss_train: 0.9520 acc_train: 0.7500 loss_val: 0.8119 acc_val: 0.8260 time: 0.0443s\n",
            "3\n",
            "Epoch: 0604 loss_train: 0.8898 acc_train: 0.8143 loss_val: 0.8110 acc_val: 0.8220 time: 0.0441s\n",
            "4\n",
            "Epoch: 0605 loss_train: 0.9195 acc_train: 0.8214 loss_val: 0.8061 acc_val: 0.8220 time: 0.0443s\n",
            "5\n",
            "Epoch: 0606 loss_train: 0.9323 acc_train: 0.7500 loss_val: 0.8048 acc_val: 0.8180 time: 0.0445s\n",
            "6\n",
            "Epoch: 0607 loss_train: 0.9205 acc_train: 0.7929 loss_val: 0.8058 acc_val: 0.8160 time: 0.0451s\n",
            "7\n",
            "Epoch: 0608 loss_train: 0.9187 acc_train: 0.7357 loss_val: 0.8057 acc_val: 0.8160 time: 0.0441s\n",
            "8\n",
            "Epoch: 0609 loss_train: 0.9060 acc_train: 0.7929 loss_val: 0.8037 acc_val: 0.8140 time: 0.0440s\n",
            "9\n",
            "Epoch: 0610 loss_train: 0.9257 acc_train: 0.7929 loss_val: 0.8015 acc_val: 0.8160 time: 0.0444s\n",
            "10\n",
            "Epoch: 0611 loss_train: 0.9154 acc_train: 0.7929 loss_val: 0.8020 acc_val: 0.8240 time: 0.0442s\n",
            "11\n",
            "Epoch: 0612 loss_train: 0.9589 acc_train: 0.7786 loss_val: 0.8066 acc_val: 0.8260 time: 0.0448s\n",
            "12\n",
            "Epoch: 0613 loss_train: 0.9579 acc_train: 0.7929 loss_val: 0.8127 acc_val: 0.8240 time: 0.0446s\n",
            "13\n",
            "Epoch: 0614 loss_train: 0.9531 acc_train: 0.8214 loss_val: 0.8181 acc_val: 0.8200 time: 0.0482s\n",
            "14\n",
            "Epoch: 0615 loss_train: 0.9133 acc_train: 0.7929 loss_val: 0.8202 acc_val: 0.8180 time: 0.0440s\n",
            "15\n",
            "Epoch: 0616 loss_train: 0.8798 acc_train: 0.8071 loss_val: 0.8184 acc_val: 0.8160 time: 0.0459s\n",
            "16\n",
            "Epoch: 0617 loss_train: 0.9537 acc_train: 0.7786 loss_val: 0.8139 acc_val: 0.8160 time: 0.0447s\n",
            "17\n",
            "Epoch: 0618 loss_train: 0.9005 acc_train: 0.7714 loss_val: 0.8087 acc_val: 0.8140 time: 0.0437s\n",
            "18\n",
            "Epoch: 0619 loss_train: 0.9261 acc_train: 0.7929 loss_val: 0.8050 acc_val: 0.8140 time: 0.0442s\n",
            "19\n",
            "Epoch: 0620 loss_train: 0.9069 acc_train: 0.7929 loss_val: 0.8040 acc_val: 0.8160 time: 0.0439s\n",
            "20\n",
            "Epoch: 0621 loss_train: 0.9531 acc_train: 0.7429 loss_val: 0.8062 acc_val: 0.8240 time: 0.0443s\n",
            "21\n",
            "Epoch: 0622 loss_train: 0.9319 acc_train: 0.8214 loss_val: 0.8092 acc_val: 0.8240 time: 0.0471s\n",
            "22\n",
            "Epoch: 0623 loss_train: 0.9512 acc_train: 0.7571 loss_val: 0.8127 acc_val: 0.8240 time: 0.0450s\n",
            "23\n",
            "Epoch: 0624 loss_train: 0.9289 acc_train: 0.8071 loss_val: 0.8130 acc_val: 0.8200 time: 0.0446s\n",
            "24\n",
            "Epoch: 0625 loss_train: 0.9236 acc_train: 0.7571 loss_val: 0.8139 acc_val: 0.8180 time: 0.0445s\n",
            "25\n",
            "Epoch: 0626 loss_train: 0.9591 acc_train: 0.7643 loss_val: 0.8157 acc_val: 0.8140 time: 0.0440s\n",
            "26\n",
            "Epoch: 0627 loss_train: 1.0017 acc_train: 0.7714 loss_val: 0.8158 acc_val: 0.8160 time: 0.0449s\n",
            "27\n",
            "Epoch: 0628 loss_train: 0.9371 acc_train: 0.8286 loss_val: 0.8147 acc_val: 0.8140 time: 0.0437s\n",
            "28\n",
            "Epoch: 0629 loss_train: 0.9022 acc_train: 0.7929 loss_val: 0.8095 acc_val: 0.8160 time: 0.0437s\n",
            "29\n",
            "Epoch: 0630 loss_train: 0.9462 acc_train: 0.7786 loss_val: 0.8063 acc_val: 0.8200 time: 0.0440s\n",
            "30\n",
            "Epoch: 0631 loss_train: 0.9136 acc_train: 0.8071 loss_val: 0.8048 acc_val: 0.8180 time: 0.0441s\n",
            "31\n",
            "Epoch: 0632 loss_train: 0.9378 acc_train: 0.8000 loss_val: 0.8040 acc_val: 0.8180 time: 0.0461s\n",
            "32\n",
            "Epoch: 0633 loss_train: 0.9271 acc_train: 0.7571 loss_val: 0.8025 acc_val: 0.8200 time: 0.0437s\n",
            "33\n",
            "Epoch: 0634 loss_train: 0.9961 acc_train: 0.7857 loss_val: 0.8050 acc_val: 0.8200 time: 0.0446s\n",
            "34\n",
            "Epoch: 0635 loss_train: 0.9301 acc_train: 0.8286 loss_val: 0.8093 acc_val: 0.8200 time: 0.0492s\n",
            "35\n",
            "Epoch: 0636 loss_train: 0.9326 acc_train: 0.8429 loss_val: 0.8124 acc_val: 0.8140 time: 0.0466s\n",
            "36\n",
            "Epoch: 0637 loss_train: 0.9454 acc_train: 0.7143 loss_val: 0.8149 acc_val: 0.8120 time: 0.0451s\n",
            "37\n",
            "Epoch: 0638 loss_train: 0.9307 acc_train: 0.7500 loss_val: 0.8178 acc_val: 0.8120 time: 0.0438s\n",
            "38\n",
            "Epoch: 0639 loss_train: 0.9449 acc_train: 0.8214 loss_val: 0.8209 acc_val: 0.8120 time: 0.0437s\n",
            "39\n",
            "Epoch: 0640 loss_train: 0.9353 acc_train: 0.7857 loss_val: 0.8206 acc_val: 0.8140 time: 0.0437s\n",
            "40\n",
            "Epoch: 0641 loss_train: 0.8983 acc_train: 0.8143 loss_val: 0.8160 acc_val: 0.8180 time: 0.0438s\n",
            "41\n",
            "Epoch: 0642 loss_train: 0.9092 acc_train: 0.8214 loss_val: 0.8096 acc_val: 0.8160 time: 0.0448s\n",
            "42\n",
            "Epoch: 0643 loss_train: 0.8742 acc_train: 0.8357 loss_val: 0.8050 acc_val: 0.8220 time: 0.0439s\n",
            "43\n",
            "Epoch: 0644 loss_train: 0.9690 acc_train: 0.8143 loss_val: 0.8031 acc_val: 0.8300 time: 0.0451s\n",
            "44\n",
            "Epoch: 0645 loss_train: 0.9515 acc_train: 0.7500 loss_val: 0.8035 acc_val: 0.8280 time: 0.0437s\n",
            "45\n",
            "Epoch: 0646 loss_train: 0.9030 acc_train: 0.8000 loss_val: 0.8061 acc_val: 0.8180 time: 0.0438s\n",
            "46\n",
            "Epoch: 0647 loss_train: 0.8775 acc_train: 0.8071 loss_val: 0.8099 acc_val: 0.8160 time: 0.0449s\n",
            "47\n",
            "Epoch: 0648 loss_train: 0.8598 acc_train: 0.8000 loss_val: 0.8123 acc_val: 0.8200 time: 0.0445s\n",
            "48\n",
            "Epoch: 0649 loss_train: 0.9675 acc_train: 0.7714 loss_val: 0.8147 acc_val: 0.8160 time: 0.0500s\n",
            "49\n",
            "Epoch: 0650 loss_train: 0.8959 acc_train: 0.8071 loss_val: 0.8131 acc_val: 0.8180 time: 0.0455s\n",
            "50\n",
            "Epoch: 0651 loss_train: 0.9071 acc_train: 0.8357 loss_val: 0.8100 acc_val: 0.8220 time: 0.0452s\n",
            "51\n",
            "Epoch: 0652 loss_train: 0.9143 acc_train: 0.7786 loss_val: 0.8076 acc_val: 0.8220 time: 0.0463s\n",
            "52\n",
            "Epoch: 0653 loss_train: 0.9300 acc_train: 0.8071 loss_val: 0.8046 acc_val: 0.8240 time: 0.0454s\n",
            "53\n",
            "Epoch: 0654 loss_train: 0.9148 acc_train: 0.8857 loss_val: 0.8050 acc_val: 0.8200 time: 0.0475s\n",
            "54\n",
            "Epoch: 0655 loss_train: 0.9370 acc_train: 0.7357 loss_val: 0.8067 acc_val: 0.8180 time: 0.0450s\n",
            "55\n",
            "Epoch: 0656 loss_train: 0.9618 acc_train: 0.7429 loss_val: 0.8104 acc_val: 0.8120 time: 0.0442s\n",
            "56\n",
            "Epoch: 0657 loss_train: 0.9264 acc_train: 0.8071 loss_val: 0.8136 acc_val: 0.8180 time: 0.0473s\n",
            "57\n",
            "Epoch: 0658 loss_train: 0.8996 acc_train: 0.8143 loss_val: 0.8142 acc_val: 0.8160 time: 0.0441s\n",
            "58\n",
            "Epoch: 0659 loss_train: 0.8951 acc_train: 0.7714 loss_val: 0.8129 acc_val: 0.8180 time: 0.0435s\n",
            "59\n",
            "Epoch: 0660 loss_train: 0.9314 acc_train: 0.8643 loss_val: 0.8100 acc_val: 0.8180 time: 0.0438s\n",
            "60\n",
            "Epoch: 0661 loss_train: 0.8943 acc_train: 0.7571 loss_val: 0.8049 acc_val: 0.8200 time: 0.0439s\n",
            "61\n",
            "Epoch: 0662 loss_train: 0.8669 acc_train: 0.7929 loss_val: 0.7999 acc_val: 0.8220 time: 0.0458s\n",
            "62\n",
            "Epoch: 0663 loss_train: 0.9373 acc_train: 0.8286 loss_val: 0.7975 acc_val: 0.8280 time: 0.0442s\n",
            "63\n",
            "Epoch: 0664 loss_train: 0.8939 acc_train: 0.8214 loss_val: 0.7982 acc_val: 0.8240 time: 0.0437s\n",
            "0\n",
            "Epoch: 0665 loss_train: 0.9129 acc_train: 0.7929 loss_val: 0.8018 acc_val: 0.8200 time: 0.0438s\n",
            "1\n",
            "Epoch: 0666 loss_train: 0.9236 acc_train: 0.8071 loss_val: 0.8035 acc_val: 0.8200 time: 0.0439s\n",
            "2\n",
            "Epoch: 0667 loss_train: 0.9596 acc_train: 0.7786 loss_val: 0.8052 acc_val: 0.8200 time: 0.0448s\n",
            "3\n",
            "Epoch: 0668 loss_train: 0.9108 acc_train: 0.8143 loss_val: 0.8080 acc_val: 0.8160 time: 0.0439s\n",
            "4\n",
            "Epoch: 0669 loss_train: 0.9089 acc_train: 0.7929 loss_val: 0.8109 acc_val: 0.8240 time: 0.0438s\n",
            "5\n",
            "Epoch: 0670 loss_train: 0.8818 acc_train: 0.8214 loss_val: 0.8110 acc_val: 0.8180 time: 0.0436s\n",
            "6\n",
            "Epoch: 0671 loss_train: 0.8954 acc_train: 0.8571 loss_val: 0.8105 acc_val: 0.8180 time: 0.0446s\n",
            "7\n",
            "Epoch: 0672 loss_train: 0.8947 acc_train: 0.7929 loss_val: 0.8089 acc_val: 0.8160 time: 0.0451s\n",
            "8\n",
            "Epoch: 0673 loss_train: 0.9328 acc_train: 0.8071 loss_val: 0.8077 acc_val: 0.8240 time: 0.0454s\n",
            "9\n",
            "Epoch: 0674 loss_train: 0.9107 acc_train: 0.8143 loss_val: 0.8036 acc_val: 0.8220 time: 0.0449s\n",
            "10\n",
            "Epoch: 0675 loss_train: 0.9131 acc_train: 0.8071 loss_val: 0.7987 acc_val: 0.8200 time: 0.0464s\n",
            "11\n",
            "Epoch: 0676 loss_train: 0.9203 acc_train: 0.7786 loss_val: 0.7964 acc_val: 0.8200 time: 0.0438s\n",
            "12\n",
            "Epoch: 0677 loss_train: 0.9093 acc_train: 0.8143 loss_val: 0.7969 acc_val: 0.8240 time: 0.0444s\n",
            "0\n",
            "Epoch: 0678 loss_train: 0.9472 acc_train: 0.7714 loss_val: 0.7974 acc_val: 0.8220 time: 0.0475s\n",
            "1\n",
            "Epoch: 0679 loss_train: 0.8996 acc_train: 0.8714 loss_val: 0.7996 acc_val: 0.8240 time: 0.0442s\n",
            "2\n",
            "Epoch: 0680 loss_train: 0.8882 acc_train: 0.8357 loss_val: 0.8023 acc_val: 0.8200 time: 0.0442s\n",
            "3\n",
            "Epoch: 0681 loss_train: 0.9144 acc_train: 0.8071 loss_val: 0.8045 acc_val: 0.8200 time: 0.0440s\n",
            "4\n",
            "Epoch: 0682 loss_train: 0.9033 acc_train: 0.7571 loss_val: 0.8071 acc_val: 0.8220 time: 0.0480s\n",
            "5\n",
            "Epoch: 0683 loss_train: 0.9292 acc_train: 0.7929 loss_val: 0.8048 acc_val: 0.8180 time: 0.0440s\n",
            "6\n",
            "Epoch: 0684 loss_train: 0.9227 acc_train: 0.7357 loss_val: 0.8029 acc_val: 0.8140 time: 0.0437s\n",
            "7\n",
            "Epoch: 0685 loss_train: 0.9333 acc_train: 0.8071 loss_val: 0.8047 acc_val: 0.8160 time: 0.0465s\n",
            "8\n",
            "Epoch: 0686 loss_train: 0.9425 acc_train: 0.8071 loss_val: 0.8086 acc_val: 0.8180 time: 0.0446s\n",
            "9\n",
            "Epoch: 0687 loss_train: 0.9109 acc_train: 0.8143 loss_val: 0.8102 acc_val: 0.8180 time: 0.0459s\n",
            "10\n",
            "Epoch: 0688 loss_train: 0.9510 acc_train: 0.7429 loss_val: 0.8084 acc_val: 0.8200 time: 0.0441s\n",
            "11\n",
            "Epoch: 0689 loss_train: 0.9299 acc_train: 0.7929 loss_val: 0.8061 acc_val: 0.8200 time: 0.0439s\n",
            "12\n",
            "Epoch: 0690 loss_train: 0.9064 acc_train: 0.8357 loss_val: 0.8042 acc_val: 0.8240 time: 0.0480s\n",
            "13\n",
            "Epoch: 0691 loss_train: 0.9613 acc_train: 0.8214 loss_val: 0.8034 acc_val: 0.8220 time: 0.0458s\n",
            "14\n",
            "Epoch: 0692 loss_train: 0.9005 acc_train: 0.8071 loss_val: 0.8015 acc_val: 0.8200 time: 0.0459s\n",
            "15\n",
            "Epoch: 0693 loss_train: 0.9046 acc_train: 0.7786 loss_val: 0.8018 acc_val: 0.8240 time: 0.0442s\n",
            "16\n",
            "Epoch: 0694 loss_train: 0.9227 acc_train: 0.8500 loss_val: 0.8011 acc_val: 0.8260 time: 0.0440s\n",
            "17\n",
            "Epoch: 0695 loss_train: 0.9413 acc_train: 0.7714 loss_val: 0.8003 acc_val: 0.8260 time: 0.0444s\n",
            "18\n",
            "Epoch: 0696 loss_train: 0.9454 acc_train: 0.7929 loss_val: 0.8001 acc_val: 0.8240 time: 0.0441s\n",
            "19\n",
            "Epoch: 0697 loss_train: 0.9581 acc_train: 0.7929 loss_val: 0.8019 acc_val: 0.8200 time: 0.0449s\n",
            "20\n",
            "Epoch: 0698 loss_train: 0.9319 acc_train: 0.8143 loss_val: 0.8051 acc_val: 0.8180 time: 0.0454s\n",
            "21\n",
            "Epoch: 0699 loss_train: 0.9039 acc_train: 0.8214 loss_val: 0.8093 acc_val: 0.8200 time: 0.0449s\n",
            "22\n",
            "Epoch: 0700 loss_train: 0.9341 acc_train: 0.7929 loss_val: 0.8125 acc_val: 0.8260 time: 0.0457s\n",
            "23\n",
            "Epoch: 0701 loss_train: 0.9259 acc_train: 0.8357 loss_val: 0.8104 acc_val: 0.8220 time: 0.0438s\n",
            "24\n",
            "Epoch: 0702 loss_train: 0.9258 acc_train: 0.8286 loss_val: 0.8043 acc_val: 0.8240 time: 0.0457s\n",
            "25\n",
            "Epoch: 0703 loss_train: 0.8989 acc_train: 0.7929 loss_val: 0.7980 acc_val: 0.8280 time: 0.0438s\n",
            "26\n",
            "Epoch: 0704 loss_train: 0.9305 acc_train: 0.7786 loss_val: 0.7955 acc_val: 0.8260 time: 0.0437s\n",
            "27\n",
            "Epoch: 0705 loss_train: 0.9523 acc_train: 0.7929 loss_val: 0.7967 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0706 loss_train: 0.8790 acc_train: 0.8000 loss_val: 0.7981 acc_val: 0.8220 time: 0.0441s\n",
            "1\n",
            "Epoch: 0707 loss_train: 0.9539 acc_train: 0.7643 loss_val: 0.8001 acc_val: 0.8200 time: 0.0445s\n",
            "2\n",
            "Epoch: 0708 loss_train: 0.9309 acc_train: 0.8143 loss_val: 0.8028 acc_val: 0.8240 time: 0.0436s\n",
            "3\n",
            "Epoch: 0709 loss_train: 0.9285 acc_train: 0.8000 loss_val: 0.8058 acc_val: 0.8140 time: 0.0438s\n",
            "4\n",
            "Epoch: 0710 loss_train: 0.8716 acc_train: 0.8357 loss_val: 0.8071 acc_val: 0.8180 time: 0.0437s\n",
            "5\n",
            "Epoch: 0711 loss_train: 0.9670 acc_train: 0.7857 loss_val: 0.8070 acc_val: 0.8220 time: 0.0439s\n",
            "6\n",
            "Epoch: 0712 loss_train: 0.9334 acc_train: 0.7929 loss_val: 0.8074 acc_val: 0.8260 time: 0.0459s\n",
            "7\n",
            "Epoch: 0713 loss_train: 0.9175 acc_train: 0.8357 loss_val: 0.8064 acc_val: 0.8260 time: 0.0440s\n",
            "8\n",
            "Epoch: 0714 loss_train: 0.9013 acc_train: 0.8143 loss_val: 0.8064 acc_val: 0.8240 time: 0.0438s\n",
            "9\n",
            "Epoch: 0715 loss_train: 0.8964 acc_train: 0.7500 loss_val: 0.8062 acc_val: 0.8240 time: 0.0440s\n",
            "10\n",
            "Epoch: 0716 loss_train: 0.9515 acc_train: 0.8000 loss_val: 0.8065 acc_val: 0.8200 time: 0.0442s\n",
            "11\n",
            "Epoch: 0717 loss_train: 0.8993 acc_train: 0.8143 loss_val: 0.8064 acc_val: 0.8140 time: 0.0456s\n",
            "12\n",
            "Epoch: 0718 loss_train: 0.9301 acc_train: 0.7571 loss_val: 0.8063 acc_val: 0.8220 time: 0.0444s\n",
            "13\n",
            "Epoch: 0719 loss_train: 0.8834 acc_train: 0.8429 loss_val: 0.8058 acc_val: 0.8220 time: 0.0439s\n",
            "14\n",
            "Epoch: 0720 loss_train: 0.9159 acc_train: 0.8357 loss_val: 0.8021 acc_val: 0.8240 time: 0.0444s\n",
            "15\n",
            "Epoch: 0721 loss_train: 0.9093 acc_train: 0.7857 loss_val: 0.8001 acc_val: 0.8260 time: 0.0497s\n",
            "16\n",
            "Epoch: 0722 loss_train: 0.9382 acc_train: 0.8143 loss_val: 0.7975 acc_val: 0.8240 time: 0.0488s\n",
            "17\n",
            "Epoch: 0723 loss_train: 0.9103 acc_train: 0.8214 loss_val: 0.7969 acc_val: 0.8260 time: 0.0441s\n",
            "18\n",
            "Epoch: 0724 loss_train: 0.9316 acc_train: 0.8071 loss_val: 0.7986 acc_val: 0.8260 time: 0.0438s\n",
            "19\n",
            "Epoch: 0725 loss_train: 0.9092 acc_train: 0.8286 loss_val: 0.8002 acc_val: 0.8320 time: 0.0438s\n",
            "20\n",
            "Epoch: 0726 loss_train: 0.8898 acc_train: 0.8357 loss_val: 0.8044 acc_val: 0.8220 time: 0.0446s\n",
            "21\n",
            "Epoch: 0727 loss_train: 0.8936 acc_train: 0.8643 loss_val: 0.8068 acc_val: 0.8200 time: 0.0453s\n",
            "22\n",
            "Epoch: 0728 loss_train: 0.9639 acc_train: 0.7714 loss_val: 0.8101 acc_val: 0.8180 time: 0.0457s\n",
            "23\n",
            "Epoch: 0729 loss_train: 0.9136 acc_train: 0.8000 loss_val: 0.8126 acc_val: 0.8160 time: 0.0470s\n",
            "24\n",
            "Epoch: 0730 loss_train: 0.9681 acc_train: 0.8357 loss_val: 0.8126 acc_val: 0.8200 time: 0.0447s\n",
            "25\n",
            "Epoch: 0731 loss_train: 0.9686 acc_train: 0.7214 loss_val: 0.8109 acc_val: 0.8200 time: 0.0449s\n",
            "26\n",
            "Epoch: 0732 loss_train: 0.9448 acc_train: 0.7286 loss_val: 0.8087 acc_val: 0.8180 time: 0.0458s\n",
            "27\n",
            "Epoch: 0733 loss_train: 0.9325 acc_train: 0.7786 loss_val: 0.8054 acc_val: 0.8200 time: 0.0437s\n",
            "28\n",
            "Epoch: 0734 loss_train: 0.9378 acc_train: 0.7714 loss_val: 0.8066 acc_val: 0.8280 time: 0.0438s\n",
            "29\n",
            "Epoch: 0735 loss_train: 0.9242 acc_train: 0.8000 loss_val: 0.8057 acc_val: 0.8280 time: 0.0438s\n",
            "30\n",
            "Epoch: 0736 loss_train: 0.9305 acc_train: 0.7714 loss_val: 0.8050 acc_val: 0.8340 time: 0.0454s\n",
            "31\n",
            "Epoch: 0737 loss_train: 0.9244 acc_train: 0.8000 loss_val: 0.8035 acc_val: 0.8280 time: 0.0461s\n",
            "32\n",
            "Epoch: 0738 loss_train: 0.9147 acc_train: 0.8357 loss_val: 0.8025 acc_val: 0.8220 time: 0.0446s\n",
            "33\n",
            "Epoch: 0739 loss_train: 0.9377 acc_train: 0.7286 loss_val: 0.8036 acc_val: 0.8180 time: 0.0437s\n",
            "34\n",
            "Epoch: 0740 loss_train: 0.8753 acc_train: 0.8000 loss_val: 0.8044 acc_val: 0.8180 time: 0.0438s\n",
            "35\n",
            "Epoch: 0741 loss_train: 0.9014 acc_train: 0.8214 loss_val: 0.8080 acc_val: 0.8140 time: 0.0438s\n",
            "36\n",
            "Epoch: 0742 loss_train: 0.9011 acc_train: 0.7857 loss_val: 0.8112 acc_val: 0.8160 time: 0.0458s\n",
            "37\n",
            "Epoch: 0743 loss_train: 0.9566 acc_train: 0.7571 loss_val: 0.8131 acc_val: 0.8140 time: 0.0474s\n",
            "38\n",
            "Epoch: 0744 loss_train: 0.8917 acc_train: 0.7786 loss_val: 0.8116 acc_val: 0.8140 time: 0.0439s\n",
            "39\n",
            "Epoch: 0745 loss_train: 0.8981 acc_train: 0.8071 loss_val: 0.8081 acc_val: 0.8160 time: 0.0448s\n",
            "40\n",
            "Epoch: 0746 loss_train: 0.9254 acc_train: 0.8571 loss_val: 0.8043 acc_val: 0.8280 time: 0.0441s\n",
            "41\n",
            "Epoch: 0747 loss_train: 0.9213 acc_train: 0.7929 loss_val: 0.8008 acc_val: 0.8340 time: 0.0447s\n",
            "42\n",
            "Epoch: 0748 loss_train: 0.9150 acc_train: 0.8143 loss_val: 0.7998 acc_val: 0.8320 time: 0.0437s\n",
            "43\n",
            "Epoch: 0749 loss_train: 0.9604 acc_train: 0.8214 loss_val: 0.8007 acc_val: 0.8320 time: 0.0439s\n",
            "44\n",
            "Epoch: 0750 loss_train: 0.9070 acc_train: 0.7929 loss_val: 0.8035 acc_val: 0.8240 time: 0.0443s\n",
            "45\n",
            "Epoch: 0751 loss_train: 0.9210 acc_train: 0.8000 loss_val: 0.8061 acc_val: 0.8260 time: 0.0455s\n",
            "46\n",
            "Epoch: 0752 loss_train: 0.9305 acc_train: 0.8357 loss_val: 0.8081 acc_val: 0.8240 time: 0.0455s\n",
            "47\n",
            "Epoch: 0753 loss_train: 0.9178 acc_train: 0.8071 loss_val: 0.8097 acc_val: 0.8220 time: 0.0450s\n",
            "48\n",
            "Epoch: 0754 loss_train: 0.9471 acc_train: 0.7643 loss_val: 0.8083 acc_val: 0.8220 time: 0.0457s\n",
            "49\n",
            "Epoch: 0755 loss_train: 0.9283 acc_train: 0.7929 loss_val: 0.8056 acc_val: 0.8180 time: 0.0439s\n",
            "50\n",
            "Epoch: 0756 loss_train: 0.9352 acc_train: 0.7714 loss_val: 0.8008 acc_val: 0.8220 time: 0.0438s\n",
            "51\n",
            "Epoch: 0757 loss_train: 0.9325 acc_train: 0.7571 loss_val: 0.7992 acc_val: 0.8260 time: 0.0447s\n",
            "52\n",
            "Epoch: 0758 loss_train: 0.9316 acc_train: 0.8071 loss_val: 0.7996 acc_val: 0.8260 time: 0.0442s\n",
            "53\n",
            "Epoch: 0759 loss_train: 0.9148 acc_train: 0.8357 loss_val: 0.7996 acc_val: 0.8220 time: 0.0441s\n",
            "54\n",
            "Epoch: 0760 loss_train: 0.9155 acc_train: 0.8143 loss_val: 0.8000 acc_val: 0.8220 time: 0.0438s\n",
            "55\n",
            "Epoch: 0761 loss_train: 0.9267 acc_train: 0.7714 loss_val: 0.8033 acc_val: 0.8260 time: 0.0441s\n",
            "56\n",
            "Epoch: 0762 loss_train: 0.9132 acc_train: 0.8071 loss_val: 0.8063 acc_val: 0.8240 time: 0.0455s\n",
            "57\n",
            "Epoch: 0763 loss_train: 0.9290 acc_train: 0.7643 loss_val: 0.8077 acc_val: 0.8260 time: 0.0473s\n",
            "58\n",
            "Epoch: 0764 loss_train: 0.9325 acc_train: 0.8000 loss_val: 0.8079 acc_val: 0.8200 time: 0.0491s\n",
            "59\n",
            "Epoch: 0765 loss_train: 0.8939 acc_train: 0.8429 loss_val: 0.8040 acc_val: 0.8180 time: 0.0441s\n",
            "60\n",
            "Epoch: 0766 loss_train: 0.8870 acc_train: 0.8500 loss_val: 0.7992 acc_val: 0.8240 time: 0.0440s\n",
            "61\n",
            "Epoch: 0767 loss_train: 0.9221 acc_train: 0.7857 loss_val: 0.7968 acc_val: 0.8220 time: 0.0451s\n",
            "62\n",
            "Epoch: 0768 loss_train: 0.9005 acc_train: 0.8143 loss_val: 0.7952 acc_val: 0.8220 time: 0.0440s\n",
            "63\n",
            "Epoch: 0769 loss_train: 0.8714 acc_train: 0.8500 loss_val: 0.7928 acc_val: 0.8260 time: 0.0435s\n",
            "0\n",
            "Epoch: 0770 loss_train: 0.8576 acc_train: 0.8143 loss_val: 0.7930 acc_val: 0.8240 time: 0.0436s\n",
            "0\n",
            "Epoch: 0771 loss_train: 0.9194 acc_train: 0.7643 loss_val: 0.7975 acc_val: 0.8220 time: 0.0440s\n",
            "1\n",
            "Epoch: 0772 loss_train: 0.9057 acc_train: 0.8143 loss_val: 0.8001 acc_val: 0.8200 time: 0.0456s\n",
            "2\n",
            "Epoch: 0773 loss_train: 0.8777 acc_train: 0.8500 loss_val: 0.8020 acc_val: 0.8180 time: 0.0436s\n",
            "3\n",
            "Epoch: 0774 loss_train: 0.9261 acc_train: 0.7500 loss_val: 0.8023 acc_val: 0.8180 time: 0.0438s\n",
            "4\n",
            "Epoch: 0775 loss_train: 0.8939 acc_train: 0.7786 loss_val: 0.8022 acc_val: 0.8200 time: 0.0450s\n",
            "5\n",
            "Epoch: 0776 loss_train: 0.9411 acc_train: 0.7071 loss_val: 0.7992 acc_val: 0.8200 time: 0.0452s\n",
            "6\n",
            "Epoch: 0777 loss_train: 0.9483 acc_train: 0.7857 loss_val: 0.7973 acc_val: 0.8280 time: 0.0459s\n",
            "7\n",
            "Epoch: 0778 loss_train: 0.9153 acc_train: 0.7786 loss_val: 0.7957 acc_val: 0.8240 time: 0.0448s\n",
            "8\n",
            "Epoch: 0779 loss_train: 0.8988 acc_train: 0.7643 loss_val: 0.7958 acc_val: 0.8200 time: 0.0452s\n",
            "9\n",
            "Epoch: 0780 loss_train: 0.9928 acc_train: 0.7500 loss_val: 0.7990 acc_val: 0.8200 time: 0.0450s\n",
            "10\n",
            "Epoch: 0781 loss_train: 0.9063 acc_train: 0.8214 loss_val: 0.8022 acc_val: 0.8200 time: 0.0444s\n",
            "11\n",
            "Epoch: 0782 loss_train: 0.9234 acc_train: 0.7500 loss_val: 0.8025 acc_val: 0.8180 time: 0.0457s\n",
            "12\n",
            "Epoch: 0783 loss_train: 0.9503 acc_train: 0.8000 loss_val: 0.8022 acc_val: 0.8180 time: 0.0458s\n",
            "13\n",
            "Epoch: 0784 loss_train: 0.9054 acc_train: 0.8000 loss_val: 0.8024 acc_val: 0.8160 time: 0.0457s\n",
            "14\n",
            "Epoch: 0785 loss_train: 0.9047 acc_train: 0.7857 loss_val: 0.8017 acc_val: 0.8200 time: 0.0464s\n",
            "15\n",
            "Epoch: 0786 loss_train: 0.9476 acc_train: 0.7786 loss_val: 0.7981 acc_val: 0.8220 time: 0.0454s\n",
            "16\n",
            "Epoch: 0787 loss_train: 0.9008 acc_train: 0.8000 loss_val: 0.7964 acc_val: 0.8280 time: 0.0451s\n",
            "17\n",
            "Epoch: 0788 loss_train: 0.8913 acc_train: 0.7929 loss_val: 0.7942 acc_val: 0.8260 time: 0.0452s\n",
            "18\n",
            "Epoch: 0789 loss_train: 0.9215 acc_train: 0.8286 loss_val: 0.7951 acc_val: 0.8280 time: 0.0441s\n",
            "19\n",
            "Epoch: 0790 loss_train: 0.9132 acc_train: 0.8429 loss_val: 0.7963 acc_val: 0.8220 time: 0.0437s\n",
            "20\n",
            "Epoch: 0791 loss_train: 0.9073 acc_train: 0.7500 loss_val: 0.8001 acc_val: 0.8180 time: 0.0449s\n",
            "21\n",
            "Epoch: 0792 loss_train: 0.9206 acc_train: 0.7571 loss_val: 0.8059 acc_val: 0.8180 time: 0.0450s\n",
            "22\n",
            "Epoch: 0793 loss_train: 0.9639 acc_train: 0.7929 loss_val: 0.8108 acc_val: 0.8180 time: 0.0452s\n",
            "23\n",
            "Epoch: 0794 loss_train: 0.9334 acc_train: 0.8286 loss_val: 0.8137 acc_val: 0.8220 time: 0.0439s\n",
            "24\n",
            "Epoch: 0795 loss_train: 0.9293 acc_train: 0.7786 loss_val: 0.8156 acc_val: 0.8200 time: 0.0440s\n",
            "25\n",
            "Epoch: 0796 loss_train: 0.9634 acc_train: 0.8143 loss_val: 0.8141 acc_val: 0.8180 time: 0.0440s\n",
            "26\n",
            "Epoch: 0797 loss_train: 0.9336 acc_train: 0.7857 loss_val: 0.8096 acc_val: 0.8160 time: 0.0453s\n",
            "27\n",
            "Epoch: 0798 loss_train: 0.9370 acc_train: 0.8000 loss_val: 0.8019 acc_val: 0.8160 time: 0.0437s\n",
            "28\n",
            "Epoch: 0799 loss_train: 0.9049 acc_train: 0.8429 loss_val: 0.7956 acc_val: 0.8240 time: 0.0436s\n",
            "29\n",
            "Epoch: 0800 loss_train: 0.9292 acc_train: 0.7929 loss_val: 0.7914 acc_val: 0.8280 time: 0.0438s\n",
            "30\n",
            "Epoch: 0801 loss_train: 0.9140 acc_train: 0.7929 loss_val: 0.7905 acc_val: 0.8180 time: 0.0443s\n",
            "0\n",
            "Epoch: 0802 loss_train: 0.9208 acc_train: 0.8286 loss_val: 0.7926 acc_val: 0.8200 time: 0.0458s\n",
            "0\n",
            "Epoch: 0803 loss_train: 0.9052 acc_train: 0.8214 loss_val: 0.7983 acc_val: 0.8200 time: 0.0469s\n",
            "1\n",
            "Epoch: 0804 loss_train: 0.8946 acc_train: 0.8143 loss_val: 0.8032 acc_val: 0.8200 time: 0.0464s\n",
            "2\n",
            "Epoch: 0805 loss_train: 0.9187 acc_train: 0.8214 loss_val: 0.8080 acc_val: 0.8160 time: 0.0443s\n",
            "3\n",
            "Epoch: 0806 loss_train: 0.9157 acc_train: 0.8000 loss_val: 0.8117 acc_val: 0.8140 time: 0.0438s\n",
            "4\n",
            "Epoch: 0807 loss_train: 0.8860 acc_train: 0.8357 loss_val: 0.8073 acc_val: 0.8120 time: 0.0474s\n",
            "5\n",
            "Epoch: 0808 loss_train: 0.8686 acc_train: 0.8000 loss_val: 0.7993 acc_val: 0.8080 time: 0.0445s\n",
            "6\n",
            "Epoch: 0809 loss_train: 0.8824 acc_train: 0.8000 loss_val: 0.7919 acc_val: 0.8140 time: 0.0436s\n",
            "7\n",
            "Epoch: 0810 loss_train: 0.9183 acc_train: 0.8214 loss_val: 0.7879 acc_val: 0.8220 time: 0.0437s\n",
            "8\n",
            "Epoch: 0811 loss_train: 0.8978 acc_train: 0.8357 loss_val: 0.7852 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0812 loss_train: 0.9568 acc_train: 0.8143 loss_val: 0.7875 acc_val: 0.8300 time: 0.0450s\n",
            "0\n",
            "Epoch: 0813 loss_train: 0.9263 acc_train: 0.7786 loss_val: 0.7945 acc_val: 0.8240 time: 0.0444s\n",
            "1\n",
            "Epoch: 0814 loss_train: 0.9380 acc_train: 0.7786 loss_val: 0.8035 acc_val: 0.8120 time: 0.0452s\n",
            "2\n",
            "Epoch: 0815 loss_train: 0.9210 acc_train: 0.7500 loss_val: 0.8118 acc_val: 0.8120 time: 0.0448s\n",
            "3\n",
            "Epoch: 0816 loss_train: 0.8931 acc_train: 0.8143 loss_val: 0.8114 acc_val: 0.8100 time: 0.0439s\n",
            "4\n",
            "Epoch: 0817 loss_train: 0.8883 acc_train: 0.8571 loss_val: 0.8093 acc_val: 0.8100 time: 0.0452s\n",
            "5\n",
            "Epoch: 0818 loss_train: 0.9164 acc_train: 0.7857 loss_val: 0.8013 acc_val: 0.8080 time: 0.0439s\n",
            "6\n",
            "Epoch: 0819 loss_train: 0.9256 acc_train: 0.8286 loss_val: 0.7936 acc_val: 0.8140 time: 0.0441s\n",
            "7\n",
            "Epoch: 0820 loss_train: 0.9140 acc_train: 0.8143 loss_val: 0.7885 acc_val: 0.8160 time: 0.0438s\n",
            "8\n",
            "Epoch: 0821 loss_train: 0.9334 acc_train: 0.7714 loss_val: 0.7872 acc_val: 0.8220 time: 0.0449s\n",
            "9\n",
            "Epoch: 0822 loss_train: 0.9511 acc_train: 0.7857 loss_val: 0.7870 acc_val: 0.8260 time: 0.0448s\n",
            "10\n",
            "Epoch: 0823 loss_train: 0.9040 acc_train: 0.8429 loss_val: 0.7904 acc_val: 0.8220 time: 0.0459s\n",
            "11\n",
            "Epoch: 0824 loss_train: 0.9104 acc_train: 0.7714 loss_val: 0.7978 acc_val: 0.8120 time: 0.0447s\n",
            "12\n",
            "Epoch: 0825 loss_train: 0.8924 acc_train: 0.8286 loss_val: 0.8072 acc_val: 0.8080 time: 0.0453s\n",
            "13\n",
            "Epoch: 0826 loss_train: 0.8774 acc_train: 0.8000 loss_val: 0.8114 acc_val: 0.8060 time: 0.0438s\n",
            "14\n",
            "Epoch: 0827 loss_train: 0.8776 acc_train: 0.8000 loss_val: 0.8126 acc_val: 0.8120 time: 0.0447s\n",
            "15\n",
            "Epoch: 0828 loss_train: 0.8896 acc_train: 0.8714 loss_val: 0.8084 acc_val: 0.8180 time: 0.0439s\n",
            "16\n",
            "Epoch: 0829 loss_train: 0.9003 acc_train: 0.8286 loss_val: 0.8010 acc_val: 0.8180 time: 0.0454s\n",
            "17\n",
            "Epoch: 0830 loss_train: 0.8798 acc_train: 0.7857 loss_val: 0.7917 acc_val: 0.8180 time: 0.0437s\n",
            "18\n",
            "Epoch: 0831 loss_train: 0.8865 acc_train: 0.8000 loss_val: 0.7833 acc_val: 0.8260 time: 0.0477s\n",
            "19\n",
            "Epoch: 0832 loss_train: 0.9140 acc_train: 0.7786 loss_val: 0.7810 acc_val: 0.8240 time: 0.0453s\n",
            "0\n",
            "Epoch: 0833 loss_train: 0.8697 acc_train: 0.8143 loss_val: 0.7816 acc_val: 0.8240 time: 0.0437s\n",
            "0\n",
            "Epoch: 0834 loss_train: 0.9192 acc_train: 0.8357 loss_val: 0.7857 acc_val: 0.8240 time: 0.0439s\n",
            "1\n",
            "Epoch: 0835 loss_train: 0.8977 acc_train: 0.8429 loss_val: 0.7904 acc_val: 0.8180 time: 0.0439s\n",
            "2\n",
            "Epoch: 0836 loss_train: 0.8995 acc_train: 0.8714 loss_val: 0.8014 acc_val: 0.8200 time: 0.0440s\n",
            "3\n",
            "Epoch: 0837 loss_train: 0.9328 acc_train: 0.8143 loss_val: 0.8116 acc_val: 0.8140 time: 0.0455s\n",
            "4\n",
            "Epoch: 0838 loss_train: 0.9140 acc_train: 0.7786 loss_val: 0.8123 acc_val: 0.8180 time: 0.0450s\n",
            "5\n",
            "Epoch: 0839 loss_train: 0.8661 acc_train: 0.8500 loss_val: 0.8079 acc_val: 0.8160 time: 0.0466s\n",
            "6\n",
            "Epoch: 0840 loss_train: 0.9062 acc_train: 0.8143 loss_val: 0.8027 acc_val: 0.8160 time: 0.0444s\n",
            "7\n",
            "Epoch: 0841 loss_train: 0.9277 acc_train: 0.7929 loss_val: 0.7978 acc_val: 0.8180 time: 0.0441s\n",
            "8\n",
            "Epoch: 0842 loss_train: 0.9093 acc_train: 0.7571 loss_val: 0.7945 acc_val: 0.8180 time: 0.0453s\n",
            "9\n",
            "Epoch: 0843 loss_train: 0.8808 acc_train: 0.8071 loss_val: 0.7918 acc_val: 0.8120 time: 0.0439s\n",
            "10\n",
            "Epoch: 0844 loss_train: 0.9098 acc_train: 0.7571 loss_val: 0.7896 acc_val: 0.8160 time: 0.0448s\n",
            "11\n",
            "Epoch: 0845 loss_train: 0.9046 acc_train: 0.8143 loss_val: 0.7875 acc_val: 0.8160 time: 0.0440s\n",
            "12\n",
            "Epoch: 0846 loss_train: 0.9148 acc_train: 0.7929 loss_val: 0.7857 acc_val: 0.8180 time: 0.0442s\n",
            "13\n",
            "Epoch: 0847 loss_train: 0.8949 acc_train: 0.8000 loss_val: 0.7862 acc_val: 0.8200 time: 0.0453s\n",
            "14\n",
            "Epoch: 0848 loss_train: 0.8698 acc_train: 0.8143 loss_val: 0.7896 acc_val: 0.8200 time: 0.0441s\n",
            "15\n",
            "Epoch: 0849 loss_train: 0.8746 acc_train: 0.8286 loss_val: 0.7927 acc_val: 0.8200 time: 0.0439s\n",
            "16\n",
            "Epoch: 0850 loss_train: 0.9025 acc_train: 0.8214 loss_val: 0.7955 acc_val: 0.8120 time: 0.0458s\n",
            "17\n",
            "Epoch: 0851 loss_train: 0.9059 acc_train: 0.7714 loss_val: 0.7955 acc_val: 0.8160 time: 0.0466s\n",
            "18\n",
            "Epoch: 0852 loss_train: 0.8856 acc_train: 0.8000 loss_val: 0.7935 acc_val: 0.8140 time: 0.0458s\n",
            "19\n",
            "Epoch: 0853 loss_train: 0.9084 acc_train: 0.7929 loss_val: 0.7922 acc_val: 0.8100 time: 0.0463s\n",
            "20\n",
            "Epoch: 0854 loss_train: 0.8966 acc_train: 0.8571 loss_val: 0.7912 acc_val: 0.8120 time: 0.0439s\n",
            "21\n",
            "Epoch: 0855 loss_train: 0.8718 acc_train: 0.7500 loss_val: 0.7894 acc_val: 0.8120 time: 0.0442s\n",
            "22\n",
            "Epoch: 0856 loss_train: 0.8946 acc_train: 0.7429 loss_val: 0.7878 acc_val: 0.8160 time: 0.0457s\n",
            "23\n",
            "Epoch: 0857 loss_train: 0.9071 acc_train: 0.8643 loss_val: 0.7877 acc_val: 0.8260 time: 0.0458s\n",
            "24\n",
            "Epoch: 0858 loss_train: 0.8873 acc_train: 0.8214 loss_val: 0.7866 acc_val: 0.8240 time: 0.0463s\n",
            "25\n",
            "Epoch: 0859 loss_train: 0.8963 acc_train: 0.8214 loss_val: 0.7868 acc_val: 0.8200 time: 0.0468s\n",
            "26\n",
            "Epoch: 0860 loss_train: 0.9307 acc_train: 0.7714 loss_val: 0.7889 acc_val: 0.8260 time: 0.0445s\n",
            "27\n",
            "Epoch: 0861 loss_train: 0.9266 acc_train: 0.7500 loss_val: 0.7928 acc_val: 0.8220 time: 0.0438s\n",
            "28\n",
            "Epoch: 0862 loss_train: 0.9223 acc_train: 0.7286 loss_val: 0.7951 acc_val: 0.8160 time: 0.0451s\n",
            "29\n",
            "Epoch: 0863 loss_train: 0.9145 acc_train: 0.7929 loss_val: 0.7967 acc_val: 0.8120 time: 0.0440s\n",
            "30\n",
            "Epoch: 0864 loss_train: 0.9215 acc_train: 0.7786 loss_val: 0.7916 acc_val: 0.8080 time: 0.0445s\n",
            "31\n",
            "Epoch: 0865 loss_train: 0.8807 acc_train: 0.8143 loss_val: 0.7866 acc_val: 0.8140 time: 0.0457s\n",
            "32\n",
            "Epoch: 0866 loss_train: 0.9013 acc_train: 0.7786 loss_val: 0.7854 acc_val: 0.8160 time: 0.0452s\n",
            "33\n",
            "Epoch: 0867 loss_train: 0.9144 acc_train: 0.8143 loss_val: 0.7866 acc_val: 0.8140 time: 0.0450s\n",
            "34\n",
            "Epoch: 0868 loss_train: 0.9010 acc_train: 0.7786 loss_val: 0.7874 acc_val: 0.8220 time: 0.0445s\n",
            "35\n",
            "Epoch: 0869 loss_train: 0.8691 acc_train: 0.8143 loss_val: 0.7897 acc_val: 0.8180 time: 0.0441s\n",
            "36\n",
            "Epoch: 0870 loss_train: 0.9572 acc_train: 0.8071 loss_val: 0.7928 acc_val: 0.8180 time: 0.0452s\n",
            "37\n",
            "Epoch: 0871 loss_train: 0.9001 acc_train: 0.8071 loss_val: 0.7937 acc_val: 0.8140 time: 0.0455s\n",
            "38\n",
            "Epoch: 0872 loss_train: 0.8740 acc_train: 0.7643 loss_val: 0.7913 acc_val: 0.8140 time: 0.0502s\n",
            "39\n",
            "Epoch: 0873 loss_train: 0.8850 acc_train: 0.8071 loss_val: 0.7894 acc_val: 0.8180 time: 0.0469s\n",
            "40\n",
            "Epoch: 0874 loss_train: 0.8739 acc_train: 0.8214 loss_val: 0.7896 acc_val: 0.8200 time: 0.0447s\n",
            "41\n",
            "Epoch: 0875 loss_train: 0.9198 acc_train: 0.7929 loss_val: 0.7893 acc_val: 0.8160 time: 0.0451s\n",
            "42\n",
            "Epoch: 0876 loss_train: 0.9581 acc_train: 0.7857 loss_val: 0.7912 acc_val: 0.8140 time: 0.0441s\n",
            "43\n",
            "Epoch: 0877 loss_train: 0.9383 acc_train: 0.7929 loss_val: 0.7946 acc_val: 0.8140 time: 0.0475s\n",
            "44\n",
            "Epoch: 0878 loss_train: 0.9337 acc_train: 0.7857 loss_val: 0.7993 acc_val: 0.8140 time: 0.0458s\n",
            "45\n",
            "Epoch: 0879 loss_train: 0.9222 acc_train: 0.8071 loss_val: 0.8041 acc_val: 0.8120 time: 0.0446s\n",
            "46\n",
            "Epoch: 0880 loss_train: 0.8990 acc_train: 0.8214 loss_val: 0.8060 acc_val: 0.8220 time: 0.0442s\n",
            "47\n",
            "Epoch: 0881 loss_train: 0.8693 acc_train: 0.8000 loss_val: 0.8061 acc_val: 0.8220 time: 0.0439s\n",
            "48\n",
            "Epoch: 0882 loss_train: 0.9271 acc_train: 0.8286 loss_val: 0.8070 acc_val: 0.8200 time: 0.0447s\n",
            "49\n",
            "Epoch: 0883 loss_train: 0.8993 acc_train: 0.8000 loss_val: 0.8047 acc_val: 0.8220 time: 0.0438s\n",
            "50\n",
            "Epoch: 0884 loss_train: 0.9176 acc_train: 0.8500 loss_val: 0.8009 acc_val: 0.8160 time: 0.0438s\n",
            "51\n",
            "Epoch: 0885 loss_train: 0.8955 acc_train: 0.7643 loss_val: 0.7982 acc_val: 0.8220 time: 0.0448s\n",
            "52\n",
            "Epoch: 0886 loss_train: 0.9543 acc_train: 0.7786 loss_val: 0.7971 acc_val: 0.8200 time: 0.0443s\n",
            "53\n",
            "Epoch: 0887 loss_train: 0.9191 acc_train: 0.7786 loss_val: 0.7960 acc_val: 0.8180 time: 0.0448s\n",
            "54\n",
            "Epoch: 0888 loss_train: 0.9097 acc_train: 0.7857 loss_val: 0.7946 acc_val: 0.8180 time: 0.0451s\n",
            "55\n",
            "Epoch: 0889 loss_train: 0.8471 acc_train: 0.8357 loss_val: 0.7930 acc_val: 0.8120 time: 0.0438s\n",
            "56\n",
            "Epoch: 0890 loss_train: 0.8949 acc_train: 0.7643 loss_val: 0.7930 acc_val: 0.8140 time: 0.0447s\n",
            "57\n",
            "Epoch: 0891 loss_train: 0.8832 acc_train: 0.8286 loss_val: 0.7928 acc_val: 0.8100 time: 0.0438s\n",
            "58\n",
            "Epoch: 0892 loss_train: 0.9037 acc_train: 0.8071 loss_val: 0.7934 acc_val: 0.8080 time: 0.0460s\n",
            "59\n",
            "Epoch: 0893 loss_train: 0.8969 acc_train: 0.8214 loss_val: 0.7933 acc_val: 0.8160 time: 0.0461s\n",
            "60\n",
            "Epoch: 0894 loss_train: 0.9093 acc_train: 0.8071 loss_val: 0.7936 acc_val: 0.8220 time: 0.0457s\n",
            "61\n",
            "Epoch: 0895 loss_train: 0.8985 acc_train: 0.8071 loss_val: 0.7933 acc_val: 0.8220 time: 0.0446s\n",
            "62\n",
            "Epoch: 0896 loss_train: 0.8959 acc_train: 0.8143 loss_val: 0.7932 acc_val: 0.8260 time: 0.0439s\n",
            "63\n",
            "Epoch: 0897 loss_train: 0.8985 acc_train: 0.8500 loss_val: 0.7934 acc_val: 0.8260 time: 0.0471s\n",
            "64\n",
            "Epoch: 0898 loss_train: 0.9094 acc_train: 0.7571 loss_val: 0.7936 acc_val: 0.8300 time: 0.0441s\n",
            "65\n",
            "Epoch: 0899 loss_train: 0.8704 acc_train: 0.8214 loss_val: 0.7893 acc_val: 0.8240 time: 0.0452s\n",
            "66\n",
            "Epoch: 0900 loss_train: 0.9033 acc_train: 0.7714 loss_val: 0.7848 acc_val: 0.8220 time: 0.0439s\n",
            "67\n",
            "Epoch: 0901 loss_train: 0.9061 acc_train: 0.8143 loss_val: 0.7847 acc_val: 0.8160 time: 0.0441s\n",
            "68\n",
            "Epoch: 0902 loss_train: 0.8747 acc_train: 0.7286 loss_val: 0.7853 acc_val: 0.8100 time: 0.0450s\n",
            "69\n",
            "Epoch: 0903 loss_train: 0.9390 acc_train: 0.7643 loss_val: 0.7896 acc_val: 0.8120 time: 0.0449s\n",
            "70\n",
            "Epoch: 0904 loss_train: 0.8895 acc_train: 0.7929 loss_val: 0.7950 acc_val: 0.8140 time: 0.0446s\n",
            "71\n",
            "Epoch: 0905 loss_train: 0.8860 acc_train: 0.8357 loss_val: 0.7955 acc_val: 0.8180 time: 0.0447s\n",
            "72\n",
            "Epoch: 0906 loss_train: 0.9306 acc_train: 0.7857 loss_val: 0.7931 acc_val: 0.8200 time: 0.0456s\n",
            "73\n",
            "Epoch: 0907 loss_train: 0.9045 acc_train: 0.8000 loss_val: 0.7896 acc_val: 0.8240 time: 0.0452s\n",
            "74\n",
            "Epoch: 0908 loss_train: 0.9353 acc_train: 0.7786 loss_val: 0.7877 acc_val: 0.8240 time: 0.0440s\n",
            "75\n",
            "Epoch: 0909 loss_train: 0.9283 acc_train: 0.8071 loss_val: 0.7885 acc_val: 0.8200 time: 0.0445s\n",
            "76\n",
            "Epoch: 0910 loss_train: 0.8814 acc_train: 0.7929 loss_val: 0.7911 acc_val: 0.8200 time: 0.0440s\n",
            "77\n",
            "Epoch: 0911 loss_train: 0.8547 acc_train: 0.8571 loss_val: 0.7934 acc_val: 0.8160 time: 0.0448s\n",
            "78\n",
            "Epoch: 0912 loss_train: 0.9108 acc_train: 0.8357 loss_val: 0.7968 acc_val: 0.8180 time: 0.0483s\n",
            "79\n",
            "Epoch: 0913 loss_train: 0.9280 acc_train: 0.8357 loss_val: 0.7983 acc_val: 0.8160 time: 0.0457s\n",
            "80\n",
            "Epoch: 0914 loss_train: 0.9233 acc_train: 0.8214 loss_val: 0.7962 acc_val: 0.8180 time: 0.0443s\n",
            "81\n",
            "Epoch: 0915 loss_train: 0.9360 acc_train: 0.7857 loss_val: 0.7913 acc_val: 0.8180 time: 0.0462s\n",
            "82\n",
            "Epoch: 0916 loss_train: 0.9067 acc_train: 0.7643 loss_val: 0.7879 acc_val: 0.8180 time: 0.0436s\n",
            "83\n",
            "Epoch: 0917 loss_train: 0.9225 acc_train: 0.7714 loss_val: 0.7866 acc_val: 0.8220 time: 0.0473s\n",
            "84\n",
            "Epoch: 0918 loss_train: 0.8873 acc_train: 0.7929 loss_val: 0.7887 acc_val: 0.8220 time: 0.0458s\n",
            "85\n",
            "Epoch: 0919 loss_train: 0.8506 acc_train: 0.8143 loss_val: 0.7902 acc_val: 0.8260 time: 0.0443s\n",
            "86\n",
            "Epoch: 0920 loss_train: 0.8715 acc_train: 0.8143 loss_val: 0.7922 acc_val: 0.8280 time: 0.0438s\n",
            "87\n",
            "Epoch: 0921 loss_train: 0.8905 acc_train: 0.7857 loss_val: 0.7951 acc_val: 0.8260 time: 0.0441s\n",
            "88\n",
            "Epoch: 0922 loss_train: 0.8908 acc_train: 0.7929 loss_val: 0.7968 acc_val: 0.8220 time: 0.0454s\n",
            "89\n",
            "Epoch: 0923 loss_train: 0.9302 acc_train: 0.8357 loss_val: 0.7975 acc_val: 0.8160 time: 0.0446s\n",
            "90\n",
            "Epoch: 0924 loss_train: 0.9168 acc_train: 0.7500 loss_val: 0.7959 acc_val: 0.8120 time: 0.0439s\n",
            "91\n",
            "Epoch: 0925 loss_train: 0.8809 acc_train: 0.8143 loss_val: 0.7919 acc_val: 0.8140 time: 0.0436s\n",
            "92\n",
            "Epoch: 0926 loss_train: 0.9108 acc_train: 0.7929 loss_val: 0.7878 acc_val: 0.8140 time: 0.0437s\n",
            "93\n",
            "Epoch: 0927 loss_train: 0.9006 acc_train: 0.8357 loss_val: 0.7866 acc_val: 0.8180 time: 0.0449s\n",
            "94\n",
            "Epoch: 0928 loss_train: 0.8665 acc_train: 0.8357 loss_val: 0.7870 acc_val: 0.8260 time: 0.0441s\n",
            "95\n",
            "Epoch: 0929 loss_train: 0.8765 acc_train: 0.8143 loss_val: 0.7890 acc_val: 0.8180 time: 0.0449s\n",
            "96\n",
            "Epoch: 0930 loss_train: 0.8968 acc_train: 0.8071 loss_val: 0.7920 acc_val: 0.8160 time: 0.0442s\n",
            "97\n",
            "Epoch: 0931 loss_train: 0.8546 acc_train: 0.8500 loss_val: 0.7955 acc_val: 0.8200 time: 0.0445s\n",
            "98\n",
            "Epoch: 0932 loss_train: 0.9161 acc_train: 0.8500 loss_val: 0.7960 acc_val: 0.8280 time: 0.0477s\n",
            "99\n",
            "Epoch: 0933 loss_train: 0.9405 acc_train: 0.8429 loss_val: 0.7941 acc_val: 0.8180 time: 0.0440s\n",
            "100\n",
            "Epoch: 0934 loss_train: 0.9207 acc_train: 0.8143 loss_val: 0.7913 acc_val: 0.8200 time: 0.0439s\n",
            "101\n",
            "Epoch: 0935 loss_train: 0.9298 acc_train: 0.7429 loss_val: 0.7880 acc_val: 0.8220 time: 0.0445s\n",
            "102\n",
            "Epoch: 0936 loss_train: 0.8696 acc_train: 0.8000 loss_val: 0.7853 acc_val: 0.8200 time: 0.0462s\n",
            "103\n",
            "Epoch: 0937 loss_train: 0.8840 acc_train: 0.7929 loss_val: 0.7872 acc_val: 0.8140 time: 0.0463s\n",
            "104\n",
            "Epoch: 0938 loss_train: 0.9103 acc_train: 0.8286 loss_val: 0.7886 acc_val: 0.8140 time: 0.0448s\n",
            "105\n",
            "Epoch: 0939 loss_train: 0.8649 acc_train: 0.8143 loss_val: 0.7897 acc_val: 0.8160 time: 0.0469s\n",
            "106\n",
            "Epoch: 0940 loss_train: 0.9467 acc_train: 0.7857 loss_val: 0.7924 acc_val: 0.8180 time: 0.0439s\n",
            "107\n",
            "Epoch: 0941 loss_train: 0.8974 acc_train: 0.7714 loss_val: 0.7909 acc_val: 0.8200 time: 0.0458s\n",
            "108\n",
            "Epoch: 0942 loss_train: 0.9013 acc_train: 0.8000 loss_val: 0.7860 acc_val: 0.8240 time: 0.0465s\n",
            "109\n",
            "Epoch: 0943 loss_train: 0.9183 acc_train: 0.7357 loss_val: 0.7848 acc_val: 0.8260 time: 0.0445s\n",
            "110\n",
            "Epoch: 0944 loss_train: 0.9301 acc_train: 0.7857 loss_val: 0.7862 acc_val: 0.8320 time: 0.0441s\n",
            "111\n",
            "Epoch: 0945 loss_train: 0.8969 acc_train: 0.7929 loss_val: 0.7893 acc_val: 0.8260 time: 0.0446s\n",
            "112\n",
            "Epoch: 0946 loss_train: 0.8944 acc_train: 0.8071 loss_val: 0.7936 acc_val: 0.8220 time: 0.0444s\n",
            "113\n",
            "Epoch: 0947 loss_train: 0.9281 acc_train: 0.8000 loss_val: 0.7992 acc_val: 0.8200 time: 0.0449s\n",
            "114\n",
            "Epoch: 0948 loss_train: 0.8986 acc_train: 0.7929 loss_val: 0.8026 acc_val: 0.8180 time: 0.0441s\n",
            "115\n",
            "Epoch: 0949 loss_train: 0.8950 acc_train: 0.8286 loss_val: 0.8050 acc_val: 0.8160 time: 0.0441s\n",
            "116\n",
            "Epoch: 0950 loss_train: 0.8770 acc_train: 0.8357 loss_val: 0.8028 acc_val: 0.8160 time: 0.0461s\n",
            "117\n",
            "Epoch: 0951 loss_train: 0.8861 acc_train: 0.7929 loss_val: 0.7948 acc_val: 0.8080 time: 0.0439s\n",
            "118\n",
            "Epoch: 0952 loss_train: 0.9096 acc_train: 0.7643 loss_val: 0.7910 acc_val: 0.8160 time: 0.0456s\n",
            "119\n",
            "Epoch: 0953 loss_train: 0.9643 acc_train: 0.7786 loss_val: 0.7912 acc_val: 0.8180 time: 0.0436s\n",
            "120\n",
            "Epoch: 0954 loss_train: 0.9174 acc_train: 0.8000 loss_val: 0.7939 acc_val: 0.8140 time: 0.0440s\n",
            "121\n",
            "Epoch: 0955 loss_train: 0.9174 acc_train: 0.8071 loss_val: 0.8007 acc_val: 0.8180 time: 0.0449s\n",
            "122\n",
            "Epoch: 0956 loss_train: 0.8587 acc_train: 0.8286 loss_val: 0.8059 acc_val: 0.8160 time: 0.0444s\n",
            "123\n",
            "Epoch: 0957 loss_train: 0.9312 acc_train: 0.8214 loss_val: 0.8084 acc_val: 0.8180 time: 0.0455s\n",
            "124\n",
            "Epoch: 0958 loss_train: 0.8967 acc_train: 0.8357 loss_val: 0.8057 acc_val: 0.8200 time: 0.0477s\n",
            "125\n",
            "Epoch: 0959 loss_train: 0.9178 acc_train: 0.8000 loss_val: 0.7986 acc_val: 0.8200 time: 0.0449s\n",
            "126\n",
            "Epoch: 0960 loss_train: 0.9014 acc_train: 0.8000 loss_val: 0.7945 acc_val: 0.8220 time: 0.0438s\n",
            "127\n",
            "Epoch: 0961 loss_train: 0.9087 acc_train: 0.8000 loss_val: 0.7931 acc_val: 0.8160 time: 0.0442s\n",
            "128\n",
            "Epoch: 0962 loss_train: 0.8956 acc_train: 0.8143 loss_val: 0.7936 acc_val: 0.8080 time: 0.0455s\n",
            "129\n",
            "Epoch: 0963 loss_train: 0.9135 acc_train: 0.8429 loss_val: 0.7971 acc_val: 0.8080 time: 0.0438s\n",
            "130\n",
            "Epoch: 0964 loss_train: 0.9284 acc_train: 0.7786 loss_val: 0.8053 acc_val: 0.8100 time: 0.0440s\n",
            "131\n",
            "Epoch: 0965 loss_train: 0.9119 acc_train: 0.8000 loss_val: 0.8136 acc_val: 0.8120 time: 0.0439s\n",
            "132\n",
            "Epoch: 0966 loss_train: 0.9343 acc_train: 0.7571 loss_val: 0.8142 acc_val: 0.8100 time: 0.0459s\n",
            "133\n",
            "Epoch: 0967 loss_train: 0.9004 acc_train: 0.8143 loss_val: 0.8066 acc_val: 0.8100 time: 0.0466s\n",
            "134\n",
            "Epoch: 0968 loss_train: 0.9253 acc_train: 0.8143 loss_val: 0.7959 acc_val: 0.8080 time: 0.0461s\n",
            "135\n",
            "Epoch: 0969 loss_train: 0.8988 acc_train: 0.7786 loss_val: 0.7897 acc_val: 0.8200 time: 0.0441s\n",
            "136\n",
            "Epoch: 0970 loss_train: 0.8891 acc_train: 0.8214 loss_val: 0.7863 acc_val: 0.8280 time: 0.0442s\n",
            "137\n",
            "Epoch: 0971 loss_train: 0.9027 acc_train: 0.7357 loss_val: 0.7843 acc_val: 0.8260 time: 0.0447s\n",
            "138\n",
            "Epoch: 0972 loss_train: 0.9062 acc_train: 0.7571 loss_val: 0.7849 acc_val: 0.8140 time: 0.0452s\n",
            "139\n",
            "Epoch: 0973 loss_train: 0.8831 acc_train: 0.8143 loss_val: 0.7890 acc_val: 0.8120 time: 0.0456s\n",
            "140\n",
            "Epoch: 0974 loss_train: 0.8894 acc_train: 0.8643 loss_val: 0.7943 acc_val: 0.8140 time: 0.0439s\n",
            "141\n",
            "Epoch: 0975 loss_train: 0.9730 acc_train: 0.7929 loss_val: 0.8001 acc_val: 0.8120 time: 0.0453s\n",
            "142\n",
            "Epoch: 0976 loss_train: 0.8963 acc_train: 0.8357 loss_val: 0.8059 acc_val: 0.8140 time: 0.0438s\n",
            "143\n",
            "Epoch: 0977 loss_train: 0.9133 acc_train: 0.8071 loss_val: 0.8118 acc_val: 0.8120 time: 0.0452s\n",
            "144\n",
            "Epoch: 0978 loss_train: 0.8957 acc_train: 0.8286 loss_val: 0.8133 acc_val: 0.8140 time: 0.0442s\n",
            "145\n",
            "Epoch: 0979 loss_train: 0.8838 acc_train: 0.8143 loss_val: 0.8116 acc_val: 0.8100 time: 0.0459s\n",
            "146\n",
            "Epoch: 0980 loss_train: 0.9324 acc_train: 0.8143 loss_val: 0.8052 acc_val: 0.8140 time: 0.0457s\n",
            "147\n",
            "Epoch: 0981 loss_train: 0.8902 acc_train: 0.7929 loss_val: 0.7948 acc_val: 0.8160 time: 0.0437s\n",
            "148\n",
            "Epoch: 0982 loss_train: 0.9219 acc_train: 0.8214 loss_val: 0.7875 acc_val: 0.8180 time: 0.0457s\n",
            "149\n",
            "Epoch: 0983 loss_train: 0.8890 acc_train: 0.8143 loss_val: 0.7845 acc_val: 0.8200 time: 0.0454s\n",
            "150\n",
            "Epoch: 0984 loss_train: 0.8596 acc_train: 0.8357 loss_val: 0.7832 acc_val: 0.8180 time: 0.0447s\n",
            "151\n",
            "Epoch: 0985 loss_train: 0.8614 acc_train: 0.8429 loss_val: 0.7850 acc_val: 0.8160 time: 0.0438s\n",
            "152\n",
            "Epoch: 0986 loss_train: 0.9097 acc_train: 0.8286 loss_val: 0.7872 acc_val: 0.8160 time: 0.0443s\n",
            "153\n",
            "Epoch: 0987 loss_train: 0.9371 acc_train: 0.7429 loss_val: 0.7921 acc_val: 0.8140 time: 0.0468s\n",
            "154\n",
            "Epoch: 0988 loss_train: 0.8781 acc_train: 0.8714 loss_val: 0.7992 acc_val: 0.8120 time: 0.0440s\n",
            "155\n",
            "Epoch: 0989 loss_train: 0.9383 acc_train: 0.7357 loss_val: 0.8049 acc_val: 0.8160 time: 0.0439s\n",
            "156\n",
            "Epoch: 0990 loss_train: 0.9040 acc_train: 0.8143 loss_val: 0.8059 acc_val: 0.8080 time: 0.0438s\n",
            "157\n",
            "Epoch: 0991 loss_train: 0.9236 acc_train: 0.8000 loss_val: 0.8041 acc_val: 0.8160 time: 0.0442s\n",
            "158\n",
            "Epoch: 0992 loss_train: 0.8923 acc_train: 0.8429 loss_val: 0.8010 acc_val: 0.8200 time: 0.0453s\n",
            "159\n",
            "Epoch: 0993 loss_train: 0.9234 acc_train: 0.7929 loss_val: 0.7975 acc_val: 0.8220 time: 0.0440s\n",
            "160\n",
            "Epoch: 0994 loss_train: 0.8942 acc_train: 0.7714 loss_val: 0.7955 acc_val: 0.8220 time: 0.0442s\n",
            "161\n",
            "Epoch: 0995 loss_train: 0.9094 acc_train: 0.8071 loss_val: 0.7936 acc_val: 0.8200 time: 0.0449s\n",
            "162\n",
            "Epoch: 0996 loss_train: 0.9350 acc_train: 0.7286 loss_val: 0.7923 acc_val: 0.8200 time: 0.0443s\n",
            "163\n",
            "Epoch: 0997 loss_train: 0.9453 acc_train: 0.7500 loss_val: 0.7900 acc_val: 0.8200 time: 0.0454s\n",
            "164\n",
            "Epoch: 0998 loss_train: 0.9156 acc_train: 0.8214 loss_val: 0.7876 acc_val: 0.8140 time: 0.0438s\n",
            "165\n",
            "Epoch: 0999 loss_train: 0.9506 acc_train: 0.7929 loss_val: 0.7882 acc_val: 0.8140 time: 0.0442s\n",
            "166\n",
            "Epoch: 1000 loss_train: 0.9440 acc_train: 0.7500 loss_val: 0.7912 acc_val: 0.8140 time: 0.0443s\n",
            "167\n",
            "Epoch: 1001 loss_train: 0.9362 acc_train: 0.7929 loss_val: 0.7964 acc_val: 0.8060 time: 0.0450s\n",
            "168\n",
            "Epoch: 1002 loss_train: 0.8817 acc_train: 0.8357 loss_val: 0.7994 acc_val: 0.8080 time: 0.0453s\n",
            "169\n",
            "Epoch: 1003 loss_train: 0.8975 acc_train: 0.7929 loss_val: 0.8010 acc_val: 0.8100 time: 0.0472s\n",
            "170\n",
            "Epoch: 1004 loss_train: 0.8730 acc_train: 0.8143 loss_val: 0.8022 acc_val: 0.8180 time: 0.0449s\n",
            "171\n",
            "Epoch: 1005 loss_train: 0.8766 acc_train: 0.8500 loss_val: 0.8037 acc_val: 0.8140 time: 0.0452s\n",
            "172\n",
            "Epoch: 1006 loss_train: 0.9182 acc_train: 0.7286 loss_val: 0.8043 acc_val: 0.8080 time: 0.0447s\n",
            "173\n",
            "Epoch: 1007 loss_train: 0.8759 acc_train: 0.8286 loss_val: 0.8022 acc_val: 0.8140 time: 0.0454s\n",
            "174\n",
            "Epoch: 1008 loss_train: 0.9338 acc_train: 0.8071 loss_val: 0.7983 acc_val: 0.8160 time: 0.0440s\n",
            "175\n",
            "Epoch: 1009 loss_train: 0.9026 acc_train: 0.8000 loss_val: 0.7951 acc_val: 0.8180 time: 0.0444s\n",
            "176\n",
            "Epoch: 1010 loss_train: 0.9036 acc_train: 0.7643 loss_val: 0.7932 acc_val: 0.8220 time: 0.0440s\n",
            "177\n",
            "Epoch: 1011 loss_train: 0.9332 acc_train: 0.8071 loss_val: 0.7955 acc_val: 0.8200 time: 0.0445s\n",
            "178\n",
            "Epoch: 1012 loss_train: 0.8974 acc_train: 0.7643 loss_val: 0.7997 acc_val: 0.8180 time: 0.0451s\n",
            "179\n",
            "Epoch: 1013 loss_train: 0.8883 acc_train: 0.8571 loss_val: 0.8006 acc_val: 0.8160 time: 0.0443s\n",
            "180\n",
            "Epoch: 1014 loss_train: 0.8952 acc_train: 0.8071 loss_val: 0.7983 acc_val: 0.8120 time: 0.0445s\n",
            "181\n",
            "Epoch: 1015 loss_train: 0.8831 acc_train: 0.7857 loss_val: 0.7955 acc_val: 0.8120 time: 0.0440s\n",
            "182\n",
            "Epoch: 1016 loss_train: 0.9408 acc_train: 0.7786 loss_val: 0.7949 acc_val: 0.8200 time: 0.0440s\n",
            "183\n",
            "Epoch: 1017 loss_train: 0.8708 acc_train: 0.8214 loss_val: 0.7967 acc_val: 0.8240 time: 0.0449s\n",
            "184\n",
            "Epoch: 1018 loss_train: 0.9427 acc_train: 0.8000 loss_val: 0.8021 acc_val: 0.8200 time: 0.0466s\n",
            "185\n",
            "Epoch: 1019 loss_train: 0.9370 acc_train: 0.8643 loss_val: 0.8061 acc_val: 0.8240 time: 0.0448s\n",
            "186\n",
            "Epoch: 1020 loss_train: 0.9191 acc_train: 0.7571 loss_val: 0.8054 acc_val: 0.8220 time: 0.0454s\n",
            "187\n",
            "Epoch: 1021 loss_train: 0.8796 acc_train: 0.8500 loss_val: 0.8008 acc_val: 0.8220 time: 0.0441s\n",
            "188\n",
            "Epoch: 1022 loss_train: 0.9113 acc_train: 0.8214 loss_val: 0.7984 acc_val: 0.8220 time: 0.0535s\n",
            "189\n",
            "Epoch: 1023 loss_train: 0.8832 acc_train: 0.8429 loss_val: 0.7956 acc_val: 0.8160 time: 0.0455s\n",
            "190\n",
            "Epoch: 1024 loss_train: 0.9244 acc_train: 0.8000 loss_val: 0.7962 acc_val: 0.8120 time: 0.0470s\n",
            "191\n",
            "Epoch: 1025 loss_train: 0.8819 acc_train: 0.8429 loss_val: 0.7960 acc_val: 0.8160 time: 0.0446s\n",
            "192\n",
            "Epoch: 1026 loss_train: 0.8682 acc_train: 0.7929 loss_val: 0.7981 acc_val: 0.8200 time: 0.0452s\n",
            "193\n",
            "Epoch: 1027 loss_train: 0.9228 acc_train: 0.8071 loss_val: 0.7983 acc_val: 0.8160 time: 0.0467s\n",
            "194\n",
            "Epoch: 1028 loss_train: 0.8987 acc_train: 0.8429 loss_val: 0.7963 acc_val: 0.8180 time: 0.0441s\n",
            "195\n",
            "Epoch: 1029 loss_train: 0.9182 acc_train: 0.7643 loss_val: 0.7943 acc_val: 0.8180 time: 0.0441s\n",
            "196\n",
            "Epoch: 1030 loss_train: 0.9169 acc_train: 0.8000 loss_val: 0.7952 acc_val: 0.8180 time: 0.0441s\n",
            "197\n",
            "Epoch: 1031 loss_train: 0.8940 acc_train: 0.8286 loss_val: 0.7939 acc_val: 0.8240 time: 0.0440s\n",
            "198\n",
            "Epoch: 1032 loss_train: 0.9438 acc_train: 0.7643 loss_val: 0.7937 acc_val: 0.8240 time: 0.0466s\n",
            "199\n",
            "Early stop! Min loss:  0.7810295224189758 , Max accuracy:  0.838\n",
            "Early stop model validation loss:  0.7810295224189758 , accuracy:  0.8240000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 49.1289s\n",
            "Loading 831th epoch\n",
            "Test set results: loss= 0.7515 accuracy= 0.8550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9FcOEAA3v-6",
        "outputId": "ecb18c18-5f03-4bd0-9fd1-439b9ae71e19"
      },
      "source": [
        "Train() #pubmed\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 5.8801 acc_train: 0.4000 loss_val: 2.0198 acc_val: 0.4160 time: 0.1196s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.8835 acc_train: 0.4167 loss_val: 1.1967 acc_val: 0.4160 time: 0.1148s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.8585 acc_train: 0.3667 loss_val: 1.0934 acc_val: 0.3880 time: 0.1092s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.5998 acc_train: 0.3167 loss_val: 1.1389 acc_val: 0.3880 time: 0.1100s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.6219 acc_train: 0.4000 loss_val: 1.1209 acc_val: 0.3880 time: 0.1094s\n",
            "1\n",
            "Epoch: 0006 loss_train: 1.6589 acc_train: 0.3000 loss_val: 1.0833 acc_val: 0.4160 time: 0.1095s\n",
            "2\n",
            "Epoch: 0007 loss_train: 1.5294 acc_train: 0.3000 loss_val: 1.2114 acc_val: 0.4160 time: 0.1093s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.7527 acc_train: 0.3500 loss_val: 1.2540 acc_val: 0.4160 time: 0.1092s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.5857 acc_train: 0.4000 loss_val: 1.1632 acc_val: 0.4160 time: 0.1091s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.5027 acc_train: 0.3667 loss_val: 1.1037 acc_val: 0.4160 time: 0.1094s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.4613 acc_train: 0.4000 loss_val: 1.0933 acc_val: 0.4160 time: 0.1093s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.5003 acc_train: 0.3833 loss_val: 1.0946 acc_val: 0.4160 time: 0.1101s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.4270 acc_train: 0.3500 loss_val: 1.0568 acc_val: 0.4160 time: 0.1099s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.4241 acc_train: 0.4000 loss_val: 1.0353 acc_val: 0.4160 time: 0.1087s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.4620 acc_train: 0.3667 loss_val: 1.0389 acc_val: 0.4160 time: 0.1092s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.4578 acc_train: 0.4167 loss_val: 1.0443 acc_val: 0.4160 time: 0.1092s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.3340 acc_train: 0.4167 loss_val: 1.0335 acc_val: 0.4160 time: 0.1094s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.4201 acc_train: 0.4333 loss_val: 1.0597 acc_val: 0.4160 time: 0.1088s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.3655 acc_train: 0.4167 loss_val: 1.1127 acc_val: 0.4160 time: 0.1094s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.3414 acc_train: 0.4167 loss_val: 1.1911 acc_val: 0.4160 time: 0.1099s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.3192 acc_train: 0.4667 loss_val: 1.2027 acc_val: 0.4160 time: 0.1090s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.3880 acc_train: 0.4333 loss_val: 1.1553 acc_val: 0.4240 time: 0.1103s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.3107 acc_train: 0.4833 loss_val: 1.0884 acc_val: 0.4380 time: 0.1091s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.3617 acc_train: 0.4667 loss_val: 1.0106 acc_val: 0.4820 time: 0.1097s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.3067 acc_train: 0.4833 loss_val: 0.9759 acc_val: 0.4980 time: 0.1095s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.3363 acc_train: 0.4667 loss_val: 0.9771 acc_val: 0.4920 time: 0.1089s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.3074 acc_train: 0.4667 loss_val: 0.9770 acc_val: 0.4980 time: 0.1103s\n",
            "1\n",
            "Epoch: 0028 loss_train: 1.2299 acc_train: 0.5333 loss_val: 0.9867 acc_val: 0.4820 time: 0.1091s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.2048 acc_train: 0.5167 loss_val: 0.9786 acc_val: 0.4720 time: 0.1100s\n",
            "1\n",
            "Epoch: 0030 loss_train: 1.2715 acc_train: 0.4833 loss_val: 0.9345 acc_val: 0.4760 time: 0.1090s\n",
            "2\n",
            "Epoch: 0031 loss_train: 1.1707 acc_train: 0.6000 loss_val: 0.9048 acc_val: 0.5060 time: 0.1096s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.2668 acc_train: 0.5667 loss_val: 0.8878 acc_val: 0.5440 time: 0.1090s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.2271 acc_train: 0.5500 loss_val: 0.8805 acc_val: 0.5520 time: 0.1089s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.2196 acc_train: 0.5167 loss_val: 0.8292 acc_val: 0.5740 time: 0.1086s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.1599 acc_train: 0.5500 loss_val: 0.7955 acc_val: 0.5840 time: 0.1087s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.1392 acc_train: 0.6667 loss_val: 0.7834 acc_val: 0.5920 time: 0.1092s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.1781 acc_train: 0.6500 loss_val: 0.7769 acc_val: 0.5980 time: 0.1090s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.1253 acc_train: 0.6667 loss_val: 0.7604 acc_val: 0.5960 time: 0.1090s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.0853 acc_train: 0.5500 loss_val: 0.7584 acc_val: 0.5900 time: 0.1087s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.0933 acc_train: 0.5667 loss_val: 0.7907 acc_val: 0.5840 time: 0.1087s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.1708 acc_train: 0.5667 loss_val: 0.8121 acc_val: 0.5820 time: 0.1092s\n",
            "1\n",
            "Epoch: 0042 loss_train: 1.1471 acc_train: 0.6000 loss_val: 0.7812 acc_val: 0.5840 time: 0.1099s\n",
            "2\n",
            "Epoch: 0043 loss_train: 1.0560 acc_train: 0.5500 loss_val: 0.7455 acc_val: 0.5940 time: 0.1102s\n",
            "3\n",
            "Epoch: 0044 loss_train: 1.0357 acc_train: 0.5500 loss_val: 0.7182 acc_val: 0.6040 time: 0.1088s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.0392 acc_train: 0.6833 loss_val: 0.7196 acc_val: 0.6040 time: 0.1090s\n",
            "0\n",
            "Epoch: 0046 loss_train: 0.9848 acc_train: 0.7333 loss_val: 0.7300 acc_val: 0.5960 time: 0.1091s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.0287 acc_train: 0.6333 loss_val: 0.7206 acc_val: 0.5960 time: 0.1095s\n",
            "1\n",
            "Epoch: 0048 loss_train: 1.0075 acc_train: 0.6333 loss_val: 0.7479 acc_val: 0.5860 time: 0.1094s\n",
            "2\n",
            "Epoch: 0049 loss_train: 1.1025 acc_train: 0.5333 loss_val: 0.7998 acc_val: 0.5740 time: 0.1091s\n",
            "3\n",
            "Epoch: 0050 loss_train: 1.1062 acc_train: 0.5833 loss_val: 0.8308 acc_val: 0.5740 time: 0.1090s\n",
            "4\n",
            "Epoch: 0051 loss_train: 1.1044 acc_train: 0.6667 loss_val: 0.8171 acc_val: 0.5740 time: 0.1095s\n",
            "5\n",
            "Epoch: 0052 loss_train: 0.9384 acc_train: 0.6667 loss_val: 0.7869 acc_val: 0.5800 time: 0.1112s\n",
            "6\n",
            "Epoch: 0053 loss_train: 1.0000 acc_train: 0.6833 loss_val: 0.7745 acc_val: 0.5820 time: 0.1094s\n",
            "7\n",
            "Epoch: 0054 loss_train: 0.9792 acc_train: 0.7000 loss_val: 0.7562 acc_val: 0.5840 time: 0.1090s\n",
            "8\n",
            "Epoch: 0055 loss_train: 0.9185 acc_train: 0.7333 loss_val: 0.7174 acc_val: 0.6340 time: 0.1098s\n",
            "9\n",
            "Epoch: 0056 loss_train: 1.0372 acc_train: 0.6500 loss_val: 0.7954 acc_val: 0.5700 time: 0.1086s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.0306 acc_train: 0.6500 loss_val: 0.9007 acc_val: 0.5660 time: 0.1090s\n",
            "1\n",
            "Epoch: 0058 loss_train: 1.0658 acc_train: 0.6833 loss_val: 0.8464 acc_val: 0.5780 time: 0.1095s\n",
            "2\n",
            "Epoch: 0059 loss_train: 1.0742 acc_train: 0.6167 loss_val: 0.7228 acc_val: 0.5960 time: 0.1092s\n",
            "3\n",
            "Epoch: 0060 loss_train: 0.9906 acc_train: 0.6167 loss_val: 0.8741 acc_val: 0.6280 time: 0.1094s\n",
            "4\n",
            "Epoch: 0061 loss_train: 0.8937 acc_train: 0.6833 loss_val: 0.6332 acc_val: 0.7360 time: 0.1092s\n",
            "5\n",
            "Epoch: 0062 loss_train: 0.9114 acc_train: 0.7333 loss_val: 0.6355 acc_val: 0.6680 time: 0.1086s\n",
            "0\n",
            "Epoch: 0063 loss_train: 0.9635 acc_train: 0.6333 loss_val: 0.6572 acc_val: 0.6500 time: 0.1091s\n",
            "1\n",
            "Epoch: 0064 loss_train: 1.0370 acc_train: 0.6000 loss_val: 0.6711 acc_val: 0.6440 time: 0.1097s\n",
            "2\n",
            "Epoch: 0065 loss_train: 0.9771 acc_train: 0.7000 loss_val: 0.6397 acc_val: 0.6700 time: 0.1100s\n",
            "3\n",
            "Epoch: 0066 loss_train: 0.9860 acc_train: 0.6333 loss_val: 0.6369 acc_val: 0.6680 time: 0.1094s\n",
            "4\n",
            "Epoch: 0067 loss_train: 0.9527 acc_train: 0.6667 loss_val: 0.6294 acc_val: 0.6940 time: 0.1093s\n",
            "5\n",
            "Epoch: 0068 loss_train: 0.8577 acc_train: 0.6833 loss_val: 0.6321 acc_val: 0.7080 time: 0.1087s\n",
            "0\n",
            "Epoch: 0069 loss_train: 0.8123 acc_train: 0.7833 loss_val: 0.6583 acc_val: 0.6460 time: 0.1093s\n",
            "1\n",
            "Epoch: 0070 loss_train: 0.9045 acc_train: 0.7833 loss_val: 0.6670 acc_val: 0.6580 time: 0.1093s\n",
            "2\n",
            "Epoch: 0071 loss_train: 0.8912 acc_train: 0.6500 loss_val: 0.6547 acc_val: 0.6640 time: 0.1092s\n",
            "3\n",
            "Epoch: 0072 loss_train: 0.9112 acc_train: 0.7500 loss_val: 0.6399 acc_val: 0.6720 time: 0.1092s\n",
            "4\n",
            "Epoch: 0073 loss_train: 0.8134 acc_train: 0.6167 loss_val: 0.6514 acc_val: 0.6740 time: 0.1091s\n",
            "5\n",
            "Epoch: 0074 loss_train: 0.8744 acc_train: 0.6833 loss_val: 0.6292 acc_val: 0.6940 time: 0.1091s\n",
            "6\n",
            "Epoch: 0075 loss_train: 0.7920 acc_train: 0.6333 loss_val: 0.6034 acc_val: 0.7440 time: 0.1086s\n",
            "0\n",
            "Epoch: 0076 loss_train: 0.8247 acc_train: 0.8167 loss_val: 0.6325 acc_val: 0.7700 time: 0.1089s\n",
            "0\n",
            "Epoch: 0077 loss_train: 0.7951 acc_train: 0.7000 loss_val: 0.6602 acc_val: 0.7620 time: 0.1089s\n",
            "0\n",
            "Epoch: 0078 loss_train: 0.7601 acc_train: 0.7833 loss_val: 0.6345 acc_val: 0.7720 time: 0.1096s\n",
            "1\n",
            "Epoch: 0079 loss_train: 0.8159 acc_train: 0.7500 loss_val: 0.6296 acc_val: 0.7820 time: 0.1091s\n",
            "0\n",
            "Epoch: 0080 loss_train: 0.8228 acc_train: 0.8167 loss_val: 0.6361 acc_val: 0.7760 time: 0.1092s\n",
            "0\n",
            "Epoch: 0081 loss_train: 0.7742 acc_train: 0.7167 loss_val: 0.6199 acc_val: 0.7780 time: 0.1092s\n",
            "1\n",
            "Epoch: 0082 loss_train: 0.7916 acc_train: 0.8333 loss_val: 0.5736 acc_val: 0.7900 time: 0.1094s\n",
            "2\n",
            "Epoch: 0083 loss_train: 0.7646 acc_train: 0.8167 loss_val: 0.5429 acc_val: 0.8060 time: 0.1092s\n",
            "0\n",
            "Epoch: 0084 loss_train: 0.7306 acc_train: 0.7333 loss_val: 0.5227 acc_val: 0.8060 time: 0.1088s\n",
            "0\n",
            "Epoch: 0085 loss_train: 0.6696 acc_train: 0.7500 loss_val: 0.5056 acc_val: 0.8120 time: 0.1090s\n",
            "0\n",
            "Epoch: 0086 loss_train: 0.7056 acc_train: 0.8000 loss_val: 0.4920 acc_val: 0.8120 time: 0.1086s\n",
            "0\n",
            "Epoch: 0087 loss_train: 0.6363 acc_train: 0.8500 loss_val: 0.4902 acc_val: 0.8040 time: 0.1094s\n",
            "0\n",
            "Epoch: 0088 loss_train: 0.7281 acc_train: 0.8000 loss_val: 0.5150 acc_val: 0.7980 time: 0.1087s\n",
            "0\n",
            "Epoch: 0089 loss_train: 0.7393 acc_train: 0.8333 loss_val: 0.5528 acc_val: 0.7880 time: 0.1095s\n",
            "1\n",
            "Epoch: 0090 loss_train: 0.6232 acc_train: 0.8667 loss_val: 0.5799 acc_val: 0.7900 time: 0.1095s\n",
            "2\n",
            "Epoch: 0091 loss_train: 0.7060 acc_train: 0.8333 loss_val: 0.5857 acc_val: 0.7860 time: 0.1091s\n",
            "3\n",
            "Epoch: 0092 loss_train: 0.7132 acc_train: 0.8000 loss_val: 0.5699 acc_val: 0.7940 time: 0.1091s\n",
            "4\n",
            "Epoch: 0093 loss_train: 0.7414 acc_train: 0.8167 loss_val: 0.5040 acc_val: 0.8160 time: 0.1091s\n",
            "5\n",
            "Epoch: 0094 loss_train: 0.6553 acc_train: 0.7667 loss_val: 0.4719 acc_val: 0.8280 time: 0.1091s\n",
            "0\n",
            "Epoch: 0095 loss_train: 0.6679 acc_train: 0.8500 loss_val: 0.4638 acc_val: 0.8240 time: 0.1087s\n",
            "0\n",
            "Epoch: 0096 loss_train: 0.7099 acc_train: 0.8500 loss_val: 0.4667 acc_val: 0.8200 time: 0.1094s\n",
            "0\n",
            "Epoch: 0097 loss_train: 0.7003 acc_train: 0.7833 loss_val: 0.4688 acc_val: 0.8220 time: 0.1093s\n",
            "1\n",
            "Epoch: 0098 loss_train: 0.6624 acc_train: 0.8333 loss_val: 0.4915 acc_val: 0.8220 time: 0.1093s\n",
            "2\n",
            "Epoch: 0099 loss_train: 0.6242 acc_train: 0.7833 loss_val: 0.5365 acc_val: 0.8200 time: 0.1090s\n",
            "3\n",
            "Epoch: 0100 loss_train: 0.7343 acc_train: 0.8500 loss_val: 0.5865 acc_val: 0.8080 time: 0.1092s\n",
            "4\n",
            "Epoch: 0101 loss_train: 0.6787 acc_train: 0.9333 loss_val: 0.5977 acc_val: 0.8120 time: 0.1091s\n",
            "5\n",
            "Epoch: 0102 loss_train: 0.6468 acc_train: 0.8167 loss_val: 0.5700 acc_val: 0.8260 time: 0.1090s\n",
            "6\n",
            "Epoch: 0103 loss_train: 0.6886 acc_train: 0.8167 loss_val: 0.5472 acc_val: 0.8260 time: 0.1093s\n",
            "7\n",
            "Epoch: 0104 loss_train: 0.6053 acc_train: 0.9000 loss_val: 0.5283 acc_val: 0.8300 time: 0.1090s\n",
            "8\n",
            "Epoch: 0105 loss_train: 0.5951 acc_train: 0.8167 loss_val: 0.5071 acc_val: 0.8320 time: 0.1097s\n",
            "0\n",
            "Epoch: 0106 loss_train: 0.6668 acc_train: 0.7500 loss_val: 0.5292 acc_val: 0.8260 time: 0.1087s\n",
            "0\n",
            "Epoch: 0107 loss_train: 0.5984 acc_train: 0.8667 loss_val: 0.5517 acc_val: 0.8240 time: 0.1094s\n",
            "1\n",
            "Epoch: 0108 loss_train: 0.6260 acc_train: 0.8833 loss_val: 0.5730 acc_val: 0.8180 time: 0.1092s\n",
            "2\n",
            "Epoch: 0109 loss_train: 0.5939 acc_train: 0.9167 loss_val: 0.5753 acc_val: 0.8040 time: 0.1103s\n",
            "3\n",
            "Epoch: 0110 loss_train: 0.5817 acc_train: 0.8833 loss_val: 0.5723 acc_val: 0.8080 time: 0.1093s\n",
            "4\n",
            "Epoch: 0111 loss_train: 0.6737 acc_train: 0.7667 loss_val: 0.5483 acc_val: 0.8220 time: 0.1103s\n",
            "5\n",
            "Epoch: 0112 loss_train: 0.6211 acc_train: 0.8167 loss_val: 0.5324 acc_val: 0.8320 time: 0.1093s\n",
            "6\n",
            "Epoch: 0113 loss_train: 0.5867 acc_train: 0.8167 loss_val: 0.5675 acc_val: 0.8360 time: 0.1099s\n",
            "0\n",
            "Epoch: 0114 loss_train: 0.7389 acc_train: 0.7000 loss_val: 0.6384 acc_val: 0.8140 time: 0.1098s\n",
            "0\n",
            "Epoch: 0115 loss_train: 0.6818 acc_train: 0.8333 loss_val: 0.6527 acc_val: 0.8080 time: 0.1097s\n",
            "1\n",
            "Epoch: 0116 loss_train: 0.6361 acc_train: 0.8167 loss_val: 0.5962 acc_val: 0.8180 time: 0.1101s\n",
            "2\n",
            "Epoch: 0117 loss_train: 0.6433 acc_train: 0.8167 loss_val: 0.5819 acc_val: 0.8160 time: 0.1094s\n",
            "3\n",
            "Epoch: 0118 loss_train: 0.6224 acc_train: 0.8667 loss_val: 0.5879 acc_val: 0.8040 time: 0.1093s\n",
            "4\n",
            "Epoch: 0119 loss_train: 0.6356 acc_train: 0.8500 loss_val: 0.5844 acc_val: 0.8180 time: 0.1096s\n",
            "5\n",
            "Epoch: 0120 loss_train: 0.6051 acc_train: 0.8500 loss_val: 0.5892 acc_val: 0.8260 time: 0.1094s\n",
            "6\n",
            "Epoch: 0121 loss_train: 0.5974 acc_train: 0.8833 loss_val: 0.5825 acc_val: 0.8220 time: 0.1096s\n",
            "7\n",
            "Epoch: 0122 loss_train: 0.6064 acc_train: 0.7500 loss_val: 0.5304 acc_val: 0.8320 time: 0.1102s\n",
            "8\n",
            "Epoch: 0123 loss_train: 0.6477 acc_train: 0.8833 loss_val: 0.5135 acc_val: 0.8220 time: 0.1101s\n",
            "9\n",
            "Epoch: 0124 loss_train: 0.6765 acc_train: 0.8667 loss_val: 0.5232 acc_val: 0.8240 time: 0.1093s\n",
            "10\n",
            "Epoch: 0125 loss_train: 0.6399 acc_train: 0.8500 loss_val: 0.5571 acc_val: 0.8340 time: 0.1102s\n",
            "11\n",
            "Epoch: 0126 loss_train: 0.7014 acc_train: 0.8333 loss_val: 0.5991 acc_val: 0.8240 time: 0.1095s\n",
            "12\n",
            "Epoch: 0127 loss_train: 0.6000 acc_train: 0.8833 loss_val: 0.5979 acc_val: 0.8240 time: 0.1097s\n",
            "13\n",
            "Epoch: 0128 loss_train: 0.6131 acc_train: 0.8833 loss_val: 0.5586 acc_val: 0.8280 time: 0.1098s\n",
            "14\n",
            "Epoch: 0129 loss_train: 0.6295 acc_train: 0.8167 loss_val: 0.5358 acc_val: 0.8280 time: 0.1097s\n",
            "15\n",
            "Epoch: 0130 loss_train: 0.5742 acc_train: 0.8833 loss_val: 0.5156 acc_val: 0.8300 time: 0.1095s\n",
            "16\n",
            "Epoch: 0131 loss_train: 0.5857 acc_train: 0.9167 loss_val: 0.5217 acc_val: 0.8420 time: 0.1091s\n",
            "17\n",
            "Epoch: 0132 loss_train: 0.6602 acc_train: 0.8000 loss_val: 0.5502 acc_val: 0.8280 time: 0.1116s\n",
            "0\n",
            "Epoch: 0133 loss_train: 0.5917 acc_train: 0.8667 loss_val: 0.5847 acc_val: 0.8360 time: 0.1093s\n",
            "1\n",
            "Epoch: 0134 loss_train: 0.6217 acc_train: 0.9167 loss_val: 0.5971 acc_val: 0.8280 time: 0.1105s\n",
            "2\n",
            "Epoch: 0135 loss_train: 0.5557 acc_train: 0.8333 loss_val: 0.5815 acc_val: 0.8260 time: 0.1098s\n",
            "3\n",
            "Epoch: 0136 loss_train: 0.6468 acc_train: 0.8833 loss_val: 0.5795 acc_val: 0.8160 time: 0.1094s\n",
            "4\n",
            "Epoch: 0137 loss_train: 0.6870 acc_train: 0.8000 loss_val: 0.5602 acc_val: 0.8200 time: 0.1094s\n",
            "5\n",
            "Epoch: 0138 loss_train: 0.6761 acc_train: 0.8333 loss_val: 0.5147 acc_val: 0.8340 time: 0.1091s\n",
            "6\n",
            "Epoch: 0139 loss_train: 0.6831 acc_train: 0.8333 loss_val: 0.4618 acc_val: 0.8460 time: 0.1092s\n",
            "7\n",
            "Epoch: 0140 loss_train: 0.6014 acc_train: 0.8333 loss_val: 0.4626 acc_val: 0.8360 time: 0.1091s\n",
            "0\n",
            "Epoch: 0141 loss_train: 0.7319 acc_train: 0.8167 loss_val: 0.4648 acc_val: 0.8400 time: 0.1123s\n",
            "1\n",
            "Epoch: 0142 loss_train: 0.6293 acc_train: 0.9333 loss_val: 0.4844 acc_val: 0.8340 time: 0.1092s\n",
            "2\n",
            "Epoch: 0143 loss_train: 0.6056 acc_train: 0.9000 loss_val: 0.5279 acc_val: 0.8180 time: 0.1092s\n",
            "3\n",
            "Epoch: 0144 loss_train: 0.5979 acc_train: 0.8167 loss_val: 0.6010 acc_val: 0.8200 time: 0.1088s\n",
            "4\n",
            "Epoch: 0145 loss_train: 0.6468 acc_train: 0.8500 loss_val: 0.6325 acc_val: 0.8200 time: 0.1092s\n",
            "5\n",
            "Epoch: 0146 loss_train: 0.6101 acc_train: 0.9000 loss_val: 0.5815 acc_val: 0.8300 time: 0.1127s\n",
            "6\n",
            "Epoch: 0147 loss_train: 0.7066 acc_train: 0.8500 loss_val: 0.5175 acc_val: 0.8320 time: 0.1093s\n",
            "7\n",
            "Epoch: 0148 loss_train: 0.6347 acc_train: 0.8500 loss_val: 0.4878 acc_val: 0.8380 time: 0.1090s\n",
            "8\n",
            "Epoch: 0149 loss_train: 0.6282 acc_train: 0.8500 loss_val: 0.4816 acc_val: 0.8340 time: 0.1093s\n",
            "9\n",
            "Epoch: 0150 loss_train: 0.6580 acc_train: 0.8833 loss_val: 0.5497 acc_val: 0.8380 time: 0.1095s\n",
            "10\n",
            "Epoch: 0151 loss_train: 0.6693 acc_train: 0.8333 loss_val: 0.6805 acc_val: 0.8120 time: 0.1093s\n",
            "11\n",
            "Epoch: 0152 loss_train: 0.6930 acc_train: 0.8000 loss_val: 0.7177 acc_val: 0.8020 time: 0.1095s\n",
            "12\n",
            "Epoch: 0153 loss_train: 0.5798 acc_train: 0.8833 loss_val: 0.6779 acc_val: 0.8100 time: 0.1089s\n",
            "13\n",
            "Epoch: 0154 loss_train: 0.5970 acc_train: 0.9000 loss_val: 0.5801 acc_val: 0.8340 time: 0.1095s\n",
            "14\n",
            "Epoch: 0155 loss_train: 0.6501 acc_train: 0.8833 loss_val: 0.5100 acc_val: 0.8380 time: 0.1090s\n",
            "15\n",
            "Epoch: 0156 loss_train: 0.6694 acc_train: 0.8333 loss_val: 0.4683 acc_val: 0.8460 time: 0.1095s\n",
            "16\n",
            "Epoch: 0157 loss_train: 0.6741 acc_train: 0.8500 loss_val: 0.4548 acc_val: 0.8400 time: 0.1093s\n",
            "0\n",
            "Epoch: 0158 loss_train: 0.6080 acc_train: 0.9000 loss_val: 0.4539 acc_val: 0.8460 time: 0.1088s\n",
            "0\n",
            "Epoch: 0159 loss_train: 0.6463 acc_train: 0.8667 loss_val: 0.4655 acc_val: 0.8440 time: 0.1092s\n",
            "0\n",
            "Epoch: 0160 loss_train: 0.6182 acc_train: 0.8500 loss_val: 0.4726 acc_val: 0.8440 time: 0.1090s\n",
            "1\n",
            "Epoch: 0161 loss_train: 0.6679 acc_train: 0.8500 loss_val: 0.4761 acc_val: 0.8480 time: 0.1091s\n",
            "2\n",
            "Epoch: 0162 loss_train: 0.6603 acc_train: 0.8667 loss_val: 0.5012 acc_val: 0.8500 time: 0.1093s\n",
            "0\n",
            "Epoch: 0163 loss_train: 0.6540 acc_train: 0.7500 loss_val: 0.5510 acc_val: 0.8340 time: 0.1089s\n",
            "0\n",
            "Epoch: 0164 loss_train: 0.6042 acc_train: 0.8333 loss_val: 0.5615 acc_val: 0.8320 time: 0.1093s\n",
            "1\n",
            "Epoch: 0165 loss_train: 0.6622 acc_train: 0.8500 loss_val: 0.5295 acc_val: 0.8380 time: 0.1097s\n",
            "2\n",
            "Epoch: 0166 loss_train: 0.6147 acc_train: 0.8167 loss_val: 0.4938 acc_val: 0.8460 time: 0.1093s\n",
            "3\n",
            "Epoch: 0167 loss_train: 0.6949 acc_train: 0.8167 loss_val: 0.4883 acc_val: 0.8400 time: 0.1091s\n",
            "4\n",
            "Epoch: 0168 loss_train: 0.6013 acc_train: 0.8500 loss_val: 0.4983 acc_val: 0.8360 time: 0.1093s\n",
            "5\n",
            "Epoch: 0169 loss_train: 0.6178 acc_train: 0.8000 loss_val: 0.5190 acc_val: 0.8320 time: 0.1094s\n",
            "6\n",
            "Epoch: 0170 loss_train: 0.6525 acc_train: 0.8500 loss_val: 0.5170 acc_val: 0.8300 time: 0.1091s\n",
            "7\n",
            "Epoch: 0171 loss_train: 0.6119 acc_train: 0.9167 loss_val: 0.5264 acc_val: 0.8280 time: 0.1093s\n",
            "8\n",
            "Epoch: 0172 loss_train: 0.6110 acc_train: 0.9000 loss_val: 0.5864 acc_val: 0.8220 time: 0.1122s\n",
            "9\n",
            "Epoch: 0173 loss_train: 0.6211 acc_train: 0.7667 loss_val: 0.6635 acc_val: 0.8080 time: 0.1092s\n",
            "10\n",
            "Epoch: 0174 loss_train: 0.7075 acc_train: 0.7667 loss_val: 0.6404 acc_val: 0.8200 time: 0.1100s\n",
            "11\n",
            "Epoch: 0175 loss_train: 0.6790 acc_train: 0.8833 loss_val: 0.5746 acc_val: 0.8300 time: 0.1102s\n",
            "12\n",
            "Epoch: 0176 loss_train: 0.5580 acc_train: 0.9000 loss_val: 0.5382 acc_val: 0.8380 time: 0.1094s\n",
            "13\n",
            "Epoch: 0177 loss_train: 0.5413 acc_train: 0.8667 loss_val: 0.5364 acc_val: 0.8360 time: 0.1096s\n",
            "14\n",
            "Epoch: 0178 loss_train: 0.7334 acc_train: 0.7667 loss_val: 0.5465 acc_val: 0.8340 time: 0.1096s\n",
            "15\n",
            "Epoch: 0179 loss_train: 0.7462 acc_train: 0.8333 loss_val: 0.5589 acc_val: 0.8340 time: 0.1094s\n",
            "16\n",
            "Epoch: 0180 loss_train: 0.7103 acc_train: 0.8333 loss_val: 0.5642 acc_val: 0.8180 time: 0.1091s\n",
            "17\n",
            "Epoch: 0181 loss_train: 0.8042 acc_train: 0.7833 loss_val: 0.4910 acc_val: 0.8300 time: 0.1094s\n",
            "18\n",
            "Epoch: 0182 loss_train: 0.6582 acc_train: 0.7833 loss_val: 0.4721 acc_val: 0.8360 time: 0.1091s\n",
            "19\n",
            "Epoch: 0183 loss_train: 0.6677 acc_train: 0.8667 loss_val: 0.4859 acc_val: 0.8280 time: 0.1092s\n",
            "20\n",
            "Epoch: 0184 loss_train: 0.6496 acc_train: 0.7833 loss_val: 0.4985 acc_val: 0.8300 time: 0.1093s\n",
            "21\n",
            "Epoch: 0185 loss_train: 0.6055 acc_train: 0.8667 loss_val: 0.5051 acc_val: 0.8280 time: 0.1095s\n",
            "22\n",
            "Epoch: 0186 loss_train: 0.6915 acc_train: 0.7667 loss_val: 0.5323 acc_val: 0.8320 time: 0.1092s\n",
            "23\n",
            "Epoch: 0187 loss_train: 0.6045 acc_train: 0.8500 loss_val: 0.5515 acc_val: 0.8280 time: 0.1091s\n",
            "24\n",
            "Epoch: 0188 loss_train: 0.7184 acc_train: 0.8000 loss_val: 0.5685 acc_val: 0.8200 time: 0.1095s\n",
            "25\n",
            "Epoch: 0189 loss_train: 0.5517 acc_train: 0.8500 loss_val: 0.5914 acc_val: 0.8180 time: 0.1091s\n",
            "26\n",
            "Epoch: 0190 loss_train: 0.6739 acc_train: 0.8667 loss_val: 0.6082 acc_val: 0.8180 time: 0.1091s\n",
            "27\n",
            "Epoch: 0191 loss_train: 0.6549 acc_train: 0.8000 loss_val: 0.5728 acc_val: 0.8320 time: 0.1092s\n",
            "28\n",
            "Epoch: 0192 loss_train: 0.6515 acc_train: 0.7500 loss_val: 0.5150 acc_val: 0.8300 time: 0.1099s\n",
            "29\n",
            "Epoch: 0193 loss_train: 0.6733 acc_train: 0.9333 loss_val: 0.5095 acc_val: 0.8200 time: 0.1091s\n",
            "30\n",
            "Epoch: 0194 loss_train: 0.5937 acc_train: 0.8000 loss_val: 0.5055 acc_val: 0.8180 time: 0.1093s\n",
            "31\n",
            "Epoch: 0195 loss_train: 0.7960 acc_train: 0.7833 loss_val: 0.5167 acc_val: 0.8160 time: 0.1095s\n",
            "32\n",
            "Epoch: 0196 loss_train: 0.6528 acc_train: 0.8667 loss_val: 0.5619 acc_val: 0.8180 time: 0.1093s\n",
            "33\n",
            "Epoch: 0197 loss_train: 0.7286 acc_train: 0.7667 loss_val: 0.6143 acc_val: 0.8160 time: 0.1099s\n",
            "34\n",
            "Epoch: 0198 loss_train: 0.6694 acc_train: 0.8500 loss_val: 0.6423 acc_val: 0.8260 time: 0.1091s\n",
            "35\n",
            "Epoch: 0199 loss_train: 0.7501 acc_train: 0.7500 loss_val: 0.6089 acc_val: 0.8300 time: 0.1090s\n",
            "36\n",
            "Epoch: 0200 loss_train: 0.6985 acc_train: 0.8333 loss_val: 0.5755 acc_val: 0.8440 time: 0.1093s\n",
            "37\n",
            "Epoch: 0201 loss_train: 0.5556 acc_train: 0.8333 loss_val: 0.5690 acc_val: 0.8440 time: 0.1104s\n",
            "38\n",
            "Epoch: 0202 loss_train: 0.6402 acc_train: 0.9333 loss_val: 0.5865 acc_val: 0.8360 time: 0.1091s\n",
            "39\n",
            "Epoch: 0203 loss_train: 0.6410 acc_train: 0.8500 loss_val: 0.5973 acc_val: 0.8300 time: 0.1102s\n",
            "40\n",
            "Epoch: 0204 loss_train: 0.7340 acc_train: 0.8000 loss_val: 0.5723 acc_val: 0.8220 time: 0.1097s\n",
            "41\n",
            "Epoch: 0205 loss_train: 0.6518 acc_train: 0.8500 loss_val: 0.5314 acc_val: 0.8220 time: 0.1092s\n",
            "42\n",
            "Epoch: 0206 loss_train: 0.6495 acc_train: 0.8833 loss_val: 0.5180 acc_val: 0.8220 time: 0.1092s\n",
            "43\n",
            "Epoch: 0207 loss_train: 0.7101 acc_train: 0.8000 loss_val: 0.5337 acc_val: 0.8420 time: 0.1092s\n",
            "44\n",
            "Epoch: 0208 loss_train: 0.6772 acc_train: 0.7833 loss_val: 0.5377 acc_val: 0.8440 time: 0.1094s\n",
            "45\n",
            "Epoch: 0209 loss_train: 0.6804 acc_train: 0.8333 loss_val: 0.5285 acc_val: 0.8360 time: 0.1091s\n",
            "46\n",
            "Epoch: 0210 loss_train: 0.7043 acc_train: 0.8333 loss_val: 0.5179 acc_val: 0.8400 time: 0.1091s\n",
            "47\n",
            "Epoch: 0211 loss_train: 0.7609 acc_train: 0.7667 loss_val: 0.5303 acc_val: 0.8280 time: 0.1094s\n",
            "48\n",
            "Epoch: 0212 loss_train: 0.6029 acc_train: 0.9167 loss_val: 0.5587 acc_val: 0.8140 time: 0.1114s\n",
            "49\n",
            "Epoch: 0213 loss_train: 0.6183 acc_train: 0.7667 loss_val: 0.5674 acc_val: 0.8100 time: 0.1097s\n",
            "50\n",
            "Epoch: 0214 loss_train: 0.6806 acc_train: 0.8667 loss_val: 0.5849 acc_val: 0.8020 time: 0.1091s\n",
            "51\n",
            "Epoch: 0215 loss_train: 0.5220 acc_train: 0.8333 loss_val: 0.6056 acc_val: 0.8140 time: 0.1102s\n",
            "52\n",
            "Epoch: 0216 loss_train: 0.6066 acc_train: 0.9500 loss_val: 0.5848 acc_val: 0.8280 time: 0.1090s\n",
            "53\n",
            "Epoch: 0217 loss_train: 0.6616 acc_train: 0.8000 loss_val: 0.5431 acc_val: 0.8340 time: 0.1096s\n",
            "54\n",
            "Epoch: 0218 loss_train: 0.5606 acc_train: 0.9500 loss_val: 0.5322 acc_val: 0.8280 time: 0.1097s\n",
            "55\n",
            "Epoch: 0219 loss_train: 0.6213 acc_train: 0.8833 loss_val: 0.5343 acc_val: 0.8320 time: 0.1092s\n",
            "56\n",
            "Epoch: 0220 loss_train: 0.6201 acc_train: 0.8000 loss_val: 0.5268 acc_val: 0.8260 time: 0.1095s\n",
            "57\n",
            "Epoch: 0221 loss_train: 0.5600 acc_train: 0.8333 loss_val: 0.5421 acc_val: 0.8340 time: 0.1099s\n",
            "58\n",
            "Epoch: 0222 loss_train: 0.5963 acc_train: 0.9333 loss_val: 0.5823 acc_val: 0.8240 time: 0.1092s\n",
            "59\n",
            "Epoch: 0223 loss_train: 0.5991 acc_train: 0.9667 loss_val: 0.6415 acc_val: 0.8160 time: 0.1093s\n",
            "60\n",
            "Epoch: 0224 loss_train: 0.6142 acc_train: 0.8500 loss_val: 0.7038 acc_val: 0.8160 time: 0.1100s\n",
            "61\n",
            "Epoch: 0225 loss_train: 0.6454 acc_train: 0.8167 loss_val: 0.7675 acc_val: 0.8200 time: 0.1096s\n",
            "62\n",
            "Epoch: 0226 loss_train: 0.5936 acc_train: 0.9000 loss_val: 0.7763 acc_val: 0.8120 time: 0.1092s\n",
            "63\n",
            "Epoch: 0227 loss_train: 0.7177 acc_train: 0.8667 loss_val: 0.6652 acc_val: 0.8220 time: 0.1098s\n",
            "64\n",
            "Epoch: 0228 loss_train: 0.6018 acc_train: 0.8667 loss_val: 0.6120 acc_val: 0.8240 time: 0.1089s\n",
            "65\n",
            "Epoch: 0229 loss_train: 0.6645 acc_train: 0.8000 loss_val: 0.5718 acc_val: 0.8220 time: 0.1093s\n",
            "66\n",
            "Epoch: 0230 loss_train: 0.6292 acc_train: 0.8167 loss_val: 0.6153 acc_val: 0.8280 time: 0.1106s\n",
            "67\n",
            "Epoch: 0231 loss_train: 0.5985 acc_train: 0.8167 loss_val: 0.6960 acc_val: 0.8220 time: 0.1111s\n",
            "68\n",
            "Epoch: 0232 loss_train: 0.7287 acc_train: 0.8000 loss_val: 0.6543 acc_val: 0.8260 time: 0.1094s\n",
            "69\n",
            "Epoch: 0233 loss_train: 0.6321 acc_train: 0.9000 loss_val: 0.6099 acc_val: 0.8200 time: 0.1099s\n",
            "70\n",
            "Epoch: 0234 loss_train: 0.6010 acc_train: 0.8500 loss_val: 0.5748 acc_val: 0.8260 time: 0.1091s\n",
            "71\n",
            "Epoch: 0235 loss_train: 0.6276 acc_train: 0.8500 loss_val: 0.5746 acc_val: 0.8320 time: 0.1094s\n",
            "72\n",
            "Epoch: 0236 loss_train: 0.6167 acc_train: 0.8500 loss_val: 0.6090 acc_val: 0.8240 time: 0.1091s\n",
            "73\n",
            "Epoch: 0237 loss_train: 0.5636 acc_train: 0.8833 loss_val: 0.7203 acc_val: 0.8120 time: 0.1097s\n",
            "74\n",
            "Epoch: 0238 loss_train: 0.6970 acc_train: 0.9000 loss_val: 0.8069 acc_val: 0.7920 time: 0.1093s\n",
            "75\n",
            "Epoch: 0239 loss_train: 0.6886 acc_train: 0.8333 loss_val: 0.7301 acc_val: 0.8040 time: 0.1114s\n",
            "76\n",
            "Epoch: 0240 loss_train: 0.5665 acc_train: 0.9000 loss_val: 0.6342 acc_val: 0.8320 time: 0.1096s\n",
            "77\n",
            "Epoch: 0241 loss_train: 0.6476 acc_train: 0.8833 loss_val: 0.5913 acc_val: 0.8160 time: 0.1090s\n",
            "78\n",
            "Epoch: 0242 loss_train: 0.6394 acc_train: 0.9167 loss_val: 0.5886 acc_val: 0.8200 time: 0.1090s\n",
            "79\n",
            "Epoch: 0243 loss_train: 0.6340 acc_train: 0.7500 loss_val: 0.5403 acc_val: 0.8320 time: 0.1089s\n",
            "80\n",
            "Epoch: 0244 loss_train: 0.6233 acc_train: 0.8667 loss_val: 0.5366 acc_val: 0.8340 time: 0.1090s\n",
            "81\n",
            "Epoch: 0245 loss_train: 0.6662 acc_train: 0.8667 loss_val: 0.5770 acc_val: 0.8260 time: 0.1091s\n",
            "82\n",
            "Epoch: 0246 loss_train: 0.6782 acc_train: 0.8167 loss_val: 0.6522 acc_val: 0.8080 time: 0.1092s\n",
            "83\n",
            "Epoch: 0247 loss_train: 0.6230 acc_train: 0.8833 loss_val: 0.6781 acc_val: 0.7940 time: 0.1091s\n",
            "84\n",
            "Epoch: 0248 loss_train: 0.6375 acc_train: 0.8667 loss_val: 0.5898 acc_val: 0.8220 time: 0.1092s\n",
            "85\n",
            "Epoch: 0249 loss_train: 0.6037 acc_train: 0.8000 loss_val: 0.5363 acc_val: 0.8320 time: 0.1111s\n",
            "86\n",
            "Epoch: 0250 loss_train: 0.6357 acc_train: 0.8333 loss_val: 0.5444 acc_val: 0.8320 time: 0.1091s\n",
            "87\n",
            "Epoch: 0251 loss_train: 0.6266 acc_train: 0.8333 loss_val: 0.5656 acc_val: 0.8260 time: 0.1095s\n",
            "88\n",
            "Epoch: 0252 loss_train: 0.6034 acc_train: 0.8500 loss_val: 0.5964 acc_val: 0.8240 time: 0.1092s\n",
            "89\n",
            "Epoch: 0253 loss_train: 0.5759 acc_train: 0.9333 loss_val: 0.6898 acc_val: 0.8060 time: 0.1091s\n",
            "90\n",
            "Epoch: 0254 loss_train: 0.5807 acc_train: 0.8833 loss_val: 0.7552 acc_val: 0.7820 time: 0.1092s\n",
            "91\n",
            "Epoch: 0255 loss_train: 0.6132 acc_train: 0.8000 loss_val: 0.8055 acc_val: 0.7840 time: 0.1090s\n",
            "92\n",
            "Epoch: 0256 loss_train: 0.6457 acc_train: 0.8833 loss_val: 0.8323 acc_val: 0.8040 time: 0.1093s\n",
            "93\n",
            "Epoch: 0257 loss_train: 0.7701 acc_train: 0.7667 loss_val: 0.7047 acc_val: 0.8260 time: 0.1128s\n",
            "94\n",
            "Epoch: 0258 loss_train: 0.6071 acc_train: 0.8333 loss_val: 0.6496 acc_val: 0.8300 time: 0.1094s\n",
            "95\n",
            "Epoch: 0259 loss_train: 0.5812 acc_train: 0.7833 loss_val: 0.6222 acc_val: 0.8320 time: 0.1091s\n",
            "96\n",
            "Epoch: 0260 loss_train: 0.5928 acc_train: 0.8500 loss_val: 0.6261 acc_val: 0.8300 time: 0.1090s\n",
            "97\n",
            "Epoch: 0261 loss_train: 0.5971 acc_train: 0.8333 loss_val: 0.6195 acc_val: 0.8400 time: 0.1095s\n",
            "98\n",
            "Epoch: 0262 loss_train: 0.6071 acc_train: 0.8833 loss_val: 0.6250 acc_val: 0.8400 time: 0.1095s\n",
            "99\n",
            "Early stop! Min loss:  0.4539202153682709 , Max accuracy:  0.85\n",
            "Early stop model validation loss:  0.4539202153682709 , accuracy:  0.846\n",
            "Optimization Finished!\n",
            "Total time elapsed: 29.4000s\n",
            "Loading 157th epoch\n",
            "Test set results: loss= 0.4877 accuracy= 0.8410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw-H4-nL3-43",
        "outputId": "3555643d-b883-478d-f225-c8adaa8ad01e"
      },
      "source": [
        "Train() #citeseer\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.9142 acc_train: 0.1667 loss_val: 1.8114 acc_val: 0.2320 time: 0.0225s\n",
            "0\n",
            "Epoch: 0002 loss_train: 1.9087 acc_train: 0.1667 loss_val: 1.8098 acc_val: 0.2320 time: 0.0199s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.9000 acc_train: 0.1667 loss_val: 1.8083 acc_val: 0.2320 time: 0.0200s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.8987 acc_train: 0.1667 loss_val: 1.8068 acc_val: 0.2320 time: 0.0196s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.8957 acc_train: 0.1667 loss_val: 1.8053 acc_val: 0.2320 time: 0.0195s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.8935 acc_train: 0.1667 loss_val: 1.8036 acc_val: 0.2320 time: 0.0196s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.8899 acc_train: 0.1667 loss_val: 1.8017 acc_val: 0.2320 time: 0.0196s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.8838 acc_train: 0.1667 loss_val: 1.8000 acc_val: 0.2320 time: 0.0197s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.8817 acc_train: 0.1667 loss_val: 1.7983 acc_val: 0.2320 time: 0.0196s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.8787 acc_train: 0.1667 loss_val: 1.7967 acc_val: 0.2320 time: 0.0191s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.8757 acc_train: 0.1667 loss_val: 1.7950 acc_val: 0.2320 time: 0.0205s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.8732 acc_train: 0.1667 loss_val: 1.7934 acc_val: 0.2320 time: 0.0188s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.8680 acc_train: 0.1667 loss_val: 1.7920 acc_val: 0.2320 time: 0.0192s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.8696 acc_train: 0.1667 loss_val: 1.7905 acc_val: 0.2320 time: 0.0188s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.8646 acc_train: 0.1667 loss_val: 1.7891 acc_val: 0.2320 time: 0.0190s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.8596 acc_train: 0.1667 loss_val: 1.7878 acc_val: 0.2320 time: 0.0192s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.8575 acc_train: 0.1667 loss_val: 1.7866 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.8506 acc_train: 0.1667 loss_val: 1.7857 acc_val: 0.2320 time: 0.0190s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.8523 acc_train: 0.1667 loss_val: 1.7850 acc_val: 0.2320 time: 0.0191s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.8501 acc_train: 0.1667 loss_val: 1.7844 acc_val: 0.2320 time: 0.0188s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.8473 acc_train: 0.1667 loss_val: 1.7839 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.8460 acc_train: 0.1667 loss_val: 1.7833 acc_val: 0.2320 time: 0.0189s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.8435 acc_train: 0.1667 loss_val: 1.7827 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.8404 acc_train: 0.1667 loss_val: 1.7820 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.8373 acc_train: 0.1667 loss_val: 1.7813 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.8362 acc_train: 0.1667 loss_val: 1.7806 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.8355 acc_train: 0.1667 loss_val: 1.7796 acc_val: 0.2320 time: 0.0186s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.8361 acc_train: 0.1667 loss_val: 1.7787 acc_val: 0.2320 time: 0.0202s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.8309 acc_train: 0.1667 loss_val: 1.7777 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.8307 acc_train: 0.1667 loss_val: 1.7765 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.8250 acc_train: 0.1667 loss_val: 1.7750 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.8219 acc_train: 0.1667 loss_val: 1.7736 acc_val: 0.2320 time: 0.0189s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.8238 acc_train: 0.1667 loss_val: 1.7722 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.8146 acc_train: 0.1667 loss_val: 1.7710 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.8213 acc_train: 0.1667 loss_val: 1.7696 acc_val: 0.2320 time: 0.0186s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.8041 acc_train: 0.1667 loss_val: 1.7683 acc_val: 0.2320 time: 0.0188s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.8074 acc_train: 0.1667 loss_val: 1.7671 acc_val: 0.2320 time: 0.0214s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.7924 acc_train: 0.1667 loss_val: 1.7661 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.7923 acc_train: 0.1667 loss_val: 1.7653 acc_val: 0.2320 time: 0.0202s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.7835 acc_train: 0.1667 loss_val: 1.7645 acc_val: 0.2320 time: 0.0191s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.7813 acc_train: 0.1750 loss_val: 1.7637 acc_val: 0.2320 time: 0.0189s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.7718 acc_train: 0.1750 loss_val: 1.7626 acc_val: 0.2320 time: 0.0190s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.7674 acc_train: 0.2000 loss_val: 1.7611 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.7609 acc_train: 0.1917 loss_val: 1.7602 acc_val: 0.2320 time: 0.0193s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.7553 acc_train: 0.2250 loss_val: 1.7599 acc_val: 0.2320 time: 0.0189s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.7539 acc_train: 0.2500 loss_val: 1.7597 acc_val: 0.2320 time: 0.0194s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.7493 acc_train: 0.2500 loss_val: 1.7596 acc_val: 0.2320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.7396 acc_train: 0.4083 loss_val: 1.7597 acc_val: 0.2340 time: 0.0187s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.7384 acc_train: 0.3167 loss_val: 1.7607 acc_val: 0.2400 time: 0.0192s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.7283 acc_train: 0.3500 loss_val: 1.7620 acc_val: 0.2520 time: 0.0190s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.7157 acc_train: 0.4083 loss_val: 1.7638 acc_val: 0.2780 time: 0.0190s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.7309 acc_train: 0.3333 loss_val: 1.7651 acc_val: 0.3100 time: 0.0191s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.7181 acc_train: 0.3417 loss_val: 1.7659 acc_val: 0.3200 time: 0.0191s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.7088 acc_train: 0.3500 loss_val: 1.7659 acc_val: 0.3400 time: 0.0198s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.7092 acc_train: 0.3333 loss_val: 1.7651 acc_val: 0.3040 time: 0.0190s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.7157 acc_train: 0.4000 loss_val: 1.7642 acc_val: 0.3420 time: 0.0200s\n",
            "1\n",
            "Epoch: 0057 loss_train: 1.6999 acc_train: 0.4083 loss_val: 1.7628 acc_val: 0.4000 time: 0.0189s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.6870 acc_train: 0.4750 loss_val: 1.7610 acc_val: 0.4240 time: 0.0190s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.7089 acc_train: 0.4083 loss_val: 1.7585 acc_val: 0.4420 time: 0.0189s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.6882 acc_train: 0.4000 loss_val: 1.7560 acc_val: 0.4640 time: 0.0187s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.6960 acc_train: 0.4667 loss_val: 1.7525 acc_val: 0.4760 time: 0.0187s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.6748 acc_train: 0.4583 loss_val: 1.7486 acc_val: 0.4860 time: 0.0187s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.6783 acc_train: 0.3833 loss_val: 1.7444 acc_val: 0.5180 time: 0.0189s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.6753 acc_train: 0.4500 loss_val: 1.7402 acc_val: 0.5240 time: 0.0189s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.6780 acc_train: 0.4250 loss_val: 1.7356 acc_val: 0.5300 time: 0.0188s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.6547 acc_train: 0.4583 loss_val: 1.7316 acc_val: 0.5140 time: 0.0188s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.6468 acc_train: 0.3833 loss_val: 1.7281 acc_val: 0.4960 time: 0.0197s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.6562 acc_train: 0.4167 loss_val: 1.7257 acc_val: 0.4680 time: 0.0190s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.6292 acc_train: 0.4917 loss_val: 1.7240 acc_val: 0.4160 time: 0.0187s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.6414 acc_train: 0.4750 loss_val: 1.7230 acc_val: 0.3660 time: 0.0187s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.6517 acc_train: 0.4333 loss_val: 1.7231 acc_val: 0.3480 time: 0.0192s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.6229 acc_train: 0.4750 loss_val: 1.7230 acc_val: 0.3360 time: 0.0187s\n",
            "1\n",
            "Epoch: 0073 loss_train: 1.6379 acc_train: 0.5417 loss_val: 1.7230 acc_val: 0.3540 time: 0.0202s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.6117 acc_train: 0.4667 loss_val: 1.7232 acc_val: 0.3860 time: 0.0192s\n",
            "1\n",
            "Epoch: 0075 loss_train: 1.6258 acc_train: 0.5250 loss_val: 1.7225 acc_val: 0.4260 time: 0.0208s\n",
            "2\n",
            "Epoch: 0076 loss_train: 1.6110 acc_train: 0.5000 loss_val: 1.7203 acc_val: 0.4520 time: 0.0189s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.5626 acc_train: 0.6500 loss_val: 1.7173 acc_val: 0.4620 time: 0.0186s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.5637 acc_train: 0.5083 loss_val: 1.7147 acc_val: 0.4600 time: 0.0187s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.5801 acc_train: 0.5333 loss_val: 1.7109 acc_val: 0.4700 time: 0.0186s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.6098 acc_train: 0.5500 loss_val: 1.7058 acc_val: 0.4680 time: 0.0186s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.5718 acc_train: 0.5417 loss_val: 1.7003 acc_val: 0.4640 time: 0.0187s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.5807 acc_train: 0.4167 loss_val: 1.6964 acc_val: 0.4560 time: 0.0204s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.5623 acc_train: 0.5000 loss_val: 1.6929 acc_val: 0.4500 time: 0.0187s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.5465 acc_train: 0.5083 loss_val: 1.6899 acc_val: 0.4380 time: 0.0187s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.5645 acc_train: 0.5083 loss_val: 1.6871 acc_val: 0.4380 time: 0.0205s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.5057 acc_train: 0.5583 loss_val: 1.6850 acc_val: 0.4260 time: 0.0202s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.5148 acc_train: 0.6333 loss_val: 1.6828 acc_val: 0.4280 time: 0.0191s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.5199 acc_train: 0.5750 loss_val: 1.6789 acc_val: 0.4380 time: 0.0188s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.5241 acc_train: 0.5167 loss_val: 1.6736 acc_val: 0.4700 time: 0.0189s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.5246 acc_train: 0.5750 loss_val: 1.6678 acc_val: 0.5160 time: 0.0188s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.4961 acc_train: 0.6333 loss_val: 1.6621 acc_val: 0.5540 time: 0.0191s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.4934 acc_train: 0.5417 loss_val: 1.6564 acc_val: 0.5680 time: 0.0188s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.4744 acc_train: 0.5833 loss_val: 1.6515 acc_val: 0.5580 time: 0.0187s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.4626 acc_train: 0.5750 loss_val: 1.6461 acc_val: 0.5620 time: 0.0195s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.4851 acc_train: 0.6167 loss_val: 1.6404 acc_val: 0.5800 time: 0.0189s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.4991 acc_train: 0.5333 loss_val: 1.6351 acc_val: 0.5840 time: 0.0187s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.4492 acc_train: 0.5917 loss_val: 1.6302 acc_val: 0.5860 time: 0.0188s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.4482 acc_train: 0.5917 loss_val: 1.6248 acc_val: 0.5880 time: 0.0187s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.4665 acc_train: 0.6000 loss_val: 1.6194 acc_val: 0.5920 time: 0.0187s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.4616 acc_train: 0.5833 loss_val: 1.6149 acc_val: 0.5800 time: 0.0192s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.4448 acc_train: 0.6250 loss_val: 1.6121 acc_val: 0.5800 time: 0.0189s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.4327 acc_train: 0.6250 loss_val: 1.6092 acc_val: 0.5600 time: 0.0188s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.4317 acc_train: 0.5750 loss_val: 1.6064 acc_val: 0.5700 time: 0.0187s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.4746 acc_train: 0.5500 loss_val: 1.6020 acc_val: 0.5780 time: 0.0186s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.4301 acc_train: 0.6250 loss_val: 1.5979 acc_val: 0.6040 time: 0.0187s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.4187 acc_train: 0.5917 loss_val: 1.5929 acc_val: 0.6300 time: 0.0187s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.4082 acc_train: 0.5917 loss_val: 1.5878 acc_val: 0.6580 time: 0.0187s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.3775 acc_train: 0.6167 loss_val: 1.5815 acc_val: 0.6620 time: 0.0187s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.3526 acc_train: 0.5750 loss_val: 1.5748 acc_val: 0.6700 time: 0.0194s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.4389 acc_train: 0.5833 loss_val: 1.5680 acc_val: 0.6640 time: 0.0187s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.4024 acc_train: 0.5750 loss_val: 1.5599 acc_val: 0.6560 time: 0.0191s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.3616 acc_train: 0.6917 loss_val: 1.5547 acc_val: 0.6440 time: 0.0189s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.3389 acc_train: 0.6750 loss_val: 1.5494 acc_val: 0.6380 time: 0.0188s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.3219 acc_train: 0.6583 loss_val: 1.5459 acc_val: 0.6500 time: 0.0187s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.3774 acc_train: 0.6167 loss_val: 1.5422 acc_val: 0.6620 time: 0.0187s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.3230 acc_train: 0.6500 loss_val: 1.5380 acc_val: 0.6760 time: 0.0187s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.3362 acc_train: 0.6750 loss_val: 1.5353 acc_val: 0.6720 time: 0.0188s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.3069 acc_train: 0.6500 loss_val: 1.5317 acc_val: 0.6760 time: 0.0191s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.3553 acc_train: 0.6000 loss_val: 1.5262 acc_val: 0.6860 time: 0.0187s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.3128 acc_train: 0.6583 loss_val: 1.5198 acc_val: 0.6820 time: 0.0186s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.2498 acc_train: 0.6750 loss_val: 1.5140 acc_val: 0.6820 time: 0.0188s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.3351 acc_train: 0.6583 loss_val: 1.5076 acc_val: 0.6760 time: 0.0205s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.3175 acc_train: 0.6917 loss_val: 1.4995 acc_val: 0.6560 time: 0.0186s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.2546 acc_train: 0.7333 loss_val: 1.4937 acc_val: 0.6460 time: 0.0187s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.2646 acc_train: 0.8000 loss_val: 1.4906 acc_val: 0.6380 time: 0.0186s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.3207 acc_train: 0.6750 loss_val: 1.4905 acc_val: 0.6420 time: 0.0187s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.3794 acc_train: 0.6167 loss_val: 1.4877 acc_val: 0.6460 time: 0.0208s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.2865 acc_train: 0.7167 loss_val: 1.4832 acc_val: 0.6560 time: 0.0188s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.2968 acc_train: 0.6333 loss_val: 1.4758 acc_val: 0.6660 time: 0.0187s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.2755 acc_train: 0.6333 loss_val: 1.4689 acc_val: 0.6660 time: 0.0186s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.2647 acc_train: 0.6667 loss_val: 1.4617 acc_val: 0.6760 time: 0.0188s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.2690 acc_train: 0.6917 loss_val: 1.4546 acc_val: 0.6800 time: 0.0188s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.2418 acc_train: 0.7333 loss_val: 1.4454 acc_val: 0.6840 time: 0.0188s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.2326 acc_train: 0.7000 loss_val: 1.4364 acc_val: 0.6960 time: 0.0188s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.1826 acc_train: 0.7583 loss_val: 1.4278 acc_val: 0.6920 time: 0.0189s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.2432 acc_train: 0.6500 loss_val: 1.4225 acc_val: 0.6900 time: 0.0197s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.2404 acc_train: 0.6500 loss_val: 1.4203 acc_val: 0.6820 time: 0.0206s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.2157 acc_train: 0.7583 loss_val: 1.4201 acc_val: 0.6800 time: 0.0188s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.1912 acc_train: 0.6833 loss_val: 1.4232 acc_val: 0.6680 time: 0.0210s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.2102 acc_train: 0.6917 loss_val: 1.4260 acc_val: 0.6640 time: 0.0195s\n",
            "1\n",
            "Epoch: 0141 loss_train: 1.1813 acc_train: 0.7250 loss_val: 1.4252 acc_val: 0.6460 time: 0.0194s\n",
            "2\n",
            "Epoch: 0142 loss_train: 1.2126 acc_train: 0.7000 loss_val: 1.4209 acc_val: 0.6500 time: 0.0192s\n",
            "3\n",
            "Epoch: 0143 loss_train: 1.1974 acc_train: 0.6750 loss_val: 1.4123 acc_val: 0.6480 time: 0.0191s\n",
            "4\n",
            "Epoch: 0144 loss_train: 1.1948 acc_train: 0.6833 loss_val: 1.4037 acc_val: 0.6600 time: 0.0187s\n",
            "0\n",
            "Epoch: 0145 loss_train: 1.2618 acc_train: 0.6750 loss_val: 1.3945 acc_val: 0.6860 time: 0.0186s\n",
            "0\n",
            "Epoch: 0146 loss_train: 1.2076 acc_train: 0.7500 loss_val: 1.3846 acc_val: 0.6920 time: 0.0191s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.1794 acc_train: 0.7250 loss_val: 1.3750 acc_val: 0.6900 time: 0.0186s\n",
            "0\n",
            "Epoch: 0148 loss_train: 1.2190 acc_train: 0.6417 loss_val: 1.3687 acc_val: 0.7020 time: 0.0186s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.1945 acc_train: 0.7083 loss_val: 1.3653 acc_val: 0.7060 time: 0.0190s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.2314 acc_train: 0.6417 loss_val: 1.3633 acc_val: 0.7120 time: 0.0195s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.3006 acc_train: 0.6250 loss_val: 1.3642 acc_val: 0.7020 time: 0.0187s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.1870 acc_train: 0.7333 loss_val: 1.3652 acc_val: 0.6940 time: 0.0198s\n",
            "1\n",
            "Epoch: 0153 loss_train: 1.1551 acc_train: 0.7417 loss_val: 1.3662 acc_val: 0.6840 time: 0.0190s\n",
            "2\n",
            "Epoch: 0154 loss_train: 1.1495 acc_train: 0.6917 loss_val: 1.3662 acc_val: 0.6680 time: 0.0190s\n",
            "3\n",
            "Epoch: 0155 loss_train: 1.1581 acc_train: 0.6667 loss_val: 1.3643 acc_val: 0.6620 time: 0.0194s\n",
            "4\n",
            "Epoch: 0156 loss_train: 1.1689 acc_train: 0.7167 loss_val: 1.3617 acc_val: 0.6660 time: 0.0190s\n",
            "5\n",
            "Epoch: 0157 loss_train: 1.1437 acc_train: 0.7500 loss_val: 1.3541 acc_val: 0.6700 time: 0.0186s\n",
            "0\n",
            "Epoch: 0158 loss_train: 1.1302 acc_train: 0.7250 loss_val: 1.3442 acc_val: 0.6820 time: 0.0186s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.1438 acc_train: 0.7083 loss_val: 1.3351 acc_val: 0.6940 time: 0.0187s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.2203 acc_train: 0.6917 loss_val: 1.3278 acc_val: 0.7020 time: 0.0187s\n",
            "0\n",
            "Epoch: 0161 loss_train: 1.1408 acc_train: 0.6917 loss_val: 1.3236 acc_val: 0.7120 time: 0.0187s\n",
            "0\n",
            "Epoch: 0162 loss_train: 1.1525 acc_train: 0.7250 loss_val: 1.3217 acc_val: 0.7060 time: 0.0186s\n",
            "0\n",
            "Epoch: 0163 loss_train: 1.1239 acc_train: 0.7083 loss_val: 1.3209 acc_val: 0.7020 time: 0.0186s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.1453 acc_train: 0.6667 loss_val: 1.3222 acc_val: 0.7020 time: 0.0196s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.1962 acc_train: 0.7083 loss_val: 1.3255 acc_val: 0.6980 time: 0.0190s\n",
            "1\n",
            "Epoch: 0166 loss_train: 1.1265 acc_train: 0.7333 loss_val: 1.3265 acc_val: 0.6860 time: 0.0193s\n",
            "2\n",
            "Epoch: 0167 loss_train: 1.1027 acc_train: 0.7500 loss_val: 1.3244 acc_val: 0.6760 time: 0.0190s\n",
            "3\n",
            "Epoch: 0168 loss_train: 1.1428 acc_train: 0.7583 loss_val: 1.3184 acc_val: 0.6920 time: 0.0190s\n",
            "4\n",
            "Epoch: 0169 loss_train: 1.0985 acc_train: 0.7333 loss_val: 1.3107 acc_val: 0.6880 time: 0.0187s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.1386 acc_train: 0.7167 loss_val: 1.3044 acc_val: 0.6780 time: 0.0187s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.0806 acc_train: 0.7083 loss_val: 1.2962 acc_val: 0.6800 time: 0.0189s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.1790 acc_train: 0.7167 loss_val: 1.2889 acc_val: 0.6940 time: 0.0187s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.1018 acc_train: 0.7000 loss_val: 1.2841 acc_val: 0.7080 time: 0.0190s\n",
            "0\n",
            "Epoch: 0174 loss_train: 1.1325 acc_train: 0.6833 loss_val: 1.2836 acc_val: 0.7040 time: 0.0188s\n",
            "0\n",
            "Epoch: 0175 loss_train: 1.1551 acc_train: 0.6833 loss_val: 1.2858 acc_val: 0.7100 time: 0.0188s\n",
            "0\n",
            "Epoch: 0176 loss_train: 1.1025 acc_train: 0.7000 loss_val: 1.2884 acc_val: 0.7120 time: 0.0190s\n",
            "1\n",
            "Epoch: 0177 loss_train: 1.2353 acc_train: 0.6667 loss_val: 1.2901 acc_val: 0.7180 time: 0.0194s\n",
            "0\n",
            "Epoch: 0178 loss_train: 1.1620 acc_train: 0.7250 loss_val: 1.2876 acc_val: 0.7180 time: 0.0192s\n",
            "0\n",
            "Epoch: 0179 loss_train: 1.1019 acc_train: 0.7583 loss_val: 1.2844 acc_val: 0.7120 time: 0.0191s\n",
            "0\n",
            "Epoch: 0180 loss_train: 1.1473 acc_train: 0.7250 loss_val: 1.2804 acc_val: 0.7080 time: 0.0190s\n",
            "1\n",
            "Epoch: 0181 loss_train: 1.1243 acc_train: 0.7333 loss_val: 1.2767 acc_val: 0.6960 time: 0.0193s\n",
            "0\n",
            "Epoch: 0182 loss_train: 1.1198 acc_train: 0.7500 loss_val: 1.2711 acc_val: 0.6920 time: 0.0193s\n",
            "0\n",
            "Epoch: 0183 loss_train: 1.1237 acc_train: 0.7333 loss_val: 1.2650 acc_val: 0.6900 time: 0.0187s\n",
            "0\n",
            "Epoch: 0184 loss_train: 1.0450 acc_train: 0.7167 loss_val: 1.2586 acc_val: 0.6940 time: 0.0187s\n",
            "0\n",
            "Epoch: 0185 loss_train: 1.1228 acc_train: 0.7250 loss_val: 1.2542 acc_val: 0.7040 time: 0.0187s\n",
            "0\n",
            "Epoch: 0186 loss_train: 1.0546 acc_train: 0.7250 loss_val: 1.2506 acc_val: 0.7000 time: 0.0187s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.0649 acc_train: 0.7500 loss_val: 1.2493 acc_val: 0.7120 time: 0.0189s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.1250 acc_train: 0.7500 loss_val: 1.2514 acc_val: 0.7240 time: 0.0189s\n",
            "0\n",
            "Epoch: 0189 loss_train: 1.0900 acc_train: 0.7833 loss_val: 1.2565 acc_val: 0.7180 time: 0.0192s\n",
            "0\n",
            "Epoch: 0190 loss_train: 1.0511 acc_train: 0.7000 loss_val: 1.2627 acc_val: 0.7160 time: 0.0195s\n",
            "1\n",
            "Epoch: 0191 loss_train: 1.0472 acc_train: 0.7500 loss_val: 1.2646 acc_val: 0.7120 time: 0.0194s\n",
            "2\n",
            "Epoch: 0192 loss_train: 1.0598 acc_train: 0.7833 loss_val: 1.2603 acc_val: 0.6960 time: 0.0201s\n",
            "3\n",
            "Epoch: 0193 loss_train: 1.1018 acc_train: 0.7083 loss_val: 1.2524 acc_val: 0.6960 time: 0.0203s\n",
            "4\n",
            "Epoch: 0194 loss_train: 1.0299 acc_train: 0.7750 loss_val: 1.2410 acc_val: 0.6980 time: 0.0194s\n",
            "5\n",
            "Epoch: 0195 loss_train: 1.0368 acc_train: 0.7667 loss_val: 1.2322 acc_val: 0.7040 time: 0.0187s\n",
            "0\n",
            "Epoch: 0196 loss_train: 1.0301 acc_train: 0.6917 loss_val: 1.2239 acc_val: 0.7220 time: 0.0187s\n",
            "0\n",
            "Epoch: 0197 loss_train: 1.0271 acc_train: 0.7750 loss_val: 1.2190 acc_val: 0.7240 time: 0.0187s\n",
            "0\n",
            "Epoch: 0198 loss_train: 0.9720 acc_train: 0.8250 loss_val: 1.2166 acc_val: 0.7240 time: 0.0186s\n",
            "0\n",
            "Epoch: 0199 loss_train: 1.0942 acc_train: 0.7583 loss_val: 1.2164 acc_val: 0.7240 time: 0.0187s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.0972 acc_train: 0.7750 loss_val: 1.2186 acc_val: 0.7240 time: 0.0187s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.0481 acc_train: 0.8000 loss_val: 1.2213 acc_val: 0.7180 time: 0.0194s\n",
            "0\n",
            "Epoch: 0202 loss_train: 1.0205 acc_train: 0.7583 loss_val: 1.2262 acc_val: 0.7100 time: 0.0202s\n",
            "1\n",
            "Epoch: 0203 loss_train: 1.0963 acc_train: 0.8000 loss_val: 1.2318 acc_val: 0.7020 time: 0.0191s\n",
            "2\n",
            "Epoch: 0204 loss_train: 0.9819 acc_train: 0.7917 loss_val: 1.2328 acc_val: 0.6940 time: 0.0190s\n",
            "3\n",
            "Epoch: 0205 loss_train: 1.0090 acc_train: 0.7667 loss_val: 1.2288 acc_val: 0.7000 time: 0.0200s\n",
            "4\n",
            "Epoch: 0206 loss_train: 1.0032 acc_train: 0.7917 loss_val: 1.2208 acc_val: 0.7060 time: 0.0192s\n",
            "5\n",
            "Epoch: 0207 loss_train: 1.0420 acc_train: 0.7917 loss_val: 1.2111 acc_val: 0.7220 time: 0.0193s\n",
            "6\n",
            "Epoch: 0208 loss_train: 1.0170 acc_train: 0.7667 loss_val: 1.2019 acc_val: 0.7280 time: 0.0188s\n",
            "0\n",
            "Epoch: 0209 loss_train: 1.1186 acc_train: 0.7250 loss_val: 1.1945 acc_val: 0.7320 time: 0.0188s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.0159 acc_train: 0.7667 loss_val: 1.1911 acc_val: 0.7340 time: 0.0190s\n",
            "0\n",
            "Epoch: 0211 loss_train: 0.9634 acc_train: 0.8000 loss_val: 1.1907 acc_val: 0.7300 time: 0.0186s\n",
            "0\n",
            "Epoch: 0212 loss_train: 1.0480 acc_train: 0.7667 loss_val: 1.1927 acc_val: 0.7280 time: 0.0187s\n",
            "0\n",
            "Epoch: 0213 loss_train: 1.0400 acc_train: 0.8167 loss_val: 1.1950 acc_val: 0.7200 time: 0.0203s\n",
            "1\n",
            "Epoch: 0214 loss_train: 1.1018 acc_train: 0.7417 loss_val: 1.1975 acc_val: 0.7180 time: 0.0191s\n",
            "2\n",
            "Epoch: 0215 loss_train: 1.0541 acc_train: 0.7083 loss_val: 1.1983 acc_val: 0.7160 time: 0.0189s\n",
            "3\n",
            "Epoch: 0216 loss_train: 1.0427 acc_train: 0.7500 loss_val: 1.1980 acc_val: 0.7160 time: 0.0189s\n",
            "4\n",
            "Epoch: 0217 loss_train: 1.0435 acc_train: 0.7167 loss_val: 1.1936 acc_val: 0.7220 time: 0.0190s\n",
            "5\n",
            "Epoch: 0218 loss_train: 1.0413 acc_train: 0.7667 loss_val: 1.1887 acc_val: 0.7240 time: 0.0189s\n",
            "6\n",
            "Epoch: 0219 loss_train: 0.9985 acc_train: 0.8000 loss_val: 1.1847 acc_val: 0.7200 time: 0.0188s\n",
            "0\n",
            "Epoch: 0220 loss_train: 1.0419 acc_train: 0.7667 loss_val: 1.1822 acc_val: 0.7300 time: 0.0192s\n",
            "0\n",
            "Epoch: 0221 loss_train: 0.9898 acc_train: 0.7917 loss_val: 1.1791 acc_val: 0.7300 time: 0.0187s\n",
            "0\n",
            "Epoch: 0222 loss_train: 1.1121 acc_train: 0.7500 loss_val: 1.1766 acc_val: 0.7340 time: 0.0187s\n",
            "0\n",
            "Epoch: 0223 loss_train: 1.0377 acc_train: 0.7583 loss_val: 1.1738 acc_val: 0.7320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0224 loss_train: 0.9811 acc_train: 0.7417 loss_val: 1.1700 acc_val: 0.7320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0225 loss_train: 0.9724 acc_train: 0.8083 loss_val: 1.1703 acc_val: 0.7200 time: 0.0204s\n",
            "0\n",
            "Epoch: 0226 loss_train: 0.9270 acc_train: 0.8000 loss_val: 1.1717 acc_val: 0.7160 time: 0.0191s\n",
            "1\n",
            "Epoch: 0227 loss_train: 1.0178 acc_train: 0.7333 loss_val: 1.1709 acc_val: 0.7100 time: 0.0190s\n",
            "2\n",
            "Epoch: 0228 loss_train: 1.0139 acc_train: 0.7667 loss_val: 1.1712 acc_val: 0.7140 time: 0.0191s\n",
            "3\n",
            "Epoch: 0229 loss_train: 0.9951 acc_train: 0.7500 loss_val: 1.1708 acc_val: 0.7240 time: 0.0190s\n",
            "4\n",
            "Epoch: 0230 loss_train: 1.0371 acc_train: 0.7500 loss_val: 1.1694 acc_val: 0.7260 time: 0.0191s\n",
            "5\n",
            "Epoch: 0231 loss_train: 1.0013 acc_train: 0.8083 loss_val: 1.1643 acc_val: 0.7320 time: 0.0187s\n",
            "0\n",
            "Epoch: 0232 loss_train: 0.9578 acc_train: 0.8000 loss_val: 1.1605 acc_val: 0.7280 time: 0.0188s\n",
            "0\n",
            "Epoch: 0233 loss_train: 0.9337 acc_train: 0.8167 loss_val: 1.1609 acc_val: 0.7180 time: 0.0187s\n",
            "0\n",
            "Epoch: 0234 loss_train: 0.9876 acc_train: 0.7583 loss_val: 1.1602 acc_val: 0.7180 time: 0.0190s\n",
            "1\n",
            "Epoch: 0235 loss_train: 0.9920 acc_train: 0.8000 loss_val: 1.1577 acc_val: 0.7080 time: 0.0186s\n",
            "0\n",
            "Epoch: 0236 loss_train: 0.9501 acc_train: 0.8500 loss_val: 1.1560 acc_val: 0.7020 time: 0.0186s\n",
            "0\n",
            "Epoch: 0237 loss_train: 0.9959 acc_train: 0.7333 loss_val: 1.1520 acc_val: 0.6980 time: 0.0189s\n",
            "0\n",
            "Epoch: 0238 loss_train: 1.0305 acc_train: 0.7750 loss_val: 1.1469 acc_val: 0.7000 time: 0.0187s\n",
            "0\n",
            "Epoch: 0239 loss_train: 0.9929 acc_train: 0.7417 loss_val: 1.1435 acc_val: 0.7080 time: 0.0187s\n",
            "0\n",
            "Epoch: 0240 loss_train: 0.9509 acc_train: 0.8333 loss_val: 1.1421 acc_val: 0.7080 time: 0.0187s\n",
            "0\n",
            "Epoch: 0241 loss_train: 0.9620 acc_train: 0.8167 loss_val: 1.1412 acc_val: 0.7140 time: 0.0186s\n",
            "0\n",
            "Epoch: 0242 loss_train: 1.0121 acc_train: 0.7500 loss_val: 1.1422 acc_val: 0.7260 time: 0.0186s\n",
            "0\n",
            "Epoch: 0243 loss_train: 0.9508 acc_train: 0.8417 loss_val: 1.1452 acc_val: 0.7240 time: 0.0192s\n",
            "1\n",
            "Epoch: 0244 loss_train: 0.9752 acc_train: 0.7833 loss_val: 1.1454 acc_val: 0.7220 time: 0.0189s\n",
            "2\n",
            "Epoch: 0245 loss_train: 1.0021 acc_train: 0.7250 loss_val: 1.1458 acc_val: 0.7220 time: 0.0191s\n",
            "3\n",
            "Epoch: 0246 loss_train: 0.9295 acc_train: 0.8000 loss_val: 1.1406 acc_val: 0.7220 time: 0.0189s\n",
            "4\n",
            "Epoch: 0247 loss_train: 0.9292 acc_train: 0.8167 loss_val: 1.1322 acc_val: 0.7160 time: 0.0187s\n",
            "0\n",
            "Epoch: 0248 loss_train: 0.9087 acc_train: 0.7917 loss_val: 1.1270 acc_val: 0.7080 time: 0.0193s\n",
            "0\n",
            "Epoch: 0249 loss_train: 1.0035 acc_train: 0.7667 loss_val: 1.1215 acc_val: 0.7060 time: 0.0186s\n",
            "0\n",
            "Epoch: 0250 loss_train: 1.0369 acc_train: 0.7417 loss_val: 1.1184 acc_val: 0.7080 time: 0.0187s\n",
            "0\n",
            "Epoch: 0251 loss_train: 0.9799 acc_train: 0.8083 loss_val: 1.1174 acc_val: 0.7200 time: 0.0186s\n",
            "0\n",
            "Epoch: 0252 loss_train: 0.9692 acc_train: 0.8000 loss_val: 1.1187 acc_val: 0.7260 time: 0.0187s\n",
            "0\n",
            "Epoch: 0253 loss_train: 0.9659 acc_train: 0.8000 loss_val: 1.1207 acc_val: 0.7300 time: 0.0191s\n",
            "1\n",
            "Epoch: 0254 loss_train: 0.9647 acc_train: 0.7833 loss_val: 1.1223 acc_val: 0.7320 time: 0.0189s\n",
            "2\n",
            "Epoch: 0255 loss_train: 1.0484 acc_train: 0.7583 loss_val: 1.1231 acc_val: 0.7300 time: 0.0189s\n",
            "3\n",
            "Epoch: 0256 loss_train: 0.9290 acc_train: 0.7750 loss_val: 1.1219 acc_val: 0.7120 time: 0.0189s\n",
            "4\n",
            "Epoch: 0257 loss_train: 0.8889 acc_train: 0.7667 loss_val: 1.1147 acc_val: 0.7140 time: 0.0197s\n",
            "5\n",
            "Epoch: 0258 loss_train: 0.9868 acc_train: 0.7667 loss_val: 1.1076 acc_val: 0.7120 time: 0.0187s\n",
            "0\n",
            "Epoch: 0259 loss_train: 0.9600 acc_train: 0.8167 loss_val: 1.1023 acc_val: 0.7120 time: 0.0187s\n",
            "0\n",
            "Epoch: 0260 loss_train: 0.8833 acc_train: 0.8333 loss_val: 1.0999 acc_val: 0.7080 time: 0.0188s\n",
            "0\n",
            "Epoch: 0261 loss_train: 0.9798 acc_train: 0.7583 loss_val: 1.0971 acc_val: 0.7180 time: 0.0187s\n",
            "0\n",
            "Epoch: 0262 loss_train: 0.8761 acc_train: 0.8333 loss_val: 1.0939 acc_val: 0.7260 time: 0.0203s\n",
            "0\n",
            "Epoch: 0263 loss_train: 0.9692 acc_train: 0.7667 loss_val: 1.0944 acc_val: 0.7240 time: 0.0191s\n",
            "0\n",
            "Epoch: 0264 loss_train: 0.9937 acc_train: 0.7750 loss_val: 1.0963 acc_val: 0.7280 time: 0.0190s\n",
            "1\n",
            "Epoch: 0265 loss_train: 0.9150 acc_train: 0.8583 loss_val: 1.0973 acc_val: 0.7280 time: 0.0190s\n",
            "2\n",
            "Epoch: 0266 loss_train: 0.9284 acc_train: 0.8083 loss_val: 1.1012 acc_val: 0.7260 time: 0.0209s\n",
            "3\n",
            "Epoch: 0267 loss_train: 0.9438 acc_train: 0.8083 loss_val: 1.1050 acc_val: 0.7240 time: 0.0190s\n",
            "4\n",
            "Epoch: 0268 loss_train: 0.9433 acc_train: 0.8333 loss_val: 1.1072 acc_val: 0.7180 time: 0.0189s\n",
            "5\n",
            "Epoch: 0269 loss_train: 1.0365 acc_train: 0.7583 loss_val: 1.1102 acc_val: 0.7140 time: 0.0190s\n",
            "6\n",
            "Epoch: 0270 loss_train: 0.8794 acc_train: 0.8500 loss_val: 1.1049 acc_val: 0.7200 time: 0.0198s\n",
            "7\n",
            "Epoch: 0271 loss_train: 1.0075 acc_train: 0.7417 loss_val: 1.0963 acc_val: 0.7220 time: 0.0191s\n",
            "8\n",
            "Epoch: 0272 loss_train: 0.8898 acc_train: 0.7750 loss_val: 1.0878 acc_val: 0.7260 time: 0.0190s\n",
            "9\n",
            "Epoch: 0273 loss_train: 0.9278 acc_train: 0.7500 loss_val: 1.0842 acc_val: 0.7260 time: 0.0187s\n",
            "0\n",
            "Epoch: 0274 loss_train: 0.9855 acc_train: 0.7667 loss_val: 1.0795 acc_val: 0.7260 time: 0.0197s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.9772 acc_train: 0.7500 loss_val: 1.0755 acc_val: 0.7280 time: 0.0198s\n",
            "0\n",
            "Epoch: 0276 loss_train: 0.9780 acc_train: 0.8083 loss_val: 1.0738 acc_val: 0.7300 time: 0.0204s\n",
            "0\n",
            "Epoch: 0277 loss_train: 0.9215 acc_train: 0.8000 loss_val: 1.0720 acc_val: 0.7300 time: 0.0191s\n",
            "0\n",
            "Epoch: 0278 loss_train: 0.9575 acc_train: 0.7583 loss_val: 1.0732 acc_val: 0.7380 time: 0.0195s\n",
            "0\n",
            "Epoch: 0279 loss_train: 0.9498 acc_train: 0.8167 loss_val: 1.0777 acc_val: 0.7380 time: 0.0202s\n",
            "0\n",
            "Epoch: 0280 loss_train: 0.9140 acc_train: 0.8583 loss_val: 1.0803 acc_val: 0.7360 time: 0.0196s\n",
            "0\n",
            "Epoch: 0281 loss_train: 0.8867 acc_train: 0.8250 loss_val: 1.0849 acc_val: 0.7380 time: 0.0191s\n",
            "1\n",
            "Epoch: 0282 loss_train: 0.9700 acc_train: 0.8167 loss_val: 1.0882 acc_val: 0.7340 time: 0.0192s\n",
            "0\n",
            "Epoch: 0283 loss_train: 0.9637 acc_train: 0.7583 loss_val: 1.0870 acc_val: 0.7360 time: 0.0190s\n",
            "1\n",
            "Epoch: 0284 loss_train: 0.9277 acc_train: 0.8083 loss_val: 1.0807 acc_val: 0.7320 time: 0.0189s\n",
            "2\n",
            "Epoch: 0285 loss_train: 0.8885 acc_train: 0.8500 loss_val: 1.0769 acc_val: 0.7340 time: 0.0191s\n",
            "3\n",
            "Epoch: 0286 loss_train: 0.9345 acc_train: 0.7750 loss_val: 1.0752 acc_val: 0.7260 time: 0.0190s\n",
            "4\n",
            "Epoch: 0287 loss_train: 0.8881 acc_train: 0.7750 loss_val: 1.0775 acc_val: 0.7240 time: 0.0194s\n",
            "5\n",
            "Epoch: 0288 loss_train: 0.9729 acc_train: 0.8083 loss_val: 1.0796 acc_val: 0.7200 time: 0.0199s\n",
            "6\n",
            "Epoch: 0289 loss_train: 0.9534 acc_train: 0.7750 loss_val: 1.0800 acc_val: 0.7220 time: 0.0189s\n",
            "7\n",
            "Epoch: 0290 loss_train: 0.9453 acc_train: 0.8083 loss_val: 1.0746 acc_val: 0.7360 time: 0.0190s\n",
            "8\n",
            "Epoch: 0291 loss_train: 0.8732 acc_train: 0.7917 loss_val: 1.0697 acc_val: 0.7340 time: 0.0190s\n",
            "9\n",
            "Epoch: 0292 loss_train: 0.9912 acc_train: 0.7500 loss_val: 1.0678 acc_val: 0.7320 time: 0.0186s\n",
            "0\n",
            "Epoch: 0293 loss_train: 0.9121 acc_train: 0.7500 loss_val: 1.0685 acc_val: 0.7280 time: 0.0187s\n",
            "0\n",
            "Epoch: 0294 loss_train: 0.8634 acc_train: 0.8167 loss_val: 1.0702 acc_val: 0.7180 time: 0.0189s\n",
            "1\n",
            "Epoch: 0295 loss_train: 0.9592 acc_train: 0.7417 loss_val: 1.0712 acc_val: 0.7040 time: 0.0189s\n",
            "2\n",
            "Epoch: 0296 loss_train: 0.9124 acc_train: 0.8250 loss_val: 1.0685 acc_val: 0.7000 time: 0.0199s\n",
            "3\n",
            "Epoch: 0297 loss_train: 0.9030 acc_train: 0.7750 loss_val: 1.0648 acc_val: 0.7080 time: 0.0190s\n",
            "4\n",
            "Epoch: 0298 loss_train: 0.9049 acc_train: 0.8000 loss_val: 1.0606 acc_val: 0.7140 time: 0.0189s\n",
            "0\n",
            "Epoch: 0299 loss_train: 0.8640 acc_train: 0.8417 loss_val: 1.0581 acc_val: 0.7180 time: 0.0188s\n",
            "0\n",
            "Epoch: 0300 loss_train: 0.9348 acc_train: 0.7417 loss_val: 1.0613 acc_val: 0.7200 time: 0.0187s\n",
            "0\n",
            "Epoch: 0301 loss_train: 0.9693 acc_train: 0.7250 loss_val: 1.0652 acc_val: 0.7240 time: 0.0190s\n",
            "1\n",
            "Epoch: 0302 loss_train: 0.9203 acc_train: 0.7583 loss_val: 1.0718 acc_val: 0.7240 time: 0.0195s\n",
            "2\n",
            "Epoch: 0303 loss_train: 0.9223 acc_train: 0.8083 loss_val: 1.0702 acc_val: 0.7360 time: 0.0195s\n",
            "3\n",
            "Epoch: 0304 loss_train: 0.8933 acc_train: 0.8000 loss_val: 1.0630 acc_val: 0.7400 time: 0.0197s\n",
            "4\n",
            "Epoch: 0305 loss_train: 0.8593 acc_train: 0.8667 loss_val: 1.0559 acc_val: 0.7300 time: 0.0191s\n",
            "0\n",
            "Epoch: 0306 loss_train: 0.9162 acc_train: 0.7667 loss_val: 1.0505 acc_val: 0.7280 time: 0.0186s\n",
            "0\n",
            "Epoch: 0307 loss_train: 0.8319 acc_train: 0.8000 loss_val: 1.0491 acc_val: 0.7240 time: 0.0187s\n",
            "0\n",
            "Epoch: 0308 loss_train: 0.9229 acc_train: 0.7250 loss_val: 1.0481 acc_val: 0.7200 time: 0.0205s\n",
            "0\n",
            "Epoch: 0309 loss_train: 0.9199 acc_train: 0.7750 loss_val: 1.0510 acc_val: 0.7120 time: 0.0187s\n",
            "0\n",
            "Epoch: 0310 loss_train: 0.8823 acc_train: 0.8167 loss_val: 1.0534 acc_val: 0.7180 time: 0.0190s\n",
            "1\n",
            "Epoch: 0311 loss_train: 0.8954 acc_train: 0.8250 loss_val: 1.0577 acc_val: 0.7060 time: 0.0190s\n",
            "2\n",
            "Epoch: 0312 loss_train: 0.9178 acc_train: 0.8167 loss_val: 1.0626 acc_val: 0.7060 time: 0.0190s\n",
            "3\n",
            "Epoch: 0313 loss_train: 0.9360 acc_train: 0.7833 loss_val: 1.0631 acc_val: 0.7120 time: 0.0186s\n",
            "4\n",
            "Epoch: 0314 loss_train: 0.9003 acc_train: 0.8167 loss_val: 1.0599 acc_val: 0.7140 time: 0.0193s\n",
            "5\n",
            "Epoch: 0315 loss_train: 0.9401 acc_train: 0.7667 loss_val: 1.0512 acc_val: 0.7280 time: 0.0188s\n",
            "6\n",
            "Epoch: 0316 loss_train: 0.8766 acc_train: 0.8083 loss_val: 1.0400 acc_val: 0.7300 time: 0.0189s\n",
            "7\n",
            "Epoch: 0317 loss_train: 0.9380 acc_train: 0.8167 loss_val: 1.0343 acc_val: 0.7380 time: 0.0194s\n",
            "0\n",
            "Epoch: 0318 loss_train: 0.8773 acc_train: 0.7917 loss_val: 1.0290 acc_val: 0.7420 time: 0.0189s\n",
            "0\n",
            "Epoch: 0319 loss_train: 0.9303 acc_train: 0.8083 loss_val: 1.0244 acc_val: 0.7400 time: 0.0188s\n",
            "0\n",
            "Epoch: 0320 loss_train: 0.8545 acc_train: 0.8000 loss_val: 1.0226 acc_val: 0.7340 time: 0.0188s\n",
            "0\n",
            "Epoch: 0321 loss_train: 0.9160 acc_train: 0.7833 loss_val: 1.0245 acc_val: 0.7300 time: 0.0187s\n",
            "0\n",
            "Epoch: 0322 loss_train: 0.9271 acc_train: 0.7833 loss_val: 1.0330 acc_val: 0.7260 time: 0.0189s\n",
            "1\n",
            "Epoch: 0323 loss_train: 0.9081 acc_train: 0.7500 loss_val: 1.0482 acc_val: 0.7120 time: 0.0185s\n",
            "2\n",
            "Epoch: 0324 loss_train: 0.8422 acc_train: 0.8417 loss_val: 1.0595 acc_val: 0.6980 time: 0.0189s\n",
            "3\n",
            "Epoch: 0325 loss_train: 0.8590 acc_train: 0.8250 loss_val: 1.0685 acc_val: 0.6940 time: 0.0204s\n",
            "4\n",
            "Epoch: 0326 loss_train: 0.8874 acc_train: 0.8417 loss_val: 1.0600 acc_val: 0.7020 time: 0.0190s\n",
            "5\n",
            "Epoch: 0327 loss_train: 0.9573 acc_train: 0.7417 loss_val: 1.0419 acc_val: 0.7220 time: 0.0200s\n",
            "6\n",
            "Epoch: 0328 loss_train: 0.8857 acc_train: 0.8167 loss_val: 1.0297 acc_val: 0.7300 time: 0.0191s\n",
            "7\n",
            "Epoch: 0329 loss_train: 0.8438 acc_train: 0.8750 loss_val: 1.0245 acc_val: 0.7420 time: 0.0189s\n",
            "8\n",
            "Epoch: 0330 loss_train: 0.8611 acc_train: 0.8000 loss_val: 1.0232 acc_val: 0.7380 time: 0.0194s\n",
            "0\n",
            "Epoch: 0331 loss_train: 0.8890 acc_train: 0.8083 loss_val: 1.0198 acc_val: 0.7380 time: 0.0190s\n",
            "1\n",
            "Epoch: 0332 loss_train: 0.9577 acc_train: 0.8500 loss_val: 1.0143 acc_val: 0.7440 time: 0.0188s\n",
            "0\n",
            "Epoch: 0333 loss_train: 0.9600 acc_train: 0.7750 loss_val: 1.0146 acc_val: 0.7420 time: 0.0187s\n",
            "0\n",
            "Epoch: 0334 loss_train: 0.8492 acc_train: 0.7917 loss_val: 1.0221 acc_val: 0.7280 time: 0.0195s\n",
            "1\n",
            "Epoch: 0335 loss_train: 0.8956 acc_train: 0.7750 loss_val: 1.0309 acc_val: 0.7220 time: 0.0190s\n",
            "2\n",
            "Epoch: 0336 loss_train: 0.9135 acc_train: 0.7917 loss_val: 1.0434 acc_val: 0.7080 time: 0.0194s\n",
            "3\n",
            "Epoch: 0337 loss_train: 0.9672 acc_train: 0.7417 loss_val: 1.0480 acc_val: 0.7060 time: 0.0190s\n",
            "4\n",
            "Epoch: 0338 loss_train: 1.0175 acc_train: 0.7250 loss_val: 1.0471 acc_val: 0.7120 time: 0.0199s\n",
            "5\n",
            "Epoch: 0339 loss_train: 0.8982 acc_train: 0.8167 loss_val: 1.0414 acc_val: 0.7180 time: 0.0190s\n",
            "6\n",
            "Epoch: 0340 loss_train: 0.8191 acc_train: 0.8750 loss_val: 1.0334 acc_val: 0.7240 time: 0.0189s\n",
            "7\n",
            "Epoch: 0341 loss_train: 0.9580 acc_train: 0.7500 loss_val: 1.0278 acc_val: 0.7280 time: 0.0192s\n",
            "8\n",
            "Epoch: 0342 loss_train: 0.8561 acc_train: 0.8333 loss_val: 1.0223 acc_val: 0.7280 time: 0.0190s\n",
            "9\n",
            "Epoch: 0343 loss_train: 0.8369 acc_train: 0.8083 loss_val: 1.0186 acc_val: 0.7400 time: 0.0185s\n",
            "10\n",
            "Epoch: 0344 loss_train: 0.9138 acc_train: 0.8167 loss_val: 1.0182 acc_val: 0.7360 time: 0.0190s\n",
            "11\n",
            "Epoch: 0345 loss_train: 0.8947 acc_train: 0.7917 loss_val: 1.0164 acc_val: 0.7320 time: 0.0227s\n",
            "12\n",
            "Epoch: 0346 loss_train: 0.8795 acc_train: 0.7917 loss_val: 1.0126 acc_val: 0.7380 time: 0.0201s\n",
            "13\n",
            "Epoch: 0347 loss_train: 0.8453 acc_train: 0.8083 loss_val: 1.0123 acc_val: 0.7360 time: 0.0191s\n",
            "0\n",
            "Epoch: 0348 loss_train: 0.8711 acc_train: 0.8167 loss_val: 1.0175 acc_val: 0.7340 time: 0.0188s\n",
            "0\n",
            "Epoch: 0349 loss_train: 0.9253 acc_train: 0.7500 loss_val: 1.0295 acc_val: 0.7280 time: 0.0193s\n",
            "1\n",
            "Epoch: 0350 loss_train: 0.9128 acc_train: 0.8250 loss_val: 1.0410 acc_val: 0.7180 time: 0.0192s\n",
            "2\n",
            "Epoch: 0351 loss_train: 0.8530 acc_train: 0.8167 loss_val: 1.0422 acc_val: 0.7180 time: 0.0190s\n",
            "3\n",
            "Epoch: 0352 loss_train: 0.8720 acc_train: 0.8083 loss_val: 1.0345 acc_val: 0.7280 time: 0.0189s\n",
            "4\n",
            "Epoch: 0353 loss_train: 0.9182 acc_train: 0.8250 loss_val: 1.0270 acc_val: 0.7260 time: 0.0189s\n",
            "5\n",
            "Epoch: 0354 loss_train: 0.8615 acc_train: 0.8667 loss_val: 1.0225 acc_val: 0.7280 time: 0.0199s\n",
            "6\n",
            "Epoch: 0355 loss_train: 0.9200 acc_train: 0.7417 loss_val: 1.0182 acc_val: 0.7220 time: 0.0191s\n",
            "7\n",
            "Epoch: 0356 loss_train: 0.8967 acc_train: 0.8000 loss_val: 1.0126 acc_val: 0.7280 time: 0.0219s\n",
            "8\n",
            "Epoch: 0357 loss_train: 0.8412 acc_train: 0.8083 loss_val: 1.0041 acc_val: 0.7340 time: 0.0203s\n",
            "9\n",
            "Epoch: 0358 loss_train: 0.8395 acc_train: 0.8250 loss_val: 0.9971 acc_val: 0.7380 time: 0.0190s\n",
            "0\n",
            "Epoch: 0359 loss_train: 0.8978 acc_train: 0.8000 loss_val: 0.9932 acc_val: 0.7360 time: 0.0188s\n",
            "0\n",
            "Epoch: 0360 loss_train: 0.9208 acc_train: 0.7333 loss_val: 0.9933 acc_val: 0.7340 time: 0.0187s\n",
            "0\n",
            "Epoch: 0361 loss_train: 0.8352 acc_train: 0.8833 loss_val: 0.9960 acc_val: 0.7360 time: 0.0191s\n",
            "1\n",
            "Epoch: 0362 loss_train: 0.8666 acc_train: 0.8083 loss_val: 1.0035 acc_val: 0.7320 time: 0.0190s\n",
            "2\n",
            "Epoch: 0363 loss_train: 0.8354 acc_train: 0.7833 loss_val: 1.0124 acc_val: 0.7340 time: 0.0191s\n",
            "3\n",
            "Epoch: 0364 loss_train: 0.9130 acc_train: 0.7833 loss_val: 1.0212 acc_val: 0.7300 time: 0.0190s\n",
            "4\n",
            "Epoch: 0365 loss_train: 0.8280 acc_train: 0.8250 loss_val: 1.0278 acc_val: 0.7200 time: 0.0188s\n",
            "5\n",
            "Epoch: 0366 loss_train: 0.8551 acc_train: 0.8500 loss_val: 1.0281 acc_val: 0.7140 time: 0.0197s\n",
            "6\n",
            "Epoch: 0367 loss_train: 0.8739 acc_train: 0.8250 loss_val: 1.0214 acc_val: 0.7140 time: 0.0189s\n",
            "7\n",
            "Epoch: 0368 loss_train: 0.8936 acc_train: 0.7833 loss_val: 1.0163 acc_val: 0.7140 time: 0.0190s\n",
            "8\n",
            "Epoch: 0369 loss_train: 0.8730 acc_train: 0.8500 loss_val: 1.0111 acc_val: 0.7300 time: 0.0191s\n",
            "9\n",
            "Epoch: 0370 loss_train: 0.8820 acc_train: 0.8083 loss_val: 1.0049 acc_val: 0.7280 time: 0.0189s\n",
            "10\n",
            "Epoch: 0371 loss_train: 0.8080 acc_train: 0.8083 loss_val: 0.9984 acc_val: 0.7340 time: 0.0191s\n",
            "11\n",
            "Epoch: 0372 loss_train: 0.8746 acc_train: 0.7917 loss_val: 0.9934 acc_val: 0.7440 time: 0.0189s\n",
            "12\n",
            "Epoch: 0373 loss_train: 0.7869 acc_train: 0.8250 loss_val: 0.9923 acc_val: 0.7380 time: 0.0190s\n",
            "0\n",
            "Epoch: 0374 loss_train: 0.8230 acc_train: 0.9000 loss_val: 0.9946 acc_val: 0.7380 time: 0.0188s\n",
            "0\n",
            "Epoch: 0375 loss_train: 0.8572 acc_train: 0.8583 loss_val: 0.9998 acc_val: 0.7380 time: 0.0207s\n",
            "1\n",
            "Epoch: 0376 loss_train: 0.8366 acc_train: 0.8833 loss_val: 1.0003 acc_val: 0.7380 time: 0.0190s\n",
            "2\n",
            "Epoch: 0377 loss_train: 0.8659 acc_train: 0.7333 loss_val: 0.9996 acc_val: 0.7380 time: 0.0189s\n",
            "3\n",
            "Epoch: 0378 loss_train: 0.8264 acc_train: 0.8417 loss_val: 1.0003 acc_val: 0.7280 time: 0.0190s\n",
            "4\n",
            "Epoch: 0379 loss_train: 0.7911 acc_train: 0.8083 loss_val: 1.0040 acc_val: 0.7320 time: 0.0190s\n",
            "5\n",
            "Epoch: 0380 loss_train: 0.7906 acc_train: 0.8833 loss_val: 1.0110 acc_val: 0.7240 time: 0.0190s\n",
            "6\n",
            "Epoch: 0381 loss_train: 0.8667 acc_train: 0.7833 loss_val: 1.0164 acc_val: 0.7240 time: 0.0190s\n",
            "7\n",
            "Epoch: 0382 loss_train: 0.7897 acc_train: 0.8333 loss_val: 1.0142 acc_val: 0.7200 time: 0.0190s\n",
            "8\n",
            "Epoch: 0383 loss_train: 0.8932 acc_train: 0.7917 loss_val: 1.0081 acc_val: 0.7200 time: 0.0189s\n",
            "9\n",
            "Epoch: 0384 loss_train: 0.8445 acc_train: 0.8583 loss_val: 1.0003 acc_val: 0.7320 time: 0.0193s\n",
            "10\n",
            "Epoch: 0385 loss_train: 0.8986 acc_train: 0.8000 loss_val: 0.9909 acc_val: 0.7380 time: 0.0201s\n",
            "11\n",
            "Epoch: 0386 loss_train: 0.8438 acc_train: 0.8167 loss_val: 0.9881 acc_val: 0.7420 time: 0.0187s\n",
            "0\n",
            "Epoch: 0387 loss_train: 0.8417 acc_train: 0.8000 loss_val: 0.9870 acc_val: 0.7360 time: 0.0187s\n",
            "0\n",
            "Epoch: 0388 loss_train: 0.8700 acc_train: 0.7917 loss_val: 0.9917 acc_val: 0.7360 time: 0.0186s\n",
            "0\n",
            "Epoch: 0389 loss_train: 0.8868 acc_train: 0.8333 loss_val: 0.9981 acc_val: 0.7340 time: 0.0189s\n",
            "1\n",
            "Epoch: 0390 loss_train: 0.8467 acc_train: 0.8083 loss_val: 0.9983 acc_val: 0.7380 time: 0.0189s\n",
            "2\n",
            "Epoch: 0391 loss_train: 0.8549 acc_train: 0.8083 loss_val: 0.9994 acc_val: 0.7360 time: 0.0190s\n",
            "3\n",
            "Epoch: 0392 loss_train: 0.8359 acc_train: 0.7917 loss_val: 1.0007 acc_val: 0.7360 time: 0.0190s\n",
            "4\n",
            "Epoch: 0393 loss_train: 0.8859 acc_train: 0.8167 loss_val: 1.0000 acc_val: 0.7360 time: 0.0191s\n",
            "5\n",
            "Epoch: 0394 loss_train: 0.8687 acc_train: 0.8000 loss_val: 0.9988 acc_val: 0.7340 time: 0.0190s\n",
            "6\n",
            "Epoch: 0395 loss_train: 0.7856 acc_train: 0.8500 loss_val: 0.9997 acc_val: 0.7260 time: 0.0199s\n",
            "7\n",
            "Epoch: 0396 loss_train: 0.8843 acc_train: 0.8083 loss_val: 0.9975 acc_val: 0.7240 time: 0.0190s\n",
            "8\n",
            "Epoch: 0397 loss_train: 0.8246 acc_train: 0.7750 loss_val: 0.9925 acc_val: 0.7340 time: 0.0190s\n",
            "9\n",
            "Epoch: 0398 loss_train: 0.8367 acc_train: 0.8417 loss_val: 0.9863 acc_val: 0.7380 time: 0.0202s\n",
            "10\n",
            "Epoch: 0399 loss_train: 0.8631 acc_train: 0.8500 loss_val: 0.9820 acc_val: 0.7360 time: 0.0187s\n",
            "0\n",
            "Epoch: 0400 loss_train: 0.7710 acc_train: 0.9083 loss_val: 0.9797 acc_val: 0.7400 time: 0.0195s\n",
            "0\n",
            "Epoch: 0401 loss_train: 0.8359 acc_train: 0.8500 loss_val: 0.9790 acc_val: 0.7440 time: 0.0187s\n",
            "0\n",
            "Epoch: 0402 loss_train: 0.8904 acc_train: 0.7417 loss_val: 0.9819 acc_val: 0.7440 time: 0.0188s\n",
            "0\n",
            "Epoch: 0403 loss_train: 0.8888 acc_train: 0.7917 loss_val: 0.9838 acc_val: 0.7420 time: 0.0189s\n",
            "0\n",
            "Epoch: 0404 loss_train: 0.8734 acc_train: 0.8333 loss_val: 0.9867 acc_val: 0.7400 time: 0.0193s\n",
            "1\n",
            "Epoch: 0405 loss_train: 0.8476 acc_train: 0.8417 loss_val: 0.9869 acc_val: 0.7340 time: 0.0190s\n",
            "2\n",
            "Epoch: 0406 loss_train: 0.8969 acc_train: 0.8083 loss_val: 0.9887 acc_val: 0.7340 time: 0.0189s\n",
            "3\n",
            "Epoch: 0407 loss_train: 0.8790 acc_train: 0.7833 loss_val: 0.9918 acc_val: 0.7280 time: 0.0192s\n",
            "4\n",
            "Epoch: 0408 loss_train: 0.9170 acc_train: 0.8083 loss_val: 0.9918 acc_val: 0.7280 time: 0.0185s\n",
            "5\n",
            "Epoch: 0409 loss_train: 0.8508 acc_train: 0.8083 loss_val: 0.9895 acc_val: 0.7280 time: 0.0189s\n",
            "6\n",
            "Epoch: 0410 loss_train: 0.8819 acc_train: 0.8167 loss_val: 0.9864 acc_val: 0.7280 time: 0.0190s\n",
            "7\n",
            "Epoch: 0411 loss_train: 0.8219 acc_train: 0.8167 loss_val: 0.9854 acc_val: 0.7280 time: 0.0190s\n",
            "8\n",
            "Epoch: 0412 loss_train: 0.8336 acc_train: 0.8000 loss_val: 0.9844 acc_val: 0.7340 time: 0.0189s\n",
            "9\n",
            "Epoch: 0413 loss_train: 0.8009 acc_train: 0.8167 loss_val: 0.9861 acc_val: 0.7220 time: 0.0201s\n",
            "10\n",
            "Epoch: 0414 loss_train: 0.8363 acc_train: 0.8083 loss_val: 0.9858 acc_val: 0.7280 time: 0.0201s\n",
            "11\n",
            "Epoch: 0415 loss_train: 0.8126 acc_train: 0.8083 loss_val: 0.9846 acc_val: 0.7320 time: 0.0188s\n",
            "12\n",
            "Epoch: 0416 loss_train: 0.8651 acc_train: 0.8583 loss_val: 0.9843 acc_val: 0.7300 time: 0.0191s\n",
            "13\n",
            "Epoch: 0417 loss_train: 0.8065 acc_train: 0.8167 loss_val: 0.9835 acc_val: 0.7320 time: 0.0189s\n",
            "14\n",
            "Epoch: 0418 loss_train: 0.7937 acc_train: 0.9000 loss_val: 0.9808 acc_val: 0.7340 time: 0.0190s\n",
            "15\n",
            "Epoch: 0419 loss_train: 0.8540 acc_train: 0.8417 loss_val: 0.9828 acc_val: 0.7240 time: 0.0190s\n",
            "16\n",
            "Epoch: 0420 loss_train: 0.8633 acc_train: 0.7833 loss_val: 0.9839 acc_val: 0.7280 time: 0.0190s\n",
            "17\n",
            "Epoch: 0421 loss_train: 0.8481 acc_train: 0.8583 loss_val: 0.9836 acc_val: 0.7240 time: 0.0188s\n",
            "18\n",
            "Epoch: 0422 loss_train: 0.8160 acc_train: 0.8083 loss_val: 0.9822 acc_val: 0.7240 time: 0.0189s\n",
            "19\n",
            "Epoch: 0423 loss_train: 0.8916 acc_train: 0.7583 loss_val: 0.9843 acc_val: 0.7280 time: 0.0190s\n",
            "20\n",
            "Epoch: 0424 loss_train: 0.8866 acc_train: 0.7667 loss_val: 0.9869 acc_val: 0.7320 time: 0.0198s\n",
            "21\n",
            "Epoch: 0425 loss_train: 0.8711 acc_train: 0.7917 loss_val: 0.9920 acc_val: 0.7300 time: 0.0192s\n",
            "22\n",
            "Epoch: 0426 loss_train: 0.7711 acc_train: 0.8583 loss_val: 0.9917 acc_val: 0.7340 time: 0.0192s\n",
            "23\n",
            "Epoch: 0427 loss_train: 0.8433 acc_train: 0.8167 loss_val: 0.9916 acc_val: 0.7400 time: 0.0191s\n",
            "24\n",
            "Epoch: 0428 loss_train: 0.8189 acc_train: 0.7917 loss_val: 0.9863 acc_val: 0.7360 time: 0.0200s\n",
            "25\n",
            "Epoch: 0429 loss_train: 0.8193 acc_train: 0.8333 loss_val: 0.9798 acc_val: 0.7360 time: 0.0192s\n",
            "26\n",
            "Epoch: 0430 loss_train: 0.8509 acc_train: 0.7917 loss_val: 0.9771 acc_val: 0.7300 time: 0.0192s\n",
            "27\n",
            "Epoch: 0431 loss_train: 0.7834 acc_train: 0.8500 loss_val: 0.9768 acc_val: 0.7300 time: 0.0188s\n",
            "0\n",
            "Epoch: 0432 loss_train: 0.8010 acc_train: 0.8250 loss_val: 0.9775 acc_val: 0.7220 time: 0.0186s\n",
            "0\n",
            "Epoch: 0433 loss_train: 0.8206 acc_train: 0.8667 loss_val: 0.9776 acc_val: 0.7200 time: 0.0187s\n",
            "1\n",
            "Epoch: 0434 loss_train: 0.8298 acc_train: 0.8083 loss_val: 0.9786 acc_val: 0.7220 time: 0.0206s\n",
            "2\n",
            "Epoch: 0435 loss_train: 0.8586 acc_train: 0.8417 loss_val: 0.9827 acc_val: 0.7220 time: 0.0195s\n",
            "3\n",
            "Epoch: 0436 loss_train: 0.8019 acc_train: 0.8250 loss_val: 0.9905 acc_val: 0.7220 time: 0.0196s\n",
            "4\n",
            "Epoch: 0437 loss_train: 0.7821 acc_train: 0.8417 loss_val: 0.9945 acc_val: 0.7300 time: 0.0193s\n",
            "5\n",
            "Epoch: 0438 loss_train: 0.8377 acc_train: 0.8000 loss_val: 0.9960 acc_val: 0.7340 time: 0.0190s\n",
            "6\n",
            "Epoch: 0439 loss_train: 0.8444 acc_train: 0.8417 loss_val: 0.9944 acc_val: 0.7340 time: 0.0190s\n",
            "7\n",
            "Epoch: 0440 loss_train: 0.8629 acc_train: 0.8750 loss_val: 0.9840 acc_val: 0.7360 time: 0.0189s\n",
            "8\n",
            "Epoch: 0441 loss_train: 0.8536 acc_train: 0.8250 loss_val: 0.9739 acc_val: 0.7380 time: 0.0198s\n",
            "9\n",
            "Epoch: 0442 loss_train: 0.8416 acc_train: 0.8250 loss_val: 0.9675 acc_val: 0.7380 time: 0.0191s\n",
            "0\n",
            "Epoch: 0443 loss_train: 0.7698 acc_train: 0.8167 loss_val: 0.9649 acc_val: 0.7420 time: 0.0188s\n",
            "0\n",
            "Epoch: 0444 loss_train: 0.8428 acc_train: 0.7833 loss_val: 0.9668 acc_val: 0.7360 time: 0.0189s\n",
            "0\n",
            "Epoch: 0445 loss_train: 0.8493 acc_train: 0.8083 loss_val: 0.9728 acc_val: 0.7360 time: 0.0190s\n",
            "1\n",
            "Epoch: 0446 loss_train: 0.8139 acc_train: 0.8667 loss_val: 0.9796 acc_val: 0.7280 time: 0.0192s\n",
            "2\n",
            "Epoch: 0447 loss_train: 0.8299 acc_train: 0.8167 loss_val: 0.9873 acc_val: 0.7180 time: 0.0191s\n",
            "3\n",
            "Epoch: 0448 loss_train: 0.8826 acc_train: 0.8000 loss_val: 0.9907 acc_val: 0.7180 time: 0.0190s\n",
            "4\n",
            "Epoch: 0449 loss_train: 0.7746 acc_train: 0.8333 loss_val: 0.9913 acc_val: 0.7220 time: 0.0189s\n",
            "5\n",
            "Epoch: 0450 loss_train: 0.7963 acc_train: 0.8250 loss_val: 0.9894 acc_val: 0.7260 time: 0.0185s\n",
            "6\n",
            "Epoch: 0451 loss_train: 0.8474 acc_train: 0.8250 loss_val: 0.9840 acc_val: 0.7300 time: 0.0190s\n",
            "7\n",
            "Epoch: 0452 loss_train: 0.8099 acc_train: 0.8000 loss_val: 0.9769 acc_val: 0.7340 time: 0.0189s\n",
            "8\n",
            "Epoch: 0453 loss_train: 0.8807 acc_train: 0.7917 loss_val: 0.9722 acc_val: 0.7360 time: 0.0191s\n",
            "9\n",
            "Epoch: 0454 loss_train: 0.7952 acc_train: 0.8667 loss_val: 0.9707 acc_val: 0.7400 time: 0.0214s\n",
            "10\n",
            "Epoch: 0455 loss_train: 0.8643 acc_train: 0.8083 loss_val: 0.9698 acc_val: 0.7420 time: 0.0189s\n",
            "11\n",
            "Epoch: 0456 loss_train: 0.8315 acc_train: 0.8083 loss_val: 0.9699 acc_val: 0.7320 time: 0.0190s\n",
            "12\n",
            "Epoch: 0457 loss_train: 0.7806 acc_train: 0.8667 loss_val: 0.9712 acc_val: 0.7320 time: 0.0190s\n",
            "13\n",
            "Epoch: 0458 loss_train: 0.7838 acc_train: 0.8083 loss_val: 0.9695 acc_val: 0.7380 time: 0.0189s\n",
            "14\n",
            "Epoch: 0459 loss_train: 0.7887 acc_train: 0.8083 loss_val: 0.9692 acc_val: 0.7440 time: 0.0194s\n",
            "15\n",
            "Epoch: 0460 loss_train: 0.8049 acc_train: 0.8500 loss_val: 0.9683 acc_val: 0.7340 time: 0.0208s\n",
            "0\n",
            "Epoch: 0461 loss_train: 0.8389 acc_train: 0.8000 loss_val: 0.9679 acc_val: 0.7340 time: 0.0191s\n",
            "1\n",
            "Epoch: 0462 loss_train: 0.8547 acc_train: 0.8167 loss_val: 0.9696 acc_val: 0.7320 time: 0.0196s\n",
            "2\n",
            "Epoch: 0463 loss_train: 0.9019 acc_train: 0.8083 loss_val: 0.9705 acc_val: 0.7340 time: 0.0195s\n",
            "3\n",
            "Epoch: 0464 loss_train: 0.8503 acc_train: 0.7833 loss_val: 0.9687 acc_val: 0.7360 time: 0.0203s\n",
            "4\n",
            "Epoch: 0465 loss_train: 0.8391 acc_train: 0.8583 loss_val: 0.9686 acc_val: 0.7420 time: 0.0191s\n",
            "5\n",
            "Epoch: 0466 loss_train: 0.8074 acc_train: 0.8000 loss_val: 0.9716 acc_val: 0.7380 time: 0.0220s\n",
            "6\n",
            "Epoch: 0467 loss_train: 0.7467 acc_train: 0.8833 loss_val: 0.9754 acc_val: 0.7360 time: 0.0189s\n",
            "7\n",
            "Epoch: 0468 loss_train: 0.8726 acc_train: 0.8167 loss_val: 0.9816 acc_val: 0.7220 time: 0.0194s\n",
            "8\n",
            "Epoch: 0469 loss_train: 0.8693 acc_train: 0.7583 loss_val: 0.9821 acc_val: 0.7160 time: 0.0190s\n",
            "9\n",
            "Epoch: 0470 loss_train: 0.8150 acc_train: 0.8083 loss_val: 0.9794 acc_val: 0.7160 time: 0.0190s\n",
            "10\n",
            "Epoch: 0471 loss_train: 0.8442 acc_train: 0.7583 loss_val: 0.9742 acc_val: 0.7200 time: 0.0190s\n",
            "11\n",
            "Epoch: 0472 loss_train: 0.8993 acc_train: 0.7917 loss_val: 0.9677 acc_val: 0.7280 time: 0.0190s\n",
            "12\n",
            "Epoch: 0473 loss_train: 0.8765 acc_train: 0.8417 loss_val: 0.9628 acc_val: 0.7380 time: 0.0196s\n",
            "13\n",
            "Epoch: 0474 loss_train: 0.8696 acc_train: 0.8667 loss_val: 0.9619 acc_val: 0.7400 time: 0.0186s\n",
            "0\n",
            "Epoch: 0475 loss_train: 0.8262 acc_train: 0.8083 loss_val: 0.9645 acc_val: 0.7420 time: 0.0187s\n",
            "0\n",
            "Epoch: 0476 loss_train: 0.8825 acc_train: 0.7500 loss_val: 0.9679 acc_val: 0.7340 time: 0.0189s\n",
            "1\n",
            "Epoch: 0477 loss_train: 0.8482 acc_train: 0.8000 loss_val: 0.9737 acc_val: 0.7320 time: 0.0188s\n",
            "2\n",
            "Epoch: 0478 loss_train: 0.8314 acc_train: 0.8333 loss_val: 0.9790 acc_val: 0.7300 time: 0.0189s\n",
            "3\n",
            "Epoch: 0479 loss_train: 0.8673 acc_train: 0.8500 loss_val: 0.9820 acc_val: 0.7160 time: 0.0219s\n",
            "4\n",
            "Epoch: 0480 loss_train: 0.9058 acc_train: 0.8000 loss_val: 0.9826 acc_val: 0.7120 time: 0.0196s\n",
            "5\n",
            "Epoch: 0481 loss_train: 0.8818 acc_train: 0.8417 loss_val: 0.9794 acc_val: 0.7120 time: 0.0189s\n",
            "6\n",
            "Epoch: 0482 loss_train: 0.8483 acc_train: 0.8167 loss_val: 0.9767 acc_val: 0.7200 time: 0.0196s\n",
            "7\n",
            "Epoch: 0483 loss_train: 0.8301 acc_train: 0.8333 loss_val: 0.9717 acc_val: 0.7240 time: 0.0198s\n",
            "8\n",
            "Epoch: 0484 loss_train: 0.8014 acc_train: 0.8250 loss_val: 0.9720 acc_val: 0.7260 time: 0.0189s\n",
            "9\n",
            "Epoch: 0485 loss_train: 0.7499 acc_train: 0.8667 loss_val: 0.9748 acc_val: 0.7260 time: 0.0192s\n",
            "10\n",
            "Epoch: 0486 loss_train: 0.7807 acc_train: 0.8417 loss_val: 0.9753 acc_val: 0.7260 time: 0.0189s\n",
            "11\n",
            "Epoch: 0487 loss_train: 0.8645 acc_train: 0.7750 loss_val: 0.9718 acc_val: 0.7300 time: 0.0188s\n",
            "12\n",
            "Epoch: 0488 loss_train: 0.8567 acc_train: 0.8000 loss_val: 0.9658 acc_val: 0.7280 time: 0.0189s\n",
            "13\n",
            "Epoch: 0489 loss_train: 0.8048 acc_train: 0.8500 loss_val: 0.9613 acc_val: 0.7280 time: 0.0205s\n",
            "14\n",
            "Epoch: 0490 loss_train: 0.7908 acc_train: 0.8000 loss_val: 0.9585 acc_val: 0.7280 time: 0.0187s\n",
            "0\n",
            "Epoch: 0491 loss_train: 0.7758 acc_train: 0.8250 loss_val: 0.9579 acc_val: 0.7220 time: 0.0186s\n",
            "0\n",
            "Epoch: 0492 loss_train: 0.8141 acc_train: 0.8333 loss_val: 0.9605 acc_val: 0.7180 time: 0.0187s\n",
            "0\n",
            "Epoch: 0493 loss_train: 0.8684 acc_train: 0.7833 loss_val: 0.9640 acc_val: 0.7100 time: 0.0212s\n",
            "1\n",
            "Epoch: 0494 loss_train: 0.8346 acc_train: 0.8333 loss_val: 0.9668 acc_val: 0.7180 time: 0.0200s\n",
            "2\n",
            "Epoch: 0495 loss_train: 0.7994 acc_train: 0.8333 loss_val: 0.9680 acc_val: 0.7160 time: 0.0191s\n",
            "3\n",
            "Epoch: 0496 loss_train: 0.8302 acc_train: 0.8417 loss_val: 0.9648 acc_val: 0.7280 time: 0.0204s\n",
            "4\n",
            "Epoch: 0497 loss_train: 0.8659 acc_train: 0.8250 loss_val: 0.9616 acc_val: 0.7280 time: 0.0193s\n",
            "5\n",
            "Epoch: 0498 loss_train: 0.8086 acc_train: 0.8083 loss_val: 0.9581 acc_val: 0.7260 time: 0.0189s\n",
            "6\n",
            "Epoch: 0499 loss_train: 0.7802 acc_train: 0.8833 loss_val: 0.9543 acc_val: 0.7380 time: 0.0192s\n",
            "7\n",
            "Epoch: 0500 loss_train: 0.7776 acc_train: 0.7583 loss_val: 0.9541 acc_val: 0.7380 time: 0.0187s\n",
            "0\n",
            "Epoch: 0501 loss_train: 0.7952 acc_train: 0.8000 loss_val: 0.9546 acc_val: 0.7280 time: 0.0187s\n",
            "0\n",
            "Epoch: 0502 loss_train: 0.7798 acc_train: 0.8833 loss_val: 0.9583 acc_val: 0.7240 time: 0.0191s\n",
            "1\n",
            "Epoch: 0503 loss_train: 0.8322 acc_train: 0.8000 loss_val: 0.9590 acc_val: 0.7260 time: 0.0189s\n",
            "2\n",
            "Epoch: 0504 loss_train: 0.8518 acc_train: 0.8333 loss_val: 0.9580 acc_val: 0.7240 time: 0.0190s\n",
            "3\n",
            "Epoch: 0505 loss_train: 0.8086 acc_train: 0.8333 loss_val: 0.9588 acc_val: 0.7260 time: 0.0192s\n",
            "4\n",
            "Epoch: 0506 loss_train: 0.8306 acc_train: 0.8583 loss_val: 0.9592 acc_val: 0.7300 time: 0.0190s\n",
            "5\n",
            "Epoch: 0507 loss_train: 0.8328 acc_train: 0.7833 loss_val: 0.9614 acc_val: 0.7300 time: 0.0191s\n",
            "6\n",
            "Epoch: 0508 loss_train: 0.8833 acc_train: 0.8000 loss_val: 0.9659 acc_val: 0.7240 time: 0.0189s\n",
            "7\n",
            "Epoch: 0509 loss_train: 0.7979 acc_train: 0.8750 loss_val: 0.9663 acc_val: 0.7240 time: 0.0190s\n",
            "8\n",
            "Epoch: 0510 loss_train: 0.8013 acc_train: 0.8333 loss_val: 0.9642 acc_val: 0.7220 time: 0.0190s\n",
            "9\n",
            "Epoch: 0511 loss_train: 0.7271 acc_train: 0.8750 loss_val: 0.9599 acc_val: 0.7240 time: 0.0189s\n",
            "10\n",
            "Epoch: 0512 loss_train: 0.7871 acc_train: 0.8000 loss_val: 0.9554 acc_val: 0.7260 time: 0.0191s\n",
            "11\n",
            "Epoch: 0513 loss_train: 0.7826 acc_train: 0.8167 loss_val: 0.9514 acc_val: 0.7280 time: 0.0212s\n",
            "12\n",
            "Epoch: 0514 loss_train: 0.7833 acc_train: 0.8500 loss_val: 0.9519 acc_val: 0.7320 time: 0.0186s\n",
            "0\n",
            "Epoch: 0515 loss_train: 0.8367 acc_train: 0.8250 loss_val: 0.9578 acc_val: 0.7380 time: 0.0190s\n",
            "1\n",
            "Epoch: 0516 loss_train: 0.8110 acc_train: 0.8667 loss_val: 0.9629 acc_val: 0.7340 time: 0.0189s\n",
            "2\n",
            "Epoch: 0517 loss_train: 0.8337 acc_train: 0.8333 loss_val: 0.9659 acc_val: 0.7320 time: 0.0189s\n",
            "3\n",
            "Epoch: 0518 loss_train: 0.8301 acc_train: 0.7833 loss_val: 0.9638 acc_val: 0.7280 time: 0.0188s\n",
            "4\n",
            "Epoch: 0519 loss_train: 0.8335 acc_train: 0.7833 loss_val: 0.9605 acc_val: 0.7200 time: 0.0189s\n",
            "5\n",
            "Epoch: 0520 loss_train: 0.7968 acc_train: 0.7750 loss_val: 0.9619 acc_val: 0.7140 time: 0.0189s\n",
            "6\n",
            "Epoch: 0521 loss_train: 0.7727 acc_train: 0.8167 loss_val: 0.9616 acc_val: 0.7140 time: 0.0190s\n",
            "7\n",
            "Epoch: 0522 loss_train: 0.8584 acc_train: 0.8000 loss_val: 0.9616 acc_val: 0.7160 time: 0.0197s\n",
            "8\n",
            "Epoch: 0523 loss_train: 0.6603 acc_train: 0.8833 loss_val: 0.9578 acc_val: 0.7200 time: 0.0189s\n",
            "9\n",
            "Epoch: 0524 loss_train: 0.7999 acc_train: 0.8417 loss_val: 0.9551 acc_val: 0.7240 time: 0.0188s\n",
            "10\n",
            "Epoch: 0525 loss_train: 0.7888 acc_train: 0.7667 loss_val: 0.9553 acc_val: 0.7320 time: 0.0199s\n",
            "11\n",
            "Epoch: 0526 loss_train: 0.7510 acc_train: 0.8667 loss_val: 0.9570 acc_val: 0.7340 time: 0.0189s\n",
            "12\n",
            "Epoch: 0527 loss_train: 0.7679 acc_train: 0.8333 loss_val: 0.9594 acc_val: 0.7320 time: 0.0189s\n",
            "13\n",
            "Epoch: 0528 loss_train: 0.8252 acc_train: 0.8000 loss_val: 0.9621 acc_val: 0.7320 time: 0.0189s\n",
            "14\n",
            "Epoch: 0529 loss_train: 0.8639 acc_train: 0.8167 loss_val: 0.9638 acc_val: 0.7340 time: 0.0186s\n",
            "15\n",
            "Epoch: 0530 loss_train: 0.7991 acc_train: 0.8750 loss_val: 0.9608 acc_val: 0.7400 time: 0.0189s\n",
            "16\n",
            "Epoch: 0531 loss_train: 0.7600 acc_train: 0.9083 loss_val: 0.9562 acc_val: 0.7360 time: 0.0193s\n",
            "17\n",
            "Epoch: 0532 loss_train: 0.7687 acc_train: 0.8583 loss_val: 0.9529 acc_val: 0.7360 time: 0.0193s\n",
            "18\n",
            "Epoch: 0533 loss_train: 0.8428 acc_train: 0.8417 loss_val: 0.9524 acc_val: 0.7340 time: 0.0191s\n",
            "19\n",
            "Epoch: 0534 loss_train: 0.7627 acc_train: 0.8500 loss_val: 0.9506 acc_val: 0.7400 time: 0.0192s\n",
            "20\n",
            "Epoch: 0535 loss_train: 0.8457 acc_train: 0.7833 loss_val: 0.9482 acc_val: 0.7420 time: 0.0189s\n",
            "0\n",
            "Epoch: 0536 loss_train: 0.7472 acc_train: 0.8417 loss_val: 0.9446 acc_val: 0.7380 time: 0.0187s\n",
            "0\n",
            "Epoch: 0537 loss_train: 0.8492 acc_train: 0.8417 loss_val: 0.9418 acc_val: 0.7400 time: 0.0209s\n",
            "0\n",
            "Epoch: 0538 loss_train: 0.8307 acc_train: 0.8417 loss_val: 0.9406 acc_val: 0.7420 time: 0.0187s\n",
            "0\n",
            "Epoch: 0539 loss_train: 0.8830 acc_train: 0.8083 loss_val: 0.9400 acc_val: 0.7400 time: 0.0189s\n",
            "0\n",
            "Epoch: 0540 loss_train: 0.8815 acc_train: 0.8083 loss_val: 0.9427 acc_val: 0.7340 time: 0.0192s\n",
            "0\n",
            "Epoch: 0541 loss_train: 0.7630 acc_train: 0.8833 loss_val: 0.9524 acc_val: 0.7340 time: 0.0219s\n",
            "1\n",
            "Epoch: 0542 loss_train: 0.8569 acc_train: 0.8333 loss_val: 0.9642 acc_val: 0.7280 time: 0.0209s\n",
            "2\n",
            "Epoch: 0543 loss_train: 0.7570 acc_train: 0.8417 loss_val: 0.9739 acc_val: 0.7280 time: 0.0195s\n",
            "3\n",
            "Epoch: 0544 loss_train: 0.7226 acc_train: 0.8417 loss_val: 0.9771 acc_val: 0.7240 time: 0.0189s\n",
            "4\n",
            "Epoch: 0545 loss_train: 0.7980 acc_train: 0.8083 loss_val: 0.9765 acc_val: 0.7280 time: 0.0196s\n",
            "5\n",
            "Epoch: 0546 loss_train: 0.8010 acc_train: 0.8500 loss_val: 0.9693 acc_val: 0.7300 time: 0.0190s\n",
            "6\n",
            "Epoch: 0547 loss_train: 0.7666 acc_train: 0.8333 loss_val: 0.9603 acc_val: 0.7280 time: 0.0189s\n",
            "7\n",
            "Epoch: 0548 loss_train: 0.8613 acc_train: 0.8250 loss_val: 0.9533 acc_val: 0.7340 time: 0.0190s\n",
            "8\n",
            "Epoch: 0549 loss_train: 0.8022 acc_train: 0.8500 loss_val: 0.9498 acc_val: 0.7360 time: 0.0193s\n",
            "9\n",
            "Epoch: 0550 loss_train: 0.7870 acc_train: 0.8750 loss_val: 0.9469 acc_val: 0.7420 time: 0.0189s\n",
            "10\n",
            "Epoch: 0551 loss_train: 0.7994 acc_train: 0.8250 loss_val: 0.9468 acc_val: 0.7360 time: 0.0194s\n",
            "11\n",
            "Epoch: 0552 loss_train: 0.8519 acc_train: 0.8250 loss_val: 0.9535 acc_val: 0.7300 time: 0.0191s\n",
            "12\n",
            "Epoch: 0553 loss_train: 0.8261 acc_train: 0.8083 loss_val: 0.9621 acc_val: 0.7140 time: 0.0191s\n",
            "13\n",
            "Epoch: 0554 loss_train: 0.7984 acc_train: 0.7750 loss_val: 0.9671 acc_val: 0.7120 time: 0.0193s\n",
            "14\n",
            "Epoch: 0555 loss_train: 0.7996 acc_train: 0.8083 loss_val: 0.9684 acc_val: 0.7180 time: 0.0189s\n",
            "15\n",
            "Epoch: 0556 loss_train: 0.8578 acc_train: 0.8667 loss_val: 0.9692 acc_val: 0.7260 time: 0.0190s\n",
            "16\n",
            "Epoch: 0557 loss_train: 0.8335 acc_train: 0.8333 loss_val: 0.9627 acc_val: 0.7340 time: 0.0190s\n",
            "17\n",
            "Epoch: 0558 loss_train: 0.7806 acc_train: 0.8417 loss_val: 0.9521 acc_val: 0.7400 time: 0.0189s\n",
            "18\n",
            "Epoch: 0559 loss_train: 0.7640 acc_train: 0.8167 loss_val: 0.9472 acc_val: 0.7380 time: 0.0189s\n",
            "19\n",
            "Epoch: 0560 loss_train: 0.8535 acc_train: 0.8000 loss_val: 0.9463 acc_val: 0.7360 time: 0.0190s\n",
            "20\n",
            "Epoch: 0561 loss_train: 0.8379 acc_train: 0.8667 loss_val: 0.9485 acc_val: 0.7320 time: 0.0197s\n",
            "21\n",
            "Epoch: 0562 loss_train: 0.8167 acc_train: 0.8167 loss_val: 0.9537 acc_val: 0.7320 time: 0.0189s\n",
            "22\n",
            "Epoch: 0563 loss_train: 0.8416 acc_train: 0.8083 loss_val: 0.9584 acc_val: 0.7260 time: 0.0191s\n",
            "23\n",
            "Epoch: 0564 loss_train: 0.7934 acc_train: 0.8417 loss_val: 0.9615 acc_val: 0.7300 time: 0.0189s\n",
            "24\n",
            "Epoch: 0565 loss_train: 0.8198 acc_train: 0.8750 loss_val: 0.9621 acc_val: 0.7260 time: 0.0189s\n",
            "25\n",
            "Epoch: 0566 loss_train: 0.7655 acc_train: 0.8750 loss_val: 0.9607 acc_val: 0.7280 time: 0.0189s\n",
            "26\n",
            "Epoch: 0567 loss_train: 0.7782 acc_train: 0.8500 loss_val: 0.9555 acc_val: 0.7340 time: 0.0192s\n",
            "27\n",
            "Epoch: 0568 loss_train: 0.7520 acc_train: 0.8833 loss_val: 0.9491 acc_val: 0.7420 time: 0.0192s\n",
            "28\n",
            "Epoch: 0569 loss_train: 0.8516 acc_train: 0.8083 loss_val: 0.9425 acc_val: 0.7460 time: 0.0189s\n",
            "29\n",
            "Epoch: 0570 loss_train: 0.8166 acc_train: 0.8250 loss_val: 0.9402 acc_val: 0.7400 time: 0.0202s\n",
            "0\n",
            "Epoch: 0571 loss_train: 0.8310 acc_train: 0.7833 loss_val: 0.9428 acc_val: 0.7340 time: 0.0192s\n",
            "1\n",
            "Epoch: 0572 loss_train: 0.8101 acc_train: 0.8500 loss_val: 0.9493 acc_val: 0.7300 time: 0.0189s\n",
            "2\n",
            "Epoch: 0573 loss_train: 0.7979 acc_train: 0.8333 loss_val: 0.9534 acc_val: 0.7240 time: 0.0189s\n",
            "3\n",
            "Epoch: 0574 loss_train: 0.7356 acc_train: 0.9000 loss_val: 0.9558 acc_val: 0.7340 time: 0.0188s\n",
            "4\n",
            "Epoch: 0575 loss_train: 0.8120 acc_train: 0.7583 loss_val: 0.9559 acc_val: 0.7340 time: 0.0192s\n",
            "5\n",
            "Epoch: 0576 loss_train: 0.8369 acc_train: 0.8083 loss_val: 0.9563 acc_val: 0.7380 time: 0.0191s\n",
            "6\n",
            "Epoch: 0577 loss_train: 0.8016 acc_train: 0.8583 loss_val: 0.9562 acc_val: 0.7420 time: 0.0193s\n",
            "7\n",
            "Epoch: 0578 loss_train: 0.7525 acc_train: 0.8417 loss_val: 0.9528 acc_val: 0.7420 time: 0.0189s\n",
            "8\n",
            "Epoch: 0579 loss_train: 0.7679 acc_train: 0.8750 loss_val: 0.9522 acc_val: 0.7380 time: 0.0189s\n",
            "9\n",
            "Epoch: 0580 loss_train: 0.7674 acc_train: 0.8417 loss_val: 0.9504 acc_val: 0.7380 time: 0.0195s\n",
            "10\n",
            "Epoch: 0581 loss_train: 0.8057 acc_train: 0.8917 loss_val: 0.9463 acc_val: 0.7420 time: 0.0197s\n",
            "11\n",
            "Epoch: 0582 loss_train: 0.8411 acc_train: 0.8083 loss_val: 0.9434 acc_val: 0.7380 time: 0.0190s\n",
            "12\n",
            "Epoch: 0583 loss_train: 0.8238 acc_train: 0.8500 loss_val: 0.9474 acc_val: 0.7300 time: 0.0189s\n",
            "13\n",
            "Epoch: 0584 loss_train: 0.8217 acc_train: 0.8917 loss_val: 0.9539 acc_val: 0.7260 time: 0.0189s\n",
            "14\n",
            "Epoch: 0585 loss_train: 0.7731 acc_train: 0.8500 loss_val: 0.9588 acc_val: 0.7220 time: 0.0189s\n",
            "15\n",
            "Epoch: 0586 loss_train: 0.7666 acc_train: 0.8667 loss_val: 0.9610 acc_val: 0.7240 time: 0.0201s\n",
            "16\n",
            "Epoch: 0587 loss_train: 0.7753 acc_train: 0.8667 loss_val: 0.9600 acc_val: 0.7220 time: 0.0244s\n",
            "17\n",
            "Epoch: 0588 loss_train: 0.7693 acc_train: 0.8583 loss_val: 0.9566 acc_val: 0.7280 time: 0.0189s\n",
            "18\n",
            "Epoch: 0589 loss_train: 0.8356 acc_train: 0.8417 loss_val: 0.9522 acc_val: 0.7300 time: 0.0196s\n",
            "19\n",
            "Epoch: 0590 loss_train: 0.8495 acc_train: 0.8250 loss_val: 0.9516 acc_val: 0.7320 time: 0.0214s\n",
            "20\n",
            "Epoch: 0591 loss_train: 0.8090 acc_train: 0.8167 loss_val: 0.9524 acc_val: 0.7380 time: 0.0194s\n",
            "21\n",
            "Epoch: 0592 loss_train: 0.8028 acc_train: 0.8417 loss_val: 0.9544 acc_val: 0.7360 time: 0.0190s\n",
            "22\n",
            "Epoch: 0593 loss_train: 0.7775 acc_train: 0.8083 loss_val: 0.9529 acc_val: 0.7360 time: 0.0189s\n",
            "23\n",
            "Epoch: 0594 loss_train: 0.7576 acc_train: 0.8833 loss_val: 0.9506 acc_val: 0.7360 time: 0.0195s\n",
            "24\n",
            "Epoch: 0595 loss_train: 0.7783 acc_train: 0.7833 loss_val: 0.9453 acc_val: 0.7340 time: 0.0189s\n",
            "25\n",
            "Epoch: 0596 loss_train: 0.8015 acc_train: 0.8500 loss_val: 0.9422 acc_val: 0.7340 time: 0.0188s\n",
            "26\n",
            "Epoch: 0597 loss_train: 0.7264 acc_train: 0.8667 loss_val: 0.9390 acc_val: 0.7340 time: 0.0193s\n",
            "27\n",
            "Epoch: 0598 loss_train: 0.8218 acc_train: 0.7917 loss_val: 0.9404 acc_val: 0.7300 time: 0.0186s\n",
            "0\n",
            "Epoch: 0599 loss_train: 0.7901 acc_train: 0.7917 loss_val: 0.9405 acc_val: 0.7360 time: 0.0196s\n",
            "1\n",
            "Epoch: 0600 loss_train: 0.6825 acc_train: 0.8833 loss_val: 0.9427 acc_val: 0.7300 time: 0.0185s\n",
            "2\n",
            "Epoch: 0601 loss_train: 0.8126 acc_train: 0.8500 loss_val: 0.9496 acc_val: 0.7320 time: 0.0207s\n",
            "3\n",
            "Epoch: 0602 loss_train: 0.8113 acc_train: 0.8167 loss_val: 0.9568 acc_val: 0.7380 time: 0.0199s\n",
            "4\n",
            "Epoch: 0603 loss_train: 0.8185 acc_train: 0.8500 loss_val: 0.9583 acc_val: 0.7380 time: 0.0189s\n",
            "5\n",
            "Epoch: 0604 loss_train: 0.7116 acc_train: 0.8417 loss_val: 0.9567 acc_val: 0.7380 time: 0.0189s\n",
            "6\n",
            "Epoch: 0605 loss_train: 0.8019 acc_train: 0.8250 loss_val: 0.9545 acc_val: 0.7360 time: 0.0216s\n",
            "7\n",
            "Epoch: 0606 loss_train: 0.7663 acc_train: 0.8333 loss_val: 0.9462 acc_val: 0.7380 time: 0.0189s\n",
            "8\n",
            "Epoch: 0607 loss_train: 0.7860 acc_train: 0.8583 loss_val: 0.9398 acc_val: 0.7360 time: 0.0190s\n",
            "9\n",
            "Epoch: 0608 loss_train: 0.7616 acc_train: 0.8417 loss_val: 0.9359 acc_val: 0.7400 time: 0.0189s\n",
            "10\n",
            "Epoch: 0609 loss_train: 0.7862 acc_train: 0.7833 loss_val: 0.9363 acc_val: 0.7360 time: 0.0186s\n",
            "0\n",
            "Epoch: 0610 loss_train: 0.8576 acc_train: 0.8417 loss_val: 0.9417 acc_val: 0.7360 time: 0.0186s\n",
            "1\n",
            "Epoch: 0611 loss_train: 0.7941 acc_train: 0.8167 loss_val: 0.9475 acc_val: 0.7280 time: 0.0200s\n",
            "2\n",
            "Epoch: 0612 loss_train: 0.8416 acc_train: 0.7833 loss_val: 0.9557 acc_val: 0.7260 time: 0.0199s\n",
            "3\n",
            "Epoch: 0613 loss_train: 0.7792 acc_train: 0.8667 loss_val: 0.9654 acc_val: 0.7300 time: 0.0198s\n",
            "4\n",
            "Epoch: 0614 loss_train: 0.8413 acc_train: 0.8417 loss_val: 0.9685 acc_val: 0.7300 time: 0.0191s\n",
            "5\n",
            "Epoch: 0615 loss_train: 0.8528 acc_train: 0.7833 loss_val: 0.9644 acc_val: 0.7320 time: 0.0199s\n",
            "6\n",
            "Epoch: 0616 loss_train: 0.7838 acc_train: 0.8500 loss_val: 0.9568 acc_val: 0.7400 time: 0.0193s\n",
            "7\n",
            "Epoch: 0617 loss_train: 0.7898 acc_train: 0.8083 loss_val: 0.9529 acc_val: 0.7320 time: 0.0197s\n",
            "8\n",
            "Epoch: 0618 loss_train: 0.7863 acc_train: 0.8417 loss_val: 0.9510 acc_val: 0.7360 time: 0.0191s\n",
            "9\n",
            "Epoch: 0619 loss_train: 0.8062 acc_train: 0.8417 loss_val: 0.9464 acc_val: 0.7320 time: 0.0188s\n",
            "10\n",
            "Epoch: 0620 loss_train: 0.8112 acc_train: 0.8333 loss_val: 0.9425 acc_val: 0.7320 time: 0.0192s\n",
            "11\n",
            "Epoch: 0621 loss_train: 0.8066 acc_train: 0.8833 loss_val: 0.9409 acc_val: 0.7400 time: 0.0216s\n",
            "12\n",
            "Epoch: 0622 loss_train: 0.7997 acc_train: 0.8583 loss_val: 0.9400 acc_val: 0.7280 time: 0.0190s\n",
            "13\n",
            "Epoch: 0623 loss_train: 0.7690 acc_train: 0.8000 loss_val: 0.9401 acc_val: 0.7340 time: 0.0189s\n",
            "14\n",
            "Epoch: 0624 loss_train: 0.8263 acc_train: 0.8000 loss_val: 0.9407 acc_val: 0.7380 time: 0.0195s\n",
            "15\n",
            "Epoch: 0625 loss_train: 0.8429 acc_train: 0.8333 loss_val: 0.9389 acc_val: 0.7360 time: 0.0194s\n",
            "16\n",
            "Epoch: 0626 loss_train: 0.8377 acc_train: 0.8417 loss_val: 0.9413 acc_val: 0.7380 time: 0.0191s\n",
            "17\n",
            "Epoch: 0627 loss_train: 0.8162 acc_train: 0.8667 loss_val: 0.9444 acc_val: 0.7340 time: 0.0191s\n",
            "18\n",
            "Epoch: 0628 loss_train: 0.8736 acc_train: 0.7917 loss_val: 0.9504 acc_val: 0.7280 time: 0.0191s\n",
            "19\n",
            "Epoch: 0629 loss_train: 0.7992 acc_train: 0.8083 loss_val: 0.9541 acc_val: 0.7280 time: 0.0191s\n",
            "20\n",
            "Epoch: 0630 loss_train: 0.7544 acc_train: 0.8750 loss_val: 0.9551 acc_val: 0.7320 time: 0.0191s\n",
            "21\n",
            "Epoch: 0631 loss_train: 0.8189 acc_train: 0.8500 loss_val: 0.9540 acc_val: 0.7300 time: 0.0208s\n",
            "22\n",
            "Epoch: 0632 loss_train: 0.7743 acc_train: 0.8583 loss_val: 0.9512 acc_val: 0.7340 time: 0.0193s\n",
            "23\n",
            "Epoch: 0633 loss_train: 0.7583 acc_train: 0.8000 loss_val: 0.9470 acc_val: 0.7340 time: 0.0222s\n",
            "24\n",
            "Epoch: 0634 loss_train: 0.7570 acc_train: 0.9000 loss_val: 0.9406 acc_val: 0.7380 time: 0.0192s\n",
            "25\n",
            "Epoch: 0635 loss_train: 0.7664 acc_train: 0.8667 loss_val: 0.9353 acc_val: 0.7360 time: 0.0194s\n",
            "26\n",
            "Epoch: 0636 loss_train: 0.7588 acc_train: 0.8333 loss_val: 0.9339 acc_val: 0.7340 time: 0.0188s\n",
            "0\n",
            "Epoch: 0637 loss_train: 0.7730 acc_train: 0.8667 loss_val: 0.9371 acc_val: 0.7320 time: 0.0189s\n",
            "0\n",
            "Epoch: 0638 loss_train: 0.8101 acc_train: 0.8333 loss_val: 0.9421 acc_val: 0.7280 time: 0.0187s\n",
            "1\n",
            "Epoch: 0639 loss_train: 0.8522 acc_train: 0.8000 loss_val: 0.9447 acc_val: 0.7260 time: 0.0191s\n",
            "2\n",
            "Epoch: 0640 loss_train: 0.8010 acc_train: 0.7917 loss_val: 0.9451 acc_val: 0.7300 time: 0.0192s\n",
            "3\n",
            "Epoch: 0641 loss_train: 0.8081 acc_train: 0.8083 loss_val: 0.9431 acc_val: 0.7360 time: 0.0197s\n",
            "4\n",
            "Epoch: 0642 loss_train: 0.8228 acc_train: 0.8500 loss_val: 0.9462 acc_val: 0.7340 time: 0.0191s\n",
            "5\n",
            "Epoch: 0643 loss_train: 0.7454 acc_train: 0.8583 loss_val: 0.9513 acc_val: 0.7340 time: 0.0191s\n",
            "6\n",
            "Epoch: 0644 loss_train: 0.8735 acc_train: 0.7750 loss_val: 0.9585 acc_val: 0.7280 time: 0.0191s\n",
            "7\n",
            "Epoch: 0645 loss_train: 0.7464 acc_train: 0.8500 loss_val: 0.9576 acc_val: 0.7300 time: 0.0198s\n",
            "8\n",
            "Epoch: 0646 loss_train: 0.8472 acc_train: 0.8167 loss_val: 0.9533 acc_val: 0.7340 time: 0.0187s\n",
            "9\n",
            "Epoch: 0647 loss_train: 0.8105 acc_train: 0.8167 loss_val: 0.9464 acc_val: 0.7300 time: 0.0194s\n",
            "10\n",
            "Epoch: 0648 loss_train: 0.7727 acc_train: 0.8750 loss_val: 0.9389 acc_val: 0.7420 time: 0.0197s\n",
            "11\n",
            "Epoch: 0649 loss_train: 0.8095 acc_train: 0.8750 loss_val: 0.9378 acc_val: 0.7340 time: 0.0191s\n",
            "12\n",
            "Epoch: 0650 loss_train: 0.8322 acc_train: 0.8333 loss_val: 0.9403 acc_val: 0.7320 time: 0.0192s\n",
            "13\n",
            "Epoch: 0651 loss_train: 0.7979 acc_train: 0.8500 loss_val: 0.9446 acc_val: 0.7320 time: 0.0192s\n",
            "14\n",
            "Epoch: 0652 loss_train: 0.7757 acc_train: 0.8417 loss_val: 0.9494 acc_val: 0.7320 time: 0.0192s\n",
            "15\n",
            "Epoch: 0653 loss_train: 0.8124 acc_train: 0.8000 loss_val: 0.9517 acc_val: 0.7340 time: 0.0200s\n",
            "16\n",
            "Epoch: 0654 loss_train: 0.8722 acc_train: 0.8250 loss_val: 0.9510 acc_val: 0.7340 time: 0.0193s\n",
            "17\n",
            "Epoch: 0655 loss_train: 0.8858 acc_train: 0.8250 loss_val: 0.9474 acc_val: 0.7400 time: 0.0191s\n",
            "18\n",
            "Epoch: 0656 loss_train: 0.7491 acc_train: 0.8167 loss_val: 0.9434 acc_val: 0.7380 time: 0.0192s\n",
            "19\n",
            "Epoch: 0657 loss_train: 0.8241 acc_train: 0.8250 loss_val: 0.9398 acc_val: 0.7360 time: 0.0192s\n",
            "20\n",
            "Epoch: 0658 loss_train: 0.7624 acc_train: 0.8167 loss_val: 0.9361 acc_val: 0.7400 time: 0.0203s\n",
            "21\n",
            "Epoch: 0659 loss_train: 0.8399 acc_train: 0.8167 loss_val: 0.9349 acc_val: 0.7420 time: 0.0191s\n",
            "22\n",
            "Epoch: 0660 loss_train: 0.8275 acc_train: 0.8333 loss_val: 0.9376 acc_val: 0.7400 time: 0.0199s\n",
            "23\n",
            "Epoch: 0661 loss_train: 0.8030 acc_train: 0.8000 loss_val: 0.9402 acc_val: 0.7340 time: 0.0189s\n",
            "24\n",
            "Epoch: 0662 loss_train: 0.7340 acc_train: 0.8500 loss_val: 0.9406 acc_val: 0.7340 time: 0.0191s\n",
            "25\n",
            "Epoch: 0663 loss_train: 0.7546 acc_train: 0.8583 loss_val: 0.9412 acc_val: 0.7360 time: 0.0190s\n",
            "26\n",
            "Epoch: 0664 loss_train: 0.8072 acc_train: 0.8000 loss_val: 0.9413 acc_val: 0.7380 time: 0.0192s\n",
            "27\n",
            "Epoch: 0665 loss_train: 0.8191 acc_train: 0.8583 loss_val: 0.9451 acc_val: 0.7380 time: 0.0189s\n",
            "28\n",
            "Epoch: 0666 loss_train: 0.8430 acc_train: 0.8083 loss_val: 0.9465 acc_val: 0.7360 time: 0.0189s\n",
            "29\n",
            "Epoch: 0667 loss_train: 0.8336 acc_train: 0.8417 loss_val: 0.9496 acc_val: 0.7360 time: 0.0189s\n",
            "30\n",
            "Epoch: 0668 loss_train: 0.7847 acc_train: 0.8583 loss_val: 0.9489 acc_val: 0.7400 time: 0.0190s\n",
            "31\n",
            "Epoch: 0669 loss_train: 0.7782 acc_train: 0.8667 loss_val: 0.9473 acc_val: 0.7360 time: 0.0189s\n",
            "32\n",
            "Epoch: 0670 loss_train: 0.7468 acc_train: 0.8917 loss_val: 0.9437 acc_val: 0.7360 time: 0.0196s\n",
            "33\n",
            "Epoch: 0671 loss_train: 0.7375 acc_train: 0.8500 loss_val: 0.9406 acc_val: 0.7360 time: 0.0189s\n",
            "34\n",
            "Epoch: 0672 loss_train: 0.7616 acc_train: 0.8167 loss_val: 0.9381 acc_val: 0.7360 time: 0.0189s\n",
            "35\n",
            "Epoch: 0673 loss_train: 0.7296 acc_train: 0.8000 loss_val: 0.9336 acc_val: 0.7380 time: 0.0205s\n",
            "36\n",
            "Epoch: 0674 loss_train: 0.7842 acc_train: 0.8333 loss_val: 0.9327 acc_val: 0.7380 time: 0.0189s\n",
            "0\n",
            "Epoch: 0675 loss_train: 0.8091 acc_train: 0.8417 loss_val: 0.9376 acc_val: 0.7420 time: 0.0190s\n",
            "0\n",
            "Epoch: 0676 loss_train: 0.7560 acc_train: 0.8917 loss_val: 0.9427 acc_val: 0.7380 time: 0.0190s\n",
            "1\n",
            "Epoch: 0677 loss_train: 0.8239 acc_train: 0.8167 loss_val: 0.9497 acc_val: 0.7340 time: 0.0197s\n",
            "2\n",
            "Epoch: 0678 loss_train: 0.7597 acc_train: 0.8833 loss_val: 0.9533 acc_val: 0.7240 time: 0.0189s\n",
            "3\n",
            "Epoch: 0679 loss_train: 0.8240 acc_train: 0.8167 loss_val: 0.9535 acc_val: 0.7200 time: 0.0189s\n",
            "4\n",
            "Epoch: 0680 loss_train: 0.8135 acc_train: 0.8250 loss_val: 0.9529 acc_val: 0.7200 time: 0.0241s\n",
            "5\n",
            "Epoch: 0681 loss_train: 0.8230 acc_train: 0.7917 loss_val: 0.9514 acc_val: 0.7180 time: 0.0206s\n",
            "6\n",
            "Epoch: 0682 loss_train: 0.7820 acc_train: 0.8250 loss_val: 0.9485 acc_val: 0.7220 time: 0.0201s\n",
            "7\n",
            "Epoch: 0683 loss_train: 0.7640 acc_train: 0.8667 loss_val: 0.9455 acc_val: 0.7280 time: 0.0192s\n",
            "8\n",
            "Epoch: 0684 loss_train: 0.8184 acc_train: 0.8167 loss_val: 0.9437 acc_val: 0.7380 time: 0.0204s\n",
            "9\n",
            "Epoch: 0685 loss_train: 0.7460 acc_train: 0.8417 loss_val: 0.9445 acc_val: 0.7440 time: 0.0214s\n",
            "10\n",
            "Epoch: 0686 loss_train: 0.7605 acc_train: 0.8000 loss_val: 0.9423 acc_val: 0.7420 time: 0.0202s\n",
            "11\n",
            "Epoch: 0687 loss_train: 0.7842 acc_train: 0.8000 loss_val: 0.9417 acc_val: 0.7400 time: 0.0193s\n",
            "12\n",
            "Epoch: 0688 loss_train: 0.7180 acc_train: 0.8750 loss_val: 0.9413 acc_val: 0.7360 time: 0.0191s\n",
            "13\n",
            "Epoch: 0689 loss_train: 0.8569 acc_train: 0.7750 loss_val: 0.9416 acc_val: 0.7300 time: 0.0199s\n",
            "14\n",
            "Epoch: 0690 loss_train: 0.8333 acc_train: 0.8167 loss_val: 0.9420 acc_val: 0.7300 time: 0.0192s\n",
            "15\n",
            "Epoch: 0691 loss_train: 0.8642 acc_train: 0.8083 loss_val: 0.9421 acc_val: 0.7320 time: 0.0193s\n",
            "16\n",
            "Epoch: 0692 loss_train: 0.8274 acc_train: 0.8583 loss_val: 0.9388 acc_val: 0.7320 time: 0.0205s\n",
            "17\n",
            "Epoch: 0693 loss_train: 0.8113 acc_train: 0.8583 loss_val: 0.9347 acc_val: 0.7340 time: 0.0190s\n",
            "18\n",
            "Epoch: 0694 loss_train: 0.8605 acc_train: 0.8250 loss_val: 0.9303 acc_val: 0.7380 time: 0.0189s\n",
            "19\n",
            "Epoch: 0695 loss_train: 0.7621 acc_train: 0.8333 loss_val: 0.9312 acc_val: 0.7360 time: 0.0186s\n",
            "0\n",
            "Epoch: 0696 loss_train: 0.7479 acc_train: 0.8583 loss_val: 0.9349 acc_val: 0.7300 time: 0.0188s\n",
            "1\n",
            "Epoch: 0697 loss_train: 0.7468 acc_train: 0.8500 loss_val: 0.9412 acc_val: 0.7260 time: 0.0192s\n",
            "2\n",
            "Epoch: 0698 loss_train: 0.7890 acc_train: 0.8500 loss_val: 0.9488 acc_val: 0.7180 time: 0.0189s\n",
            "3\n",
            "Epoch: 0699 loss_train: 0.7276 acc_train: 0.8583 loss_val: 0.9542 acc_val: 0.7180 time: 0.0189s\n",
            "4\n",
            "Epoch: 0700 loss_train: 0.7420 acc_train: 0.8333 loss_val: 0.9514 acc_val: 0.7280 time: 0.0214s\n",
            "5\n",
            "Epoch: 0701 loss_train: 0.7610 acc_train: 0.8417 loss_val: 0.9462 acc_val: 0.7320 time: 0.0190s\n",
            "6\n",
            "Epoch: 0702 loss_train: 0.7870 acc_train: 0.8417 loss_val: 0.9448 acc_val: 0.7400 time: 0.0192s\n",
            "7\n",
            "Epoch: 0703 loss_train: 0.8267 acc_train: 0.7667 loss_val: 0.9428 acc_val: 0.7420 time: 0.0189s\n",
            "8\n",
            "Epoch: 0704 loss_train: 0.8595 acc_train: 0.7500 loss_val: 0.9383 acc_val: 0.7400 time: 0.0189s\n",
            "9\n",
            "Epoch: 0705 loss_train: 0.7944 acc_train: 0.8500 loss_val: 0.9361 acc_val: 0.7360 time: 0.0189s\n",
            "10\n",
            "Epoch: 0706 loss_train: 0.8128 acc_train: 0.7750 loss_val: 0.9390 acc_val: 0.7300 time: 0.0190s\n",
            "11\n",
            "Epoch: 0707 loss_train: 0.7827 acc_train: 0.8583 loss_val: 0.9423 acc_val: 0.7280 time: 0.0193s\n",
            "12\n",
            "Epoch: 0708 loss_train: 0.8166 acc_train: 0.8333 loss_val: 0.9439 acc_val: 0.7300 time: 0.0191s\n",
            "13\n",
            "Epoch: 0709 loss_train: 0.8023 acc_train: 0.8250 loss_val: 0.9475 acc_val: 0.7220 time: 0.0216s\n",
            "14\n",
            "Epoch: 0710 loss_train: 0.8113 acc_train: 0.8583 loss_val: 0.9544 acc_val: 0.7240 time: 0.0199s\n",
            "15\n",
            "Epoch: 0711 loss_train: 0.7948 acc_train: 0.7833 loss_val: 0.9582 acc_val: 0.7300 time: 0.0189s\n",
            "16\n",
            "Epoch: 0712 loss_train: 0.7896 acc_train: 0.8167 loss_val: 0.9588 acc_val: 0.7300 time: 0.0189s\n",
            "17\n",
            "Epoch: 0713 loss_train: 0.8688 acc_train: 0.7917 loss_val: 0.9550 acc_val: 0.7360 time: 0.0190s\n",
            "18\n",
            "Epoch: 0714 loss_train: 0.7876 acc_train: 0.8583 loss_val: 0.9497 acc_val: 0.7380 time: 0.0190s\n",
            "19\n",
            "Epoch: 0715 loss_train: 0.7898 acc_train: 0.8500 loss_val: 0.9413 acc_val: 0.7320 time: 0.0190s\n",
            "20\n",
            "Epoch: 0716 loss_train: 0.7127 acc_train: 0.8833 loss_val: 0.9340 acc_val: 0.7400 time: 0.0205s\n",
            "21\n",
            "Epoch: 0717 loss_train: 0.7419 acc_train: 0.8083 loss_val: 0.9329 acc_val: 0.7400 time: 0.0190s\n",
            "22\n",
            "Epoch: 0718 loss_train: 0.7767 acc_train: 0.8083 loss_val: 0.9324 acc_val: 0.7440 time: 0.0194s\n",
            "23\n",
            "Epoch: 0719 loss_train: 0.8464 acc_train: 0.8083 loss_val: 0.9342 acc_val: 0.7440 time: 0.0191s\n",
            "24\n",
            "Epoch: 0720 loss_train: 0.8183 acc_train: 0.8583 loss_val: 0.9390 acc_val: 0.7340 time: 0.0200s\n",
            "25\n",
            "Epoch: 0721 loss_train: 0.7469 acc_train: 0.8333 loss_val: 0.9488 acc_val: 0.7300 time: 0.0190s\n",
            "26\n",
            "Epoch: 0722 loss_train: 0.7837 acc_train: 0.8417 loss_val: 0.9598 acc_val: 0.7280 time: 0.0193s\n",
            "27\n",
            "Epoch: 0723 loss_train: 0.8225 acc_train: 0.8417 loss_val: 0.9633 acc_val: 0.7280 time: 0.0207s\n",
            "28\n",
            "Epoch: 0724 loss_train: 0.7732 acc_train: 0.8667 loss_val: 0.9647 acc_val: 0.7280 time: 0.0200s\n",
            "29\n",
            "Epoch: 0725 loss_train: 0.7767 acc_train: 0.8333 loss_val: 0.9582 acc_val: 0.7280 time: 0.0201s\n",
            "30\n",
            "Epoch: 0726 loss_train: 0.7800 acc_train: 0.8667 loss_val: 0.9507 acc_val: 0.7360 time: 0.0190s\n",
            "31\n",
            "Epoch: 0727 loss_train: 0.8272 acc_train: 0.7833 loss_val: 0.9453 acc_val: 0.7360 time: 0.0191s\n",
            "32\n",
            "Epoch: 0728 loss_train: 0.7947 acc_train: 0.8333 loss_val: 0.9426 acc_val: 0.7360 time: 0.0187s\n",
            "33\n",
            "Epoch: 0729 loss_train: 0.7661 acc_train: 0.8500 loss_val: 0.9412 acc_val: 0.7320 time: 0.0197s\n",
            "34\n",
            "Epoch: 0730 loss_train: 0.7397 acc_train: 0.8500 loss_val: 0.9422 acc_val: 0.7360 time: 0.0200s\n",
            "35\n",
            "Epoch: 0731 loss_train: 0.8046 acc_train: 0.8750 loss_val: 0.9455 acc_val: 0.7340 time: 0.0192s\n",
            "36\n",
            "Epoch: 0732 loss_train: 0.7869 acc_train: 0.8417 loss_val: 0.9481 acc_val: 0.7320 time: 0.0189s\n",
            "37\n",
            "Epoch: 0733 loss_train: 0.7399 acc_train: 0.8250 loss_val: 0.9469 acc_val: 0.7320 time: 0.0185s\n",
            "38\n",
            "Epoch: 0734 loss_train: 0.7471 acc_train: 0.8917 loss_val: 0.9461 acc_val: 0.7340 time: 0.0190s\n",
            "39\n",
            "Epoch: 0735 loss_train: 0.8206 acc_train: 0.8083 loss_val: 0.9416 acc_val: 0.7340 time: 0.0226s\n",
            "40\n",
            "Epoch: 0736 loss_train: 0.7331 acc_train: 0.8833 loss_val: 0.9365 acc_val: 0.7380 time: 0.0205s\n",
            "41\n",
            "Epoch: 0737 loss_train: 0.7366 acc_train: 0.8917 loss_val: 0.9322 acc_val: 0.7380 time: 0.0191s\n",
            "42\n",
            "Epoch: 0738 loss_train: 0.8540 acc_train: 0.8583 loss_val: 0.9319 acc_val: 0.7420 time: 0.0190s\n",
            "43\n",
            "Epoch: 0739 loss_train: 0.7376 acc_train: 0.8750 loss_val: 0.9330 acc_val: 0.7460 time: 0.0190s\n",
            "44\n",
            "Epoch: 0740 loss_train: 0.8036 acc_train: 0.8000 loss_val: 0.9359 acc_val: 0.7460 time: 0.0196s\n",
            "0\n",
            "Epoch: 0741 loss_train: 0.7913 acc_train: 0.8917 loss_val: 0.9374 acc_val: 0.7420 time: 0.0192s\n",
            "0\n",
            "Epoch: 0742 loss_train: 0.7544 acc_train: 0.9083 loss_val: 0.9372 acc_val: 0.7460 time: 0.0191s\n",
            "1\n",
            "Epoch: 0743 loss_train: 0.7709 acc_train: 0.8500 loss_val: 0.9362 acc_val: 0.7440 time: 0.0193s\n",
            "0\n",
            "Epoch: 0744 loss_train: 0.8528 acc_train: 0.8333 loss_val: 0.9339 acc_val: 0.7420 time: 0.0192s\n",
            "1\n",
            "Epoch: 0745 loss_train: 0.7923 acc_train: 0.8750 loss_val: 0.9340 acc_val: 0.7420 time: 0.0201s\n",
            "2\n",
            "Epoch: 0746 loss_train: 0.7702 acc_train: 0.8500 loss_val: 0.9342 acc_val: 0.7340 time: 0.0195s\n",
            "3\n",
            "Epoch: 0747 loss_train: 0.7369 acc_train: 0.8500 loss_val: 0.9307 acc_val: 0.7380 time: 0.0190s\n",
            "4\n",
            "Epoch: 0748 loss_train: 0.8328 acc_train: 0.8000 loss_val: 0.9294 acc_val: 0.7340 time: 0.0189s\n",
            "5\n",
            "Epoch: 0749 loss_train: 0.7091 acc_train: 0.8667 loss_val: 0.9294 acc_val: 0.7380 time: 0.0188s\n",
            "0\n",
            "Epoch: 0750 loss_train: 0.8056 acc_train: 0.8250 loss_val: 0.9317 acc_val: 0.7420 time: 0.0198s\n",
            "1\n",
            "Epoch: 0751 loss_train: 0.7521 acc_train: 0.8750 loss_val: 0.9369 acc_val: 0.7340 time: 0.0194s\n",
            "2\n",
            "Epoch: 0752 loss_train: 0.7473 acc_train: 0.8417 loss_val: 0.9419 acc_val: 0.7300 time: 0.0190s\n",
            "3\n",
            "Epoch: 0753 loss_train: 0.8425 acc_train: 0.8583 loss_val: 0.9466 acc_val: 0.7320 time: 0.0190s\n",
            "4\n",
            "Epoch: 0754 loss_train: 0.7629 acc_train: 0.8917 loss_val: 0.9477 acc_val: 0.7380 time: 0.0190s\n",
            "5\n",
            "Epoch: 0755 loss_train: 0.7865 acc_train: 0.8500 loss_val: 0.9454 acc_val: 0.7400 time: 0.0192s\n",
            "6\n",
            "Epoch: 0756 loss_train: 0.7759 acc_train: 0.8417 loss_val: 0.9415 acc_val: 0.7440 time: 0.0189s\n",
            "7\n",
            "Epoch: 0757 loss_train: 0.7722 acc_train: 0.8167 loss_val: 0.9386 acc_val: 0.7440 time: 0.0193s\n",
            "8\n",
            "Epoch: 0758 loss_train: 0.8157 acc_train: 0.8167 loss_val: 0.9375 acc_val: 0.7420 time: 0.0189s\n",
            "9\n",
            "Epoch: 0759 loss_train: 0.7499 acc_train: 0.8500 loss_val: 0.9366 acc_val: 0.7420 time: 0.0190s\n",
            "10\n",
            "Epoch: 0760 loss_train: 0.8223 acc_train: 0.8417 loss_val: 0.9399 acc_val: 0.7440 time: 0.0195s\n",
            "11\n",
            "Epoch: 0761 loss_train: 0.7828 acc_train: 0.8333 loss_val: 0.9439 acc_val: 0.7380 time: 0.0190s\n",
            "12\n",
            "Epoch: 0762 loss_train: 0.7475 acc_train: 0.8083 loss_val: 0.9462 acc_val: 0.7340 time: 0.0201s\n",
            "13\n",
            "Epoch: 0763 loss_train: 0.8031 acc_train: 0.8000 loss_val: 0.9501 acc_val: 0.7280 time: 0.0189s\n",
            "14\n",
            "Epoch: 0764 loss_train: 0.8106 acc_train: 0.8583 loss_val: 0.9516 acc_val: 0.7300 time: 0.0189s\n",
            "15\n",
            "Epoch: 0765 loss_train: 0.7760 acc_train: 0.8333 loss_val: 0.9562 acc_val: 0.7360 time: 0.0190s\n",
            "16\n",
            "Epoch: 0766 loss_train: 0.8423 acc_train: 0.7917 loss_val: 0.9544 acc_val: 0.7340 time: 0.0189s\n",
            "17\n",
            "Epoch: 0767 loss_train: 0.7008 acc_train: 0.8667 loss_val: 0.9514 acc_val: 0.7340 time: 0.0190s\n",
            "18\n",
            "Epoch: 0768 loss_train: 0.7784 acc_train: 0.8417 loss_val: 0.9427 acc_val: 0.7360 time: 0.0189s\n",
            "19\n",
            "Epoch: 0769 loss_train: 0.7543 acc_train: 0.8250 loss_val: 0.9354 acc_val: 0.7340 time: 0.0196s\n",
            "20\n",
            "Epoch: 0770 loss_train: 0.7802 acc_train: 0.8667 loss_val: 0.9324 acc_val: 0.7300 time: 0.0203s\n",
            "21\n",
            "Epoch: 0771 loss_train: 0.7866 acc_train: 0.7917 loss_val: 0.9312 acc_val: 0.7340 time: 0.0210s\n",
            "22\n",
            "Epoch: 0772 loss_train: 0.8168 acc_train: 0.7917 loss_val: 0.9324 acc_val: 0.7300 time: 0.0191s\n",
            "23\n",
            "Epoch: 0773 loss_train: 0.8743 acc_train: 0.7000 loss_val: 0.9338 acc_val: 0.7380 time: 0.0204s\n",
            "24\n",
            "Epoch: 0774 loss_train: 0.7344 acc_train: 0.8417 loss_val: 0.9384 acc_val: 0.7400 time: 0.0214s\n",
            "25\n",
            "Epoch: 0775 loss_train: 0.7810 acc_train: 0.8667 loss_val: 0.9429 acc_val: 0.7380 time: 0.0195s\n",
            "26\n",
            "Epoch: 0776 loss_train: 0.7949 acc_train: 0.8167 loss_val: 0.9480 acc_val: 0.7400 time: 0.0192s\n",
            "27\n",
            "Epoch: 0777 loss_train: 0.8680 acc_train: 0.8333 loss_val: 0.9499 acc_val: 0.7420 time: 0.0203s\n",
            "28\n",
            "Epoch: 0778 loss_train: 0.7706 acc_train: 0.8750 loss_val: 0.9512 acc_val: 0.7360 time: 0.0190s\n",
            "29\n",
            "Epoch: 0779 loss_train: 0.8232 acc_train: 0.7917 loss_val: 0.9526 acc_val: 0.7380 time: 0.0192s\n",
            "30\n",
            "Epoch: 0780 loss_train: 0.7361 acc_train: 0.8917 loss_val: 0.9539 acc_val: 0.7280 time: 0.0203s\n",
            "31\n",
            "Epoch: 0781 loss_train: 0.8112 acc_train: 0.8250 loss_val: 0.9524 acc_val: 0.7260 time: 0.0189s\n",
            "32\n",
            "Epoch: 0782 loss_train: 0.7796 acc_train: 0.8667 loss_val: 0.9475 acc_val: 0.7240 time: 0.0189s\n",
            "33\n",
            "Epoch: 0783 loss_train: 0.8284 acc_train: 0.7667 loss_val: 0.9424 acc_val: 0.7380 time: 0.0189s\n",
            "34\n",
            "Epoch: 0784 loss_train: 0.7464 acc_train: 0.8750 loss_val: 0.9445 acc_val: 0.7360 time: 0.0190s\n",
            "35\n",
            "Epoch: 0785 loss_train: 0.8457 acc_train: 0.8083 loss_val: 0.9437 acc_val: 0.7400 time: 0.0191s\n",
            "36\n",
            "Epoch: 0786 loss_train: 0.7668 acc_train: 0.8750 loss_val: 0.9439 acc_val: 0.7340 time: 0.0189s\n",
            "37\n",
            "Epoch: 0787 loss_train: 0.7264 acc_train: 0.8583 loss_val: 0.9436 acc_val: 0.7340 time: 0.0201s\n",
            "38\n",
            "Epoch: 0788 loss_train: 0.7690 acc_train: 0.8000 loss_val: 0.9422 acc_val: 0.7380 time: 0.0189s\n",
            "39\n",
            "Epoch: 0789 loss_train: 0.7743 acc_train: 0.8833 loss_val: 0.9411 acc_val: 0.7400 time: 0.0194s\n",
            "40\n",
            "Epoch: 0790 loss_train: 0.7783 acc_train: 0.8500 loss_val: 0.9403 acc_val: 0.7380 time: 0.0225s\n",
            "41\n",
            "Epoch: 0791 loss_train: 0.7750 acc_train: 0.8417 loss_val: 0.9381 acc_val: 0.7360 time: 0.0191s\n",
            "42\n",
            "Epoch: 0792 loss_train: 0.7744 acc_train: 0.8333 loss_val: 0.9376 acc_val: 0.7340 time: 0.0191s\n",
            "43\n",
            "Epoch: 0793 loss_train: 0.7373 acc_train: 0.8583 loss_val: 0.9398 acc_val: 0.7260 time: 0.0202s\n",
            "44\n",
            "Epoch: 0794 loss_train: 0.8582 acc_train: 0.7917 loss_val: 0.9410 acc_val: 0.7240 time: 0.0192s\n",
            "45\n",
            "Epoch: 0795 loss_train: 0.7966 acc_train: 0.8583 loss_val: 0.9441 acc_val: 0.7200 time: 0.0193s\n",
            "46\n",
            "Epoch: 0796 loss_train: 0.8246 acc_train: 0.7917 loss_val: 0.9478 acc_val: 0.7240 time: 0.0210s\n",
            "47\n",
            "Epoch: 0797 loss_train: 0.8148 acc_train: 0.8417 loss_val: 0.9507 acc_val: 0.7220 time: 0.0192s\n",
            "48\n",
            "Epoch: 0798 loss_train: 0.7981 acc_train: 0.8750 loss_val: 0.9486 acc_val: 0.7320 time: 0.0190s\n",
            "49\n",
            "Epoch: 0799 loss_train: 0.7457 acc_train: 0.9000 loss_val: 0.9420 acc_val: 0.7400 time: 0.0189s\n",
            "50\n",
            "Epoch: 0800 loss_train: 0.7648 acc_train: 0.8667 loss_val: 0.9370 acc_val: 0.7400 time: 0.0214s\n",
            "51\n",
            "Epoch: 0801 loss_train: 0.7617 acc_train: 0.8917 loss_val: 0.9378 acc_val: 0.7340 time: 0.0190s\n",
            "52\n",
            "Epoch: 0802 loss_train: 0.7748 acc_train: 0.8250 loss_val: 0.9449 acc_val: 0.7300 time: 0.0189s\n",
            "53\n",
            "Epoch: 0803 loss_train: 0.7776 acc_train: 0.8333 loss_val: 0.9492 acc_val: 0.7280 time: 0.0190s\n",
            "54\n",
            "Epoch: 0804 loss_train: 0.8125 acc_train: 0.8000 loss_val: 0.9500 acc_val: 0.7260 time: 0.0189s\n",
            "55\n",
            "Epoch: 0805 loss_train: 0.7524 acc_train: 0.7917 loss_val: 0.9468 acc_val: 0.7280 time: 0.0189s\n",
            "56\n",
            "Epoch: 0806 loss_train: 0.7501 acc_train: 0.8500 loss_val: 0.9424 acc_val: 0.7300 time: 0.0190s\n",
            "57\n",
            "Epoch: 0807 loss_train: 0.8521 acc_train: 0.7833 loss_val: 0.9407 acc_val: 0.7280 time: 0.0190s\n",
            "58\n",
            "Epoch: 0808 loss_train: 0.7338 acc_train: 0.8333 loss_val: 0.9377 acc_val: 0.7280 time: 0.0191s\n",
            "59\n",
            "Epoch: 0809 loss_train: 0.8399 acc_train: 0.8000 loss_val: 0.9365 acc_val: 0.7260 time: 0.0193s\n",
            "60\n",
            "Epoch: 0810 loss_train: 0.8107 acc_train: 0.8250 loss_val: 0.9340 acc_val: 0.7260 time: 0.0209s\n",
            "61\n",
            "Epoch: 0811 loss_train: 0.7595 acc_train: 0.7917 loss_val: 0.9348 acc_val: 0.7260 time: 0.0189s\n",
            "62\n",
            "Epoch: 0812 loss_train: 0.8222 acc_train: 0.8250 loss_val: 0.9367 acc_val: 0.7280 time: 0.0196s\n",
            "63\n",
            "Epoch: 0813 loss_train: 0.7700 acc_train: 0.8333 loss_val: 0.9419 acc_val: 0.7260 time: 0.0187s\n",
            "64\n",
            "Epoch: 0814 loss_train: 0.8369 acc_train: 0.8417 loss_val: 0.9531 acc_val: 0.7220 time: 0.0189s\n",
            "65\n",
            "Epoch: 0815 loss_train: 0.7496 acc_train: 0.8333 loss_val: 0.9644 acc_val: 0.7220 time: 0.0205s\n",
            "66\n",
            "Epoch: 0816 loss_train: 0.6959 acc_train: 0.8667 loss_val: 0.9592 acc_val: 0.7280 time: 0.0190s\n",
            "67\n",
            "Epoch: 0817 loss_train: 0.8080 acc_train: 0.8250 loss_val: 0.9473 acc_val: 0.7360 time: 0.0188s\n",
            "68\n",
            "Epoch: 0818 loss_train: 0.8385 acc_train: 0.7917 loss_val: 0.9382 acc_val: 0.7360 time: 0.0189s\n",
            "69\n",
            "Epoch: 0819 loss_train: 0.8030 acc_train: 0.8333 loss_val: 0.9311 acc_val: 0.7400 time: 0.0190s\n",
            "70\n",
            "Epoch: 0820 loss_train: 0.7576 acc_train: 0.8083 loss_val: 0.9278 acc_val: 0.7320 time: 0.0199s\n",
            "71\n",
            "Epoch: 0821 loss_train: 0.8303 acc_train: 0.7833 loss_val: 0.9271 acc_val: 0.7340 time: 0.0192s\n",
            "0\n",
            "Epoch: 0822 loss_train: 0.7774 acc_train: 0.8083 loss_val: 0.9279 acc_val: 0.7360 time: 0.0186s\n",
            "0\n",
            "Epoch: 0823 loss_train: 0.7488 acc_train: 0.8583 loss_val: 0.9284 acc_val: 0.7380 time: 0.0189s\n",
            "1\n",
            "Epoch: 0824 loss_train: 0.7682 acc_train: 0.8000 loss_val: 0.9296 acc_val: 0.7380 time: 0.0190s\n",
            "2\n",
            "Epoch: 0825 loss_train: 0.7513 acc_train: 0.8167 loss_val: 0.9305 acc_val: 0.7460 time: 0.0189s\n",
            "3\n",
            "Epoch: 0826 loss_train: 0.7568 acc_train: 0.8667 loss_val: 0.9327 acc_val: 0.7400 time: 0.0189s\n",
            "0\n",
            "Epoch: 0827 loss_train: 0.8180 acc_train: 0.8417 loss_val: 0.9353 acc_val: 0.7380 time: 0.0191s\n",
            "1\n",
            "Epoch: 0828 loss_train: 0.8151 acc_train: 0.7750 loss_val: 0.9378 acc_val: 0.7400 time: 0.0189s\n",
            "2\n",
            "Epoch: 0829 loss_train: 0.7959 acc_train: 0.8667 loss_val: 0.9378 acc_val: 0.7440 time: 0.0192s\n",
            "3\n",
            "Epoch: 0830 loss_train: 0.6864 acc_train: 0.8333 loss_val: 0.9364 acc_val: 0.7440 time: 0.0207s\n",
            "4\n",
            "Epoch: 0831 loss_train: 0.7327 acc_train: 0.8667 loss_val: 0.9346 acc_val: 0.7340 time: 0.0204s\n",
            "5\n",
            "Epoch: 0832 loss_train: 0.7728 acc_train: 0.8583 loss_val: 0.9342 acc_val: 0.7320 time: 0.0195s\n",
            "6\n",
            "Epoch: 0833 loss_train: 0.7233 acc_train: 0.8833 loss_val: 0.9313 acc_val: 0.7320 time: 0.0189s\n",
            "7\n",
            "Epoch: 0834 loss_train: 0.7835 acc_train: 0.8417 loss_val: 0.9329 acc_val: 0.7420 time: 0.0192s\n",
            "8\n",
            "Epoch: 0835 loss_train: 0.7995 acc_train: 0.8583 loss_val: 0.9374 acc_val: 0.7380 time: 0.0198s\n",
            "9\n",
            "Epoch: 0836 loss_train: 0.7723 acc_train: 0.8083 loss_val: 0.9425 acc_val: 0.7340 time: 0.0189s\n",
            "10\n",
            "Epoch: 0837 loss_train: 0.7282 acc_train: 0.8500 loss_val: 0.9489 acc_val: 0.7340 time: 0.0195s\n",
            "11\n",
            "Epoch: 0838 loss_train: 0.8028 acc_train: 0.8750 loss_val: 0.9537 acc_val: 0.7300 time: 0.0189s\n",
            "12\n",
            "Epoch: 0839 loss_train: 0.8183 acc_train: 0.8000 loss_val: 0.9568 acc_val: 0.7320 time: 0.0190s\n",
            "13\n",
            "Epoch: 0840 loss_train: 0.7590 acc_train: 0.8833 loss_val: 0.9548 acc_val: 0.7320 time: 0.0215s\n",
            "14\n",
            "Epoch: 0841 loss_train: 0.8596 acc_train: 0.8167 loss_val: 0.9500 acc_val: 0.7360 time: 0.0200s\n",
            "15\n",
            "Epoch: 0842 loss_train: 0.7787 acc_train: 0.8333 loss_val: 0.9425 acc_val: 0.7420 time: 0.0195s\n",
            "16\n",
            "Epoch: 0843 loss_train: 0.9103 acc_train: 0.7417 loss_val: 0.9355 acc_val: 0.7460 time: 0.0191s\n",
            "17\n",
            "Epoch: 0844 loss_train: 0.7746 acc_train: 0.8667 loss_val: 0.9310 acc_val: 0.7440 time: 0.0209s\n",
            "0\n",
            "Epoch: 0845 loss_train: 0.7315 acc_train: 0.8500 loss_val: 0.9330 acc_val: 0.7340 time: 0.0191s\n",
            "1\n",
            "Epoch: 0846 loss_train: 0.8000 acc_train: 0.8667 loss_val: 0.9378 acc_val: 0.7300 time: 0.0196s\n",
            "2\n",
            "Epoch: 0847 loss_train: 0.7966 acc_train: 0.8250 loss_val: 0.9427 acc_val: 0.7300 time: 0.0189s\n",
            "3\n",
            "Epoch: 0848 loss_train: 0.7348 acc_train: 0.8750 loss_val: 0.9489 acc_val: 0.7280 time: 0.0191s\n",
            "4\n",
            "Epoch: 0849 loss_train: 0.7463 acc_train: 0.9000 loss_val: 0.9509 acc_val: 0.7280 time: 0.0189s\n",
            "5\n",
            "Epoch: 0850 loss_train: 0.8164 acc_train: 0.8167 loss_val: 0.9477 acc_val: 0.7320 time: 0.0192s\n",
            "6\n",
            "Epoch: 0851 loss_train: 0.7109 acc_train: 0.8500 loss_val: 0.9479 acc_val: 0.7280 time: 0.0190s\n",
            "7\n",
            "Epoch: 0852 loss_train: 0.7676 acc_train: 0.8167 loss_val: 0.9454 acc_val: 0.7320 time: 0.0193s\n",
            "8\n",
            "Epoch: 0853 loss_train: 0.7973 acc_train: 0.8250 loss_val: 0.9411 acc_val: 0.7360 time: 0.0190s\n",
            "9\n",
            "Epoch: 0854 loss_train: 0.7697 acc_train: 0.8167 loss_val: 0.9357 acc_val: 0.7400 time: 0.0203s\n",
            "10\n",
            "Epoch: 0855 loss_train: 0.8105 acc_train: 0.8417 loss_val: 0.9345 acc_val: 0.7380 time: 0.0189s\n",
            "11\n",
            "Epoch: 0856 loss_train: 0.7544 acc_train: 0.8417 loss_val: 0.9366 acc_val: 0.7380 time: 0.0186s\n",
            "12\n",
            "Epoch: 0857 loss_train: 0.7753 acc_train: 0.8083 loss_val: 0.9401 acc_val: 0.7420 time: 0.0189s\n",
            "13\n",
            "Epoch: 0858 loss_train: 0.7726 acc_train: 0.8667 loss_val: 0.9470 acc_val: 0.7300 time: 0.0189s\n",
            "14\n",
            "Epoch: 0859 loss_train: 0.7491 acc_train: 0.8750 loss_val: 0.9561 acc_val: 0.7200 time: 0.0190s\n",
            "15\n",
            "Epoch: 0860 loss_train: 0.8310 acc_train: 0.8333 loss_val: 0.9610 acc_val: 0.7160 time: 0.0197s\n",
            "16\n",
            "Epoch: 0861 loss_train: 0.8209 acc_train: 0.8250 loss_val: 0.9605 acc_val: 0.7180 time: 0.0198s\n",
            "17\n",
            "Epoch: 0862 loss_train: 0.8029 acc_train: 0.8167 loss_val: 0.9554 acc_val: 0.7320 time: 0.0193s\n",
            "18\n",
            "Epoch: 0863 loss_train: 0.8066 acc_train: 0.8417 loss_val: 0.9492 acc_val: 0.7360 time: 0.0189s\n",
            "19\n",
            "Epoch: 0864 loss_train: 0.6821 acc_train: 0.8333 loss_val: 0.9447 acc_val: 0.7360 time: 0.0188s\n",
            "20\n",
            "Epoch: 0865 loss_train: 0.7953 acc_train: 0.8667 loss_val: 0.9366 acc_val: 0.7360 time: 0.0190s\n",
            "21\n",
            "Epoch: 0866 loss_train: 0.7877 acc_train: 0.8417 loss_val: 0.9322 acc_val: 0.7380 time: 0.0196s\n",
            "22\n",
            "Epoch: 0867 loss_train: 0.8175 acc_train: 0.8250 loss_val: 0.9306 acc_val: 0.7420 time: 0.0205s\n",
            "23\n",
            "Epoch: 0868 loss_train: 0.7182 acc_train: 0.8500 loss_val: 0.9308 acc_val: 0.7420 time: 0.0221s\n",
            "24\n",
            "Epoch: 0869 loss_train: 0.8141 acc_train: 0.8083 loss_val: 0.9344 acc_val: 0.7340 time: 0.0190s\n",
            "25\n",
            "Epoch: 0870 loss_train: 0.7156 acc_train: 0.8750 loss_val: 0.9415 acc_val: 0.7320 time: 0.0197s\n",
            "26\n",
            "Epoch: 0871 loss_train: 0.7599 acc_train: 0.8333 loss_val: 0.9472 acc_val: 0.7340 time: 0.0191s\n",
            "27\n",
            "Epoch: 0872 loss_train: 0.7361 acc_train: 0.8750 loss_val: 0.9498 acc_val: 0.7320 time: 0.0190s\n",
            "28\n",
            "Epoch: 0873 loss_train: 0.8327 acc_train: 0.7833 loss_val: 0.9518 acc_val: 0.7340 time: 0.0205s\n",
            "29\n",
            "Epoch: 0874 loss_train: 0.8578 acc_train: 0.8083 loss_val: 0.9487 acc_val: 0.7340 time: 0.0189s\n",
            "30\n",
            "Epoch: 0875 loss_train: 0.8218 acc_train: 0.8000 loss_val: 0.9452 acc_val: 0.7420 time: 0.0200s\n",
            "31\n",
            "Epoch: 0876 loss_train: 0.7313 acc_train: 0.8750 loss_val: 0.9438 acc_val: 0.7280 time: 0.0190s\n",
            "32\n",
            "Epoch: 0877 loss_train: 0.7677 acc_train: 0.8417 loss_val: 0.9449 acc_val: 0.7240 time: 0.0191s\n",
            "33\n",
            "Epoch: 0878 loss_train: 0.7705 acc_train: 0.8833 loss_val: 0.9427 acc_val: 0.7260 time: 0.0202s\n",
            "34\n",
            "Epoch: 0879 loss_train: 0.7033 acc_train: 0.8917 loss_val: 0.9382 acc_val: 0.7280 time: 0.0194s\n",
            "35\n",
            "Epoch: 0880 loss_train: 0.7919 acc_train: 0.8083 loss_val: 0.9339 acc_val: 0.7320 time: 0.0208s\n",
            "36\n",
            "Epoch: 0881 loss_train: 0.7291 acc_train: 0.8583 loss_val: 0.9342 acc_val: 0.7320 time: 0.0203s\n",
            "37\n",
            "Epoch: 0882 loss_train: 0.7544 acc_train: 0.7833 loss_val: 0.9391 acc_val: 0.7420 time: 0.0194s\n",
            "38\n",
            "Epoch: 0883 loss_train: 0.8327 acc_train: 0.7583 loss_val: 0.9458 acc_val: 0.7360 time: 0.0195s\n",
            "39\n",
            "Epoch: 0884 loss_train: 0.7076 acc_train: 0.8167 loss_val: 0.9520 acc_val: 0.7320 time: 0.0203s\n",
            "40\n",
            "Epoch: 0885 loss_train: 0.8323 acc_train: 0.8000 loss_val: 0.9537 acc_val: 0.7340 time: 0.0197s\n",
            "41\n",
            "Epoch: 0886 loss_train: 0.8560 acc_train: 0.8250 loss_val: 0.9492 acc_val: 0.7380 time: 0.0187s\n",
            "42\n",
            "Epoch: 0887 loss_train: 0.8109 acc_train: 0.8167 loss_val: 0.9426 acc_val: 0.7360 time: 0.0203s\n",
            "43\n",
            "Epoch: 0888 loss_train: 0.7990 acc_train: 0.8417 loss_val: 0.9366 acc_val: 0.7360 time: 0.0190s\n",
            "44\n",
            "Epoch: 0889 loss_train: 0.8231 acc_train: 0.7917 loss_val: 0.9305 acc_val: 0.7380 time: 0.0191s\n",
            "45\n",
            "Epoch: 0890 loss_train: 0.8287 acc_train: 0.8333 loss_val: 0.9264 acc_val: 0.7420 time: 0.0197s\n",
            "46\n",
            "Epoch: 0891 loss_train: 0.7932 acc_train: 0.8500 loss_val: 0.9257 acc_val: 0.7400 time: 0.0188s\n",
            "0\n",
            "Epoch: 0892 loss_train: 0.7678 acc_train: 0.7917 loss_val: 0.9275 acc_val: 0.7400 time: 0.0189s\n",
            "0\n",
            "Epoch: 0893 loss_train: 0.7434 acc_train: 0.8833 loss_val: 0.9329 acc_val: 0.7440 time: 0.0192s\n",
            "1\n",
            "Epoch: 0894 loss_train: 0.7302 acc_train: 0.8583 loss_val: 0.9418 acc_val: 0.7440 time: 0.0194s\n",
            "2\n",
            "Epoch: 0895 loss_train: 0.7369 acc_train: 0.8167 loss_val: 0.9513 acc_val: 0.7340 time: 0.0192s\n",
            "3\n",
            "Epoch: 0896 loss_train: 0.7369 acc_train: 0.8417 loss_val: 0.9559 acc_val: 0.7320 time: 0.0190s\n",
            "4\n",
            "Epoch: 0897 loss_train: 0.7499 acc_train: 0.8500 loss_val: 0.9578 acc_val: 0.7240 time: 0.0190s\n",
            "5\n",
            "Epoch: 0898 loss_train: 0.7753 acc_train: 0.8583 loss_val: 0.9535 acc_val: 0.7280 time: 0.0190s\n",
            "6\n",
            "Epoch: 0899 loss_train: 0.7589 acc_train: 0.8500 loss_val: 0.9410 acc_val: 0.7300 time: 0.0190s\n",
            "7\n",
            "Epoch: 0900 loss_train: 0.7557 acc_train: 0.8000 loss_val: 0.9330 acc_val: 0.7300 time: 0.0188s\n",
            "8\n",
            "Epoch: 0901 loss_train: 0.7814 acc_train: 0.8667 loss_val: 0.9282 acc_val: 0.7260 time: 0.0198s\n",
            "9\n",
            "Epoch: 0902 loss_train: 0.7220 acc_train: 0.8750 loss_val: 0.9258 acc_val: 0.7300 time: 0.0189s\n",
            "10\n",
            "Epoch: 0903 loss_train: 0.7496 acc_train: 0.8500 loss_val: 0.9255 acc_val: 0.7360 time: 0.0190s\n",
            "11\n",
            "Epoch: 0904 loss_train: 0.8330 acc_train: 0.8000 loss_val: 0.9284 acc_val: 0.7360 time: 0.0187s\n",
            "0\n",
            "Epoch: 0905 loss_train: 0.8088 acc_train: 0.8500 loss_val: 0.9340 acc_val: 0.7340 time: 0.0189s\n",
            "1\n",
            "Epoch: 0906 loss_train: 0.7881 acc_train: 0.8667 loss_val: 0.9392 acc_val: 0.7420 time: 0.0190s\n",
            "2\n",
            "Epoch: 0907 loss_train: 0.7520 acc_train: 0.8167 loss_val: 0.9442 acc_val: 0.7440 time: 0.0190s\n",
            "3\n",
            "Epoch: 0908 loss_train: 0.8127 acc_train: 0.8167 loss_val: 0.9491 acc_val: 0.7440 time: 0.0193s\n",
            "4\n",
            "Epoch: 0909 loss_train: 0.7856 acc_train: 0.8083 loss_val: 0.9505 acc_val: 0.7420 time: 0.0198s\n",
            "5\n",
            "Epoch: 0910 loss_train: 0.7904 acc_train: 0.8833 loss_val: 0.9482 acc_val: 0.7380 time: 0.0201s\n",
            "6\n",
            "Epoch: 0911 loss_train: 0.7903 acc_train: 0.8500 loss_val: 0.9439 acc_val: 0.7380 time: 0.0189s\n",
            "7\n",
            "Epoch: 0912 loss_train: 0.7820 acc_train: 0.8000 loss_val: 0.9384 acc_val: 0.7340 time: 0.0190s\n",
            "8\n",
            "Epoch: 0913 loss_train: 0.7608 acc_train: 0.8667 loss_val: 0.9323 acc_val: 0.7280 time: 0.0191s\n",
            "9\n",
            "Epoch: 0914 loss_train: 0.7775 acc_train: 0.8833 loss_val: 0.9272 acc_val: 0.7320 time: 0.0198s\n",
            "10\n",
            "Epoch: 0915 loss_train: 0.7179 acc_train: 0.8417 loss_val: 0.9255 acc_val: 0.7340 time: 0.0188s\n",
            "11\n",
            "Epoch: 0916 loss_train: 0.7919 acc_train: 0.8250 loss_val: 0.9265 acc_val: 0.7400 time: 0.0187s\n",
            "0\n",
            "Epoch: 0917 loss_train: 0.7051 acc_train: 0.8667 loss_val: 0.9305 acc_val: 0.7360 time: 0.0190s\n",
            "1\n",
            "Epoch: 0918 loss_train: 0.7635 acc_train: 0.8833 loss_val: 0.9370 acc_val: 0.7380 time: 0.0190s\n",
            "2\n",
            "Epoch: 0919 loss_train: 0.8096 acc_train: 0.8000 loss_val: 0.9453 acc_val: 0.7300 time: 0.0193s\n",
            "3\n",
            "Epoch: 0920 loss_train: 0.6946 acc_train: 0.8500 loss_val: 0.9488 acc_val: 0.7320 time: 0.0192s\n",
            "4\n",
            "Epoch: 0921 loss_train: 0.7341 acc_train: 0.8333 loss_val: 0.9498 acc_val: 0.7280 time: 0.0189s\n",
            "5\n",
            "Epoch: 0922 loss_train: 0.7323 acc_train: 0.8417 loss_val: 0.9488 acc_val: 0.7300 time: 0.0203s\n",
            "6\n",
            "Epoch: 0923 loss_train: 0.7735 acc_train: 0.8750 loss_val: 0.9465 acc_val: 0.7260 time: 0.0189s\n",
            "7\n",
            "Epoch: 0924 loss_train: 0.7237 acc_train: 0.8250 loss_val: 0.9456 acc_val: 0.7280 time: 0.0193s\n",
            "8\n",
            "Epoch: 0925 loss_train: 0.7777 acc_train: 0.8250 loss_val: 0.9424 acc_val: 0.7300 time: 0.0202s\n",
            "9\n",
            "Epoch: 0926 loss_train: 0.8170 acc_train: 0.8083 loss_val: 0.9398 acc_val: 0.7280 time: 0.0195s\n",
            "10\n",
            "Epoch: 0927 loss_train: 0.7803 acc_train: 0.7917 loss_val: 0.9338 acc_val: 0.7300 time: 0.0194s\n",
            "11\n",
            "Epoch: 0928 loss_train: 0.8200 acc_train: 0.8333 loss_val: 0.9286 acc_val: 0.7300 time: 0.0191s\n",
            "12\n",
            "Epoch: 0929 loss_train: 0.7836 acc_train: 0.8500 loss_val: 0.9269 acc_val: 0.7300 time: 0.0199s\n",
            "13\n",
            "Epoch: 0930 loss_train: 0.7930 acc_train: 0.8083 loss_val: 0.9274 acc_val: 0.7380 time: 0.0207s\n",
            "14\n",
            "Epoch: 0931 loss_train: 0.8183 acc_train: 0.8417 loss_val: 0.9340 acc_val: 0.7340 time: 0.0191s\n",
            "15\n",
            "Epoch: 0932 loss_train: 0.7697 acc_train: 0.7833 loss_val: 0.9437 acc_val: 0.7300 time: 0.0192s\n",
            "16\n",
            "Epoch: 0933 loss_train: 0.8177 acc_train: 0.7917 loss_val: 0.9500 acc_val: 0.7280 time: 0.0193s\n",
            "17\n",
            "Epoch: 0934 loss_train: 0.8385 acc_train: 0.8083 loss_val: 0.9490 acc_val: 0.7240 time: 0.0201s\n",
            "18\n",
            "Epoch: 0935 loss_train: 0.8168 acc_train: 0.8167 loss_val: 0.9494 acc_val: 0.7160 time: 0.0194s\n",
            "19\n",
            "Epoch: 0936 loss_train: 0.7639 acc_train: 0.8250 loss_val: 0.9489 acc_val: 0.7200 time: 0.0189s\n",
            "20\n",
            "Epoch: 0937 loss_train: 0.7395 acc_train: 0.8417 loss_val: 0.9456 acc_val: 0.7280 time: 0.0189s\n",
            "21\n",
            "Epoch: 0938 loss_train: 0.7521 acc_train: 0.8583 loss_val: 0.9427 acc_val: 0.7260 time: 0.0190s\n",
            "22\n",
            "Epoch: 0939 loss_train: 0.7602 acc_train: 0.8750 loss_val: 0.9396 acc_val: 0.7280 time: 0.0204s\n",
            "23\n",
            "Epoch: 0940 loss_train: 0.7392 acc_train: 0.8417 loss_val: 0.9399 acc_val: 0.7300 time: 0.0201s\n",
            "24\n",
            "Epoch: 0941 loss_train: 0.7539 acc_train: 0.8667 loss_val: 0.9397 acc_val: 0.7320 time: 0.0191s\n",
            "25\n",
            "Epoch: 0942 loss_train: 0.7162 acc_train: 0.8917 loss_val: 0.9381 acc_val: 0.7240 time: 0.0190s\n",
            "26\n",
            "Epoch: 0943 loss_train: 0.8148 acc_train: 0.8333 loss_val: 0.9376 acc_val: 0.7260 time: 0.0192s\n",
            "27\n",
            "Epoch: 0944 loss_train: 0.7863 acc_train: 0.8250 loss_val: 0.9363 acc_val: 0.7240 time: 0.0193s\n",
            "28\n",
            "Epoch: 0945 loss_train: 0.7844 acc_train: 0.8250 loss_val: 0.9388 acc_val: 0.7320 time: 0.0193s\n",
            "29\n",
            "Epoch: 0946 loss_train: 0.7851 acc_train: 0.8500 loss_val: 0.9393 acc_val: 0.7300 time: 0.0191s\n",
            "30\n",
            "Epoch: 0947 loss_train: 0.8374 acc_train: 0.7917 loss_val: 0.9387 acc_val: 0.7360 time: 0.0191s\n",
            "31\n",
            "Epoch: 0948 loss_train: 0.8322 acc_train: 0.8083 loss_val: 0.9338 acc_val: 0.7340 time: 0.0192s\n",
            "32\n",
            "Epoch: 0949 loss_train: 0.7447 acc_train: 0.8583 loss_val: 0.9305 acc_val: 0.7360 time: 0.0196s\n",
            "33\n",
            "Epoch: 0950 loss_train: 0.7734 acc_train: 0.9083 loss_val: 0.9293 acc_val: 0.7400 time: 0.0192s\n",
            "34\n",
            "Epoch: 0951 loss_train: 0.7407 acc_train: 0.8833 loss_val: 0.9311 acc_val: 0.7400 time: 0.0200s\n",
            "35\n",
            "Epoch: 0952 loss_train: 0.7347 acc_train: 0.8750 loss_val: 0.9310 acc_val: 0.7360 time: 0.0191s\n",
            "36\n",
            "Epoch: 0953 loss_train: 0.8023 acc_train: 0.8333 loss_val: 0.9315 acc_val: 0.7340 time: 0.0190s\n",
            "37\n",
            "Epoch: 0954 loss_train: 0.7787 acc_train: 0.8000 loss_val: 0.9305 acc_val: 0.7320 time: 0.0192s\n",
            "38\n",
            "Epoch: 0955 loss_train: 0.7579 acc_train: 0.8000 loss_val: 0.9292 acc_val: 0.7340 time: 0.0193s\n",
            "39\n",
            "Epoch: 0956 loss_train: 0.8616 acc_train: 0.7500 loss_val: 0.9271 acc_val: 0.7400 time: 0.0189s\n",
            "40\n",
            "Epoch: 0957 loss_train: 0.7473 acc_train: 0.8000 loss_val: 0.9305 acc_val: 0.7400 time: 0.0190s\n",
            "41\n",
            "Epoch: 0958 loss_train: 0.7767 acc_train: 0.8750 loss_val: 0.9377 acc_val: 0.7400 time: 0.0189s\n",
            "42\n",
            "Epoch: 0959 loss_train: 0.8094 acc_train: 0.8083 loss_val: 0.9468 acc_val: 0.7380 time: 0.0215s\n",
            "43\n",
            "Epoch: 0960 loss_train: 0.8031 acc_train: 0.8500 loss_val: 0.9474 acc_val: 0.7320 time: 0.0205s\n",
            "44\n",
            "Epoch: 0961 loss_train: 0.7549 acc_train: 0.8833 loss_val: 0.9465 acc_val: 0.7320 time: 0.0203s\n",
            "45\n",
            "Epoch: 0962 loss_train: 0.7703 acc_train: 0.8000 loss_val: 0.9450 acc_val: 0.7200 time: 0.0190s\n",
            "46\n",
            "Epoch: 0963 loss_train: 0.7890 acc_train: 0.8167 loss_val: 0.9464 acc_val: 0.7200 time: 0.0191s\n",
            "47\n",
            "Epoch: 0964 loss_train: 0.7935 acc_train: 0.8583 loss_val: 0.9463 acc_val: 0.7180 time: 0.0198s\n",
            "48\n",
            "Epoch: 0965 loss_train: 0.8168 acc_train: 0.7917 loss_val: 0.9443 acc_val: 0.7180 time: 0.0189s\n",
            "49\n",
            "Epoch: 0966 loss_train: 0.8355 acc_train: 0.8167 loss_val: 0.9410 acc_val: 0.7260 time: 0.0197s\n",
            "50\n",
            "Epoch: 0967 loss_train: 0.7946 acc_train: 0.8333 loss_val: 0.9388 acc_val: 0.7280 time: 0.0189s\n",
            "51\n",
            "Epoch: 0968 loss_train: 0.7288 acc_train: 0.8833 loss_val: 0.9378 acc_val: 0.7340 time: 0.0194s\n",
            "52\n",
            "Epoch: 0969 loss_train: 0.7980 acc_train: 0.8500 loss_val: 0.9424 acc_val: 0.7360 time: 0.0215s\n",
            "53\n",
            "Epoch: 0970 loss_train: 0.8166 acc_train: 0.7750 loss_val: 0.9435 acc_val: 0.7380 time: 0.0209s\n",
            "54\n",
            "Epoch: 0971 loss_train: 0.8091 acc_train: 0.8250 loss_val: 0.9395 acc_val: 0.7440 time: 0.0192s\n",
            "55\n",
            "Epoch: 0972 loss_train: 0.7840 acc_train: 0.8500 loss_val: 0.9378 acc_val: 0.7400 time: 0.0206s\n",
            "56\n",
            "Epoch: 0973 loss_train: 0.7760 acc_train: 0.8250 loss_val: 0.9361 acc_val: 0.7360 time: 0.0194s\n",
            "57\n",
            "Epoch: 0974 loss_train: 0.8027 acc_train: 0.8167 loss_val: 0.9363 acc_val: 0.7260 time: 0.0198s\n",
            "58\n",
            "Epoch: 0975 loss_train: 0.7932 acc_train: 0.8167 loss_val: 0.9396 acc_val: 0.7220 time: 0.0189s\n",
            "59\n",
            "Epoch: 0976 loss_train: 0.8076 acc_train: 0.8333 loss_val: 0.9420 acc_val: 0.7180 time: 0.0189s\n",
            "60\n",
            "Epoch: 0977 loss_train: 0.8238 acc_train: 0.7750 loss_val: 0.9409 acc_val: 0.7160 time: 0.0190s\n",
            "61\n",
            "Epoch: 0978 loss_train: 0.8061 acc_train: 0.8083 loss_val: 0.9388 acc_val: 0.7180 time: 0.0197s\n",
            "62\n",
            "Epoch: 0979 loss_train: 0.7487 acc_train: 0.8833 loss_val: 0.9372 acc_val: 0.7220 time: 0.0219s\n",
            "63\n",
            "Epoch: 0980 loss_train: 0.7612 acc_train: 0.8750 loss_val: 0.9375 acc_val: 0.7300 time: 0.0187s\n",
            "64\n",
            "Epoch: 0981 loss_train: 0.6705 acc_train: 0.8833 loss_val: 0.9367 acc_val: 0.7360 time: 0.0191s\n",
            "65\n",
            "Epoch: 0982 loss_train: 0.7703 acc_train: 0.8333 loss_val: 0.9404 acc_val: 0.7340 time: 0.0192s\n",
            "66\n",
            "Epoch: 0983 loss_train: 0.7644 acc_train: 0.8750 loss_val: 0.9398 acc_val: 0.7420 time: 0.0191s\n",
            "67\n",
            "Epoch: 0984 loss_train: 0.7965 acc_train: 0.8250 loss_val: 0.9368 acc_val: 0.7440 time: 0.0193s\n",
            "68\n",
            "Epoch: 0985 loss_train: 0.6989 acc_train: 0.8833 loss_val: 0.9323 acc_val: 0.7440 time: 0.0192s\n",
            "69\n",
            "Epoch: 0986 loss_train: 0.6984 acc_train: 0.8750 loss_val: 0.9298 acc_val: 0.7400 time: 0.0191s\n",
            "70\n",
            "Epoch: 0987 loss_train: 0.7223 acc_train: 0.8250 loss_val: 0.9297 acc_val: 0.7340 time: 0.0190s\n",
            "71\n",
            "Epoch: 0988 loss_train: 0.7228 acc_train: 0.8417 loss_val: 0.9300 acc_val: 0.7220 time: 0.0200s\n",
            "72\n",
            "Epoch: 0989 loss_train: 0.7697 acc_train: 0.8417 loss_val: 0.9329 acc_val: 0.7200 time: 0.0209s\n",
            "73\n",
            "Epoch: 0990 loss_train: 0.7948 acc_train: 0.8250 loss_val: 0.9385 acc_val: 0.7160 time: 0.0196s\n",
            "74\n",
            "Epoch: 0991 loss_train: 0.7712 acc_train: 0.8167 loss_val: 0.9448 acc_val: 0.7160 time: 0.0194s\n",
            "75\n",
            "Epoch: 0992 loss_train: 0.7991 acc_train: 0.8583 loss_val: 0.9487 acc_val: 0.7160 time: 0.0189s\n",
            "76\n",
            "Epoch: 0993 loss_train: 0.7806 acc_train: 0.8583 loss_val: 0.9501 acc_val: 0.7200 time: 0.0189s\n",
            "77\n",
            "Epoch: 0994 loss_train: 0.8071 acc_train: 0.8167 loss_val: 0.9514 acc_val: 0.7340 time: 0.0205s\n",
            "78\n",
            "Epoch: 0995 loss_train: 0.6928 acc_train: 0.9167 loss_val: 0.9482 acc_val: 0.7380 time: 0.0189s\n",
            "79\n",
            "Epoch: 0996 loss_train: 0.7255 acc_train: 0.8583 loss_val: 0.9407 acc_val: 0.7440 time: 0.0196s\n",
            "80\n",
            "Epoch: 0997 loss_train: 0.8504 acc_train: 0.8750 loss_val: 0.9328 acc_val: 0.7400 time: 0.0189s\n",
            "81\n",
            "Epoch: 0998 loss_train: 0.7450 acc_train: 0.7833 loss_val: 0.9261 acc_val: 0.7400 time: 0.0191s\n",
            "82\n",
            "Epoch: 0999 loss_train: 0.7733 acc_train: 0.7917 loss_val: 0.9243 acc_val: 0.7400 time: 0.0208s\n",
            "83\n",
            "Epoch: 1000 loss_train: 0.7692 acc_train: 0.8167 loss_val: 0.9231 acc_val: 0.7440 time: 0.0189s\n",
            "0\n",
            "Epoch: 1001 loss_train: 0.6948 acc_train: 0.8917 loss_val: 0.9249 acc_val: 0.7380 time: 0.0187s\n",
            "0\n",
            "Epoch: 1002 loss_train: 0.7548 acc_train: 0.8500 loss_val: 0.9296 acc_val: 0.7360 time: 0.0190s\n",
            "1\n",
            "Epoch: 1003 loss_train: 0.7381 acc_train: 0.8833 loss_val: 0.9378 acc_val: 0.7220 time: 0.0189s\n",
            "2\n",
            "Epoch: 1004 loss_train: 0.8074 acc_train: 0.8000 loss_val: 0.9492 acc_val: 0.7180 time: 0.0190s\n",
            "3\n",
            "Epoch: 1005 loss_train: 0.7334 acc_train: 0.8250 loss_val: 0.9613 acc_val: 0.7140 time: 0.0189s\n",
            "4\n",
            "Epoch: 1006 loss_train: 0.8319 acc_train: 0.8333 loss_val: 0.9645 acc_val: 0.7120 time: 0.0186s\n",
            "5\n",
            "Epoch: 1007 loss_train: 0.7033 acc_train: 0.8667 loss_val: 0.9595 acc_val: 0.7140 time: 0.0189s\n",
            "6\n",
            "Epoch: 1008 loss_train: 0.7420 acc_train: 0.8833 loss_val: 0.9521 acc_val: 0.7160 time: 0.0196s\n",
            "7\n",
            "Epoch: 1009 loss_train: 0.7316 acc_train: 0.8417 loss_val: 0.9447 acc_val: 0.7240 time: 0.0198s\n",
            "8\n",
            "Epoch: 1010 loss_train: 0.7737 acc_train: 0.8000 loss_val: 0.9365 acc_val: 0.7380 time: 0.0210s\n",
            "9\n",
            "Epoch: 1011 loss_train: 0.7491 acc_train: 0.8417 loss_val: 0.9310 acc_val: 0.7360 time: 0.0191s\n",
            "10\n",
            "Epoch: 1012 loss_train: 0.7609 acc_train: 0.8500 loss_val: 0.9312 acc_val: 0.7300 time: 0.0206s\n",
            "11\n",
            "Epoch: 1013 loss_train: 0.7821 acc_train: 0.8583 loss_val: 0.9327 acc_val: 0.7300 time: 0.0194s\n",
            "12\n",
            "Epoch: 1014 loss_train: 0.8270 acc_train: 0.7333 loss_val: 0.9319 acc_val: 0.7380 time: 0.0191s\n",
            "13\n",
            "Epoch: 1015 loss_train: 0.7126 acc_train: 0.8667 loss_val: 0.9335 acc_val: 0.7400 time: 0.0191s\n",
            "14\n",
            "Epoch: 1016 loss_train: 0.8264 acc_train: 0.8500 loss_val: 0.9364 acc_val: 0.7380 time: 0.0191s\n",
            "15\n",
            "Epoch: 1017 loss_train: 0.6935 acc_train: 0.9000 loss_val: 0.9392 acc_val: 0.7300 time: 0.0191s\n",
            "16\n",
            "Epoch: 1018 loss_train: 0.8022 acc_train: 0.8083 loss_val: 0.9430 acc_val: 0.7280 time: 0.0196s\n",
            "17\n",
            "Epoch: 1019 loss_train: 0.8524 acc_train: 0.8167 loss_val: 0.9422 acc_val: 0.7260 time: 0.0194s\n",
            "18\n",
            "Epoch: 1020 loss_train: 0.8002 acc_train: 0.8500 loss_val: 0.9404 acc_val: 0.7240 time: 0.0202s\n",
            "19\n",
            "Epoch: 1021 loss_train: 0.8185 acc_train: 0.7333 loss_val: 0.9385 acc_val: 0.7220 time: 0.0188s\n",
            "20\n",
            "Epoch: 1022 loss_train: 0.8575 acc_train: 0.8250 loss_val: 0.9395 acc_val: 0.7300 time: 0.0190s\n",
            "21\n",
            "Epoch: 1023 loss_train: 0.6864 acc_train: 0.8750 loss_val: 0.9423 acc_val: 0.7360 time: 0.0188s\n",
            "22\n",
            "Epoch: 1024 loss_train: 0.7335 acc_train: 0.9000 loss_val: 0.9406 acc_val: 0.7360 time: 0.0190s\n",
            "23\n",
            "Epoch: 1025 loss_train: 0.8007 acc_train: 0.8333 loss_val: 0.9371 acc_val: 0.7420 time: 0.0189s\n",
            "24\n",
            "Epoch: 1026 loss_train: 0.8415 acc_train: 0.8500 loss_val: 0.9359 acc_val: 0.7460 time: 0.0189s\n",
            "25\n",
            "Epoch: 1027 loss_train: 0.7576 acc_train: 0.8083 loss_val: 0.9356 acc_val: 0.7400 time: 0.0206s\n",
            "0\n",
            "Epoch: 1028 loss_train: 0.7669 acc_train: 0.7833 loss_val: 0.9393 acc_val: 0.7360 time: 0.0190s\n",
            "1\n",
            "Epoch: 1029 loss_train: 0.8508 acc_train: 0.8167 loss_val: 0.9407 acc_val: 0.7320 time: 0.0208s\n",
            "2\n",
            "Epoch: 1030 loss_train: 0.7840 acc_train: 0.8000 loss_val: 0.9427 acc_val: 0.7300 time: 0.0189s\n",
            "3\n",
            "Epoch: 1031 loss_train: 0.7759 acc_train: 0.8333 loss_val: 0.9433 acc_val: 0.7220 time: 0.0189s\n",
            "4\n",
            "Epoch: 1032 loss_train: 0.7491 acc_train: 0.8833 loss_val: 0.9419 acc_val: 0.7260 time: 0.0189s\n",
            "5\n",
            "Epoch: 1033 loss_train: 0.8493 acc_train: 0.8417 loss_val: 0.9389 acc_val: 0.7220 time: 0.0194s\n",
            "6\n",
            "Epoch: 1034 loss_train: 0.7153 acc_train: 0.8500 loss_val: 0.9358 acc_val: 0.7340 time: 0.0189s\n",
            "7\n",
            "Epoch: 1035 loss_train: 0.8139 acc_train: 0.8083 loss_val: 0.9321 acc_val: 0.7380 time: 0.0189s\n",
            "8\n",
            "Epoch: 1036 loss_train: 0.7134 acc_train: 0.8833 loss_val: 0.9301 acc_val: 0.7400 time: 0.0189s\n",
            "9\n",
            "Epoch: 1037 loss_train: 0.7858 acc_train: 0.8000 loss_val: 0.9308 acc_val: 0.7420 time: 0.0191s\n",
            "10\n",
            "Epoch: 1038 loss_train: 0.8584 acc_train: 0.8083 loss_val: 0.9369 acc_val: 0.7380 time: 0.0190s\n",
            "11\n",
            "Epoch: 1039 loss_train: 0.7411 acc_train: 0.8417 loss_val: 0.9423 acc_val: 0.7320 time: 0.0192s\n",
            "12\n",
            "Epoch: 1040 loss_train: 0.7917 acc_train: 0.8417 loss_val: 0.9456 acc_val: 0.7300 time: 0.0191s\n",
            "13\n",
            "Epoch: 1041 loss_train: 0.7905 acc_train: 0.8333 loss_val: 0.9445 acc_val: 0.7300 time: 0.0186s\n",
            "14\n",
            "Epoch: 1042 loss_train: 0.7645 acc_train: 0.8417 loss_val: 0.9410 acc_val: 0.7340 time: 0.0200s\n",
            "15\n",
            "Epoch: 1043 loss_train: 0.8083 acc_train: 0.8167 loss_val: 0.9386 acc_val: 0.7360 time: 0.0190s\n",
            "16\n",
            "Epoch: 1044 loss_train: 0.8136 acc_train: 0.7667 loss_val: 0.9353 acc_val: 0.7340 time: 0.0186s\n",
            "17\n",
            "Epoch: 1045 loss_train: 0.7932 acc_train: 0.8000 loss_val: 0.9348 acc_val: 0.7340 time: 0.0195s\n",
            "18\n",
            "Epoch: 1046 loss_train: 0.8425 acc_train: 0.8083 loss_val: 0.9342 acc_val: 0.7360 time: 0.0190s\n",
            "19\n",
            "Epoch: 1047 loss_train: 0.7964 acc_train: 0.8333 loss_val: 0.9342 acc_val: 0.7360 time: 0.0189s\n",
            "20\n",
            "Epoch: 1048 loss_train: 0.7859 acc_train: 0.9083 loss_val: 0.9335 acc_val: 0.7400 time: 0.0188s\n",
            "21\n",
            "Epoch: 1049 loss_train: 0.7085 acc_train: 0.8917 loss_val: 0.9343 acc_val: 0.7380 time: 0.0234s\n",
            "22\n",
            "Epoch: 1050 loss_train: 0.8263 acc_train: 0.8167 loss_val: 0.9389 acc_val: 0.7380 time: 0.0203s\n",
            "23\n",
            "Epoch: 1051 loss_train: 0.7829 acc_train: 0.8833 loss_val: 0.9464 acc_val: 0.7360 time: 0.0205s\n",
            "24\n",
            "Epoch: 1052 loss_train: 0.7252 acc_train: 0.9167 loss_val: 0.9510 acc_val: 0.7380 time: 0.0190s\n",
            "25\n",
            "Epoch: 1053 loss_train: 0.7634 acc_train: 0.8667 loss_val: 0.9494 acc_val: 0.7360 time: 0.0191s\n",
            "26\n",
            "Epoch: 1054 loss_train: 0.7743 acc_train: 0.8667 loss_val: 0.9452 acc_val: 0.7380 time: 0.0204s\n",
            "27\n",
            "Epoch: 1055 loss_train: 0.8009 acc_train: 0.8250 loss_val: 0.9373 acc_val: 0.7360 time: 0.0196s\n",
            "28\n",
            "Epoch: 1056 loss_train: 0.7760 acc_train: 0.8667 loss_val: 0.9295 acc_val: 0.7380 time: 0.0207s\n",
            "29\n",
            "Epoch: 1057 loss_train: 0.7843 acc_train: 0.8333 loss_val: 0.9234 acc_val: 0.7400 time: 0.0189s\n",
            "30\n",
            "Epoch: 1058 loss_train: 0.7875 acc_train: 0.8000 loss_val: 0.9207 acc_val: 0.7420 time: 0.0189s\n",
            "31\n",
            "Epoch: 1059 loss_train: 0.7776 acc_train: 0.8500 loss_val: 0.9224 acc_val: 0.7440 time: 0.0188s\n",
            "0\n",
            "Epoch: 1060 loss_train: 0.7648 acc_train: 0.8083 loss_val: 0.9246 acc_val: 0.7380 time: 0.0189s\n",
            "1\n",
            "Epoch: 1061 loss_train: 0.7942 acc_train: 0.8750 loss_val: 0.9323 acc_val: 0.7440 time: 0.0192s\n",
            "2\n",
            "Epoch: 1062 loss_train: 0.8458 acc_train: 0.8333 loss_val: 0.9444 acc_val: 0.7340 time: 0.0189s\n",
            "3\n",
            "Epoch: 1063 loss_train: 0.7696 acc_train: 0.8417 loss_val: 0.9556 acc_val: 0.7240 time: 0.0190s\n",
            "4\n",
            "Epoch: 1064 loss_train: 0.7946 acc_train: 0.9250 loss_val: 0.9577 acc_val: 0.7240 time: 0.0210s\n",
            "5\n",
            "Epoch: 1065 loss_train: 0.7775 acc_train: 0.8417 loss_val: 0.9543 acc_val: 0.7240 time: 0.0191s\n",
            "6\n",
            "Epoch: 1066 loss_train: 0.7985 acc_train: 0.7917 loss_val: 0.9476 acc_val: 0.7220 time: 0.0197s\n",
            "7\n",
            "Epoch: 1067 loss_train: 0.8039 acc_train: 0.8000 loss_val: 0.9370 acc_val: 0.7360 time: 0.0199s\n",
            "8\n",
            "Epoch: 1068 loss_train: 0.7793 acc_train: 0.8000 loss_val: 0.9315 acc_val: 0.7380 time: 0.0203s\n",
            "9\n",
            "Epoch: 1069 loss_train: 0.7841 acc_train: 0.8333 loss_val: 0.9273 acc_val: 0.7380 time: 0.0199s\n",
            "10\n",
            "Epoch: 1070 loss_train: 0.7566 acc_train: 0.8000 loss_val: 0.9244 acc_val: 0.7440 time: 0.0192s\n",
            "11\n",
            "Epoch: 1071 loss_train: 0.8259 acc_train: 0.8417 loss_val: 0.9244 acc_val: 0.7420 time: 0.0190s\n",
            "12\n",
            "Epoch: 1072 loss_train: 0.7436 acc_train: 0.9000 loss_val: 0.9264 acc_val: 0.7420 time: 0.0201s\n",
            "13\n",
            "Epoch: 1073 loss_train: 0.7975 acc_train: 0.8500 loss_val: 0.9294 acc_val: 0.7380 time: 0.0193s\n",
            "14\n",
            "Epoch: 1074 loss_train: 0.8316 acc_train: 0.8000 loss_val: 0.9316 acc_val: 0.7400 time: 0.0190s\n",
            "15\n",
            "Epoch: 1075 loss_train: 0.7998 acc_train: 0.8250 loss_val: 0.9336 acc_val: 0.7380 time: 0.0202s\n",
            "16\n",
            "Epoch: 1076 loss_train: 0.7479 acc_train: 0.9167 loss_val: 0.9347 acc_val: 0.7400 time: 0.0185s\n",
            "17\n",
            "Epoch: 1077 loss_train: 0.8012 acc_train: 0.8500 loss_val: 0.9332 acc_val: 0.7460 time: 0.0190s\n",
            "18\n",
            "Epoch: 1078 loss_train: 0.7601 acc_train: 0.8583 loss_val: 0.9320 acc_val: 0.7400 time: 0.0190s\n",
            "0\n",
            "Epoch: 1079 loss_train: 0.7568 acc_train: 0.8833 loss_val: 0.9286 acc_val: 0.7360 time: 0.0211s\n",
            "1\n",
            "Epoch: 1080 loss_train: 0.7132 acc_train: 0.9083 loss_val: 0.9268 acc_val: 0.7400 time: 0.0189s\n",
            "2\n",
            "Epoch: 1081 loss_train: 0.6890 acc_train: 0.8500 loss_val: 0.9251 acc_val: 0.7440 time: 0.0207s\n",
            "3\n",
            "Epoch: 1082 loss_train: 0.7443 acc_train: 0.8250 loss_val: 0.9244 acc_val: 0.7460 time: 0.0190s\n",
            "4\n",
            "Epoch: 1083 loss_train: 0.7533 acc_train: 0.8250 loss_val: 0.9254 acc_val: 0.7300 time: 0.0190s\n",
            "0\n",
            "Epoch: 1084 loss_train: 0.7608 acc_train: 0.7917 loss_val: 0.9257 acc_val: 0.7340 time: 0.0189s\n",
            "1\n",
            "Epoch: 1085 loss_train: 0.8145 acc_train: 0.8500 loss_val: 0.9268 acc_val: 0.7320 time: 0.0189s\n",
            "2\n",
            "Epoch: 1086 loss_train: 0.7352 acc_train: 0.8583 loss_val: 0.9303 acc_val: 0.7360 time: 0.0189s\n",
            "3\n",
            "Epoch: 1087 loss_train: 0.7264 acc_train: 0.8500 loss_val: 0.9354 acc_val: 0.7300 time: 0.0189s\n",
            "4\n",
            "Epoch: 1088 loss_train: 0.7535 acc_train: 0.8417 loss_val: 0.9383 acc_val: 0.7300 time: 0.0189s\n",
            "5\n",
            "Epoch: 1089 loss_train: 0.7988 acc_train: 0.8167 loss_val: 0.9356 acc_val: 0.7420 time: 0.0195s\n",
            "6\n",
            "Epoch: 1090 loss_train: 0.6918 acc_train: 0.9167 loss_val: 0.9287 acc_val: 0.7420 time: 0.0190s\n",
            "7\n",
            "Epoch: 1091 loss_train: 0.7343 acc_train: 0.8750 loss_val: 0.9261 acc_val: 0.7420 time: 0.0188s\n",
            "8\n",
            "Epoch: 1092 loss_train: 0.7595 acc_train: 0.8667 loss_val: 0.9258 acc_val: 0.7380 time: 0.0189s\n",
            "9\n",
            "Epoch: 1093 loss_train: 0.7527 acc_train: 0.8917 loss_val: 0.9250 acc_val: 0.7360 time: 0.0189s\n",
            "10\n",
            "Epoch: 1094 loss_train: 0.8424 acc_train: 0.8583 loss_val: 0.9262 acc_val: 0.7400 time: 0.0194s\n",
            "11\n",
            "Epoch: 1095 loss_train: 0.8602 acc_train: 0.7500 loss_val: 0.9306 acc_val: 0.7400 time: 0.0195s\n",
            "12\n",
            "Epoch: 1096 loss_train: 0.8103 acc_train: 0.8000 loss_val: 0.9385 acc_val: 0.7300 time: 0.0189s\n",
            "13\n",
            "Epoch: 1097 loss_train: 0.8549 acc_train: 0.8167 loss_val: 0.9443 acc_val: 0.7280 time: 0.0189s\n",
            "14\n",
            "Epoch: 1098 loss_train: 0.8257 acc_train: 0.8083 loss_val: 0.9466 acc_val: 0.7280 time: 0.0189s\n",
            "15\n",
            "Epoch: 1099 loss_train: 0.8113 acc_train: 0.8333 loss_val: 0.9458 acc_val: 0.7340 time: 0.0245s\n",
            "16\n",
            "Epoch: 1100 loss_train: 0.7639 acc_train: 0.8250 loss_val: 0.9412 acc_val: 0.7380 time: 0.0191s\n",
            "17\n",
            "Epoch: 1101 loss_train: 0.8359 acc_train: 0.8333 loss_val: 0.9353 acc_val: 0.7380 time: 0.0203s\n",
            "18\n",
            "Epoch: 1102 loss_train: 0.7963 acc_train: 0.8250 loss_val: 0.9328 acc_val: 0.7380 time: 0.0197s\n",
            "19\n",
            "Epoch: 1103 loss_train: 0.7851 acc_train: 0.8750 loss_val: 0.9291 acc_val: 0.7460 time: 0.0204s\n",
            "20\n",
            "Epoch: 1104 loss_train: 0.7139 acc_train: 0.8583 loss_val: 0.9249 acc_val: 0.7460 time: 0.0195s\n",
            "0\n",
            "Epoch: 1105 loss_train: 0.7642 acc_train: 0.9000 loss_val: 0.9225 acc_val: 0.7420 time: 0.0191s\n",
            "0\n",
            "Epoch: 1106 loss_train: 0.7593 acc_train: 0.8583 loss_val: 0.9221 acc_val: 0.7380 time: 0.0189s\n",
            "1\n",
            "Epoch: 1107 loss_train: 0.7965 acc_train: 0.7667 loss_val: 0.9241 acc_val: 0.7380 time: 0.0190s\n",
            "2\n",
            "Epoch: 1108 loss_train: 0.7680 acc_train: 0.8417 loss_val: 0.9265 acc_val: 0.7360 time: 0.0186s\n",
            "3\n",
            "Epoch: 1109 loss_train: 0.7511 acc_train: 0.8583 loss_val: 0.9288 acc_val: 0.7340 time: 0.0202s\n",
            "4\n",
            "Epoch: 1110 loss_train: 0.7653 acc_train: 0.8750 loss_val: 0.9298 acc_val: 0.7340 time: 0.0201s\n",
            "5\n",
            "Epoch: 1111 loss_train: 0.7557 acc_train: 0.8250 loss_val: 0.9330 acc_val: 0.7260 time: 0.0192s\n",
            "6\n",
            "Epoch: 1112 loss_train: 0.7233 acc_train: 0.8500 loss_val: 0.9376 acc_val: 0.7260 time: 0.0199s\n",
            "7\n",
            "Epoch: 1113 loss_train: 0.7768 acc_train: 0.8333 loss_val: 0.9387 acc_val: 0.7260 time: 0.0189s\n",
            "8\n",
            "Epoch: 1114 loss_train: 0.7293 acc_train: 0.8583 loss_val: 0.9382 acc_val: 0.7200 time: 0.0189s\n",
            "9\n",
            "Epoch: 1115 loss_train: 0.7666 acc_train: 0.8417 loss_val: 0.9348 acc_val: 0.7220 time: 0.0189s\n",
            "10\n",
            "Epoch: 1116 loss_train: 0.7730 acc_train: 0.8417 loss_val: 0.9296 acc_val: 0.7320 time: 0.0189s\n",
            "11\n",
            "Epoch: 1117 loss_train: 0.8843 acc_train: 0.8333 loss_val: 0.9264 acc_val: 0.7360 time: 0.0189s\n",
            "12\n",
            "Epoch: 1118 loss_train: 0.7996 acc_train: 0.8583 loss_val: 0.9244 acc_val: 0.7340 time: 0.0200s\n",
            "13\n",
            "Epoch: 1119 loss_train: 0.8277 acc_train: 0.8083 loss_val: 0.9243 acc_val: 0.7360 time: 0.0223s\n",
            "14\n",
            "Epoch: 1120 loss_train: 0.8161 acc_train: 0.8667 loss_val: 0.9285 acc_val: 0.7460 time: 0.0199s\n",
            "15\n",
            "Epoch: 1121 loss_train: 0.7627 acc_train: 0.8583 loss_val: 0.9329 acc_val: 0.7420 time: 0.0196s\n",
            "0\n",
            "Epoch: 1122 loss_train: 0.7520 acc_train: 0.8500 loss_val: 0.9333 acc_val: 0.7420 time: 0.0194s\n",
            "1\n",
            "Epoch: 1123 loss_train: 0.8302 acc_train: 0.8417 loss_val: 0.9336 acc_val: 0.7420 time: 0.0194s\n",
            "2\n",
            "Epoch: 1124 loss_train: 0.7852 acc_train: 0.8083 loss_val: 0.9320 acc_val: 0.7420 time: 0.0198s\n",
            "3\n",
            "Epoch: 1125 loss_train: 0.8155 acc_train: 0.8250 loss_val: 0.9293 acc_val: 0.7360 time: 0.0191s\n",
            "4\n",
            "Epoch: 1126 loss_train: 0.7748 acc_train: 0.8333 loss_val: 0.9261 acc_val: 0.7400 time: 0.0219s\n",
            "5\n",
            "Epoch: 1127 loss_train: 0.7656 acc_train: 0.9000 loss_val: 0.9251 acc_val: 0.7320 time: 0.0189s\n",
            "6\n",
            "Epoch: 1128 loss_train: 0.7132 acc_train: 0.9000 loss_val: 0.9261 acc_val: 0.7360 time: 0.0189s\n",
            "7\n",
            "Epoch: 1129 loss_train: 0.7449 acc_train: 0.8417 loss_val: 0.9287 acc_val: 0.7360 time: 0.0192s\n",
            "8\n",
            "Epoch: 1130 loss_train: 0.7977 acc_train: 0.8250 loss_val: 0.9323 acc_val: 0.7360 time: 0.0189s\n",
            "9\n",
            "Epoch: 1131 loss_train: 0.7763 acc_train: 0.8250 loss_val: 0.9354 acc_val: 0.7340 time: 0.0193s\n",
            "10\n",
            "Epoch: 1132 loss_train: 0.8083 acc_train: 0.8417 loss_val: 0.9381 acc_val: 0.7340 time: 0.0203s\n",
            "11\n",
            "Epoch: 1133 loss_train: 0.7999 acc_train: 0.8500 loss_val: 0.9390 acc_val: 0.7320 time: 0.0194s\n",
            "12\n",
            "Epoch: 1134 loss_train: 0.7445 acc_train: 0.8500 loss_val: 0.9386 acc_val: 0.7300 time: 0.0194s\n",
            "13\n",
            "Epoch: 1135 loss_train: 0.8271 acc_train: 0.7917 loss_val: 0.9386 acc_val: 0.7300 time: 0.0189s\n",
            "14\n",
            "Epoch: 1136 loss_train: 0.7505 acc_train: 0.8250 loss_val: 0.9399 acc_val: 0.7320 time: 0.0205s\n",
            "15\n",
            "Epoch: 1137 loss_train: 0.7430 acc_train: 0.8333 loss_val: 0.9384 acc_val: 0.7320 time: 0.0189s\n",
            "16\n",
            "Epoch: 1138 loss_train: 0.7671 acc_train: 0.8583 loss_val: 0.9309 acc_val: 0.7260 time: 0.0192s\n",
            "17\n",
            "Epoch: 1139 loss_train: 0.7828 acc_train: 0.8000 loss_val: 0.9274 acc_val: 0.7280 time: 0.0214s\n",
            "18\n",
            "Epoch: 1140 loss_train: 0.8073 acc_train: 0.8250 loss_val: 0.9270 acc_val: 0.7380 time: 0.0191s\n",
            "19\n",
            "Epoch: 1141 loss_train: 0.7506 acc_train: 0.8333 loss_val: 0.9285 acc_val: 0.7340 time: 0.0190s\n",
            "20\n",
            "Epoch: 1142 loss_train: 0.7445 acc_train: 0.8667 loss_val: 0.9303 acc_val: 0.7360 time: 0.0195s\n",
            "21\n",
            "Epoch: 1143 loss_train: 0.8040 acc_train: 0.8000 loss_val: 0.9336 acc_val: 0.7380 time: 0.0191s\n",
            "22\n",
            "Epoch: 1144 loss_train: 0.7468 acc_train: 0.8917 loss_val: 0.9365 acc_val: 0.7360 time: 0.0190s\n",
            "23\n",
            "Epoch: 1145 loss_train: 0.7457 acc_train: 0.8583 loss_val: 0.9351 acc_val: 0.7420 time: 0.0191s\n",
            "24\n",
            "Epoch: 1146 loss_train: 0.7725 acc_train: 0.8167 loss_val: 0.9381 acc_val: 0.7380 time: 0.0190s\n",
            "25\n",
            "Epoch: 1147 loss_train: 0.8153 acc_train: 0.7667 loss_val: 0.9410 acc_val: 0.7400 time: 0.0190s\n",
            "26\n",
            "Epoch: 1148 loss_train: 0.7959 acc_train: 0.8417 loss_val: 0.9423 acc_val: 0.7380 time: 0.0189s\n",
            "27\n",
            "Epoch: 1149 loss_train: 0.8105 acc_train: 0.8333 loss_val: 0.9427 acc_val: 0.7360 time: 0.0288s\n",
            "28\n",
            "Epoch: 1150 loss_train: 0.7539 acc_train: 0.8583 loss_val: 0.9427 acc_val: 0.7340 time: 0.0193s\n",
            "29\n",
            "Epoch: 1151 loss_train: 0.7417 acc_train: 0.8167 loss_val: 0.9425 acc_val: 0.7200 time: 0.0193s\n",
            "30\n",
            "Epoch: 1152 loss_train: 0.7916 acc_train: 0.8667 loss_val: 0.9401 acc_val: 0.7180 time: 0.0208s\n",
            "31\n",
            "Epoch: 1153 loss_train: 0.7622 acc_train: 0.9167 loss_val: 0.9359 acc_val: 0.7240 time: 0.0208s\n",
            "32\n",
            "Epoch: 1154 loss_train: 0.7634 acc_train: 0.8750 loss_val: 0.9312 acc_val: 0.7220 time: 0.0188s\n",
            "33\n",
            "Epoch: 1155 loss_train: 0.7233 acc_train: 0.8333 loss_val: 0.9259 acc_val: 0.7300 time: 0.0192s\n",
            "34\n",
            "Epoch: 1156 loss_train: 0.6966 acc_train: 0.8917 loss_val: 0.9203 acc_val: 0.7380 time: 0.0191s\n",
            "35\n",
            "Epoch: 1157 loss_train: 0.8453 acc_train: 0.7833 loss_val: 0.9202 acc_val: 0.7460 time: 0.0188s\n",
            "0\n",
            "Epoch: 1158 loss_train: 0.7662 acc_train: 0.8417 loss_val: 0.9251 acc_val: 0.7480 time: 0.0194s\n",
            "0\n",
            "Epoch: 1159 loss_train: 0.7240 acc_train: 0.8667 loss_val: 0.9350 acc_val: 0.7400 time: 0.0192s\n",
            "0\n",
            "Epoch: 1160 loss_train: 0.8003 acc_train: 0.7917 loss_val: 0.9444 acc_val: 0.7440 time: 0.0189s\n",
            "1\n",
            "Epoch: 1161 loss_train: 0.7821 acc_train: 0.7917 loss_val: 0.9504 acc_val: 0.7360 time: 0.0203s\n",
            "2\n",
            "Epoch: 1162 loss_train: 0.7212 acc_train: 0.8417 loss_val: 0.9535 acc_val: 0.7260 time: 0.0189s\n",
            "3\n",
            "Epoch: 1163 loss_train: 0.8198 acc_train: 0.8000 loss_val: 0.9534 acc_val: 0.7180 time: 0.0192s\n",
            "4\n",
            "Epoch: 1164 loss_train: 0.8239 acc_train: 0.7417 loss_val: 0.9472 acc_val: 0.7200 time: 0.0196s\n",
            "5\n",
            "Epoch: 1165 loss_train: 0.7597 acc_train: 0.8250 loss_val: 0.9406 acc_val: 0.7300 time: 0.0189s\n",
            "6\n",
            "Epoch: 1166 loss_train: 0.8347 acc_train: 0.8000 loss_val: 0.9340 acc_val: 0.7340 time: 0.0190s\n",
            "7\n",
            "Epoch: 1167 loss_train: 0.8224 acc_train: 0.8083 loss_val: 0.9288 acc_val: 0.7380 time: 0.0208s\n",
            "8\n",
            "Epoch: 1168 loss_train: 0.7950 acc_train: 0.8250 loss_val: 0.9250 acc_val: 0.7440 time: 0.0202s\n",
            "9\n",
            "Epoch: 1169 loss_train: 0.8142 acc_train: 0.8000 loss_val: 0.9249 acc_val: 0.7440 time: 0.0186s\n",
            "10\n",
            "Epoch: 1170 loss_train: 0.7884 acc_train: 0.7917 loss_val: 0.9283 acc_val: 0.7460 time: 0.0189s\n",
            "11\n",
            "Epoch: 1171 loss_train: 0.7384 acc_train: 0.8250 loss_val: 0.9306 acc_val: 0.7440 time: 0.0191s\n",
            "12\n",
            "Epoch: 1172 loss_train: 0.6885 acc_train: 0.9500 loss_val: 0.9344 acc_val: 0.7440 time: 0.0190s\n",
            "13\n",
            "Epoch: 1173 loss_train: 0.7253 acc_train: 0.9000 loss_val: 0.9372 acc_val: 0.7360 time: 0.0196s\n",
            "14\n",
            "Epoch: 1174 loss_train: 0.7491 acc_train: 0.8583 loss_val: 0.9422 acc_val: 0.7340 time: 0.0189s\n",
            "15\n",
            "Epoch: 1175 loss_train: 0.8100 acc_train: 0.8500 loss_val: 0.9452 acc_val: 0.7320 time: 0.0204s\n",
            "16\n",
            "Epoch: 1176 loss_train: 0.7855 acc_train: 0.8500 loss_val: 0.9482 acc_val: 0.7340 time: 0.0202s\n",
            "17\n",
            "Epoch: 1177 loss_train: 0.7584 acc_train: 0.8750 loss_val: 0.9461 acc_val: 0.7320 time: 0.0189s\n",
            "18\n",
            "Epoch: 1178 loss_train: 0.7457 acc_train: 0.8583 loss_val: 0.9448 acc_val: 0.7340 time: 0.0208s\n",
            "19\n",
            "Epoch: 1179 loss_train: 0.7330 acc_train: 0.8667 loss_val: 0.9418 acc_val: 0.7360 time: 0.0194s\n",
            "20\n",
            "Epoch: 1180 loss_train: 0.7575 acc_train: 0.8583 loss_val: 0.9359 acc_val: 0.7380 time: 0.0189s\n",
            "21\n",
            "Epoch: 1181 loss_train: 0.8054 acc_train: 0.8417 loss_val: 0.9320 acc_val: 0.7340 time: 0.0203s\n",
            "22\n",
            "Epoch: 1182 loss_train: 0.8211 acc_train: 0.8417 loss_val: 0.9300 acc_val: 0.7360 time: 0.0191s\n",
            "23\n",
            "Epoch: 1183 loss_train: 0.7303 acc_train: 0.8250 loss_val: 0.9287 acc_val: 0.7360 time: 0.0204s\n",
            "24\n",
            "Epoch: 1184 loss_train: 0.8379 acc_train: 0.8417 loss_val: 0.9272 acc_val: 0.7360 time: 0.0191s\n",
            "25\n",
            "Epoch: 1185 loss_train: 0.7644 acc_train: 0.8000 loss_val: 0.9275 acc_val: 0.7420 time: 0.0189s\n",
            "26\n",
            "Epoch: 1186 loss_train: 0.7616 acc_train: 0.8667 loss_val: 0.9308 acc_val: 0.7420 time: 0.0189s\n",
            "27\n",
            "Epoch: 1187 loss_train: 0.7266 acc_train: 0.8417 loss_val: 0.9364 acc_val: 0.7400 time: 0.0185s\n",
            "28\n",
            "Epoch: 1188 loss_train: 0.8060 acc_train: 0.8333 loss_val: 0.9413 acc_val: 0.7400 time: 0.0201s\n",
            "29\n",
            "Epoch: 1189 loss_train: 0.7483 acc_train: 0.8583 loss_val: 0.9396 acc_val: 0.7420 time: 0.0191s\n",
            "30\n",
            "Epoch: 1190 loss_train: 0.7595 acc_train: 0.8167 loss_val: 0.9374 acc_val: 0.7400 time: 0.0189s\n",
            "31\n",
            "Epoch: 1191 loss_train: 0.8498 acc_train: 0.7667 loss_val: 0.9358 acc_val: 0.7440 time: 0.0189s\n",
            "32\n",
            "Epoch: 1192 loss_train: 0.7986 acc_train: 0.7833 loss_val: 0.9344 acc_val: 0.7420 time: 0.0193s\n",
            "33\n",
            "Epoch: 1193 loss_train: 0.8144 acc_train: 0.8250 loss_val: 0.9331 acc_val: 0.7380 time: 0.0189s\n",
            "34\n",
            "Epoch: 1194 loss_train: 0.8006 acc_train: 0.8083 loss_val: 0.9365 acc_val: 0.7360 time: 0.0190s\n",
            "35\n",
            "Epoch: 1195 loss_train: 0.7389 acc_train: 0.8500 loss_val: 0.9372 acc_val: 0.7340 time: 0.0190s\n",
            "36\n",
            "Epoch: 1196 loss_train: 0.8419 acc_train: 0.8333 loss_val: 0.9345 acc_val: 0.7320 time: 0.0194s\n",
            "37\n",
            "Epoch: 1197 loss_train: 0.7522 acc_train: 0.8583 loss_val: 0.9302 acc_val: 0.7360 time: 0.0192s\n",
            "38\n",
            "Epoch: 1198 loss_train: 0.7729 acc_train: 0.8333 loss_val: 0.9275 acc_val: 0.7380 time: 0.0193s\n",
            "39\n",
            "Epoch: 1199 loss_train: 0.7634 acc_train: 0.8667 loss_val: 0.9263 acc_val: 0.7420 time: 0.0203s\n",
            "40\n",
            "Epoch: 1200 loss_train: 0.8392 acc_train: 0.8250 loss_val: 0.9299 acc_val: 0.7380 time: 0.0188s\n",
            "41\n",
            "Epoch: 1201 loss_train: 0.7999 acc_train: 0.8333 loss_val: 0.9351 acc_val: 0.7340 time: 0.0189s\n",
            "42\n",
            "Epoch: 1202 loss_train: 0.7479 acc_train: 0.8583 loss_val: 0.9394 acc_val: 0.7320 time: 0.0189s\n",
            "43\n",
            "Epoch: 1203 loss_train: 0.7549 acc_train: 0.8500 loss_val: 0.9411 acc_val: 0.7380 time: 0.0191s\n",
            "44\n",
            "Epoch: 1204 loss_train: 0.7599 acc_train: 0.8833 loss_val: 0.9450 acc_val: 0.7240 time: 0.0190s\n",
            "45\n",
            "Epoch: 1205 loss_train: 0.8259 acc_train: 0.8083 loss_val: 0.9457 acc_val: 0.7200 time: 0.0191s\n",
            "46\n",
            "Epoch: 1206 loss_train: 0.7698 acc_train: 0.8333 loss_val: 0.9443 acc_val: 0.7300 time: 0.0190s\n",
            "47\n",
            "Epoch: 1207 loss_train: 0.7674 acc_train: 0.8333 loss_val: 0.9436 acc_val: 0.7280 time: 0.0189s\n",
            "48\n",
            "Epoch: 1208 loss_train: 0.7903 acc_train: 0.8667 loss_val: 0.9383 acc_val: 0.7320 time: 0.0197s\n",
            "49\n",
            "Epoch: 1209 loss_train: 0.8449 acc_train: 0.8083 loss_val: 0.9309 acc_val: 0.7360 time: 0.0195s\n",
            "50\n",
            "Epoch: 1210 loss_train: 0.6840 acc_train: 0.8667 loss_val: 0.9257 acc_val: 0.7420 time: 0.0188s\n",
            "51\n",
            "Epoch: 1211 loss_train: 0.7879 acc_train: 0.8167 loss_val: 0.9239 acc_val: 0.7420 time: 0.0189s\n",
            "52\n",
            "Epoch: 1212 loss_train: 0.7236 acc_train: 0.8583 loss_val: 0.9250 acc_val: 0.7440 time: 0.0189s\n",
            "53\n",
            "Epoch: 1213 loss_train: 0.8788 acc_train: 0.8250 loss_val: 0.9294 acc_val: 0.7420 time: 0.0186s\n",
            "54\n",
            "Epoch: 1214 loss_train: 0.7694 acc_train: 0.8250 loss_val: 0.9386 acc_val: 0.7380 time: 0.0190s\n",
            "55\n",
            "Epoch: 1215 loss_train: 0.8164 acc_train: 0.8333 loss_val: 0.9521 acc_val: 0.7360 time: 0.0189s\n",
            "56\n",
            "Epoch: 1216 loss_train: 0.7539 acc_train: 0.8750 loss_val: 0.9618 acc_val: 0.7260 time: 0.0189s\n",
            "57\n",
            "Epoch: 1217 loss_train: 0.7385 acc_train: 0.8333 loss_val: 0.9622 acc_val: 0.7240 time: 0.0190s\n",
            "58\n",
            "Epoch: 1218 loss_train: 0.7949 acc_train: 0.8083 loss_val: 0.9535 acc_val: 0.7260 time: 0.0209s\n",
            "59\n",
            "Epoch: 1219 loss_train: 0.7488 acc_train: 0.8500 loss_val: 0.9411 acc_val: 0.7280 time: 0.0202s\n",
            "60\n",
            "Epoch: 1220 loss_train: 0.7782 acc_train: 0.8250 loss_val: 0.9319 acc_val: 0.7240 time: 0.0189s\n",
            "61\n",
            "Epoch: 1221 loss_train: 0.7966 acc_train: 0.8333 loss_val: 0.9271 acc_val: 0.7320 time: 0.0191s\n",
            "62\n",
            "Epoch: 1222 loss_train: 0.8310 acc_train: 0.8083 loss_val: 0.9264 acc_val: 0.7300 time: 0.0189s\n",
            "63\n",
            "Epoch: 1223 loss_train: 0.7897 acc_train: 0.8083 loss_val: 0.9273 acc_val: 0.7320 time: 0.0189s\n",
            "64\n",
            "Epoch: 1224 loss_train: 0.7772 acc_train: 0.8917 loss_val: 0.9286 acc_val: 0.7320 time: 0.0191s\n",
            "65\n",
            "Epoch: 1225 loss_train: 0.7586 acc_train: 0.8917 loss_val: 0.9323 acc_val: 0.7320 time: 0.0188s\n",
            "66\n",
            "Epoch: 1226 loss_train: 0.7840 acc_train: 0.8583 loss_val: 0.9426 acc_val: 0.7220 time: 0.0189s\n",
            "67\n",
            "Epoch: 1227 loss_train: 0.7844 acc_train: 0.8750 loss_val: 0.9532 acc_val: 0.7180 time: 0.0185s\n",
            "68\n",
            "Epoch: 1228 loss_train: 0.7801 acc_train: 0.8000 loss_val: 0.9570 acc_val: 0.7200 time: 0.0215s\n",
            "69\n",
            "Epoch: 1229 loss_train: 0.7845 acc_train: 0.8500 loss_val: 0.9517 acc_val: 0.7300 time: 0.0197s\n",
            "70\n",
            "Epoch: 1230 loss_train: 0.8284 acc_train: 0.8333 loss_val: 0.9390 acc_val: 0.7340 time: 0.0196s\n",
            "71\n",
            "Epoch: 1231 loss_train: 0.7976 acc_train: 0.8750 loss_val: 0.9289 acc_val: 0.7360 time: 0.0218s\n",
            "72\n",
            "Epoch: 1232 loss_train: 0.7950 acc_train: 0.7917 loss_val: 0.9244 acc_val: 0.7380 time: 0.0197s\n",
            "73\n",
            "Epoch: 1233 loss_train: 0.7534 acc_train: 0.8833 loss_val: 0.9224 acc_val: 0.7400 time: 0.0193s\n",
            "74\n",
            "Epoch: 1234 loss_train: 0.7777 acc_train: 0.8417 loss_val: 0.9235 acc_val: 0.7340 time: 0.0193s\n",
            "75\n",
            "Epoch: 1235 loss_train: 0.7669 acc_train: 0.8583 loss_val: 0.9257 acc_val: 0.7340 time: 0.0191s\n",
            "76\n",
            "Epoch: 1236 loss_train: 0.8247 acc_train: 0.7917 loss_val: 0.9313 acc_val: 0.7340 time: 0.0191s\n",
            "77\n",
            "Epoch: 1237 loss_train: 0.7686 acc_train: 0.8167 loss_val: 0.9384 acc_val: 0.7300 time: 0.0189s\n",
            "78\n",
            "Epoch: 1238 loss_train: 0.6873 acc_train: 0.8833 loss_val: 0.9443 acc_val: 0.7240 time: 0.0212s\n",
            "79\n",
            "Epoch: 1239 loss_train: 0.8038 acc_train: 0.8083 loss_val: 0.9432 acc_val: 0.7260 time: 0.0189s\n",
            "80\n",
            "Epoch: 1240 loss_train: 0.7043 acc_train: 0.8667 loss_val: 0.9419 acc_val: 0.7260 time: 0.0189s\n",
            "81\n",
            "Epoch: 1241 loss_train: 0.7859 acc_train: 0.8000 loss_val: 0.9426 acc_val: 0.7340 time: 0.0189s\n",
            "82\n",
            "Epoch: 1242 loss_train: 0.8504 acc_train: 0.7917 loss_val: 0.9407 acc_val: 0.7340 time: 0.0205s\n",
            "83\n",
            "Epoch: 1243 loss_train: 0.8376 acc_train: 0.8167 loss_val: 0.9390 acc_val: 0.7380 time: 0.0197s\n",
            "84\n",
            "Epoch: 1244 loss_train: 0.8164 acc_train: 0.8333 loss_val: 0.9364 acc_val: 0.7340 time: 0.0190s\n",
            "85\n",
            "Epoch: 1245 loss_train: 0.7589 acc_train: 0.8417 loss_val: 0.9321 acc_val: 0.7380 time: 0.0192s\n",
            "86\n",
            "Epoch: 1246 loss_train: 0.7766 acc_train: 0.8083 loss_val: 0.9275 acc_val: 0.7380 time: 0.0190s\n",
            "87\n",
            "Epoch: 1247 loss_train: 0.7883 acc_train: 0.8750 loss_val: 0.9239 acc_val: 0.7380 time: 0.0192s\n",
            "88\n",
            "Epoch: 1248 loss_train: 0.7900 acc_train: 0.8417 loss_val: 0.9239 acc_val: 0.7400 time: 0.0227s\n",
            "89\n",
            "Epoch: 1249 loss_train: 0.7288 acc_train: 0.8583 loss_val: 0.9247 acc_val: 0.7340 time: 0.0197s\n",
            "90\n",
            "Epoch: 1250 loss_train: 0.7788 acc_train: 0.8750 loss_val: 0.9270 acc_val: 0.7320 time: 0.0191s\n",
            "91\n",
            "Epoch: 1251 loss_train: 0.7721 acc_train: 0.8583 loss_val: 0.9325 acc_val: 0.7360 time: 0.0193s\n",
            "92\n",
            "Epoch: 1252 loss_train: 0.7304 acc_train: 0.9083 loss_val: 0.9367 acc_val: 0.7340 time: 0.0205s\n",
            "93\n",
            "Epoch: 1253 loss_train: 0.7760 acc_train: 0.8583 loss_val: 0.9370 acc_val: 0.7300 time: 0.0192s\n",
            "94\n",
            "Epoch: 1254 loss_train: 0.7462 acc_train: 0.8000 loss_val: 0.9324 acc_val: 0.7320 time: 0.0198s\n",
            "95\n",
            "Epoch: 1255 loss_train: 0.8162 acc_train: 0.7917 loss_val: 0.9276 acc_val: 0.7360 time: 0.0191s\n",
            "96\n",
            "Epoch: 1256 loss_train: 0.7608 acc_train: 0.8583 loss_val: 0.9245 acc_val: 0.7420 time: 0.0190s\n",
            "97\n",
            "Epoch: 1257 loss_train: 0.7860 acc_train: 0.8583 loss_val: 0.9257 acc_val: 0.7460 time: 0.0190s\n",
            "98\n",
            "Epoch: 1258 loss_train: 0.8061 acc_train: 0.8333 loss_val: 0.9301 acc_val: 0.7420 time: 0.0195s\n",
            "99\n",
            "Epoch: 1259 loss_train: 0.7751 acc_train: 0.8417 loss_val: 0.9320 acc_val: 0.7440 time: 0.0189s\n",
            "100\n",
            "Epoch: 1260 loss_train: 0.7482 acc_train: 0.8250 loss_val: 0.9321 acc_val: 0.7420 time: 0.0189s\n",
            "101\n",
            "Epoch: 1261 loss_train: 0.7595 acc_train: 0.8667 loss_val: 0.9267 acc_val: 0.7440 time: 0.0189s\n",
            "102\n",
            "Epoch: 1262 loss_train: 0.7124 acc_train: 0.8500 loss_val: 0.9222 acc_val: 0.7460 time: 0.0189s\n",
            "103\n",
            "Epoch: 1263 loss_train: 0.8788 acc_train: 0.7917 loss_val: 0.9247 acc_val: 0.7420 time: 0.0192s\n",
            "104\n",
            "Epoch: 1264 loss_train: 0.7919 acc_train: 0.8083 loss_val: 0.9287 acc_val: 0.7400 time: 0.0190s\n",
            "105\n",
            "Epoch: 1265 loss_train: 0.7713 acc_train: 0.7917 loss_val: 0.9360 acc_val: 0.7360 time: 0.0223s\n",
            "106\n",
            "Epoch: 1266 loss_train: 0.7803 acc_train: 0.8167 loss_val: 0.9440 acc_val: 0.7260 time: 0.0194s\n",
            "107\n",
            "Epoch: 1267 loss_train: 0.7535 acc_train: 0.8167 loss_val: 0.9446 acc_val: 0.7260 time: 0.0201s\n",
            "108\n",
            "Epoch: 1268 loss_train: 0.7768 acc_train: 0.8083 loss_val: 0.9400 acc_val: 0.7280 time: 0.0199s\n",
            "109\n",
            "Epoch: 1269 loss_train: 0.8442 acc_train: 0.8333 loss_val: 0.9344 acc_val: 0.7320 time: 0.0195s\n",
            "110\n",
            "Epoch: 1270 loss_train: 0.8380 acc_train: 0.8083 loss_val: 0.9282 acc_val: 0.7420 time: 0.0193s\n",
            "111\n",
            "Epoch: 1271 loss_train: 0.7672 acc_train: 0.8417 loss_val: 0.9230 acc_val: 0.7500 time: 0.0189s\n",
            "112\n",
            "Epoch: 1272 loss_train: 0.7489 acc_train: 0.8167 loss_val: 0.9220 acc_val: 0.7460 time: 0.0189s\n",
            "0\n",
            "Epoch: 1273 loss_train: 0.7555 acc_train: 0.8583 loss_val: 0.9213 acc_val: 0.7480 time: 0.0194s\n",
            "1\n",
            "Epoch: 1274 loss_train: 0.7275 acc_train: 0.8583 loss_val: 0.9245 acc_val: 0.7440 time: 0.0191s\n",
            "2\n",
            "Epoch: 1275 loss_train: 0.7919 acc_train: 0.8250 loss_val: 0.9330 acc_val: 0.7400 time: 0.0193s\n",
            "3\n",
            "Epoch: 1276 loss_train: 0.7702 acc_train: 0.8333 loss_val: 0.9428 acc_val: 0.7340 time: 0.0194s\n",
            "4\n",
            "Epoch: 1277 loss_train: 0.7460 acc_train: 0.8667 loss_val: 0.9535 acc_val: 0.7260 time: 0.0190s\n",
            "5\n",
            "Epoch: 1278 loss_train: 0.8073 acc_train: 0.8583 loss_val: 0.9610 acc_val: 0.7240 time: 0.0223s\n",
            "6\n",
            "Epoch: 1279 loss_train: 0.7588 acc_train: 0.8583 loss_val: 0.9591 acc_val: 0.7220 time: 0.0189s\n",
            "7\n",
            "Epoch: 1280 loss_train: 0.7531 acc_train: 0.7833 loss_val: 0.9493 acc_val: 0.7300 time: 0.0190s\n",
            "8\n",
            "Epoch: 1281 loss_train: 0.7417 acc_train: 0.8250 loss_val: 0.9387 acc_val: 0.7260 time: 0.0190s\n",
            "9\n",
            "Epoch: 1282 loss_train: 0.8104 acc_train: 0.8417 loss_val: 0.9267 acc_val: 0.7380 time: 0.0190s\n",
            "10\n",
            "Epoch: 1283 loss_train: 0.7618 acc_train: 0.8417 loss_val: 0.9181 acc_val: 0.7420 time: 0.0189s\n",
            "11\n",
            "Epoch: 1284 loss_train: 0.8262 acc_train: 0.8750 loss_val: 0.9149 acc_val: 0.7420 time: 0.0187s\n",
            "0\n",
            "Epoch: 1285 loss_train: 0.7911 acc_train: 0.8250 loss_val: 0.9145 acc_val: 0.7500 time: 0.0187s\n",
            "0\n",
            "Epoch: 1286 loss_train: 0.7536 acc_train: 0.8750 loss_val: 0.9164 acc_val: 0.7480 time: 0.0187s\n",
            "0\n",
            "Epoch: 1287 loss_train: 0.7569 acc_train: 0.8000 loss_val: 0.9206 acc_val: 0.7400 time: 0.0190s\n",
            "1\n",
            "Epoch: 1288 loss_train: 0.6848 acc_train: 0.8750 loss_val: 0.9252 acc_val: 0.7380 time: 0.0205s\n",
            "2\n",
            "Epoch: 1289 loss_train: 0.7967 acc_train: 0.8417 loss_val: 0.9320 acc_val: 0.7360 time: 0.0192s\n",
            "3\n",
            "Epoch: 1290 loss_train: 0.8023 acc_train: 0.7667 loss_val: 0.9393 acc_val: 0.7260 time: 0.0192s\n",
            "4\n",
            "Epoch: 1291 loss_train: 0.7988 acc_train: 0.8250 loss_val: 0.9507 acc_val: 0.7200 time: 0.0203s\n",
            "5\n",
            "Epoch: 1292 loss_train: 0.7898 acc_train: 0.7667 loss_val: 0.9529 acc_val: 0.7200 time: 0.0195s\n",
            "6\n",
            "Epoch: 1293 loss_train: 0.7644 acc_train: 0.8417 loss_val: 0.9470 acc_val: 0.7220 time: 0.0191s\n",
            "7\n",
            "Epoch: 1294 loss_train: 0.7235 acc_train: 0.8500 loss_val: 0.9362 acc_val: 0.7320 time: 0.0191s\n",
            "8\n",
            "Epoch: 1295 loss_train: 0.7751 acc_train: 0.8167 loss_val: 0.9303 acc_val: 0.7340 time: 0.0189s\n",
            "9\n",
            "Epoch: 1296 loss_train: 0.7975 acc_train: 0.7833 loss_val: 0.9247 acc_val: 0.7440 time: 0.0206s\n",
            "10\n",
            "Epoch: 1297 loss_train: 0.7513 acc_train: 0.8667 loss_val: 0.9238 acc_val: 0.7360 time: 0.0193s\n",
            "11\n",
            "Epoch: 1298 loss_train: 0.8558 acc_train: 0.8083 loss_val: 0.9293 acc_val: 0.7380 time: 0.0196s\n",
            "12\n",
            "Epoch: 1299 loss_train: 0.7699 acc_train: 0.8417 loss_val: 0.9387 acc_val: 0.7280 time: 0.0189s\n",
            "13\n",
            "Epoch: 1300 loss_train: 0.8369 acc_train: 0.8417 loss_val: 0.9459 acc_val: 0.7200 time: 0.0191s\n",
            "14\n",
            "Epoch: 1301 loss_train: 0.7780 acc_train: 0.8250 loss_val: 0.9510 acc_val: 0.7240 time: 0.0191s\n",
            "15\n",
            "Epoch: 1302 loss_train: 0.7113 acc_train: 0.8750 loss_val: 0.9526 acc_val: 0.7220 time: 0.0193s\n",
            "16\n",
            "Epoch: 1303 loss_train: 0.7230 acc_train: 0.8417 loss_val: 0.9499 acc_val: 0.7280 time: 0.0209s\n",
            "17\n",
            "Epoch: 1304 loss_train: 0.7872 acc_train: 0.8750 loss_val: 0.9469 acc_val: 0.7300 time: 0.0191s\n",
            "18\n",
            "Epoch: 1305 loss_train: 0.7770 acc_train: 0.8083 loss_val: 0.9364 acc_val: 0.7340 time: 0.0190s\n",
            "19\n",
            "Epoch: 1306 loss_train: 0.7393 acc_train: 0.8333 loss_val: 0.9248 acc_val: 0.7420 time: 0.0190s\n",
            "20\n",
            "Epoch: 1307 loss_train: 0.6998 acc_train: 0.9000 loss_val: 0.9183 acc_val: 0.7480 time: 0.0190s\n",
            "21\n",
            "Epoch: 1308 loss_train: 0.7529 acc_train: 0.8583 loss_val: 0.9175 acc_val: 0.7540 time: 0.0210s\n",
            "22\n",
            "Epoch: 1309 loss_train: 0.7533 acc_train: 0.8667 loss_val: 0.9205 acc_val: 0.7460 time: 0.0190s\n",
            "0\n",
            "Epoch: 1310 loss_train: 0.8066 acc_train: 0.8417 loss_val: 0.9291 acc_val: 0.7400 time: 0.0190s\n",
            "1\n",
            "Epoch: 1311 loss_train: 0.7792 acc_train: 0.8417 loss_val: 0.9400 acc_val: 0.7380 time: 0.0191s\n",
            "2\n",
            "Epoch: 1312 loss_train: 0.7629 acc_train: 0.8333 loss_val: 0.9443 acc_val: 0.7400 time: 0.0198s\n",
            "3\n",
            "Epoch: 1313 loss_train: 0.7806 acc_train: 0.8500 loss_val: 0.9479 acc_val: 0.7420 time: 0.0190s\n",
            "4\n",
            "Epoch: 1314 loss_train: 0.7424 acc_train: 0.8000 loss_val: 0.9477 acc_val: 0.7340 time: 0.0202s\n",
            "5\n",
            "Epoch: 1315 loss_train: 0.7872 acc_train: 0.8083 loss_val: 0.9420 acc_val: 0.7280 time: 0.0190s\n",
            "6\n",
            "Epoch: 1316 loss_train: 0.7985 acc_train: 0.8667 loss_val: 0.9384 acc_val: 0.7260 time: 0.0190s\n",
            "7\n",
            "Epoch: 1317 loss_train: 0.6933 acc_train: 0.8667 loss_val: 0.9337 acc_val: 0.7360 time: 0.0190s\n",
            "8\n",
            "Epoch: 1318 loss_train: 0.7843 acc_train: 0.8167 loss_val: 0.9306 acc_val: 0.7360 time: 0.0226s\n",
            "9\n",
            "Epoch: 1319 loss_train: 0.7650 acc_train: 0.8500 loss_val: 0.9322 acc_val: 0.7400 time: 0.0208s\n",
            "10\n",
            "Epoch: 1320 loss_train: 0.8052 acc_train: 0.8083 loss_val: 0.9315 acc_val: 0.7320 time: 0.0193s\n",
            "11\n",
            "Epoch: 1321 loss_train: 0.7862 acc_train: 0.8833 loss_val: 0.9351 acc_val: 0.7360 time: 0.0188s\n",
            "12\n",
            "Epoch: 1322 loss_train: 0.7493 acc_train: 0.8583 loss_val: 0.9386 acc_val: 0.7380 time: 0.0192s\n",
            "13\n",
            "Epoch: 1323 loss_train: 0.8007 acc_train: 0.8500 loss_val: 0.9439 acc_val: 0.7380 time: 0.0190s\n",
            "14\n",
            "Epoch: 1324 loss_train: 0.7454 acc_train: 0.8667 loss_val: 0.9460 acc_val: 0.7360 time: 0.0192s\n",
            "15\n",
            "Epoch: 1325 loss_train: 0.7693 acc_train: 0.8833 loss_val: 0.9472 acc_val: 0.7360 time: 0.0186s\n",
            "16\n",
            "Epoch: 1326 loss_train: 0.8933 acc_train: 0.7750 loss_val: 0.9428 acc_val: 0.7320 time: 0.0202s\n",
            "17\n",
            "Epoch: 1327 loss_train: 0.8030 acc_train: 0.8417 loss_val: 0.9396 acc_val: 0.7320 time: 0.0203s\n",
            "18\n",
            "Epoch: 1328 loss_train: 0.6900 acc_train: 0.9000 loss_val: 0.9399 acc_val: 0.7280 time: 0.0198s\n",
            "19\n",
            "Epoch: 1329 loss_train: 0.7959 acc_train: 0.8083 loss_val: 0.9391 acc_val: 0.7260 time: 0.0206s\n",
            "20\n",
            "Epoch: 1330 loss_train: 0.8030 acc_train: 0.8417 loss_val: 0.9355 acc_val: 0.7280 time: 0.0194s\n",
            "21\n",
            "Epoch: 1331 loss_train: 0.7575 acc_train: 0.8500 loss_val: 0.9323 acc_val: 0.7260 time: 0.0191s\n",
            "22\n",
            "Epoch: 1332 loss_train: 0.7710 acc_train: 0.8333 loss_val: 0.9314 acc_val: 0.7300 time: 0.0190s\n",
            "23\n",
            "Epoch: 1333 loss_train: 0.8052 acc_train: 0.8500 loss_val: 0.9338 acc_val: 0.7320 time: 0.0190s\n",
            "24\n",
            "Epoch: 1334 loss_train: 0.8199 acc_train: 0.8417 loss_val: 0.9360 acc_val: 0.7320 time: 0.0189s\n",
            "25\n",
            "Epoch: 1335 loss_train: 0.7724 acc_train: 0.8750 loss_val: 0.9369 acc_val: 0.7340 time: 0.0189s\n",
            "26\n",
            "Epoch: 1336 loss_train: 0.7018 acc_train: 0.8833 loss_val: 0.9327 acc_val: 0.7420 time: 0.0200s\n",
            "27\n",
            "Epoch: 1337 loss_train: 0.7672 acc_train: 0.8167 loss_val: 0.9280 acc_val: 0.7420 time: 0.0192s\n",
            "28\n",
            "Epoch: 1338 loss_train: 0.7343 acc_train: 0.8417 loss_val: 0.9261 acc_val: 0.7400 time: 0.0198s\n",
            "29\n",
            "Epoch: 1339 loss_train: 0.7609 acc_train: 0.8083 loss_val: 0.9258 acc_val: 0.7420 time: 0.0190s\n",
            "30\n",
            "Epoch: 1340 loss_train: 0.7779 acc_train: 0.8333 loss_val: 0.9319 acc_val: 0.7380 time: 0.0191s\n",
            "31\n",
            "Epoch: 1341 loss_train: 0.8039 acc_train: 0.8083 loss_val: 0.9378 acc_val: 0.7380 time: 0.0189s\n",
            "32\n",
            "Epoch: 1342 loss_train: 0.7408 acc_train: 0.8333 loss_val: 0.9430 acc_val: 0.7300 time: 0.0191s\n",
            "33\n",
            "Epoch: 1343 loss_train: 0.7590 acc_train: 0.8417 loss_val: 0.9428 acc_val: 0.7280 time: 0.0190s\n",
            "34\n",
            "Epoch: 1344 loss_train: 0.7256 acc_train: 0.8667 loss_val: 0.9408 acc_val: 0.7300 time: 0.0189s\n",
            "35\n",
            "Epoch: 1345 loss_train: 0.8032 acc_train: 0.7833 loss_val: 0.9402 acc_val: 0.7320 time: 0.0195s\n",
            "36\n",
            "Epoch: 1346 loss_train: 0.7048 acc_train: 0.8750 loss_val: 0.9369 acc_val: 0.7340 time: 0.0189s\n",
            "37\n",
            "Epoch: 1347 loss_train: 0.7162 acc_train: 0.8500 loss_val: 0.9334 acc_val: 0.7360 time: 0.0198s\n",
            "38\n",
            "Epoch: 1348 loss_train: 0.7825 acc_train: 0.8250 loss_val: 0.9304 acc_val: 0.7400 time: 0.0202s\n",
            "39\n",
            "Epoch: 1349 loss_train: 0.8065 acc_train: 0.8333 loss_val: 0.9288 acc_val: 0.7340 time: 0.0215s\n",
            "40\n",
            "Epoch: 1350 loss_train: 0.8009 acc_train: 0.8417 loss_val: 0.9310 acc_val: 0.7340 time: 0.0191s\n",
            "41\n",
            "Epoch: 1351 loss_train: 0.7830 acc_train: 0.8250 loss_val: 0.9400 acc_val: 0.7380 time: 0.0195s\n",
            "42\n",
            "Epoch: 1352 loss_train: 0.8110 acc_train: 0.8333 loss_val: 0.9476 acc_val: 0.7380 time: 0.0193s\n",
            "43\n",
            "Epoch: 1353 loss_train: 0.8330 acc_train: 0.8667 loss_val: 0.9511 acc_val: 0.7300 time: 0.0204s\n",
            "44\n",
            "Epoch: 1354 loss_train: 0.7911 acc_train: 0.8750 loss_val: 0.9480 acc_val: 0.7320 time: 0.0190s\n",
            "45\n",
            "Epoch: 1355 loss_train: 0.7502 acc_train: 0.8250 loss_val: 0.9441 acc_val: 0.7260 time: 0.0188s\n",
            "46\n",
            "Epoch: 1356 loss_train: 0.7705 acc_train: 0.8333 loss_val: 0.9400 acc_val: 0.7280 time: 0.0189s\n",
            "47\n",
            "Epoch: 1357 loss_train: 0.8277 acc_train: 0.8333 loss_val: 0.9376 acc_val: 0.7320 time: 0.0207s\n",
            "48\n",
            "Epoch: 1358 loss_train: 0.7654 acc_train: 0.8667 loss_val: 0.9356 acc_val: 0.7320 time: 0.0195s\n",
            "49\n",
            "Epoch: 1359 loss_train: 0.7546 acc_train: 0.8583 loss_val: 0.9334 acc_val: 0.7320 time: 0.0191s\n",
            "50\n",
            "Epoch: 1360 loss_train: 0.8128 acc_train: 0.7667 loss_val: 0.9292 acc_val: 0.7380 time: 0.0190s\n",
            "51\n",
            "Epoch: 1361 loss_train: 0.7373 acc_train: 0.8333 loss_val: 0.9265 acc_val: 0.7380 time: 0.0190s\n",
            "52\n",
            "Epoch: 1362 loss_train: 0.8239 acc_train: 0.7667 loss_val: 0.9280 acc_val: 0.7380 time: 0.0189s\n",
            "53\n",
            "Epoch: 1363 loss_train: 0.7997 acc_train: 0.8250 loss_val: 0.9311 acc_val: 0.7360 time: 0.0191s\n",
            "54\n",
            "Epoch: 1364 loss_train: 0.7135 acc_train: 0.8667 loss_val: 0.9380 acc_val: 0.7360 time: 0.0189s\n",
            "55\n",
            "Epoch: 1365 loss_train: 0.8375 acc_train: 0.7750 loss_val: 0.9454 acc_val: 0.7340 time: 0.0190s\n",
            "56\n",
            "Epoch: 1366 loss_train: 0.7635 acc_train: 0.8667 loss_val: 0.9550 acc_val: 0.7280 time: 0.0189s\n",
            "57\n",
            "Epoch: 1367 loss_train: 0.8260 acc_train: 0.8417 loss_val: 0.9580 acc_val: 0.7260 time: 0.0190s\n",
            "58\n",
            "Epoch: 1368 loss_train: 0.8088 acc_train: 0.8333 loss_val: 0.9552 acc_val: 0.7200 time: 0.0216s\n",
            "59\n",
            "Epoch: 1369 loss_train: 0.7689 acc_train: 0.8333 loss_val: 0.9494 acc_val: 0.7220 time: 0.0207s\n",
            "60\n",
            "Epoch: 1370 loss_train: 0.8293 acc_train: 0.7750 loss_val: 0.9407 acc_val: 0.7300 time: 0.0189s\n",
            "61\n",
            "Epoch: 1371 loss_train: 0.7740 acc_train: 0.8417 loss_val: 0.9331 acc_val: 0.7380 time: 0.0190s\n",
            "62\n",
            "Epoch: 1372 loss_train: 0.7502 acc_train: 0.8750 loss_val: 0.9296 acc_val: 0.7380 time: 0.0190s\n",
            "63\n",
            "Epoch: 1373 loss_train: 0.8486 acc_train: 0.8250 loss_val: 0.9301 acc_val: 0.7360 time: 0.0190s\n",
            "64\n",
            "Epoch: 1374 loss_train: 0.7856 acc_train: 0.7917 loss_val: 0.9322 acc_val: 0.7300 time: 0.0189s\n",
            "65\n",
            "Epoch: 1375 loss_train: 0.7406 acc_train: 0.8333 loss_val: 0.9317 acc_val: 0.7360 time: 0.0186s\n",
            "66\n",
            "Epoch: 1376 loss_train: 0.8008 acc_train: 0.7917 loss_val: 0.9307 acc_val: 0.7360 time: 0.0196s\n",
            "67\n",
            "Epoch: 1377 loss_train: 0.8141 acc_train: 0.8333 loss_val: 0.9295 acc_val: 0.7360 time: 0.0190s\n",
            "68\n",
            "Epoch: 1378 loss_train: 0.6955 acc_train: 0.8833 loss_val: 0.9296 acc_val: 0.7380 time: 0.0210s\n",
            "69\n",
            "Epoch: 1379 loss_train: 0.7690 acc_train: 0.8833 loss_val: 0.9306 acc_val: 0.7360 time: 0.0190s\n",
            "70\n",
            "Epoch: 1380 loss_train: 0.8231 acc_train: 0.8583 loss_val: 0.9314 acc_val: 0.7320 time: 0.0192s\n",
            "71\n",
            "Epoch: 1381 loss_train: 0.7183 acc_train: 0.8500 loss_val: 0.9321 acc_val: 0.7320 time: 0.0191s\n",
            "72\n",
            "Epoch: 1382 loss_train: 0.7672 acc_train: 0.8250 loss_val: 0.9317 acc_val: 0.7360 time: 0.0188s\n",
            "73\n",
            "Epoch: 1383 loss_train: 0.8434 acc_train: 0.8250 loss_val: 0.9336 acc_val: 0.7400 time: 0.0191s\n",
            "74\n",
            "Epoch: 1384 loss_train: 0.6923 acc_train: 0.9000 loss_val: 0.9360 acc_val: 0.7360 time: 0.0221s\n",
            "75\n",
            "Epoch: 1385 loss_train: 0.7700 acc_train: 0.8583 loss_val: 0.9397 acc_val: 0.7360 time: 0.0189s\n",
            "76\n",
            "Epoch: 1386 loss_train: 0.8315 acc_train: 0.7667 loss_val: 0.9443 acc_val: 0.7360 time: 0.0191s\n",
            "77\n",
            "Epoch: 1387 loss_train: 0.7503 acc_train: 0.8500 loss_val: 0.9455 acc_val: 0.7340 time: 0.0185s\n",
            "78\n",
            "Epoch: 1388 loss_train: 0.7916 acc_train: 0.8583 loss_val: 0.9414 acc_val: 0.7360 time: 0.0201s\n",
            "79\n",
            "Epoch: 1389 loss_train: 0.7474 acc_train: 0.8000 loss_val: 0.9386 acc_val: 0.7400 time: 0.0200s\n",
            "80\n",
            "Epoch: 1390 loss_train: 0.8087 acc_train: 0.8500 loss_val: 0.9382 acc_val: 0.7400 time: 0.0200s\n",
            "81\n",
            "Epoch: 1391 loss_train: 0.7614 acc_train: 0.8417 loss_val: 0.9383 acc_val: 0.7440 time: 0.0189s\n",
            "82\n",
            "Epoch: 1392 loss_train: 0.8479 acc_train: 0.8583 loss_val: 0.9370 acc_val: 0.7400 time: 0.0189s\n",
            "83\n",
            "Epoch: 1393 loss_train: 0.7995 acc_train: 0.8833 loss_val: 0.9367 acc_val: 0.7440 time: 0.0189s\n",
            "84\n",
            "Epoch: 1394 loss_train: 0.7513 acc_train: 0.8417 loss_val: 0.9365 acc_val: 0.7460 time: 0.0204s\n",
            "85\n",
            "Epoch: 1395 loss_train: 0.7717 acc_train: 0.8167 loss_val: 0.9355 acc_val: 0.7460 time: 0.0201s\n",
            "86\n",
            "Epoch: 1396 loss_train: 0.8140 acc_train: 0.7667 loss_val: 0.9394 acc_val: 0.7380 time: 0.0190s\n",
            "87\n",
            "Epoch: 1397 loss_train: 0.8022 acc_train: 0.8167 loss_val: 0.9428 acc_val: 0.7360 time: 0.0191s\n",
            "88\n",
            "Epoch: 1398 loss_train: 0.7332 acc_train: 0.8667 loss_val: 0.9456 acc_val: 0.7320 time: 0.0206s\n",
            "89\n",
            "Epoch: 1399 loss_train: 0.7146 acc_train: 0.8917 loss_val: 0.9458 acc_val: 0.7320 time: 0.0192s\n",
            "90\n",
            "Epoch: 1400 loss_train: 0.8238 acc_train: 0.8000 loss_val: 0.9428 acc_val: 0.7340 time: 0.0191s\n",
            "91\n",
            "Epoch: 1401 loss_train: 0.7061 acc_train: 0.8750 loss_val: 0.9369 acc_val: 0.7360 time: 0.0191s\n",
            "92\n",
            "Epoch: 1402 loss_train: 0.8201 acc_train: 0.8000 loss_val: 0.9320 acc_val: 0.7380 time: 0.0191s\n",
            "93\n",
            "Epoch: 1403 loss_train: 0.8210 acc_train: 0.8333 loss_val: 0.9283 acc_val: 0.7360 time: 0.0191s\n",
            "94\n",
            "Epoch: 1404 loss_train: 0.7886 acc_train: 0.8250 loss_val: 0.9260 acc_val: 0.7340 time: 0.0191s\n",
            "95\n",
            "Epoch: 1405 loss_train: 0.8030 acc_train: 0.8250 loss_val: 0.9261 acc_val: 0.7360 time: 0.0190s\n",
            "96\n",
            "Epoch: 1406 loss_train: 0.8066 acc_train: 0.8167 loss_val: 0.9278 acc_val: 0.7340 time: 0.0190s\n",
            "97\n",
            "Epoch: 1407 loss_train: 0.7463 acc_train: 0.8667 loss_val: 0.9281 acc_val: 0.7340 time: 0.0189s\n",
            "98\n",
            "Epoch: 1408 loss_train: 0.7264 acc_train: 0.8417 loss_val: 0.9310 acc_val: 0.7360 time: 0.0222s\n",
            "99\n",
            "Epoch: 1409 loss_train: 0.8037 acc_train: 0.8500 loss_val: 0.9340 acc_val: 0.7360 time: 0.0237s\n",
            "100\n",
            "Epoch: 1410 loss_train: 0.7864 acc_train: 0.8500 loss_val: 0.9422 acc_val: 0.7380 time: 0.0190s\n",
            "101\n",
            "Epoch: 1411 loss_train: 0.7855 acc_train: 0.8583 loss_val: 0.9517 acc_val: 0.7340 time: 0.0190s\n",
            "102\n",
            "Epoch: 1412 loss_train: 0.7116 acc_train: 0.8667 loss_val: 0.9558 acc_val: 0.7360 time: 0.0190s\n",
            "103\n",
            "Epoch: 1413 loss_train: 0.7917 acc_train: 0.7750 loss_val: 0.9505 acc_val: 0.7340 time: 0.0188s\n",
            "104\n",
            "Epoch: 1414 loss_train: 0.8547 acc_train: 0.8083 loss_val: 0.9410 acc_val: 0.7320 time: 0.0190s\n",
            "105\n",
            "Epoch: 1415 loss_train: 0.7821 acc_train: 0.8417 loss_val: 0.9364 acc_val: 0.7400 time: 0.0188s\n",
            "106\n",
            "Epoch: 1416 loss_train: 0.8117 acc_train: 0.8667 loss_val: 0.9320 acc_val: 0.7380 time: 0.0189s\n",
            "107\n",
            "Epoch: 1417 loss_train: 0.7290 acc_train: 0.8083 loss_val: 0.9324 acc_val: 0.7380 time: 0.0190s\n",
            "108\n",
            "Epoch: 1418 loss_train: 0.7084 acc_train: 0.8917 loss_val: 0.9325 acc_val: 0.7360 time: 0.0217s\n",
            "109\n",
            "Epoch: 1419 loss_train: 0.7847 acc_train: 0.8583 loss_val: 0.9388 acc_val: 0.7400 time: 0.0191s\n",
            "110\n",
            "Epoch: 1420 loss_train: 0.8170 acc_train: 0.8167 loss_val: 0.9465 acc_val: 0.7360 time: 0.0189s\n",
            "111\n",
            "Epoch: 1421 loss_train: 0.7312 acc_train: 0.9250 loss_val: 0.9511 acc_val: 0.7240 time: 0.0189s\n",
            "112\n",
            "Epoch: 1422 loss_train: 0.7540 acc_train: 0.8250 loss_val: 0.9495 acc_val: 0.7200 time: 0.0191s\n",
            "113\n",
            "Epoch: 1423 loss_train: 0.7958 acc_train: 0.7917 loss_val: 0.9489 acc_val: 0.7300 time: 0.0210s\n",
            "114\n",
            "Epoch: 1424 loss_train: 0.7842 acc_train: 0.8167 loss_val: 0.9471 acc_val: 0.7300 time: 0.0193s\n",
            "115\n",
            "Epoch: 1425 loss_train: 0.7846 acc_train: 0.7917 loss_val: 0.9472 acc_val: 0.7260 time: 0.0192s\n",
            "116\n",
            "Epoch: 1426 loss_train: 0.7205 acc_train: 0.8500 loss_val: 0.9429 acc_val: 0.7280 time: 0.0193s\n",
            "117\n",
            "Epoch: 1427 loss_train: 0.7149 acc_train: 0.8250 loss_val: 0.9360 acc_val: 0.7280 time: 0.0188s\n",
            "118\n",
            "Epoch: 1428 loss_train: 0.7802 acc_train: 0.8500 loss_val: 0.9305 acc_val: 0.7360 time: 0.0226s\n",
            "119\n",
            "Epoch: 1429 loss_train: 0.7808 acc_train: 0.8500 loss_val: 0.9296 acc_val: 0.7340 time: 0.0189s\n",
            "120\n",
            "Epoch: 1430 loss_train: 0.7350 acc_train: 0.8667 loss_val: 0.9339 acc_val: 0.7320 time: 0.0190s\n",
            "121\n",
            "Epoch: 1431 loss_train: 0.7790 acc_train: 0.8417 loss_val: 0.9435 acc_val: 0.7260 time: 0.0200s\n",
            "122\n",
            "Epoch: 1432 loss_train: 0.8419 acc_train: 0.7917 loss_val: 0.9515 acc_val: 0.7300 time: 0.0190s\n",
            "123\n",
            "Epoch: 1433 loss_train: 0.7392 acc_train: 0.8833 loss_val: 0.9597 acc_val: 0.7240 time: 0.0190s\n",
            "124\n",
            "Epoch: 1434 loss_train: 0.8605 acc_train: 0.8083 loss_val: 0.9581 acc_val: 0.7220 time: 0.0190s\n",
            "125\n",
            "Epoch: 1435 loss_train: 0.8236 acc_train: 0.8250 loss_val: 0.9521 acc_val: 0.7320 time: 0.0186s\n",
            "126\n",
            "Epoch: 1436 loss_train: 0.8251 acc_train: 0.8500 loss_val: 0.9456 acc_val: 0.7380 time: 0.0189s\n",
            "127\n",
            "Epoch: 1437 loss_train: 0.6288 acc_train: 0.9000 loss_val: 0.9427 acc_val: 0.7360 time: 0.0189s\n",
            "128\n",
            "Epoch: 1438 loss_train: 0.7678 acc_train: 0.8917 loss_val: 0.9379 acc_val: 0.7280 time: 0.0208s\n",
            "129\n",
            "Epoch: 1439 loss_train: 0.8309 acc_train: 0.8250 loss_val: 0.9366 acc_val: 0.7260 time: 0.0191s\n",
            "130\n",
            "Epoch: 1440 loss_train: 0.7375 acc_train: 0.8750 loss_val: 0.9356 acc_val: 0.7320 time: 0.0193s\n",
            "131\n",
            "Epoch: 1441 loss_train: 0.8103 acc_train: 0.8000 loss_val: 0.9369 acc_val: 0.7320 time: 0.0192s\n",
            "132\n",
            "Epoch: 1442 loss_train: 0.8160 acc_train: 0.8333 loss_val: 0.9410 acc_val: 0.7260 time: 0.0192s\n",
            "133\n",
            "Epoch: 1443 loss_train: 0.7874 acc_train: 0.7667 loss_val: 0.9484 acc_val: 0.7220 time: 0.0197s\n",
            "134\n",
            "Epoch: 1444 loss_train: 0.8017 acc_train: 0.8000 loss_val: 0.9547 acc_val: 0.7180 time: 0.0192s\n",
            "135\n",
            "Epoch: 1445 loss_train: 0.8850 acc_train: 0.8000 loss_val: 0.9606 acc_val: 0.7080 time: 0.0185s\n",
            "136\n",
            "Epoch: 1446 loss_train: 0.7451 acc_train: 0.8667 loss_val: 0.9588 acc_val: 0.7060 time: 0.0189s\n",
            "137\n",
            "Epoch: 1447 loss_train: 0.7994 acc_train: 0.8083 loss_val: 0.9500 acc_val: 0.7060 time: 0.0189s\n",
            "138\n",
            "Epoch: 1448 loss_train: 0.7736 acc_train: 0.8250 loss_val: 0.9377 acc_val: 0.7220 time: 0.0219s\n",
            "139\n",
            "Epoch: 1449 loss_train: 0.7479 acc_train: 0.8417 loss_val: 0.9303 acc_val: 0.7300 time: 0.0205s\n",
            "140\n",
            "Epoch: 1450 loss_train: 0.7154 acc_train: 0.8917 loss_val: 0.9267 acc_val: 0.7340 time: 0.0194s\n",
            "141\n",
            "Epoch: 1451 loss_train: 0.7377 acc_train: 0.8833 loss_val: 0.9263 acc_val: 0.7280 time: 0.0190s\n",
            "142\n",
            "Epoch: 1452 loss_train: 0.7797 acc_train: 0.8250 loss_val: 0.9278 acc_val: 0.7340 time: 0.0201s\n",
            "143\n",
            "Epoch: 1453 loss_train: 0.7737 acc_train: 0.8667 loss_val: 0.9321 acc_val: 0.7320 time: 0.0186s\n",
            "144\n",
            "Epoch: 1454 loss_train: 0.7542 acc_train: 0.8500 loss_val: 0.9370 acc_val: 0.7400 time: 0.0190s\n",
            "145\n",
            "Epoch: 1455 loss_train: 0.7626 acc_train: 0.8417 loss_val: 0.9443 acc_val: 0.7320 time: 0.0192s\n",
            "146\n",
            "Epoch: 1456 loss_train: 0.7743 acc_train: 0.8167 loss_val: 0.9533 acc_val: 0.7200 time: 0.0190s\n",
            "147\n",
            "Epoch: 1457 loss_train: 0.7816 acc_train: 0.8500 loss_val: 0.9591 acc_val: 0.7180 time: 0.0189s\n",
            "148\n",
            "Epoch: 1458 loss_train: 0.7568 acc_train: 0.8750 loss_val: 0.9530 acc_val: 0.7160 time: 0.0228s\n",
            "149\n",
            "Epoch: 1459 loss_train: 0.7992 acc_train: 0.7833 loss_val: 0.9457 acc_val: 0.7180 time: 0.0191s\n",
            "150\n",
            "Epoch: 1460 loss_train: 0.7806 acc_train: 0.8917 loss_val: 0.9391 acc_val: 0.7160 time: 0.0193s\n",
            "151\n",
            "Epoch: 1461 loss_train: 0.7956 acc_train: 0.8500 loss_val: 0.9345 acc_val: 0.7300 time: 0.0190s\n",
            "152\n",
            "Epoch: 1462 loss_train: 0.7701 acc_train: 0.8417 loss_val: 0.9322 acc_val: 0.7320 time: 0.0192s\n",
            "153\n",
            "Epoch: 1463 loss_train: 0.7705 acc_train: 0.8750 loss_val: 0.9310 acc_val: 0.7380 time: 0.0194s\n",
            "154\n",
            "Epoch: 1464 loss_train: 0.7003 acc_train: 0.8833 loss_val: 0.9283 acc_val: 0.7380 time: 0.0189s\n",
            "155\n",
            "Epoch: 1465 loss_train: 0.7408 acc_train: 0.8333 loss_val: 0.9282 acc_val: 0.7420 time: 0.0194s\n",
            "156\n",
            "Epoch: 1466 loss_train: 0.7660 acc_train: 0.8417 loss_val: 0.9311 acc_val: 0.7440 time: 0.0189s\n",
            "157\n",
            "Epoch: 1467 loss_train: 0.7638 acc_train: 0.8250 loss_val: 0.9367 acc_val: 0.7360 time: 0.0189s\n",
            "158\n",
            "Epoch: 1468 loss_train: 0.8613 acc_train: 0.8083 loss_val: 0.9422 acc_val: 0.7340 time: 0.0215s\n",
            "159\n",
            "Epoch: 1469 loss_train: 0.7239 acc_train: 0.8583 loss_val: 0.9456 acc_val: 0.7240 time: 0.0191s\n",
            "160\n",
            "Epoch: 1470 loss_train: 0.7905 acc_train: 0.8583 loss_val: 0.9502 acc_val: 0.7260 time: 0.0199s\n",
            "161\n",
            "Epoch: 1471 loss_train: 0.8421 acc_train: 0.8250 loss_val: 0.9562 acc_val: 0.7100 time: 0.0222s\n",
            "162\n",
            "Epoch: 1472 loss_train: 0.7849 acc_train: 0.8250 loss_val: 0.9500 acc_val: 0.7120 time: 0.0195s\n",
            "163\n",
            "Epoch: 1473 loss_train: 0.7236 acc_train: 0.8583 loss_val: 0.9396 acc_val: 0.7200 time: 0.0191s\n",
            "164\n",
            "Epoch: 1474 loss_train: 0.8032 acc_train: 0.8000 loss_val: 0.9274 acc_val: 0.7280 time: 0.0190s\n",
            "165\n",
            "Epoch: 1475 loss_train: 0.8656 acc_train: 0.7583 loss_val: 0.9252 acc_val: 0.7340 time: 0.0189s\n",
            "166\n",
            "Epoch: 1476 loss_train: 0.8396 acc_train: 0.8333 loss_val: 0.9277 acc_val: 0.7300 time: 0.0190s\n",
            "167\n",
            "Epoch: 1477 loss_train: 0.7814 acc_train: 0.8333 loss_val: 0.9299 acc_val: 0.7360 time: 0.0191s\n",
            "168\n",
            "Epoch: 1478 loss_train: 0.7541 acc_train: 0.8500 loss_val: 0.9306 acc_val: 0.7340 time: 0.0200s\n",
            "169\n",
            "Epoch: 1479 loss_train: 0.8572 acc_train: 0.8417 loss_val: 0.9366 acc_val: 0.7400 time: 0.0190s\n",
            "170\n",
            "Epoch: 1480 loss_train: 0.8243 acc_train: 0.8583 loss_val: 0.9432 acc_val: 0.7340 time: 0.0199s\n",
            "171\n",
            "Epoch: 1481 loss_train: 0.7442 acc_train: 0.8250 loss_val: 0.9457 acc_val: 0.7340 time: 0.0190s\n",
            "172\n",
            "Epoch: 1482 loss_train: 0.8039 acc_train: 0.7917 loss_val: 0.9418 acc_val: 0.7340 time: 0.0190s\n",
            "173\n",
            "Epoch: 1483 loss_train: 0.7432 acc_train: 0.8333 loss_val: 0.9407 acc_val: 0.7260 time: 0.0189s\n",
            "174\n",
            "Epoch: 1484 loss_train: 0.8224 acc_train: 0.8000 loss_val: 0.9373 acc_val: 0.7200 time: 0.0190s\n",
            "175\n",
            "Epoch: 1485 loss_train: 0.8302 acc_train: 0.8000 loss_val: 0.9371 acc_val: 0.7200 time: 0.0197s\n",
            "176\n",
            "Epoch: 1486 loss_train: 0.7078 acc_train: 0.8667 loss_val: 0.9347 acc_val: 0.7200 time: 0.0190s\n",
            "177\n",
            "Epoch: 1487 loss_train: 0.7237 acc_train: 0.8917 loss_val: 0.9327 acc_val: 0.7260 time: 0.0199s\n",
            "178\n",
            "Epoch: 1488 loss_train: 0.7552 acc_train: 0.8500 loss_val: 0.9314 acc_val: 0.7300 time: 0.0232s\n",
            "179\n",
            "Epoch: 1489 loss_train: 0.7113 acc_train: 0.8417 loss_val: 0.9332 acc_val: 0.7320 time: 0.0209s\n",
            "180\n",
            "Epoch: 1490 loss_train: 0.7926 acc_train: 0.8500 loss_val: 0.9328 acc_val: 0.7320 time: 0.0208s\n",
            "181\n",
            "Epoch: 1491 loss_train: 0.7392 acc_train: 0.8500 loss_val: 0.9296 acc_val: 0.7320 time: 0.0192s\n",
            "182\n",
            "Epoch: 1492 loss_train: 0.7957 acc_train: 0.8250 loss_val: 0.9303 acc_val: 0.7360 time: 0.0191s\n",
            "183\n",
            "Epoch: 1493 loss_train: 0.8936 acc_train: 0.7917 loss_val: 0.9340 acc_val: 0.7380 time: 0.0192s\n",
            "184\n",
            "Epoch: 1494 loss_train: 0.7329 acc_train: 0.8667 loss_val: 0.9377 acc_val: 0.7340 time: 0.0195s\n",
            "185\n",
            "Epoch: 1495 loss_train: 0.7548 acc_train: 0.8750 loss_val: 0.9407 acc_val: 0.7280 time: 0.0206s\n",
            "186\n",
            "Epoch: 1496 loss_train: 0.7422 acc_train: 0.8750 loss_val: 0.9424 acc_val: 0.7260 time: 0.0196s\n",
            "187\n",
            "Epoch: 1497 loss_train: 0.7981 acc_train: 0.8667 loss_val: 0.9425 acc_val: 0.7240 time: 0.0190s\n",
            "188\n",
            "Epoch: 1498 loss_train: 0.7888 acc_train: 0.8667 loss_val: 0.9447 acc_val: 0.7240 time: 0.0197s\n",
            "189\n",
            "Epoch: 1499 loss_train: 0.8316 acc_train: 0.8000 loss_val: 0.9461 acc_val: 0.7240 time: 0.0190s\n",
            "190\n",
            "Epoch: 1500 loss_train: 0.7201 acc_train: 0.8583 loss_val: 0.9482 acc_val: 0.7220 time: 0.0189s\n",
            "191\n",
            "Epoch: 1501 loss_train: 0.8115 acc_train: 0.8500 loss_val: 0.9422 acc_val: 0.7260 time: 0.0190s\n",
            "192\n",
            "Epoch: 1502 loss_train: 0.8128 acc_train: 0.8250 loss_val: 0.9352 acc_val: 0.7360 time: 0.0191s\n",
            "193\n",
            "Epoch: 1503 loss_train: 0.7644 acc_train: 0.8583 loss_val: 0.9301 acc_val: 0.7340 time: 0.0190s\n",
            "194\n",
            "Epoch: 1504 loss_train: 0.8350 acc_train: 0.8333 loss_val: 0.9271 acc_val: 0.7360 time: 0.0190s\n",
            "195\n",
            "Epoch: 1505 loss_train: 0.7802 acc_train: 0.8667 loss_val: 0.9245 acc_val: 0.7380 time: 0.0185s\n",
            "196\n",
            "Epoch: 1506 loss_train: 0.7378 acc_train: 0.8583 loss_val: 0.9243 acc_val: 0.7360 time: 0.0189s\n",
            "197\n",
            "Epoch: 1507 loss_train: 0.6669 acc_train: 0.9333 loss_val: 0.9241 acc_val: 0.7400 time: 0.0190s\n",
            "198\n",
            "Epoch: 1508 loss_train: 0.7596 acc_train: 0.8417 loss_val: 0.9230 acc_val: 0.7440 time: 0.0218s\n",
            "199\n",
            "Early stop! Min loss:  0.9145210981369019 , Max accuracy:  0.754\n",
            "Early stop model validation loss:  0.9145210981369019 , accuracy:  0.75\n",
            "Optimization Finished!\n",
            "Total time elapsed: 33.3375s\n",
            "Loading 1284th epoch\n",
            "Test set results: loss= 0.8963 accuracy= 0.7580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMr9lujlfe4C",
        "outputId": "18c88e5c-792c-4494-875a-b66b673e9761"
      },
      "source": [
        "Train(lam=0) #cora\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.0268 acc_train: 0.1286 loss_val: 2.0262 acc_val: 0.1140 time: 0.2243s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.0199 acc_train: 0.1429 loss_val: 2.0207 acc_val: 0.1140 time: 0.0466s\n",
            "0\n",
            "Epoch: 0003 loss_train: 2.0124 acc_train: 0.1500 loss_val: 2.0149 acc_val: 0.1140 time: 0.0468s\n",
            "0\n",
            "Epoch: 0004 loss_train: 2.0090 acc_train: 0.1571 loss_val: 2.0089 acc_val: 0.1140 time: 0.0467s\n",
            "0\n",
            "Epoch: 0005 loss_train: 2.0038 acc_train: 0.1500 loss_val: 2.0030 acc_val: 0.1140 time: 0.0471s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.9958 acc_train: 0.1286 loss_val: 1.9972 acc_val: 0.1140 time: 0.0445s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.9929 acc_train: 0.1214 loss_val: 1.9917 acc_val: 0.1140 time: 0.0462s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.9877 acc_train: 0.1429 loss_val: 1.9864 acc_val: 0.1140 time: 0.0461s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.9812 acc_train: 0.1286 loss_val: 1.9813 acc_val: 0.1140 time: 0.0461s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.9775 acc_train: 0.1429 loss_val: 1.9764 acc_val: 0.1140 time: 0.0471s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.9787 acc_train: 0.1500 loss_val: 1.9719 acc_val: 0.1140 time: 0.0451s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.9717 acc_train: 0.1643 loss_val: 1.9673 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.9621 acc_train: 0.1357 loss_val: 1.9627 acc_val: 0.1140 time: 0.0442s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.9650 acc_train: 0.1214 loss_val: 1.9583 acc_val: 0.1140 time: 0.0446s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.9591 acc_train: 0.1357 loss_val: 1.9540 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.9539 acc_train: 0.1429 loss_val: 1.9500 acc_val: 0.1140 time: 0.0462s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.9547 acc_train: 0.1714 loss_val: 1.9463 acc_val: 0.1140 time: 0.0445s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.9494 acc_train: 0.1500 loss_val: 1.9425 acc_val: 0.1160 time: 0.0443s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.9417 acc_train: 0.1571 loss_val: 1.9388 acc_val: 0.1360 time: 0.0440s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.9517 acc_train: 0.1071 loss_val: 1.9357 acc_val: 0.1280 time: 0.0443s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.9417 acc_train: 0.1857 loss_val: 1.9333 acc_val: 0.0940 time: 0.0441s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.9471 acc_train: 0.1571 loss_val: 1.9309 acc_val: 0.0900 time: 0.0461s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.9347 acc_train: 0.1500 loss_val: 1.9291 acc_val: 0.0900 time: 0.0453s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.9347 acc_train: 0.1857 loss_val: 1.9275 acc_val: 0.1160 time: 0.0449s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.9479 acc_train: 0.1500 loss_val: 1.9259 acc_val: 0.2140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.9255 acc_train: 0.2143 loss_val: 1.9247 acc_val: 0.3320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.9344 acc_train: 0.1714 loss_val: 1.9237 acc_val: 0.3700 time: 0.0448s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.9297 acc_train: 0.2071 loss_val: 1.9222 acc_val: 0.4020 time: 0.0447s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.9238 acc_train: 0.1786 loss_val: 1.9195 acc_val: 0.4520 time: 0.0441s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.9259 acc_train: 0.1714 loss_val: 1.9173 acc_val: 0.5340 time: 0.0440s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.9122 acc_train: 0.1929 loss_val: 1.9150 acc_val: 0.6080 time: 0.0470s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.9112 acc_train: 0.2071 loss_val: 1.9129 acc_val: 0.6080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.9221 acc_train: 0.1786 loss_val: 1.9107 acc_val: 0.5940 time: 0.0452s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.9140 acc_train: 0.2143 loss_val: 1.9091 acc_val: 0.5680 time: 0.0442s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.9049 acc_train: 0.2643 loss_val: 1.9080 acc_val: 0.5760 time: 0.0441s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.9049 acc_train: 0.2571 loss_val: 1.9072 acc_val: 0.5820 time: 0.0472s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.8940 acc_train: 0.2857 loss_val: 1.9066 acc_val: 0.5780 time: 0.0441s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.8879 acc_train: 0.2714 loss_val: 1.9049 acc_val: 0.5640 time: 0.0445s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.9061 acc_train: 0.2643 loss_val: 1.9029 acc_val: 0.5600 time: 0.0441s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.8976 acc_train: 0.3214 loss_val: 1.9003 acc_val: 0.5660 time: 0.0446s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.8861 acc_train: 0.2857 loss_val: 1.8971 acc_val: 0.5940 time: 0.0441s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.8839 acc_train: 0.3000 loss_val: 1.8937 acc_val: 0.6340 time: 0.0440s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.8791 acc_train: 0.2714 loss_val: 1.8897 acc_val: 0.6300 time: 0.0461s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.8789 acc_train: 0.3643 loss_val: 1.8860 acc_val: 0.6380 time: 0.0438s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.8824 acc_train: 0.2786 loss_val: 1.8827 acc_val: 0.6380 time: 0.0439s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.8585 acc_train: 0.2714 loss_val: 1.8799 acc_val: 0.6300 time: 0.0454s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.8652 acc_train: 0.3357 loss_val: 1.8772 acc_val: 0.6200 time: 0.0442s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.8554 acc_train: 0.3286 loss_val: 1.8745 acc_val: 0.6060 time: 0.0457s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.8468 acc_train: 0.3500 loss_val: 1.8710 acc_val: 0.6040 time: 0.0441s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.8440 acc_train: 0.3929 loss_val: 1.8675 acc_val: 0.6340 time: 0.0441s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.8459 acc_train: 0.3786 loss_val: 1.8633 acc_val: 0.6740 time: 0.0444s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.8434 acc_train: 0.3143 loss_val: 1.8605 acc_val: 0.6800 time: 0.0443s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.8307 acc_train: 0.3929 loss_val: 1.8582 acc_val: 0.6900 time: 0.0450s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.8242 acc_train: 0.3571 loss_val: 1.8569 acc_val: 0.6700 time: 0.0441s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.8083 acc_train: 0.4000 loss_val: 1.8537 acc_val: 0.6620 time: 0.0440s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.8083 acc_train: 0.4643 loss_val: 1.8487 acc_val: 0.6680 time: 0.0444s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.8077 acc_train: 0.3857 loss_val: 1.8431 acc_val: 0.6780 time: 0.0458s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.8137 acc_train: 0.4000 loss_val: 1.8379 acc_val: 0.6820 time: 0.0447s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.7914 acc_train: 0.3857 loss_val: 1.8315 acc_val: 0.7100 time: 0.0463s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.7802 acc_train: 0.4071 loss_val: 1.8248 acc_val: 0.7400 time: 0.0438s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.7724 acc_train: 0.4714 loss_val: 1.8172 acc_val: 0.7480 time: 0.0442s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.7579 acc_train: 0.4714 loss_val: 1.8103 acc_val: 0.7560 time: 0.0439s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.7677 acc_train: 0.4286 loss_val: 1.8032 acc_val: 0.7460 time: 0.0447s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.7623 acc_train: 0.4714 loss_val: 1.7984 acc_val: 0.7520 time: 0.0442s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.7393 acc_train: 0.4429 loss_val: 1.7938 acc_val: 0.7640 time: 0.0452s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.7438 acc_train: 0.5143 loss_val: 1.7895 acc_val: 0.7720 time: 0.0437s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.7220 acc_train: 0.4929 loss_val: 1.7836 acc_val: 0.7880 time: 0.0439s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.7362 acc_train: 0.4714 loss_val: 1.7766 acc_val: 0.7960 time: 0.0449s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.6950 acc_train: 0.4357 loss_val: 1.7685 acc_val: 0.7880 time: 0.0446s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.7083 acc_train: 0.3929 loss_val: 1.7607 acc_val: 0.7800 time: 0.0446s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.6875 acc_train: 0.3929 loss_val: 1.7532 acc_val: 0.7800 time: 0.0442s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.7073 acc_train: 0.3643 loss_val: 1.7467 acc_val: 0.7860 time: 0.0443s\n",
            "0\n",
            "Epoch: 0073 loss_train: 1.6775 acc_train: 0.4500 loss_val: 1.7416 acc_val: 0.7820 time: 0.0448s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.6858 acc_train: 0.4929 loss_val: 1.7371 acc_val: 0.7880 time: 0.0441s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.6599 acc_train: 0.4857 loss_val: 1.7335 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.6425 acc_train: 0.5214 loss_val: 1.7295 acc_val: 0.7960 time: 0.0443s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.6335 acc_train: 0.5286 loss_val: 1.7252 acc_val: 0.7740 time: 0.0458s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.6347 acc_train: 0.5214 loss_val: 1.7191 acc_val: 0.7900 time: 0.0499s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.6307 acc_train: 0.4857 loss_val: 1.7112 acc_val: 0.7800 time: 0.0453s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.6445 acc_train: 0.5214 loss_val: 1.7026 acc_val: 0.7820 time: 0.0452s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.6000 acc_train: 0.5429 loss_val: 1.6932 acc_val: 0.7740 time: 0.0454s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.6052 acc_train: 0.5714 loss_val: 1.6836 acc_val: 0.7700 time: 0.0448s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.6067 acc_train: 0.5286 loss_val: 1.6756 acc_val: 0.7740 time: 0.0450s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.5607 acc_train: 0.5929 loss_val: 1.6675 acc_val: 0.7800 time: 0.0439s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.5796 acc_train: 0.5000 loss_val: 1.6601 acc_val: 0.7900 time: 0.0441s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.5586 acc_train: 0.5714 loss_val: 1.6528 acc_val: 0.7860 time: 0.0448s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.5213 acc_train: 0.6000 loss_val: 1.6438 acc_val: 0.7960 time: 0.0453s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.5437 acc_train: 0.5286 loss_val: 1.6344 acc_val: 0.8000 time: 0.0446s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.5291 acc_train: 0.5929 loss_val: 1.6254 acc_val: 0.7980 time: 0.0449s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.5146 acc_train: 0.6214 loss_val: 1.6153 acc_val: 0.8000 time: 0.0454s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.5023 acc_train: 0.5857 loss_val: 1.6068 acc_val: 0.7980 time: 0.0457s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.5003 acc_train: 0.5643 loss_val: 1.6002 acc_val: 0.7980 time: 0.0478s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.4901 acc_train: 0.6000 loss_val: 1.5953 acc_val: 0.8000 time: 0.0442s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.4757 acc_train: 0.4500 loss_val: 1.5912 acc_val: 0.7960 time: 0.0446s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.5198 acc_train: 0.5286 loss_val: 1.5866 acc_val: 0.7940 time: 0.0438s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.4531 acc_train: 0.6000 loss_val: 1.5800 acc_val: 0.7820 time: 0.0448s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.4874 acc_train: 0.5643 loss_val: 1.5715 acc_val: 0.7860 time: 0.0443s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.4577 acc_train: 0.5571 loss_val: 1.5634 acc_val: 0.7860 time: 0.0458s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.4430 acc_train: 0.5286 loss_val: 1.5545 acc_val: 0.8000 time: 0.0441s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.4650 acc_train: 0.6071 loss_val: 1.5453 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.4273 acc_train: 0.6071 loss_val: 1.5359 acc_val: 0.7940 time: 0.0447s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.4285 acc_train: 0.5786 loss_val: 1.5254 acc_val: 0.8000 time: 0.0441s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.4146 acc_train: 0.6286 loss_val: 1.5146 acc_val: 0.8100 time: 0.0480s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.3997 acc_train: 0.7143 loss_val: 1.5046 acc_val: 0.8120 time: 0.0447s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.3899 acc_train: 0.6071 loss_val: 1.4954 acc_val: 0.8140 time: 0.0453s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.3934 acc_train: 0.6143 loss_val: 1.4870 acc_val: 0.8060 time: 0.0446s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.3852 acc_train: 0.6714 loss_val: 1.4825 acc_val: 0.8020 time: 0.0474s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.3623 acc_train: 0.6929 loss_val: 1.4806 acc_val: 0.8020 time: 0.0442s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.3414 acc_train: 0.6571 loss_val: 1.4802 acc_val: 0.8020 time: 0.0449s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.3351 acc_train: 0.5857 loss_val: 1.4743 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.3554 acc_train: 0.7000 loss_val: 1.4653 acc_val: 0.8000 time: 0.0442s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.3719 acc_train: 0.6357 loss_val: 1.4589 acc_val: 0.7980 time: 0.0444s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.3340 acc_train: 0.5929 loss_val: 1.4524 acc_val: 0.7940 time: 0.0457s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.3603 acc_train: 0.5786 loss_val: 1.4449 acc_val: 0.7920 time: 0.0441s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.3197 acc_train: 0.6571 loss_val: 1.4363 acc_val: 0.7960 time: 0.0441s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.2885 acc_train: 0.6571 loss_val: 1.4277 acc_val: 0.8060 time: 0.0447s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.3208 acc_train: 0.6000 loss_val: 1.4197 acc_val: 0.8060 time: 0.0469s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.3039 acc_train: 0.6286 loss_val: 1.4116 acc_val: 0.8060 time: 0.0456s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.3174 acc_train: 0.6571 loss_val: 1.4063 acc_val: 0.8040 time: 0.0459s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.3074 acc_train: 0.6143 loss_val: 1.3994 acc_val: 0.8060 time: 0.0451s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.2855 acc_train: 0.6500 loss_val: 1.3909 acc_val: 0.8020 time: 0.0447s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.2735 acc_train: 0.6429 loss_val: 1.3819 acc_val: 0.8040 time: 0.0459s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.2635 acc_train: 0.7286 loss_val: 1.3764 acc_val: 0.8040 time: 0.0446s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.2627 acc_train: 0.7214 loss_val: 1.3717 acc_val: 0.8080 time: 0.0441s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.2565 acc_train: 0.6643 loss_val: 1.3691 acc_val: 0.8080 time: 0.0439s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.2630 acc_train: 0.6214 loss_val: 1.3665 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.2417 acc_train: 0.6786 loss_val: 1.3617 acc_val: 0.8140 time: 0.0453s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.2151 acc_train: 0.6786 loss_val: 1.3569 acc_val: 0.8100 time: 0.0443s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.2621 acc_train: 0.6571 loss_val: 1.3549 acc_val: 0.8040 time: 0.0441s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.2309 acc_train: 0.6857 loss_val: 1.3529 acc_val: 0.8040 time: 0.0454s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.2444 acc_train: 0.5857 loss_val: 1.3499 acc_val: 0.8060 time: 0.0456s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.1923 acc_train: 0.6786 loss_val: 1.3428 acc_val: 0.8040 time: 0.0451s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.2186 acc_train: 0.6571 loss_val: 1.3361 acc_val: 0.8040 time: 0.0443s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.2258 acc_train: 0.6429 loss_val: 1.3300 acc_val: 0.8020 time: 0.0437s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.2120 acc_train: 0.6214 loss_val: 1.3271 acc_val: 0.8060 time: 0.0446s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.1607 acc_train: 0.6071 loss_val: 1.3215 acc_val: 0.8060 time: 0.0471s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.1860 acc_train: 0.7143 loss_val: 1.3140 acc_val: 0.8100 time: 0.0467s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.2213 acc_train: 0.6000 loss_val: 1.3086 acc_val: 0.8120 time: 0.0486s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.1644 acc_train: 0.6500 loss_val: 1.3020 acc_val: 0.8100 time: 0.0454s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.1999 acc_train: 0.7214 loss_val: 1.2946 acc_val: 0.8100 time: 0.0447s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.1982 acc_train: 0.7000 loss_val: 1.2867 acc_val: 0.8100 time: 0.0444s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.1340 acc_train: 0.7071 loss_val: 1.2790 acc_val: 0.8040 time: 0.0447s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.1816 acc_train: 0.6286 loss_val: 1.2797 acc_val: 0.8060 time: 0.0443s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.1642 acc_train: 0.6714 loss_val: 1.2817 acc_val: 0.8100 time: 0.0441s\n",
            "1\n",
            "Epoch: 0145 loss_train: 1.1495 acc_train: 0.7143 loss_val: 1.2829 acc_val: 0.8060 time: 0.0451s\n",
            "2\n",
            "Epoch: 0146 loss_train: 1.1927 acc_train: 0.6571 loss_val: 1.2841 acc_val: 0.8040 time: 0.0453s\n",
            "3\n",
            "Epoch: 0147 loss_train: 1.1436 acc_train: 0.6571 loss_val: 1.2805 acc_val: 0.8020 time: 0.0446s\n",
            "4\n",
            "Epoch: 0148 loss_train: 1.1815 acc_train: 0.7214 loss_val: 1.2738 acc_val: 0.8000 time: 0.0460s\n",
            "5\n",
            "Epoch: 0149 loss_train: 1.1486 acc_train: 0.6857 loss_val: 1.2674 acc_val: 0.8060 time: 0.0441s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.1788 acc_train: 0.6571 loss_val: 1.2619 acc_val: 0.8020 time: 0.0440s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.1313 acc_train: 0.6571 loss_val: 1.2568 acc_val: 0.8060 time: 0.0462s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.1464 acc_train: 0.7143 loss_val: 1.2549 acc_val: 0.8100 time: 0.0442s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.1316 acc_train: 0.7643 loss_val: 1.2542 acc_val: 0.8120 time: 0.0441s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.2005 acc_train: 0.6929 loss_val: 1.2532 acc_val: 0.8060 time: 0.0442s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.1371 acc_train: 0.7071 loss_val: 1.2497 acc_val: 0.8040 time: 0.0443s\n",
            "0\n",
            "Epoch: 0156 loss_train: 1.1237 acc_train: 0.6429 loss_val: 1.2400 acc_val: 0.7980 time: 0.0453s\n",
            "0\n",
            "Epoch: 0157 loss_train: 1.1419 acc_train: 0.6500 loss_val: 1.2324 acc_val: 0.8060 time: 0.0444s\n",
            "0\n",
            "Epoch: 0158 loss_train: 1.1171 acc_train: 0.6714 loss_val: 1.2250 acc_val: 0.8080 time: 0.0454s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.1257 acc_train: 0.6071 loss_val: 1.2225 acc_val: 0.8060 time: 0.0439s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.1197 acc_train: 0.7071 loss_val: 1.2175 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0161 loss_train: 1.1157 acc_train: 0.6929 loss_val: 1.2144 acc_val: 0.8060 time: 0.0449s\n",
            "0\n",
            "Epoch: 0162 loss_train: 1.1436 acc_train: 0.7000 loss_val: 1.2121 acc_val: 0.8020 time: 0.0441s\n",
            "0\n",
            "Epoch: 0163 loss_train: 1.1127 acc_train: 0.6714 loss_val: 1.2114 acc_val: 0.7980 time: 0.0441s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.1148 acc_train: 0.7143 loss_val: 1.2149 acc_val: 0.8020 time: 0.0441s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.1030 acc_train: 0.6714 loss_val: 1.2165 acc_val: 0.8080 time: 0.0447s\n",
            "1\n",
            "Epoch: 0166 loss_train: 1.0846 acc_train: 0.6500 loss_val: 1.2149 acc_val: 0.8040 time: 0.0463s\n",
            "2\n",
            "Epoch: 0167 loss_train: 1.1146 acc_train: 0.7214 loss_val: 1.2107 acc_val: 0.8060 time: 0.0451s\n",
            "3\n",
            "Epoch: 0168 loss_train: 1.0606 acc_train: 0.7143 loss_val: 1.2060 acc_val: 0.8100 time: 0.0446s\n",
            "0\n",
            "Epoch: 0169 loss_train: 1.1104 acc_train: 0.6714 loss_val: 1.2040 acc_val: 0.8040 time: 0.0447s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.1040 acc_train: 0.6786 loss_val: 1.2017 acc_val: 0.8100 time: 0.0446s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.0653 acc_train: 0.6786 loss_val: 1.1968 acc_val: 0.8020 time: 0.0486s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.1096 acc_train: 0.6714 loss_val: 1.1890 acc_val: 0.7940 time: 0.0446s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.0356 acc_train: 0.7357 loss_val: 1.1807 acc_val: 0.8040 time: 0.0446s\n",
            "0\n",
            "Epoch: 0174 loss_train: 1.1060 acc_train: 0.6929 loss_val: 1.1724 acc_val: 0.8020 time: 0.0445s\n",
            "0\n",
            "Epoch: 0175 loss_train: 1.0973 acc_train: 0.6929 loss_val: 1.1684 acc_val: 0.8020 time: 0.0440s\n",
            "0\n",
            "Epoch: 0176 loss_train: 1.0900 acc_train: 0.7000 loss_val: 1.1667 acc_val: 0.7940 time: 0.0459s\n",
            "0\n",
            "Epoch: 0177 loss_train: 1.1019 acc_train: 0.6500 loss_val: 1.1708 acc_val: 0.8040 time: 0.0465s\n",
            "0\n",
            "Epoch: 0178 loss_train: 1.0704 acc_train: 0.7214 loss_val: 1.1751 acc_val: 0.8060 time: 0.0449s\n",
            "1\n",
            "Epoch: 0179 loss_train: 1.0297 acc_train: 0.7571 loss_val: 1.1759 acc_val: 0.8100 time: 0.0471s\n",
            "2\n",
            "Epoch: 0180 loss_train: 1.0392 acc_train: 0.7214 loss_val: 1.1762 acc_val: 0.8100 time: 0.0447s\n",
            "3\n",
            "Epoch: 0181 loss_train: 1.0741 acc_train: 0.7357 loss_val: 1.1802 acc_val: 0.8040 time: 0.0452s\n",
            "4\n",
            "Epoch: 0182 loss_train: 1.0652 acc_train: 0.7143 loss_val: 1.1830 acc_val: 0.7980 time: 0.0498s\n",
            "5\n",
            "Epoch: 0183 loss_train: 1.0199 acc_train: 0.7714 loss_val: 1.1803 acc_val: 0.8000 time: 0.0458s\n",
            "6\n",
            "Epoch: 0184 loss_train: 1.0481 acc_train: 0.7571 loss_val: 1.1738 acc_val: 0.8020 time: 0.0469s\n",
            "7\n",
            "Epoch: 0185 loss_train: 1.0823 acc_train: 0.6500 loss_val: 1.1642 acc_val: 0.8000 time: 0.0446s\n",
            "8\n",
            "Epoch: 0186 loss_train: 1.0308 acc_train: 0.7643 loss_val: 1.1520 acc_val: 0.8020 time: 0.0452s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.0619 acc_train: 0.7143 loss_val: 1.1408 acc_val: 0.8040 time: 0.0441s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.0251 acc_train: 0.7286 loss_val: 1.1361 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0189 loss_train: 1.0121 acc_train: 0.7286 loss_val: 1.1326 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0190 loss_train: 1.0719 acc_train: 0.7071 loss_val: 1.1341 acc_val: 0.8100 time: 0.0444s\n",
            "0\n",
            "Epoch: 0191 loss_train: 1.0878 acc_train: 0.7071 loss_val: 1.1424 acc_val: 0.8100 time: 0.0454s\n",
            "1\n",
            "Epoch: 0192 loss_train: 1.0418 acc_train: 0.6643 loss_val: 1.1551 acc_val: 0.8040 time: 0.0458s\n",
            "2\n",
            "Epoch: 0193 loss_train: 1.0337 acc_train: 0.7429 loss_val: 1.1597 acc_val: 0.8040 time: 0.0445s\n",
            "3\n",
            "Epoch: 0194 loss_train: 1.0287 acc_train: 0.7143 loss_val: 1.1575 acc_val: 0.8080 time: 0.0443s\n",
            "4\n",
            "Epoch: 0195 loss_train: 1.0704 acc_train: 0.6857 loss_val: 1.1537 acc_val: 0.8020 time: 0.0446s\n",
            "5\n",
            "Epoch: 0196 loss_train: 1.0291 acc_train: 0.6786 loss_val: 1.1480 acc_val: 0.7960 time: 0.0469s\n",
            "6\n",
            "Epoch: 0197 loss_train: 1.0354 acc_train: 0.7714 loss_val: 1.1373 acc_val: 0.8000 time: 0.0446s\n",
            "7\n",
            "Epoch: 0198 loss_train: 1.0106 acc_train: 0.7429 loss_val: 1.1291 acc_val: 0.8020 time: 0.0454s\n",
            "8\n",
            "Epoch: 0199 loss_train: 0.9993 acc_train: 0.6929 loss_val: 1.1232 acc_val: 0.8020 time: 0.0448s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.0405 acc_train: 0.6857 loss_val: 1.1230 acc_val: 0.8060 time: 0.0441s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.0545 acc_train: 0.5929 loss_val: 1.1279 acc_val: 0.8040 time: 0.0449s\n",
            "0\n",
            "Epoch: 0202 loss_train: 1.0271 acc_train: 0.7143 loss_val: 1.1322 acc_val: 0.8000 time: 0.0445s\n",
            "1\n",
            "Epoch: 0203 loss_train: 1.0653 acc_train: 0.7500 loss_val: 1.1343 acc_val: 0.8020 time: 0.0446s\n",
            "2\n",
            "Epoch: 0204 loss_train: 1.0052 acc_train: 0.7143 loss_val: 1.1342 acc_val: 0.8060 time: 0.0447s\n",
            "3\n",
            "Epoch: 0205 loss_train: 1.0590 acc_train: 0.7357 loss_val: 1.1337 acc_val: 0.8060 time: 0.0442s\n",
            "4\n",
            "Epoch: 0206 loss_train: 1.0394 acc_train: 0.7071 loss_val: 1.1283 acc_val: 0.8040 time: 0.0452s\n",
            "5\n",
            "Epoch: 0207 loss_train: 1.0480 acc_train: 0.6786 loss_val: 1.1244 acc_val: 0.8020 time: 0.0482s\n",
            "6\n",
            "Epoch: 0208 loss_train: 1.0332 acc_train: 0.7071 loss_val: 1.1223 acc_val: 0.7980 time: 0.0466s\n",
            "7\n",
            "Epoch: 0209 loss_train: 1.0016 acc_train: 0.7214 loss_val: 1.1197 acc_val: 0.7960 time: 0.0442s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.0075 acc_train: 0.7357 loss_val: 1.1184 acc_val: 0.7980 time: 0.0440s\n",
            "0\n",
            "Epoch: 0211 loss_train: 1.0648 acc_train: 0.6857 loss_val: 1.1200 acc_val: 0.8020 time: 0.0448s\n",
            "0\n",
            "Epoch: 0212 loss_train: 0.9635 acc_train: 0.7357 loss_val: 1.1197 acc_val: 0.8040 time: 0.0456s\n",
            "1\n",
            "Epoch: 0213 loss_train: 1.0029 acc_train: 0.7500 loss_val: 1.1171 acc_val: 0.8060 time: 0.0444s\n",
            "2\n",
            "Epoch: 0214 loss_train: 1.0012 acc_train: 0.6857 loss_val: 1.1149 acc_val: 0.8080 time: 0.0439s\n",
            "0\n",
            "Epoch: 0215 loss_train: 0.9911 acc_train: 0.7571 loss_val: 1.1094 acc_val: 0.8040 time: 0.0454s\n",
            "0\n",
            "Epoch: 0216 loss_train: 0.9925 acc_train: 0.7071 loss_val: 1.1002 acc_val: 0.8120 time: 0.0438s\n",
            "0\n",
            "Epoch: 0217 loss_train: 0.9667 acc_train: 0.7714 loss_val: 1.0921 acc_val: 0.8080 time: 0.0452s\n",
            "0\n",
            "Epoch: 0218 loss_train: 0.9787 acc_train: 0.7071 loss_val: 1.0885 acc_val: 0.8060 time: 0.0445s\n",
            "0\n",
            "Epoch: 0219 loss_train: 0.9521 acc_train: 0.7000 loss_val: 1.0884 acc_val: 0.8000 time: 0.0441s\n",
            "0\n",
            "Epoch: 0220 loss_train: 1.0418 acc_train: 0.7643 loss_val: 1.0923 acc_val: 0.8000 time: 0.0477s\n",
            "0\n",
            "Epoch: 0221 loss_train: 1.0105 acc_train: 0.6929 loss_val: 1.1010 acc_val: 0.8000 time: 0.0447s\n",
            "1\n",
            "Epoch: 0222 loss_train: 0.9819 acc_train: 0.7143 loss_val: 1.1070 acc_val: 0.7980 time: 0.0446s\n",
            "2\n",
            "Epoch: 0223 loss_train: 0.9816 acc_train: 0.7143 loss_val: 1.1060 acc_val: 0.8020 time: 0.0441s\n",
            "3\n",
            "Epoch: 0224 loss_train: 1.0155 acc_train: 0.6857 loss_val: 1.1065 acc_val: 0.8060 time: 0.0444s\n",
            "4\n",
            "Epoch: 0225 loss_train: 0.9727 acc_train: 0.7500 loss_val: 1.1023 acc_val: 0.8000 time: 0.0453s\n",
            "5\n",
            "Epoch: 0226 loss_train: 0.9788 acc_train: 0.7286 loss_val: 1.0979 acc_val: 0.8080 time: 0.0443s\n",
            "6\n",
            "Epoch: 0227 loss_train: 0.9938 acc_train: 0.6714 loss_val: 1.0893 acc_val: 0.8080 time: 0.0455s\n",
            "7\n",
            "Epoch: 0228 loss_train: 0.9487 acc_train: 0.7429 loss_val: 1.0854 acc_val: 0.8140 time: 0.0447s\n",
            "8\n",
            "Epoch: 0229 loss_train: 0.9731 acc_train: 0.7143 loss_val: 1.0837 acc_val: 0.8080 time: 0.0446s\n",
            "0\n",
            "Epoch: 0230 loss_train: 1.0233 acc_train: 0.6643 loss_val: 1.0885 acc_val: 0.8020 time: 0.0451s\n",
            "0\n",
            "Epoch: 0231 loss_train: 1.0146 acc_train: 0.7214 loss_val: 1.0967 acc_val: 0.7980 time: 0.0442s\n",
            "1\n",
            "Epoch: 0232 loss_train: 0.9766 acc_train: 0.7143 loss_val: 1.1008 acc_val: 0.8020 time: 0.0449s\n",
            "2\n",
            "Epoch: 0233 loss_train: 0.9600 acc_train: 0.7214 loss_val: 1.1004 acc_val: 0.8020 time: 0.0447s\n",
            "3\n",
            "Epoch: 0234 loss_train: 0.9629 acc_train: 0.7286 loss_val: 1.0972 acc_val: 0.8020 time: 0.0444s\n",
            "4\n",
            "Epoch: 0235 loss_train: 0.9960 acc_train: 0.7429 loss_val: 1.0905 acc_val: 0.8000 time: 0.0457s\n",
            "5\n",
            "Epoch: 0236 loss_train: 0.9124 acc_train: 0.7143 loss_val: 1.0829 acc_val: 0.8040 time: 0.0445s\n",
            "6\n",
            "Epoch: 0237 loss_train: 0.9323 acc_train: 0.7286 loss_val: 1.0802 acc_val: 0.8040 time: 0.0464s\n",
            "0\n",
            "Epoch: 0238 loss_train: 1.0060 acc_train: 0.7357 loss_val: 1.0786 acc_val: 0.8080 time: 0.0438s\n",
            "0\n",
            "Epoch: 0239 loss_train: 0.9779 acc_train: 0.7643 loss_val: 1.0782 acc_val: 0.8120 time: 0.0453s\n",
            "0\n",
            "Epoch: 0240 loss_train: 1.0137 acc_train: 0.6929 loss_val: 1.0780 acc_val: 0.8100 time: 0.0455s\n",
            "0\n",
            "Epoch: 0241 loss_train: 0.9954 acc_train: 0.7357 loss_val: 1.0799 acc_val: 0.8060 time: 0.0449s\n",
            "0\n",
            "Epoch: 0242 loss_train: 0.9418 acc_train: 0.7714 loss_val: 1.0814 acc_val: 0.8060 time: 0.0446s\n",
            "1\n",
            "Epoch: 0243 loss_train: 0.9746 acc_train: 0.7429 loss_val: 1.0802 acc_val: 0.8080 time: 0.0444s\n",
            "2\n",
            "Epoch: 0244 loss_train: 0.9502 acc_train: 0.7429 loss_val: 1.0799 acc_val: 0.8080 time: 0.0441s\n",
            "3\n",
            "Epoch: 0245 loss_train: 0.9738 acc_train: 0.7214 loss_val: 1.0791 acc_val: 0.8080 time: 0.0458s\n",
            "4\n",
            "Epoch: 0246 loss_train: 0.9346 acc_train: 0.8071 loss_val: 1.0772 acc_val: 0.8060 time: 0.0445s\n",
            "5\n",
            "Epoch: 0247 loss_train: 0.9775 acc_train: 0.7714 loss_val: 1.0718 acc_val: 0.8020 time: 0.0452s\n",
            "0\n",
            "Epoch: 0248 loss_train: 0.9542 acc_train: 0.7643 loss_val: 1.0674 acc_val: 0.8020 time: 0.0443s\n",
            "0\n",
            "Epoch: 0249 loss_train: 0.9402 acc_train: 0.7786 loss_val: 1.0669 acc_val: 0.8080 time: 0.0437s\n",
            "0\n",
            "Epoch: 0250 loss_train: 0.9889 acc_train: 0.7571 loss_val: 1.0687 acc_val: 0.8080 time: 0.0450s\n",
            "0\n",
            "Epoch: 0251 loss_train: 0.9687 acc_train: 0.7929 loss_val: 1.0671 acc_val: 0.8060 time: 0.0443s\n",
            "1\n",
            "Epoch: 0252 loss_train: 0.9493 acc_train: 0.7357 loss_val: 1.0663 acc_val: 0.8020 time: 0.0441s\n",
            "2\n",
            "Epoch: 0253 loss_train: 0.9042 acc_train: 0.8000 loss_val: 1.0644 acc_val: 0.8040 time: 0.0439s\n",
            "0\n",
            "Epoch: 0254 loss_train: 0.9129 acc_train: 0.8143 loss_val: 1.0660 acc_val: 0.7980 time: 0.0445s\n",
            "0\n",
            "Epoch: 0255 loss_train: 0.9659 acc_train: 0.7714 loss_val: 1.0682 acc_val: 0.8040 time: 0.0455s\n",
            "1\n",
            "Epoch: 0256 loss_train: 0.9396 acc_train: 0.7429 loss_val: 1.0670 acc_val: 0.8060 time: 0.0447s\n",
            "2\n",
            "Epoch: 0257 loss_train: 0.9543 acc_train: 0.7786 loss_val: 1.0641 acc_val: 0.8100 time: 0.0445s\n",
            "3\n",
            "Epoch: 0258 loss_train: 0.9696 acc_train: 0.7357 loss_val: 1.0584 acc_val: 0.8000 time: 0.0441s\n",
            "0\n",
            "Epoch: 0259 loss_train: 0.9651 acc_train: 0.6786 loss_val: 1.0578 acc_val: 0.7940 time: 0.0451s\n",
            "0\n",
            "Epoch: 0260 loss_train: 0.9444 acc_train: 0.7500 loss_val: 1.0575 acc_val: 0.7960 time: 0.0460s\n",
            "0\n",
            "Epoch: 0261 loss_train: 0.9876 acc_train: 0.6929 loss_val: 1.0588 acc_val: 0.7980 time: 0.0440s\n",
            "0\n",
            "Epoch: 0262 loss_train: 0.9522 acc_train: 0.7214 loss_val: 1.0612 acc_val: 0.7980 time: 0.0453s\n",
            "1\n",
            "Epoch: 0263 loss_train: 0.9482 acc_train: 0.7643 loss_val: 1.0660 acc_val: 0.8020 time: 0.0445s\n",
            "2\n",
            "Epoch: 0264 loss_train: 0.9442 acc_train: 0.8143 loss_val: 1.0675 acc_val: 0.8060 time: 0.0447s\n",
            "3\n",
            "Epoch: 0265 loss_train: 0.9578 acc_train: 0.8143 loss_val: 1.0634 acc_val: 0.8040 time: 0.0488s\n",
            "4\n",
            "Epoch: 0266 loss_train: 0.9462 acc_train: 0.7357 loss_val: 1.0578 acc_val: 0.8080 time: 0.0474s\n",
            "5\n",
            "Epoch: 0267 loss_train: 0.9787 acc_train: 0.7643 loss_val: 1.0508 acc_val: 0.8040 time: 0.0450s\n",
            "6\n",
            "Epoch: 0268 loss_train: 0.9339 acc_train: 0.7857 loss_val: 1.0455 acc_val: 0.8020 time: 0.0450s\n",
            "0\n",
            "Epoch: 0269 loss_train: 0.9658 acc_train: 0.7714 loss_val: 1.0451 acc_val: 0.8040 time: 0.0454s\n",
            "0\n",
            "Epoch: 0270 loss_train: 0.9465 acc_train: 0.7429 loss_val: 1.0473 acc_val: 0.8020 time: 0.0460s\n",
            "0\n",
            "Epoch: 0271 loss_train: 0.9400 acc_train: 0.7071 loss_val: 1.0478 acc_val: 0.8020 time: 0.0446s\n",
            "1\n",
            "Epoch: 0272 loss_train: 0.9316 acc_train: 0.7286 loss_val: 1.0461 acc_val: 0.7960 time: 0.0445s\n",
            "2\n",
            "Epoch: 0273 loss_train: 0.9542 acc_train: 0.7643 loss_val: 1.0443 acc_val: 0.7920 time: 0.0444s\n",
            "3\n",
            "Epoch: 0274 loss_train: 0.9776 acc_train: 0.7143 loss_val: 1.0465 acc_val: 0.8000 time: 0.0441s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.9552 acc_train: 0.7286 loss_val: 1.0470 acc_val: 0.8020 time: 0.0463s\n",
            "1\n",
            "Epoch: 0276 loss_train: 0.9241 acc_train: 0.7000 loss_val: 1.0464 acc_val: 0.8020 time: 0.0444s\n",
            "2\n",
            "Epoch: 0277 loss_train: 0.9358 acc_train: 0.7286 loss_val: 1.0431 acc_val: 0.7960 time: 0.0444s\n",
            "3\n",
            "Epoch: 0278 loss_train: 0.9415 acc_train: 0.7357 loss_val: 1.0372 acc_val: 0.7960 time: 0.0441s\n",
            "0\n",
            "Epoch: 0279 loss_train: 0.9500 acc_train: 0.7143 loss_val: 1.0317 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0280 loss_train: 0.9430 acc_train: 0.7643 loss_val: 1.0305 acc_val: 0.7980 time: 0.0452s\n",
            "0\n",
            "Epoch: 0281 loss_train: 0.9246 acc_train: 0.7429 loss_val: 1.0324 acc_val: 0.7980 time: 0.0448s\n",
            "0\n",
            "Epoch: 0282 loss_train: 0.9258 acc_train: 0.7286 loss_val: 1.0364 acc_val: 0.7980 time: 0.0444s\n",
            "1\n",
            "Epoch: 0283 loss_train: 0.9682 acc_train: 0.7643 loss_val: 1.0404 acc_val: 0.7980 time: 0.0455s\n",
            "2\n",
            "Epoch: 0284 loss_train: 0.8966 acc_train: 0.8143 loss_val: 1.0408 acc_val: 0.7980 time: 0.0463s\n",
            "3\n",
            "Epoch: 0285 loss_train: 0.8863 acc_train: 0.8071 loss_val: 1.0331 acc_val: 0.7940 time: 0.0452s\n",
            "4\n",
            "Epoch: 0286 loss_train: 0.8939 acc_train: 0.7643 loss_val: 1.0230 acc_val: 0.7980 time: 0.0459s\n",
            "5\n",
            "Epoch: 0287 loss_train: 0.9053 acc_train: 0.7643 loss_val: 1.0167 acc_val: 0.8020 time: 0.0441s\n",
            "0\n",
            "Epoch: 0288 loss_train: 0.8762 acc_train: 0.8143 loss_val: 1.0143 acc_val: 0.8040 time: 0.0438s\n",
            "0\n",
            "Epoch: 0289 loss_train: 0.9424 acc_train: 0.7500 loss_val: 1.0202 acc_val: 0.8040 time: 0.0440s\n",
            "0\n",
            "Epoch: 0290 loss_train: 0.9467 acc_train: 0.6786 loss_val: 1.0300 acc_val: 0.8000 time: 0.0471s\n",
            "1\n",
            "Epoch: 0291 loss_train: 0.9168 acc_train: 0.7929 loss_val: 1.0373 acc_val: 0.7980 time: 0.0446s\n",
            "2\n",
            "Epoch: 0292 loss_train: 0.9061 acc_train: 0.8143 loss_val: 1.0377 acc_val: 0.8000 time: 0.0445s\n",
            "3\n",
            "Epoch: 0293 loss_train: 0.9498 acc_train: 0.7214 loss_val: 1.0389 acc_val: 0.8000 time: 0.0446s\n",
            "4\n",
            "Epoch: 0294 loss_train: 0.9016 acc_train: 0.8143 loss_val: 1.0371 acc_val: 0.8020 time: 0.0442s\n",
            "5\n",
            "Epoch: 0295 loss_train: 0.9085 acc_train: 0.8000 loss_val: 1.0331 acc_val: 0.7980 time: 0.0455s\n",
            "6\n",
            "Epoch: 0296 loss_train: 0.9274 acc_train: 0.7929 loss_val: 1.0320 acc_val: 0.8000 time: 0.0446s\n",
            "7\n",
            "Epoch: 0297 loss_train: 0.8867 acc_train: 0.8357 loss_val: 1.0325 acc_val: 0.8020 time: 0.0442s\n",
            "8\n",
            "Epoch: 0298 loss_train: 0.9209 acc_train: 0.7500 loss_val: 1.0325 acc_val: 0.8040 time: 0.0447s\n",
            "9\n",
            "Epoch: 0299 loss_train: 0.9041 acc_train: 0.7929 loss_val: 1.0285 acc_val: 0.7940 time: 0.0447s\n",
            "10\n",
            "Epoch: 0300 loss_train: 0.9461 acc_train: 0.7071 loss_val: 1.0213 acc_val: 0.7960 time: 0.0464s\n",
            "11\n",
            "Epoch: 0301 loss_train: 0.9178 acc_train: 0.7571 loss_val: 1.0125 acc_val: 0.8000 time: 0.0455s\n",
            "12\n",
            "Epoch: 0302 loss_train: 0.9348 acc_train: 0.7500 loss_val: 1.0101 acc_val: 0.8040 time: 0.0447s\n",
            "0\n",
            "Epoch: 0303 loss_train: 0.9535 acc_train: 0.6929 loss_val: 1.0135 acc_val: 0.8040 time: 0.0464s\n",
            "0\n",
            "Epoch: 0304 loss_train: 0.9359 acc_train: 0.7857 loss_val: 1.0210 acc_val: 0.8060 time: 0.0446s\n",
            "1\n",
            "Epoch: 0305 loss_train: 0.9550 acc_train: 0.6857 loss_val: 1.0281 acc_val: 0.8000 time: 0.0487s\n",
            "2\n",
            "Epoch: 0306 loss_train: 0.8923 acc_train: 0.7857 loss_val: 1.0394 acc_val: 0.8020 time: 0.0447s\n",
            "3\n",
            "Epoch: 0307 loss_train: 0.9614 acc_train: 0.7357 loss_val: 1.0445 acc_val: 0.7920 time: 0.0452s\n",
            "4\n",
            "Epoch: 0308 loss_train: 0.9027 acc_train: 0.7643 loss_val: 1.0429 acc_val: 0.7960 time: 0.0445s\n",
            "5\n",
            "Epoch: 0309 loss_train: 0.9151 acc_train: 0.7714 loss_val: 1.0323 acc_val: 0.8000 time: 0.0446s\n",
            "6\n",
            "Epoch: 0310 loss_train: 0.9212 acc_train: 0.7429 loss_val: 1.0187 acc_val: 0.7940 time: 0.0458s\n",
            "7\n",
            "Epoch: 0311 loss_train: 0.8525 acc_train: 0.8357 loss_val: 1.0044 acc_val: 0.8020 time: 0.0446s\n",
            "8\n",
            "Epoch: 0312 loss_train: 0.8911 acc_train: 0.7786 loss_val: 0.9980 acc_val: 0.8100 time: 0.0441s\n",
            "0\n",
            "Epoch: 0313 loss_train: 0.8831 acc_train: 0.7071 loss_val: 1.0001 acc_val: 0.8120 time: 0.0465s\n",
            "0\n",
            "Epoch: 0314 loss_train: 0.8888 acc_train: 0.7643 loss_val: 1.0085 acc_val: 0.8120 time: 0.0448s\n",
            "1\n",
            "Epoch: 0315 loss_train: 0.9236 acc_train: 0.8000 loss_val: 1.0143 acc_val: 0.8120 time: 0.0456s\n",
            "2\n",
            "Epoch: 0316 loss_train: 0.8810 acc_train: 0.7857 loss_val: 1.0219 acc_val: 0.8100 time: 0.0462s\n",
            "3\n",
            "Epoch: 0317 loss_train: 0.9122 acc_train: 0.7500 loss_val: 1.0221 acc_val: 0.8060 time: 0.0445s\n",
            "4\n",
            "Epoch: 0318 loss_train: 0.9372 acc_train: 0.7714 loss_val: 1.0173 acc_val: 0.8040 time: 0.0443s\n",
            "5\n",
            "Epoch: 0319 loss_train: 0.8754 acc_train: 0.7500 loss_val: 1.0105 acc_val: 0.8100 time: 0.0446s\n",
            "6\n",
            "Epoch: 0320 loss_train: 0.9306 acc_train: 0.7143 loss_val: 1.0070 acc_val: 0.8020 time: 0.0466s\n",
            "7\n",
            "Epoch: 0321 loss_train: 0.8853 acc_train: 0.8643 loss_val: 1.0062 acc_val: 0.8040 time: 0.0448s\n",
            "8\n",
            "Epoch: 0322 loss_train: 0.8644 acc_train: 0.7571 loss_val: 1.0043 acc_val: 0.7960 time: 0.0449s\n",
            "9\n",
            "Epoch: 0323 loss_train: 0.8886 acc_train: 0.8214 loss_val: 1.0043 acc_val: 0.8000 time: 0.0453s\n",
            "10\n",
            "Epoch: 0324 loss_train: 0.9457 acc_train: 0.7429 loss_val: 1.0085 acc_val: 0.8080 time: 0.0445s\n",
            "11\n",
            "Epoch: 0325 loss_train: 0.9240 acc_train: 0.7643 loss_val: 1.0097 acc_val: 0.8100 time: 0.0454s\n",
            "12\n",
            "Epoch: 0326 loss_train: 0.8610 acc_train: 0.8143 loss_val: 1.0108 acc_val: 0.8060 time: 0.0461s\n",
            "13\n",
            "Epoch: 0327 loss_train: 0.9268 acc_train: 0.7286 loss_val: 1.0113 acc_val: 0.8040 time: 0.0441s\n",
            "14\n",
            "Epoch: 0328 loss_train: 0.8945 acc_train: 0.8000 loss_val: 1.0132 acc_val: 0.8040 time: 0.0446s\n",
            "15\n",
            "Epoch: 0329 loss_train: 0.8605 acc_train: 0.7643 loss_val: 1.0140 acc_val: 0.8020 time: 0.0446s\n",
            "16\n",
            "Epoch: 0330 loss_train: 0.8312 acc_train: 0.7929 loss_val: 1.0116 acc_val: 0.8000 time: 0.0462s\n",
            "17\n",
            "Epoch: 0331 loss_train: 0.9364 acc_train: 0.7286 loss_val: 1.0120 acc_val: 0.7980 time: 0.0441s\n",
            "18\n",
            "Epoch: 0332 loss_train: 0.8699 acc_train: 0.8286 loss_val: 1.0104 acc_val: 0.8000 time: 0.0443s\n",
            "19\n",
            "Epoch: 0333 loss_train: 0.9481 acc_train: 0.7071 loss_val: 1.0090 acc_val: 0.8020 time: 0.0444s\n",
            "20\n",
            "Epoch: 0334 loss_train: 0.9075 acc_train: 0.7214 loss_val: 1.0082 acc_val: 0.8000 time: 0.0444s\n",
            "21\n",
            "Epoch: 0335 loss_train: 0.9173 acc_train: 0.7714 loss_val: 1.0076 acc_val: 0.7940 time: 0.0452s\n",
            "22\n",
            "Epoch: 0336 loss_train: 0.8968 acc_train: 0.7714 loss_val: 1.0067 acc_val: 0.7960 time: 0.0442s\n",
            "23\n",
            "Epoch: 0337 loss_train: 0.8905 acc_train: 0.8000 loss_val: 1.0061 acc_val: 0.8040 time: 0.0448s\n",
            "24\n",
            "Epoch: 0338 loss_train: 0.8967 acc_train: 0.7643 loss_val: 1.0021 acc_val: 0.8020 time: 0.0445s\n",
            "25\n",
            "Epoch: 0339 loss_train: 0.8898 acc_train: 0.7500 loss_val: 1.0018 acc_val: 0.8040 time: 0.0446s\n",
            "26\n",
            "Epoch: 0340 loss_train: 0.8509 acc_train: 0.8429 loss_val: 0.9984 acc_val: 0.8040 time: 0.0456s\n",
            "27\n",
            "Epoch: 0341 loss_train: 0.8718 acc_train: 0.7714 loss_val: 1.0018 acc_val: 0.8020 time: 0.0445s\n",
            "28\n",
            "Epoch: 0342 loss_train: 0.8696 acc_train: 0.7786 loss_val: 1.0066 acc_val: 0.8000 time: 0.0450s\n",
            "29\n",
            "Epoch: 0343 loss_train: 0.8767 acc_train: 0.7786 loss_val: 1.0083 acc_val: 0.8000 time: 0.0445s\n",
            "30\n",
            "Epoch: 0344 loss_train: 0.9180 acc_train: 0.7714 loss_val: 1.0103 acc_val: 0.8020 time: 0.0450s\n",
            "31\n",
            "Epoch: 0345 loss_train: 0.8867 acc_train: 0.8071 loss_val: 1.0081 acc_val: 0.8000 time: 0.0463s\n",
            "32\n",
            "Epoch: 0346 loss_train: 0.9194 acc_train: 0.7429 loss_val: 1.0026 acc_val: 0.7940 time: 0.0454s\n",
            "33\n",
            "Epoch: 0347 loss_train: 0.9009 acc_train: 0.7786 loss_val: 0.9955 acc_val: 0.7960 time: 0.0477s\n",
            "34\n",
            "Epoch: 0348 loss_train: 0.9037 acc_train: 0.7571 loss_val: 0.9903 acc_val: 0.7980 time: 0.0442s\n",
            "0\n",
            "Epoch: 0349 loss_train: 0.9038 acc_train: 0.7429 loss_val: 0.9917 acc_val: 0.7960 time: 0.0447s\n",
            "0\n",
            "Epoch: 0350 loss_train: 0.8324 acc_train: 0.8071 loss_val: 0.9897 acc_val: 0.8060 time: 0.0457s\n",
            "1\n",
            "Epoch: 0351 loss_train: 0.9199 acc_train: 0.7500 loss_val: 0.9897 acc_val: 0.8040 time: 0.0439s\n",
            "0\n",
            "Epoch: 0352 loss_train: 0.8727 acc_train: 0.7500 loss_val: 0.9931 acc_val: 0.8020 time: 0.0444s\n",
            "1\n",
            "Epoch: 0353 loss_train: 0.9138 acc_train: 0.7643 loss_val: 0.9990 acc_val: 0.8060 time: 0.0456s\n",
            "2\n",
            "Epoch: 0354 loss_train: 0.8674 acc_train: 0.8071 loss_val: 1.0016 acc_val: 0.8020 time: 0.0445s\n",
            "3\n",
            "Epoch: 0355 loss_train: 0.8547 acc_train: 0.7714 loss_val: 1.0027 acc_val: 0.8000 time: 0.0457s\n",
            "4\n",
            "Epoch: 0356 loss_train: 0.8609 acc_train: 0.8286 loss_val: 0.9972 acc_val: 0.8020 time: 0.0455s\n",
            "5\n",
            "Epoch: 0357 loss_train: 0.8968 acc_train: 0.7643 loss_val: 0.9897 acc_val: 0.8040 time: 0.0443s\n",
            "6\n",
            "Epoch: 0358 loss_train: 0.9227 acc_train: 0.7571 loss_val: 0.9868 acc_val: 0.8000 time: 0.0458s\n",
            "7\n",
            "Epoch: 0359 loss_train: 0.8493 acc_train: 0.8071 loss_val: 0.9861 acc_val: 0.8000 time: 0.0462s\n",
            "0\n",
            "Epoch: 0360 loss_train: 0.8900 acc_train: 0.8143 loss_val: 0.9885 acc_val: 0.8000 time: 0.0471s\n",
            "0\n",
            "Epoch: 0361 loss_train: 0.9049 acc_train: 0.7214 loss_val: 0.9910 acc_val: 0.8020 time: 0.0446s\n",
            "1\n",
            "Epoch: 0362 loss_train: 0.8876 acc_train: 0.7643 loss_val: 0.9926 acc_val: 0.7980 time: 0.0446s\n",
            "2\n",
            "Epoch: 0363 loss_train: 0.9121 acc_train: 0.7571 loss_val: 0.9947 acc_val: 0.8040 time: 0.0452s\n",
            "3\n",
            "Epoch: 0364 loss_train: 0.8873 acc_train: 0.7786 loss_val: 0.9907 acc_val: 0.8020 time: 0.0447s\n",
            "4\n",
            "Epoch: 0365 loss_train: 0.8860 acc_train: 0.7500 loss_val: 0.9890 acc_val: 0.8000 time: 0.0459s\n",
            "5\n",
            "Epoch: 0366 loss_train: 0.8569 acc_train: 0.7714 loss_val: 0.9879 acc_val: 0.7960 time: 0.0444s\n",
            "6\n",
            "Epoch: 0367 loss_train: 0.9081 acc_train: 0.7929 loss_val: 0.9905 acc_val: 0.7980 time: 0.0446s\n",
            "7\n",
            "Epoch: 0368 loss_train: 0.8666 acc_train: 0.7500 loss_val: 0.9937 acc_val: 0.7920 time: 0.0473s\n",
            "8\n",
            "Epoch: 0369 loss_train: 0.8176 acc_train: 0.7857 loss_val: 0.9944 acc_val: 0.7940 time: 0.0460s\n",
            "9\n",
            "Epoch: 0370 loss_train: 0.8812 acc_train: 0.7286 loss_val: 0.9949 acc_val: 0.7980 time: 0.0457s\n",
            "10\n",
            "Epoch: 0371 loss_train: 0.9079 acc_train: 0.7571 loss_val: 0.9923 acc_val: 0.7980 time: 0.0445s\n",
            "11\n",
            "Epoch: 0372 loss_train: 0.8936 acc_train: 0.8000 loss_val: 0.9930 acc_val: 0.8000 time: 0.0448s\n",
            "12\n",
            "Epoch: 0373 loss_train: 0.8475 acc_train: 0.7571 loss_val: 0.9956 acc_val: 0.7960 time: 0.0449s\n",
            "13\n",
            "Epoch: 0374 loss_train: 0.8839 acc_train: 0.7714 loss_val: 0.9976 acc_val: 0.7980 time: 0.0446s\n",
            "14\n",
            "Epoch: 0375 loss_train: 0.8529 acc_train: 0.7500 loss_val: 1.0015 acc_val: 0.7960 time: 0.0452s\n",
            "15\n",
            "Epoch: 0376 loss_train: 0.8835 acc_train: 0.7071 loss_val: 1.0031 acc_val: 0.7940 time: 0.0450s\n",
            "16\n",
            "Epoch: 0377 loss_train: 0.8536 acc_train: 0.7571 loss_val: 0.9995 acc_val: 0.7960 time: 0.0451s\n",
            "17\n",
            "Epoch: 0378 loss_train: 0.8096 acc_train: 0.8143 loss_val: 0.9882 acc_val: 0.7920 time: 0.0450s\n",
            "18\n",
            "Epoch: 0379 loss_train: 0.8524 acc_train: 0.7929 loss_val: 0.9767 acc_val: 0.7940 time: 0.0456s\n",
            "19\n",
            "Epoch: 0380 loss_train: 0.8706 acc_train: 0.7500 loss_val: 0.9710 acc_val: 0.7940 time: 0.0463s\n",
            "0\n",
            "Epoch: 0381 loss_train: 0.8631 acc_train: 0.7429 loss_val: 0.9683 acc_val: 0.8060 time: 0.0444s\n",
            "0\n",
            "Epoch: 0382 loss_train: 0.8493 acc_train: 0.7214 loss_val: 0.9688 acc_val: 0.8080 time: 0.0450s\n",
            "0\n",
            "Epoch: 0383 loss_train: 0.8675 acc_train: 0.7786 loss_val: 0.9737 acc_val: 0.8040 time: 0.0457s\n",
            "1\n",
            "Epoch: 0384 loss_train: 0.8809 acc_train: 0.8429 loss_val: 0.9815 acc_val: 0.7980 time: 0.0448s\n",
            "2\n",
            "Epoch: 0385 loss_train: 0.8671 acc_train: 0.7357 loss_val: 0.9918 acc_val: 0.8000 time: 0.0467s\n",
            "3\n",
            "Epoch: 0386 loss_train: 0.9115 acc_train: 0.8000 loss_val: 1.0015 acc_val: 0.7960 time: 0.0447s\n",
            "4\n",
            "Epoch: 0387 loss_train: 0.8344 acc_train: 0.8000 loss_val: 1.0039 acc_val: 0.8020 time: 0.0445s\n",
            "5\n",
            "Epoch: 0388 loss_train: 0.8663 acc_train: 0.7929 loss_val: 0.9974 acc_val: 0.8080 time: 0.0446s\n",
            "6\n",
            "Epoch: 0389 loss_train: 0.8893 acc_train: 0.7500 loss_val: 0.9839 acc_val: 0.8020 time: 0.0477s\n",
            "7\n",
            "Epoch: 0390 loss_train: 0.8500 acc_train: 0.7571 loss_val: 0.9691 acc_val: 0.7980 time: 0.0473s\n",
            "8\n",
            "Epoch: 0391 loss_train: 0.8732 acc_train: 0.7214 loss_val: 0.9574 acc_val: 0.8140 time: 0.0450s\n",
            "9\n",
            "Epoch: 0392 loss_train: 0.8852 acc_train: 0.7643 loss_val: 0.9550 acc_val: 0.8180 time: 0.0458s\n",
            "0\n",
            "Epoch: 0393 loss_train: 0.8831 acc_train: 0.8071 loss_val: 0.9620 acc_val: 0.8160 time: 0.0444s\n",
            "0\n",
            "Epoch: 0394 loss_train: 0.8746 acc_train: 0.7357 loss_val: 0.9722 acc_val: 0.8020 time: 0.0444s\n",
            "1\n",
            "Epoch: 0395 loss_train: 0.8875 acc_train: 0.7143 loss_val: 0.9884 acc_val: 0.8000 time: 0.0452s\n",
            "2\n",
            "Epoch: 0396 loss_train: 0.8865 acc_train: 0.7571 loss_val: 1.0012 acc_val: 0.7960 time: 0.0446s\n",
            "3\n",
            "Epoch: 0397 loss_train: 0.8654 acc_train: 0.8214 loss_val: 1.0037 acc_val: 0.8040 time: 0.0447s\n",
            "4\n",
            "Epoch: 0398 loss_train: 0.8413 acc_train: 0.8286 loss_val: 1.0013 acc_val: 0.8020 time: 0.0444s\n",
            "5\n",
            "Epoch: 0399 loss_train: 0.8420 acc_train: 0.7429 loss_val: 0.9918 acc_val: 0.8100 time: 0.0448s\n",
            "6\n",
            "Epoch: 0400 loss_train: 0.8778 acc_train: 0.7357 loss_val: 0.9759 acc_val: 0.8040 time: 0.0502s\n",
            "7\n",
            "Epoch: 0401 loss_train: 0.8297 acc_train: 0.7929 loss_val: 0.9604 acc_val: 0.8020 time: 0.0447s\n",
            "8\n",
            "Epoch: 0402 loss_train: 0.8937 acc_train: 0.7714 loss_val: 0.9524 acc_val: 0.8080 time: 0.0445s\n",
            "9\n",
            "Epoch: 0403 loss_train: 0.8850 acc_train: 0.8000 loss_val: 0.9545 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0404 loss_train: 0.8606 acc_train: 0.7500 loss_val: 0.9625 acc_val: 0.8060 time: 0.0450s\n",
            "1\n",
            "Epoch: 0405 loss_train: 0.8571 acc_train: 0.8071 loss_val: 0.9724 acc_val: 0.8020 time: 0.0486s\n",
            "2\n",
            "Epoch: 0406 loss_train: 0.8530 acc_train: 0.8071 loss_val: 0.9809 acc_val: 0.7980 time: 0.0451s\n",
            "3\n",
            "Epoch: 0407 loss_train: 0.8347 acc_train: 0.8643 loss_val: 0.9860 acc_val: 0.7980 time: 0.0450s\n",
            "4\n",
            "Epoch: 0408 loss_train: 0.9101 acc_train: 0.7643 loss_val: 0.9855 acc_val: 0.7980 time: 0.0446s\n",
            "5\n",
            "Epoch: 0409 loss_train: 0.8919 acc_train: 0.7571 loss_val: 0.9829 acc_val: 0.8000 time: 0.0447s\n",
            "6\n",
            "Epoch: 0410 loss_train: 0.8878 acc_train: 0.7143 loss_val: 0.9810 acc_val: 0.7960 time: 0.0502s\n",
            "7\n",
            "Epoch: 0411 loss_train: 0.9072 acc_train: 0.7357 loss_val: 0.9803 acc_val: 0.7960 time: 0.0457s\n",
            "8\n",
            "Epoch: 0412 loss_train: 0.8323 acc_train: 0.8214 loss_val: 0.9739 acc_val: 0.7960 time: 0.0449s\n",
            "9\n",
            "Epoch: 0413 loss_train: 0.8386 acc_train: 0.7786 loss_val: 0.9677 acc_val: 0.7900 time: 0.0444s\n",
            "10\n",
            "Epoch: 0414 loss_train: 0.8491 acc_train: 0.8071 loss_val: 0.9674 acc_val: 0.7980 time: 0.0446s\n",
            "11\n",
            "Epoch: 0415 loss_train: 0.8126 acc_train: 0.7929 loss_val: 0.9720 acc_val: 0.8020 time: 0.0533s\n",
            "12\n",
            "Epoch: 0416 loss_train: 0.7946 acc_train: 0.8214 loss_val: 0.9779 acc_val: 0.8000 time: 0.0464s\n",
            "13\n",
            "Epoch: 0417 loss_train: 0.8724 acc_train: 0.8071 loss_val: 0.9817 acc_val: 0.8000 time: 0.0454s\n",
            "14\n",
            "Epoch: 0418 loss_train: 0.8845 acc_train: 0.7571 loss_val: 0.9823 acc_val: 0.8020 time: 0.0446s\n",
            "15\n",
            "Epoch: 0419 loss_train: 0.8286 acc_train: 0.7929 loss_val: 0.9753 acc_val: 0.7960 time: 0.0451s\n",
            "16\n",
            "Epoch: 0420 loss_train: 0.8608 acc_train: 0.7429 loss_val: 0.9696 acc_val: 0.7980 time: 0.0472s\n",
            "17\n",
            "Epoch: 0421 loss_train: 0.8613 acc_train: 0.7857 loss_val: 0.9655 acc_val: 0.7940 time: 0.0449s\n",
            "18\n",
            "Epoch: 0422 loss_train: 0.8902 acc_train: 0.7714 loss_val: 0.9603 acc_val: 0.7960 time: 0.0443s\n",
            "19\n",
            "Epoch: 0423 loss_train: 0.8530 acc_train: 0.8143 loss_val: 0.9577 acc_val: 0.7980 time: 0.0454s\n",
            "20\n",
            "Epoch: 0424 loss_train: 0.8671 acc_train: 0.7357 loss_val: 0.9576 acc_val: 0.8020 time: 0.0444s\n",
            "21\n",
            "Epoch: 0425 loss_train: 0.8194 acc_train: 0.8429 loss_val: 0.9600 acc_val: 0.8100 time: 0.0464s\n",
            "22\n",
            "Epoch: 0426 loss_train: 0.8528 acc_train: 0.7929 loss_val: 0.9626 acc_val: 0.8120 time: 0.0445s\n",
            "23\n",
            "Epoch: 0427 loss_train: 0.8430 acc_train: 0.8571 loss_val: 0.9670 acc_val: 0.8080 time: 0.0450s\n",
            "24\n",
            "Epoch: 0428 loss_train: 0.8763 acc_train: 0.7786 loss_val: 0.9752 acc_val: 0.8060 time: 0.0443s\n",
            "25\n",
            "Epoch: 0429 loss_train: 0.8142 acc_train: 0.8357 loss_val: 0.9799 acc_val: 0.8040 time: 0.0449s\n",
            "26\n",
            "Epoch: 0430 loss_train: 0.8717 acc_train: 0.7500 loss_val: 0.9838 acc_val: 0.7960 time: 0.0474s\n",
            "27\n",
            "Epoch: 0431 loss_train: 0.9036 acc_train: 0.7000 loss_val: 0.9858 acc_val: 0.7960 time: 0.0473s\n",
            "28\n",
            "Epoch: 0432 loss_train: 0.8544 acc_train: 0.7357 loss_val: 0.9826 acc_val: 0.7920 time: 0.0465s\n",
            "29\n",
            "Epoch: 0433 loss_train: 0.8674 acc_train: 0.7786 loss_val: 0.9718 acc_val: 0.7960 time: 0.0443s\n",
            "30\n",
            "Epoch: 0434 loss_train: 0.8631 acc_train: 0.8071 loss_val: 0.9597 acc_val: 0.7980 time: 0.0445s\n",
            "31\n",
            "Epoch: 0435 loss_train: 0.8674 acc_train: 0.8357 loss_val: 0.9517 acc_val: 0.8060 time: 0.0461s\n",
            "32\n",
            "Epoch: 0436 loss_train: 0.8521 acc_train: 0.7786 loss_val: 0.9506 acc_val: 0.8180 time: 0.0449s\n",
            "0\n",
            "Epoch: 0437 loss_train: 0.8184 acc_train: 0.7929 loss_val: 0.9529 acc_val: 0.8140 time: 0.0444s\n",
            "0\n",
            "Epoch: 0438 loss_train: 0.8471 acc_train: 0.7429 loss_val: 0.9595 acc_val: 0.8080 time: 0.0446s\n",
            "1\n",
            "Epoch: 0439 loss_train: 0.8371 acc_train: 0.7643 loss_val: 0.9672 acc_val: 0.7980 time: 0.0445s\n",
            "2\n",
            "Epoch: 0440 loss_train: 0.9145 acc_train: 0.7214 loss_val: 0.9764 acc_val: 0.8020 time: 0.0455s\n",
            "3\n",
            "Epoch: 0441 loss_train: 0.8581 acc_train: 0.7643 loss_val: 0.9851 acc_val: 0.8000 time: 0.0461s\n",
            "4\n",
            "Epoch: 0442 loss_train: 0.8508 acc_train: 0.7786 loss_val: 0.9873 acc_val: 0.7980 time: 0.0449s\n",
            "5\n",
            "Epoch: 0443 loss_train: 0.8402 acc_train: 0.7286 loss_val: 0.9867 acc_val: 0.8000 time: 0.0447s\n",
            "6\n",
            "Epoch: 0444 loss_train: 0.8557 acc_train: 0.8000 loss_val: 0.9776 acc_val: 0.7960 time: 0.0446s\n",
            "7\n",
            "Epoch: 0445 loss_train: 0.8293 acc_train: 0.7500 loss_val: 0.9648 acc_val: 0.7980 time: 0.0455s\n",
            "8\n",
            "Epoch: 0446 loss_train: 0.8649 acc_train: 0.7643 loss_val: 0.9533 acc_val: 0.7980 time: 0.0450s\n",
            "9\n",
            "Epoch: 0447 loss_train: 0.8304 acc_train: 0.7857 loss_val: 0.9496 acc_val: 0.8080 time: 0.0446s\n",
            "10\n",
            "Epoch: 0448 loss_train: 0.8339 acc_train: 0.7786 loss_val: 0.9478 acc_val: 0.8080 time: 0.0449s\n",
            "0\n",
            "Epoch: 0449 loss_train: 0.8379 acc_train: 0.8429 loss_val: 0.9482 acc_val: 0.8080 time: 0.0464s\n",
            "0\n",
            "Epoch: 0450 loss_train: 0.8333 acc_train: 0.7857 loss_val: 0.9564 acc_val: 0.7960 time: 0.0453s\n",
            "1\n",
            "Epoch: 0451 loss_train: 0.8686 acc_train: 0.7929 loss_val: 0.9664 acc_val: 0.8000 time: 0.0448s\n",
            "2\n",
            "Epoch: 0452 loss_train: 0.8242 acc_train: 0.8214 loss_val: 0.9791 acc_val: 0.7920 time: 0.0501s\n",
            "3\n",
            "Epoch: 0453 loss_train: 0.8631 acc_train: 0.7643 loss_val: 0.9888 acc_val: 0.7960 time: 0.0475s\n",
            "4\n",
            "Epoch: 0454 loss_train: 0.8199 acc_train: 0.7786 loss_val: 0.9908 acc_val: 0.7960 time: 0.0451s\n",
            "5\n",
            "Epoch: 0455 loss_train: 0.8415 acc_train: 0.7786 loss_val: 0.9859 acc_val: 0.7960 time: 0.0455s\n",
            "6\n",
            "Epoch: 0456 loss_train: 0.8151 acc_train: 0.7857 loss_val: 0.9778 acc_val: 0.7960 time: 0.0439s\n",
            "7\n",
            "Epoch: 0457 loss_train: 0.8223 acc_train: 0.7929 loss_val: 0.9722 acc_val: 0.7940 time: 0.0445s\n",
            "8\n",
            "Epoch: 0458 loss_train: 0.8001 acc_train: 0.8071 loss_val: 0.9641 acc_val: 0.7980 time: 0.0448s\n",
            "9\n",
            "Epoch: 0459 loss_train: 0.8407 acc_train: 0.8071 loss_val: 0.9576 acc_val: 0.8020 time: 0.0448s\n",
            "10\n",
            "Epoch: 0460 loss_train: 0.7897 acc_train: 0.8000 loss_val: 0.9533 acc_val: 0.8000 time: 0.0470s\n",
            "11\n",
            "Epoch: 0461 loss_train: 0.8457 acc_train: 0.7571 loss_val: 0.9529 acc_val: 0.7980 time: 0.0459s\n",
            "12\n",
            "Epoch: 0462 loss_train: 0.8265 acc_train: 0.7857 loss_val: 0.9539 acc_val: 0.8000 time: 0.0469s\n",
            "13\n",
            "Epoch: 0463 loss_train: 0.8537 acc_train: 0.7786 loss_val: 0.9586 acc_val: 0.7980 time: 0.0447s\n",
            "14\n",
            "Epoch: 0464 loss_train: 0.8110 acc_train: 0.8357 loss_val: 0.9637 acc_val: 0.7980 time: 0.0449s\n",
            "15\n",
            "Epoch: 0465 loss_train: 0.8455 acc_train: 0.7929 loss_val: 0.9676 acc_val: 0.8000 time: 0.0457s\n",
            "16\n",
            "Epoch: 0466 loss_train: 0.8447 acc_train: 0.7071 loss_val: 0.9716 acc_val: 0.8020 time: 0.0450s\n",
            "17\n",
            "Epoch: 0467 loss_train: 0.8666 acc_train: 0.7786 loss_val: 0.9696 acc_val: 0.8020 time: 0.0444s\n",
            "18\n",
            "Epoch: 0468 loss_train: 0.8715 acc_train: 0.7214 loss_val: 0.9658 acc_val: 0.8020 time: 0.0445s\n",
            "19\n",
            "Epoch: 0469 loss_train: 0.7852 acc_train: 0.8143 loss_val: 0.9595 acc_val: 0.7980 time: 0.0448s\n",
            "20\n",
            "Epoch: 0470 loss_train: 0.8694 acc_train: 0.7000 loss_val: 0.9568 acc_val: 0.8020 time: 0.0454s\n",
            "21\n",
            "Epoch: 0471 loss_train: 0.8311 acc_train: 0.7429 loss_val: 0.9562 acc_val: 0.7980 time: 0.0447s\n",
            "22\n",
            "Epoch: 0472 loss_train: 0.8290 acc_train: 0.7857 loss_val: 0.9546 acc_val: 0.7980 time: 0.0445s\n",
            "23\n",
            "Epoch: 0473 loss_train: 0.8623 acc_train: 0.7786 loss_val: 0.9560 acc_val: 0.7960 time: 0.0450s\n",
            "24\n",
            "Epoch: 0474 loss_train: 0.7667 acc_train: 0.8000 loss_val: 0.9520 acc_val: 0.7980 time: 0.0459s\n",
            "25\n",
            "Epoch: 0475 loss_train: 0.8478 acc_train: 0.7786 loss_val: 0.9508 acc_val: 0.8000 time: 0.0458s\n",
            "26\n",
            "Epoch: 0476 loss_train: 0.8274 acc_train: 0.7286 loss_val: 0.9528 acc_val: 0.8020 time: 0.0469s\n",
            "27\n",
            "Epoch: 0477 loss_train: 0.7872 acc_train: 0.8071 loss_val: 0.9496 acc_val: 0.8040 time: 0.0454s\n",
            "28\n",
            "Epoch: 0478 loss_train: 0.8170 acc_train: 0.7643 loss_val: 0.9478 acc_val: 0.8020 time: 0.0441s\n",
            "29\n",
            "Epoch: 0479 loss_train: 0.8228 acc_train: 0.7857 loss_val: 0.9516 acc_val: 0.8060 time: 0.0455s\n",
            "0\n",
            "Epoch: 0480 loss_train: 0.8188 acc_train: 0.7500 loss_val: 0.9590 acc_val: 0.7960 time: 0.0468s\n",
            "1\n",
            "Epoch: 0481 loss_train: 0.8265 acc_train: 0.7786 loss_val: 0.9630 acc_val: 0.7960 time: 0.0457s\n",
            "2\n",
            "Epoch: 0482 loss_train: 0.8553 acc_train: 0.7929 loss_val: 0.9631 acc_val: 0.7940 time: 0.0453s\n",
            "3\n",
            "Epoch: 0483 loss_train: 0.8319 acc_train: 0.7857 loss_val: 0.9606 acc_val: 0.7940 time: 0.0459s\n",
            "4\n",
            "Epoch: 0484 loss_train: 0.8148 acc_train: 0.8000 loss_val: 0.9606 acc_val: 0.7980 time: 0.0449s\n",
            "5\n",
            "Epoch: 0485 loss_train: 0.8330 acc_train: 0.8357 loss_val: 0.9590 acc_val: 0.7960 time: 0.0455s\n",
            "6\n",
            "Epoch: 0486 loss_train: 0.8425 acc_train: 0.8143 loss_val: 0.9572 acc_val: 0.7960 time: 0.0511s\n",
            "7\n",
            "Epoch: 0487 loss_train: 0.8353 acc_train: 0.7571 loss_val: 0.9533 acc_val: 0.8020 time: 0.0458s\n",
            "8\n",
            "Epoch: 0488 loss_train: 0.8448 acc_train: 0.7929 loss_val: 0.9520 acc_val: 0.8020 time: 0.0463s\n",
            "9\n",
            "Epoch: 0489 loss_train: 0.8362 acc_train: 0.8286 loss_val: 0.9507 acc_val: 0.7960 time: 0.0446s\n",
            "10\n",
            "Epoch: 0490 loss_train: 0.8272 acc_train: 0.8286 loss_val: 0.9491 acc_val: 0.7940 time: 0.0452s\n",
            "11\n",
            "Epoch: 0491 loss_train: 0.8176 acc_train: 0.8071 loss_val: 0.9490 acc_val: 0.8000 time: 0.0450s\n",
            "12\n",
            "Epoch: 0492 loss_train: 0.8041 acc_train: 0.8143 loss_val: 0.9472 acc_val: 0.7980 time: 0.0443s\n",
            "13\n",
            "Epoch: 0493 loss_train: 0.8412 acc_train: 0.7786 loss_val: 0.9527 acc_val: 0.8000 time: 0.0443s\n",
            "0\n",
            "Epoch: 0494 loss_train: 0.8192 acc_train: 0.7714 loss_val: 0.9527 acc_val: 0.7980 time: 0.0446s\n",
            "1\n",
            "Epoch: 0495 loss_train: 0.7866 acc_train: 0.8000 loss_val: 0.9475 acc_val: 0.8000 time: 0.0468s\n",
            "2\n",
            "Epoch: 0496 loss_train: 0.8182 acc_train: 0.7071 loss_val: 0.9440 acc_val: 0.8020 time: 0.0447s\n",
            "3\n",
            "Epoch: 0497 loss_train: 0.8390 acc_train: 0.8357 loss_val: 0.9409 acc_val: 0.8140 time: 0.0446s\n",
            "0\n",
            "Epoch: 0498 loss_train: 0.8797 acc_train: 0.7429 loss_val: 0.9397 acc_val: 0.8120 time: 0.0445s\n",
            "0\n",
            "Epoch: 0499 loss_train: 0.8497 acc_train: 0.8000 loss_val: 0.9379 acc_val: 0.8140 time: 0.0440s\n",
            "0\n",
            "Epoch: 0500 loss_train: 0.8179 acc_train: 0.7714 loss_val: 0.9418 acc_val: 0.8060 time: 0.0450s\n",
            "0\n",
            "Epoch: 0501 loss_train: 0.8560 acc_train: 0.8000 loss_val: 0.9540 acc_val: 0.7980 time: 0.0444s\n",
            "1\n",
            "Epoch: 0502 loss_train: 0.8517 acc_train: 0.8429 loss_val: 0.9645 acc_val: 0.7960 time: 0.0441s\n",
            "2\n",
            "Epoch: 0503 loss_train: 0.8448 acc_train: 0.8071 loss_val: 0.9704 acc_val: 0.7940 time: 0.0442s\n",
            "3\n",
            "Epoch: 0504 loss_train: 0.8698 acc_train: 0.7786 loss_val: 0.9729 acc_val: 0.8000 time: 0.0451s\n",
            "4\n",
            "Epoch: 0505 loss_train: 0.8514 acc_train: 0.7643 loss_val: 0.9667 acc_val: 0.7980 time: 0.0455s\n",
            "5\n",
            "Epoch: 0506 loss_train: 0.8135 acc_train: 0.8357 loss_val: 0.9552 acc_val: 0.7940 time: 0.0446s\n",
            "6\n",
            "Epoch: 0507 loss_train: 0.8452 acc_train: 0.7571 loss_val: 0.9471 acc_val: 0.8020 time: 0.0456s\n",
            "7\n",
            "Epoch: 0508 loss_train: 0.8248 acc_train: 0.8143 loss_val: 0.9400 acc_val: 0.8000 time: 0.0446s\n",
            "8\n",
            "Epoch: 0509 loss_train: 0.8441 acc_train: 0.7929 loss_val: 0.9349 acc_val: 0.8080 time: 0.0453s\n",
            "9\n",
            "Epoch: 0510 loss_train: 0.8234 acc_train: 0.7643 loss_val: 0.9305 acc_val: 0.8180 time: 0.0459s\n",
            "0\n",
            "Epoch: 0511 loss_train: 0.8672 acc_train: 0.8000 loss_val: 0.9337 acc_val: 0.8120 time: 0.0442s\n",
            "0\n",
            "Epoch: 0512 loss_train: 0.8670 acc_train: 0.8143 loss_val: 0.9456 acc_val: 0.8100 time: 0.0449s\n",
            "1\n",
            "Epoch: 0513 loss_train: 0.8357 acc_train: 0.7429 loss_val: 0.9576 acc_val: 0.8000 time: 0.0443s\n",
            "2\n",
            "Epoch: 0514 loss_train: 0.8266 acc_train: 0.8214 loss_val: 0.9652 acc_val: 0.8020 time: 0.0446s\n",
            "3\n",
            "Epoch: 0515 loss_train: 0.8911 acc_train: 0.7857 loss_val: 0.9700 acc_val: 0.8000 time: 0.0466s\n",
            "4\n",
            "Epoch: 0516 loss_train: 0.8467 acc_train: 0.7571 loss_val: 0.9649 acc_val: 0.7960 time: 0.0469s\n",
            "5\n",
            "Epoch: 0517 loss_train: 0.7953 acc_train: 0.8429 loss_val: 0.9591 acc_val: 0.7960 time: 0.0459s\n",
            "6\n",
            "Epoch: 0518 loss_train: 0.7720 acc_train: 0.8214 loss_val: 0.9476 acc_val: 0.7940 time: 0.0446s\n",
            "7\n",
            "Epoch: 0519 loss_train: 0.8525 acc_train: 0.7714 loss_val: 0.9390 acc_val: 0.7980 time: 0.0442s\n",
            "8\n",
            "Epoch: 0520 loss_train: 0.8135 acc_train: 0.7786 loss_val: 0.9353 acc_val: 0.8040 time: 0.0455s\n",
            "9\n",
            "Epoch: 0521 loss_train: 0.8366 acc_train: 0.7786 loss_val: 0.9363 acc_val: 0.8060 time: 0.0446s\n",
            "10\n",
            "Epoch: 0522 loss_train: 0.8719 acc_train: 0.7929 loss_val: 0.9400 acc_val: 0.8080 time: 0.0468s\n",
            "11\n",
            "Epoch: 0523 loss_train: 0.7845 acc_train: 0.8429 loss_val: 0.9457 acc_val: 0.8100 time: 0.0444s\n",
            "12\n",
            "Epoch: 0524 loss_train: 0.8399 acc_train: 0.8143 loss_val: 0.9532 acc_val: 0.8020 time: 0.0448s\n",
            "13\n",
            "Epoch: 0525 loss_train: 0.8428 acc_train: 0.7929 loss_val: 0.9602 acc_val: 0.8000 time: 0.0480s\n",
            "14\n",
            "Epoch: 0526 loss_train: 0.8711 acc_train: 0.7643 loss_val: 0.9667 acc_val: 0.8000 time: 0.0449s\n",
            "15\n",
            "Epoch: 0527 loss_train: 0.8196 acc_train: 0.7929 loss_val: 0.9663 acc_val: 0.7980 time: 0.0457s\n",
            "16\n",
            "Epoch: 0528 loss_train: 0.8078 acc_train: 0.7857 loss_val: 0.9585 acc_val: 0.8000 time: 0.0446s\n",
            "17\n",
            "Epoch: 0529 loss_train: 0.8252 acc_train: 0.7643 loss_val: 0.9447 acc_val: 0.7980 time: 0.0442s\n",
            "18\n",
            "Epoch: 0530 loss_train: 0.8079 acc_train: 0.7500 loss_val: 0.9334 acc_val: 0.8000 time: 0.0455s\n",
            "19\n",
            "Epoch: 0531 loss_train: 0.7973 acc_train: 0.8357 loss_val: 0.9232 acc_val: 0.8120 time: 0.0461s\n",
            "20\n",
            "Epoch: 0532 loss_train: 0.8306 acc_train: 0.8286 loss_val: 0.9177 acc_val: 0.8120 time: 0.0441s\n",
            "0\n",
            "Epoch: 0533 loss_train: 0.8420 acc_train: 0.7429 loss_val: 0.9194 acc_val: 0.8100 time: 0.0438s\n",
            "0\n",
            "Epoch: 0534 loss_train: 0.8422 acc_train: 0.7500 loss_val: 0.9286 acc_val: 0.8040 time: 0.0442s\n",
            "1\n",
            "Epoch: 0535 loss_train: 0.8521 acc_train: 0.8143 loss_val: 0.9414 acc_val: 0.8000 time: 0.0461s\n",
            "2\n",
            "Epoch: 0536 loss_train: 0.8192 acc_train: 0.8357 loss_val: 0.9545 acc_val: 0.7980 time: 0.0444s\n",
            "3\n",
            "Epoch: 0537 loss_train: 0.8155 acc_train: 0.8214 loss_val: 0.9651 acc_val: 0.7940 time: 0.0458s\n",
            "4\n",
            "Epoch: 0538 loss_train: 0.8059 acc_train: 0.8429 loss_val: 0.9656 acc_val: 0.7980 time: 0.0454s\n",
            "5\n",
            "Epoch: 0539 loss_train: 0.8368 acc_train: 0.8286 loss_val: 0.9577 acc_val: 0.8020 time: 0.0445s\n",
            "6\n",
            "Epoch: 0540 loss_train: 0.8130 acc_train: 0.8143 loss_val: 0.9478 acc_val: 0.8020 time: 0.0451s\n",
            "7\n",
            "Epoch: 0541 loss_train: 0.8506 acc_train: 0.8071 loss_val: 0.9403 acc_val: 0.8080 time: 0.0446s\n",
            "8\n",
            "Epoch: 0542 loss_train: 0.8255 acc_train: 0.7143 loss_val: 0.9348 acc_val: 0.8080 time: 0.0446s\n",
            "9\n",
            "Epoch: 0543 loss_train: 0.8377 acc_train: 0.7643 loss_val: 0.9320 acc_val: 0.7980 time: 0.0444s\n",
            "10\n",
            "Epoch: 0544 loss_train: 0.8580 acc_train: 0.7429 loss_val: 0.9349 acc_val: 0.7940 time: 0.0441s\n",
            "11\n",
            "Epoch: 0545 loss_train: 0.8348 acc_train: 0.8429 loss_val: 0.9428 acc_val: 0.7960 time: 0.0452s\n",
            "12\n",
            "Epoch: 0546 loss_train: 0.8348 acc_train: 0.8357 loss_val: 0.9521 acc_val: 0.7980 time: 0.0446s\n",
            "13\n",
            "Epoch: 0547 loss_train: 0.8372 acc_train: 0.7857 loss_val: 0.9572 acc_val: 0.7980 time: 0.0445s\n",
            "14\n",
            "Epoch: 0548 loss_train: 0.8269 acc_train: 0.7571 loss_val: 0.9591 acc_val: 0.7920 time: 0.0466s\n",
            "15\n",
            "Epoch: 0549 loss_train: 0.8371 acc_train: 0.7929 loss_val: 0.9546 acc_val: 0.8020 time: 0.0448s\n",
            "16\n",
            "Epoch: 0550 loss_train: 0.8053 acc_train: 0.8000 loss_val: 0.9518 acc_val: 0.8100 time: 0.0461s\n",
            "17\n",
            "Epoch: 0551 loss_train: 0.8467 acc_train: 0.8071 loss_val: 0.9497 acc_val: 0.8160 time: 0.0445s\n",
            "18\n",
            "Epoch: 0552 loss_train: 0.8282 acc_train: 0.7786 loss_val: 0.9447 acc_val: 0.8140 time: 0.0442s\n",
            "19\n",
            "Epoch: 0553 loss_train: 0.8743 acc_train: 0.7714 loss_val: 0.9373 acc_val: 0.8060 time: 0.0449s\n",
            "20\n",
            "Epoch: 0554 loss_train: 0.8290 acc_train: 0.8214 loss_val: 0.9340 acc_val: 0.7960 time: 0.0442s\n",
            "21\n",
            "Epoch: 0555 loss_train: 0.8122 acc_train: 0.7929 loss_val: 0.9345 acc_val: 0.7920 time: 0.0453s\n",
            "22\n",
            "Epoch: 0556 loss_train: 0.7915 acc_train: 0.7571 loss_val: 0.9375 acc_val: 0.7960 time: 0.0447s\n",
            "23\n",
            "Epoch: 0557 loss_train: 0.8251 acc_train: 0.8143 loss_val: 0.9382 acc_val: 0.7940 time: 0.0444s\n",
            "24\n",
            "Epoch: 0558 loss_train: 0.8307 acc_train: 0.8214 loss_val: 0.9392 acc_val: 0.7960 time: 0.0452s\n",
            "25\n",
            "Epoch: 0559 loss_train: 0.8375 acc_train: 0.8071 loss_val: 0.9423 acc_val: 0.8020 time: 0.0472s\n",
            "26\n",
            "Epoch: 0560 loss_train: 0.8500 acc_train: 0.8214 loss_val: 0.9438 acc_val: 0.8020 time: 0.0476s\n",
            "27\n",
            "Epoch: 0561 loss_train: 0.8004 acc_train: 0.8357 loss_val: 0.9443 acc_val: 0.8000 time: 0.0453s\n",
            "28\n",
            "Epoch: 0562 loss_train: 0.7881 acc_train: 0.8071 loss_val: 0.9427 acc_val: 0.8000 time: 0.0444s\n",
            "29\n",
            "Epoch: 0563 loss_train: 0.8101 acc_train: 0.8000 loss_val: 0.9406 acc_val: 0.8020 time: 0.0441s\n",
            "30\n",
            "Epoch: 0564 loss_train: 0.8319 acc_train: 0.7786 loss_val: 0.9393 acc_val: 0.8080 time: 0.0449s\n",
            "31\n",
            "Epoch: 0565 loss_train: 0.8191 acc_train: 0.8286 loss_val: 0.9373 acc_val: 0.8060 time: 0.0478s\n",
            "32\n",
            "Epoch: 0566 loss_train: 0.8171 acc_train: 0.8214 loss_val: 0.9381 acc_val: 0.8020 time: 0.0476s\n",
            "33\n",
            "Epoch: 0567 loss_train: 0.8165 acc_train: 0.8000 loss_val: 0.9394 acc_val: 0.7980 time: 0.0455s\n",
            "34\n",
            "Epoch: 0568 loss_train: 0.7927 acc_train: 0.8357 loss_val: 0.9385 acc_val: 0.7900 time: 0.0447s\n",
            "35\n",
            "Epoch: 0569 loss_train: 0.8193 acc_train: 0.7571 loss_val: 0.9359 acc_val: 0.7900 time: 0.0445s\n",
            "36\n",
            "Epoch: 0570 loss_train: 0.8272 acc_train: 0.8071 loss_val: 0.9374 acc_val: 0.7960 time: 0.0457s\n",
            "37\n",
            "Epoch: 0571 loss_train: 0.8084 acc_train: 0.8143 loss_val: 0.9432 acc_val: 0.7980 time: 0.0446s\n",
            "38\n",
            "Epoch: 0572 loss_train: 0.8113 acc_train: 0.7857 loss_val: 0.9481 acc_val: 0.8000 time: 0.0453s\n",
            "39\n",
            "Epoch: 0573 loss_train: 0.7941 acc_train: 0.8286 loss_val: 0.9497 acc_val: 0.8020 time: 0.0450s\n",
            "40\n",
            "Epoch: 0574 loss_train: 0.8357 acc_train: 0.7714 loss_val: 0.9486 acc_val: 0.8000 time: 0.0453s\n",
            "41\n",
            "Epoch: 0575 loss_train: 0.8279 acc_train: 0.8071 loss_val: 0.9472 acc_val: 0.8000 time: 0.0454s\n",
            "42\n",
            "Epoch: 0576 loss_train: 0.8187 acc_train: 0.8286 loss_val: 0.9411 acc_val: 0.8080 time: 0.0444s\n",
            "43\n",
            "Epoch: 0577 loss_train: 0.8257 acc_train: 0.7786 loss_val: 0.9364 acc_val: 0.8120 time: 0.0447s\n",
            "44\n",
            "Epoch: 0578 loss_train: 0.8238 acc_train: 0.7929 loss_val: 0.9339 acc_val: 0.8100 time: 0.0446s\n",
            "45\n",
            "Epoch: 0579 loss_train: 0.8109 acc_train: 0.7857 loss_val: 0.9361 acc_val: 0.8020 time: 0.0447s\n",
            "46\n",
            "Epoch: 0580 loss_train: 0.7903 acc_train: 0.7643 loss_val: 0.9405 acc_val: 0.8040 time: 0.0471s\n",
            "47\n",
            "Epoch: 0581 loss_train: 0.8830 acc_train: 0.7500 loss_val: 0.9496 acc_val: 0.8000 time: 0.0445s\n",
            "48\n",
            "Epoch: 0582 loss_train: 0.8317 acc_train: 0.8500 loss_val: 0.9525 acc_val: 0.7960 time: 0.0441s\n",
            "49\n",
            "Epoch: 0583 loss_train: 0.8228 acc_train: 0.7714 loss_val: 0.9506 acc_val: 0.7940 time: 0.0444s\n",
            "50\n",
            "Epoch: 0584 loss_train: 0.8404 acc_train: 0.7643 loss_val: 0.9469 acc_val: 0.7940 time: 0.0443s\n",
            "51\n",
            "Epoch: 0585 loss_train: 0.8322 acc_train: 0.8286 loss_val: 0.9453 acc_val: 0.7980 time: 0.0455s\n",
            "52\n",
            "Epoch: 0586 loss_train: 0.7857 acc_train: 0.8143 loss_val: 0.9417 acc_val: 0.7980 time: 0.0453s\n",
            "53\n",
            "Epoch: 0587 loss_train: 0.7936 acc_train: 0.8071 loss_val: 0.9385 acc_val: 0.8060 time: 0.0444s\n",
            "54\n",
            "Epoch: 0588 loss_train: 0.8074 acc_train: 0.8000 loss_val: 0.9354 acc_val: 0.8060 time: 0.0448s\n",
            "55\n",
            "Epoch: 0589 loss_train: 0.8239 acc_train: 0.8000 loss_val: 0.9368 acc_val: 0.8000 time: 0.0446s\n",
            "56\n",
            "Epoch: 0590 loss_train: 0.8491 acc_train: 0.8071 loss_val: 0.9342 acc_val: 0.8000 time: 0.0453s\n",
            "57\n",
            "Epoch: 0591 loss_train: 0.8128 acc_train: 0.7500 loss_val: 0.9377 acc_val: 0.7940 time: 0.0442s\n",
            "58\n",
            "Epoch: 0592 loss_train: 0.8017 acc_train: 0.7857 loss_val: 0.9441 acc_val: 0.7960 time: 0.0442s\n",
            "59\n",
            "Epoch: 0593 loss_train: 0.8325 acc_train: 0.7214 loss_val: 0.9460 acc_val: 0.7980 time: 0.0444s\n",
            "60\n",
            "Epoch: 0594 loss_train: 0.8448 acc_train: 0.7571 loss_val: 0.9467 acc_val: 0.7980 time: 0.0445s\n",
            "61\n",
            "Epoch: 0595 loss_train: 0.7998 acc_train: 0.8071 loss_val: 0.9464 acc_val: 0.7980 time: 0.0457s\n",
            "62\n",
            "Epoch: 0596 loss_train: 0.8416 acc_train: 0.7643 loss_val: 0.9401 acc_val: 0.7960 time: 0.0445s\n",
            "63\n",
            "Epoch: 0597 loss_train: 0.8575 acc_train: 0.7357 loss_val: 0.9365 acc_val: 0.7940 time: 0.0453s\n",
            "64\n",
            "Epoch: 0598 loss_train: 0.8255 acc_train: 0.7929 loss_val: 0.9352 acc_val: 0.8060 time: 0.0444s\n",
            "65\n",
            "Epoch: 0599 loss_train: 0.8102 acc_train: 0.8143 loss_val: 0.9350 acc_val: 0.8060 time: 0.0446s\n",
            "66\n",
            "Epoch: 0600 loss_train: 0.8102 acc_train: 0.8357 loss_val: 0.9321 acc_val: 0.8040 time: 0.0473s\n",
            "67\n",
            "Epoch: 0601 loss_train: 0.7902 acc_train: 0.8143 loss_val: 0.9323 acc_val: 0.7960 time: 0.0477s\n",
            "68\n",
            "Epoch: 0602 loss_train: 0.8095 acc_train: 0.8000 loss_val: 0.9306 acc_val: 0.7940 time: 0.0455s\n",
            "69\n",
            "Epoch: 0603 loss_train: 0.8109 acc_train: 0.8071 loss_val: 0.9310 acc_val: 0.7940 time: 0.0443s\n",
            "70\n",
            "Epoch: 0604 loss_train: 0.7947 acc_train: 0.8500 loss_val: 0.9342 acc_val: 0.7900 time: 0.0442s\n",
            "71\n",
            "Epoch: 0605 loss_train: 0.8151 acc_train: 0.8429 loss_val: 0.9395 acc_val: 0.7920 time: 0.0476s\n",
            "72\n",
            "Epoch: 0606 loss_train: 0.8358 acc_train: 0.8000 loss_val: 0.9448 acc_val: 0.7940 time: 0.0445s\n",
            "73\n",
            "Epoch: 0607 loss_train: 0.8371 acc_train: 0.7429 loss_val: 0.9458 acc_val: 0.7980 time: 0.0444s\n",
            "74\n",
            "Epoch: 0608 loss_train: 0.8089 acc_train: 0.8071 loss_val: 0.9478 acc_val: 0.8000 time: 0.0442s\n",
            "75\n",
            "Epoch: 0609 loss_train: 0.8065 acc_train: 0.7929 loss_val: 0.9458 acc_val: 0.8020 time: 0.0449s\n",
            "76\n",
            "Epoch: 0610 loss_train: 0.8128 acc_train: 0.8143 loss_val: 0.9387 acc_val: 0.8040 time: 0.0456s\n",
            "77\n",
            "Epoch: 0611 loss_train: 0.8662 acc_train: 0.7286 loss_val: 0.9356 acc_val: 0.8080 time: 0.0443s\n",
            "78\n",
            "Epoch: 0612 loss_train: 0.8141 acc_train: 0.8571 loss_val: 0.9322 acc_val: 0.8040 time: 0.0454s\n",
            "79\n",
            "Epoch: 0613 loss_train: 0.8638 acc_train: 0.7286 loss_val: 0.9332 acc_val: 0.7960 time: 0.0446s\n",
            "80\n",
            "Epoch: 0614 loss_train: 0.7606 acc_train: 0.8214 loss_val: 0.9370 acc_val: 0.8000 time: 0.0449s\n",
            "81\n",
            "Epoch: 0615 loss_train: 0.8526 acc_train: 0.8071 loss_val: 0.9406 acc_val: 0.7980 time: 0.0455s\n",
            "82\n",
            "Epoch: 0616 loss_train: 0.7919 acc_train: 0.8143 loss_val: 0.9437 acc_val: 0.7880 time: 0.0451s\n",
            "83\n",
            "Epoch: 0617 loss_train: 0.8267 acc_train: 0.8214 loss_val: 0.9466 acc_val: 0.7940 time: 0.0447s\n",
            "84\n",
            "Epoch: 0618 loss_train: 0.8461 acc_train: 0.7571 loss_val: 0.9484 acc_val: 0.8040 time: 0.0445s\n",
            "85\n",
            "Epoch: 0619 loss_train: 0.8307 acc_train: 0.8286 loss_val: 0.9490 acc_val: 0.8020 time: 0.0443s\n",
            "86\n",
            "Epoch: 0620 loss_train: 0.8038 acc_train: 0.7929 loss_val: 0.9467 acc_val: 0.8040 time: 0.0451s\n",
            "87\n",
            "Epoch: 0621 loss_train: 0.8135 acc_train: 0.7714 loss_val: 0.9418 acc_val: 0.8080 time: 0.0446s\n",
            "88\n",
            "Epoch: 0622 loss_train: 0.7826 acc_train: 0.8500 loss_val: 0.9343 acc_val: 0.8040 time: 0.0461s\n",
            "89\n",
            "Epoch: 0623 loss_train: 0.8585 acc_train: 0.7429 loss_val: 0.9283 acc_val: 0.8020 time: 0.0456s\n",
            "90\n",
            "Epoch: 0624 loss_train: 0.7830 acc_train: 0.7786 loss_val: 0.9264 acc_val: 0.8020 time: 0.0444s\n",
            "91\n",
            "Epoch: 0625 loss_train: 0.8286 acc_train: 0.8357 loss_val: 0.9242 acc_val: 0.8060 time: 0.0453s\n",
            "92\n",
            "Epoch: 0626 loss_train: 0.8207 acc_train: 0.7857 loss_val: 0.9249 acc_val: 0.8060 time: 0.0449s\n",
            "93\n",
            "Epoch: 0627 loss_train: 0.8294 acc_train: 0.8143 loss_val: 0.9298 acc_val: 0.8060 time: 0.0446s\n",
            "94\n",
            "Epoch: 0628 loss_train: 0.8251 acc_train: 0.8357 loss_val: 0.9346 acc_val: 0.8060 time: 0.0477s\n",
            "95\n",
            "Epoch: 0629 loss_train: 0.8321 acc_train: 0.7500 loss_val: 0.9411 acc_val: 0.8060 time: 0.0445s\n",
            "96\n",
            "Epoch: 0630 loss_train: 0.8398 acc_train: 0.8071 loss_val: 0.9470 acc_val: 0.8000 time: 0.0459s\n",
            "97\n",
            "Epoch: 0631 loss_train: 0.7994 acc_train: 0.8214 loss_val: 0.9492 acc_val: 0.8020 time: 0.0447s\n",
            "98\n",
            "Epoch: 0632 loss_train: 0.8159 acc_train: 0.7786 loss_val: 0.9526 acc_val: 0.8000 time: 0.0445s\n",
            "99\n",
            "Epoch: 0633 loss_train: 0.8822 acc_train: 0.7500 loss_val: 0.9536 acc_val: 0.8000 time: 0.0443s\n",
            "100\n",
            "Epoch: 0634 loss_train: 0.8353 acc_train: 0.7857 loss_val: 0.9544 acc_val: 0.7980 time: 0.0468s\n",
            "101\n",
            "Epoch: 0635 loss_train: 0.8172 acc_train: 0.7643 loss_val: 0.9516 acc_val: 0.7980 time: 0.0476s\n",
            "102\n",
            "Epoch: 0636 loss_train: 0.8174 acc_train: 0.7857 loss_val: 0.9473 acc_val: 0.8000 time: 0.0453s\n",
            "103\n",
            "Epoch: 0637 loss_train: 0.8591 acc_train: 0.7857 loss_val: 0.9449 acc_val: 0.8000 time: 0.0447s\n",
            "104\n",
            "Epoch: 0638 loss_train: 0.8440 acc_train: 0.7714 loss_val: 0.9388 acc_val: 0.8080 time: 0.0446s\n",
            "105\n",
            "Epoch: 0639 loss_train: 0.8306 acc_train: 0.7929 loss_val: 0.9353 acc_val: 0.8120 time: 0.0438s\n",
            "106\n",
            "Epoch: 0640 loss_train: 0.8102 acc_train: 0.8286 loss_val: 0.9301 acc_val: 0.8140 time: 0.0466s\n",
            "107\n",
            "Epoch: 0641 loss_train: 0.8462 acc_train: 0.7071 loss_val: 0.9304 acc_val: 0.8140 time: 0.0470s\n",
            "108\n",
            "Epoch: 0642 loss_train: 0.8393 acc_train: 0.7714 loss_val: 0.9326 acc_val: 0.8080 time: 0.0454s\n",
            "109\n",
            "Epoch: 0643 loss_train: 0.7800 acc_train: 0.8000 loss_val: 0.9360 acc_val: 0.8000 time: 0.0467s\n",
            "110\n",
            "Epoch: 0644 loss_train: 0.8011 acc_train: 0.8286 loss_val: 0.9422 acc_val: 0.7960 time: 0.0475s\n",
            "111\n",
            "Epoch: 0645 loss_train: 0.8033 acc_train: 0.7786 loss_val: 0.9461 acc_val: 0.7940 time: 0.0457s\n",
            "112\n",
            "Epoch: 0646 loss_train: 0.8569 acc_train: 0.7786 loss_val: 0.9484 acc_val: 0.7960 time: 0.0446s\n",
            "113\n",
            "Epoch: 0647 loss_train: 0.8514 acc_train: 0.7571 loss_val: 0.9465 acc_val: 0.7980 time: 0.0445s\n",
            "114\n",
            "Epoch: 0648 loss_train: 0.8311 acc_train: 0.7857 loss_val: 0.9419 acc_val: 0.8000 time: 0.0446s\n",
            "115\n",
            "Epoch: 0649 loss_train: 0.7877 acc_train: 0.8071 loss_val: 0.9395 acc_val: 0.8000 time: 0.0446s\n",
            "116\n",
            "Epoch: 0650 loss_train: 0.8420 acc_train: 0.7857 loss_val: 0.9375 acc_val: 0.8060 time: 0.0456s\n",
            "117\n",
            "Epoch: 0651 loss_train: 0.8143 acc_train: 0.7786 loss_val: 0.9339 acc_val: 0.8060 time: 0.0449s\n",
            "118\n",
            "Epoch: 0652 loss_train: 0.8740 acc_train: 0.7857 loss_val: 0.9359 acc_val: 0.8000 time: 0.0461s\n",
            "119\n",
            "Epoch: 0653 loss_train: 0.8150 acc_train: 0.7571 loss_val: 0.9365 acc_val: 0.7920 time: 0.0445s\n",
            "120\n",
            "Epoch: 0654 loss_train: 0.8475 acc_train: 0.8286 loss_val: 0.9385 acc_val: 0.7900 time: 0.0447s\n",
            "121\n",
            "Epoch: 0655 loss_train: 0.7935 acc_train: 0.7929 loss_val: 0.9415 acc_val: 0.7940 time: 0.0479s\n",
            "122\n",
            "Epoch: 0656 loss_train: 0.8366 acc_train: 0.7571 loss_val: 0.9427 acc_val: 0.7900 time: 0.0446s\n",
            "123\n",
            "Epoch: 0657 loss_train: 0.8196 acc_train: 0.8357 loss_val: 0.9431 acc_val: 0.7920 time: 0.0443s\n",
            "124\n",
            "Epoch: 0658 loss_train: 0.8546 acc_train: 0.8071 loss_val: 0.9429 acc_val: 0.7980 time: 0.0447s\n",
            "125\n",
            "Epoch: 0659 loss_train: 0.8248 acc_train: 0.7357 loss_val: 0.9404 acc_val: 0.7980 time: 0.0446s\n",
            "126\n",
            "Epoch: 0660 loss_train: 0.8408 acc_train: 0.7929 loss_val: 0.9355 acc_val: 0.8060 time: 0.0453s\n",
            "127\n",
            "Epoch: 0661 loss_train: 0.8350 acc_train: 0.7286 loss_val: 0.9331 acc_val: 0.8060 time: 0.0446s\n",
            "128\n",
            "Epoch: 0662 loss_train: 0.8031 acc_train: 0.7500 loss_val: 0.9328 acc_val: 0.8040 time: 0.0448s\n",
            "129\n",
            "Epoch: 0663 loss_train: 0.8061 acc_train: 0.7929 loss_val: 0.9361 acc_val: 0.7900 time: 0.0441s\n",
            "130\n",
            "Epoch: 0664 loss_train: 0.7938 acc_train: 0.7929 loss_val: 0.9375 acc_val: 0.7940 time: 0.0444s\n",
            "131\n",
            "Epoch: 0665 loss_train: 0.8644 acc_train: 0.7714 loss_val: 0.9451 acc_val: 0.7960 time: 0.0478s\n",
            "132\n",
            "Epoch: 0666 loss_train: 0.8150 acc_train: 0.7571 loss_val: 0.9462 acc_val: 0.7980 time: 0.0441s\n",
            "133\n",
            "Epoch: 0667 loss_train: 0.7929 acc_train: 0.7643 loss_val: 0.9445 acc_val: 0.8000 time: 0.0443s\n",
            "134\n",
            "Epoch: 0668 loss_train: 0.8163 acc_train: 0.8071 loss_val: 0.9401 acc_val: 0.7980 time: 0.0446s\n",
            "135\n",
            "Epoch: 0669 loss_train: 0.8176 acc_train: 0.8000 loss_val: 0.9335 acc_val: 0.7980 time: 0.0451s\n",
            "136\n",
            "Epoch: 0670 loss_train: 0.8044 acc_train: 0.7214 loss_val: 0.9305 acc_val: 0.8000 time: 0.0455s\n",
            "137\n",
            "Epoch: 0671 loss_train: 0.8279 acc_train: 0.8000 loss_val: 0.9340 acc_val: 0.7960 time: 0.0444s\n",
            "138\n",
            "Epoch: 0672 loss_train: 0.8660 acc_train: 0.8000 loss_val: 0.9410 acc_val: 0.7980 time: 0.0459s\n",
            "139\n",
            "Epoch: 0673 loss_train: 0.8251 acc_train: 0.7857 loss_val: 0.9451 acc_val: 0.7940 time: 0.0445s\n",
            "140\n",
            "Epoch: 0674 loss_train: 0.7873 acc_train: 0.7786 loss_val: 0.9461 acc_val: 0.7960 time: 0.0442s\n",
            "141\n",
            "Epoch: 0675 loss_train: 0.7977 acc_train: 0.8000 loss_val: 0.9456 acc_val: 0.7980 time: 0.0461s\n",
            "142\n",
            "Epoch: 0676 loss_train: 0.8114 acc_train: 0.8000 loss_val: 0.9447 acc_val: 0.7980 time: 0.0454s\n",
            "143\n",
            "Epoch: 0677 loss_train: 0.7858 acc_train: 0.7714 loss_val: 0.9409 acc_val: 0.8020 time: 0.0461s\n",
            "144\n",
            "Epoch: 0678 loss_train: 0.8455 acc_train: 0.7857 loss_val: 0.9369 acc_val: 0.8020 time: 0.0451s\n",
            "145\n",
            "Epoch: 0679 loss_train: 0.8212 acc_train: 0.7500 loss_val: 0.9352 acc_val: 0.8000 time: 0.0447s\n",
            "146\n",
            "Epoch: 0680 loss_train: 0.8137 acc_train: 0.7857 loss_val: 0.9332 acc_val: 0.8000 time: 0.0479s\n",
            "147\n",
            "Epoch: 0681 loss_train: 0.7984 acc_train: 0.8143 loss_val: 0.9303 acc_val: 0.7980 time: 0.0449s\n",
            "148\n",
            "Epoch: 0682 loss_train: 0.8142 acc_train: 0.8000 loss_val: 0.9290 acc_val: 0.7980 time: 0.0442s\n",
            "149\n",
            "Epoch: 0683 loss_train: 0.8198 acc_train: 0.8286 loss_val: 0.9296 acc_val: 0.8000 time: 0.0439s\n",
            "150\n",
            "Epoch: 0684 loss_train: 0.8680 acc_train: 0.7714 loss_val: 0.9285 acc_val: 0.7980 time: 0.0443s\n",
            "151\n",
            "Epoch: 0685 loss_train: 0.7981 acc_train: 0.7786 loss_val: 0.9321 acc_val: 0.8000 time: 0.0452s\n",
            "152\n",
            "Epoch: 0686 loss_train: 0.8539 acc_train: 0.7143 loss_val: 0.9368 acc_val: 0.8000 time: 0.0449s\n",
            "153\n",
            "Epoch: 0687 loss_train: 0.8114 acc_train: 0.8214 loss_val: 0.9420 acc_val: 0.8000 time: 0.0463s\n",
            "154\n",
            "Epoch: 0688 loss_train: 0.7947 acc_train: 0.8357 loss_val: 0.9425 acc_val: 0.8020 time: 0.0478s\n",
            "155\n",
            "Epoch: 0689 loss_train: 0.8323 acc_train: 0.8071 loss_val: 0.9442 acc_val: 0.8000 time: 0.0464s\n",
            "156\n",
            "Epoch: 0690 loss_train: 0.8140 acc_train: 0.7929 loss_val: 0.9467 acc_val: 0.7960 time: 0.0463s\n",
            "157\n",
            "Epoch: 0691 loss_train: 0.7642 acc_train: 0.8071 loss_val: 0.9443 acc_val: 0.7920 time: 0.0447s\n",
            "158\n",
            "Epoch: 0692 loss_train: 0.8350 acc_train: 0.7857 loss_val: 0.9401 acc_val: 0.7960 time: 0.0441s\n",
            "159\n",
            "Epoch: 0693 loss_train: 0.8200 acc_train: 0.8143 loss_val: 0.9343 acc_val: 0.7960 time: 0.0444s\n",
            "160\n",
            "Epoch: 0694 loss_train: 0.8304 acc_train: 0.7786 loss_val: 0.9277 acc_val: 0.7980 time: 0.0464s\n",
            "161\n",
            "Epoch: 0695 loss_train: 0.8326 acc_train: 0.8429 loss_val: 0.9268 acc_val: 0.8020 time: 0.0455s\n",
            "162\n",
            "Epoch: 0696 loss_train: 0.8763 acc_train: 0.8357 loss_val: 0.9294 acc_val: 0.8000 time: 0.0443s\n",
            "163\n",
            "Epoch: 0697 loss_train: 0.8183 acc_train: 0.8000 loss_val: 0.9318 acc_val: 0.7960 time: 0.0446s\n",
            "164\n",
            "Epoch: 0698 loss_train: 0.7706 acc_train: 0.7714 loss_val: 0.9353 acc_val: 0.7980 time: 0.0444s\n",
            "165\n",
            "Epoch: 0699 loss_train: 0.8158 acc_train: 0.7714 loss_val: 0.9383 acc_val: 0.7960 time: 0.0449s\n",
            "166\n",
            "Epoch: 0700 loss_train: 0.8305 acc_train: 0.7429 loss_val: 0.9411 acc_val: 0.7900 time: 0.0475s\n",
            "167\n",
            "Epoch: 0701 loss_train: 0.7923 acc_train: 0.7500 loss_val: 0.9404 acc_val: 0.7880 time: 0.0454s\n",
            "168\n",
            "Epoch: 0702 loss_train: 0.8384 acc_train: 0.7929 loss_val: 0.9368 acc_val: 0.7900 time: 0.0446s\n",
            "169\n",
            "Epoch: 0703 loss_train: 0.7972 acc_train: 0.7786 loss_val: 0.9331 acc_val: 0.7960 time: 0.0443s\n",
            "170\n",
            "Epoch: 0704 loss_train: 0.8049 acc_train: 0.8286 loss_val: 0.9321 acc_val: 0.8020 time: 0.0444s\n",
            "171\n",
            "Epoch: 0705 loss_train: 0.7869 acc_train: 0.7857 loss_val: 0.9339 acc_val: 0.8060 time: 0.0457s\n",
            "172\n",
            "Epoch: 0706 loss_train: 0.7964 acc_train: 0.7857 loss_val: 0.9353 acc_val: 0.8040 time: 0.0445s\n",
            "173\n",
            "Epoch: 0707 loss_train: 0.8650 acc_train: 0.7000 loss_val: 0.9394 acc_val: 0.8000 time: 0.0448s\n",
            "174\n",
            "Epoch: 0708 loss_train: 0.8163 acc_train: 0.8000 loss_val: 0.9417 acc_val: 0.7940 time: 0.0462s\n",
            "175\n",
            "Epoch: 0709 loss_train: 0.8104 acc_train: 0.7714 loss_val: 0.9411 acc_val: 0.7940 time: 0.0448s\n",
            "176\n",
            "Epoch: 0710 loss_train: 0.8446 acc_train: 0.7643 loss_val: 0.9390 acc_val: 0.7940 time: 0.0468s\n",
            "177\n",
            "Epoch: 0711 loss_train: 0.8104 acc_train: 0.7714 loss_val: 0.9365 acc_val: 0.7940 time: 0.0454s\n",
            "178\n",
            "Epoch: 0712 loss_train: 0.8104 acc_train: 0.8071 loss_val: 0.9373 acc_val: 0.7920 time: 0.0450s\n",
            "179\n",
            "Epoch: 0713 loss_train: 0.8285 acc_train: 0.7714 loss_val: 0.9380 acc_val: 0.7920 time: 0.0444s\n",
            "180\n",
            "Epoch: 0714 loss_train: 0.8239 acc_train: 0.8000 loss_val: 0.9376 acc_val: 0.7940 time: 0.0458s\n",
            "181\n",
            "Epoch: 0715 loss_train: 0.8117 acc_train: 0.7500 loss_val: 0.9348 acc_val: 0.7960 time: 0.0457s\n",
            "182\n",
            "Epoch: 0716 loss_train: 0.8178 acc_train: 0.7857 loss_val: 0.9317 acc_val: 0.7980 time: 0.0442s\n",
            "183\n",
            "Epoch: 0717 loss_train: 0.8374 acc_train: 0.7429 loss_val: 0.9333 acc_val: 0.8020 time: 0.0441s\n",
            "184\n",
            "Epoch: 0718 loss_train: 0.7895 acc_train: 0.7929 loss_val: 0.9345 acc_val: 0.8020 time: 0.0444s\n",
            "185\n",
            "Epoch: 0719 loss_train: 0.8010 acc_train: 0.7857 loss_val: 0.9390 acc_val: 0.8080 time: 0.0447s\n",
            "186\n",
            "Epoch: 0720 loss_train: 0.8311 acc_train: 0.8214 loss_val: 0.9469 acc_val: 0.8000 time: 0.0451s\n",
            "187\n",
            "Epoch: 0721 loss_train: 0.8369 acc_train: 0.7571 loss_val: 0.9490 acc_val: 0.7980 time: 0.0444s\n",
            "188\n",
            "Epoch: 0722 loss_train: 0.8011 acc_train: 0.7929 loss_val: 0.9492 acc_val: 0.8000 time: 0.0454s\n",
            "189\n",
            "Epoch: 0723 loss_train: 0.8249 acc_train: 0.7357 loss_val: 0.9429 acc_val: 0.7980 time: 0.0441s\n",
            "190\n",
            "Epoch: 0724 loss_train: 0.7934 acc_train: 0.7857 loss_val: 0.9342 acc_val: 0.8000 time: 0.0443s\n",
            "191\n",
            "Epoch: 0725 loss_train: 0.8022 acc_train: 0.8357 loss_val: 0.9252 acc_val: 0.7980 time: 0.0452s\n",
            "192\n",
            "Epoch: 0726 loss_train: 0.8215 acc_train: 0.7571 loss_val: 0.9205 acc_val: 0.7980 time: 0.0445s\n",
            "193\n",
            "Epoch: 0727 loss_train: 0.8215 acc_train: 0.7286 loss_val: 0.9194 acc_val: 0.7960 time: 0.0443s\n",
            "194\n",
            "Epoch: 0728 loss_train: 0.8413 acc_train: 0.7571 loss_val: 0.9234 acc_val: 0.8000 time: 0.0445s\n",
            "195\n",
            "Epoch: 0729 loss_train: 0.7966 acc_train: 0.7071 loss_val: 0.9338 acc_val: 0.7940 time: 0.0464s\n",
            "196\n",
            "Epoch: 0730 loss_train: 0.8050 acc_train: 0.7500 loss_val: 0.9455 acc_val: 0.7960 time: 0.0451s\n",
            "197\n",
            "Epoch: 0731 loss_train: 0.7831 acc_train: 0.8286 loss_val: 0.9578 acc_val: 0.7940 time: 0.0443s\n",
            "198\n",
            "Epoch: 0732 loss_train: 0.8067 acc_train: 0.7929 loss_val: 0.9641 acc_val: 0.7980 time: 0.0445s\n",
            "199\n",
            "Early stop! Min loss:  0.9177087545394897 , Max accuracy:  0.8180000000000001\n",
            "Early stop model validation loss:  0.9177087545394897 , accuracy:  0.812\n",
            "Optimization Finished!\n",
            "Total time elapsed: 35.5562s\n",
            "Loading 531th epoch\n",
            "Test set results: loss= 0.8894 accuracy= 0.8450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8450, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qqvI0rEgtFh",
        "outputId": "85cf5581-02ee-4ac3-9073-7693059657b0"
      },
      "source": [
        "Train(lam=0) #pubmed\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 5.2474 acc_train: 0.4333 loss_val: 2.0049 acc_val: 0.4160 time: 0.1588s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.9157 acc_train: 0.4000 loss_val: 1.1156 acc_val: 0.4160 time: 0.1444s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.2248 acc_train: 0.6333 loss_val: 1.0686 acc_val: 0.3880 time: 0.1472s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.2495 acc_train: 0.5167 loss_val: 1.0772 acc_val: 0.3880 time: 0.1443s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.2806 acc_train: 0.5000 loss_val: 1.0813 acc_val: 0.4160 time: 0.1459s\n",
            "1\n",
            "Epoch: 0006 loss_train: 1.3184 acc_train: 0.4333 loss_val: 1.1581 acc_val: 0.4160 time: 0.1453s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.2430 acc_train: 0.5167 loss_val: 1.1059 acc_val: 0.4160 time: 0.1455s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.1276 acc_train: 0.3833 loss_val: 1.0676 acc_val: 0.3880 time: 0.1448s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.1118 acc_train: 0.4500 loss_val: 1.0643 acc_val: 0.3880 time: 0.1448s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.0740 acc_train: 0.4333 loss_val: 1.0667 acc_val: 0.4160 time: 0.1443s\n",
            "0\n",
            "Epoch: 0011 loss_train: 0.9873 acc_train: 0.4667 loss_val: 1.1285 acc_val: 0.4160 time: 0.1456s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.0099 acc_train: 0.5333 loss_val: 1.1350 acc_val: 0.4160 time: 0.1448s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.9412 acc_train: 0.5167 loss_val: 1.0765 acc_val: 0.4160 time: 0.1476s\n",
            "0\n",
            "Epoch: 0014 loss_train: 0.9089 acc_train: 0.5333 loss_val: 1.0328 acc_val: 0.4160 time: 0.1460s\n",
            "0\n",
            "Epoch: 0015 loss_train: 0.9417 acc_train: 0.5833 loss_val: 1.0076 acc_val: 0.4200 time: 0.1454s\n",
            "0\n",
            "Epoch: 0016 loss_train: 0.9185 acc_train: 0.5333 loss_val: 0.9872 acc_val: 0.4280 time: 0.1459s\n",
            "0\n",
            "Epoch: 0017 loss_train: 0.8790 acc_train: 0.6833 loss_val: 0.9759 acc_val: 0.4380 time: 0.1454s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.0328 acc_train: 0.5500 loss_val: 0.9243 acc_val: 0.4820 time: 0.1444s\n",
            "0\n",
            "Epoch: 0019 loss_train: 0.8721 acc_train: 0.7000 loss_val: 0.8751 acc_val: 0.5700 time: 0.1448s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.0709 acc_train: 0.6500 loss_val: 0.8361 acc_val: 0.7260 time: 0.1450s\n",
            "0\n",
            "Epoch: 0021 loss_train: 0.7638 acc_train: 0.5667 loss_val: 0.8021 acc_val: 0.7040 time: 0.1448s\n",
            "0\n",
            "Epoch: 0022 loss_train: 0.7763 acc_train: 0.6667 loss_val: 0.7936 acc_val: 0.6960 time: 0.1445s\n",
            "0\n",
            "Epoch: 0023 loss_train: 0.7690 acc_train: 0.8000 loss_val: 0.7825 acc_val: 0.7000 time: 0.1449s\n",
            "0\n",
            "Epoch: 0024 loss_train: 0.8374 acc_train: 0.6500 loss_val: 0.7374 acc_val: 0.7480 time: 0.1444s\n",
            "0\n",
            "Epoch: 0025 loss_train: 0.6958 acc_train: 0.7167 loss_val: 0.6848 acc_val: 0.7580 time: 0.1455s\n",
            "0\n",
            "Epoch: 0026 loss_train: 0.8037 acc_train: 0.6167 loss_val: 0.6651 acc_val: 0.7640 time: 0.1461s\n",
            "0\n",
            "Epoch: 0027 loss_train: 0.6928 acc_train: 0.6833 loss_val: 0.6508 acc_val: 0.7880 time: 0.1448s\n",
            "0\n",
            "Epoch: 0028 loss_train: 0.8315 acc_train: 0.6333 loss_val: 0.6499 acc_val: 0.7660 time: 0.1447s\n",
            "0\n",
            "Epoch: 0029 loss_train: 0.7844 acc_train: 0.6167 loss_val: 0.6598 acc_val: 0.7660 time: 0.1446s\n",
            "0\n",
            "Epoch: 0030 loss_train: 0.7809 acc_train: 0.5500 loss_val: 0.6678 acc_val: 0.7700 time: 0.1458s\n",
            "1\n",
            "Epoch: 0031 loss_train: 0.6164 acc_train: 0.7167 loss_val: 0.6756 acc_val: 0.7640 time: 0.1455s\n",
            "2\n",
            "Epoch: 0032 loss_train: 0.6695 acc_train: 0.6667 loss_val: 0.6949 acc_val: 0.7580 time: 0.1456s\n",
            "3\n",
            "Epoch: 0033 loss_train: 0.6234 acc_train: 0.7000 loss_val: 0.7019 acc_val: 0.7580 time: 0.1461s\n",
            "4\n",
            "Epoch: 0034 loss_train: 0.6897 acc_train: 0.7333 loss_val: 0.6724 acc_val: 0.7680 time: 0.1448s\n",
            "5\n",
            "Epoch: 0035 loss_train: 0.6416 acc_train: 0.7000 loss_val: 0.6594 acc_val: 0.7640 time: 0.1455s\n",
            "6\n",
            "Epoch: 0036 loss_train: 0.6336 acc_train: 0.7667 loss_val: 0.6329 acc_val: 0.7740 time: 0.1451s\n",
            "7\n",
            "Epoch: 0037 loss_train: 0.5966 acc_train: 0.7000 loss_val: 0.6408 acc_val: 0.7700 time: 0.1449s\n",
            "0\n",
            "Epoch: 0038 loss_train: 0.6214 acc_train: 0.8000 loss_val: 0.6578 acc_val: 0.7640 time: 0.1451s\n",
            "1\n",
            "Epoch: 0039 loss_train: 0.6571 acc_train: 0.6833 loss_val: 0.6889 acc_val: 0.7560 time: 0.1462s\n",
            "2\n",
            "Epoch: 0040 loss_train: 0.6163 acc_train: 0.8500 loss_val: 0.6836 acc_val: 0.7520 time: 0.1462s\n",
            "3\n",
            "Epoch: 0041 loss_train: 0.6592 acc_train: 0.7667 loss_val: 0.6382 acc_val: 0.7680 time: 0.1457s\n",
            "4\n",
            "Epoch: 0042 loss_train: 0.5761 acc_train: 0.7500 loss_val: 0.6168 acc_val: 0.7800 time: 0.1453s\n",
            "5\n",
            "Epoch: 0043 loss_train: 0.5831 acc_train: 0.7833 loss_val: 0.6084 acc_val: 0.7900 time: 0.1452s\n",
            "0\n",
            "Epoch: 0044 loss_train: 0.5259 acc_train: 0.8000 loss_val: 0.6116 acc_val: 0.7840 time: 0.1447s\n",
            "0\n",
            "Epoch: 0045 loss_train: 0.6726 acc_train: 0.6667 loss_val: 0.5698 acc_val: 0.8000 time: 0.1454s\n",
            "1\n",
            "Epoch: 0046 loss_train: 0.6298 acc_train: 0.7333 loss_val: 0.5472 acc_val: 0.8040 time: 0.1449s\n",
            "0\n",
            "Epoch: 0047 loss_train: 0.6076 acc_train: 0.8000 loss_val: 0.5426 acc_val: 0.8080 time: 0.1451s\n",
            "0\n",
            "Epoch: 0048 loss_train: 0.5819 acc_train: 0.7667 loss_val: 0.5409 acc_val: 0.8080 time: 0.1443s\n",
            "0\n",
            "Epoch: 0049 loss_train: 0.5310 acc_train: 0.7500 loss_val: 0.5548 acc_val: 0.7820 time: 0.1445s\n",
            "0\n",
            "Epoch: 0050 loss_train: 0.5509 acc_train: 0.8333 loss_val: 0.5586 acc_val: 0.7660 time: 0.1448s\n",
            "1\n",
            "Epoch: 0051 loss_train: 0.6282 acc_train: 0.7167 loss_val: 0.5597 acc_val: 0.7700 time: 0.1449s\n",
            "2\n",
            "Epoch: 0052 loss_train: 0.5230 acc_train: 0.7000 loss_val: 0.5588 acc_val: 0.7800 time: 0.1459s\n",
            "3\n",
            "Epoch: 0053 loss_train: 0.6213 acc_train: 0.8333 loss_val: 0.5439 acc_val: 0.7960 time: 0.1453s\n",
            "4\n",
            "Epoch: 0054 loss_train: 0.5241 acc_train: 0.8333 loss_val: 0.5219 acc_val: 0.7940 time: 0.1450s\n",
            "5\n",
            "Epoch: 0055 loss_train: 0.5655 acc_train: 0.7667 loss_val: 0.5321 acc_val: 0.7840 time: 0.1453s\n",
            "0\n",
            "Epoch: 0056 loss_train: 0.5152 acc_train: 0.8000 loss_val: 0.5340 acc_val: 0.7780 time: 0.1456s\n",
            "1\n",
            "Epoch: 0057 loss_train: 0.5462 acc_train: 0.7167 loss_val: 0.5206 acc_val: 0.7920 time: 0.1451s\n",
            "2\n",
            "Epoch: 0058 loss_train: 0.5618 acc_train: 0.8333 loss_val: 0.5054 acc_val: 0.8120 time: 0.1444s\n",
            "0\n",
            "Epoch: 0059 loss_train: 0.5598 acc_train: 0.8333 loss_val: 0.5147 acc_val: 0.8060 time: 0.1456s\n",
            "0\n",
            "Epoch: 0060 loss_train: 0.6149 acc_train: 0.7667 loss_val: 0.5546 acc_val: 0.8000 time: 0.1451s\n",
            "1\n",
            "Epoch: 0061 loss_train: 0.5120 acc_train: 0.7500 loss_val: 0.5749 acc_val: 0.7880 time: 0.1456s\n",
            "2\n",
            "Epoch: 0062 loss_train: 0.4556 acc_train: 0.8167 loss_val: 0.5259 acc_val: 0.8240 time: 0.1448s\n",
            "3\n",
            "Epoch: 0063 loss_train: 0.4632 acc_train: 0.8000 loss_val: 0.5035 acc_val: 0.8100 time: 0.1450s\n",
            "0\n",
            "Epoch: 0064 loss_train: 0.5398 acc_train: 0.7833 loss_val: 0.5021 acc_val: 0.8020 time: 0.1446s\n",
            "0\n",
            "Epoch: 0065 loss_train: 0.4793 acc_train: 0.8000 loss_val: 0.5026 acc_val: 0.7960 time: 0.1448s\n",
            "0\n",
            "Epoch: 0066 loss_train: 0.6008 acc_train: 0.7833 loss_val: 0.5006 acc_val: 0.7980 time: 0.1450s\n",
            "1\n",
            "Epoch: 0067 loss_train: 0.5296 acc_train: 0.8000 loss_val: 0.5010 acc_val: 0.8020 time: 0.1453s\n",
            "0\n",
            "Epoch: 0068 loss_train: 0.4842 acc_train: 0.7333 loss_val: 0.4969 acc_val: 0.8040 time: 0.1448s\n",
            "1\n",
            "Epoch: 0069 loss_train: 0.4093 acc_train: 0.8500 loss_val: 0.5087 acc_val: 0.7960 time: 0.1448s\n",
            "0\n",
            "Epoch: 0070 loss_train: 0.5358 acc_train: 0.8333 loss_val: 0.5415 acc_val: 0.7920 time: 0.1454s\n",
            "1\n",
            "Epoch: 0071 loss_train: 0.4759 acc_train: 0.8333 loss_val: 0.5710 acc_val: 0.7900 time: 0.1459s\n",
            "2\n",
            "Epoch: 0072 loss_train: 0.4731 acc_train: 0.8167 loss_val: 0.6042 acc_val: 0.8020 time: 0.1450s\n",
            "3\n",
            "Epoch: 0073 loss_train: 0.3752 acc_train: 0.9167 loss_val: 0.6279 acc_val: 0.8000 time: 0.1452s\n",
            "4\n",
            "Epoch: 0074 loss_train: 0.5042 acc_train: 0.7500 loss_val: 0.5943 acc_val: 0.8000 time: 0.1448s\n",
            "5\n",
            "Epoch: 0075 loss_train: 0.4083 acc_train: 0.7333 loss_val: 0.5712 acc_val: 0.8140 time: 0.1485s\n",
            "6\n",
            "Epoch: 0076 loss_train: 0.3348 acc_train: 0.9000 loss_val: 0.5810 acc_val: 0.8120 time: 0.1447s\n",
            "7\n",
            "Epoch: 0077 loss_train: 0.3902 acc_train: 0.8500 loss_val: 0.5962 acc_val: 0.8060 time: 0.1451s\n",
            "8\n",
            "Epoch: 0078 loss_train: 0.4688 acc_train: 0.7500 loss_val: 0.6066 acc_val: 0.8020 time: 0.1453s\n",
            "9\n",
            "Epoch: 0079 loss_train: 0.4886 acc_train: 0.8167 loss_val: 0.6241 acc_val: 0.7920 time: 0.1448s\n",
            "10\n",
            "Epoch: 0080 loss_train: 0.4579 acc_train: 0.8500 loss_val: 0.5734 acc_val: 0.8060 time: 0.1448s\n",
            "11\n",
            "Epoch: 0081 loss_train: 0.3705 acc_train: 0.7667 loss_val: 0.5068 acc_val: 0.8220 time: 0.1452s\n",
            "12\n",
            "Epoch: 0082 loss_train: 0.3938 acc_train: 0.9333 loss_val: 0.5310 acc_val: 0.7940 time: 0.1450s\n",
            "13\n",
            "Epoch: 0083 loss_train: 0.4485 acc_train: 0.8333 loss_val: 0.5776 acc_val: 0.7640 time: 0.1451s\n",
            "14\n",
            "Epoch: 0084 loss_train: 0.3958 acc_train: 0.9333 loss_val: 0.6081 acc_val: 0.7460 time: 0.1450s\n",
            "15\n",
            "Epoch: 0085 loss_train: 0.3918 acc_train: 0.8667 loss_val: 0.5707 acc_val: 0.7600 time: 0.1451s\n",
            "16\n",
            "Epoch: 0086 loss_train: 0.5039 acc_train: 0.7833 loss_val: 0.5245 acc_val: 0.8020 time: 0.1454s\n",
            "17\n",
            "Epoch: 0087 loss_train: 0.4316 acc_train: 0.8000 loss_val: 0.5181 acc_val: 0.8160 time: 0.1455s\n",
            "18\n",
            "Epoch: 0088 loss_train: 0.4014 acc_train: 0.8333 loss_val: 0.5380 acc_val: 0.8180 time: 0.1461s\n",
            "19\n",
            "Epoch: 0089 loss_train: 0.4157 acc_train: 0.8167 loss_val: 0.5298 acc_val: 0.8260 time: 0.1461s\n",
            "20\n",
            "Epoch: 0090 loss_train: 0.4087 acc_train: 0.9000 loss_val: 0.5233 acc_val: 0.8180 time: 0.1449s\n",
            "0\n",
            "Epoch: 0091 loss_train: 0.4116 acc_train: 0.8667 loss_val: 0.5293 acc_val: 0.8200 time: 0.1450s\n",
            "1\n",
            "Epoch: 0092 loss_train: 0.3057 acc_train: 0.8333 loss_val: 0.5605 acc_val: 0.8200 time: 0.1465s\n",
            "2\n",
            "Epoch: 0093 loss_train: 0.4465 acc_train: 0.8000 loss_val: 0.6104 acc_val: 0.8020 time: 0.1450s\n",
            "3\n",
            "Epoch: 0094 loss_train: 0.4144 acc_train: 0.8333 loss_val: 0.6254 acc_val: 0.7780 time: 0.1468s\n",
            "4\n",
            "Epoch: 0095 loss_train: 0.5239 acc_train: 0.8167 loss_val: 0.6235 acc_val: 0.7660 time: 0.1467s\n",
            "5\n",
            "Epoch: 0096 loss_train: 0.3692 acc_train: 0.8333 loss_val: 0.6107 acc_val: 0.7700 time: 0.1454s\n",
            "6\n",
            "Epoch: 0097 loss_train: 0.4301 acc_train: 0.7500 loss_val: 0.5886 acc_val: 0.7780 time: 0.1468s\n",
            "7\n",
            "Epoch: 0098 loss_train: 0.4658 acc_train: 0.8167 loss_val: 0.5754 acc_val: 0.7880 time: 0.1447s\n",
            "8\n",
            "Epoch: 0099 loss_train: 0.4409 acc_train: 0.8167 loss_val: 0.5897 acc_val: 0.7900 time: 0.1457s\n",
            "9\n",
            "Epoch: 0100 loss_train: 0.4455 acc_train: 0.8333 loss_val: 0.5964 acc_val: 0.7760 time: 0.1448s\n",
            "10\n",
            "Epoch: 0101 loss_train: 0.4572 acc_train: 0.8000 loss_val: 0.6050 acc_val: 0.7720 time: 0.1454s\n",
            "11\n",
            "Epoch: 0102 loss_train: 0.4793 acc_train: 0.7500 loss_val: 0.5857 acc_val: 0.7740 time: 0.1469s\n",
            "12\n",
            "Epoch: 0103 loss_train: 0.4162 acc_train: 0.8000 loss_val: 0.5590 acc_val: 0.7980 time: 0.1450s\n",
            "13\n",
            "Epoch: 0104 loss_train: 0.5957 acc_train: 0.8167 loss_val: 0.6560 acc_val: 0.7700 time: 0.1454s\n",
            "14\n",
            "Epoch: 0105 loss_train: 0.4276 acc_train: 0.7833 loss_val: 0.6581 acc_val: 0.7580 time: 0.1452s\n",
            "15\n",
            "Epoch: 0106 loss_train: 0.4540 acc_train: 0.7167 loss_val: 0.6314 acc_val: 0.7800 time: 0.1451s\n",
            "16\n",
            "Epoch: 0107 loss_train: 0.4555 acc_train: 0.7833 loss_val: 0.5418 acc_val: 0.8040 time: 0.1454s\n",
            "17\n",
            "Epoch: 0108 loss_train: 0.4433 acc_train: 0.8667 loss_val: 0.5761 acc_val: 0.7940 time: 0.1477s\n",
            "18\n",
            "Epoch: 0109 loss_train: 0.3572 acc_train: 0.9333 loss_val: 0.6875 acc_val: 0.7560 time: 0.1450s\n",
            "19\n",
            "Epoch: 0110 loss_train: 0.3617 acc_train: 0.8333 loss_val: 0.7077 acc_val: 0.7440 time: 0.1462s\n",
            "20\n",
            "Epoch: 0111 loss_train: 0.4881 acc_train: 0.7833 loss_val: 0.6411 acc_val: 0.7780 time: 0.1478s\n",
            "21\n",
            "Epoch: 0112 loss_train: 0.3980 acc_train: 0.8333 loss_val: 0.5995 acc_val: 0.7820 time: 0.1443s\n",
            "22\n",
            "Epoch: 0113 loss_train: 0.3840 acc_train: 0.8833 loss_val: 0.5889 acc_val: 0.7960 time: 0.1451s\n",
            "23\n",
            "Epoch: 0114 loss_train: 0.4360 acc_train: 0.8333 loss_val: 0.5776 acc_val: 0.8020 time: 0.1448s\n",
            "24\n",
            "Epoch: 0115 loss_train: 0.4272 acc_train: 0.8000 loss_val: 0.5693 acc_val: 0.8060 time: 0.1456s\n",
            "25\n",
            "Epoch: 0116 loss_train: 0.5022 acc_train: 0.7667 loss_val: 0.5851 acc_val: 0.7920 time: 0.1471s\n",
            "26\n",
            "Epoch: 0117 loss_train: 0.4804 acc_train: 0.8667 loss_val: 0.6101 acc_val: 0.7820 time: 0.1454s\n",
            "27\n",
            "Epoch: 0118 loss_train: 0.5012 acc_train: 0.8500 loss_val: 0.6314 acc_val: 0.7740 time: 0.1456s\n",
            "28\n",
            "Epoch: 0119 loss_train: 0.4452 acc_train: 0.8000 loss_val: 0.5912 acc_val: 0.7980 time: 0.1454s\n",
            "29\n",
            "Epoch: 0120 loss_train: 0.4074 acc_train: 0.8333 loss_val: 0.5969 acc_val: 0.7920 time: 0.1450s\n",
            "30\n",
            "Epoch: 0121 loss_train: 0.4293 acc_train: 0.8333 loss_val: 0.5588 acc_val: 0.8020 time: 0.1452s\n",
            "31\n",
            "Epoch: 0122 loss_train: 0.3992 acc_train: 0.8667 loss_val: 0.5298 acc_val: 0.8140 time: 0.1454s\n",
            "32\n",
            "Epoch: 0123 loss_train: 0.3889 acc_train: 0.8167 loss_val: 0.5678 acc_val: 0.7760 time: 0.1453s\n",
            "33\n",
            "Epoch: 0124 loss_train: 0.4644 acc_train: 0.8667 loss_val: 0.5649 acc_val: 0.7780 time: 0.1458s\n",
            "34\n",
            "Epoch: 0125 loss_train: 0.5753 acc_train: 0.8000 loss_val: 0.5348 acc_val: 0.8040 time: 0.1451s\n",
            "35\n",
            "Epoch: 0126 loss_train: 0.4098 acc_train: 0.7833 loss_val: 0.5512 acc_val: 0.8240 time: 0.1466s\n",
            "36\n",
            "Epoch: 0127 loss_train: 0.4141 acc_train: 0.8667 loss_val: 0.5738 acc_val: 0.8180 time: 0.1453s\n",
            "37\n",
            "Epoch: 0128 loss_train: 0.4691 acc_train: 0.8500 loss_val: 0.5677 acc_val: 0.8220 time: 0.1449s\n",
            "38\n",
            "Epoch: 0129 loss_train: 0.5104 acc_train: 0.7667 loss_val: 0.5401 acc_val: 0.8140 time: 0.1453s\n",
            "39\n",
            "Epoch: 0130 loss_train: 0.4121 acc_train: 0.8333 loss_val: 0.5101 acc_val: 0.8180 time: 0.1449s\n",
            "40\n",
            "Epoch: 0131 loss_train: 0.4500 acc_train: 0.8167 loss_val: 0.5143 acc_val: 0.8060 time: 0.1452s\n",
            "41\n",
            "Epoch: 0132 loss_train: 0.4624 acc_train: 0.8000 loss_val: 0.5166 acc_val: 0.8160 time: 0.1448s\n",
            "42\n",
            "Epoch: 0133 loss_train: 0.3932 acc_train: 0.8500 loss_val: 0.5250 acc_val: 0.8100 time: 0.1451s\n",
            "43\n",
            "Epoch: 0134 loss_train: 0.4785 acc_train: 0.8000 loss_val: 0.5321 acc_val: 0.8100 time: 0.1448s\n",
            "44\n",
            "Epoch: 0135 loss_train: 0.3784 acc_train: 0.8333 loss_val: 0.5323 acc_val: 0.8020 time: 0.1447s\n",
            "45\n",
            "Epoch: 0136 loss_train: 0.5699 acc_train: 0.7333 loss_val: 0.4898 acc_val: 0.8240 time: 0.1454s\n",
            "46\n",
            "Epoch: 0137 loss_train: 0.4545 acc_train: 0.8667 loss_val: 0.4727 acc_val: 0.8200 time: 0.1449s\n",
            "0\n",
            "Epoch: 0138 loss_train: 0.5324 acc_train: 0.8667 loss_val: 0.4838 acc_val: 0.8300 time: 0.1449s\n",
            "0\n",
            "Epoch: 0139 loss_train: 0.4303 acc_train: 0.8667 loss_val: 0.5218 acc_val: 0.8280 time: 0.1451s\n",
            "0\n",
            "Epoch: 0140 loss_train: 0.4470 acc_train: 0.8667 loss_val: 0.5502 acc_val: 0.8220 time: 0.1463s\n",
            "1\n",
            "Epoch: 0141 loss_train: 0.4658 acc_train: 0.8167 loss_val: 0.5563 acc_val: 0.8200 time: 0.1458s\n",
            "2\n",
            "Epoch: 0142 loss_train: 0.4454 acc_train: 0.8167 loss_val: 0.5557 acc_val: 0.8160 time: 0.1450s\n",
            "3\n",
            "Epoch: 0143 loss_train: 0.3731 acc_train: 0.8000 loss_val: 0.5613 acc_val: 0.8200 time: 0.1473s\n",
            "4\n",
            "Epoch: 0144 loss_train: 0.3724 acc_train: 0.7833 loss_val: 0.6143 acc_val: 0.8100 time: 0.1466s\n",
            "5\n",
            "Epoch: 0145 loss_train: 0.4994 acc_train: 0.7833 loss_val: 0.6135 acc_val: 0.8200 time: 0.1458s\n",
            "6\n",
            "Epoch: 0146 loss_train: 0.4051 acc_train: 0.9000 loss_val: 0.6002 acc_val: 0.8120 time: 0.1452s\n",
            "7\n",
            "Epoch: 0147 loss_train: 0.4861 acc_train: 0.7333 loss_val: 0.5358 acc_val: 0.8180 time: 0.1458s\n",
            "8\n",
            "Epoch: 0148 loss_train: 0.4282 acc_train: 0.9000 loss_val: 0.5121 acc_val: 0.8280 time: 0.1458s\n",
            "9\n",
            "Epoch: 0149 loss_train: 0.3957 acc_train: 0.8333 loss_val: 0.5059 acc_val: 0.8260 time: 0.1460s\n",
            "10\n",
            "Epoch: 0150 loss_train: 0.3999 acc_train: 0.8500 loss_val: 0.5154 acc_val: 0.8280 time: 0.1448s\n",
            "11\n",
            "Epoch: 0151 loss_train: 0.4905 acc_train: 0.8167 loss_val: 0.5133 acc_val: 0.8400 time: 0.1450s\n",
            "12\n",
            "Epoch: 0152 loss_train: 0.4142 acc_train: 0.8167 loss_val: 0.5125 acc_val: 0.8380 time: 0.1450s\n",
            "0\n",
            "Epoch: 0153 loss_train: 0.4001 acc_train: 0.8500 loss_val: 0.5193 acc_val: 0.8380 time: 0.1453s\n",
            "1\n",
            "Epoch: 0154 loss_train: 0.3334 acc_train: 0.8667 loss_val: 0.5449 acc_val: 0.8300 time: 0.1453s\n",
            "2\n",
            "Epoch: 0155 loss_train: 0.4080 acc_train: 0.8667 loss_val: 0.5681 acc_val: 0.8240 time: 0.1451s\n",
            "3\n",
            "Epoch: 0156 loss_train: 0.4404 acc_train: 0.8833 loss_val: 0.5464 acc_val: 0.8180 time: 0.1448s\n",
            "4\n",
            "Epoch: 0157 loss_train: 0.4715 acc_train: 0.7667 loss_val: 0.5200 acc_val: 0.8300 time: 0.1451s\n",
            "5\n",
            "Epoch: 0158 loss_train: 0.4075 acc_train: 0.8833 loss_val: 0.5016 acc_val: 0.8400 time: 0.1449s\n",
            "6\n",
            "Epoch: 0159 loss_train: 0.4445 acc_train: 0.8167 loss_val: 0.5018 acc_val: 0.8320 time: 0.1452s\n",
            "0\n",
            "Epoch: 0160 loss_train: 0.3721 acc_train: 0.9333 loss_val: 0.5051 acc_val: 0.8360 time: 0.1457s\n",
            "1\n",
            "Epoch: 0161 loss_train: 0.3779 acc_train: 0.8667 loss_val: 0.5145 acc_val: 0.8360 time: 0.1461s\n",
            "2\n",
            "Epoch: 0162 loss_train: 0.3997 acc_train: 0.7833 loss_val: 0.5116 acc_val: 0.8360 time: 0.1449s\n",
            "3\n",
            "Epoch: 0163 loss_train: 0.4000 acc_train: 0.8833 loss_val: 0.5260 acc_val: 0.8220 time: 0.1458s\n",
            "4\n",
            "Epoch: 0164 loss_train: 0.4446 acc_train: 0.8167 loss_val: 0.5164 acc_val: 0.8360 time: 0.1446s\n",
            "5\n",
            "Epoch: 0165 loss_train: 0.4831 acc_train: 0.7667 loss_val: 0.5329 acc_val: 0.8340 time: 0.1456s\n",
            "6\n",
            "Epoch: 0166 loss_train: 0.4397 acc_train: 0.7833 loss_val: 0.5615 acc_val: 0.8140 time: 0.1489s\n",
            "7\n",
            "Epoch: 0167 loss_train: 0.5506 acc_train: 0.7833 loss_val: 0.5910 acc_val: 0.8040 time: 0.1457s\n",
            "8\n",
            "Epoch: 0168 loss_train: 0.3944 acc_train: 0.7500 loss_val: 0.5843 acc_val: 0.8020 time: 0.1480s\n",
            "9\n",
            "Epoch: 0169 loss_train: 0.4385 acc_train: 0.8167 loss_val: 0.5804 acc_val: 0.7980 time: 0.1459s\n",
            "10\n",
            "Epoch: 0170 loss_train: 0.4787 acc_train: 0.7833 loss_val: 0.5390 acc_val: 0.8320 time: 0.1455s\n",
            "11\n",
            "Epoch: 0171 loss_train: 0.4656 acc_train: 0.8167 loss_val: 0.5436 acc_val: 0.8240 time: 0.1466s\n",
            "12\n",
            "Epoch: 0172 loss_train: 0.4361 acc_train: 0.8667 loss_val: 0.5632 acc_val: 0.8200 time: 0.1451s\n",
            "13\n",
            "Epoch: 0173 loss_train: 0.4937 acc_train: 0.8167 loss_val: 0.5933 acc_val: 0.8220 time: 0.1453s\n",
            "14\n",
            "Epoch: 0174 loss_train: 0.3934 acc_train: 0.8000 loss_val: 0.6270 acc_val: 0.8120 time: 0.1447s\n",
            "15\n",
            "Epoch: 0175 loss_train: 0.5049 acc_train: 0.7833 loss_val: 0.6374 acc_val: 0.7960 time: 0.1463s\n",
            "16\n",
            "Epoch: 0176 loss_train: 0.4465 acc_train: 0.8833 loss_val: 0.6813 acc_val: 0.7600 time: 0.1450s\n",
            "17\n",
            "Epoch: 0177 loss_train: 0.4738 acc_train: 0.8000 loss_val: 0.7063 acc_val: 0.7520 time: 0.1458s\n",
            "18\n",
            "Epoch: 0178 loss_train: 0.4823 acc_train: 0.8333 loss_val: 0.6433 acc_val: 0.7900 time: 0.1449s\n",
            "19\n",
            "Epoch: 0179 loss_train: 0.5051 acc_train: 0.8000 loss_val: 0.6088 acc_val: 0.8080 time: 0.1458s\n",
            "20\n",
            "Epoch: 0180 loss_train: 0.4245 acc_train: 0.9000 loss_val: 0.5818 acc_val: 0.8160 time: 0.1456s\n",
            "21\n",
            "Epoch: 0181 loss_train: 0.4444 acc_train: 0.8500 loss_val: 0.5632 acc_val: 0.8180 time: 0.1456s\n",
            "22\n",
            "Epoch: 0182 loss_train: 0.5014 acc_train: 0.8667 loss_val: 0.5544 acc_val: 0.8180 time: 0.1449s\n",
            "23\n",
            "Epoch: 0183 loss_train: 0.3962 acc_train: 0.8667 loss_val: 0.5646 acc_val: 0.8220 time: 0.1451s\n",
            "24\n",
            "Epoch: 0184 loss_train: 0.3333 acc_train: 0.8833 loss_val: 0.5871 acc_val: 0.8160 time: 0.1453s\n",
            "25\n",
            "Epoch: 0185 loss_train: 0.3869 acc_train: 0.8667 loss_val: 0.5877 acc_val: 0.8140 time: 0.1452s\n",
            "26\n",
            "Epoch: 0186 loss_train: 0.3805 acc_train: 0.8167 loss_val: 0.5945 acc_val: 0.8220 time: 0.1447s\n",
            "27\n",
            "Epoch: 0187 loss_train: 0.4106 acc_train: 0.7833 loss_val: 0.5873 acc_val: 0.8180 time: 0.1456s\n",
            "28\n",
            "Epoch: 0188 loss_train: 0.5096 acc_train: 0.8333 loss_val: 0.5737 acc_val: 0.8200 time: 0.1450s\n",
            "29\n",
            "Epoch: 0189 loss_train: 0.4007 acc_train: 0.8667 loss_val: 0.5535 acc_val: 0.8140 time: 0.1460s\n",
            "30\n",
            "Epoch: 0190 loss_train: 0.4562 acc_train: 0.8167 loss_val: 0.5540 acc_val: 0.8080 time: 0.1453s\n",
            "31\n",
            "Epoch: 0191 loss_train: 0.4580 acc_train: 0.8500 loss_val: 0.5583 acc_val: 0.8060 time: 0.1451s\n",
            "32\n",
            "Epoch: 0192 loss_train: 0.5526 acc_train: 0.7167 loss_val: 0.5314 acc_val: 0.8240 time: 0.1451s\n",
            "33\n",
            "Epoch: 0193 loss_train: 0.5987 acc_train: 0.8333 loss_val: 0.5398 acc_val: 0.8080 time: 0.1452s\n",
            "34\n",
            "Epoch: 0194 loss_train: 0.3608 acc_train: 0.8833 loss_val: 0.5435 acc_val: 0.8020 time: 0.1450s\n",
            "35\n",
            "Epoch: 0195 loss_train: 0.3938 acc_train: 0.8167 loss_val: 0.5484 acc_val: 0.8020 time: 0.1459s\n",
            "36\n",
            "Epoch: 0196 loss_train: 0.4079 acc_train: 0.8500 loss_val: 0.5442 acc_val: 0.8020 time: 0.1448s\n",
            "37\n",
            "Epoch: 0197 loss_train: 0.4391 acc_train: 0.8000 loss_val: 0.5361 acc_val: 0.8100 time: 0.1451s\n",
            "38\n",
            "Epoch: 0198 loss_train: 0.3718 acc_train: 0.9000 loss_val: 0.5360 acc_val: 0.8120 time: 0.1455s\n",
            "39\n",
            "Epoch: 0199 loss_train: 0.4176 acc_train: 0.8167 loss_val: 0.5392 acc_val: 0.8160 time: 0.1451s\n",
            "40\n",
            "Epoch: 0200 loss_train: 0.5026 acc_train: 0.8500 loss_val: 0.5646 acc_val: 0.8060 time: 0.1448s\n",
            "41\n",
            "Epoch: 0201 loss_train: 0.4537 acc_train: 0.7833 loss_val: 0.6317 acc_val: 0.8180 time: 0.1452s\n",
            "42\n",
            "Epoch: 0202 loss_train: 0.4023 acc_train: 0.8833 loss_val: 0.6742 acc_val: 0.8120 time: 0.1458s\n",
            "43\n",
            "Epoch: 0203 loss_train: 0.3443 acc_train: 0.8500 loss_val: 0.7123 acc_val: 0.7940 time: 0.1457s\n",
            "44\n",
            "Epoch: 0204 loss_train: 0.4217 acc_train: 0.8000 loss_val: 0.6626 acc_val: 0.8080 time: 0.1469s\n",
            "45\n",
            "Epoch: 0205 loss_train: 0.4728 acc_train: 0.7333 loss_val: 0.6474 acc_val: 0.7940 time: 0.1452s\n",
            "46\n",
            "Epoch: 0206 loss_train: 0.4920 acc_train: 0.7833 loss_val: 0.6533 acc_val: 0.8020 time: 0.1450s\n",
            "47\n",
            "Epoch: 0207 loss_train: 0.5308 acc_train: 0.8333 loss_val: 0.6336 acc_val: 0.8060 time: 0.1456s\n",
            "48\n",
            "Epoch: 0208 loss_train: 0.3782 acc_train: 0.8667 loss_val: 0.6201 acc_val: 0.8140 time: 0.1453s\n",
            "49\n",
            "Epoch: 0209 loss_train: 0.4736 acc_train: 0.8000 loss_val: 0.5872 acc_val: 0.8080 time: 0.1455s\n",
            "50\n",
            "Epoch: 0210 loss_train: 0.5260 acc_train: 0.8333 loss_val: 0.5489 acc_val: 0.8060 time: 0.1488s\n",
            "51\n",
            "Epoch: 0211 loss_train: 0.4323 acc_train: 0.8500 loss_val: 0.5150 acc_val: 0.8040 time: 0.1455s\n",
            "52\n",
            "Epoch: 0212 loss_train: 0.4211 acc_train: 0.8167 loss_val: 0.5105 acc_val: 0.7940 time: 0.1447s\n",
            "53\n",
            "Epoch: 0213 loss_train: 0.4946 acc_train: 0.8167 loss_val: 0.5079 acc_val: 0.7940 time: 0.1453s\n",
            "54\n",
            "Epoch: 0214 loss_train: 0.4849 acc_train: 0.9000 loss_val: 0.5137 acc_val: 0.7920 time: 0.1452s\n",
            "55\n",
            "Epoch: 0215 loss_train: 0.4548 acc_train: 0.8833 loss_val: 0.5129 acc_val: 0.8060 time: 0.1453s\n",
            "56\n",
            "Epoch: 0216 loss_train: 0.5866 acc_train: 0.8667 loss_val: 0.5647 acc_val: 0.8060 time: 0.1451s\n",
            "57\n",
            "Epoch: 0217 loss_train: 0.4675 acc_train: 0.8167 loss_val: 0.6469 acc_val: 0.7620 time: 0.1456s\n",
            "58\n",
            "Epoch: 0218 loss_train: 0.4396 acc_train: 0.8167 loss_val: 0.6029 acc_val: 0.7940 time: 0.1453s\n",
            "59\n",
            "Epoch: 0219 loss_train: 0.4712 acc_train: 0.6667 loss_val: 0.5270 acc_val: 0.8220 time: 0.1454s\n",
            "60\n",
            "Epoch: 0220 loss_train: 0.5193 acc_train: 0.7000 loss_val: 0.4970 acc_val: 0.8080 time: 0.1451s\n",
            "61\n",
            "Epoch: 0221 loss_train: 0.4844 acc_train: 0.8500 loss_val: 0.5092 acc_val: 0.7940 time: 0.1452s\n",
            "62\n",
            "Epoch: 0222 loss_train: 0.5149 acc_train: 0.7333 loss_val: 0.5455 acc_val: 0.7700 time: 0.1462s\n",
            "63\n",
            "Epoch: 0223 loss_train: 0.3983 acc_train: 0.8667 loss_val: 0.5506 acc_val: 0.7840 time: 0.1457s\n",
            "64\n",
            "Epoch: 0224 loss_train: 0.5060 acc_train: 0.8167 loss_val: 0.5775 acc_val: 0.7880 time: 0.1448s\n",
            "65\n",
            "Epoch: 0225 loss_train: 0.5549 acc_train: 0.8167 loss_val: 0.5344 acc_val: 0.8100 time: 0.1459s\n",
            "66\n",
            "Epoch: 0226 loss_train: 0.3812 acc_train: 0.8667 loss_val: 0.5299 acc_val: 0.8080 time: 0.1464s\n",
            "67\n",
            "Epoch: 0227 loss_train: 0.8401 acc_train: 0.7500 loss_val: 0.5254 acc_val: 0.8100 time: 0.1451s\n",
            "68\n",
            "Epoch: 0228 loss_train: 0.4781 acc_train: 0.8333 loss_val: 0.5206 acc_val: 0.8120 time: 0.1447s\n",
            "69\n",
            "Epoch: 0229 loss_train: 0.5106 acc_train: 0.8833 loss_val: 0.5232 acc_val: 0.8000 time: 0.1451s\n",
            "70\n",
            "Epoch: 0230 loss_train: 0.3678 acc_train: 0.7833 loss_val: 0.5340 acc_val: 0.7800 time: 0.1452s\n",
            "71\n",
            "Epoch: 0231 loss_train: 0.4739 acc_train: 0.8667 loss_val: 0.5251 acc_val: 0.8000 time: 0.1472s\n",
            "72\n",
            "Epoch: 0232 loss_train: 0.5079 acc_train: 0.8333 loss_val: 0.5480 acc_val: 0.8180 time: 0.1450s\n",
            "73\n",
            "Epoch: 0233 loss_train: 0.5077 acc_train: 0.8333 loss_val: 0.6256 acc_val: 0.8120 time: 0.1456s\n",
            "74\n",
            "Epoch: 0234 loss_train: 0.4776 acc_train: 0.8167 loss_val: 0.6897 acc_val: 0.7960 time: 0.1448s\n",
            "75\n",
            "Epoch: 0235 loss_train: 0.4922 acc_train: 0.8167 loss_val: 0.7775 acc_val: 0.7840 time: 0.1452s\n",
            "76\n",
            "Epoch: 0236 loss_train: 0.5561 acc_train: 0.8000 loss_val: 0.7646 acc_val: 0.7860 time: 0.1449s\n",
            "77\n",
            "Epoch: 0237 loss_train: 0.3581 acc_train: 0.8333 loss_val: 0.7157 acc_val: 0.8000 time: 0.1450s\n",
            "78\n",
            "Epoch: 0238 loss_train: 0.5120 acc_train: 0.8167 loss_val: 0.6842 acc_val: 0.8060 time: 0.1451s\n",
            "79\n",
            "Epoch: 0239 loss_train: 0.4609 acc_train: 0.7833 loss_val: 0.6642 acc_val: 0.8080 time: 0.1455s\n",
            "80\n",
            "Epoch: 0240 loss_train: 0.4333 acc_train: 0.9167 loss_val: 0.6334 acc_val: 0.7940 time: 0.1465s\n",
            "81\n",
            "Epoch: 0241 loss_train: 0.3932 acc_train: 0.9500 loss_val: 0.6305 acc_val: 0.7840 time: 0.1477s\n",
            "82\n",
            "Epoch: 0242 loss_train: 0.5384 acc_train: 0.7833 loss_val: 0.6904 acc_val: 0.7500 time: 0.1453s\n",
            "83\n",
            "Epoch: 0243 loss_train: 0.4653 acc_train: 0.7167 loss_val: 0.6963 acc_val: 0.7380 time: 0.1470s\n",
            "84\n",
            "Epoch: 0244 loss_train: 0.4823 acc_train: 0.7833 loss_val: 0.5909 acc_val: 0.7860 time: 0.1476s\n",
            "85\n",
            "Epoch: 0245 loss_train: 0.4918 acc_train: 0.8500 loss_val: 0.5793 acc_val: 0.8300 time: 0.1452s\n",
            "86\n",
            "Epoch: 0246 loss_train: 0.4541 acc_train: 0.8500 loss_val: 0.6446 acc_val: 0.8080 time: 0.1449s\n",
            "87\n",
            "Epoch: 0247 loss_train: 0.4894 acc_train: 0.8500 loss_val: 0.6490 acc_val: 0.8080 time: 0.1460s\n",
            "88\n",
            "Epoch: 0248 loss_train: 0.5002 acc_train: 0.8333 loss_val: 0.5510 acc_val: 0.8100 time: 0.1449s\n",
            "89\n",
            "Epoch: 0249 loss_train: 0.5021 acc_train: 0.8667 loss_val: 0.5479 acc_val: 0.8100 time: 0.1452s\n",
            "90\n",
            "Epoch: 0250 loss_train: 0.5558 acc_train: 0.7833 loss_val: 0.5566 acc_val: 0.8080 time: 0.1450s\n",
            "91\n",
            "Epoch: 0251 loss_train: 0.5736 acc_train: 0.8000 loss_val: 0.6044 acc_val: 0.8000 time: 0.1453s\n",
            "92\n",
            "Epoch: 0252 loss_train: 0.4522 acc_train: 0.8500 loss_val: 0.6372 acc_val: 0.7940 time: 0.1455s\n",
            "93\n",
            "Epoch: 0253 loss_train: 0.5379 acc_train: 0.7667 loss_val: 0.5987 acc_val: 0.8080 time: 0.1452s\n",
            "94\n",
            "Epoch: 0254 loss_train: 0.4267 acc_train: 0.8500 loss_val: 0.5716 acc_val: 0.8240 time: 0.1444s\n",
            "95\n",
            "Epoch: 0255 loss_train: 0.3742 acc_train: 0.9333 loss_val: 0.5881 acc_val: 0.8120 time: 0.1450s\n",
            "96\n",
            "Epoch: 0256 loss_train: 0.5529 acc_train: 0.8167 loss_val: 0.6123 acc_val: 0.8040 time: 0.1451s\n",
            "97\n",
            "Epoch: 0257 loss_train: 0.4985 acc_train: 0.8000 loss_val: 0.5777 acc_val: 0.8100 time: 0.1463s\n",
            "98\n",
            "Epoch: 0258 loss_train: 0.5289 acc_train: 0.8167 loss_val: 0.5619 acc_val: 0.8040 time: 0.1451s\n",
            "99\n",
            "Early stop! Min loss:  0.4727284908294678 , Max accuracy:  0.84\n",
            "Early stop model validation loss:  0.4727284908294678 , accuracy:  0.8200000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 38.2458s\n",
            "Loading 136th epoch\n",
            "Test set results: loss= 0.5401 accuracy= 0.8110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8110, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkHhEk5XhNdk",
        "outputId": "0a57c423-ab2f-42b4-95f8-b3f2878351b2"
      },
      "source": [
        "Train(lam=0) #citeseer\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.8608 acc_train: 0.1667 loss_val: 1.8114 acc_val: 0.2320 time: 0.1128s\n",
            "0\n",
            "Epoch: 0002 loss_train: 1.8546 acc_train: 0.1667 loss_val: 1.8101 acc_val: 0.2320 time: 0.1059s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.8541 acc_train: 0.1667 loss_val: 1.8092 acc_val: 0.2320 time: 0.1052s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.8496 acc_train: 0.1667 loss_val: 1.8085 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.8457 acc_train: 0.1667 loss_val: 1.8082 acc_val: 0.2320 time: 0.1058s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.8429 acc_train: 0.1667 loss_val: 1.8080 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.8397 acc_train: 0.1667 loss_val: 1.8082 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.8367 acc_train: 0.1667 loss_val: 1.8084 acc_val: 0.2320 time: 0.1038s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.8313 acc_train: 0.1667 loss_val: 1.8089 acc_val: 0.2320 time: 0.1052s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.8299 acc_train: 0.1667 loss_val: 1.8096 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.8272 acc_train: 0.1667 loss_val: 1.8103 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.8227 acc_train: 0.1667 loss_val: 1.8108 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.8191 acc_train: 0.1667 loss_val: 1.8112 acc_val: 0.2320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.8195 acc_train: 0.1667 loss_val: 1.8113 acc_val: 0.2320 time: 0.1056s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.8164 acc_train: 0.1667 loss_val: 1.8112 acc_val: 0.2320 time: 0.1064s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.8111 acc_train: 0.1667 loss_val: 1.8108 acc_val: 0.2320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.8104 acc_train: 0.1667 loss_val: 1.8104 acc_val: 0.2320 time: 0.1049s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.8100 acc_train: 0.1667 loss_val: 1.8095 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.8051 acc_train: 0.1667 loss_val: 1.8082 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.8049 acc_train: 0.1667 loss_val: 1.8067 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.7995 acc_train: 0.1667 loss_val: 1.8050 acc_val: 0.2320 time: 0.1054s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.7983 acc_train: 0.1667 loss_val: 1.8031 acc_val: 0.2320 time: 0.1038s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.7941 acc_train: 0.1833 loss_val: 1.8011 acc_val: 0.2320 time: 0.1045s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.7905 acc_train: 0.1583 loss_val: 1.7990 acc_val: 0.2320 time: 0.1054s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.7829 acc_train: 0.1917 loss_val: 1.7969 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.7805 acc_train: 0.2500 loss_val: 1.7952 acc_val: 0.2400 time: 0.1040s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.7777 acc_train: 0.2333 loss_val: 1.7934 acc_val: 0.1720 time: 0.1045s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.7731 acc_train: 0.2000 loss_val: 1.7917 acc_val: 0.1060 time: 0.1059s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.7673 acc_train: 0.2750 loss_val: 1.7901 acc_val: 0.1060 time: 0.1054s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.7693 acc_train: 0.2333 loss_val: 1.7886 acc_val: 0.1340 time: 0.1054s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.7674 acc_train: 0.2417 loss_val: 1.7870 acc_val: 0.1680 time: 0.1060s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.7635 acc_train: 0.2667 loss_val: 1.7851 acc_val: 0.2640 time: 0.1060s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.7623 acc_train: 0.2917 loss_val: 1.7827 acc_val: 0.4080 time: 0.1068s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.7564 acc_train: 0.2667 loss_val: 1.7800 acc_val: 0.3300 time: 0.1044s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.7550 acc_train: 0.2583 loss_val: 1.7773 acc_val: 0.3320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.7528 acc_train: 0.2917 loss_val: 1.7742 acc_val: 0.3520 time: 0.1041s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.7485 acc_train: 0.2917 loss_val: 1.7712 acc_val: 0.3620 time: 0.1048s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.7486 acc_train: 0.3250 loss_val: 1.7680 acc_val: 0.3780 time: 0.1045s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.7302 acc_train: 0.4250 loss_val: 1.7650 acc_val: 0.3860 time: 0.1048s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.7376 acc_train: 0.3250 loss_val: 1.7618 acc_val: 0.4020 time: 0.1040s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.7354 acc_train: 0.4083 loss_val: 1.7591 acc_val: 0.4280 time: 0.1050s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.7278 acc_train: 0.3667 loss_val: 1.7562 acc_val: 0.4420 time: 0.1047s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.7262 acc_train: 0.3333 loss_val: 1.7543 acc_val: 0.5220 time: 0.1044s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.7177 acc_train: 0.4750 loss_val: 1.7526 acc_val: 0.5760 time: 0.1038s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.7149 acc_train: 0.4333 loss_val: 1.7509 acc_val: 0.5820 time: 0.1051s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.7042 acc_train: 0.4333 loss_val: 1.7496 acc_val: 0.5800 time: 0.1047s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.7074 acc_train: 0.4917 loss_val: 1.7484 acc_val: 0.5720 time: 0.1071s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.7084 acc_train: 0.4500 loss_val: 1.7470 acc_val: 0.5800 time: 0.1043s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.6937 acc_train: 0.4333 loss_val: 1.7456 acc_val: 0.5980 time: 0.1042s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.6958 acc_train: 0.4250 loss_val: 1.7444 acc_val: 0.6140 time: 0.1036s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.6877 acc_train: 0.5167 loss_val: 1.7433 acc_val: 0.5820 time: 0.1067s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.6906 acc_train: 0.5250 loss_val: 1.7415 acc_val: 0.5620 time: 0.1044s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.6825 acc_train: 0.4750 loss_val: 1.7390 acc_val: 0.5880 time: 0.1071s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.6738 acc_train: 0.4917 loss_val: 1.7356 acc_val: 0.6420 time: 0.1041s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.6722 acc_train: 0.4167 loss_val: 1.7314 acc_val: 0.6540 time: 0.1043s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.6673 acc_train: 0.5750 loss_val: 1.7266 acc_val: 0.6600 time: 0.1038s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.6417 acc_train: 0.5667 loss_val: 1.7213 acc_val: 0.6520 time: 0.1048s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.6527 acc_train: 0.4750 loss_val: 1.7154 acc_val: 0.6500 time: 0.1037s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.6361 acc_train: 0.5250 loss_val: 1.7103 acc_val: 0.6460 time: 0.1048s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.6453 acc_train: 0.5000 loss_val: 1.7054 acc_val: 0.6520 time: 0.1051s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.6289 acc_train: 0.5667 loss_val: 1.7012 acc_val: 0.6520 time: 0.1044s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.6278 acc_train: 0.5500 loss_val: 1.6974 acc_val: 0.6560 time: 0.1037s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.6084 acc_train: 0.6500 loss_val: 1.6952 acc_val: 0.6400 time: 0.1039s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.6227 acc_train: 0.5750 loss_val: 1.6934 acc_val: 0.6380 time: 0.1041s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.5990 acc_train: 0.5583 loss_val: 1.6917 acc_val: 0.6220 time: 0.1042s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.6039 acc_train: 0.5333 loss_val: 1.6897 acc_val: 0.6180 time: 0.1039s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.5884 acc_train: 0.6083 loss_val: 1.6855 acc_val: 0.6140 time: 0.1042s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.5729 acc_train: 0.6083 loss_val: 1.6803 acc_val: 0.6180 time: 0.1048s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.5703 acc_train: 0.6333 loss_val: 1.6746 acc_val: 0.6140 time: 0.1049s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.5664 acc_train: 0.5750 loss_val: 1.6680 acc_val: 0.6100 time: 0.1039s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.5633 acc_train: 0.6083 loss_val: 1.6607 acc_val: 0.6140 time: 0.1049s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.5395 acc_train: 0.5500 loss_val: 1.6551 acc_val: 0.6180 time: 0.1042s\n",
            "0\n",
            "Epoch: 0073 loss_train: 1.5640 acc_train: 0.5583 loss_val: 1.6496 acc_val: 0.6440 time: 0.1048s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.5356 acc_train: 0.5167 loss_val: 1.6450 acc_val: 0.6500 time: 0.1040s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.5319 acc_train: 0.6000 loss_val: 1.6415 acc_val: 0.6620 time: 0.1042s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.5367 acc_train: 0.6000 loss_val: 1.6388 acc_val: 0.6620 time: 0.1037s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.5086 acc_train: 0.6083 loss_val: 1.6360 acc_val: 0.6700 time: 0.1044s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.5028 acc_train: 0.6000 loss_val: 1.6326 acc_val: 0.6780 time: 0.1049s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.4941 acc_train: 0.6500 loss_val: 1.6272 acc_val: 0.7080 time: 0.1059s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.5043 acc_train: 0.6250 loss_val: 1.6207 acc_val: 0.6900 time: 0.1037s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.4811 acc_train: 0.6250 loss_val: 1.6143 acc_val: 0.6920 time: 0.1041s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.4726 acc_train: 0.6583 loss_val: 1.6098 acc_val: 0.6880 time: 0.1040s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.4704 acc_train: 0.7083 loss_val: 1.6073 acc_val: 0.6740 time: 0.1044s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.4514 acc_train: 0.7167 loss_val: 1.6046 acc_val: 0.6660 time: 0.1039s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.4558 acc_train: 0.6333 loss_val: 1.6004 acc_val: 0.6540 time: 0.1045s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.4404 acc_train: 0.6750 loss_val: 1.5924 acc_val: 0.6840 time: 0.1059s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.4241 acc_train: 0.6917 loss_val: 1.5836 acc_val: 0.6900 time: 0.1044s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.4204 acc_train: 0.6250 loss_val: 1.5769 acc_val: 0.6840 time: 0.1046s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.4466 acc_train: 0.6417 loss_val: 1.5704 acc_val: 0.6900 time: 0.1043s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.4180 acc_train: 0.6917 loss_val: 1.5661 acc_val: 0.6900 time: 0.1041s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.4210 acc_train: 0.6333 loss_val: 1.5632 acc_val: 0.6900 time: 0.1054s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.3811 acc_train: 0.7333 loss_val: 1.5611 acc_val: 0.6980 time: 0.1042s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.3778 acc_train: 0.6917 loss_val: 1.5572 acc_val: 0.6980 time: 0.1097s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.3735 acc_train: 0.6417 loss_val: 1.5538 acc_val: 0.6980 time: 0.1043s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.3602 acc_train: 0.6833 loss_val: 1.5498 acc_val: 0.7000 time: 0.1046s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.3549 acc_train: 0.6917 loss_val: 1.5424 acc_val: 0.6900 time: 0.1046s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.3542 acc_train: 0.6500 loss_val: 1.5335 acc_val: 0.6900 time: 0.1049s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.3271 acc_train: 0.6667 loss_val: 1.5250 acc_val: 0.6920 time: 0.1054s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.3102 acc_train: 0.7000 loss_val: 1.5177 acc_val: 0.6940 time: 0.1046s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.3436 acc_train: 0.7000 loss_val: 1.5122 acc_val: 0.6900 time: 0.1040s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.3056 acc_train: 0.6750 loss_val: 1.5093 acc_val: 0.6940 time: 0.1042s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.3019 acc_train: 0.7000 loss_val: 1.5104 acc_val: 0.6960 time: 0.1041s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.2778 acc_train: 0.7167 loss_val: 1.5095 acc_val: 0.7000 time: 0.1048s\n",
            "1\n",
            "Epoch: 0104 loss_train: 1.2872 acc_train: 0.7000 loss_val: 1.5047 acc_val: 0.7020 time: 0.1050s\n",
            "2\n",
            "Epoch: 0105 loss_train: 1.2915 acc_train: 0.6917 loss_val: 1.4958 acc_val: 0.7020 time: 0.1044s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.2650 acc_train: 0.7583 loss_val: 1.4867 acc_val: 0.7000 time: 0.1050s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.2866 acc_train: 0.7083 loss_val: 1.4789 acc_val: 0.7000 time: 0.1041s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.2780 acc_train: 0.6667 loss_val: 1.4739 acc_val: 0.6980 time: 0.1038s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.2626 acc_train: 0.6917 loss_val: 1.4713 acc_val: 0.7000 time: 0.1042s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.2542 acc_train: 0.7583 loss_val: 1.4705 acc_val: 0.7040 time: 0.1037s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.2668 acc_train: 0.7500 loss_val: 1.4684 acc_val: 0.6980 time: 0.1043s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.2340 acc_train: 0.7083 loss_val: 1.4638 acc_val: 0.7000 time: 0.1038s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.2054 acc_train: 0.7250 loss_val: 1.4577 acc_val: 0.7000 time: 0.1040s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.2155 acc_train: 0.6667 loss_val: 1.4500 acc_val: 0.6920 time: 0.1046s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.2356 acc_train: 0.6750 loss_val: 1.4430 acc_val: 0.6940 time: 0.1060s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.1933 acc_train: 0.7500 loss_val: 1.4370 acc_val: 0.6980 time: 0.1038s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.1754 acc_train: 0.7417 loss_val: 1.4326 acc_val: 0.7000 time: 0.1042s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.1925 acc_train: 0.7500 loss_val: 1.4313 acc_val: 0.7000 time: 0.1047s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.1948 acc_train: 0.7583 loss_val: 1.4272 acc_val: 0.6940 time: 0.1053s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.1974 acc_train: 0.7083 loss_val: 1.4246 acc_val: 0.6960 time: 0.1037s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.1816 acc_train: 0.7500 loss_val: 1.4241 acc_val: 0.7020 time: 0.1040s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.1648 acc_train: 0.7667 loss_val: 1.4232 acc_val: 0.7000 time: 0.1039s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.1646 acc_train: 0.7250 loss_val: 1.4210 acc_val: 0.6980 time: 0.1049s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.1390 acc_train: 0.7417 loss_val: 1.4166 acc_val: 0.6860 time: 0.1043s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.1941 acc_train: 0.6667 loss_val: 1.4121 acc_val: 0.6920 time: 0.1043s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.1617 acc_train: 0.7333 loss_val: 1.4039 acc_val: 0.7000 time: 0.1038s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.1513 acc_train: 0.7500 loss_val: 1.3955 acc_val: 0.7060 time: 0.1042s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.1630 acc_train: 0.7500 loss_val: 1.3901 acc_val: 0.7140 time: 0.1040s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.1230 acc_train: 0.7417 loss_val: 1.3846 acc_val: 0.7120 time: 0.1043s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.1086 acc_train: 0.7250 loss_val: 1.3800 acc_val: 0.7120 time: 0.1053s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.0938 acc_train: 0.7500 loss_val: 1.3759 acc_val: 0.7120 time: 0.1045s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.1362 acc_train: 0.7250 loss_val: 1.3745 acc_val: 0.7040 time: 0.1040s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.0960 acc_train: 0.7917 loss_val: 1.3734 acc_val: 0.7140 time: 0.1045s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.1125 acc_train: 0.8000 loss_val: 1.3719 acc_val: 0.7080 time: 0.1043s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.1186 acc_train: 0.7333 loss_val: 1.3701 acc_val: 0.7080 time: 0.1041s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.1213 acc_train: 0.7250 loss_val: 1.3679 acc_val: 0.7100 time: 0.1052s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.0887 acc_train: 0.7083 loss_val: 1.3658 acc_val: 0.7140 time: 0.1046s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.1328 acc_train: 0.7417 loss_val: 1.3636 acc_val: 0.7260 time: 0.1039s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.0981 acc_train: 0.6833 loss_val: 1.3550 acc_val: 0.7280 time: 0.1061s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.0783 acc_train: 0.7750 loss_val: 1.3477 acc_val: 0.7240 time: 0.1041s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.0814 acc_train: 0.7833 loss_val: 1.3418 acc_val: 0.7080 time: 0.1050s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.0966 acc_train: 0.7750 loss_val: 1.3379 acc_val: 0.7000 time: 0.1043s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.0626 acc_train: 0.7750 loss_val: 1.3416 acc_val: 0.6960 time: 0.1053s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.0645 acc_train: 0.7417 loss_val: 1.3489 acc_val: 0.7000 time: 0.1041s\n",
            "1\n",
            "Epoch: 0145 loss_train: 1.0769 acc_train: 0.7917 loss_val: 1.3507 acc_val: 0.6980 time: 0.1042s\n",
            "2\n",
            "Epoch: 0146 loss_train: 1.0759 acc_train: 0.7917 loss_val: 1.3445 acc_val: 0.6940 time: 0.1045s\n",
            "3\n",
            "Epoch: 0147 loss_train: 1.0474 acc_train: 0.7333 loss_val: 1.3333 acc_val: 0.7080 time: 0.1058s\n",
            "4\n",
            "Epoch: 0148 loss_train: 1.0820 acc_train: 0.6833 loss_val: 1.3204 acc_val: 0.7240 time: 0.1039s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.0557 acc_train: 0.7500 loss_val: 1.3104 acc_val: 0.7200 time: 0.1042s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.0228 acc_train: 0.7917 loss_val: 1.3091 acc_val: 0.7140 time: 0.1037s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.0700 acc_train: 0.6667 loss_val: 1.3156 acc_val: 0.7080 time: 0.1047s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.0445 acc_train: 0.7917 loss_val: 1.3231 acc_val: 0.7200 time: 0.1047s\n",
            "1\n",
            "Epoch: 0153 loss_train: 1.0280 acc_train: 0.7833 loss_val: 1.3282 acc_val: 0.7140 time: 0.1047s\n",
            "2\n",
            "Epoch: 0154 loss_train: 1.0225 acc_train: 0.7583 loss_val: 1.3259 acc_val: 0.7000 time: 0.1042s\n",
            "3\n",
            "Epoch: 0155 loss_train: 1.0137 acc_train: 0.8000 loss_val: 1.3151 acc_val: 0.7080 time: 0.1056s\n",
            "4\n",
            "Epoch: 0156 loss_train: 1.0490 acc_train: 0.7250 loss_val: 1.3040 acc_val: 0.7080 time: 0.1046s\n",
            "5\n",
            "Epoch: 0157 loss_train: 1.0273 acc_train: 0.7417 loss_val: 1.2976 acc_val: 0.7140 time: 0.1046s\n",
            "0\n",
            "Epoch: 0158 loss_train: 1.0174 acc_train: 0.7833 loss_val: 1.2943 acc_val: 0.7100 time: 0.1039s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.0218 acc_train: 0.8000 loss_val: 1.2954 acc_val: 0.7160 time: 0.1042s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.0160 acc_train: 0.7500 loss_val: 1.2958 acc_val: 0.7180 time: 0.1047s\n",
            "1\n",
            "Epoch: 0161 loss_train: 1.0116 acc_train: 0.7750 loss_val: 1.3003 acc_val: 0.7240 time: 0.1073s\n",
            "2\n",
            "Epoch: 0162 loss_train: 1.0166 acc_train: 0.7750 loss_val: 1.3013 acc_val: 0.7140 time: 0.1050s\n",
            "3\n",
            "Epoch: 0163 loss_train: 1.0117 acc_train: 0.8167 loss_val: 1.3002 acc_val: 0.6920 time: 0.1055s\n",
            "4\n",
            "Epoch: 0164 loss_train: 1.0353 acc_train: 0.7250 loss_val: 1.2918 acc_val: 0.7000 time: 0.1054s\n",
            "5\n",
            "Epoch: 0165 loss_train: 0.9804 acc_train: 0.8333 loss_val: 1.2791 acc_val: 0.7080 time: 0.1045s\n",
            "0\n",
            "Epoch: 0166 loss_train: 1.0125 acc_train: 0.8250 loss_val: 1.2703 acc_val: 0.7180 time: 0.1054s\n",
            "0\n",
            "Epoch: 0167 loss_train: 1.0204 acc_train: 0.7417 loss_val: 1.2695 acc_val: 0.7200 time: 0.1078s\n",
            "0\n",
            "Epoch: 0168 loss_train: 1.0049 acc_train: 0.7833 loss_val: 1.2735 acc_val: 0.7220 time: 0.1045s\n",
            "0\n",
            "Epoch: 0169 loss_train: 1.0470 acc_train: 0.7583 loss_val: 1.2786 acc_val: 0.7280 time: 0.1068s\n",
            "1\n",
            "Epoch: 0170 loss_train: 0.9555 acc_train: 0.7833 loss_val: 1.2867 acc_val: 0.7100 time: 0.1049s\n",
            "0\n",
            "Epoch: 0171 loss_train: 0.9987 acc_train: 0.6917 loss_val: 1.2887 acc_val: 0.6960 time: 0.1055s\n",
            "1\n",
            "Epoch: 0172 loss_train: 0.9731 acc_train: 0.7917 loss_val: 1.2824 acc_val: 0.7000 time: 0.1050s\n",
            "2\n",
            "Epoch: 0173 loss_train: 0.9614 acc_train: 0.7333 loss_val: 1.2692 acc_val: 0.7080 time: 0.1051s\n",
            "3\n",
            "Epoch: 0174 loss_train: 0.9434 acc_train: 0.8167 loss_val: 1.2605 acc_val: 0.7280 time: 0.1043s\n",
            "0\n",
            "Epoch: 0175 loss_train: 0.9996 acc_train: 0.7667 loss_val: 1.2595 acc_val: 0.7180 time: 0.1046s\n",
            "0\n",
            "Epoch: 0176 loss_train: 0.9728 acc_train: 0.7667 loss_val: 1.2596 acc_val: 0.7220 time: 0.1038s\n",
            "0\n",
            "Epoch: 0177 loss_train: 0.9889 acc_train: 0.8083 loss_val: 1.2584 acc_val: 0.7180 time: 0.1045s\n",
            "1\n",
            "Epoch: 0178 loss_train: 0.9886 acc_train: 0.7833 loss_val: 1.2581 acc_val: 0.7140 time: 0.1056s\n",
            "0\n",
            "Epoch: 0179 loss_train: 0.9252 acc_train: 0.7750 loss_val: 1.2541 acc_val: 0.7080 time: 0.1043s\n",
            "0\n",
            "Epoch: 0180 loss_train: 0.9789 acc_train: 0.8417 loss_val: 1.2477 acc_val: 0.7060 time: 0.1048s\n",
            "0\n",
            "Epoch: 0181 loss_train: 0.9348 acc_train: 0.8000 loss_val: 1.2425 acc_val: 0.7180 time: 0.1044s\n",
            "0\n",
            "Epoch: 0182 loss_train: 0.9538 acc_train: 0.7833 loss_val: 1.2394 acc_val: 0.7180 time: 0.1044s\n",
            "0\n",
            "Epoch: 0183 loss_train: 0.9126 acc_train: 0.8167 loss_val: 1.2396 acc_val: 0.7300 time: 0.1083s\n",
            "0\n",
            "Epoch: 0184 loss_train: 0.9581 acc_train: 0.8083 loss_val: 1.2444 acc_val: 0.7320 time: 0.1065s\n",
            "0\n",
            "Epoch: 0185 loss_train: 0.9648 acc_train: 0.8083 loss_val: 1.2483 acc_val: 0.7320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0186 loss_train: 0.9298 acc_train: 0.7500 loss_val: 1.2488 acc_val: 0.7220 time: 0.1045s\n",
            "0\n",
            "Epoch: 0187 loss_train: 0.9061 acc_train: 0.8500 loss_val: 1.2450 acc_val: 0.7160 time: 0.1051s\n",
            "1\n",
            "Epoch: 0188 loss_train: 0.9341 acc_train: 0.8417 loss_val: 1.2384 acc_val: 0.7040 time: 0.1052s\n",
            "2\n",
            "Epoch: 0189 loss_train: 0.9084 acc_train: 0.7750 loss_val: 1.2318 acc_val: 0.7060 time: 0.1059s\n",
            "0\n",
            "Epoch: 0190 loss_train: 0.8969 acc_train: 0.7833 loss_val: 1.2296 acc_val: 0.7140 time: 0.1042s\n",
            "0\n",
            "Epoch: 0191 loss_train: 0.9199 acc_train: 0.8000 loss_val: 1.2294 acc_val: 0.7200 time: 0.1047s\n",
            "0\n",
            "Epoch: 0192 loss_train: 0.9430 acc_train: 0.7583 loss_val: 1.2311 acc_val: 0.7360 time: 0.1042s\n",
            "0\n",
            "Epoch: 0193 loss_train: 0.9321 acc_train: 0.7917 loss_val: 1.2323 acc_val: 0.7360 time: 0.1051s\n",
            "0\n",
            "Epoch: 0194 loss_train: 0.9179 acc_train: 0.7917 loss_val: 1.2363 acc_val: 0.7240 time: 0.1043s\n",
            "0\n",
            "Epoch: 0195 loss_train: 0.9040 acc_train: 0.8167 loss_val: 1.2372 acc_val: 0.7240 time: 0.1052s\n",
            "1\n",
            "Epoch: 0196 loss_train: 0.9118 acc_train: 0.7917 loss_val: 1.2369 acc_val: 0.7240 time: 0.1051s\n",
            "2\n",
            "Epoch: 0197 loss_train: 0.9154 acc_train: 0.8083 loss_val: 1.2330 acc_val: 0.7220 time: 0.1060s\n",
            "3\n",
            "Epoch: 0198 loss_train: 0.8928 acc_train: 0.8167 loss_val: 1.2280 acc_val: 0.7200 time: 0.1043s\n",
            "4\n",
            "Epoch: 0199 loss_train: 0.8857 acc_train: 0.7833 loss_val: 1.2211 acc_val: 0.7220 time: 0.1054s\n",
            "0\n",
            "Epoch: 0200 loss_train: 0.8820 acc_train: 0.7917 loss_val: 1.2151 acc_val: 0.7240 time: 0.1045s\n",
            "0\n",
            "Epoch: 0201 loss_train: 0.9137 acc_train: 0.8583 loss_val: 1.2120 acc_val: 0.7280 time: 0.1044s\n",
            "0\n",
            "Epoch: 0202 loss_train: 0.9283 acc_train: 0.7917 loss_val: 1.2117 acc_val: 0.7360 time: 0.1041s\n",
            "0\n",
            "Epoch: 0203 loss_train: 0.9226 acc_train: 0.8667 loss_val: 1.2103 acc_val: 0.7340 time: 0.1045s\n",
            "0\n",
            "Epoch: 0204 loss_train: 0.9351 acc_train: 0.7333 loss_val: 1.2092 acc_val: 0.7320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0205 loss_train: 0.9160 acc_train: 0.8417 loss_val: 1.2093 acc_val: 0.7200 time: 0.1045s\n",
            "0\n",
            "Epoch: 0206 loss_train: 0.8780 acc_train: 0.8250 loss_val: 1.2146 acc_val: 0.7180 time: 0.1041s\n",
            "1\n",
            "Epoch: 0207 loss_train: 0.8821 acc_train: 0.8083 loss_val: 1.2176 acc_val: 0.7160 time: 0.1046s\n",
            "2\n",
            "Epoch: 0208 loss_train: 0.8889 acc_train: 0.7833 loss_val: 1.2162 acc_val: 0.7140 time: 0.1050s\n",
            "3\n",
            "Epoch: 0209 loss_train: 0.8666 acc_train: 0.7667 loss_val: 1.2086 acc_val: 0.7280 time: 0.1046s\n",
            "4\n",
            "Epoch: 0210 loss_train: 0.8952 acc_train: 0.8083 loss_val: 1.2001 acc_val: 0.7260 time: 0.1051s\n",
            "0\n",
            "Epoch: 0211 loss_train: 0.8816 acc_train: 0.8167 loss_val: 1.1962 acc_val: 0.7180 time: 0.1050s\n",
            "0\n",
            "Epoch: 0212 loss_train: 0.9310 acc_train: 0.7500 loss_val: 1.1999 acc_val: 0.7180 time: 0.1039s\n",
            "0\n",
            "Epoch: 0213 loss_train: 0.8828 acc_train: 0.7583 loss_val: 1.2058 acc_val: 0.7240 time: 0.1047s\n",
            "1\n",
            "Epoch: 0214 loss_train: 0.8692 acc_train: 0.7750 loss_val: 1.2119 acc_val: 0.7180 time: 0.1043s\n",
            "2\n",
            "Epoch: 0215 loss_train: 0.8824 acc_train: 0.8417 loss_val: 1.2081 acc_val: 0.7180 time: 0.1049s\n",
            "3\n",
            "Epoch: 0216 loss_train: 0.8611 acc_train: 0.8167 loss_val: 1.1988 acc_val: 0.7160 time: 0.1046s\n",
            "4\n",
            "Epoch: 0217 loss_train: 0.8756 acc_train: 0.8250 loss_val: 1.1890 acc_val: 0.7200 time: 0.1094s\n",
            "5\n",
            "Epoch: 0218 loss_train: 0.8768 acc_train: 0.8250 loss_val: 1.1864 acc_val: 0.7180 time: 0.1038s\n",
            "0\n",
            "Epoch: 0219 loss_train: 0.8881 acc_train: 0.8000 loss_val: 1.1885 acc_val: 0.7140 time: 0.1046s\n",
            "0\n",
            "Epoch: 0220 loss_train: 0.8729 acc_train: 0.7667 loss_val: 1.1940 acc_val: 0.7160 time: 0.1041s\n",
            "1\n",
            "Epoch: 0221 loss_train: 0.8940 acc_train: 0.7583 loss_val: 1.2008 acc_val: 0.7280 time: 0.1061s\n",
            "2\n",
            "Epoch: 0222 loss_train: 0.8451 acc_train: 0.8333 loss_val: 1.2037 acc_val: 0.7260 time: 0.1042s\n",
            "3\n",
            "Epoch: 0223 loss_train: 0.8521 acc_train: 0.8167 loss_val: 1.2009 acc_val: 0.7220 time: 0.1043s\n",
            "4\n",
            "Epoch: 0224 loss_train: 0.9047 acc_train: 0.7833 loss_val: 1.1915 acc_val: 0.7140 time: 0.1059s\n",
            "5\n",
            "Epoch: 0225 loss_train: 0.8333 acc_train: 0.8167 loss_val: 1.1826 acc_val: 0.7180 time: 0.1046s\n",
            "6\n",
            "Epoch: 0226 loss_train: 0.8693 acc_train: 0.8417 loss_val: 1.1764 acc_val: 0.7240 time: 0.1036s\n",
            "0\n",
            "Epoch: 0227 loss_train: 0.8858 acc_train: 0.7417 loss_val: 1.1772 acc_val: 0.7340 time: 0.1049s\n",
            "0\n",
            "Epoch: 0228 loss_train: 0.8819 acc_train: 0.8000 loss_val: 1.1787 acc_val: 0.7280 time: 0.1050s\n",
            "1\n",
            "Epoch: 0229 loss_train: 0.8449 acc_train: 0.8333 loss_val: 1.1813 acc_val: 0.7240 time: 0.1051s\n",
            "2\n",
            "Epoch: 0230 loss_train: 0.8317 acc_train: 0.8167 loss_val: 1.1840 acc_val: 0.7240 time: 0.1043s\n",
            "3\n",
            "Epoch: 0231 loss_train: 0.8610 acc_train: 0.7667 loss_val: 1.1839 acc_val: 0.7260 time: 0.1052s\n",
            "4\n",
            "Epoch: 0232 loss_train: 0.8767 acc_train: 0.7917 loss_val: 1.1798 acc_val: 0.7260 time: 0.1040s\n",
            "5\n",
            "Epoch: 0233 loss_train: 0.8405 acc_train: 0.8667 loss_val: 1.1758 acc_val: 0.7220 time: 0.1045s\n",
            "6\n",
            "Epoch: 0234 loss_train: 0.8425 acc_train: 0.8250 loss_val: 1.1736 acc_val: 0.7140 time: 0.1039s\n",
            "0\n",
            "Epoch: 0235 loss_train: 0.8457 acc_train: 0.7750 loss_val: 1.1734 acc_val: 0.7180 time: 0.1049s\n",
            "0\n",
            "Epoch: 0236 loss_train: 0.8739 acc_train: 0.8583 loss_val: 1.1761 acc_val: 0.7240 time: 0.1046s\n",
            "0\n",
            "Epoch: 0237 loss_train: 0.8884 acc_train: 0.7917 loss_val: 1.1789 acc_val: 0.7280 time: 0.1048s\n",
            "1\n",
            "Epoch: 0238 loss_train: 0.8732 acc_train: 0.8000 loss_val: 1.1821 acc_val: 0.7300 time: 0.1043s\n",
            "2\n",
            "Epoch: 0239 loss_train: 0.8491 acc_train: 0.8417 loss_val: 1.1829 acc_val: 0.7240 time: 0.1053s\n",
            "3\n",
            "Epoch: 0240 loss_train: 0.8892 acc_train: 0.8667 loss_val: 1.1759 acc_val: 0.7180 time: 0.1062s\n",
            "4\n",
            "Epoch: 0241 loss_train: 0.8780 acc_train: 0.8083 loss_val: 1.1706 acc_val: 0.7140 time: 0.1045s\n",
            "5\n",
            "Epoch: 0242 loss_train: 0.8251 acc_train: 0.8250 loss_val: 1.1694 acc_val: 0.7140 time: 0.1038s\n",
            "0\n",
            "Epoch: 0243 loss_train: 0.8147 acc_train: 0.8167 loss_val: 1.1651 acc_val: 0.7160 time: 0.1048s\n",
            "0\n",
            "Epoch: 0244 loss_train: 0.8697 acc_train: 0.8250 loss_val: 1.1605 acc_val: 0.7260 time: 0.1043s\n",
            "0\n",
            "Epoch: 0245 loss_train: 0.8067 acc_train: 0.8417 loss_val: 1.1609 acc_val: 0.7320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0246 loss_train: 0.8270 acc_train: 0.8250 loss_val: 1.1647 acc_val: 0.7420 time: 0.1050s\n",
            "1\n",
            "Epoch: 0247 loss_train: 0.8447 acc_train: 0.7750 loss_val: 1.1695 acc_val: 0.7340 time: 0.1086s\n",
            "0\n",
            "Epoch: 0248 loss_train: 0.8197 acc_train: 0.8083 loss_val: 1.1688 acc_val: 0.7220 time: 0.1045s\n",
            "1\n",
            "Epoch: 0249 loss_train: 0.8490 acc_train: 0.7917 loss_val: 1.1659 acc_val: 0.7240 time: 0.1053s\n",
            "2\n",
            "Epoch: 0250 loss_train: 0.8140 acc_train: 0.8750 loss_val: 1.1610 acc_val: 0.7280 time: 0.1072s\n",
            "3\n",
            "Epoch: 0251 loss_train: 0.7933 acc_train: 0.8250 loss_val: 1.1582 acc_val: 0.7180 time: 0.1049s\n",
            "4\n",
            "Epoch: 0252 loss_train: 0.8529 acc_train: 0.8000 loss_val: 1.1510 acc_val: 0.7140 time: 0.1047s\n",
            "0\n",
            "Epoch: 0253 loss_train: 0.8334 acc_train: 0.7750 loss_val: 1.1480 acc_val: 0.7220 time: 0.1042s\n",
            "0\n",
            "Epoch: 0254 loss_train: 0.8677 acc_train: 0.7167 loss_val: 1.1532 acc_val: 0.7280 time: 0.1037s\n",
            "0\n",
            "Epoch: 0255 loss_train: 0.8075 acc_train: 0.9000 loss_val: 1.1578 acc_val: 0.7300 time: 0.1051s\n",
            "1\n",
            "Epoch: 0256 loss_train: 0.7665 acc_train: 0.8750 loss_val: 1.1616 acc_val: 0.7380 time: 0.1046s\n",
            "2\n",
            "Epoch: 0257 loss_train: 0.7922 acc_train: 0.8167 loss_val: 1.1613 acc_val: 0.7300 time: 0.1047s\n",
            "3\n",
            "Epoch: 0258 loss_train: 0.8149 acc_train: 0.8250 loss_val: 1.1562 acc_val: 0.7220 time: 0.1054s\n",
            "4\n",
            "Epoch: 0259 loss_train: 0.8230 acc_train: 0.8333 loss_val: 1.1485 acc_val: 0.7120 time: 0.1045s\n",
            "5\n",
            "Epoch: 0260 loss_train: 0.8260 acc_train: 0.8000 loss_val: 1.1420 acc_val: 0.7100 time: 0.1054s\n",
            "6\n",
            "Epoch: 0261 loss_train: 0.8382 acc_train: 0.8167 loss_val: 1.1390 acc_val: 0.7160 time: 0.1047s\n",
            "0\n",
            "Epoch: 0262 loss_train: 0.7514 acc_train: 0.9083 loss_val: 1.1403 acc_val: 0.7240 time: 0.1041s\n",
            "0\n",
            "Epoch: 0263 loss_train: 0.7903 acc_train: 0.8250 loss_val: 1.1452 acc_val: 0.7320 time: 0.1047s\n",
            "1\n",
            "Epoch: 0264 loss_train: 0.8021 acc_train: 0.8000 loss_val: 1.1546 acc_val: 0.7340 time: 0.1051s\n",
            "2\n",
            "Epoch: 0265 loss_train: 0.8206 acc_train: 0.8000 loss_val: 1.1593 acc_val: 0.7340 time: 0.1056s\n",
            "3\n",
            "Epoch: 0266 loss_train: 0.7949 acc_train: 0.8583 loss_val: 1.1563 acc_val: 0.7340 time: 0.1051s\n",
            "4\n",
            "Epoch: 0267 loss_train: 0.8039 acc_train: 0.8083 loss_val: 1.1517 acc_val: 0.7200 time: 0.1051s\n",
            "5\n",
            "Epoch: 0268 loss_train: 0.7961 acc_train: 0.7833 loss_val: 1.1432 acc_val: 0.7140 time: 0.1047s\n",
            "6\n",
            "Epoch: 0269 loss_train: 0.8206 acc_train: 0.8083 loss_val: 1.1338 acc_val: 0.7140 time: 0.1057s\n",
            "7\n",
            "Epoch: 0270 loss_train: 0.8459 acc_train: 0.8167 loss_val: 1.1269 acc_val: 0.7240 time: 0.1042s\n",
            "0\n",
            "Epoch: 0271 loss_train: 0.8036 acc_train: 0.8500 loss_val: 1.1303 acc_val: 0.7300 time: 0.1046s\n",
            "0\n",
            "Epoch: 0272 loss_train: 0.7420 acc_train: 0.8417 loss_val: 1.1364 acc_val: 0.7280 time: 0.1041s\n",
            "1\n",
            "Epoch: 0273 loss_train: 0.7983 acc_train: 0.7833 loss_val: 1.1433 acc_val: 0.7300 time: 0.1053s\n",
            "2\n",
            "Epoch: 0274 loss_train: 0.8113 acc_train: 0.8333 loss_val: 1.1490 acc_val: 0.7280 time: 0.1068s\n",
            "3\n",
            "Epoch: 0275 loss_train: 0.7790 acc_train: 0.8167 loss_val: 1.1505 acc_val: 0.7220 time: 0.1066s\n",
            "4\n",
            "Epoch: 0276 loss_train: 0.8218 acc_train: 0.8000 loss_val: 1.1471 acc_val: 0.7180 time: 0.1045s\n",
            "5\n",
            "Epoch: 0277 loss_train: 0.8058 acc_train: 0.7833 loss_val: 1.1396 acc_val: 0.7120 time: 0.1051s\n",
            "6\n",
            "Epoch: 0278 loss_train: 0.8224 acc_train: 0.7917 loss_val: 1.1353 acc_val: 0.7220 time: 0.1041s\n",
            "7\n",
            "Epoch: 0279 loss_train: 0.8120 acc_train: 0.8000 loss_val: 1.1289 acc_val: 0.7260 time: 0.1045s\n",
            "8\n",
            "Epoch: 0280 loss_train: 0.7867 acc_train: 0.8167 loss_val: 1.1265 acc_val: 0.7300 time: 0.1065s\n",
            "9\n",
            "Epoch: 0281 loss_train: 0.8212 acc_train: 0.8500 loss_val: 1.1296 acc_val: 0.7240 time: 0.1044s\n",
            "0\n",
            "Epoch: 0282 loss_train: 0.8069 acc_train: 0.8417 loss_val: 1.1363 acc_val: 0.7300 time: 0.1043s\n",
            "1\n",
            "Epoch: 0283 loss_train: 0.7861 acc_train: 0.7917 loss_val: 1.1413 acc_val: 0.7260 time: 0.1053s\n",
            "2\n",
            "Epoch: 0284 loss_train: 0.7570 acc_train: 0.8333 loss_val: 1.1448 acc_val: 0.7280 time: 0.1062s\n",
            "3\n",
            "Epoch: 0285 loss_train: 0.8094 acc_train: 0.7583 loss_val: 1.1417 acc_val: 0.7260 time: 0.1058s\n",
            "4\n",
            "Epoch: 0286 loss_train: 0.7713 acc_train: 0.7833 loss_val: 1.1359 acc_val: 0.7240 time: 0.1073s\n",
            "5\n",
            "Epoch: 0287 loss_train: 0.7756 acc_train: 0.8333 loss_val: 1.1270 acc_val: 0.7200 time: 0.1055s\n",
            "6\n",
            "Epoch: 0288 loss_train: 0.8144 acc_train: 0.8167 loss_val: 1.1220 acc_val: 0.7220 time: 0.1036s\n",
            "7\n",
            "Epoch: 0289 loss_train: 0.7737 acc_train: 0.8750 loss_val: 1.1210 acc_val: 0.7260 time: 0.1052s\n",
            "0\n",
            "Epoch: 0290 loss_train: 0.7611 acc_train: 0.8167 loss_val: 1.1277 acc_val: 0.7280 time: 0.1042s\n",
            "0\n",
            "Epoch: 0291 loss_train: 0.7997 acc_train: 0.8833 loss_val: 1.1350 acc_val: 0.7360 time: 0.1061s\n",
            "1\n",
            "Epoch: 0292 loss_train: 0.7815 acc_train: 0.8417 loss_val: 1.1443 acc_val: 0.7280 time: 0.1053s\n",
            "2\n",
            "Epoch: 0293 loss_train: 0.7671 acc_train: 0.8833 loss_val: 1.1462 acc_val: 0.7220 time: 0.1049s\n",
            "3\n",
            "Epoch: 0294 loss_train: 0.7628 acc_train: 0.8417 loss_val: 1.1382 acc_val: 0.7160 time: 0.1045s\n",
            "4\n",
            "Epoch: 0295 loss_train: 0.7965 acc_train: 0.8250 loss_val: 1.1277 acc_val: 0.7160 time: 0.1046s\n",
            "5\n",
            "Epoch: 0296 loss_train: 0.7646 acc_train: 0.8250 loss_val: 1.1192 acc_val: 0.7180 time: 0.1046s\n",
            "6\n",
            "Epoch: 0297 loss_train: 0.7602 acc_train: 0.8500 loss_val: 1.1163 acc_val: 0.7240 time: 0.1042s\n",
            "0\n",
            "Epoch: 0298 loss_train: 0.7902 acc_train: 0.7750 loss_val: 1.1149 acc_val: 0.7300 time: 0.1049s\n",
            "0\n",
            "Epoch: 0299 loss_train: 0.7689 acc_train: 0.8667 loss_val: 1.1126 acc_val: 0.7320 time: 0.1057s\n",
            "0\n",
            "Epoch: 0300 loss_train: 0.7305 acc_train: 0.8167 loss_val: 1.1141 acc_val: 0.7280 time: 0.1044s\n",
            "0\n",
            "Epoch: 0301 loss_train: 0.7767 acc_train: 0.8583 loss_val: 1.1171 acc_val: 0.7280 time: 0.1059s\n",
            "1\n",
            "Epoch: 0302 loss_train: 0.7460 acc_train: 0.8500 loss_val: 1.1175 acc_val: 0.7240 time: 0.1047s\n",
            "2\n",
            "Epoch: 0303 loss_train: 0.7631 acc_train: 0.7833 loss_val: 1.1167 acc_val: 0.7240 time: 0.1049s\n",
            "3\n",
            "Epoch: 0304 loss_train: 0.7674 acc_train: 0.8500 loss_val: 1.1161 acc_val: 0.7340 time: 0.1050s\n",
            "4\n",
            "Epoch: 0305 loss_train: 0.7984 acc_train: 0.8417 loss_val: 1.1186 acc_val: 0.7300 time: 0.1056s\n",
            "5\n",
            "Epoch: 0306 loss_train: 0.7827 acc_train: 0.8000 loss_val: 1.1244 acc_val: 0.7260 time: 0.1047s\n",
            "6\n",
            "Epoch: 0307 loss_train: 0.7761 acc_train: 0.8083 loss_val: 1.1277 acc_val: 0.7300 time: 0.1110s\n",
            "7\n",
            "Epoch: 0308 loss_train: 0.7835 acc_train: 0.7417 loss_val: 1.1261 acc_val: 0.7220 time: 0.1056s\n",
            "8\n",
            "Epoch: 0309 loss_train: 0.7797 acc_train: 0.7750 loss_val: 1.1238 acc_val: 0.7160 time: 0.1052s\n",
            "9\n",
            "Epoch: 0310 loss_train: 0.7729 acc_train: 0.8167 loss_val: 1.1205 acc_val: 0.7180 time: 0.1043s\n",
            "10\n",
            "Epoch: 0311 loss_train: 0.7592 acc_train: 0.8833 loss_val: 1.1167 acc_val: 0.7240 time: 0.1062s\n",
            "11\n",
            "Epoch: 0312 loss_train: 0.7604 acc_train: 0.7917 loss_val: 1.1148 acc_val: 0.7340 time: 0.1047s\n",
            "12\n",
            "Epoch: 0313 loss_train: 0.8058 acc_train: 0.8750 loss_val: 1.1145 acc_val: 0.7320 time: 0.1049s\n",
            "13\n",
            "Epoch: 0314 loss_train: 0.7905 acc_train: 0.8167 loss_val: 1.1168 acc_val: 0.7360 time: 0.1055s\n",
            "14\n",
            "Epoch: 0315 loss_train: 0.7584 acc_train: 0.8250 loss_val: 1.1133 acc_val: 0.7320 time: 0.1045s\n",
            "15\n",
            "Epoch: 0316 loss_train: 0.7554 acc_train: 0.8667 loss_val: 1.1113 acc_val: 0.7320 time: 0.1045s\n",
            "16\n",
            "Epoch: 0317 loss_train: 0.7613 acc_train: 0.7833 loss_val: 1.1087 acc_val: 0.7280 time: 0.1044s\n",
            "0\n",
            "Epoch: 0318 loss_train: 0.7559 acc_train: 0.8000 loss_val: 1.1095 acc_val: 0.7260 time: 0.1039s\n",
            "0\n",
            "Epoch: 0319 loss_train: 0.7506 acc_train: 0.8500 loss_val: 1.1125 acc_val: 0.7260 time: 0.1056s\n",
            "1\n",
            "Epoch: 0320 loss_train: 0.7907 acc_train: 0.8000 loss_val: 1.1148 acc_val: 0.7160 time: 0.1047s\n",
            "2\n",
            "Epoch: 0321 loss_train: 0.7753 acc_train: 0.8083 loss_val: 1.1153 acc_val: 0.7200 time: 0.1047s\n",
            "3\n",
            "Epoch: 0322 loss_train: 0.7616 acc_train: 0.8250 loss_val: 1.1154 acc_val: 0.7300 time: 0.1039s\n",
            "4\n",
            "Epoch: 0323 loss_train: 0.7609 acc_train: 0.8167 loss_val: 1.1143 acc_val: 0.7320 time: 0.1054s\n",
            "5\n",
            "Epoch: 0324 loss_train: 0.7612 acc_train: 0.8667 loss_val: 1.1076 acc_val: 0.7340 time: 0.1041s\n",
            "6\n",
            "Epoch: 0325 loss_train: 0.7983 acc_train: 0.8250 loss_val: 1.1038 acc_val: 0.7360 time: 0.1050s\n",
            "0\n",
            "Epoch: 0326 loss_train: 0.7495 acc_train: 0.8500 loss_val: 1.1045 acc_val: 0.7280 time: 0.1041s\n",
            "0\n",
            "Epoch: 0327 loss_train: 0.7981 acc_train: 0.8250 loss_val: 1.1050 acc_val: 0.7180 time: 0.1055s\n",
            "1\n",
            "Epoch: 0328 loss_train: 0.7831 acc_train: 0.8250 loss_val: 1.1078 acc_val: 0.7260 time: 0.1055s\n",
            "2\n",
            "Epoch: 0329 loss_train: 0.7605 acc_train: 0.7750 loss_val: 1.1113 acc_val: 0.7220 time: 0.1052s\n",
            "3\n",
            "Epoch: 0330 loss_train: 0.7578 acc_train: 0.7917 loss_val: 1.1128 acc_val: 0.7220 time: 0.1066s\n",
            "4\n",
            "Epoch: 0331 loss_train: 0.7224 acc_train: 0.8583 loss_val: 1.1058 acc_val: 0.7240 time: 0.1055s\n",
            "5\n",
            "Epoch: 0332 loss_train: 0.7357 acc_train: 0.8917 loss_val: 1.0998 acc_val: 0.7300 time: 0.1055s\n",
            "6\n",
            "Epoch: 0333 loss_train: 0.7981 acc_train: 0.8667 loss_val: 1.0971 acc_val: 0.7320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0334 loss_train: 0.7689 acc_train: 0.8583 loss_val: 1.0986 acc_val: 0.7360 time: 0.1038s\n",
            "0\n",
            "Epoch: 0335 loss_train: 0.7346 acc_train: 0.8667 loss_val: 1.1021 acc_val: 0.7360 time: 0.1076s\n",
            "1\n",
            "Epoch: 0336 loss_train: 0.7197 acc_train: 0.8500 loss_val: 1.1064 acc_val: 0.7320 time: 0.1052s\n",
            "2\n",
            "Epoch: 0337 loss_train: 0.7129 acc_train: 0.8250 loss_val: 1.1097 acc_val: 0.7320 time: 0.1048s\n",
            "3\n",
            "Epoch: 0338 loss_train: 0.7371 acc_train: 0.8583 loss_val: 1.1111 acc_val: 0.7240 time: 0.1042s\n",
            "4\n",
            "Epoch: 0339 loss_train: 0.7502 acc_train: 0.8333 loss_val: 1.1049 acc_val: 0.7200 time: 0.1061s\n",
            "5\n",
            "Epoch: 0340 loss_train: 0.7636 acc_train: 0.8583 loss_val: 1.0943 acc_val: 0.7180 time: 0.1055s\n",
            "6\n",
            "Epoch: 0341 loss_train: 0.7614 acc_train: 0.8333 loss_val: 1.0891 acc_val: 0.7320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0342 loss_train: 0.7431 acc_train: 0.8417 loss_val: 1.0895 acc_val: 0.7280 time: 0.1038s\n",
            "0\n",
            "Epoch: 0343 loss_train: 0.7453 acc_train: 0.8333 loss_val: 1.0974 acc_val: 0.7320 time: 0.1048s\n",
            "1\n",
            "Epoch: 0344 loss_train: 0.7104 acc_train: 0.8167 loss_val: 1.1088 acc_val: 0.7300 time: 0.1043s\n",
            "2\n",
            "Epoch: 0345 loss_train: 0.7812 acc_train: 0.7583 loss_val: 1.1169 acc_val: 0.7240 time: 0.1047s\n",
            "3\n",
            "Epoch: 0346 loss_train: 0.7633 acc_train: 0.8167 loss_val: 1.1211 acc_val: 0.7260 time: 0.1049s\n",
            "4\n",
            "Epoch: 0347 loss_train: 0.7862 acc_train: 0.8250 loss_val: 1.1049 acc_val: 0.7240 time: 0.1048s\n",
            "5\n",
            "Epoch: 0348 loss_train: 0.7318 acc_train: 0.8333 loss_val: 1.0896 acc_val: 0.7240 time: 0.1071s\n",
            "6\n",
            "Epoch: 0349 loss_train: 0.7170 acc_train: 0.8417 loss_val: 1.0800 acc_val: 0.7260 time: 0.1050s\n",
            "7\n",
            "Epoch: 0350 loss_train: 0.6933 acc_train: 0.8500 loss_val: 1.0774 acc_val: 0.7300 time: 0.1042s\n",
            "0\n",
            "Epoch: 0351 loss_train: 0.7031 acc_train: 0.8500 loss_val: 1.0812 acc_val: 0.7340 time: 0.1047s\n",
            "0\n",
            "Epoch: 0352 loss_train: 0.7772 acc_train: 0.8167 loss_val: 1.0878 acc_val: 0.7340 time: 0.1041s\n",
            "1\n",
            "Epoch: 0353 loss_train: 0.7568 acc_train: 0.8250 loss_val: 1.0983 acc_val: 0.7280 time: 0.1052s\n",
            "2\n",
            "Epoch: 0354 loss_train: 0.7303 acc_train: 0.8583 loss_val: 1.1080 acc_val: 0.7220 time: 0.1042s\n",
            "3\n",
            "Epoch: 0355 loss_train: 0.7317 acc_train: 0.8500 loss_val: 1.1133 acc_val: 0.7180 time: 0.1048s\n",
            "4\n",
            "Epoch: 0356 loss_train: 0.7557 acc_train: 0.7750 loss_val: 1.1082 acc_val: 0.7220 time: 0.1040s\n",
            "5\n",
            "Epoch: 0357 loss_train: 0.7528 acc_train: 0.8000 loss_val: 1.0969 acc_val: 0.7300 time: 0.1072s\n",
            "6\n",
            "Epoch: 0358 loss_train: 0.7082 acc_train: 0.8250 loss_val: 1.0829 acc_val: 0.7280 time: 0.1055s\n",
            "7\n",
            "Epoch: 0359 loss_train: 0.7259 acc_train: 0.8583 loss_val: 1.0776 acc_val: 0.7380 time: 0.1048s\n",
            "8\n",
            "Epoch: 0360 loss_train: 0.7763 acc_train: 0.8417 loss_val: 1.0776 acc_val: 0.7400 time: 0.1044s\n",
            "9\n",
            "Epoch: 0361 loss_train: 0.7269 acc_train: 0.8250 loss_val: 1.0838 acc_val: 0.7300 time: 0.1053s\n",
            "10\n",
            "Epoch: 0362 loss_train: 0.7331 acc_train: 0.8167 loss_val: 1.0941 acc_val: 0.7260 time: 0.1042s\n",
            "11\n",
            "Epoch: 0363 loss_train: 0.6877 acc_train: 0.8250 loss_val: 1.1039 acc_val: 0.7280 time: 0.1048s\n",
            "12\n",
            "Epoch: 0364 loss_train: 0.7642 acc_train: 0.8417 loss_val: 1.1060 acc_val: 0.7260 time: 0.1055s\n",
            "13\n",
            "Epoch: 0365 loss_train: 0.7153 acc_train: 0.8500 loss_val: 1.1046 acc_val: 0.7200 time: 0.1047s\n",
            "14\n",
            "Epoch: 0366 loss_train: 0.7467 acc_train: 0.8667 loss_val: 1.0964 acc_val: 0.7280 time: 0.1046s\n",
            "15\n",
            "Epoch: 0367 loss_train: 0.6867 acc_train: 0.8167 loss_val: 1.0887 acc_val: 0.7320 time: 0.1058s\n",
            "16\n",
            "Epoch: 0368 loss_train: 0.7405 acc_train: 0.8250 loss_val: 1.0839 acc_val: 0.7360 time: 0.1055s\n",
            "17\n",
            "Epoch: 0369 loss_train: 0.7407 acc_train: 0.9000 loss_val: 1.0817 acc_val: 0.7320 time: 0.1049s\n",
            "18\n",
            "Epoch: 0370 loss_train: 0.7376 acc_train: 0.8333 loss_val: 1.0839 acc_val: 0.7280 time: 0.1047s\n",
            "19\n",
            "Epoch: 0371 loss_train: 0.7405 acc_train: 0.8833 loss_val: 1.0873 acc_val: 0.7320 time: 0.1045s\n",
            "20\n",
            "Epoch: 0372 loss_train: 0.7608 acc_train: 0.7917 loss_val: 1.0863 acc_val: 0.7240 time: 0.1051s\n",
            "21\n",
            "Epoch: 0373 loss_train: 0.7268 acc_train: 0.8500 loss_val: 1.0866 acc_val: 0.7240 time: 0.1046s\n",
            "22\n",
            "Epoch: 0374 loss_train: 0.7249 acc_train: 0.8667 loss_val: 1.0859 acc_val: 0.7240 time: 0.1040s\n",
            "23\n",
            "Epoch: 0375 loss_train: 0.7187 acc_train: 0.8917 loss_val: 1.0843 acc_val: 0.7240 time: 0.1043s\n",
            "24\n",
            "Epoch: 0376 loss_train: 0.7036 acc_train: 0.8083 loss_val: 1.0882 acc_val: 0.7340 time: 0.1057s\n",
            "25\n",
            "Epoch: 0377 loss_train: 0.7236 acc_train: 0.8750 loss_val: 1.0918 acc_val: 0.7280 time: 0.1055s\n",
            "26\n",
            "Epoch: 0378 loss_train: 0.7201 acc_train: 0.8500 loss_val: 1.0945 acc_val: 0.7280 time: 0.1041s\n",
            "27\n",
            "Epoch: 0379 loss_train: 0.7415 acc_train: 0.8083 loss_val: 1.0950 acc_val: 0.7240 time: 0.1046s\n",
            "28\n",
            "Epoch: 0380 loss_train: 0.7222 acc_train: 0.8583 loss_val: 1.0957 acc_val: 0.7220 time: 0.1046s\n",
            "29\n",
            "Epoch: 0381 loss_train: 0.6999 acc_train: 0.8917 loss_val: 1.0931 acc_val: 0.7280 time: 0.1043s\n",
            "30\n",
            "Epoch: 0382 loss_train: 0.7508 acc_train: 0.8250 loss_val: 1.0908 acc_val: 0.7240 time: 0.1039s\n",
            "31\n",
            "Epoch: 0383 loss_train: 0.7457 acc_train: 0.8833 loss_val: 1.0909 acc_val: 0.7220 time: 0.1052s\n",
            "32\n",
            "Epoch: 0384 loss_train: 0.6995 acc_train: 0.8583 loss_val: 1.0887 acc_val: 0.7240 time: 0.1041s\n",
            "33\n",
            "Epoch: 0385 loss_train: 0.7228 acc_train: 0.8167 loss_val: 1.0895 acc_val: 0.7240 time: 0.1050s\n",
            "34\n",
            "Epoch: 0386 loss_train: 0.7452 acc_train: 0.8000 loss_val: 1.0918 acc_val: 0.7260 time: 0.1048s\n",
            "35\n",
            "Epoch: 0387 loss_train: 0.7336 acc_train: 0.7667 loss_val: 1.0945 acc_val: 0.7260 time: 0.1046s\n",
            "36\n",
            "Epoch: 0388 loss_train: 0.7228 acc_train: 0.8583 loss_val: 1.0933 acc_val: 0.7300 time: 0.1051s\n",
            "37\n",
            "Epoch: 0389 loss_train: 0.7572 acc_train: 0.7667 loss_val: 1.0845 acc_val: 0.7320 time: 0.1062s\n",
            "38\n",
            "Epoch: 0390 loss_train: 0.7297 acc_train: 0.8250 loss_val: 1.0796 acc_val: 0.7280 time: 0.1049s\n",
            "39\n",
            "Epoch: 0391 loss_train: 0.7120 acc_train: 0.8500 loss_val: 1.0797 acc_val: 0.7240 time: 0.1059s\n",
            "40\n",
            "Epoch: 0392 loss_train: 0.7267 acc_train: 0.7667 loss_val: 1.0862 acc_val: 0.7260 time: 0.1058s\n",
            "41\n",
            "Epoch: 0393 loss_train: 0.7234 acc_train: 0.8833 loss_val: 1.0909 acc_val: 0.7300 time: 0.1053s\n",
            "42\n",
            "Epoch: 0394 loss_train: 0.6765 acc_train: 0.8417 loss_val: 1.0936 acc_val: 0.7260 time: 0.1045s\n",
            "43\n",
            "Epoch: 0395 loss_train: 0.7093 acc_train: 0.8833 loss_val: 1.0954 acc_val: 0.7280 time: 0.1055s\n",
            "44\n",
            "Epoch: 0396 loss_train: 0.7278 acc_train: 0.8167 loss_val: 1.0879 acc_val: 0.7220 time: 0.1052s\n",
            "45\n",
            "Epoch: 0397 loss_train: 0.7320 acc_train: 0.8500 loss_val: 1.0810 acc_val: 0.7280 time: 0.1051s\n",
            "46\n",
            "Epoch: 0398 loss_train: 0.7470 acc_train: 0.8250 loss_val: 1.0765 acc_val: 0.7260 time: 0.1042s\n",
            "47\n",
            "Epoch: 0399 loss_train: 0.7312 acc_train: 0.8500 loss_val: 1.0736 acc_val: 0.7240 time: 0.1042s\n",
            "0\n",
            "Epoch: 0400 loss_train: 0.7101 acc_train: 0.8667 loss_val: 1.0734 acc_val: 0.7300 time: 0.1041s\n",
            "0\n",
            "Epoch: 0401 loss_train: 0.7204 acc_train: 0.8500 loss_val: 1.0816 acc_val: 0.7280 time: 0.1048s\n",
            "0\n",
            "Epoch: 0402 loss_train: 0.7275 acc_train: 0.8500 loss_val: 1.0876 acc_val: 0.7340 time: 0.1044s\n",
            "1\n",
            "Epoch: 0403 loss_train: 0.6842 acc_train: 0.8417 loss_val: 1.0867 acc_val: 0.7340 time: 0.1058s\n",
            "2\n",
            "Epoch: 0404 loss_train: 0.7276 acc_train: 0.8083 loss_val: 1.0815 acc_val: 0.7300 time: 0.1044s\n",
            "3\n",
            "Epoch: 0405 loss_train: 0.7392 acc_train: 0.8333 loss_val: 1.0761 acc_val: 0.7300 time: 0.1055s\n",
            "4\n",
            "Epoch: 0406 loss_train: 0.7238 acc_train: 0.8250 loss_val: 1.0747 acc_val: 0.7200 time: 0.1048s\n",
            "5\n",
            "Epoch: 0407 loss_train: 0.7205 acc_train: 0.8500 loss_val: 1.0803 acc_val: 0.7160 time: 0.1053s\n",
            "6\n",
            "Epoch: 0408 loss_train: 0.6696 acc_train: 0.8500 loss_val: 1.0806 acc_val: 0.7180 time: 0.1057s\n",
            "7\n",
            "Epoch: 0409 loss_train: 0.7455 acc_train: 0.7917 loss_val: 1.0807 acc_val: 0.7220 time: 0.1048s\n",
            "8\n",
            "Epoch: 0410 loss_train: 0.7029 acc_train: 0.8500 loss_val: 1.0837 acc_val: 0.7340 time: 0.1048s\n",
            "9\n",
            "Epoch: 0411 loss_train: 0.7382 acc_train: 0.7750 loss_val: 1.0843 acc_val: 0.7420 time: 0.1057s\n",
            "10\n",
            "Epoch: 0412 loss_train: 0.7202 acc_train: 0.8250 loss_val: 1.0806 acc_val: 0.7380 time: 0.1050s\n",
            "0\n",
            "Epoch: 0413 loss_train: 0.6966 acc_train: 0.8500 loss_val: 1.0765 acc_val: 0.7380 time: 0.1057s\n",
            "1\n",
            "Epoch: 0414 loss_train: 0.7419 acc_train: 0.7917 loss_val: 1.0703 acc_val: 0.7320 time: 0.1088s\n",
            "2\n",
            "Epoch: 0415 loss_train: 0.6912 acc_train: 0.8667 loss_val: 1.0661 acc_val: 0.7260 time: 0.1058s\n",
            "0\n",
            "Epoch: 0416 loss_train: 0.7073 acc_train: 0.8917 loss_val: 1.0694 acc_val: 0.7320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0417 loss_train: 0.7021 acc_train: 0.8500 loss_val: 1.0750 acc_val: 0.7240 time: 0.1051s\n",
            "1\n",
            "Epoch: 0418 loss_train: 0.7068 acc_train: 0.8417 loss_val: 1.0809 acc_val: 0.7320 time: 0.1044s\n",
            "2\n",
            "Epoch: 0419 loss_train: 0.7006 acc_train: 0.8417 loss_val: 1.0881 acc_val: 0.7280 time: 0.1056s\n",
            "3\n",
            "Epoch: 0420 loss_train: 0.7157 acc_train: 0.8167 loss_val: 1.0896 acc_val: 0.7300 time: 0.1045s\n",
            "4\n",
            "Epoch: 0421 loss_train: 0.7229 acc_train: 0.8583 loss_val: 1.0839 acc_val: 0.7280 time: 0.1053s\n",
            "5\n",
            "Epoch: 0422 loss_train: 0.7572 acc_train: 0.8167 loss_val: 1.0710 acc_val: 0.7300 time: 0.1050s\n",
            "6\n",
            "Epoch: 0423 loss_train: 0.6889 acc_train: 0.8500 loss_val: 1.0655 acc_val: 0.7320 time: 0.1045s\n",
            "7\n",
            "Epoch: 0424 loss_train: 0.7081 acc_train: 0.8750 loss_val: 1.0666 acc_val: 0.7320 time: 0.1059s\n",
            "0\n",
            "Epoch: 0425 loss_train: 0.7001 acc_train: 0.9250 loss_val: 1.0688 acc_val: 0.7300 time: 0.1062s\n",
            "1\n",
            "Epoch: 0426 loss_train: 0.6816 acc_train: 0.8667 loss_val: 1.0733 acc_val: 0.7280 time: 0.1045s\n",
            "2\n",
            "Epoch: 0427 loss_train: 0.7043 acc_train: 0.8750 loss_val: 1.0792 acc_val: 0.7300 time: 0.1049s\n",
            "3\n",
            "Epoch: 0428 loss_train: 0.7117 acc_train: 0.8750 loss_val: 1.0888 acc_val: 0.7260 time: 0.1049s\n",
            "4\n",
            "Epoch: 0429 loss_train: 0.6929 acc_train: 0.8250 loss_val: 1.0929 acc_val: 0.7180 time: 0.1051s\n",
            "5\n",
            "Epoch: 0430 loss_train: 0.7278 acc_train: 0.8833 loss_val: 1.0948 acc_val: 0.7200 time: 0.1046s\n",
            "6\n",
            "Epoch: 0431 loss_train: 0.7190 acc_train: 0.8583 loss_val: 1.0890 acc_val: 0.7220 time: 0.1056s\n",
            "7\n",
            "Epoch: 0432 loss_train: 0.6877 acc_train: 0.8667 loss_val: 1.0804 acc_val: 0.7300 time: 0.1049s\n",
            "8\n",
            "Epoch: 0433 loss_train: 0.7216 acc_train: 0.8167 loss_val: 1.0718 acc_val: 0.7280 time: 0.1066s\n",
            "9\n",
            "Epoch: 0434 loss_train: 0.7043 acc_train: 0.8167 loss_val: 1.0692 acc_val: 0.7340 time: 0.1061s\n",
            "10\n",
            "Epoch: 0435 loss_train: 0.6809 acc_train: 0.8250 loss_val: 1.0720 acc_val: 0.7280 time: 0.1058s\n",
            "11\n",
            "Epoch: 0436 loss_train: 0.6838 acc_train: 0.8250 loss_val: 1.0774 acc_val: 0.7320 time: 0.1072s\n",
            "12\n",
            "Epoch: 0437 loss_train: 0.7422 acc_train: 0.8417 loss_val: 1.0885 acc_val: 0.7180 time: 0.1068s\n",
            "13\n",
            "Epoch: 0438 loss_train: 0.6879 acc_train: 0.8083 loss_val: 1.0916 acc_val: 0.7160 time: 0.1054s\n",
            "14\n",
            "Epoch: 0439 loss_train: 0.6869 acc_train: 0.8333 loss_val: 1.0867 acc_val: 0.7200 time: 0.1048s\n",
            "15\n",
            "Epoch: 0440 loss_train: 0.6979 acc_train: 0.8333 loss_val: 1.0747 acc_val: 0.7200 time: 0.1047s\n",
            "16\n",
            "Epoch: 0441 loss_train: 0.6624 acc_train: 0.8750 loss_val: 1.0678 acc_val: 0.7240 time: 0.1044s\n",
            "17\n",
            "Epoch: 0442 loss_train: 0.7057 acc_train: 0.7667 loss_val: 1.0640 acc_val: 0.7300 time: 0.1060s\n",
            "18\n",
            "Epoch: 0443 loss_train: 0.7435 acc_train: 0.8333 loss_val: 1.0631 acc_val: 0.7300 time: 0.1050s\n",
            "0\n",
            "Epoch: 0444 loss_train: 0.7283 acc_train: 0.8750 loss_val: 1.0660 acc_val: 0.7300 time: 0.1042s\n",
            "0\n",
            "Epoch: 0445 loss_train: 0.7307 acc_train: 0.8000 loss_val: 1.0692 acc_val: 0.7320 time: 0.1047s\n",
            "1\n",
            "Epoch: 0446 loss_train: 0.7111 acc_train: 0.8583 loss_val: 1.0719 acc_val: 0.7300 time: 0.1043s\n",
            "2\n",
            "Epoch: 0447 loss_train: 0.6652 acc_train: 0.8917 loss_val: 1.0781 acc_val: 0.7240 time: 0.1048s\n",
            "3\n",
            "Epoch: 0448 loss_train: 0.6696 acc_train: 0.8750 loss_val: 1.0811 acc_val: 0.7220 time: 0.1071s\n",
            "4\n",
            "Epoch: 0449 loss_train: 0.6871 acc_train: 0.8750 loss_val: 1.0777 acc_val: 0.7220 time: 0.1055s\n",
            "5\n",
            "Epoch: 0450 loss_train: 0.6812 acc_train: 0.8500 loss_val: 1.0680 acc_val: 0.7220 time: 0.1051s\n",
            "6\n",
            "Epoch: 0451 loss_train: 0.6712 acc_train: 0.8833 loss_val: 1.0648 acc_val: 0.7360 time: 0.1051s\n",
            "7\n",
            "Epoch: 0452 loss_train: 0.7030 acc_train: 0.8000 loss_val: 1.0617 acc_val: 0.7300 time: 0.1063s\n",
            "8\n",
            "Epoch: 0453 loss_train: 0.7197 acc_train: 0.8500 loss_val: 1.0596 acc_val: 0.7340 time: 0.1053s\n",
            "0\n",
            "Epoch: 0454 loss_train: 0.7227 acc_train: 0.8167 loss_val: 1.0637 acc_val: 0.7360 time: 0.1051s\n",
            "0\n",
            "Epoch: 0455 loss_train: 0.7150 acc_train: 0.8750 loss_val: 1.0714 acc_val: 0.7280 time: 0.1050s\n",
            "1\n",
            "Epoch: 0456 loss_train: 0.7163 acc_train: 0.7833 loss_val: 1.0795 acc_val: 0.7220 time: 0.1041s\n",
            "2\n",
            "Epoch: 0457 loss_train: 0.6763 acc_train: 0.8667 loss_val: 1.0792 acc_val: 0.7240 time: 0.1052s\n",
            "3\n",
            "Epoch: 0458 loss_train: 0.6855 acc_train: 0.8583 loss_val: 1.0764 acc_val: 0.7220 time: 0.1040s\n",
            "4\n",
            "Epoch: 0459 loss_train: 0.6692 acc_train: 0.9000 loss_val: 1.0700 acc_val: 0.7300 time: 0.1046s\n",
            "5\n",
            "Epoch: 0460 loss_train: 0.6848 acc_train: 0.8583 loss_val: 1.0630 acc_val: 0.7280 time: 0.1042s\n",
            "6\n",
            "Epoch: 0461 loss_train: 0.6764 acc_train: 0.8500 loss_val: 1.0633 acc_val: 0.7280 time: 0.1056s\n",
            "7\n",
            "Epoch: 0462 loss_train: 0.6683 acc_train: 0.8917 loss_val: 1.0673 acc_val: 0.7300 time: 0.1048s\n",
            "8\n",
            "Epoch: 0463 loss_train: 0.7130 acc_train: 0.8000 loss_val: 1.0645 acc_val: 0.7340 time: 0.1047s\n",
            "9\n",
            "Epoch: 0464 loss_train: 0.7041 acc_train: 0.8500 loss_val: 1.0635 acc_val: 0.7320 time: 0.1043s\n",
            "10\n",
            "Epoch: 0465 loss_train: 0.6929 acc_train: 0.8333 loss_val: 1.0622 acc_val: 0.7360 time: 0.1045s\n",
            "11\n",
            "Epoch: 0466 loss_train: 0.7129 acc_train: 0.8250 loss_val: 1.0653 acc_val: 0.7360 time: 0.1045s\n",
            "12\n",
            "Epoch: 0467 loss_train: 0.7317 acc_train: 0.8083 loss_val: 1.0676 acc_val: 0.7320 time: 0.1053s\n",
            "13\n",
            "Epoch: 0468 loss_train: 0.7069 acc_train: 0.7917 loss_val: 1.0726 acc_val: 0.7300 time: 0.1037s\n",
            "14\n",
            "Epoch: 0469 loss_train: 0.6520 acc_train: 0.8500 loss_val: 1.0747 acc_val: 0.7260 time: 0.1049s\n",
            "15\n",
            "Epoch: 0470 loss_train: 0.6834 acc_train: 0.8583 loss_val: 1.0727 acc_val: 0.7240 time: 0.1047s\n",
            "16\n",
            "Epoch: 0471 loss_train: 0.6680 acc_train: 0.8333 loss_val: 1.0664 acc_val: 0.7340 time: 0.1050s\n",
            "17\n",
            "Epoch: 0472 loss_train: 0.6822 acc_train: 0.8333 loss_val: 1.0603 acc_val: 0.7320 time: 0.1045s\n",
            "18\n",
            "Epoch: 0473 loss_train: 0.6894 acc_train: 0.8333 loss_val: 1.0572 acc_val: 0.7300 time: 0.1046s\n",
            "19\n",
            "Epoch: 0474 loss_train: 0.7289 acc_train: 0.8000 loss_val: 1.0545 acc_val: 0.7300 time: 0.1038s\n",
            "0\n",
            "Epoch: 0475 loss_train: 0.6666 acc_train: 0.8667 loss_val: 1.0575 acc_val: 0.7340 time: 0.1045s\n",
            "0\n",
            "Epoch: 0476 loss_train: 0.6543 acc_train: 0.8917 loss_val: 1.0612 acc_val: 0.7240 time: 0.1045s\n",
            "1\n",
            "Epoch: 0477 loss_train: 0.6874 acc_train: 0.8417 loss_val: 1.0620 acc_val: 0.7160 time: 0.1048s\n",
            "2\n",
            "Epoch: 0478 loss_train: 0.7098 acc_train: 0.8250 loss_val: 1.0622 acc_val: 0.7280 time: 0.1072s\n",
            "3\n",
            "Epoch: 0479 loss_train: 0.6755 acc_train: 0.8333 loss_val: 1.0675 acc_val: 0.7300 time: 0.1048s\n",
            "4\n",
            "Epoch: 0480 loss_train: 0.7190 acc_train: 0.8417 loss_val: 1.0698 acc_val: 0.7260 time: 0.1052s\n",
            "5\n",
            "Epoch: 0481 loss_train: 0.6704 acc_train: 0.9000 loss_val: 1.0687 acc_val: 0.7240 time: 0.1052s\n",
            "6\n",
            "Epoch: 0482 loss_train: 0.7051 acc_train: 0.8750 loss_val: 1.0654 acc_val: 0.7320 time: 0.1041s\n",
            "7\n",
            "Epoch: 0483 loss_train: 0.7292 acc_train: 0.8583 loss_val: 1.0665 acc_val: 0.7300 time: 0.1087s\n",
            "8\n",
            "Epoch: 0484 loss_train: 0.6829 acc_train: 0.8417 loss_val: 1.0687 acc_val: 0.7300 time: 0.1056s\n",
            "9\n",
            "Epoch: 0485 loss_train: 0.7290 acc_train: 0.8583 loss_val: 1.0739 acc_val: 0.7240 time: 0.1044s\n",
            "10\n",
            "Epoch: 0486 loss_train: 0.6883 acc_train: 0.8167 loss_val: 1.0719 acc_val: 0.7260 time: 0.1041s\n",
            "11\n",
            "Epoch: 0487 loss_train: 0.7035 acc_train: 0.8167 loss_val: 1.0675 acc_val: 0.7320 time: 0.1074s\n",
            "12\n",
            "Epoch: 0488 loss_train: 0.6980 acc_train: 0.8667 loss_val: 1.0621 acc_val: 0.7400 time: 0.1053s\n",
            "13\n",
            "Epoch: 0489 loss_train: 0.7301 acc_train: 0.7917 loss_val: 1.0581 acc_val: 0.7360 time: 0.1059s\n",
            "14\n",
            "Epoch: 0490 loss_train: 0.6760 acc_train: 0.8833 loss_val: 1.0559 acc_val: 0.7360 time: 0.1044s\n",
            "15\n",
            "Epoch: 0491 loss_train: 0.6594 acc_train: 0.8917 loss_val: 1.0566 acc_val: 0.7340 time: 0.1047s\n",
            "16\n",
            "Epoch: 0492 loss_train: 0.6750 acc_train: 0.8833 loss_val: 1.0604 acc_val: 0.7280 time: 0.1048s\n",
            "17\n",
            "Epoch: 0493 loss_train: 0.6191 acc_train: 0.9000 loss_val: 1.0655 acc_val: 0.7180 time: 0.1054s\n",
            "18\n",
            "Epoch: 0494 loss_train: 0.6612 acc_train: 0.8417 loss_val: 1.0682 acc_val: 0.7160 time: 0.1043s\n",
            "19\n",
            "Epoch: 0495 loss_train: 0.6957 acc_train: 0.8833 loss_val: 1.0702 acc_val: 0.7300 time: 0.1052s\n",
            "20\n",
            "Epoch: 0496 loss_train: 0.6839 acc_train: 0.8333 loss_val: 1.0728 acc_val: 0.7280 time: 0.1042s\n",
            "21\n",
            "Epoch: 0497 loss_train: 0.7161 acc_train: 0.8500 loss_val: 1.0763 acc_val: 0.7220 time: 0.1054s\n",
            "22\n",
            "Epoch: 0498 loss_train: 0.6380 acc_train: 0.8833 loss_val: 1.0724 acc_val: 0.7280 time: 0.1043s\n",
            "23\n",
            "Epoch: 0499 loss_train: 0.6853 acc_train: 0.8333 loss_val: 1.0654 acc_val: 0.7340 time: 0.1061s\n",
            "24\n",
            "Epoch: 0500 loss_train: 0.6831 acc_train: 0.8417 loss_val: 1.0574 acc_val: 0.7300 time: 0.1058s\n",
            "25\n",
            "Epoch: 0501 loss_train: 0.6380 acc_train: 0.9083 loss_val: 1.0540 acc_val: 0.7360 time: 0.1052s\n",
            "26\n",
            "Epoch: 0502 loss_train: 0.6670 acc_train: 0.9250 loss_val: 1.0596 acc_val: 0.7280 time: 0.1044s\n",
            "0\n",
            "Epoch: 0503 loss_train: 0.7001 acc_train: 0.8667 loss_val: 1.0673 acc_val: 0.7220 time: 0.1054s\n",
            "1\n",
            "Epoch: 0504 loss_train: 0.6429 acc_train: 0.8500 loss_val: 1.0745 acc_val: 0.7140 time: 0.1039s\n",
            "2\n",
            "Epoch: 0505 loss_train: 0.6701 acc_train: 0.8583 loss_val: 1.0742 acc_val: 0.7220 time: 0.1051s\n",
            "3\n",
            "Epoch: 0506 loss_train: 0.6437 acc_train: 0.8833 loss_val: 1.0733 acc_val: 0.7220 time: 0.1049s\n",
            "4\n",
            "Epoch: 0507 loss_train: 0.6878 acc_train: 0.8750 loss_val: 1.0643 acc_val: 0.7420 time: 0.1052s\n",
            "5\n",
            "Epoch: 0508 loss_train: 0.6799 acc_train: 0.8667 loss_val: 1.0548 acc_val: 0.7420 time: 0.1055s\n",
            "0\n",
            "Epoch: 0509 loss_train: 0.6760 acc_train: 0.8750 loss_val: 1.0455 acc_val: 0.7380 time: 0.1054s\n",
            "0\n",
            "Epoch: 0510 loss_train: 0.7202 acc_train: 0.8167 loss_val: 1.0440 acc_val: 0.7320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0511 loss_train: 0.7357 acc_train: 0.8167 loss_val: 1.0485 acc_val: 0.7380 time: 0.1067s\n",
            "0\n",
            "Epoch: 0512 loss_train: 0.6385 acc_train: 0.8583 loss_val: 1.0557 acc_val: 0.7320 time: 0.1046s\n",
            "1\n",
            "Epoch: 0513 loss_train: 0.7046 acc_train: 0.8750 loss_val: 1.0654 acc_val: 0.7300 time: 0.1050s\n",
            "2\n",
            "Epoch: 0514 loss_train: 0.6770 acc_train: 0.8583 loss_val: 1.0755 acc_val: 0.7200 time: 0.1042s\n",
            "3\n",
            "Epoch: 0515 loss_train: 0.7164 acc_train: 0.8083 loss_val: 1.0744 acc_val: 0.7220 time: 0.1052s\n",
            "4\n",
            "Epoch: 0516 loss_train: 0.6668 acc_train: 0.8583 loss_val: 1.0629 acc_val: 0.7320 time: 0.1047s\n",
            "5\n",
            "Epoch: 0517 loss_train: 0.6890 acc_train: 0.8500 loss_val: 1.0504 acc_val: 0.7280 time: 0.1069s\n",
            "6\n",
            "Epoch: 0518 loss_train: 0.6561 acc_train: 0.8583 loss_val: 1.0432 acc_val: 0.7400 time: 0.1054s\n",
            "7\n",
            "Epoch: 0519 loss_train: 0.7122 acc_train: 0.8083 loss_val: 1.0469 acc_val: 0.7360 time: 0.1045s\n",
            "0\n",
            "Epoch: 0520 loss_train: 0.6634 acc_train: 0.8250 loss_val: 1.0547 acc_val: 0.7320 time: 0.1052s\n",
            "1\n",
            "Epoch: 0521 loss_train: 0.6652 acc_train: 0.8333 loss_val: 1.0634 acc_val: 0.7240 time: 0.1045s\n",
            "2\n",
            "Epoch: 0522 loss_train: 0.7212 acc_train: 0.9167 loss_val: 1.0677 acc_val: 0.7260 time: 0.1047s\n",
            "3\n",
            "Epoch: 0523 loss_train: 0.6976 acc_train: 0.8417 loss_val: 1.0697 acc_val: 0.7280 time: 0.1045s\n",
            "4\n",
            "Epoch: 0524 loss_train: 0.6945 acc_train: 0.8667 loss_val: 1.0677 acc_val: 0.7300 time: 0.1048s\n",
            "5\n",
            "Epoch: 0525 loss_train: 0.6670 acc_train: 0.8833 loss_val: 1.0668 acc_val: 0.7280 time: 0.1047s\n",
            "6\n",
            "Epoch: 0526 loss_train: 0.6630 acc_train: 0.8833 loss_val: 1.0685 acc_val: 0.7240 time: 0.1048s\n",
            "7\n",
            "Epoch: 0527 loss_train: 0.6820 acc_train: 0.8333 loss_val: 1.0663 acc_val: 0.7320 time: 0.1069s\n",
            "8\n",
            "Epoch: 0528 loss_train: 0.6912 acc_train: 0.8333 loss_val: 1.0577 acc_val: 0.7320 time: 0.1058s\n",
            "9\n",
            "Epoch: 0529 loss_train: 0.6838 acc_train: 0.8750 loss_val: 1.0461 acc_val: 0.7360 time: 0.1053s\n",
            "10\n",
            "Epoch: 0530 loss_train: 0.6650 acc_train: 0.8250 loss_val: 1.0408 acc_val: 0.7360 time: 0.1055s\n",
            "11\n",
            "Epoch: 0531 loss_train: 0.7080 acc_train: 0.9083 loss_val: 1.0437 acc_val: 0.7380 time: 0.1062s\n",
            "0\n",
            "Epoch: 0532 loss_train: 0.6901 acc_train: 0.8417 loss_val: 1.0470 acc_val: 0.7360 time: 0.1053s\n",
            "1\n",
            "Epoch: 0533 loss_train: 0.6893 acc_train: 0.8583 loss_val: 1.0553 acc_val: 0.7260 time: 0.1050s\n",
            "2\n",
            "Epoch: 0534 loss_train: 0.6878 acc_train: 0.8333 loss_val: 1.0642 acc_val: 0.7260 time: 0.1066s\n",
            "3\n",
            "Epoch: 0535 loss_train: 0.6859 acc_train: 0.8583 loss_val: 1.0663 acc_val: 0.7300 time: 0.1051s\n",
            "4\n",
            "Epoch: 0536 loss_train: 0.6834 acc_train: 0.8750 loss_val: 1.0644 acc_val: 0.7320 time: 0.1069s\n",
            "5\n",
            "Epoch: 0537 loss_train: 0.7072 acc_train: 0.8500 loss_val: 1.0573 acc_val: 0.7340 time: 0.1048s\n",
            "6\n",
            "Epoch: 0538 loss_train: 0.6884 acc_train: 0.8333 loss_val: 1.0492 acc_val: 0.7340 time: 0.1047s\n",
            "7\n",
            "Epoch: 0539 loss_train: 0.6856 acc_train: 0.8083 loss_val: 1.0417 acc_val: 0.7360 time: 0.1051s\n",
            "8\n",
            "Epoch: 0540 loss_train: 0.6414 acc_train: 0.8500 loss_val: 1.0387 acc_val: 0.7380 time: 0.1044s\n",
            "9\n",
            "Epoch: 0541 loss_train: 0.6594 acc_train: 0.8500 loss_val: 1.0411 acc_val: 0.7340 time: 0.1043s\n",
            "0\n",
            "Epoch: 0542 loss_train: 0.6811 acc_train: 0.8417 loss_val: 1.0460 acc_val: 0.7340 time: 0.1049s\n",
            "1\n",
            "Epoch: 0543 loss_train: 0.6650 acc_train: 0.8750 loss_val: 1.0548 acc_val: 0.7280 time: 0.1049s\n",
            "2\n",
            "Epoch: 0544 loss_train: 0.6440 acc_train: 0.8583 loss_val: 1.0613 acc_val: 0.7260 time: 0.1043s\n",
            "3\n",
            "Epoch: 0545 loss_train: 0.6607 acc_train: 0.8500 loss_val: 1.0606 acc_val: 0.7300 time: 0.1050s\n",
            "4\n",
            "Epoch: 0546 loss_train: 0.6645 acc_train: 0.8583 loss_val: 1.0592 acc_val: 0.7300 time: 0.1094s\n",
            "5\n",
            "Epoch: 0547 loss_train: 0.7078 acc_train: 0.8750 loss_val: 1.0558 acc_val: 0.7320 time: 0.1067s\n",
            "6\n",
            "Epoch: 0548 loss_train: 0.7154 acc_train: 0.7750 loss_val: 1.0539 acc_val: 0.7320 time: 0.1049s\n",
            "7\n",
            "Epoch: 0549 loss_train: 0.7184 acc_train: 0.8583 loss_val: 1.0535 acc_val: 0.7360 time: 0.1053s\n",
            "8\n",
            "Epoch: 0550 loss_train: 0.6916 acc_train: 0.8000 loss_val: 1.0577 acc_val: 0.7280 time: 0.1073s\n",
            "9\n",
            "Epoch: 0551 loss_train: 0.7022 acc_train: 0.8250 loss_val: 1.0647 acc_val: 0.7180 time: 0.1063s\n",
            "10\n",
            "Epoch: 0552 loss_train: 0.6626 acc_train: 0.8833 loss_val: 1.0615 acc_val: 0.7200 time: 0.1067s\n",
            "11\n",
            "Epoch: 0553 loss_train: 0.6545 acc_train: 0.8583 loss_val: 1.0550 acc_val: 0.7240 time: 0.1052s\n",
            "12\n",
            "Epoch: 0554 loss_train: 0.6608 acc_train: 0.8250 loss_val: 1.0495 acc_val: 0.7260 time: 0.1066s\n",
            "13\n",
            "Epoch: 0555 loss_train: 0.6674 acc_train: 0.8417 loss_val: 1.0458 acc_val: 0.7340 time: 0.1057s\n",
            "14\n",
            "Epoch: 0556 loss_train: 0.6559 acc_train: 0.8167 loss_val: 1.0463 acc_val: 0.7280 time: 0.1047s\n",
            "15\n",
            "Epoch: 0557 loss_train: 0.6756 acc_train: 0.8833 loss_val: 1.0469 acc_val: 0.7340 time: 0.1051s\n",
            "16\n",
            "Epoch: 0558 loss_train: 0.6796 acc_train: 0.8250 loss_val: 1.0508 acc_val: 0.7320 time: 0.1045s\n",
            "17\n",
            "Epoch: 0559 loss_train: 0.7224 acc_train: 0.8167 loss_val: 1.0551 acc_val: 0.7260 time: 0.1059s\n",
            "18\n",
            "Epoch: 0560 loss_train: 0.7140 acc_train: 0.8583 loss_val: 1.0588 acc_val: 0.7240 time: 0.1053s\n",
            "19\n",
            "Epoch: 0561 loss_train: 0.6719 acc_train: 0.8417 loss_val: 1.0566 acc_val: 0.7260 time: 0.1056s\n",
            "20\n",
            "Epoch: 0562 loss_train: 0.6896 acc_train: 0.8333 loss_val: 1.0547 acc_val: 0.7340 time: 0.1046s\n",
            "21\n",
            "Epoch: 0563 loss_train: 0.6864 acc_train: 0.7417 loss_val: 1.0488 acc_val: 0.7340 time: 0.1052s\n",
            "22\n",
            "Epoch: 0564 loss_train: 0.6458 acc_train: 0.9000 loss_val: 1.0455 acc_val: 0.7300 time: 0.1060s\n",
            "23\n",
            "Epoch: 0565 loss_train: 0.6831 acc_train: 0.8417 loss_val: 1.0486 acc_val: 0.7260 time: 0.1048s\n",
            "24\n",
            "Epoch: 0566 loss_train: 0.6749 acc_train: 0.8500 loss_val: 1.0522 acc_val: 0.7240 time: 0.1060s\n",
            "25\n",
            "Epoch: 0567 loss_train: 0.6835 acc_train: 0.8500 loss_val: 1.0591 acc_val: 0.7240 time: 0.1046s\n",
            "26\n",
            "Epoch: 0568 loss_train: 0.6932 acc_train: 0.7583 loss_val: 1.0687 acc_val: 0.7200 time: 0.1050s\n",
            "27\n",
            "Epoch: 0569 loss_train: 0.6723 acc_train: 0.8250 loss_val: 1.0674 acc_val: 0.7240 time: 0.1073s\n",
            "28\n",
            "Epoch: 0570 loss_train: 0.6933 acc_train: 0.8083 loss_val: 1.0652 acc_val: 0.7280 time: 0.1070s\n",
            "29\n",
            "Epoch: 0571 loss_train: 0.6577 acc_train: 0.8333 loss_val: 1.0567 acc_val: 0.7280 time: 0.1053s\n",
            "30\n",
            "Epoch: 0572 loss_train: 0.6835 acc_train: 0.7833 loss_val: 1.0491 acc_val: 0.7300 time: 0.1055s\n",
            "31\n",
            "Epoch: 0573 loss_train: 0.6575 acc_train: 0.8167 loss_val: 1.0462 acc_val: 0.7320 time: 0.1048s\n",
            "32\n",
            "Epoch: 0574 loss_train: 0.6963 acc_train: 0.7833 loss_val: 1.0485 acc_val: 0.7360 time: 0.1056s\n",
            "33\n",
            "Epoch: 0575 loss_train: 0.6733 acc_train: 0.8167 loss_val: 1.0525 acc_val: 0.7220 time: 0.1048s\n",
            "34\n",
            "Epoch: 0576 loss_train: 0.6586 acc_train: 0.8583 loss_val: 1.0536 acc_val: 0.7260 time: 0.1046s\n",
            "35\n",
            "Epoch: 0577 loss_train: 0.6777 acc_train: 0.8583 loss_val: 1.0559 acc_val: 0.7200 time: 0.1051s\n",
            "36\n",
            "Epoch: 0578 loss_train: 0.6334 acc_train: 0.8417 loss_val: 1.0529 acc_val: 0.7320 time: 0.1046s\n",
            "37\n",
            "Epoch: 0579 loss_train: 0.6826 acc_train: 0.8083 loss_val: 1.0507 acc_val: 0.7340 time: 0.1051s\n",
            "38\n",
            "Epoch: 0580 loss_train: 0.6550 acc_train: 0.8667 loss_val: 1.0546 acc_val: 0.7280 time: 0.1063s\n",
            "39\n",
            "Epoch: 0581 loss_train: 0.6717 acc_train: 0.8167 loss_val: 1.0578 acc_val: 0.7260 time: 0.1049s\n",
            "40\n",
            "Epoch: 0582 loss_train: 0.7055 acc_train: 0.8000 loss_val: 1.0608 acc_val: 0.7300 time: 0.1044s\n",
            "41\n",
            "Epoch: 0583 loss_train: 0.6921 acc_train: 0.7917 loss_val: 1.0629 acc_val: 0.7280 time: 0.1063s\n",
            "42\n",
            "Epoch: 0584 loss_train: 0.6891 acc_train: 0.8333 loss_val: 1.0607 acc_val: 0.7200 time: 0.1057s\n",
            "43\n",
            "Epoch: 0585 loss_train: 0.6935 acc_train: 0.8083 loss_val: 1.0565 acc_val: 0.7300 time: 0.1063s\n",
            "44\n",
            "Epoch: 0586 loss_train: 0.6278 acc_train: 0.8583 loss_val: 1.0505 acc_val: 0.7300 time: 0.1069s\n",
            "45\n",
            "Epoch: 0587 loss_train: 0.6500 acc_train: 0.9167 loss_val: 1.0458 acc_val: 0.7340 time: 0.1050s\n",
            "46\n",
            "Epoch: 0588 loss_train: 0.6918 acc_train: 0.8333 loss_val: 1.0468 acc_val: 0.7260 time: 0.1041s\n",
            "47\n",
            "Epoch: 0589 loss_train: 0.6499 acc_train: 0.8750 loss_val: 1.0532 acc_val: 0.7180 time: 0.1049s\n",
            "48\n",
            "Epoch: 0590 loss_train: 0.6425 acc_train: 0.9167 loss_val: 1.0582 acc_val: 0.7200 time: 0.1047s\n",
            "49\n",
            "Epoch: 0591 loss_train: 0.6942 acc_train: 0.8667 loss_val: 1.0614 acc_val: 0.7260 time: 0.1048s\n",
            "50\n",
            "Epoch: 0592 loss_train: 0.6842 acc_train: 0.8333 loss_val: 1.0614 acc_val: 0.7320 time: 0.1053s\n",
            "51\n",
            "Epoch: 0593 loss_train: 0.6750 acc_train: 0.8417 loss_val: 1.0624 acc_val: 0.7360 time: 0.1066s\n",
            "52\n",
            "Epoch: 0594 loss_train: 0.6878 acc_train: 0.8500 loss_val: 1.0640 acc_val: 0.7280 time: 0.1047s\n",
            "53\n",
            "Epoch: 0595 loss_train: 0.6731 acc_train: 0.8333 loss_val: 1.0581 acc_val: 0.7280 time: 0.1059s\n",
            "54\n",
            "Epoch: 0596 loss_train: 0.6945 acc_train: 0.8000 loss_val: 1.0540 acc_val: 0.7300 time: 0.1050s\n",
            "55\n",
            "Epoch: 0597 loss_train: 0.6898 acc_train: 0.8333 loss_val: 1.0519 acc_val: 0.7320 time: 0.1052s\n",
            "56\n",
            "Epoch: 0598 loss_train: 0.6635 acc_train: 0.8750 loss_val: 1.0463 acc_val: 0.7320 time: 0.1047s\n",
            "57\n",
            "Epoch: 0599 loss_train: 0.6569 acc_train: 0.8833 loss_val: 1.0416 acc_val: 0.7360 time: 0.1071s\n",
            "58\n",
            "Epoch: 0600 loss_train: 0.6777 acc_train: 0.8750 loss_val: 1.0442 acc_val: 0.7440 time: 0.1042s\n",
            "59\n",
            "Epoch: 0601 loss_train: 0.6728 acc_train: 0.8583 loss_val: 1.0477 acc_val: 0.7440 time: 0.1060s\n",
            "0\n",
            "Epoch: 0602 loss_train: 0.6600 acc_train: 0.8500 loss_val: 1.0524 acc_val: 0.7400 time: 0.1066s\n",
            "0\n",
            "Epoch: 0603 loss_train: 0.7062 acc_train: 0.8333 loss_val: 1.0547 acc_val: 0.7320 time: 0.1047s\n",
            "1\n",
            "Epoch: 0604 loss_train: 0.6663 acc_train: 0.8750 loss_val: 1.0522 acc_val: 0.7260 time: 0.1062s\n",
            "2\n",
            "Epoch: 0605 loss_train: 0.6634 acc_train: 0.8083 loss_val: 1.0483 acc_val: 0.7360 time: 0.1060s\n",
            "3\n",
            "Epoch: 0606 loss_train: 0.6710 acc_train: 0.8583 loss_val: 1.0477 acc_val: 0.7320 time: 0.1059s\n",
            "4\n",
            "Epoch: 0607 loss_train: 0.6964 acc_train: 0.8417 loss_val: 1.0495 acc_val: 0.7360 time: 0.1047s\n",
            "5\n",
            "Epoch: 0608 loss_train: 0.6700 acc_train: 0.9083 loss_val: 1.0552 acc_val: 0.7260 time: 0.1045s\n",
            "6\n",
            "Epoch: 0609 loss_train: 0.6664 acc_train: 0.8833 loss_val: 1.0626 acc_val: 0.7260 time: 0.1048s\n",
            "7\n",
            "Epoch: 0610 loss_train: 0.6723 acc_train: 0.8417 loss_val: 1.0649 acc_val: 0.7400 time: 0.1044s\n",
            "8\n",
            "Epoch: 0611 loss_train: 0.7221 acc_train: 0.8333 loss_val: 1.0569 acc_val: 0.7360 time: 0.1116s\n",
            "9\n",
            "Epoch: 0612 loss_train: 0.6680 acc_train: 0.8083 loss_val: 1.0503 acc_val: 0.7280 time: 0.1045s\n",
            "10\n",
            "Epoch: 0613 loss_train: 0.6671 acc_train: 0.8917 loss_val: 1.0454 acc_val: 0.7320 time: 0.1046s\n",
            "11\n",
            "Epoch: 0614 loss_train: 0.6751 acc_train: 0.8500 loss_val: 1.0418 acc_val: 0.7300 time: 0.1045s\n",
            "12\n",
            "Epoch: 0615 loss_train: 0.7086 acc_train: 0.8000 loss_val: 1.0415 acc_val: 0.7320 time: 0.1072s\n",
            "13\n",
            "Epoch: 0616 loss_train: 0.6998 acc_train: 0.8917 loss_val: 1.0458 acc_val: 0.7260 time: 0.1046s\n",
            "14\n",
            "Epoch: 0617 loss_train: 0.6494 acc_train: 0.9167 loss_val: 1.0518 acc_val: 0.7280 time: 0.1050s\n",
            "15\n",
            "Epoch: 0618 loss_train: 0.6770 acc_train: 0.8583 loss_val: 1.0567 acc_val: 0.7320 time: 0.1055s\n",
            "16\n",
            "Epoch: 0619 loss_train: 0.6531 acc_train: 0.7917 loss_val: 1.0568 acc_val: 0.7300 time: 0.1065s\n",
            "17\n",
            "Epoch: 0620 loss_train: 0.6536 acc_train: 0.7833 loss_val: 1.0525 acc_val: 0.7360 time: 0.1048s\n",
            "18\n",
            "Epoch: 0621 loss_train: 0.7028 acc_train: 0.8000 loss_val: 1.0500 acc_val: 0.7360 time: 0.1061s\n",
            "19\n",
            "Epoch: 0622 loss_train: 0.7265 acc_train: 0.8417 loss_val: 1.0465 acc_val: 0.7320 time: 0.1061s\n",
            "20\n",
            "Epoch: 0623 loss_train: 0.6510 acc_train: 0.8667 loss_val: 1.0414 acc_val: 0.7280 time: 0.1053s\n",
            "21\n",
            "Epoch: 0624 loss_train: 0.6844 acc_train: 0.8667 loss_val: 1.0410 acc_val: 0.7340 time: 0.1058s\n",
            "22\n",
            "Epoch: 0625 loss_train: 0.6254 acc_train: 0.9000 loss_val: 1.0443 acc_val: 0.7300 time: 0.1062s\n",
            "23\n",
            "Epoch: 0626 loss_train: 0.6535 acc_train: 0.8417 loss_val: 1.0495 acc_val: 0.7260 time: 0.1048s\n",
            "24\n",
            "Epoch: 0627 loss_train: 0.6668 acc_train: 0.8833 loss_val: 1.0504 acc_val: 0.7280 time: 0.1052s\n",
            "25\n",
            "Epoch: 0628 loss_train: 0.6788 acc_train: 0.8500 loss_val: 1.0518 acc_val: 0.7320 time: 0.1054s\n",
            "26\n",
            "Epoch: 0629 loss_train: 0.7108 acc_train: 0.8333 loss_val: 1.0559 acc_val: 0.7300 time: 0.1052s\n",
            "27\n",
            "Epoch: 0630 loss_train: 0.6704 acc_train: 0.8250 loss_val: 1.0536 acc_val: 0.7300 time: 0.1047s\n",
            "28\n",
            "Epoch: 0631 loss_train: 0.6454 acc_train: 0.8500 loss_val: 1.0450 acc_val: 0.7320 time: 0.1054s\n",
            "29\n",
            "Epoch: 0632 loss_train: 0.7258 acc_train: 0.8250 loss_val: 1.0416 acc_val: 0.7240 time: 0.1072s\n",
            "30\n",
            "Epoch: 0633 loss_train: 0.6726 acc_train: 0.8583 loss_val: 1.0429 acc_val: 0.7300 time: 0.1045s\n",
            "31\n",
            "Epoch: 0634 loss_train: 0.6718 acc_train: 0.8500 loss_val: 1.0407 acc_val: 0.7260 time: 0.1042s\n",
            "32\n",
            "Epoch: 0635 loss_train: 0.7219 acc_train: 0.8250 loss_val: 1.0400 acc_val: 0.7300 time: 0.1049s\n",
            "33\n",
            "Epoch: 0636 loss_train: 0.6706 acc_train: 0.8417 loss_val: 1.0423 acc_val: 0.7280 time: 0.1051s\n",
            "34\n",
            "Epoch: 0637 loss_train: 0.6481 acc_train: 0.8750 loss_val: 1.0479 acc_val: 0.7380 time: 0.1054s\n",
            "35\n",
            "Epoch: 0638 loss_train: 0.6764 acc_train: 0.8583 loss_val: 1.0536 acc_val: 0.7320 time: 0.1045s\n",
            "36\n",
            "Epoch: 0639 loss_train: 0.6608 acc_train: 0.8500 loss_val: 1.0615 acc_val: 0.7320 time: 0.1049s\n",
            "37\n",
            "Epoch: 0640 loss_train: 0.6689 acc_train: 0.8250 loss_val: 1.0642 acc_val: 0.7260 time: 0.1043s\n",
            "38\n",
            "Epoch: 0641 loss_train: 0.6663 acc_train: 0.8750 loss_val: 1.0610 acc_val: 0.7260 time: 0.1062s\n",
            "39\n",
            "Epoch: 0642 loss_train: 0.6912 acc_train: 0.8833 loss_val: 1.0522 acc_val: 0.7300 time: 0.1075s\n",
            "40\n",
            "Epoch: 0643 loss_train: 0.6645 acc_train: 0.8417 loss_val: 1.0408 acc_val: 0.7340 time: 0.1043s\n",
            "41\n",
            "Epoch: 0644 loss_train: 0.6397 acc_train: 0.8333 loss_val: 1.0329 acc_val: 0.7380 time: 0.1050s\n",
            "42\n",
            "Epoch: 0645 loss_train: 0.6860 acc_train: 0.8500 loss_val: 1.0326 acc_val: 0.7380 time: 0.1046s\n",
            "0\n",
            "Epoch: 0646 loss_train: 0.6740 acc_train: 0.8667 loss_val: 1.0378 acc_val: 0.7360 time: 0.1039s\n",
            "0\n",
            "Epoch: 0647 loss_train: 0.6557 acc_train: 0.8417 loss_val: 1.0461 acc_val: 0.7360 time: 0.1051s\n",
            "1\n",
            "Epoch: 0648 loss_train: 0.6734 acc_train: 0.8417 loss_val: 1.0551 acc_val: 0.7220 time: 0.1055s\n",
            "2\n",
            "Epoch: 0649 loss_train: 0.7077 acc_train: 0.8333 loss_val: 1.0584 acc_val: 0.7160 time: 0.1065s\n",
            "3\n",
            "Epoch: 0650 loss_train: 0.7048 acc_train: 0.8417 loss_val: 1.0577 acc_val: 0.7200 time: 0.1046s\n",
            "4\n",
            "Epoch: 0651 loss_train: 0.6464 acc_train: 0.8000 loss_val: 1.0510 acc_val: 0.7240 time: 0.1059s\n",
            "5\n",
            "Epoch: 0652 loss_train: 0.6426 acc_train: 0.9000 loss_val: 1.0453 acc_val: 0.7380 time: 0.1044s\n",
            "6\n",
            "Epoch: 0653 loss_train: 0.6514 acc_train: 0.8583 loss_val: 1.0396 acc_val: 0.7260 time: 0.1050s\n",
            "7\n",
            "Epoch: 0654 loss_train: 0.6168 acc_train: 0.9083 loss_val: 1.0389 acc_val: 0.7320 time: 0.1058s\n",
            "8\n",
            "Epoch: 0655 loss_train: 0.6667 acc_train: 0.8917 loss_val: 1.0430 acc_val: 0.7320 time: 0.1047s\n",
            "9\n",
            "Epoch: 0656 loss_train: 0.6639 acc_train: 0.8583 loss_val: 1.0483 acc_val: 0.7360 time: 0.1042s\n",
            "10\n",
            "Epoch: 0657 loss_train: 0.6509 acc_train: 0.8500 loss_val: 1.0564 acc_val: 0.7200 time: 0.1048s\n",
            "11\n",
            "Epoch: 0658 loss_train: 0.6755 acc_train: 0.8500 loss_val: 1.0579 acc_val: 0.7200 time: 0.1062s\n",
            "12\n",
            "Epoch: 0659 loss_train: 0.6055 acc_train: 0.9000 loss_val: 1.0562 acc_val: 0.7220 time: 0.1050s\n",
            "13\n",
            "Epoch: 0660 loss_train: 0.6962 acc_train: 0.8500 loss_val: 1.0504 acc_val: 0.7260 time: 0.1041s\n",
            "14\n",
            "Epoch: 0661 loss_train: 0.6554 acc_train: 0.8583 loss_val: 1.0456 acc_val: 0.7340 time: 0.1050s\n",
            "15\n",
            "Epoch: 0662 loss_train: 0.6589 acc_train: 0.8500 loss_val: 1.0450 acc_val: 0.7380 time: 0.1066s\n",
            "16\n",
            "Epoch: 0663 loss_train: 0.6969 acc_train: 0.8833 loss_val: 1.0477 acc_val: 0.7360 time: 0.1051s\n",
            "17\n",
            "Epoch: 0664 loss_train: 0.6429 acc_train: 0.8500 loss_val: 1.0539 acc_val: 0.7280 time: 0.1051s\n",
            "18\n",
            "Epoch: 0665 loss_train: 0.6746 acc_train: 0.8583 loss_val: 1.0554 acc_val: 0.7320 time: 0.1047s\n",
            "19\n",
            "Epoch: 0666 loss_train: 0.6676 acc_train: 0.8583 loss_val: 1.0536 acc_val: 0.7340 time: 0.1044s\n",
            "20\n",
            "Epoch: 0667 loss_train: 0.6883 acc_train: 0.8583 loss_val: 1.0503 acc_val: 0.7340 time: 0.1048s\n",
            "21\n",
            "Epoch: 0668 loss_train: 0.6361 acc_train: 0.8833 loss_val: 1.0463 acc_val: 0.7320 time: 0.1053s\n",
            "22\n",
            "Epoch: 0669 loss_train: 0.6426 acc_train: 0.8500 loss_val: 1.0442 acc_val: 0.7200 time: 0.1048s\n",
            "23\n",
            "Epoch: 0670 loss_train: 0.6629 acc_train: 0.8333 loss_val: 1.0463 acc_val: 0.7200 time: 0.1051s\n",
            "24\n",
            "Epoch: 0671 loss_train: 0.6853 acc_train: 0.8250 loss_val: 1.0494 acc_val: 0.7280 time: 0.1054s\n",
            "25\n",
            "Epoch: 0672 loss_train: 0.6489 acc_train: 0.8833 loss_val: 1.0493 acc_val: 0.7320 time: 0.1040s\n",
            "26\n",
            "Epoch: 0673 loss_train: 0.6587 acc_train: 0.8167 loss_val: 1.0501 acc_val: 0.7280 time: 0.1058s\n",
            "27\n",
            "Epoch: 0674 loss_train: 0.6445 acc_train: 0.8583 loss_val: 1.0477 acc_val: 0.7300 time: 0.1041s\n",
            "28\n",
            "Epoch: 0675 loss_train: 0.6639 acc_train: 0.8500 loss_val: 1.0449 acc_val: 0.7360 time: 0.1058s\n",
            "29\n",
            "Epoch: 0676 loss_train: 0.6849 acc_train: 0.8500 loss_val: 1.0448 acc_val: 0.7360 time: 0.1067s\n",
            "30\n",
            "Epoch: 0677 loss_train: 0.6841 acc_train: 0.8167 loss_val: 1.0456 acc_val: 0.7300 time: 0.1055s\n",
            "31\n",
            "Epoch: 0678 loss_train: 0.6595 acc_train: 0.8750 loss_val: 1.0479 acc_val: 0.7300 time: 0.1047s\n",
            "32\n",
            "Epoch: 0679 loss_train: 0.6837 acc_train: 0.9000 loss_val: 1.0492 acc_val: 0.7360 time: 0.1047s\n",
            "33\n",
            "Epoch: 0680 loss_train: 0.6884 acc_train: 0.9250 loss_val: 1.0457 acc_val: 0.7360 time: 0.1045s\n",
            "34\n",
            "Epoch: 0681 loss_train: 0.6715 acc_train: 0.9083 loss_val: 1.0435 acc_val: 0.7320 time: 0.1048s\n",
            "35\n",
            "Epoch: 0682 loss_train: 0.6596 acc_train: 0.8500 loss_val: 1.0426 acc_val: 0.7340 time: 0.1052s\n",
            "36\n",
            "Epoch: 0683 loss_train: 0.6689 acc_train: 0.8083 loss_val: 1.0477 acc_val: 0.7240 time: 0.1051s\n",
            "37\n",
            "Epoch: 0684 loss_train: 0.7034 acc_train: 0.8500 loss_val: 1.0548 acc_val: 0.7200 time: 0.1044s\n",
            "38\n",
            "Epoch: 0685 loss_train: 0.7060 acc_train: 0.8500 loss_val: 1.0579 acc_val: 0.7200 time: 0.1046s\n",
            "39\n",
            "Epoch: 0686 loss_train: 0.6641 acc_train: 0.8583 loss_val: 1.0582 acc_val: 0.7280 time: 0.1054s\n",
            "40\n",
            "Epoch: 0687 loss_train: 0.7076 acc_train: 0.8250 loss_val: 1.0552 acc_val: 0.7280 time: 0.1065s\n",
            "41\n",
            "Epoch: 0688 loss_train: 0.6720 acc_train: 0.8750 loss_val: 1.0473 acc_val: 0.7340 time: 0.1046s\n",
            "42\n",
            "Epoch: 0689 loss_train: 0.6532 acc_train: 0.8583 loss_val: 1.0404 acc_val: 0.7320 time: 0.1055s\n",
            "43\n",
            "Epoch: 0690 loss_train: 0.6713 acc_train: 0.8750 loss_val: 1.0354 acc_val: 0.7360 time: 0.1056s\n",
            "44\n",
            "Epoch: 0691 loss_train: 0.6382 acc_train: 0.8833 loss_val: 1.0342 acc_val: 0.7360 time: 0.1056s\n",
            "45\n",
            "Epoch: 0692 loss_train: 0.6623 acc_train: 0.8500 loss_val: 1.0383 acc_val: 0.7280 time: 0.1046s\n",
            "46\n",
            "Epoch: 0693 loss_train: 0.6838 acc_train: 0.8583 loss_val: 1.0475 acc_val: 0.7240 time: 0.1052s\n",
            "47\n",
            "Epoch: 0694 loss_train: 0.6594 acc_train: 0.8333 loss_val: 1.0562 acc_val: 0.7320 time: 0.1044s\n",
            "48\n",
            "Epoch: 0695 loss_train: 0.6668 acc_train: 0.8500 loss_val: 1.0645 acc_val: 0.7200 time: 0.1050s\n",
            "49\n",
            "Epoch: 0696 loss_train: 0.6874 acc_train: 0.8750 loss_val: 1.0652 acc_val: 0.7260 time: 0.1064s\n",
            "50\n",
            "Epoch: 0697 loss_train: 0.6622 acc_train: 0.8667 loss_val: 1.0617 acc_val: 0.7300 time: 0.1055s\n",
            "51\n",
            "Epoch: 0698 loss_train: 0.6895 acc_train: 0.8250 loss_val: 1.0580 acc_val: 0.7340 time: 0.1052s\n",
            "52\n",
            "Epoch: 0699 loss_train: 0.6481 acc_train: 0.8833 loss_val: 1.0512 acc_val: 0.7340 time: 0.1051s\n",
            "53\n",
            "Epoch: 0700 loss_train: 0.6587 acc_train: 0.9167 loss_val: 1.0445 acc_val: 0.7340 time: 0.1048s\n",
            "54\n",
            "Epoch: 0701 loss_train: 0.6680 acc_train: 0.8667 loss_val: 1.0432 acc_val: 0.7320 time: 0.1058s\n",
            "55\n",
            "Epoch: 0702 loss_train: 0.6863 acc_train: 0.8500 loss_val: 1.0437 acc_val: 0.7240 time: 0.1062s\n",
            "56\n",
            "Epoch: 0703 loss_train: 0.6837 acc_train: 0.8500 loss_val: 1.0446 acc_val: 0.7280 time: 0.1051s\n",
            "57\n",
            "Epoch: 0704 loss_train: 0.6431 acc_train: 0.8583 loss_val: 1.0466 acc_val: 0.7320 time: 0.1044s\n",
            "58\n",
            "Epoch: 0705 loss_train: 0.6775 acc_train: 0.8917 loss_val: 1.0555 acc_val: 0.7340 time: 0.1108s\n",
            "59\n",
            "Epoch: 0706 loss_train: 0.6437 acc_train: 0.8667 loss_val: 1.0678 acc_val: 0.7340 time: 0.1042s\n",
            "60\n",
            "Epoch: 0707 loss_train: 0.6869 acc_train: 0.7917 loss_val: 1.0700 acc_val: 0.7240 time: 0.1054s\n",
            "61\n",
            "Epoch: 0708 loss_train: 0.6711 acc_train: 0.8750 loss_val: 1.0608 acc_val: 0.7240 time: 0.1044s\n",
            "62\n",
            "Epoch: 0709 loss_train: 0.6150 acc_train: 0.8333 loss_val: 1.0516 acc_val: 0.7340 time: 0.1048s\n",
            "63\n",
            "Epoch: 0710 loss_train: 0.6759 acc_train: 0.8583 loss_val: 1.0502 acc_val: 0.7240 time: 0.1045s\n",
            "64\n",
            "Epoch: 0711 loss_train: 0.6544 acc_train: 0.9167 loss_val: 1.0512 acc_val: 0.7160 time: 0.1050s\n",
            "65\n",
            "Epoch: 0712 loss_train: 0.6688 acc_train: 0.8250 loss_val: 1.0518 acc_val: 0.7200 time: 0.1047s\n",
            "66\n",
            "Epoch: 0713 loss_train: 0.6665 acc_train: 0.8333 loss_val: 1.0509 acc_val: 0.7280 time: 0.1049s\n",
            "67\n",
            "Epoch: 0714 loss_train: 0.6501 acc_train: 0.8250 loss_val: 1.0483 acc_val: 0.7300 time: 0.1061s\n",
            "68\n",
            "Epoch: 0715 loss_train: 0.6740 acc_train: 0.8583 loss_val: 1.0480 acc_val: 0.7400 time: 0.1066s\n",
            "69\n",
            "Epoch: 0716 loss_train: 0.6846 acc_train: 0.8750 loss_val: 1.0463 acc_val: 0.7400 time: 0.1046s\n",
            "70\n",
            "Epoch: 0717 loss_train: 0.6579 acc_train: 0.8917 loss_val: 1.0492 acc_val: 0.7320 time: 0.1055s\n",
            "71\n",
            "Epoch: 0718 loss_train: 0.7017 acc_train: 0.8500 loss_val: 1.0566 acc_val: 0.7180 time: 0.1041s\n",
            "72\n",
            "Epoch: 0719 loss_train: 0.5920 acc_train: 0.8833 loss_val: 1.0583 acc_val: 0.7180 time: 0.1048s\n",
            "73\n",
            "Epoch: 0720 loss_train: 0.6792 acc_train: 0.7750 loss_val: 1.0598 acc_val: 0.7280 time: 0.1050s\n",
            "74\n",
            "Epoch: 0721 loss_train: 0.6906 acc_train: 0.7833 loss_val: 1.0569 acc_val: 0.7280 time: 0.1049s\n",
            "75\n",
            "Epoch: 0722 loss_train: 0.6831 acc_train: 0.8500 loss_val: 1.0541 acc_val: 0.7280 time: 0.1042s\n",
            "76\n",
            "Epoch: 0723 loss_train: 0.6755 acc_train: 0.8583 loss_val: 1.0497 acc_val: 0.7300 time: 0.1047s\n",
            "77\n",
            "Epoch: 0724 loss_train: 0.6715 acc_train: 0.8917 loss_val: 1.0422 acc_val: 0.7300 time: 0.1055s\n",
            "78\n",
            "Epoch: 0725 loss_train: 0.6304 acc_train: 0.8917 loss_val: 1.0398 acc_val: 0.7360 time: 0.1067s\n",
            "79\n",
            "Epoch: 0726 loss_train: 0.6375 acc_train: 0.9167 loss_val: 1.0427 acc_val: 0.7360 time: 0.1046s\n",
            "80\n",
            "Epoch: 0727 loss_train: 0.6604 acc_train: 0.8333 loss_val: 1.0465 acc_val: 0.7400 time: 0.1058s\n",
            "81\n",
            "Epoch: 0728 loss_train: 0.6428 acc_train: 0.8333 loss_val: 1.0528 acc_val: 0.7300 time: 0.1053s\n",
            "82\n",
            "Epoch: 0729 loss_train: 0.6651 acc_train: 0.8500 loss_val: 1.0575 acc_val: 0.7260 time: 0.1047s\n",
            "83\n",
            "Epoch: 0730 loss_train: 0.6847 acc_train: 0.8667 loss_val: 1.0603 acc_val: 0.7220 time: 0.1055s\n",
            "84\n",
            "Epoch: 0731 loss_train: 0.6711 acc_train: 0.8667 loss_val: 1.0591 acc_val: 0.7260 time: 0.1048s\n",
            "85\n",
            "Epoch: 0732 loss_train: 0.6429 acc_train: 0.8583 loss_val: 1.0509 acc_val: 0.7360 time: 0.1042s\n",
            "86\n",
            "Epoch: 0733 loss_train: 0.6207 acc_train: 0.8417 loss_val: 1.0453 acc_val: 0.7360 time: 0.1050s\n",
            "87\n",
            "Epoch: 0734 loss_train: 0.6890 acc_train: 0.8583 loss_val: 1.0419 acc_val: 0.7360 time: 0.1044s\n",
            "88\n",
            "Epoch: 0735 loss_train: 0.6485 acc_train: 0.8667 loss_val: 1.0393 acc_val: 0.7300 time: 0.1048s\n",
            "89\n",
            "Epoch: 0736 loss_train: 0.6856 acc_train: 0.8750 loss_val: 1.0399 acc_val: 0.7280 time: 0.1064s\n",
            "90\n",
            "Epoch: 0737 loss_train: 0.6459 acc_train: 0.8250 loss_val: 1.0404 acc_val: 0.7320 time: 0.1048s\n",
            "91\n",
            "Epoch: 0738 loss_train: 0.6970 acc_train: 0.8250 loss_val: 1.0413 acc_val: 0.7340 time: 0.1047s\n",
            "92\n",
            "Epoch: 0739 loss_train: 0.6503 acc_train: 0.8833 loss_val: 1.0405 acc_val: 0.7360 time: 0.1046s\n",
            "93\n",
            "Epoch: 0740 loss_train: 0.7065 acc_train: 0.8833 loss_val: 1.0428 acc_val: 0.7380 time: 0.1055s\n",
            "94\n",
            "Epoch: 0741 loss_train: 0.6651 acc_train: 0.8583 loss_val: 1.0412 acc_val: 0.7320 time: 0.1050s\n",
            "95\n",
            "Epoch: 0742 loss_train: 0.6650 acc_train: 0.8667 loss_val: 1.0416 acc_val: 0.7340 time: 0.1042s\n",
            "96\n",
            "Epoch: 0743 loss_train: 0.6641 acc_train: 0.8417 loss_val: 1.0407 acc_val: 0.7400 time: 0.1056s\n",
            "97\n",
            "Epoch: 0744 loss_train: 0.6213 acc_train: 0.8833 loss_val: 1.0395 acc_val: 0.7300 time: 0.1043s\n",
            "98\n",
            "Epoch: 0745 loss_train: 0.6528 acc_train: 0.8667 loss_val: 1.0387 acc_val: 0.7340 time: 0.1051s\n",
            "99\n",
            "Epoch: 0746 loss_train: 0.6549 acc_train: 0.8333 loss_val: 1.0419 acc_val: 0.7280 time: 0.1041s\n",
            "100\n",
            "Epoch: 0747 loss_train: 0.6910 acc_train: 0.8000 loss_val: 1.0447 acc_val: 0.7300 time: 0.1048s\n",
            "101\n",
            "Epoch: 0748 loss_train: 0.6403 acc_train: 0.8417 loss_val: 1.0458 acc_val: 0.7300 time: 0.1044s\n",
            "102\n",
            "Epoch: 0749 loss_train: 0.6714 acc_train: 0.8417 loss_val: 1.0477 acc_val: 0.7280 time: 0.1058s\n",
            "103\n",
            "Epoch: 0750 loss_train: 0.6733 acc_train: 0.8250 loss_val: 1.0502 acc_val: 0.7220 time: 0.1058s\n",
            "104\n",
            "Epoch: 0751 loss_train: 0.6801 acc_train: 0.8417 loss_val: 1.0454 acc_val: 0.7220 time: 0.1051s\n",
            "105\n",
            "Epoch: 0752 loss_train: 0.6880 acc_train: 0.8750 loss_val: 1.0401 acc_val: 0.7300 time: 0.1049s\n",
            "106\n",
            "Epoch: 0753 loss_train: 0.6236 acc_train: 0.9083 loss_val: 1.0364 acc_val: 0.7380 time: 0.1052s\n",
            "107\n",
            "Epoch: 0754 loss_train: 0.6233 acc_train: 0.8917 loss_val: 1.0322 acc_val: 0.7360 time: 0.1069s\n",
            "108\n",
            "Epoch: 0755 loss_train: 0.6559 acc_train: 0.9250 loss_val: 1.0294 acc_val: 0.7400 time: 0.1048s\n",
            "0\n",
            "Epoch: 0756 loss_train: 0.6443 acc_train: 0.8583 loss_val: 1.0310 acc_val: 0.7380 time: 0.1041s\n",
            "0\n",
            "Epoch: 0757 loss_train: 0.6331 acc_train: 0.8750 loss_val: 1.0380 acc_val: 0.7400 time: 0.1053s\n",
            "1\n",
            "Epoch: 0758 loss_train: 0.6311 acc_train: 0.8667 loss_val: 1.0497 acc_val: 0.7300 time: 0.1053s\n",
            "2\n",
            "Epoch: 0759 loss_train: 0.6942 acc_train: 0.8083 loss_val: 1.0600 acc_val: 0.7160 time: 0.1100s\n",
            "3\n",
            "Epoch: 0760 loss_train: 0.6627 acc_train: 0.8833 loss_val: 1.0653 acc_val: 0.7160 time: 0.1049s\n",
            "4\n",
            "Epoch: 0761 loss_train: 0.6569 acc_train: 0.8583 loss_val: 1.0596 acc_val: 0.7180 time: 0.1047s\n",
            "5\n",
            "Epoch: 0762 loss_train: 0.6320 acc_train: 0.8667 loss_val: 1.0449 acc_val: 0.7340 time: 0.1055s\n",
            "6\n",
            "Epoch: 0763 loss_train: 0.6339 acc_train: 0.8500 loss_val: 1.0346 acc_val: 0.7380 time: 0.1054s\n",
            "7\n",
            "Epoch: 0764 loss_train: 0.6632 acc_train: 0.8917 loss_val: 1.0284 acc_val: 0.7420 time: 0.1055s\n",
            "8\n",
            "Epoch: 0765 loss_train: 0.6640 acc_train: 0.8417 loss_val: 1.0296 acc_val: 0.7420 time: 0.1046s\n",
            "0\n",
            "Epoch: 0766 loss_train: 0.6575 acc_train: 0.8750 loss_val: 1.0346 acc_val: 0.7380 time: 0.1058s\n",
            "1\n",
            "Epoch: 0767 loss_train: 0.6797 acc_train: 0.8333 loss_val: 1.0437 acc_val: 0.7340 time: 0.1063s\n",
            "2\n",
            "Epoch: 0768 loss_train: 0.6205 acc_train: 0.8750 loss_val: 1.0503 acc_val: 0.7340 time: 0.1047s\n",
            "3\n",
            "Epoch: 0769 loss_train: 0.6719 acc_train: 0.8167 loss_val: 1.0529 acc_val: 0.7340 time: 0.1047s\n",
            "4\n",
            "Epoch: 0770 loss_train: 0.6422 acc_train: 0.8917 loss_val: 1.0543 acc_val: 0.7300 time: 0.1039s\n",
            "5\n",
            "Epoch: 0771 loss_train: 0.6692 acc_train: 0.8583 loss_val: 1.0494 acc_val: 0.7360 time: 0.1054s\n",
            "6\n",
            "Epoch: 0772 loss_train: 0.7010 acc_train: 0.8083 loss_val: 1.0403 acc_val: 0.7380 time: 0.1048s\n",
            "7\n",
            "Epoch: 0773 loss_train: 0.6211 acc_train: 0.8583 loss_val: 1.0355 acc_val: 0.7360 time: 0.1048s\n",
            "8\n",
            "Epoch: 0774 loss_train: 0.6620 acc_train: 0.8750 loss_val: 1.0346 acc_val: 0.7320 time: 0.1043s\n",
            "9\n",
            "Epoch: 0775 loss_train: 0.6071 acc_train: 0.8083 loss_val: 1.0382 acc_val: 0.7340 time: 0.1050s\n",
            "10\n",
            "Epoch: 0776 loss_train: 0.6607 acc_train: 0.8917 loss_val: 1.0433 acc_val: 0.7380 time: 0.1056s\n",
            "11\n",
            "Epoch: 0777 loss_train: 0.6437 acc_train: 0.8667 loss_val: 1.0517 acc_val: 0.7340 time: 0.1071s\n",
            "12\n",
            "Epoch: 0778 loss_train: 0.6574 acc_train: 0.8500 loss_val: 1.0581 acc_val: 0.7260 time: 0.1045s\n",
            "13\n",
            "Epoch: 0779 loss_train: 0.6556 acc_train: 0.8417 loss_val: 1.0621 acc_val: 0.7200 time: 0.1058s\n",
            "14\n",
            "Epoch: 0780 loss_train: 0.6891 acc_train: 0.8250 loss_val: 1.0588 acc_val: 0.7300 time: 0.1058s\n",
            "15\n",
            "Epoch: 0781 loss_train: 0.6597 acc_train: 0.8250 loss_val: 1.0529 acc_val: 0.7300 time: 0.1064s\n",
            "16\n",
            "Epoch: 0782 loss_train: 0.7167 acc_train: 0.8917 loss_val: 1.0508 acc_val: 0.7320 time: 0.1054s\n",
            "17\n",
            "Epoch: 0783 loss_train: 0.6826 acc_train: 0.8667 loss_val: 1.0471 acc_val: 0.7320 time: 0.1051s\n",
            "18\n",
            "Epoch: 0784 loss_train: 0.6570 acc_train: 0.9000 loss_val: 1.0459 acc_val: 0.7340 time: 0.1054s\n",
            "19\n",
            "Epoch: 0785 loss_train: 0.6292 acc_train: 0.8500 loss_val: 1.0472 acc_val: 0.7340 time: 0.1054s\n",
            "20\n",
            "Epoch: 0786 loss_train: 0.6678 acc_train: 0.8750 loss_val: 1.0502 acc_val: 0.7340 time: 0.1048s\n",
            "21\n",
            "Epoch: 0787 loss_train: 0.6479 acc_train: 0.8417 loss_val: 1.0537 acc_val: 0.7340 time: 0.1052s\n",
            "22\n",
            "Epoch: 0788 loss_train: 0.6803 acc_train: 0.8833 loss_val: 1.0590 acc_val: 0.7260 time: 0.1056s\n",
            "23\n",
            "Epoch: 0789 loss_train: 0.6896 acc_train: 0.8333 loss_val: 1.0603 acc_val: 0.7260 time: 0.1056s\n",
            "24\n",
            "Epoch: 0790 loss_train: 0.6603 acc_train: 0.8167 loss_val: 1.0521 acc_val: 0.7280 time: 0.1048s\n",
            "25\n",
            "Epoch: 0791 loss_train: 0.6478 acc_train: 0.8333 loss_val: 1.0437 acc_val: 0.7380 time: 0.1048s\n",
            "26\n",
            "Epoch: 0792 loss_train: 0.6759 acc_train: 0.8000 loss_val: 1.0376 acc_val: 0.7320 time: 0.1051s\n",
            "27\n",
            "Epoch: 0793 loss_train: 0.6770 acc_train: 0.8500 loss_val: 1.0371 acc_val: 0.7360 time: 0.1049s\n",
            "28\n",
            "Epoch: 0794 loss_train: 0.6285 acc_train: 0.8333 loss_val: 1.0430 acc_val: 0.7380 time: 0.1060s\n",
            "29\n",
            "Epoch: 0795 loss_train: 0.6432 acc_train: 0.9000 loss_val: 1.0499 acc_val: 0.7360 time: 0.1042s\n",
            "30\n",
            "Epoch: 0796 loss_train: 0.6418 acc_train: 0.8250 loss_val: 1.0562 acc_val: 0.7360 time: 0.1048s\n",
            "31\n",
            "Epoch: 0797 loss_train: 0.6401 acc_train: 0.8083 loss_val: 1.0612 acc_val: 0.7240 time: 0.1055s\n",
            "32\n",
            "Epoch: 0798 loss_train: 0.6493 acc_train: 0.8750 loss_val: 1.0606 acc_val: 0.7260 time: 0.1072s\n",
            "33\n",
            "Epoch: 0799 loss_train: 0.6779 acc_train: 0.8333 loss_val: 1.0494 acc_val: 0.7340 time: 0.1067s\n",
            "34\n",
            "Epoch: 0800 loss_train: 0.7328 acc_train: 0.7917 loss_val: 1.0414 acc_val: 0.7360 time: 0.1045s\n",
            "35\n",
            "Epoch: 0801 loss_train: 0.6366 acc_train: 0.8333 loss_val: 1.0356 acc_val: 0.7380 time: 0.1047s\n",
            "36\n",
            "Epoch: 0802 loss_train: 0.6702 acc_train: 0.8417 loss_val: 1.0305 acc_val: 0.7320 time: 0.1040s\n",
            "37\n",
            "Epoch: 0803 loss_train: 0.6233 acc_train: 0.8833 loss_val: 1.0324 acc_val: 0.7360 time: 0.1048s\n",
            "38\n",
            "Epoch: 0804 loss_train: 0.6587 acc_train: 0.8500 loss_val: 1.0370 acc_val: 0.7360 time: 0.1046s\n",
            "39\n",
            "Epoch: 0805 loss_train: 0.6692 acc_train: 0.8667 loss_val: 1.0418 acc_val: 0.7380 time: 0.1047s\n",
            "40\n",
            "Epoch: 0806 loss_train: 0.6211 acc_train: 0.8583 loss_val: 1.0472 acc_val: 0.7300 time: 0.1044s\n",
            "41\n",
            "Epoch: 0807 loss_train: 0.6758 acc_train: 0.9167 loss_val: 1.0556 acc_val: 0.7260 time: 0.1048s\n",
            "42\n",
            "Epoch: 0808 loss_train: 0.6965 acc_train: 0.8333 loss_val: 1.0579 acc_val: 0.7280 time: 0.1062s\n",
            "43\n",
            "Epoch: 0809 loss_train: 0.6066 acc_train: 0.8917 loss_val: 1.0539 acc_val: 0.7320 time: 0.1057s\n",
            "44\n",
            "Epoch: 0810 loss_train: 0.6845 acc_train: 0.8667 loss_val: 1.0500 acc_val: 0.7320 time: 0.1094s\n",
            "45\n",
            "Epoch: 0811 loss_train: 0.6412 acc_train: 0.8583 loss_val: 1.0454 acc_val: 0.7260 time: 0.1055s\n",
            "46\n",
            "Epoch: 0812 loss_train: 0.6399 acc_train: 0.8833 loss_val: 1.0410 acc_val: 0.7300 time: 0.1056s\n",
            "47\n",
            "Epoch: 0813 loss_train: 0.6339 acc_train: 0.8833 loss_val: 1.0388 acc_val: 0.7300 time: 0.1060s\n",
            "48\n",
            "Epoch: 0814 loss_train: 0.6560 acc_train: 0.8417 loss_val: 1.0382 acc_val: 0.7260 time: 0.1046s\n",
            "49\n",
            "Epoch: 0815 loss_train: 0.6761 acc_train: 0.8583 loss_val: 1.0401 acc_val: 0.7320 time: 0.1049s\n",
            "50\n",
            "Epoch: 0816 loss_train: 0.6327 acc_train: 0.8583 loss_val: 1.0431 acc_val: 0.7280 time: 0.1044s\n",
            "51\n",
            "Epoch: 0817 loss_train: 0.6812 acc_train: 0.8667 loss_val: 1.0435 acc_val: 0.7280 time: 0.1050s\n",
            "52\n",
            "Epoch: 0818 loss_train: 0.6903 acc_train: 0.8583 loss_val: 1.0437 acc_val: 0.7300 time: 0.1061s\n",
            "53\n",
            "Epoch: 0819 loss_train: 0.6290 acc_train: 0.9083 loss_val: 1.0429 acc_val: 0.7320 time: 0.1050s\n",
            "54\n",
            "Epoch: 0820 loss_train: 0.6530 acc_train: 0.8333 loss_val: 1.0374 acc_val: 0.7280 time: 0.1057s\n",
            "55\n",
            "Epoch: 0821 loss_train: 0.6551 acc_train: 0.8917 loss_val: 1.0361 acc_val: 0.7320 time: 0.1062s\n",
            "56\n",
            "Epoch: 0822 loss_train: 0.6518 acc_train: 0.8583 loss_val: 1.0357 acc_val: 0.7300 time: 0.1064s\n",
            "57\n",
            "Epoch: 0823 loss_train: 0.6778 acc_train: 0.8500 loss_val: 1.0379 acc_val: 0.7300 time: 0.1051s\n",
            "58\n",
            "Epoch: 0824 loss_train: 0.6483 acc_train: 0.8667 loss_val: 1.0422 acc_val: 0.7200 time: 0.1044s\n",
            "59\n",
            "Epoch: 0825 loss_train: 0.6681 acc_train: 0.8583 loss_val: 1.0529 acc_val: 0.7300 time: 0.1046s\n",
            "60\n",
            "Epoch: 0826 loss_train: 0.6254 acc_train: 0.8667 loss_val: 1.0620 acc_val: 0.7320 time: 0.1045s\n",
            "61\n",
            "Epoch: 0827 loss_train: 0.6573 acc_train: 0.9000 loss_val: 1.0640 acc_val: 0.7300 time: 0.1053s\n",
            "62\n",
            "Epoch: 0828 loss_train: 0.6731 acc_train: 0.8667 loss_val: 1.0600 acc_val: 0.7320 time: 0.1048s\n",
            "63\n",
            "Epoch: 0829 loss_train: 0.6494 acc_train: 0.8500 loss_val: 1.0510 acc_val: 0.7280 time: 0.1046s\n",
            "64\n",
            "Epoch: 0830 loss_train: 0.6584 acc_train: 0.9167 loss_val: 1.0446 acc_val: 0.7220 time: 0.1046s\n",
            "65\n",
            "Epoch: 0831 loss_train: 0.6523 acc_train: 0.8833 loss_val: 1.0401 acc_val: 0.7300 time: 0.1051s\n",
            "66\n",
            "Epoch: 0832 loss_train: 0.6623 acc_train: 0.8000 loss_val: 1.0371 acc_val: 0.7320 time: 0.1070s\n",
            "67\n",
            "Epoch: 0833 loss_train: 0.6779 acc_train: 0.8750 loss_val: 1.0355 acc_val: 0.7280 time: 0.1050s\n",
            "68\n",
            "Epoch: 0834 loss_train: 0.6435 acc_train: 0.8833 loss_val: 1.0396 acc_val: 0.7340 time: 0.1040s\n",
            "69\n",
            "Epoch: 0835 loss_train: 0.6304 acc_train: 0.9000 loss_val: 1.0444 acc_val: 0.7320 time: 0.1044s\n",
            "70\n",
            "Epoch: 0836 loss_train: 0.6591 acc_train: 0.8417 loss_val: 1.0493 acc_val: 0.7280 time: 0.1045s\n",
            "71\n",
            "Epoch: 0837 loss_train: 0.6582 acc_train: 0.8750 loss_val: 1.0532 acc_val: 0.7340 time: 0.1056s\n",
            "72\n",
            "Epoch: 0838 loss_train: 0.6481 acc_train: 0.8167 loss_val: 1.0526 acc_val: 0.7300 time: 0.1055s\n",
            "73\n",
            "Epoch: 0839 loss_train: 0.6681 acc_train: 0.8500 loss_val: 1.0468 acc_val: 0.7320 time: 0.1045s\n",
            "74\n",
            "Epoch: 0840 loss_train: 0.6382 acc_train: 0.8250 loss_val: 1.0416 acc_val: 0.7280 time: 0.1042s\n",
            "75\n",
            "Epoch: 0841 loss_train: 0.6401 acc_train: 0.8583 loss_val: 1.0342 acc_val: 0.7320 time: 0.1044s\n",
            "76\n",
            "Epoch: 0842 loss_train: 0.6634 acc_train: 0.8833 loss_val: 1.0328 acc_val: 0.7420 time: 0.1055s\n",
            "77\n",
            "Epoch: 0843 loss_train: 0.6934 acc_train: 0.8750 loss_val: 1.0326 acc_val: 0.7380 time: 0.1047s\n",
            "78\n",
            "Epoch: 0844 loss_train: 0.6672 acc_train: 0.8583 loss_val: 1.0428 acc_val: 0.7320 time: 0.1045s\n",
            "79\n",
            "Epoch: 0845 loss_train: 0.6554 acc_train: 0.8667 loss_val: 1.0526 acc_val: 0.7300 time: 0.1044s\n",
            "80\n",
            "Epoch: 0846 loss_train: 0.6250 acc_train: 0.9083 loss_val: 1.0524 acc_val: 0.7280 time: 0.1049s\n",
            "81\n",
            "Epoch: 0847 loss_train: 0.6764 acc_train: 0.8583 loss_val: 1.0491 acc_val: 0.7280 time: 0.1052s\n",
            "82\n",
            "Epoch: 0848 loss_train: 0.6856 acc_train: 0.8833 loss_val: 1.0425 acc_val: 0.7320 time: 0.1040s\n",
            "83\n",
            "Epoch: 0849 loss_train: 0.6338 acc_train: 0.8667 loss_val: 1.0380 acc_val: 0.7340 time: 0.1066s\n",
            "84\n",
            "Epoch: 0850 loss_train: 0.6530 acc_train: 0.8833 loss_val: 1.0361 acc_val: 0.7280 time: 0.1042s\n",
            "85\n",
            "Epoch: 0851 loss_train: 0.6706 acc_train: 0.8750 loss_val: 1.0367 acc_val: 0.7300 time: 0.1056s\n",
            "86\n",
            "Epoch: 0852 loss_train: 0.6603 acc_train: 0.8417 loss_val: 1.0381 acc_val: 0.7360 time: 0.1058s\n",
            "87\n",
            "Epoch: 0853 loss_train: 0.6584 acc_train: 0.9000 loss_val: 1.0383 acc_val: 0.7380 time: 0.1068s\n",
            "88\n",
            "Epoch: 0854 loss_train: 0.6073 acc_train: 0.8583 loss_val: 1.0417 acc_val: 0.7360 time: 0.1046s\n",
            "89\n",
            "Epoch: 0855 loss_train: 0.6443 acc_train: 0.8667 loss_val: 1.0436 acc_val: 0.7360 time: 0.1049s\n",
            "90\n",
            "Epoch: 0856 loss_train: 0.6566 acc_train: 0.8417 loss_val: 1.0492 acc_val: 0.7360 time: 0.1052s\n",
            "91\n",
            "Epoch: 0857 loss_train: 0.6463 acc_train: 0.8917 loss_val: 1.0531 acc_val: 0.7280 time: 0.1063s\n",
            "92\n",
            "Epoch: 0858 loss_train: 0.6230 acc_train: 0.8750 loss_val: 1.0556 acc_val: 0.7260 time: 0.1047s\n",
            "93\n",
            "Epoch: 0859 loss_train: 0.6365 acc_train: 0.8750 loss_val: 1.0507 acc_val: 0.7260 time: 0.1069s\n",
            "94\n",
            "Epoch: 0860 loss_train: 0.6562 acc_train: 0.8667 loss_val: 1.0408 acc_val: 0.7320 time: 0.1047s\n",
            "95\n",
            "Epoch: 0861 loss_train: 0.6764 acc_train: 0.8500 loss_val: 1.0331 acc_val: 0.7360 time: 0.1055s\n",
            "96\n",
            "Epoch: 0862 loss_train: 0.6374 acc_train: 0.8583 loss_val: 1.0260 acc_val: 0.7360 time: 0.1075s\n",
            "97\n",
            "Epoch: 0863 loss_train: 0.6067 acc_train: 0.8667 loss_val: 1.0253 acc_val: 0.7420 time: 0.1048s\n",
            "0\n",
            "Epoch: 0864 loss_train: 0.6106 acc_train: 0.9000 loss_val: 1.0306 acc_val: 0.7440 time: 0.1061s\n",
            "0\n",
            "Epoch: 0865 loss_train: 0.6703 acc_train: 0.8250 loss_val: 1.0422 acc_val: 0.7420 time: 0.1063s\n",
            "0\n",
            "Epoch: 0866 loss_train: 0.6580 acc_train: 0.8833 loss_val: 1.0506 acc_val: 0.7340 time: 0.1054s\n",
            "1\n",
            "Epoch: 0867 loss_train: 0.6807 acc_train: 0.8500 loss_val: 1.0513 acc_val: 0.7340 time: 0.1051s\n",
            "2\n",
            "Epoch: 0868 loss_train: 0.6703 acc_train: 0.8750 loss_val: 1.0459 acc_val: 0.7380 time: 0.1051s\n",
            "3\n",
            "Epoch: 0869 loss_train: 0.6556 acc_train: 0.8500 loss_val: 1.0425 acc_val: 0.7320 time: 0.1059s\n",
            "4\n",
            "Epoch: 0870 loss_train: 0.6589 acc_train: 0.8750 loss_val: 1.0410 acc_val: 0.7320 time: 0.1054s\n",
            "5\n",
            "Epoch: 0871 loss_train: 0.6480 acc_train: 0.8417 loss_val: 1.0406 acc_val: 0.7360 time: 0.1053s\n",
            "6\n",
            "Epoch: 0872 loss_train: 0.6627 acc_train: 0.8667 loss_val: 1.0399 acc_val: 0.7340 time: 0.1045s\n",
            "7\n",
            "Epoch: 0873 loss_train: 0.6380 acc_train: 0.8667 loss_val: 1.0474 acc_val: 0.7280 time: 0.1049s\n",
            "8\n",
            "Epoch: 0874 loss_train: 0.6574 acc_train: 0.8167 loss_val: 1.0561 acc_val: 0.7300 time: 0.1047s\n",
            "9\n",
            "Epoch: 0875 loss_train: 0.6781 acc_train: 0.8083 loss_val: 1.0558 acc_val: 0.7260 time: 0.1054s\n",
            "10\n",
            "Epoch: 0876 loss_train: 0.6769 acc_train: 0.8500 loss_val: 1.0495 acc_val: 0.7240 time: 0.1046s\n",
            "11\n",
            "Epoch: 0877 loss_train: 0.7072 acc_train: 0.8583 loss_val: 1.0406 acc_val: 0.7300 time: 0.1054s\n",
            "12\n",
            "Epoch: 0878 loss_train: 0.6608 acc_train: 0.8667 loss_val: 1.0316 acc_val: 0.7280 time: 0.1062s\n",
            "13\n",
            "Epoch: 0879 loss_train: 0.6632 acc_train: 0.8667 loss_val: 1.0271 acc_val: 0.7380 time: 0.1063s\n",
            "14\n",
            "Epoch: 0880 loss_train: 0.6990 acc_train: 0.8000 loss_val: 1.0274 acc_val: 0.7400 time: 0.1065s\n",
            "15\n",
            "Epoch: 0881 loss_train: 0.6149 acc_train: 0.8833 loss_val: 1.0338 acc_val: 0.7380 time: 0.1052s\n",
            "16\n",
            "Epoch: 0882 loss_train: 0.6247 acc_train: 0.8750 loss_val: 1.0443 acc_val: 0.7340 time: 0.1038s\n",
            "17\n",
            "Epoch: 0883 loss_train: 0.6400 acc_train: 0.7750 loss_val: 1.0565 acc_val: 0.7260 time: 0.1049s\n",
            "18\n",
            "Epoch: 0884 loss_train: 0.6473 acc_train: 0.8833 loss_val: 1.0631 acc_val: 0.7300 time: 0.1059s\n",
            "19\n",
            "Epoch: 0885 loss_train: 0.6393 acc_train: 0.8250 loss_val: 1.0597 acc_val: 0.7240 time: 0.1050s\n",
            "20\n",
            "Epoch: 0886 loss_train: 0.6644 acc_train: 0.8833 loss_val: 1.0521 acc_val: 0.7260 time: 0.1077s\n",
            "21\n",
            "Epoch: 0887 loss_train: 0.6163 acc_train: 0.8833 loss_val: 1.0436 acc_val: 0.7280 time: 0.1048s\n",
            "22\n",
            "Epoch: 0888 loss_train: 0.6789 acc_train: 0.8167 loss_val: 1.0387 acc_val: 0.7220 time: 0.1049s\n",
            "23\n",
            "Epoch: 0889 loss_train: 0.6491 acc_train: 0.8500 loss_val: 1.0324 acc_val: 0.7300 time: 0.1049s\n",
            "24\n",
            "Epoch: 0890 loss_train: 0.6513 acc_train: 0.8833 loss_val: 1.0299 acc_val: 0.7340 time: 0.1053s\n",
            "25\n",
            "Epoch: 0891 loss_train: 0.6485 acc_train: 0.8500 loss_val: 1.0353 acc_val: 0.7360 time: 0.1086s\n",
            "26\n",
            "Epoch: 0892 loss_train: 0.6729 acc_train: 0.8583 loss_val: 1.0476 acc_val: 0.7320 time: 0.1045s\n",
            "27\n",
            "Epoch: 0893 loss_train: 0.6555 acc_train: 0.8583 loss_val: 1.0593 acc_val: 0.7280 time: 0.1074s\n",
            "28\n",
            "Epoch: 0894 loss_train: 0.6879 acc_train: 0.8083 loss_val: 1.0652 acc_val: 0.7180 time: 0.1056s\n",
            "29\n",
            "Epoch: 0895 loss_train: 0.6454 acc_train: 0.8833 loss_val: 1.0585 acc_val: 0.7220 time: 0.1062s\n",
            "30\n",
            "Epoch: 0896 loss_train: 0.6761 acc_train: 0.8250 loss_val: 1.0467 acc_val: 0.7340 time: 0.1059s\n",
            "31\n",
            "Epoch: 0897 loss_train: 0.6753 acc_train: 0.8500 loss_val: 1.0389 acc_val: 0.7320 time: 0.1050s\n",
            "32\n",
            "Epoch: 0898 loss_train: 0.6942 acc_train: 0.8417 loss_val: 1.0314 acc_val: 0.7380 time: 0.1060s\n",
            "33\n",
            "Epoch: 0899 loss_train: 0.6676 acc_train: 0.8500 loss_val: 1.0301 acc_val: 0.7320 time: 0.1048s\n",
            "34\n",
            "Epoch: 0900 loss_train: 0.6207 acc_train: 0.9000 loss_val: 1.0331 acc_val: 0.7280 time: 0.1047s\n",
            "35\n",
            "Epoch: 0901 loss_train: 0.6641 acc_train: 0.8667 loss_val: 1.0424 acc_val: 0.7300 time: 0.1057s\n",
            "36\n",
            "Epoch: 0902 loss_train: 0.6759 acc_train: 0.8417 loss_val: 1.0512 acc_val: 0.7360 time: 0.1054s\n",
            "37\n",
            "Epoch: 0903 loss_train: 0.6704 acc_train: 0.8750 loss_val: 1.0549 acc_val: 0.7340 time: 0.1057s\n",
            "38\n",
            "Epoch: 0904 loss_train: 0.6522 acc_train: 0.8667 loss_val: 1.0541 acc_val: 0.7260 time: 0.1048s\n",
            "39\n",
            "Epoch: 0905 loss_train: 0.6644 acc_train: 0.8417 loss_val: 1.0469 acc_val: 0.7320 time: 0.1046s\n",
            "40\n",
            "Epoch: 0906 loss_train: 0.6638 acc_train: 0.9083 loss_val: 1.0370 acc_val: 0.7420 time: 0.1042s\n",
            "41\n",
            "Epoch: 0907 loss_train: 0.7028 acc_train: 0.8333 loss_val: 1.0313 acc_val: 0.7400 time: 0.1051s\n",
            "42\n",
            "Epoch: 0908 loss_train: 0.6461 acc_train: 0.8500 loss_val: 1.0289 acc_val: 0.7420 time: 0.1042s\n",
            "43\n",
            "Epoch: 0909 loss_train: 0.6506 acc_train: 0.8667 loss_val: 1.0306 acc_val: 0.7380 time: 0.1046s\n",
            "44\n",
            "Epoch: 0910 loss_train: 0.6757 acc_train: 0.8417 loss_val: 1.0354 acc_val: 0.7440 time: 0.1054s\n",
            "45\n",
            "Epoch: 0911 loss_train: 0.6780 acc_train: 0.8167 loss_val: 1.0445 acc_val: 0.7340 time: 0.1048s\n",
            "0\n",
            "Epoch: 0912 loss_train: 0.6475 acc_train: 0.9083 loss_val: 1.0528 acc_val: 0.7380 time: 0.1067s\n",
            "1\n",
            "Epoch: 0913 loss_train: 0.6490 acc_train: 0.8583 loss_val: 1.0581 acc_val: 0.7360 time: 0.1047s\n",
            "2\n",
            "Epoch: 0914 loss_train: 0.6581 acc_train: 0.8917 loss_val: 1.0587 acc_val: 0.7180 time: 0.1045s\n",
            "3\n",
            "Epoch: 0915 loss_train: 0.6094 acc_train: 0.8500 loss_val: 1.0516 acc_val: 0.7220 time: 0.1048s\n",
            "4\n",
            "Epoch: 0916 loss_train: 0.6624 acc_train: 0.9083 loss_val: 1.0434 acc_val: 0.7320 time: 0.1044s\n",
            "5\n",
            "Epoch: 0917 loss_train: 0.6635 acc_train: 0.8750 loss_val: 1.0367 acc_val: 0.7360 time: 0.1086s\n",
            "6\n",
            "Epoch: 0918 loss_train: 0.6552 acc_train: 0.8583 loss_val: 1.0365 acc_val: 0.7400 time: 0.1060s\n",
            "7\n",
            "Epoch: 0919 loss_train: 0.6522 acc_train: 0.8583 loss_val: 1.0407 acc_val: 0.7360 time: 0.1048s\n",
            "8\n",
            "Epoch: 0920 loss_train: 0.6374 acc_train: 0.8500 loss_val: 1.0431 acc_val: 0.7340 time: 0.1055s\n",
            "9\n",
            "Epoch: 0921 loss_train: 0.6691 acc_train: 0.8917 loss_val: 1.0473 acc_val: 0.7340 time: 0.1051s\n",
            "10\n",
            "Epoch: 0922 loss_train: 0.6453 acc_train: 0.8750 loss_val: 1.0534 acc_val: 0.7320 time: 0.1045s\n",
            "11\n",
            "Epoch: 0923 loss_train: 0.6617 acc_train: 0.8667 loss_val: 1.0610 acc_val: 0.7200 time: 0.1054s\n",
            "12\n",
            "Epoch: 0924 loss_train: 0.6009 acc_train: 0.9167 loss_val: 1.0617 acc_val: 0.7180 time: 0.1054s\n",
            "13\n",
            "Epoch: 0925 loss_train: 0.6596 acc_train: 0.8583 loss_val: 1.0574 acc_val: 0.7220 time: 0.1054s\n",
            "14\n",
            "Epoch: 0926 loss_train: 0.6672 acc_train: 0.8833 loss_val: 1.0496 acc_val: 0.7320 time: 0.1045s\n",
            "15\n",
            "Epoch: 0927 loss_train: 0.6391 acc_train: 0.8667 loss_val: 1.0448 acc_val: 0.7340 time: 0.1051s\n",
            "16\n",
            "Epoch: 0928 loss_train: 0.6662 acc_train: 0.8833 loss_val: 1.0419 acc_val: 0.7360 time: 0.1045s\n",
            "17\n",
            "Epoch: 0929 loss_train: 0.6687 acc_train: 0.8500 loss_val: 1.0400 acc_val: 0.7320 time: 0.1050s\n",
            "18\n",
            "Epoch: 0930 loss_train: 0.6847 acc_train: 0.8917 loss_val: 1.0405 acc_val: 0.7340 time: 0.1054s\n",
            "19\n",
            "Epoch: 0931 loss_train: 0.6446 acc_train: 0.8667 loss_val: 1.0445 acc_val: 0.7380 time: 0.1056s\n",
            "20\n",
            "Epoch: 0932 loss_train: 0.6416 acc_train: 0.8500 loss_val: 1.0503 acc_val: 0.7360 time: 0.1040s\n",
            "21\n",
            "Epoch: 0933 loss_train: 0.6878 acc_train: 0.8417 loss_val: 1.0495 acc_val: 0.7360 time: 0.1051s\n",
            "22\n",
            "Epoch: 0934 loss_train: 0.6766 acc_train: 0.8500 loss_val: 1.0486 acc_val: 0.7360 time: 0.1044s\n",
            "23\n",
            "Epoch: 0935 loss_train: 0.6857 acc_train: 0.8250 loss_val: 1.0401 acc_val: 0.7380 time: 0.1048s\n",
            "24\n",
            "Epoch: 0936 loss_train: 0.6493 acc_train: 0.8000 loss_val: 1.0365 acc_val: 0.7440 time: 0.1064s\n",
            "25\n",
            "Epoch: 0937 loss_train: 0.6659 acc_train: 0.8667 loss_val: 1.0386 acc_val: 0.7400 time: 0.1047s\n",
            "0\n",
            "Epoch: 0938 loss_train: 0.6572 acc_train: 0.8667 loss_val: 1.0429 acc_val: 0.7360 time: 0.1040s\n",
            "1\n",
            "Epoch: 0939 loss_train: 0.6475 acc_train: 0.8333 loss_val: 1.0472 acc_val: 0.7340 time: 0.1051s\n",
            "2\n",
            "Epoch: 0940 loss_train: 0.6746 acc_train: 0.7833 loss_val: 1.0532 acc_val: 0.7280 time: 0.1066s\n",
            "3\n",
            "Epoch: 0941 loss_train: 0.6351 acc_train: 0.8583 loss_val: 1.0543 acc_val: 0.7320 time: 0.1047s\n",
            "4\n",
            "Epoch: 0942 loss_train: 0.6413 acc_train: 0.8500 loss_val: 1.0532 acc_val: 0.7260 time: 0.1046s\n",
            "5\n",
            "Epoch: 0943 loss_train: 0.6766 acc_train: 0.8667 loss_val: 1.0457 acc_val: 0.7260 time: 0.1044s\n",
            "6\n",
            "Epoch: 0944 loss_train: 0.6591 acc_train: 0.8500 loss_val: 1.0330 acc_val: 0.7260 time: 0.1041s\n",
            "7\n",
            "Epoch: 0945 loss_train: 0.6859 acc_train: 0.7833 loss_val: 1.0274 acc_val: 0.7380 time: 0.1048s\n",
            "8\n",
            "Epoch: 0946 loss_train: 0.6540 acc_train: 0.7917 loss_val: 1.0258 acc_val: 0.7400 time: 0.1049s\n",
            "9\n",
            "Epoch: 0947 loss_train: 0.6357 acc_train: 0.8583 loss_val: 1.0276 acc_val: 0.7380 time: 0.1042s\n",
            "10\n",
            "Epoch: 0948 loss_train: 0.6618 acc_train: 0.8583 loss_val: 1.0341 acc_val: 0.7360 time: 0.1072s\n",
            "11\n",
            "Epoch: 0949 loss_train: 0.6601 acc_train: 0.8000 loss_val: 1.0434 acc_val: 0.7320 time: 0.1048s\n",
            "12\n",
            "Epoch: 0950 loss_train: 0.6298 acc_train: 0.8500 loss_val: 1.0507 acc_val: 0.7300 time: 0.1055s\n",
            "13\n",
            "Epoch: 0951 loss_train: 0.6537 acc_train: 0.8583 loss_val: 1.0594 acc_val: 0.7260 time: 0.1051s\n",
            "14\n",
            "Epoch: 0952 loss_train: 0.6766 acc_train: 0.8083 loss_val: 1.0606 acc_val: 0.7260 time: 0.1047s\n",
            "15\n",
            "Epoch: 0953 loss_train: 0.6688 acc_train: 0.8500 loss_val: 1.0531 acc_val: 0.7320 time: 0.1072s\n",
            "16\n",
            "Epoch: 0954 loss_train: 0.6375 acc_train: 0.8750 loss_val: 1.0455 acc_val: 0.7320 time: 0.1054s\n",
            "17\n",
            "Epoch: 0955 loss_train: 0.6670 acc_train: 0.7833 loss_val: 1.0367 acc_val: 0.7320 time: 0.1045s\n",
            "18\n",
            "Epoch: 0956 loss_train: 0.6550 acc_train: 0.8417 loss_val: 1.0340 acc_val: 0.7280 time: 0.1047s\n",
            "19\n",
            "Epoch: 0957 loss_train: 0.6471 acc_train: 0.8750 loss_val: 1.0347 acc_val: 0.7260 time: 0.1047s\n",
            "20\n",
            "Epoch: 0958 loss_train: 0.6779 acc_train: 0.8417 loss_val: 1.0372 acc_val: 0.7380 time: 0.1047s\n",
            "21\n",
            "Epoch: 0959 loss_train: 0.6430 acc_train: 0.9000 loss_val: 1.0439 acc_val: 0.7360 time: 0.1056s\n",
            "22\n",
            "Epoch: 0960 loss_train: 0.6729 acc_train: 0.8167 loss_val: 1.0504 acc_val: 0.7300 time: 0.1046s\n",
            "23\n",
            "Epoch: 0961 loss_train: 0.6666 acc_train: 0.8833 loss_val: 1.0509 acc_val: 0.7320 time: 0.1057s\n",
            "24\n",
            "Epoch: 0962 loss_train: 0.6634 acc_train: 0.8750 loss_val: 1.0505 acc_val: 0.7320 time: 0.1049s\n",
            "25\n",
            "Epoch: 0963 loss_train: 0.6216 acc_train: 0.8833 loss_val: 1.0505 acc_val: 0.7260 time: 0.1051s\n",
            "26\n",
            "Epoch: 0964 loss_train: 0.6531 acc_train: 0.8500 loss_val: 1.0498 acc_val: 0.7260 time: 0.1060s\n",
            "27\n",
            "Epoch: 0965 loss_train: 0.6762 acc_train: 0.8333 loss_val: 1.0456 acc_val: 0.7320 time: 0.1054s\n",
            "28\n",
            "Epoch: 0966 loss_train: 0.6677 acc_train: 0.8167 loss_val: 1.0430 acc_val: 0.7340 time: 0.1046s\n",
            "29\n",
            "Epoch: 0967 loss_train: 0.6583 acc_train: 0.8667 loss_val: 1.0428 acc_val: 0.7360 time: 0.1052s\n",
            "30\n",
            "Epoch: 0968 loss_train: 0.6869 acc_train: 0.8583 loss_val: 1.0437 acc_val: 0.7320 time: 0.1048s\n",
            "31\n",
            "Epoch: 0969 loss_train: 0.6605 acc_train: 0.9083 loss_val: 1.0446 acc_val: 0.7360 time: 0.1053s\n",
            "32\n",
            "Epoch: 0970 loss_train: 0.6713 acc_train: 0.8583 loss_val: 1.0437 acc_val: 0.7340 time: 0.1049s\n",
            "33\n",
            "Epoch: 0971 loss_train: 0.6431 acc_train: 0.8500 loss_val: 1.0467 acc_val: 0.7380 time: 0.1050s\n",
            "34\n",
            "Epoch: 0972 loss_train: 0.6303 acc_train: 0.8833 loss_val: 1.0505 acc_val: 0.7340 time: 0.1042s\n",
            "35\n",
            "Epoch: 0973 loss_train: 0.6584 acc_train: 0.8667 loss_val: 1.0534 acc_val: 0.7340 time: 0.1056s\n",
            "36\n",
            "Epoch: 0974 loss_train: 0.6285 acc_train: 0.9000 loss_val: 1.0537 acc_val: 0.7300 time: 0.1062s\n",
            "37\n",
            "Epoch: 0975 loss_train: 0.6215 acc_train: 0.8750 loss_val: 1.0492 acc_val: 0.7340 time: 0.1052s\n",
            "38\n",
            "Epoch: 0976 loss_train: 0.6193 acc_train: 0.7917 loss_val: 1.0424 acc_val: 0.7340 time: 0.1043s\n",
            "39\n",
            "Epoch: 0977 loss_train: 0.6123 acc_train: 0.8667 loss_val: 1.0404 acc_val: 0.7340 time: 0.1050s\n",
            "40\n",
            "Epoch: 0978 loss_train: 0.6236 acc_train: 0.8667 loss_val: 1.0411 acc_val: 0.7380 time: 0.1051s\n",
            "41\n",
            "Epoch: 0979 loss_train: 0.6703 acc_train: 0.9000 loss_val: 1.0456 acc_val: 0.7360 time: 0.1066s\n",
            "42\n",
            "Epoch: 0980 loss_train: 0.6700 acc_train: 0.8500 loss_val: 1.0459 acc_val: 0.7360 time: 0.1059s\n",
            "43\n",
            "Epoch: 0981 loss_train: 0.6116 acc_train: 0.8667 loss_val: 1.0489 acc_val: 0.7380 time: 0.1050s\n",
            "44\n",
            "Epoch: 0982 loss_train: 0.6460 acc_train: 0.8583 loss_val: 1.0522 acc_val: 0.7320 time: 0.1040s\n",
            "45\n",
            "Epoch: 0983 loss_train: 0.6298 acc_train: 0.8833 loss_val: 1.0539 acc_val: 0.7280 time: 0.1056s\n",
            "46\n",
            "Epoch: 0984 loss_train: 0.5836 acc_train: 0.8667 loss_val: 1.0516 acc_val: 0.7340 time: 0.1055s\n",
            "47\n",
            "Epoch: 0985 loss_train: 0.6227 acc_train: 0.8750 loss_val: 1.0461 acc_val: 0.7380 time: 0.1060s\n",
            "48\n",
            "Epoch: 0986 loss_train: 0.6669 acc_train: 0.8750 loss_val: 1.0413 acc_val: 0.7360 time: 0.1044s\n",
            "49\n",
            "Epoch: 0987 loss_train: 0.6476 acc_train: 0.8917 loss_val: 1.0414 acc_val: 0.7360 time: 0.1098s\n",
            "50\n",
            "Epoch: 0988 loss_train: 0.6677 acc_train: 0.8500 loss_val: 1.0450 acc_val: 0.7320 time: 0.1043s\n",
            "51\n",
            "Epoch: 0989 loss_train: 0.6873 acc_train: 0.8583 loss_val: 1.0521 acc_val: 0.7300 time: 0.1048s\n",
            "52\n",
            "Epoch: 0990 loss_train: 0.6756 acc_train: 0.8667 loss_val: 1.0581 acc_val: 0.7300 time: 0.1051s\n",
            "53\n",
            "Epoch: 0991 loss_train: 0.6843 acc_train: 0.8500 loss_val: 1.0586 acc_val: 0.7240 time: 0.1047s\n",
            "54\n",
            "Epoch: 0992 loss_train: 0.6843 acc_train: 0.8417 loss_val: 1.0499 acc_val: 0.7340 time: 0.1042s\n",
            "55\n",
            "Epoch: 0993 loss_train: 0.6434 acc_train: 0.8333 loss_val: 1.0388 acc_val: 0.7380 time: 0.1052s\n",
            "56\n",
            "Epoch: 0994 loss_train: 0.6899 acc_train: 0.8333 loss_val: 1.0331 acc_val: 0.7420 time: 0.1048s\n",
            "57\n",
            "Epoch: 0995 loss_train: 0.6667 acc_train: 0.8833 loss_val: 1.0324 acc_val: 0.7380 time: 0.1048s\n",
            "58\n",
            "Epoch: 0996 loss_train: 0.6814 acc_train: 0.8333 loss_val: 1.0381 acc_val: 0.7360 time: 0.1046s\n",
            "59\n",
            "Epoch: 0997 loss_train: 0.6336 acc_train: 0.8750 loss_val: 1.0453 acc_val: 0.7340 time: 0.1058s\n",
            "60\n",
            "Epoch: 0998 loss_train: 0.6580 acc_train: 0.8750 loss_val: 1.0518 acc_val: 0.7280 time: 0.1068s\n",
            "61\n",
            "Epoch: 0999 loss_train: 0.6280 acc_train: 0.8750 loss_val: 1.0562 acc_val: 0.7280 time: 0.1080s\n",
            "62\n",
            "Epoch: 1000 loss_train: 0.6506 acc_train: 0.9250 loss_val: 1.0518 acc_val: 0.7280 time: 0.1045s\n",
            "63\n",
            "Epoch: 1001 loss_train: 0.6662 acc_train: 0.8333 loss_val: 1.0477 acc_val: 0.7280 time: 0.1049s\n",
            "64\n",
            "Epoch: 1002 loss_train: 0.6579 acc_train: 0.8833 loss_val: 1.0406 acc_val: 0.7360 time: 0.1044s\n",
            "65\n",
            "Epoch: 1003 loss_train: 0.6919 acc_train: 0.9167 loss_val: 1.0375 acc_val: 0.7360 time: 0.1055s\n",
            "66\n",
            "Epoch: 1004 loss_train: 0.7191 acc_train: 0.8750 loss_val: 1.0383 acc_val: 0.7340 time: 0.1046s\n",
            "67\n",
            "Epoch: 1005 loss_train: 0.6483 acc_train: 0.8583 loss_val: 1.0424 acc_val: 0.7300 time: 0.1054s\n",
            "68\n",
            "Epoch: 1006 loss_train: 0.6448 acc_train: 0.8583 loss_val: 1.0417 acc_val: 0.7320 time: 0.1064s\n",
            "69\n",
            "Epoch: 1007 loss_train: 0.6275 acc_train: 0.8583 loss_val: 1.0458 acc_val: 0.7340 time: 0.1067s\n",
            "70\n",
            "Epoch: 1008 loss_train: 0.6727 acc_train: 0.8250 loss_val: 1.0528 acc_val: 0.7200 time: 0.1060s\n",
            "71\n",
            "Epoch: 1009 loss_train: 0.6443 acc_train: 0.8417 loss_val: 1.0548 acc_val: 0.7240 time: 0.1052s\n",
            "72\n",
            "Epoch: 1010 loss_train: 0.6720 acc_train: 0.8583 loss_val: 1.0498 acc_val: 0.7280 time: 0.1055s\n",
            "73\n",
            "Epoch: 1011 loss_train: 0.6578 acc_train: 0.8417 loss_val: 1.0415 acc_val: 0.7340 time: 0.1047s\n",
            "74\n",
            "Epoch: 1012 loss_train: 0.6560 acc_train: 0.8500 loss_val: 1.0349 acc_val: 0.7380 time: 0.1068s\n",
            "75\n",
            "Epoch: 1013 loss_train: 0.6676 acc_train: 0.8000 loss_val: 1.0334 acc_val: 0.7320 time: 0.1052s\n",
            "76\n",
            "Epoch: 1014 loss_train: 0.6701 acc_train: 0.8583 loss_val: 1.0336 acc_val: 0.7340 time: 0.1046s\n",
            "77\n",
            "Epoch: 1015 loss_train: 0.6782 acc_train: 0.8500 loss_val: 1.0372 acc_val: 0.7360 time: 0.1050s\n",
            "78\n",
            "Epoch: 1016 loss_train: 0.6452 acc_train: 0.8000 loss_val: 1.0456 acc_val: 0.7320 time: 0.1050s\n",
            "79\n",
            "Epoch: 1017 loss_train: 0.6849 acc_train: 0.8667 loss_val: 1.0566 acc_val: 0.7240 time: 0.1050s\n",
            "80\n",
            "Epoch: 1018 loss_train: 0.6639 acc_train: 0.8167 loss_val: 1.0599 acc_val: 0.7280 time: 0.1048s\n",
            "81\n",
            "Epoch: 1019 loss_train: 0.6522 acc_train: 0.8500 loss_val: 1.0551 acc_val: 0.7240 time: 0.1050s\n",
            "82\n",
            "Epoch: 1020 loss_train: 0.6967 acc_train: 0.7917 loss_val: 1.0434 acc_val: 0.7300 time: 0.1067s\n",
            "83\n",
            "Epoch: 1021 loss_train: 0.6875 acc_train: 0.8417 loss_val: 1.0323 acc_val: 0.7300 time: 0.1047s\n",
            "84\n",
            "Epoch: 1022 loss_train: 0.6544 acc_train: 0.9167 loss_val: 1.0294 acc_val: 0.7340 time: 0.1044s\n",
            "85\n",
            "Epoch: 1023 loss_train: 0.6539 acc_train: 0.7833 loss_val: 1.0324 acc_val: 0.7380 time: 0.1051s\n",
            "86\n",
            "Epoch: 1024 loss_train: 0.7035 acc_train: 0.8333 loss_val: 1.0405 acc_val: 0.7340 time: 0.1045s\n",
            "87\n",
            "Epoch: 1025 loss_train: 0.6833 acc_train: 0.8333 loss_val: 1.0504 acc_val: 0.7240 time: 0.1067s\n",
            "88\n",
            "Epoch: 1026 loss_train: 0.6681 acc_train: 0.8167 loss_val: 1.0576 acc_val: 0.7220 time: 0.1045s\n",
            "89\n",
            "Epoch: 1027 loss_train: 0.6413 acc_train: 0.8250 loss_val: 1.0598 acc_val: 0.7180 time: 0.1054s\n",
            "90\n",
            "Epoch: 1028 loss_train: 0.7222 acc_train: 0.7750 loss_val: 1.0591 acc_val: 0.7240 time: 0.1052s\n",
            "91\n",
            "Epoch: 1029 loss_train: 0.6711 acc_train: 0.8667 loss_val: 1.0514 acc_val: 0.7260 time: 0.1048s\n",
            "92\n",
            "Epoch: 1030 loss_train: 0.6552 acc_train: 0.8917 loss_val: 1.0409 acc_val: 0.7360 time: 0.1069s\n",
            "93\n",
            "Epoch: 1031 loss_train: 0.6646 acc_train: 0.8333 loss_val: 1.0346 acc_val: 0.7260 time: 0.1047s\n",
            "94\n",
            "Epoch: 1032 loss_train: 0.6669 acc_train: 0.8583 loss_val: 1.0335 acc_val: 0.7280 time: 0.1059s\n",
            "95\n",
            "Epoch: 1033 loss_train: 0.6819 acc_train: 0.8667 loss_val: 1.0354 acc_val: 0.7320 time: 0.1084s\n",
            "96\n",
            "Epoch: 1034 loss_train: 0.6337 acc_train: 0.8500 loss_val: 1.0436 acc_val: 0.7360 time: 0.1057s\n",
            "97\n",
            "Epoch: 1035 loss_train: 0.6459 acc_train: 0.8583 loss_val: 1.0503 acc_val: 0.7320 time: 0.1049s\n",
            "98\n",
            "Epoch: 1036 loss_train: 0.6501 acc_train: 0.8167 loss_val: 1.0564 acc_val: 0.7300 time: 0.1044s\n",
            "99\n",
            "Epoch: 1037 loss_train: 0.6350 acc_train: 0.8833 loss_val: 1.0555 acc_val: 0.7300 time: 0.1049s\n",
            "100\n",
            "Epoch: 1038 loss_train: 0.6519 acc_train: 0.9000 loss_val: 1.0477 acc_val: 0.7340 time: 0.1056s\n",
            "101\n",
            "Epoch: 1039 loss_train: 0.6973 acc_train: 0.8500 loss_val: 1.0411 acc_val: 0.7340 time: 0.1067s\n",
            "102\n",
            "Epoch: 1040 loss_train: 0.6511 acc_train: 0.9000 loss_val: 1.0393 acc_val: 0.7360 time: 0.1049s\n",
            "103\n",
            "Epoch: 1041 loss_train: 0.6624 acc_train: 0.8333 loss_val: 1.0399 acc_val: 0.7360 time: 0.1049s\n",
            "104\n",
            "Epoch: 1042 loss_train: 0.6461 acc_train: 0.8333 loss_val: 1.0451 acc_val: 0.7400 time: 0.1045s\n",
            "105\n",
            "Epoch: 1043 loss_train: 0.6449 acc_train: 0.8667 loss_val: 1.0527 acc_val: 0.7340 time: 0.1046s\n",
            "106\n",
            "Epoch: 1044 loss_train: 0.6398 acc_train: 0.8750 loss_val: 1.0562 acc_val: 0.7260 time: 0.1056s\n",
            "107\n",
            "Epoch: 1045 loss_train: 0.6543 acc_train: 0.8417 loss_val: 1.0554 acc_val: 0.7220 time: 0.1053s\n",
            "108\n",
            "Epoch: 1046 loss_train: 0.6775 acc_train: 0.8250 loss_val: 1.0481 acc_val: 0.7320 time: 0.1055s\n",
            "109\n",
            "Epoch: 1047 loss_train: 0.6735 acc_train: 0.8667 loss_val: 1.0393 acc_val: 0.7320 time: 0.1047s\n",
            "110\n",
            "Epoch: 1048 loss_train: 0.6522 acc_train: 0.8750 loss_val: 1.0344 acc_val: 0.7360 time: 0.1041s\n",
            "111\n",
            "Epoch: 1049 loss_train: 0.6562 acc_train: 0.8083 loss_val: 1.0336 acc_val: 0.7360 time: 0.1049s\n",
            "112\n",
            "Epoch: 1050 loss_train: 0.6267 acc_train: 0.8333 loss_val: 1.0372 acc_val: 0.7380 time: 0.1057s\n",
            "113\n",
            "Epoch: 1051 loss_train: 0.6336 acc_train: 0.9000 loss_val: 1.0471 acc_val: 0.7340 time: 0.1054s\n",
            "114\n",
            "Epoch: 1052 loss_train: 0.6299 acc_train: 0.8583 loss_val: 1.0554 acc_val: 0.7240 time: 0.1043s\n",
            "115\n",
            "Epoch: 1053 loss_train: 0.6310 acc_train: 0.8750 loss_val: 1.0635 acc_val: 0.7240 time: 0.1051s\n",
            "116\n",
            "Epoch: 1054 loss_train: 0.6636 acc_train: 0.8750 loss_val: 1.0627 acc_val: 0.7280 time: 0.1078s\n",
            "117\n",
            "Epoch: 1055 loss_train: 0.6552 acc_train: 0.8417 loss_val: 1.0493 acc_val: 0.7340 time: 0.1048s\n",
            "118\n",
            "Epoch: 1056 loss_train: 0.6189 acc_train: 0.8667 loss_val: 1.0376 acc_val: 0.7380 time: 0.1049s\n",
            "119\n",
            "Epoch: 1057 loss_train: 0.6556 acc_train: 0.8833 loss_val: 1.0310 acc_val: 0.7380 time: 0.1046s\n",
            "120\n",
            "Epoch: 1058 loss_train: 0.6804 acc_train: 0.8417 loss_val: 1.0313 acc_val: 0.7400 time: 0.1045s\n",
            "121\n",
            "Epoch: 1059 loss_train: 0.6154 acc_train: 0.8917 loss_val: 1.0360 acc_val: 0.7360 time: 0.1067s\n",
            "122\n",
            "Epoch: 1060 loss_train: 0.6632 acc_train: 0.8417 loss_val: 1.0446 acc_val: 0.7380 time: 0.1054s\n",
            "123\n",
            "Epoch: 1061 loss_train: 0.6640 acc_train: 0.8083 loss_val: 1.0526 acc_val: 0.7240 time: 0.1057s\n",
            "124\n",
            "Epoch: 1062 loss_train: 0.6820 acc_train: 0.8250 loss_val: 1.0557 acc_val: 0.7260 time: 0.1059s\n",
            "125\n",
            "Epoch: 1063 loss_train: 0.6529 acc_train: 0.8583 loss_val: 1.0530 acc_val: 0.7280 time: 0.1070s\n",
            "126\n",
            "Epoch: 1064 loss_train: 0.6314 acc_train: 0.8750 loss_val: 1.0461 acc_val: 0.7300 time: 0.1041s\n",
            "127\n",
            "Epoch: 1065 loss_train: 0.6142 acc_train: 0.8583 loss_val: 1.0393 acc_val: 0.7300 time: 0.1047s\n",
            "128\n",
            "Epoch: 1066 loss_train: 0.6196 acc_train: 0.9083 loss_val: 1.0354 acc_val: 0.7300 time: 0.1061s\n",
            "129\n",
            "Epoch: 1067 loss_train: 0.6715 acc_train: 0.8750 loss_val: 1.0372 acc_val: 0.7300 time: 0.1048s\n",
            "130\n",
            "Epoch: 1068 loss_train: 0.6945 acc_train: 0.8667 loss_val: 1.0457 acc_val: 0.7300 time: 0.1044s\n",
            "131\n",
            "Epoch: 1069 loss_train: 0.6303 acc_train: 0.8500 loss_val: 1.0562 acc_val: 0.7260 time: 0.1047s\n",
            "132\n",
            "Epoch: 1070 loss_train: 0.6290 acc_train: 0.9083 loss_val: 1.0608 acc_val: 0.7260 time: 0.1043s\n",
            "133\n",
            "Epoch: 1071 loss_train: 0.6945 acc_train: 0.8083 loss_val: 1.0585 acc_val: 0.7260 time: 0.1046s\n",
            "134\n",
            "Epoch: 1072 loss_train: 0.6397 acc_train: 0.8833 loss_val: 1.0465 acc_val: 0.7340 time: 0.1056s\n",
            "135\n",
            "Epoch: 1073 loss_train: 0.6464 acc_train: 0.8750 loss_val: 1.0377 acc_val: 0.7320 time: 0.1052s\n",
            "136\n",
            "Epoch: 1074 loss_train: 0.6454 acc_train: 0.8750 loss_val: 1.0331 acc_val: 0.7320 time: 0.1053s\n",
            "137\n",
            "Epoch: 1075 loss_train: 0.6520 acc_train: 0.8417 loss_val: 1.0329 acc_val: 0.7320 time: 0.1049s\n",
            "138\n",
            "Epoch: 1076 loss_train: 0.6630 acc_train: 0.8333 loss_val: 1.0372 acc_val: 0.7320 time: 0.1042s\n",
            "139\n",
            "Epoch: 1077 loss_train: 0.6981 acc_train: 0.8833 loss_val: 1.0446 acc_val: 0.7320 time: 0.1048s\n",
            "140\n",
            "Epoch: 1078 loss_train: 0.6824 acc_train: 0.8083 loss_val: 1.0535 acc_val: 0.7300 time: 0.1045s\n",
            "141\n",
            "Epoch: 1079 loss_train: 0.6732 acc_train: 0.8167 loss_val: 1.0539 acc_val: 0.7280 time: 0.1048s\n",
            "142\n",
            "Epoch: 1080 loss_train: 0.6043 acc_train: 0.8917 loss_val: 1.0470 acc_val: 0.7300 time: 0.1045s\n",
            "143\n",
            "Epoch: 1081 loss_train: 0.6939 acc_train: 0.8500 loss_val: 1.0405 acc_val: 0.7340 time: 0.1050s\n",
            "144\n",
            "Epoch: 1082 loss_train: 0.6763 acc_train: 0.8250 loss_val: 1.0346 acc_val: 0.7340 time: 0.1045s\n",
            "145\n",
            "Epoch: 1083 loss_train: 0.6671 acc_train: 0.8833 loss_val: 1.0328 acc_val: 0.7300 time: 0.1069s\n",
            "146\n",
            "Epoch: 1084 loss_train: 0.6567 acc_train: 0.8667 loss_val: 1.0397 acc_val: 0.7320 time: 0.1060s\n",
            "147\n",
            "Epoch: 1085 loss_train: 0.6914 acc_train: 0.8250 loss_val: 1.0480 acc_val: 0.7340 time: 0.1056s\n",
            "148\n",
            "Epoch: 1086 loss_train: 0.6105 acc_train: 0.9000 loss_val: 1.0591 acc_val: 0.7320 time: 0.1043s\n",
            "149\n",
            "Epoch: 1087 loss_train: 0.6308 acc_train: 0.8083 loss_val: 1.0661 acc_val: 0.7180 time: 0.1049s\n",
            "150\n",
            "Epoch: 1088 loss_train: 0.6651 acc_train: 0.8583 loss_val: 1.0655 acc_val: 0.7260 time: 0.1047s\n",
            "151\n",
            "Epoch: 1089 loss_train: 0.6735 acc_train: 0.8167 loss_val: 1.0588 acc_val: 0.7280 time: 0.1052s\n",
            "152\n",
            "Epoch: 1090 loss_train: 0.6736 acc_train: 0.8833 loss_val: 1.0486 acc_val: 0.7360 time: 0.1044s\n",
            "153\n",
            "Epoch: 1091 loss_train: 0.6566 acc_train: 0.8833 loss_val: 1.0390 acc_val: 0.7360 time: 0.1057s\n",
            "154\n",
            "Epoch: 1092 loss_train: 0.6820 acc_train: 0.8667 loss_val: 1.0342 acc_val: 0.7360 time: 0.1057s\n",
            "155\n",
            "Epoch: 1093 loss_train: 0.6559 acc_train: 0.8750 loss_val: 1.0339 acc_val: 0.7360 time: 0.1053s\n",
            "156\n",
            "Epoch: 1094 loss_train: 0.6487 acc_train: 0.8250 loss_val: 1.0352 acc_val: 0.7340 time: 0.1042s\n",
            "157\n",
            "Epoch: 1095 loss_train: 0.6483 acc_train: 0.8583 loss_val: 1.0408 acc_val: 0.7360 time: 0.1046s\n",
            "158\n",
            "Epoch: 1096 loss_train: 0.6396 acc_train: 0.8917 loss_val: 1.0470 acc_val: 0.7300 time: 0.1042s\n",
            "159\n",
            "Epoch: 1097 loss_train: 0.6818 acc_train: 0.8167 loss_val: 1.0525 acc_val: 0.7300 time: 0.1047s\n",
            "160\n",
            "Epoch: 1098 loss_train: 0.6323 acc_train: 0.8750 loss_val: 1.0571 acc_val: 0.7280 time: 0.1058s\n",
            "161\n",
            "Epoch: 1099 loss_train: 0.6840 acc_train: 0.8250 loss_val: 1.0538 acc_val: 0.7320 time: 0.1047s\n",
            "162\n",
            "Epoch: 1100 loss_train: 0.6557 acc_train: 0.8000 loss_val: 1.0451 acc_val: 0.7340 time: 0.1060s\n",
            "163\n",
            "Epoch: 1101 loss_train: 0.6686 acc_train: 0.8750 loss_val: 1.0373 acc_val: 0.7380 time: 0.1053s\n",
            "164\n",
            "Epoch: 1102 loss_train: 0.6437 acc_train: 0.8167 loss_val: 1.0347 acc_val: 0.7380 time: 0.1047s\n",
            "165\n",
            "Epoch: 1103 loss_train: 0.6416 acc_train: 0.8833 loss_val: 1.0355 acc_val: 0.7420 time: 0.1048s\n",
            "166\n",
            "Epoch: 1104 loss_train: 0.6466 acc_train: 0.8833 loss_val: 1.0417 acc_val: 0.7360 time: 0.1041s\n",
            "167\n",
            "Epoch: 1105 loss_train: 0.6436 acc_train: 0.8583 loss_val: 1.0485 acc_val: 0.7340 time: 0.1048s\n",
            "168\n",
            "Epoch: 1106 loss_train: 0.6526 acc_train: 0.9000 loss_val: 1.0537 acc_val: 0.7300 time: 0.1052s\n",
            "169\n",
            "Epoch: 1107 loss_train: 0.6184 acc_train: 0.8250 loss_val: 1.0577 acc_val: 0.7280 time: 0.1049s\n",
            "170\n",
            "Epoch: 1108 loss_train: 0.6447 acc_train: 0.8167 loss_val: 1.0541 acc_val: 0.7280 time: 0.1043s\n",
            "171\n",
            "Epoch: 1109 loss_train: 0.6447 acc_train: 0.8833 loss_val: 1.0445 acc_val: 0.7320 time: 0.1053s\n",
            "172\n",
            "Epoch: 1110 loss_train: 0.6448 acc_train: 0.8500 loss_val: 1.0361 acc_val: 0.7320 time: 0.1071s\n",
            "173\n",
            "Epoch: 1111 loss_train: 0.6181 acc_train: 0.8917 loss_val: 1.0322 acc_val: 0.7280 time: 0.1050s\n",
            "174\n",
            "Epoch: 1112 loss_train: 0.6587 acc_train: 0.8250 loss_val: 1.0310 acc_val: 0.7400 time: 0.1043s\n",
            "175\n",
            "Epoch: 1113 loss_train: 0.6182 acc_train: 0.8833 loss_val: 1.0343 acc_val: 0.7340 time: 0.1063s\n",
            "176\n",
            "Epoch: 1114 loss_train: 0.6326 acc_train: 0.8833 loss_val: 1.0410 acc_val: 0.7360 time: 0.1049s\n",
            "177\n",
            "Epoch: 1115 loss_train: 0.6508 acc_train: 0.8333 loss_val: 1.0476 acc_val: 0.7380 time: 0.1064s\n",
            "178\n",
            "Epoch: 1116 loss_train: 0.6137 acc_train: 0.8500 loss_val: 1.0500 acc_val: 0.7300 time: 0.1069s\n",
            "179\n",
            "Epoch: 1117 loss_train: 0.6384 acc_train: 0.8417 loss_val: 1.0485 acc_val: 0.7320 time: 0.1048s\n",
            "180\n",
            "Epoch: 1118 loss_train: 0.6469 acc_train: 0.8917 loss_val: 1.0437 acc_val: 0.7340 time: 0.1064s\n",
            "181\n",
            "Epoch: 1119 loss_train: 0.6167 acc_train: 0.8917 loss_val: 1.0379 acc_val: 0.7360 time: 0.1057s\n",
            "182\n",
            "Epoch: 1120 loss_train: 0.6776 acc_train: 0.8917 loss_val: 1.0337 acc_val: 0.7380 time: 0.1042s\n",
            "183\n",
            "Epoch: 1121 loss_train: 0.6575 acc_train: 0.9000 loss_val: 1.0315 acc_val: 0.7360 time: 0.1048s\n",
            "184\n",
            "Epoch: 1122 loss_train: 0.6832 acc_train: 0.8833 loss_val: 1.0348 acc_val: 0.7320 time: 0.1061s\n",
            "185\n",
            "Epoch: 1123 loss_train: 0.6305 acc_train: 0.8750 loss_val: 1.0386 acc_val: 0.7340 time: 0.1048s\n",
            "186\n",
            "Epoch: 1124 loss_train: 0.6371 acc_train: 0.8500 loss_val: 1.0458 acc_val: 0.7360 time: 0.1044s\n",
            "187\n",
            "Epoch: 1125 loss_train: 0.6383 acc_train: 0.8083 loss_val: 1.0533 acc_val: 0.7360 time: 0.1086s\n",
            "188\n",
            "Epoch: 1126 loss_train: 0.6486 acc_train: 0.8500 loss_val: 1.0574 acc_val: 0.7360 time: 0.1049s\n",
            "189\n",
            "Epoch: 1127 loss_train: 0.6675 acc_train: 0.8583 loss_val: 1.0550 acc_val: 0.7320 time: 0.1045s\n",
            "190\n",
            "Epoch: 1128 loss_train: 0.6224 acc_train: 0.8667 loss_val: 1.0469 acc_val: 0.7360 time: 0.1045s\n",
            "191\n",
            "Epoch: 1129 loss_train: 0.6820 acc_train: 0.8333 loss_val: 1.0421 acc_val: 0.7300 time: 0.1050s\n",
            "192\n",
            "Epoch: 1130 loss_train: 0.6300 acc_train: 0.8833 loss_val: 1.0419 acc_val: 0.7340 time: 0.1065s\n",
            "193\n",
            "Epoch: 1131 loss_train: 0.6570 acc_train: 0.8750 loss_val: 1.0422 acc_val: 0.7380 time: 0.1055s\n",
            "194\n",
            "Epoch: 1132 loss_train: 0.6528 acc_train: 0.8500 loss_val: 1.0434 acc_val: 0.7380 time: 0.1054s\n",
            "195\n",
            "Epoch: 1133 loss_train: 0.6603 acc_train: 0.8417 loss_val: 1.0456 acc_val: 0.7400 time: 0.1048s\n",
            "196\n",
            "Epoch: 1134 loss_train: 0.6904 acc_train: 0.8417 loss_val: 1.0508 acc_val: 0.7380 time: 0.1047s\n",
            "197\n",
            "Epoch: 1135 loss_train: 0.6242 acc_train: 0.8667 loss_val: 1.0571 acc_val: 0.7340 time: 0.1059s\n",
            "198\n",
            "Epoch: 1136 loss_train: 0.6680 acc_train: 0.7917 loss_val: 1.0629 acc_val: 0.7280 time: 0.1043s\n",
            "199\n",
            "Early stop! Min loss:  1.0252892971038818 , Max accuracy:  0.744\n",
            "Early stop model validation loss:  1.0252892971038818 , accuracy:  0.742\n",
            "Optimization Finished!\n",
            "Total time elapsed: 122.8429s\n",
            "Loading 862th epoch\n",
            "Test set results: loss= 1.0022 accuracy= 0.7280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7280, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDCbF0-9jWxS",
        "outputId": "09de3517-bd2e-497e-e1bf-31d3a9e83fd4"
      },
      "source": [
        "Train(sample=1) #cora\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.0569 acc_train: 0.1286 loss_val: 2.0273 acc_val: 0.1140 time: 0.0243s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.0349 acc_train: 0.1643 loss_val: 2.0226 acc_val: 0.1140 time: 0.0192s\n",
            "0\n",
            "Epoch: 0003 loss_train: 2.0368 acc_train: 0.1357 loss_val: 2.0177 acc_val: 0.1140 time: 0.0188s\n",
            "0\n",
            "Epoch: 0004 loss_train: 2.0259 acc_train: 0.1214 loss_val: 2.0129 acc_val: 0.1140 time: 0.0190s\n",
            "0\n",
            "Epoch: 0005 loss_train: 2.0179 acc_train: 0.1429 loss_val: 2.0080 acc_val: 0.1140 time: 0.0192s\n",
            "0\n",
            "Epoch: 0006 loss_train: 2.0131 acc_train: 0.1571 loss_val: 2.0031 acc_val: 0.1140 time: 0.0212s\n",
            "0\n",
            "Epoch: 0007 loss_train: 2.0170 acc_train: 0.1429 loss_val: 1.9983 acc_val: 0.1140 time: 0.0204s\n",
            "0\n",
            "Epoch: 0008 loss_train: 2.0085 acc_train: 0.1429 loss_val: 1.9934 acc_val: 0.1140 time: 0.0183s\n",
            "0\n",
            "Epoch: 0009 loss_train: 2.0003 acc_train: 0.1429 loss_val: 1.9886 acc_val: 0.1140 time: 0.0183s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.9983 acc_train: 0.1429 loss_val: 1.9837 acc_val: 0.1140 time: 0.0193s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.9925 acc_train: 0.1357 loss_val: 1.9792 acc_val: 0.1140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.9805 acc_train: 0.1429 loss_val: 1.9748 acc_val: 0.1140 time: 0.0184s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.9834 acc_train: 0.1643 loss_val: 1.9707 acc_val: 0.1140 time: 0.0180s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.9813 acc_train: 0.1500 loss_val: 1.9671 acc_val: 0.1140 time: 0.0183s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.9747 acc_train: 0.1357 loss_val: 1.9638 acc_val: 0.1140 time: 0.0182s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.9661 acc_train: 0.1500 loss_val: 1.9603 acc_val: 0.1140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.9650 acc_train: 0.1286 loss_val: 1.9569 acc_val: 0.1140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.9627 acc_train: 0.1357 loss_val: 1.9537 acc_val: 0.1140 time: 0.0199s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.9580 acc_train: 0.1500 loss_val: 1.9501 acc_val: 0.1140 time: 0.0185s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.9568 acc_train: 0.1571 loss_val: 1.9465 acc_val: 0.1140 time: 0.0238s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.9506 acc_train: 0.1643 loss_val: 1.9424 acc_val: 0.1140 time: 0.0183s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.9440 acc_train: 0.1929 loss_val: 1.9393 acc_val: 0.1140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.9476 acc_train: 0.1714 loss_val: 1.9364 acc_val: 0.1140 time: 0.0180s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.9413 acc_train: 0.1786 loss_val: 1.9339 acc_val: 0.1340 time: 0.0202s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.9377 acc_train: 0.1571 loss_val: 1.9318 acc_val: 0.1900 time: 0.0181s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.9304 acc_train: 0.2071 loss_val: 1.9300 acc_val: 0.1740 time: 0.0181s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.9376 acc_train: 0.1214 loss_val: 1.9281 acc_val: 0.1720 time: 0.0181s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.9449 acc_train: 0.1929 loss_val: 1.9270 acc_val: 0.2220 time: 0.0193s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.9128 acc_train: 0.2286 loss_val: 1.9247 acc_val: 0.3560 time: 0.0183s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.9306 acc_train: 0.2214 loss_val: 1.9228 acc_val: 0.3840 time: 0.0180s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.9453 acc_train: 0.1214 loss_val: 1.9212 acc_val: 0.4200 time: 0.0180s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.9248 acc_train: 0.1929 loss_val: 1.9190 acc_val: 0.4780 time: 0.0180s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.9257 acc_train: 0.2429 loss_val: 1.9168 acc_val: 0.5420 time: 0.0181s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.9100 acc_train: 0.2429 loss_val: 1.9152 acc_val: 0.5260 time: 0.0179s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.9044 acc_train: 0.2357 loss_val: 1.9135 acc_val: 0.4720 time: 0.0185s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.9180 acc_train: 0.1786 loss_val: 1.9120 acc_val: 0.3960 time: 0.0182s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.9314 acc_train: 0.1429 loss_val: 1.9103 acc_val: 0.3600 time: 0.0185s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.9018 acc_train: 0.2857 loss_val: 1.9089 acc_val: 0.3200 time: 0.0192s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.8960 acc_train: 0.1714 loss_val: 1.9078 acc_val: 0.2460 time: 0.0182s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.9225 acc_train: 0.2071 loss_val: 1.9055 acc_val: 0.2320 time: 0.0180s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.9250 acc_train: 0.1929 loss_val: 1.9024 acc_val: 0.2540 time: 0.0181s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.9115 acc_train: 0.2071 loss_val: 1.8993 acc_val: 0.2940 time: 0.0182s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.9141 acc_train: 0.1929 loss_val: 1.8980 acc_val: 0.3360 time: 0.0186s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.8909 acc_train: 0.2357 loss_val: 1.8954 acc_val: 0.4100 time: 0.0181s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.8904 acc_train: 0.2214 loss_val: 1.8924 acc_val: 0.5020 time: 0.0181s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.9007 acc_train: 0.2286 loss_val: 1.8888 acc_val: 0.5660 time: 0.0180s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.9176 acc_train: 0.2214 loss_val: 1.8869 acc_val: 0.6200 time: 0.0191s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.8996 acc_train: 0.2357 loss_val: 1.8845 acc_val: 0.6580 time: 0.0180s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.8668 acc_train: 0.3786 loss_val: 1.8818 acc_val: 0.6620 time: 0.0181s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.8963 acc_train: 0.2500 loss_val: 1.8802 acc_val: 0.6820 time: 0.0180s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.8610 acc_train: 0.2929 loss_val: 1.8786 acc_val: 0.6660 time: 0.0180s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.8590 acc_train: 0.3214 loss_val: 1.8770 acc_val: 0.6440 time: 0.0183s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.8698 acc_train: 0.2857 loss_val: 1.8752 acc_val: 0.6460 time: 0.0180s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.8681 acc_train: 0.3000 loss_val: 1.8738 acc_val: 0.6580 time: 0.0181s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.8441 acc_train: 0.3429 loss_val: 1.8723 acc_val: 0.6740 time: 0.0180s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.8477 acc_train: 0.3857 loss_val: 1.8706 acc_val: 0.6600 time: 0.0193s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.8389 acc_train: 0.3643 loss_val: 1.8689 acc_val: 0.6520 time: 0.0207s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.8275 acc_train: 0.4214 loss_val: 1.8676 acc_val: 0.6300 time: 0.0186s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.8363 acc_train: 0.3357 loss_val: 1.8655 acc_val: 0.6080 time: 0.0183s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.8191 acc_train: 0.3714 loss_val: 1.8620 acc_val: 0.6260 time: 0.0183s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.8379 acc_train: 0.4000 loss_val: 1.8584 acc_val: 0.6560 time: 0.0182s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.8478 acc_train: 0.3786 loss_val: 1.8550 acc_val: 0.6560 time: 0.0202s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.8254 acc_train: 0.4286 loss_val: 1.8508 acc_val: 0.6660 time: 0.0181s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.8103 acc_train: 0.3786 loss_val: 1.8474 acc_val: 0.6380 time: 0.0180s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.7978 acc_train: 0.4071 loss_val: 1.8448 acc_val: 0.6140 time: 0.0215s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.8097 acc_train: 0.4143 loss_val: 1.8415 acc_val: 0.6000 time: 0.0181s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.7960 acc_train: 0.3929 loss_val: 1.8386 acc_val: 0.5820 time: 0.0180s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.7578 acc_train: 0.4500 loss_val: 1.8341 acc_val: 0.5800 time: 0.0183s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.7874 acc_train: 0.4071 loss_val: 1.8288 acc_val: 0.5760 time: 0.0182s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.7708 acc_train: 0.4143 loss_val: 1.8232 acc_val: 0.5760 time: 0.0181s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.7616 acc_train: 0.4143 loss_val: 1.8156 acc_val: 0.6220 time: 0.0181s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.7656 acc_train: 0.4071 loss_val: 1.8091 acc_val: 0.6520 time: 0.0181s\n",
            "0\n",
            "Epoch: 0073 loss_train: 1.7359 acc_train: 0.4143 loss_val: 1.8017 acc_val: 0.6780 time: 0.0181s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.7390 acc_train: 0.4214 loss_val: 1.7939 acc_val: 0.7060 time: 0.0180s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.7488 acc_train: 0.4500 loss_val: 1.7874 acc_val: 0.7220 time: 0.0180s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.7339 acc_train: 0.4143 loss_val: 1.7820 acc_val: 0.7160 time: 0.0180s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.7257 acc_train: 0.4000 loss_val: 1.7770 acc_val: 0.7180 time: 0.0189s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.7854 acc_train: 0.3857 loss_val: 1.7733 acc_val: 0.7240 time: 0.0183s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.7121 acc_train: 0.4857 loss_val: 1.7694 acc_val: 0.7240 time: 0.0181s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.6635 acc_train: 0.5000 loss_val: 1.7637 acc_val: 0.7220 time: 0.0184s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.7106 acc_train: 0.3929 loss_val: 1.7586 acc_val: 0.7200 time: 0.0187s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.6817 acc_train: 0.4857 loss_val: 1.7539 acc_val: 0.7320 time: 0.0191s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.7164 acc_train: 0.4429 loss_val: 1.7507 acc_val: 0.7560 time: 0.0208s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.6693 acc_train: 0.4429 loss_val: 1.7472 acc_val: 0.7600 time: 0.0183s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.7211 acc_train: 0.4357 loss_val: 1.7424 acc_val: 0.7520 time: 0.0183s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.6531 acc_train: 0.4857 loss_val: 1.7374 acc_val: 0.7660 time: 0.0184s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.7064 acc_train: 0.4429 loss_val: 1.7323 acc_val: 0.7720 time: 0.0183s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.6963 acc_train: 0.4143 loss_val: 1.7256 acc_val: 0.7720 time: 0.0182s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.6802 acc_train: 0.4500 loss_val: 1.7189 acc_val: 0.7680 time: 0.0195s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.6684 acc_train: 0.4929 loss_val: 1.7121 acc_val: 0.7600 time: 0.0180s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.6225 acc_train: 0.4714 loss_val: 1.7035 acc_val: 0.7500 time: 0.0182s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.6494 acc_train: 0.5143 loss_val: 1.6941 acc_val: 0.7280 time: 0.0185s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.5996 acc_train: 0.4857 loss_val: 1.6842 acc_val: 0.7220 time: 0.0180s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.6351 acc_train: 0.4714 loss_val: 1.6764 acc_val: 0.7220 time: 0.0181s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.6141 acc_train: 0.5286 loss_val: 1.6687 acc_val: 0.7220 time: 0.0191s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.6144 acc_train: 0.4643 loss_val: 1.6611 acc_val: 0.7300 time: 0.0180s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.5944 acc_train: 0.5071 loss_val: 1.6535 acc_val: 0.7420 time: 0.0185s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.5936 acc_train: 0.5357 loss_val: 1.6472 acc_val: 0.7360 time: 0.0181s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.6313 acc_train: 0.4929 loss_val: 1.6416 acc_val: 0.7440 time: 0.0181s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.6280 acc_train: 0.4357 loss_val: 1.6359 acc_val: 0.7500 time: 0.0180s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.5498 acc_train: 0.5643 loss_val: 1.6288 acc_val: 0.7600 time: 0.0203s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.5682 acc_train: 0.5143 loss_val: 1.6258 acc_val: 0.7560 time: 0.0197s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.5589 acc_train: 0.5357 loss_val: 1.6214 acc_val: 0.7700 time: 0.0180s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.5550 acc_train: 0.5000 loss_val: 1.6152 acc_val: 0.7680 time: 0.0180s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.5453 acc_train: 0.5786 loss_val: 1.6083 acc_val: 0.7640 time: 0.0180s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.5362 acc_train: 0.5143 loss_val: 1.6013 acc_val: 0.7480 time: 0.0190s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.5830 acc_train: 0.5000 loss_val: 1.5954 acc_val: 0.7300 time: 0.0195s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.5326 acc_train: 0.5286 loss_val: 1.5903 acc_val: 0.6820 time: 0.0180s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.5560 acc_train: 0.5214 loss_val: 1.5862 acc_val: 0.6620 time: 0.0183s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.4961 acc_train: 0.5500 loss_val: 1.5801 acc_val: 0.6300 time: 0.0192s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.5500 acc_train: 0.5143 loss_val: 1.5732 acc_val: 0.6260 time: 0.0189s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.4592 acc_train: 0.5500 loss_val: 1.5649 acc_val: 0.6260 time: 0.0182s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.5155 acc_train: 0.5500 loss_val: 1.5564 acc_val: 0.6520 time: 0.0184s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.5380 acc_train: 0.5429 loss_val: 1.5497 acc_val: 0.6680 time: 0.0183s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.4397 acc_train: 0.5714 loss_val: 1.5397 acc_val: 0.7160 time: 0.0181s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.5168 acc_train: 0.5071 loss_val: 1.5308 acc_val: 0.7420 time: 0.0185s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.4992 acc_train: 0.5214 loss_val: 1.5205 acc_val: 0.7580 time: 0.0184s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.5060 acc_train: 0.5500 loss_val: 1.5111 acc_val: 0.7660 time: 0.0183s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.4185 acc_train: 0.5929 loss_val: 1.5017 acc_val: 0.7720 time: 0.0184s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.4259 acc_train: 0.5357 loss_val: 1.4909 acc_val: 0.7860 time: 0.0189s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.4286 acc_train: 0.5571 loss_val: 1.4790 acc_val: 0.7960 time: 0.0182s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.4367 acc_train: 0.5429 loss_val: 1.4678 acc_val: 0.8020 time: 0.0184s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.3551 acc_train: 0.6571 loss_val: 1.4578 acc_val: 0.8020 time: 0.0182s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.4292 acc_train: 0.5643 loss_val: 1.4504 acc_val: 0.7980 time: 0.0183s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.4148 acc_train: 0.6214 loss_val: 1.4458 acc_val: 0.7820 time: 0.0183s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.4596 acc_train: 0.5571 loss_val: 1.4444 acc_val: 0.7840 time: 0.0184s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.3927 acc_train: 0.5857 loss_val: 1.4455 acc_val: 0.7860 time: 0.0179s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.4100 acc_train: 0.5714 loss_val: 1.4458 acc_val: 0.7840 time: 0.0184s\n",
            "1\n",
            "Epoch: 0129 loss_train: 1.4146 acc_train: 0.5786 loss_val: 1.4456 acc_val: 0.7760 time: 0.0197s\n",
            "2\n",
            "Epoch: 0130 loss_train: 1.3243 acc_train: 0.5857 loss_val: 1.4447 acc_val: 0.7780 time: 0.0194s\n",
            "3\n",
            "Epoch: 0131 loss_train: 1.4666 acc_train: 0.5500 loss_val: 1.4383 acc_val: 0.7800 time: 0.0198s\n",
            "4\n",
            "Epoch: 0132 loss_train: 1.3756 acc_train: 0.6214 loss_val: 1.4283 acc_val: 0.7800 time: 0.0180s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.3205 acc_train: 0.6429 loss_val: 1.4146 acc_val: 0.7840 time: 0.0180s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.3429 acc_train: 0.6571 loss_val: 1.4015 acc_val: 0.7960 time: 0.0182s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.4274 acc_train: 0.5429 loss_val: 1.3917 acc_val: 0.7820 time: 0.0181s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.3814 acc_train: 0.5571 loss_val: 1.3834 acc_val: 0.7680 time: 0.0180s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.3826 acc_train: 0.5571 loss_val: 1.3804 acc_val: 0.7320 time: 0.0182s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.3453 acc_train: 0.6071 loss_val: 1.3793 acc_val: 0.7180 time: 0.0185s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.3145 acc_train: 0.6429 loss_val: 1.3778 acc_val: 0.7160 time: 0.0202s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.3028 acc_train: 0.6357 loss_val: 1.3778 acc_val: 0.7420 time: 0.0181s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.3808 acc_train: 0.5500 loss_val: 1.3770 acc_val: 0.7620 time: 0.0180s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.3117 acc_train: 0.5714 loss_val: 1.3727 acc_val: 0.7740 time: 0.0180s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.4060 acc_train: 0.5643 loss_val: 1.3682 acc_val: 0.7780 time: 0.0180s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.3122 acc_train: 0.5857 loss_val: 1.3628 acc_val: 0.7860 time: 0.0192s\n",
            "0\n",
            "Epoch: 0145 loss_train: 1.2642 acc_train: 0.6214 loss_val: 1.3539 acc_val: 0.7900 time: 0.0206s\n",
            "0\n",
            "Epoch: 0146 loss_train: 1.2895 acc_train: 0.6286 loss_val: 1.3415 acc_val: 0.7900 time: 0.0184s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.3353 acc_train: 0.5786 loss_val: 1.3291 acc_val: 0.7800 time: 0.0187s\n",
            "0\n",
            "Epoch: 0148 loss_train: 1.3029 acc_train: 0.5857 loss_val: 1.3175 acc_val: 0.7700 time: 0.0196s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.3114 acc_train: 0.6214 loss_val: 1.3069 acc_val: 0.7800 time: 0.0181s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.2221 acc_train: 0.6571 loss_val: 1.2977 acc_val: 0.7840 time: 0.0182s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.2743 acc_train: 0.6286 loss_val: 1.2903 acc_val: 0.7840 time: 0.0196s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.3068 acc_train: 0.5714 loss_val: 1.2861 acc_val: 0.7880 time: 0.0181s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.3007 acc_train: 0.6357 loss_val: 1.2846 acc_val: 0.7880 time: 0.0182s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.3439 acc_train: 0.5571 loss_val: 1.2895 acc_val: 0.8100 time: 0.0180s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.3124 acc_train: 0.5857 loss_val: 1.2978 acc_val: 0.7980 time: 0.0189s\n",
            "0\n",
            "Epoch: 0156 loss_train: 1.4136 acc_train: 0.5286 loss_val: 1.3121 acc_val: 0.7880 time: 0.0211s\n",
            "1\n",
            "Epoch: 0157 loss_train: 1.3096 acc_train: 0.6214 loss_val: 1.3225 acc_val: 0.7820 time: 0.0192s\n",
            "2\n",
            "Epoch: 0158 loss_train: 1.2723 acc_train: 0.6143 loss_val: 1.3282 acc_val: 0.7780 time: 0.0215s\n",
            "3\n",
            "Epoch: 0159 loss_train: 1.3345 acc_train: 0.6214 loss_val: 1.3243 acc_val: 0.7800 time: 0.0188s\n",
            "4\n",
            "Epoch: 0160 loss_train: 1.2154 acc_train: 0.6429 loss_val: 1.3133 acc_val: 0.7840 time: 0.0186s\n",
            "5\n",
            "Epoch: 0161 loss_train: 1.2228 acc_train: 0.6357 loss_val: 1.2956 acc_val: 0.8080 time: 0.0184s\n",
            "6\n",
            "Epoch: 0162 loss_train: 1.2158 acc_train: 0.6571 loss_val: 1.2777 acc_val: 0.8080 time: 0.0187s\n",
            "7\n",
            "Epoch: 0163 loss_train: 1.2643 acc_train: 0.6357 loss_val: 1.2638 acc_val: 0.8080 time: 0.0179s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.2538 acc_train: 0.6214 loss_val: 1.2498 acc_val: 0.7980 time: 0.0180s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.2546 acc_train: 0.5929 loss_val: 1.2378 acc_val: 0.8000 time: 0.0179s\n",
            "0\n",
            "Epoch: 0166 loss_train: 1.2564 acc_train: 0.6214 loss_val: 1.2303 acc_val: 0.8000 time: 0.0181s\n",
            "0\n",
            "Epoch: 0167 loss_train: 1.2378 acc_train: 0.6143 loss_val: 1.2251 acc_val: 0.8100 time: 0.0193s\n",
            "0\n",
            "Epoch: 0168 loss_train: 1.1770 acc_train: 0.7000 loss_val: 1.2231 acc_val: 0.8060 time: 0.0180s\n",
            "0\n",
            "Epoch: 0169 loss_train: 1.2029 acc_train: 0.6214 loss_val: 1.2232 acc_val: 0.7960 time: 0.0182s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.2599 acc_train: 0.5929 loss_val: 1.2245 acc_val: 0.8080 time: 0.0183s\n",
            "1\n",
            "Epoch: 0171 loss_train: 1.2671 acc_train: 0.6214 loss_val: 1.2267 acc_val: 0.8040 time: 0.0189s\n",
            "2\n",
            "Epoch: 0172 loss_train: 1.1727 acc_train: 0.6571 loss_val: 1.2286 acc_val: 0.8060 time: 0.0184s\n",
            "3\n",
            "Epoch: 0173 loss_train: 1.2275 acc_train: 0.6286 loss_val: 1.2308 acc_val: 0.8080 time: 0.0183s\n",
            "4\n",
            "Epoch: 0174 loss_train: 1.2451 acc_train: 0.6357 loss_val: 1.2344 acc_val: 0.8040 time: 0.0185s\n",
            "5\n",
            "Epoch: 0175 loss_train: 1.1557 acc_train: 0.6857 loss_val: 1.2331 acc_val: 0.7920 time: 0.0192s\n",
            "6\n",
            "Epoch: 0176 loss_train: 1.2617 acc_train: 0.6000 loss_val: 1.2300 acc_val: 0.7920 time: 0.0186s\n",
            "7\n",
            "Epoch: 0177 loss_train: 1.2170 acc_train: 0.6786 loss_val: 1.2230 acc_val: 0.7920 time: 0.0193s\n",
            "8\n",
            "Epoch: 0178 loss_train: 1.1283 acc_train: 0.6643 loss_val: 1.2119 acc_val: 0.8080 time: 0.0183s\n",
            "0\n",
            "Epoch: 0179 loss_train: 1.2847 acc_train: 0.5714 loss_val: 1.2027 acc_val: 0.8100 time: 0.0181s\n",
            "0\n",
            "Epoch: 0180 loss_train: 1.1970 acc_train: 0.6571 loss_val: 1.1962 acc_val: 0.8040 time: 0.0180s\n",
            "0\n",
            "Epoch: 0181 loss_train: 1.2722 acc_train: 0.5857 loss_val: 1.1891 acc_val: 0.8080 time: 0.0181s\n",
            "0\n",
            "Epoch: 0182 loss_train: 1.2383 acc_train: 0.6571 loss_val: 1.1853 acc_val: 0.8080 time: 0.0181s\n",
            "0\n",
            "Epoch: 0183 loss_train: 1.1409 acc_train: 0.6571 loss_val: 1.1822 acc_val: 0.8040 time: 0.0182s\n",
            "0\n",
            "Epoch: 0184 loss_train: 1.2160 acc_train: 0.6286 loss_val: 1.1790 acc_val: 0.8020 time: 0.0181s\n",
            "0\n",
            "Epoch: 0185 loss_train: 1.2568 acc_train: 0.5929 loss_val: 1.1754 acc_val: 0.8000 time: 0.0181s\n",
            "0\n",
            "Epoch: 0186 loss_train: 1.1873 acc_train: 0.6714 loss_val: 1.1709 acc_val: 0.7940 time: 0.0184s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.1927 acc_train: 0.6357 loss_val: 1.1689 acc_val: 0.8000 time: 0.0233s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.0845 acc_train: 0.6857 loss_val: 1.1667 acc_val: 0.8060 time: 0.0185s\n",
            "0\n",
            "Epoch: 0189 loss_train: 1.1458 acc_train: 0.6929 loss_val: 1.1632 acc_val: 0.8000 time: 0.0189s\n",
            "0\n",
            "Epoch: 0190 loss_train: 1.2512 acc_train: 0.6143 loss_val: 1.1645 acc_val: 0.8020 time: 0.0183s\n",
            "0\n",
            "Epoch: 0191 loss_train: 1.1418 acc_train: 0.6714 loss_val: 1.1674 acc_val: 0.8080 time: 0.0192s\n",
            "1\n",
            "Epoch: 0192 loss_train: 1.1550 acc_train: 0.6357 loss_val: 1.1696 acc_val: 0.7980 time: 0.0185s\n",
            "2\n",
            "Epoch: 0193 loss_train: 1.2293 acc_train: 0.6286 loss_val: 1.1695 acc_val: 0.7980 time: 0.0184s\n",
            "3\n",
            "Epoch: 0194 loss_train: 1.1775 acc_train: 0.6571 loss_val: 1.1681 acc_val: 0.7960 time: 0.0184s\n",
            "4\n",
            "Epoch: 0195 loss_train: 1.1393 acc_train: 0.6500 loss_val: 1.1617 acc_val: 0.8020 time: 0.0194s\n",
            "5\n",
            "Epoch: 0196 loss_train: 1.1206 acc_train: 0.6214 loss_val: 1.1543 acc_val: 0.8020 time: 0.0195s\n",
            "0\n",
            "Epoch: 0197 loss_train: 1.0890 acc_train: 0.6857 loss_val: 1.1442 acc_val: 0.8100 time: 0.0202s\n",
            "0\n",
            "Epoch: 0198 loss_train: 1.1178 acc_train: 0.6500 loss_val: 1.1333 acc_val: 0.8120 time: 0.0194s\n",
            "0\n",
            "Epoch: 0199 loss_train: 1.1456 acc_train: 0.6357 loss_val: 1.1287 acc_val: 0.8080 time: 0.0182s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.2189 acc_train: 0.6071 loss_val: 1.1278 acc_val: 0.8060 time: 0.0182s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.1129 acc_train: 0.6857 loss_val: 1.1235 acc_val: 0.8060 time: 0.0186s\n",
            "0\n",
            "Epoch: 0202 loss_train: 1.1652 acc_train: 0.6357 loss_val: 1.1211 acc_val: 0.8040 time: 0.0184s\n",
            "0\n",
            "Epoch: 0203 loss_train: 1.0987 acc_train: 0.6786 loss_val: 1.1207 acc_val: 0.8020 time: 0.0181s\n",
            "0\n",
            "Epoch: 0204 loss_train: 1.2200 acc_train: 0.6786 loss_val: 1.1236 acc_val: 0.7980 time: 0.0183s\n",
            "0\n",
            "Epoch: 0205 loss_train: 1.2783 acc_train: 0.5714 loss_val: 1.1301 acc_val: 0.7960 time: 0.0206s\n",
            "1\n",
            "Epoch: 0206 loss_train: 1.2490 acc_train: 0.5929 loss_val: 1.1391 acc_val: 0.7960 time: 0.0197s\n",
            "2\n",
            "Epoch: 0207 loss_train: 1.0849 acc_train: 0.6643 loss_val: 1.1477 acc_val: 0.7940 time: 0.0185s\n",
            "3\n",
            "Epoch: 0208 loss_train: 1.0250 acc_train: 0.7929 loss_val: 1.1531 acc_val: 0.7920 time: 0.0184s\n",
            "4\n",
            "Epoch: 0209 loss_train: 1.1589 acc_train: 0.6429 loss_val: 1.1601 acc_val: 0.7840 time: 0.0182s\n",
            "5\n",
            "Epoch: 0210 loss_train: 1.1441 acc_train: 0.6786 loss_val: 1.1653 acc_val: 0.7720 time: 0.0185s\n",
            "6\n",
            "Epoch: 0211 loss_train: 1.1167 acc_train: 0.6429 loss_val: 1.1628 acc_val: 0.7800 time: 0.0183s\n",
            "7\n",
            "Epoch: 0212 loss_train: 1.1284 acc_train: 0.6500 loss_val: 1.1570 acc_val: 0.7740 time: 0.0183s\n",
            "8\n",
            "Epoch: 0213 loss_train: 1.1522 acc_train: 0.6071 loss_val: 1.1477 acc_val: 0.7800 time: 0.0179s\n",
            "9\n",
            "Epoch: 0214 loss_train: 1.0654 acc_train: 0.7143 loss_val: 1.1314 acc_val: 0.7920 time: 0.0185s\n",
            "10\n",
            "Epoch: 0215 loss_train: 1.1359 acc_train: 0.6643 loss_val: 1.1137 acc_val: 0.8000 time: 0.0195s\n",
            "11\n",
            "Epoch: 0216 loss_train: 1.1573 acc_train: 0.6786 loss_val: 1.0978 acc_val: 0.8120 time: 0.0182s\n",
            "0\n",
            "Epoch: 0217 loss_train: 1.1567 acc_train: 0.6357 loss_val: 1.0850 acc_val: 0.8060 time: 0.0184s\n",
            "0\n",
            "Epoch: 0218 loss_train: 1.2423 acc_train: 0.6000 loss_val: 1.0781 acc_val: 0.8040 time: 0.0182s\n",
            "0\n",
            "Epoch: 0219 loss_train: 1.0566 acc_train: 0.6929 loss_val: 1.0734 acc_val: 0.8060 time: 0.0194s\n",
            "0\n",
            "Epoch: 0220 loss_train: 1.1222 acc_train: 0.6429 loss_val: 1.0695 acc_val: 0.8060 time: 0.0198s\n",
            "0\n",
            "Epoch: 0221 loss_train: 1.0275 acc_train: 0.7143 loss_val: 1.0666 acc_val: 0.8100 time: 0.0184s\n",
            "0\n",
            "Epoch: 0222 loss_train: 1.1189 acc_train: 0.6143 loss_val: 1.0669 acc_val: 0.8060 time: 0.0183s\n",
            "0\n",
            "Epoch: 0223 loss_train: 1.1226 acc_train: 0.6643 loss_val: 1.0683 acc_val: 0.8100 time: 0.0185s\n",
            "1\n",
            "Epoch: 0224 loss_train: 1.1088 acc_train: 0.7000 loss_val: 1.0735 acc_val: 0.8060 time: 0.0191s\n",
            "2\n",
            "Epoch: 0225 loss_train: 1.1704 acc_train: 0.6500 loss_val: 1.0780 acc_val: 0.8020 time: 0.0191s\n",
            "3\n",
            "Epoch: 0226 loss_train: 1.1274 acc_train: 0.6929 loss_val: 1.0840 acc_val: 0.8040 time: 0.0186s\n",
            "4\n",
            "Epoch: 0227 loss_train: 0.9992 acc_train: 0.7571 loss_val: 1.0937 acc_val: 0.8100 time: 0.0185s\n",
            "5\n",
            "Epoch: 0228 loss_train: 1.1811 acc_train: 0.6286 loss_val: 1.1075 acc_val: 0.8020 time: 0.0185s\n",
            "6\n",
            "Epoch: 0229 loss_train: 1.0466 acc_train: 0.7214 loss_val: 1.1165 acc_val: 0.7880 time: 0.0187s\n",
            "7\n",
            "Epoch: 0230 loss_train: 1.0893 acc_train: 0.7714 loss_val: 1.1189 acc_val: 0.7840 time: 0.0187s\n",
            "8\n",
            "Epoch: 0231 loss_train: 1.1501 acc_train: 0.6571 loss_val: 1.1117 acc_val: 0.7880 time: 0.0187s\n",
            "9\n",
            "Epoch: 0232 loss_train: 1.1324 acc_train: 0.7000 loss_val: 1.1012 acc_val: 0.7980 time: 0.0184s\n",
            "10\n",
            "Epoch: 0233 loss_train: 1.1413 acc_train: 0.6571 loss_val: 1.0900 acc_val: 0.8040 time: 0.0186s\n",
            "11\n",
            "Epoch: 0234 loss_train: 1.0923 acc_train: 0.7143 loss_val: 1.0760 acc_val: 0.8080 time: 0.0200s\n",
            "12\n",
            "Epoch: 0235 loss_train: 1.0933 acc_train: 0.7071 loss_val: 1.0619 acc_val: 0.8060 time: 0.0182s\n",
            "13\n",
            "Epoch: 0236 loss_train: 0.9993 acc_train: 0.8071 loss_val: 1.0490 acc_val: 0.8100 time: 0.0189s\n",
            "0\n",
            "Epoch: 0237 loss_train: 1.1133 acc_train: 0.6571 loss_val: 1.0394 acc_val: 0.8160 time: 0.0186s\n",
            "0\n",
            "Epoch: 0238 loss_train: 0.9982 acc_train: 0.6786 loss_val: 1.0356 acc_val: 0.8220 time: 0.0183s\n",
            "0\n",
            "Epoch: 0239 loss_train: 1.0887 acc_train: 0.6500 loss_val: 1.0372 acc_val: 0.8140 time: 0.0184s\n",
            "0\n",
            "Epoch: 0240 loss_train: 1.0157 acc_train: 0.6857 loss_val: 1.0388 acc_val: 0.8060 time: 0.0186s\n",
            "1\n",
            "Epoch: 0241 loss_train: 1.0210 acc_train: 0.7214 loss_val: 1.0430 acc_val: 0.8080 time: 0.0222s\n",
            "2\n",
            "Epoch: 0242 loss_train: 1.0452 acc_train: 0.6857 loss_val: 1.0459 acc_val: 0.8040 time: 0.0188s\n",
            "3\n",
            "Epoch: 0243 loss_train: 1.0643 acc_train: 0.7000 loss_val: 1.0460 acc_val: 0.8040 time: 0.0194s\n",
            "4\n",
            "Epoch: 0244 loss_train: 1.1152 acc_train: 0.6571 loss_val: 1.0437 acc_val: 0.8020 time: 0.0200s\n",
            "5\n",
            "Epoch: 0245 loss_train: 1.0417 acc_train: 0.6929 loss_val: 1.0406 acc_val: 0.8060 time: 0.0190s\n",
            "6\n",
            "Epoch: 0246 loss_train: 1.0546 acc_train: 0.7071 loss_val: 1.0372 acc_val: 0.8140 time: 0.0199s\n",
            "7\n",
            "Epoch: 0247 loss_train: 1.0037 acc_train: 0.6929 loss_val: 1.0349 acc_val: 0.8180 time: 0.0186s\n",
            "8\n",
            "Epoch: 0248 loss_train: 1.1047 acc_train: 0.6286 loss_val: 1.0340 acc_val: 0.8160 time: 0.0181s\n",
            "0\n",
            "Epoch: 0249 loss_train: 1.0664 acc_train: 0.6786 loss_val: 1.0340 acc_val: 0.8180 time: 0.0186s\n",
            "0\n",
            "Epoch: 0250 loss_train: 1.0508 acc_train: 0.7000 loss_val: 1.0340 acc_val: 0.8040 time: 0.0181s\n",
            "0\n",
            "Epoch: 0251 loss_train: 1.1200 acc_train: 0.6500 loss_val: 1.0384 acc_val: 0.8020 time: 0.0197s\n",
            "1\n",
            "Epoch: 0252 loss_train: 1.1019 acc_train: 0.6786 loss_val: 1.0443 acc_val: 0.8000 time: 0.0184s\n",
            "2\n",
            "Epoch: 0253 loss_train: 0.9472 acc_train: 0.7714 loss_val: 1.0509 acc_val: 0.7980 time: 0.0185s\n",
            "3\n",
            "Epoch: 0254 loss_train: 1.1465 acc_train: 0.6214 loss_val: 1.0543 acc_val: 0.7940 time: 0.0185s\n",
            "4\n",
            "Epoch: 0255 loss_train: 1.0649 acc_train: 0.7071 loss_val: 1.0567 acc_val: 0.7980 time: 0.0185s\n",
            "5\n",
            "Epoch: 0256 loss_train: 1.0628 acc_train: 0.6571 loss_val: 1.0556 acc_val: 0.8020 time: 0.0185s\n",
            "6\n",
            "Epoch: 0257 loss_train: 1.1314 acc_train: 0.6429 loss_val: 1.0521 acc_val: 0.8020 time: 0.0184s\n",
            "7\n",
            "Epoch: 0258 loss_train: 0.9826 acc_train: 0.7500 loss_val: 1.0487 acc_val: 0.8040 time: 0.0183s\n",
            "8\n",
            "Epoch: 0259 loss_train: 1.0302 acc_train: 0.7000 loss_val: 1.0382 acc_val: 0.8080 time: 0.0184s\n",
            "9\n",
            "Epoch: 0260 loss_train: 1.0040 acc_train: 0.7286 loss_val: 1.0265 acc_val: 0.8140 time: 0.0184s\n",
            "10\n",
            "Epoch: 0261 loss_train: 1.0345 acc_train: 0.7214 loss_val: 1.0145 acc_val: 0.8080 time: 0.0213s\n",
            "0\n",
            "Epoch: 0262 loss_train: 1.1197 acc_train: 0.6357 loss_val: 1.0087 acc_val: 0.8140 time: 0.0182s\n",
            "0\n",
            "Epoch: 0263 loss_train: 1.0286 acc_train: 0.7143 loss_val: 1.0011 acc_val: 0.8180 time: 0.0181s\n",
            "0\n",
            "Epoch: 0264 loss_train: 1.1650 acc_train: 0.6000 loss_val: 0.9986 acc_val: 0.8200 time: 0.0185s\n",
            "0\n",
            "Epoch: 0265 loss_train: 1.0431 acc_train: 0.7143 loss_val: 0.9992 acc_val: 0.8180 time: 0.0181s\n",
            "0\n",
            "Epoch: 0266 loss_train: 1.0176 acc_train: 0.7143 loss_val: 1.0000 acc_val: 0.8200 time: 0.0183s\n",
            "1\n",
            "Epoch: 0267 loss_train: 1.0398 acc_train: 0.6786 loss_val: 0.9989 acc_val: 0.8180 time: 0.0194s\n",
            "2\n",
            "Epoch: 0268 loss_train: 1.1040 acc_train: 0.6500 loss_val: 0.9992 acc_val: 0.8100 time: 0.0217s\n",
            "3\n",
            "Epoch: 0269 loss_train: 1.1524 acc_train: 0.6357 loss_val: 1.0046 acc_val: 0.7960 time: 0.0195s\n",
            "4\n",
            "Epoch: 0270 loss_train: 1.0477 acc_train: 0.7071 loss_val: 1.0095 acc_val: 0.7980 time: 0.0198s\n",
            "5\n",
            "Epoch: 0271 loss_train: 1.0900 acc_train: 0.6643 loss_val: 1.0131 acc_val: 0.8000 time: 0.0199s\n",
            "6\n",
            "Epoch: 0272 loss_train: 1.0121 acc_train: 0.7143 loss_val: 1.0156 acc_val: 0.8020 time: 0.0207s\n",
            "7\n",
            "Epoch: 0273 loss_train: 1.0093 acc_train: 0.7143 loss_val: 1.0115 acc_val: 0.8060 time: 0.0184s\n",
            "8\n",
            "Epoch: 0274 loss_train: 0.9778 acc_train: 0.7500 loss_val: 1.0065 acc_val: 0.8140 time: 0.0184s\n",
            "9\n",
            "Epoch: 0275 loss_train: 1.0082 acc_train: 0.6857 loss_val: 1.0021 acc_val: 0.8180 time: 0.0184s\n",
            "10\n",
            "Epoch: 0276 loss_train: 0.9068 acc_train: 0.7571 loss_val: 0.9969 acc_val: 0.8160 time: 0.0184s\n",
            "11\n",
            "Epoch: 0277 loss_train: 1.0556 acc_train: 0.6643 loss_val: 0.9928 acc_val: 0.8140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0278 loss_train: 0.9651 acc_train: 0.7429 loss_val: 0.9938 acc_val: 0.8140 time: 0.0183s\n",
            "0\n",
            "Epoch: 0279 loss_train: 1.0312 acc_train: 0.7571 loss_val: 0.9954 acc_val: 0.8100 time: 0.0184s\n",
            "1\n",
            "Epoch: 0280 loss_train: 1.0031 acc_train: 0.7143 loss_val: 0.9924 acc_val: 0.8140 time: 0.0189s\n",
            "2\n",
            "Epoch: 0281 loss_train: 1.0941 acc_train: 0.6929 loss_val: 0.9890 acc_val: 0.8100 time: 0.0182s\n",
            "0\n",
            "Epoch: 0282 loss_train: 1.0104 acc_train: 0.7071 loss_val: 0.9850 acc_val: 0.8060 time: 0.0180s\n",
            "0\n",
            "Epoch: 0283 loss_train: 0.9175 acc_train: 0.7429 loss_val: 0.9802 acc_val: 0.8040 time: 0.0180s\n",
            "0\n",
            "Epoch: 0284 loss_train: 0.9613 acc_train: 0.7071 loss_val: 0.9809 acc_val: 0.8060 time: 0.0180s\n",
            "0\n",
            "Epoch: 0285 loss_train: 1.1630 acc_train: 0.6500 loss_val: 0.9901 acc_val: 0.8040 time: 0.0185s\n",
            "1\n",
            "Epoch: 0286 loss_train: 1.1913 acc_train: 0.6000 loss_val: 1.0024 acc_val: 0.7960 time: 0.0184s\n",
            "2\n",
            "Epoch: 0287 loss_train: 1.0662 acc_train: 0.6714 loss_val: 1.0128 acc_val: 0.7960 time: 0.0192s\n",
            "3\n",
            "Epoch: 0288 loss_train: 0.9902 acc_train: 0.7500 loss_val: 1.0152 acc_val: 0.8020 time: 0.0185s\n",
            "4\n",
            "Epoch: 0289 loss_train: 1.0496 acc_train: 0.6643 loss_val: 1.0148 acc_val: 0.8040 time: 0.0184s\n",
            "5\n",
            "Epoch: 0290 loss_train: 1.0455 acc_train: 0.7143 loss_val: 1.0100 acc_val: 0.8040 time: 0.0204s\n",
            "6\n",
            "Epoch: 0291 loss_train: 0.9962 acc_train: 0.7214 loss_val: 0.9983 acc_val: 0.8080 time: 0.0207s\n",
            "7\n",
            "Epoch: 0292 loss_train: 1.0619 acc_train: 0.6571 loss_val: 0.9878 acc_val: 0.8160 time: 0.0184s\n",
            "8\n",
            "Epoch: 0293 loss_train: 1.0055 acc_train: 0.7500 loss_val: 0.9778 acc_val: 0.8100 time: 0.0183s\n",
            "9\n",
            "Epoch: 0294 loss_train: 1.0393 acc_train: 0.6857 loss_val: 0.9728 acc_val: 0.8080 time: 0.0185s\n",
            "0\n",
            "Epoch: 0295 loss_train: 1.1235 acc_train: 0.6500 loss_val: 0.9696 acc_val: 0.8100 time: 0.0181s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.9799 acc_train: 0.7214 loss_val: 0.9646 acc_val: 0.8080 time: 0.0183s\n",
            "0\n",
            "Epoch: 0297 loss_train: 1.0547 acc_train: 0.7143 loss_val: 0.9636 acc_val: 0.8060 time: 0.0183s\n",
            "0\n",
            "Epoch: 0298 loss_train: 1.0396 acc_train: 0.6714 loss_val: 0.9655 acc_val: 0.8060 time: 0.0182s\n",
            "0\n",
            "Epoch: 0299 loss_train: 0.9582 acc_train: 0.7000 loss_val: 0.9677 acc_val: 0.8080 time: 0.0182s\n",
            "1\n",
            "Epoch: 0300 loss_train: 0.9750 acc_train: 0.6929 loss_val: 0.9713 acc_val: 0.8140 time: 0.0194s\n",
            "2\n",
            "Epoch: 0301 loss_train: 0.9804 acc_train: 0.7071 loss_val: 0.9769 acc_val: 0.8140 time: 0.0191s\n",
            "3\n",
            "Epoch: 0302 loss_train: 1.0615 acc_train: 0.6857 loss_val: 0.9836 acc_val: 0.8100 time: 0.0217s\n",
            "4\n",
            "Epoch: 0303 loss_train: 0.9841 acc_train: 0.7214 loss_val: 0.9893 acc_val: 0.8100 time: 0.0187s\n",
            "5\n",
            "Epoch: 0304 loss_train: 1.0057 acc_train: 0.6714 loss_val: 0.9873 acc_val: 0.8120 time: 0.0187s\n",
            "6\n",
            "Epoch: 0305 loss_train: 0.9788 acc_train: 0.6857 loss_val: 0.9875 acc_val: 0.8160 time: 0.0185s\n",
            "7\n",
            "Epoch: 0306 loss_train: 1.0167 acc_train: 0.6786 loss_val: 0.9848 acc_val: 0.8140 time: 0.0186s\n",
            "8\n",
            "Epoch: 0307 loss_train: 1.0141 acc_train: 0.7500 loss_val: 0.9781 acc_val: 0.8160 time: 0.0179s\n",
            "9\n",
            "Epoch: 0308 loss_train: 1.0466 acc_train: 0.6786 loss_val: 0.9736 acc_val: 0.8160 time: 0.0183s\n",
            "10\n",
            "Epoch: 0309 loss_train: 0.9957 acc_train: 0.6571 loss_val: 0.9686 acc_val: 0.8140 time: 0.0184s\n",
            "11\n",
            "Epoch: 0310 loss_train: 1.0292 acc_train: 0.7286 loss_val: 0.9621 acc_val: 0.8160 time: 0.0193s\n",
            "12\n",
            "Epoch: 0311 loss_train: 0.9417 acc_train: 0.7643 loss_val: 0.9580 acc_val: 0.8140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0312 loss_train: 0.9249 acc_train: 0.7500 loss_val: 0.9545 acc_val: 0.8120 time: 0.0181s\n",
            "0\n",
            "Epoch: 0313 loss_train: 1.0185 acc_train: 0.6929 loss_val: 0.9534 acc_val: 0.8100 time: 0.0180s\n",
            "0\n",
            "Epoch: 0314 loss_train: 0.9993 acc_train: 0.7214 loss_val: 0.9535 acc_val: 0.8140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0315 loss_train: 1.0199 acc_train: 0.7214 loss_val: 0.9569 acc_val: 0.8080 time: 0.0185s\n",
            "1\n",
            "Epoch: 0316 loss_train: 0.9643 acc_train: 0.7071 loss_val: 0.9623 acc_val: 0.8020 time: 0.0184s\n",
            "2\n",
            "Epoch: 0317 loss_train: 1.0271 acc_train: 0.6786 loss_val: 0.9691 acc_val: 0.8040 time: 0.0185s\n",
            "3\n",
            "Epoch: 0318 loss_train: 1.0645 acc_train: 0.7000 loss_val: 0.9740 acc_val: 0.8100 time: 0.0187s\n",
            "4\n",
            "Epoch: 0319 loss_train: 0.9783 acc_train: 0.7500 loss_val: 0.9767 acc_val: 0.8120 time: 0.0183s\n",
            "5\n",
            "Epoch: 0320 loss_train: 1.0623 acc_train: 0.7143 loss_val: 0.9818 acc_val: 0.8100 time: 0.0203s\n",
            "6\n",
            "Epoch: 0321 loss_train: 0.9798 acc_train: 0.7000 loss_val: 0.9814 acc_val: 0.8080 time: 0.0180s\n",
            "7\n",
            "Epoch: 0322 loss_train: 0.9401 acc_train: 0.7429 loss_val: 0.9812 acc_val: 0.8020 time: 0.0184s\n",
            "8\n",
            "Epoch: 0323 loss_train: 0.9364 acc_train: 0.7357 loss_val: 0.9767 acc_val: 0.8100 time: 0.0185s\n",
            "9\n",
            "Epoch: 0324 loss_train: 1.0671 acc_train: 0.6500 loss_val: 0.9680 acc_val: 0.8120 time: 0.0185s\n",
            "10\n",
            "Epoch: 0325 loss_train: 0.9066 acc_train: 0.7857 loss_val: 0.9574 acc_val: 0.8080 time: 0.0184s\n",
            "11\n",
            "Epoch: 0326 loss_train: 0.9830 acc_train: 0.6786 loss_val: 0.9445 acc_val: 0.8100 time: 0.0185s\n",
            "12\n",
            "Epoch: 0327 loss_train: 0.9766 acc_train: 0.7143 loss_val: 0.9361 acc_val: 0.8160 time: 0.0181s\n",
            "0\n",
            "Epoch: 0328 loss_train: 1.0333 acc_train: 0.7071 loss_val: 0.9310 acc_val: 0.8160 time: 0.0205s\n",
            "0\n",
            "Epoch: 0329 loss_train: 1.0029 acc_train: 0.7286 loss_val: 0.9317 acc_val: 0.8160 time: 0.0181s\n",
            "0\n",
            "Epoch: 0330 loss_train: 1.0368 acc_train: 0.6714 loss_val: 0.9333 acc_val: 0.8140 time: 0.0214s\n",
            "1\n",
            "Epoch: 0331 loss_train: 1.0525 acc_train: 0.6643 loss_val: 0.9354 acc_val: 0.8140 time: 0.0188s\n",
            "2\n",
            "Epoch: 0332 loss_train: 0.9632 acc_train: 0.7000 loss_val: 0.9395 acc_val: 0.8060 time: 0.0189s\n",
            "3\n",
            "Epoch: 0333 loss_train: 0.9495 acc_train: 0.7571 loss_val: 0.9430 acc_val: 0.8060 time: 0.0189s\n",
            "4\n",
            "Epoch: 0334 loss_train: 0.9071 acc_train: 0.7786 loss_val: 0.9470 acc_val: 0.8080 time: 0.0197s\n",
            "5\n",
            "Epoch: 0335 loss_train: 0.9598 acc_train: 0.7429 loss_val: 0.9495 acc_val: 0.8060 time: 0.0189s\n",
            "6\n",
            "Epoch: 0336 loss_train: 1.0574 acc_train: 0.6929 loss_val: 0.9514 acc_val: 0.8100 time: 0.0198s\n",
            "7\n",
            "Epoch: 0337 loss_train: 0.9797 acc_train: 0.7357 loss_val: 0.9553 acc_val: 0.8100 time: 0.0193s\n",
            "8\n",
            "Epoch: 0338 loss_train: 0.9619 acc_train: 0.7500 loss_val: 0.9599 acc_val: 0.8060 time: 0.0186s\n",
            "9\n",
            "Epoch: 0339 loss_train: 0.9676 acc_train: 0.7286 loss_val: 0.9627 acc_val: 0.8100 time: 0.0191s\n",
            "10\n",
            "Epoch: 0340 loss_train: 1.0367 acc_train: 0.6500 loss_val: 0.9630 acc_val: 0.8060 time: 0.0207s\n",
            "11\n",
            "Epoch: 0341 loss_train: 0.9907 acc_train: 0.7714 loss_val: 0.9606 acc_val: 0.8080 time: 0.0184s\n",
            "12\n",
            "Epoch: 0342 loss_train: 0.9895 acc_train: 0.7286 loss_val: 0.9534 acc_val: 0.8040 time: 0.0185s\n",
            "13\n",
            "Epoch: 0343 loss_train: 0.9690 acc_train: 0.7071 loss_val: 0.9477 acc_val: 0.8020 time: 0.0190s\n",
            "14\n",
            "Epoch: 0344 loss_train: 0.9922 acc_train: 0.7071 loss_val: 0.9444 acc_val: 0.8020 time: 0.0196s\n",
            "15\n",
            "Epoch: 0345 loss_train: 0.9043 acc_train: 0.7429 loss_val: 0.9414 acc_val: 0.8040 time: 0.0193s\n",
            "16\n",
            "Epoch: 0346 loss_train: 0.8966 acc_train: 0.7214 loss_val: 0.9433 acc_val: 0.8080 time: 0.0187s\n",
            "17\n",
            "Epoch: 0347 loss_train: 0.8991 acc_train: 0.7500 loss_val: 0.9403 acc_val: 0.8060 time: 0.0182s\n",
            "18\n",
            "Epoch: 0348 loss_train: 0.9757 acc_train: 0.7429 loss_val: 0.9359 acc_val: 0.8060 time: 0.0190s\n",
            "19\n",
            "Epoch: 0349 loss_train: 1.0692 acc_train: 0.6286 loss_val: 0.9339 acc_val: 0.8060 time: 0.0185s\n",
            "20\n",
            "Epoch: 0350 loss_train: 0.8958 acc_train: 0.7429 loss_val: 0.9320 acc_val: 0.8000 time: 0.0198s\n",
            "21\n",
            "Epoch: 0351 loss_train: 0.9867 acc_train: 0.7214 loss_val: 0.9301 acc_val: 0.8020 time: 0.0188s\n",
            "22\n",
            "Epoch: 0352 loss_train: 0.9767 acc_train: 0.6786 loss_val: 0.9297 acc_val: 0.8060 time: 0.0181s\n",
            "0\n",
            "Epoch: 0353 loss_train: 1.0001 acc_train: 0.7214 loss_val: 0.9289 acc_val: 0.8120 time: 0.0181s\n",
            "0\n",
            "Epoch: 0354 loss_train: 0.9622 acc_train: 0.7357 loss_val: 0.9277 acc_val: 0.8100 time: 0.0181s\n",
            "0\n",
            "Epoch: 0355 loss_train: 0.9849 acc_train: 0.7143 loss_val: 0.9282 acc_val: 0.8140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0356 loss_train: 0.9970 acc_train: 0.6786 loss_val: 0.9297 acc_val: 0.8220 time: 0.0184s\n",
            "1\n",
            "Epoch: 0357 loss_train: 0.9033 acc_train: 0.7786 loss_val: 0.9314 acc_val: 0.8260 time: 0.0186s\n",
            "0\n",
            "Epoch: 0358 loss_train: 1.0153 acc_train: 0.6786 loss_val: 0.9359 acc_val: 0.8160 time: 0.0185s\n",
            "0\n",
            "Epoch: 0359 loss_train: 0.9247 acc_train: 0.7500 loss_val: 0.9405 acc_val: 0.8100 time: 0.0184s\n",
            "1\n",
            "Epoch: 0360 loss_train: 0.9728 acc_train: 0.7500 loss_val: 0.9423 acc_val: 0.8100 time: 0.0193s\n",
            "2\n",
            "Epoch: 0361 loss_train: 0.9359 acc_train: 0.7357 loss_val: 0.9411 acc_val: 0.8080 time: 0.0184s\n",
            "3\n",
            "Epoch: 0362 loss_train: 0.9043 acc_train: 0.7429 loss_val: 0.9387 acc_val: 0.8060 time: 0.0198s\n",
            "4\n",
            "Epoch: 0363 loss_train: 1.0713 acc_train: 0.6429 loss_val: 0.9345 acc_val: 0.8020 time: 0.0184s\n",
            "5\n",
            "Epoch: 0364 loss_train: 0.8392 acc_train: 0.8071 loss_val: 0.9286 acc_val: 0.7980 time: 0.0187s\n",
            "6\n",
            "Epoch: 0365 loss_train: 0.9972 acc_train: 0.6786 loss_val: 0.9218 acc_val: 0.8040 time: 0.0188s\n",
            "7\n",
            "Epoch: 0366 loss_train: 0.9193 acc_train: 0.7357 loss_val: 0.9178 acc_val: 0.8040 time: 0.0182s\n",
            "0\n",
            "Epoch: 0367 loss_train: 0.8535 acc_train: 0.7500 loss_val: 0.9178 acc_val: 0.7980 time: 0.0182s\n",
            "0\n",
            "Epoch: 0368 loss_train: 1.0063 acc_train: 0.6786 loss_val: 0.9181 acc_val: 0.7960 time: 0.0181s\n",
            "0\n",
            "Epoch: 0369 loss_train: 0.9116 acc_train: 0.7643 loss_val: 0.9172 acc_val: 0.7980 time: 0.0183s\n",
            "1\n",
            "Epoch: 0370 loss_train: 1.0287 acc_train: 0.6786 loss_val: 0.9174 acc_val: 0.8060 time: 0.0214s\n",
            "0\n",
            "Epoch: 0371 loss_train: 0.8916 acc_train: 0.7857 loss_val: 0.9223 acc_val: 0.8140 time: 0.0186s\n",
            "1\n",
            "Epoch: 0372 loss_train: 0.9532 acc_train: 0.7429 loss_val: 0.9291 acc_val: 0.8120 time: 0.0183s\n",
            "2\n",
            "Epoch: 0373 loss_train: 0.9312 acc_train: 0.6857 loss_val: 0.9349 acc_val: 0.8080 time: 0.0183s\n",
            "3\n",
            "Epoch: 0374 loss_train: 1.0274 acc_train: 0.6643 loss_val: 0.9368 acc_val: 0.8040 time: 0.0184s\n",
            "4\n",
            "Epoch: 0375 loss_train: 0.9423 acc_train: 0.7643 loss_val: 0.9318 acc_val: 0.8060 time: 0.0183s\n",
            "5\n",
            "Epoch: 0376 loss_train: 0.9146 acc_train: 0.7571 loss_val: 0.9222 acc_val: 0.8120 time: 0.0184s\n",
            "6\n",
            "Epoch: 0377 loss_train: 0.9826 acc_train: 0.7000 loss_val: 0.9124 acc_val: 0.8220 time: 0.0184s\n",
            "7\n",
            "Epoch: 0378 loss_train: 1.0444 acc_train: 0.7071 loss_val: 0.9036 acc_val: 0.8140 time: 0.0180s\n",
            "0\n",
            "Epoch: 0379 loss_train: 0.9397 acc_train: 0.7500 loss_val: 0.9024 acc_val: 0.8120 time: 0.0181s\n",
            "0\n",
            "Epoch: 0380 loss_train: 0.9539 acc_train: 0.7429 loss_val: 0.9051 acc_val: 0.8000 time: 0.0197s\n",
            "0\n",
            "Epoch: 0381 loss_train: 0.8954 acc_train: 0.7571 loss_val: 0.9098 acc_val: 0.7980 time: 0.0197s\n",
            "1\n",
            "Epoch: 0382 loss_train: 1.0072 acc_train: 0.7000 loss_val: 0.9177 acc_val: 0.7960 time: 0.0200s\n",
            "2\n",
            "Epoch: 0383 loss_train: 0.9934 acc_train: 0.7143 loss_val: 0.9208 acc_val: 0.7940 time: 0.0186s\n",
            "3\n",
            "Epoch: 0384 loss_train: 0.9197 acc_train: 0.7143 loss_val: 0.9251 acc_val: 0.7900 time: 0.0205s\n",
            "4\n",
            "Epoch: 0385 loss_train: 1.0467 acc_train: 0.6714 loss_val: 0.9268 acc_val: 0.7900 time: 0.0183s\n",
            "5\n",
            "Epoch: 0386 loss_train: 0.8837 acc_train: 0.7500 loss_val: 0.9252 acc_val: 0.8000 time: 0.0186s\n",
            "6\n",
            "Epoch: 0387 loss_train: 0.9810 acc_train: 0.7571 loss_val: 0.9236 acc_val: 0.8060 time: 0.0185s\n",
            "7\n",
            "Epoch: 0388 loss_train: 0.9638 acc_train: 0.7500 loss_val: 0.9191 acc_val: 0.8080 time: 0.0185s\n",
            "8\n",
            "Epoch: 0389 loss_train: 0.9042 acc_train: 0.7643 loss_val: 0.9119 acc_val: 0.8100 time: 0.0184s\n",
            "9\n",
            "Epoch: 0390 loss_train: 0.9115 acc_train: 0.7500 loss_val: 0.9063 acc_val: 0.8140 time: 0.0197s\n",
            "10\n",
            "Epoch: 0391 loss_train: 0.9611 acc_train: 0.7786 loss_val: 0.8991 acc_val: 0.8180 time: 0.0186s\n",
            "11\n",
            "Epoch: 0392 loss_train: 0.9148 acc_train: 0.7714 loss_val: 0.8929 acc_val: 0.8200 time: 0.0179s\n",
            "0\n",
            "Epoch: 0393 loss_train: 1.0520 acc_train: 0.7000 loss_val: 0.8884 acc_val: 0.8240 time: 0.0179s\n",
            "0\n",
            "Epoch: 0394 loss_train: 0.8856 acc_train: 0.7714 loss_val: 0.8864 acc_val: 0.8280 time: 0.0181s\n",
            "0\n",
            "Epoch: 0395 loss_train: 0.9424 acc_train: 0.7357 loss_val: 0.8917 acc_val: 0.8220 time: 0.0180s\n",
            "0\n",
            "Epoch: 0396 loss_train: 0.8706 acc_train: 0.7643 loss_val: 0.8948 acc_val: 0.8140 time: 0.0196s\n",
            "1\n",
            "Epoch: 0397 loss_train: 0.9835 acc_train: 0.7214 loss_val: 0.9037 acc_val: 0.8060 time: 0.0183s\n",
            "2\n",
            "Epoch: 0398 loss_train: 1.0541 acc_train: 0.6429 loss_val: 0.9137 acc_val: 0.8000 time: 0.0194s\n",
            "3\n",
            "Epoch: 0399 loss_train: 0.9022 acc_train: 0.7571 loss_val: 0.9214 acc_val: 0.7960 time: 0.0184s\n",
            "4\n",
            "Epoch: 0400 loss_train: 0.9848 acc_train: 0.6714 loss_val: 0.9291 acc_val: 0.7960 time: 0.0200s\n",
            "5\n",
            "Epoch: 0401 loss_train: 0.9203 acc_train: 0.7643 loss_val: 0.9323 acc_val: 0.7960 time: 0.0184s\n",
            "6\n",
            "Epoch: 0402 loss_train: 1.0182 acc_train: 0.6571 loss_val: 0.9298 acc_val: 0.7980 time: 0.0184s\n",
            "7\n",
            "Epoch: 0403 loss_train: 0.9623 acc_train: 0.7500 loss_val: 0.9266 acc_val: 0.8020 time: 0.0184s\n",
            "8\n",
            "Epoch: 0404 loss_train: 0.8662 acc_train: 0.7500 loss_val: 0.9156 acc_val: 0.8000 time: 0.0187s\n",
            "9\n",
            "Epoch: 0405 loss_train: 0.9967 acc_train: 0.7286 loss_val: 0.9049 acc_val: 0.8000 time: 0.0183s\n",
            "10\n",
            "Epoch: 0406 loss_train: 0.9802 acc_train: 0.7214 loss_val: 0.8967 acc_val: 0.8100 time: 0.0184s\n",
            "11\n",
            "Epoch: 0407 loss_train: 1.0200 acc_train: 0.7000 loss_val: 0.8909 acc_val: 0.8100 time: 0.0184s\n",
            "12\n",
            "Epoch: 0408 loss_train: 0.9055 acc_train: 0.7786 loss_val: 0.8847 acc_val: 0.8240 time: 0.0185s\n",
            "13\n",
            "Epoch: 0409 loss_train: 0.9789 acc_train: 0.7214 loss_val: 0.8785 acc_val: 0.8240 time: 0.0181s\n",
            "0\n",
            "Epoch: 0410 loss_train: 0.9028 acc_train: 0.7357 loss_val: 0.8729 acc_val: 0.8300 time: 0.0257s\n",
            "0\n",
            "Epoch: 0411 loss_train: 0.9909 acc_train: 0.6857 loss_val: 0.8728 acc_val: 0.8320 time: 0.0182s\n",
            "0\n",
            "Epoch: 0412 loss_train: 0.8976 acc_train: 0.7357 loss_val: 0.8731 acc_val: 0.8300 time: 0.0183s\n",
            "0\n",
            "Epoch: 0413 loss_train: 0.8395 acc_train: 0.8071 loss_val: 0.8719 acc_val: 0.8300 time: 0.0184s\n",
            "1\n",
            "Epoch: 0414 loss_train: 0.9924 acc_train: 0.7071 loss_val: 0.8703 acc_val: 0.8260 time: 0.0181s\n",
            "0\n",
            "Epoch: 0415 loss_train: 0.9744 acc_train: 0.7143 loss_val: 0.8675 acc_val: 0.8220 time: 0.0181s\n",
            "0\n",
            "Epoch: 0416 loss_train: 1.0085 acc_train: 0.6786 loss_val: 0.8685 acc_val: 0.8180 time: 0.0183s\n",
            "0\n",
            "Epoch: 0417 loss_train: 0.9830 acc_train: 0.7000 loss_val: 0.8697 acc_val: 0.8120 time: 0.0185s\n",
            "1\n",
            "Epoch: 0418 loss_train: 0.9147 acc_train: 0.7500 loss_val: 0.8717 acc_val: 0.8100 time: 0.0199s\n",
            "2\n",
            "Epoch: 0419 loss_train: 0.9956 acc_train: 0.7143 loss_val: 0.8717 acc_val: 0.8120 time: 0.0183s\n",
            "3\n",
            "Epoch: 0420 loss_train: 0.9090 acc_train: 0.8071 loss_val: 0.8751 acc_val: 0.8100 time: 0.0194s\n",
            "4\n",
            "Epoch: 0421 loss_train: 0.8793 acc_train: 0.7857 loss_val: 0.8797 acc_val: 0.8100 time: 0.0184s\n",
            "5\n",
            "Epoch: 0422 loss_train: 0.9447 acc_train: 0.7214 loss_val: 0.8864 acc_val: 0.8140 time: 0.0185s\n",
            "6\n",
            "Epoch: 0423 loss_train: 0.9877 acc_train: 0.7286 loss_val: 0.8934 acc_val: 0.8060 time: 0.0183s\n",
            "7\n",
            "Epoch: 0424 loss_train: 0.9161 acc_train: 0.7643 loss_val: 0.8987 acc_val: 0.8060 time: 0.0186s\n",
            "8\n",
            "Epoch: 0425 loss_train: 0.8665 acc_train: 0.7500 loss_val: 0.9005 acc_val: 0.8040 time: 0.0185s\n",
            "9\n",
            "Epoch: 0426 loss_train: 0.8912 acc_train: 0.7786 loss_val: 0.8987 acc_val: 0.8080 time: 0.0185s\n",
            "10\n",
            "Epoch: 0427 loss_train: 0.9915 acc_train: 0.7214 loss_val: 0.9004 acc_val: 0.8080 time: 0.0184s\n",
            "11\n",
            "Epoch: 0428 loss_train: 0.9406 acc_train: 0.7214 loss_val: 0.8990 acc_val: 0.8080 time: 0.0183s\n",
            "12\n",
            "Epoch: 0429 loss_train: 0.8258 acc_train: 0.8500 loss_val: 0.8958 acc_val: 0.8080 time: 0.0204s\n",
            "13\n",
            "Epoch: 0430 loss_train: 0.9224 acc_train: 0.7143 loss_val: 0.8919 acc_val: 0.8120 time: 0.0214s\n",
            "14\n",
            "Epoch: 0431 loss_train: 0.9948 acc_train: 0.6714 loss_val: 0.8882 acc_val: 0.8140 time: 0.0184s\n",
            "15\n",
            "Epoch: 0432 loss_train: 0.8782 acc_train: 0.8000 loss_val: 0.8858 acc_val: 0.8120 time: 0.0186s\n",
            "16\n",
            "Epoch: 0433 loss_train: 0.8658 acc_train: 0.7643 loss_val: 0.8835 acc_val: 0.8140 time: 0.0183s\n",
            "17\n",
            "Epoch: 0434 loss_train: 0.8827 acc_train: 0.7786 loss_val: 0.8806 acc_val: 0.8140 time: 0.0182s\n",
            "18\n",
            "Epoch: 0435 loss_train: 0.8311 acc_train: 0.7714 loss_val: 0.8783 acc_val: 0.8140 time: 0.0183s\n",
            "19\n",
            "Epoch: 0436 loss_train: 0.8950 acc_train: 0.7500 loss_val: 0.8766 acc_val: 0.8120 time: 0.0184s\n",
            "20\n",
            "Epoch: 0437 loss_train: 0.8923 acc_train: 0.7857 loss_val: 0.8748 acc_val: 0.8100 time: 0.0185s\n",
            "21\n",
            "Epoch: 0438 loss_train: 0.9141 acc_train: 0.7286 loss_val: 0.8716 acc_val: 0.8120 time: 0.0193s\n",
            "22\n",
            "Epoch: 0439 loss_train: 0.9115 acc_train: 0.7214 loss_val: 0.8703 acc_val: 0.8100 time: 0.0185s\n",
            "23\n",
            "Epoch: 0440 loss_train: 0.8240 acc_train: 0.7786 loss_val: 0.8704 acc_val: 0.8120 time: 0.0194s\n",
            "24\n",
            "Epoch: 0441 loss_train: 0.8925 acc_train: 0.7071 loss_val: 0.8714 acc_val: 0.8120 time: 0.0209s\n",
            "25\n",
            "Epoch: 0442 loss_train: 0.9824 acc_train: 0.7143 loss_val: 0.8810 acc_val: 0.8080 time: 0.0197s\n",
            "26\n",
            "Epoch: 0443 loss_train: 0.8950 acc_train: 0.7643 loss_val: 0.8915 acc_val: 0.8020 time: 0.0189s\n",
            "27\n",
            "Epoch: 0444 loss_train: 0.9010 acc_train: 0.7357 loss_val: 0.8997 acc_val: 0.8000 time: 0.0198s\n",
            "28\n",
            "Epoch: 0445 loss_train: 0.9734 acc_train: 0.7214 loss_val: 0.9097 acc_val: 0.8080 time: 0.0222s\n",
            "29\n",
            "Epoch: 0446 loss_train: 0.9056 acc_train: 0.7429 loss_val: 0.9161 acc_val: 0.8100 time: 0.0190s\n",
            "30\n",
            "Epoch: 0447 loss_train: 1.0212 acc_train: 0.6857 loss_val: 0.9169 acc_val: 0.8100 time: 0.0190s\n",
            "31\n",
            "Epoch: 0448 loss_train: 0.9379 acc_train: 0.7214 loss_val: 0.9128 acc_val: 0.8160 time: 0.0187s\n",
            "32\n",
            "Epoch: 0449 loss_train: 0.9119 acc_train: 0.7429 loss_val: 0.9088 acc_val: 0.8200 time: 0.0185s\n",
            "33\n",
            "Epoch: 0450 loss_train: 0.9018 acc_train: 0.7429 loss_val: 0.9004 acc_val: 0.8200 time: 0.0204s\n",
            "34\n",
            "Epoch: 0451 loss_train: 0.9037 acc_train: 0.7643 loss_val: 0.8930 acc_val: 0.8140 time: 0.0186s\n",
            "35\n",
            "Epoch: 0452 loss_train: 0.9600 acc_train: 0.7214 loss_val: 0.8830 acc_val: 0.8180 time: 0.0185s\n",
            "36\n",
            "Epoch: 0453 loss_train: 0.9552 acc_train: 0.7286 loss_val: 0.8757 acc_val: 0.8140 time: 0.0185s\n",
            "37\n",
            "Epoch: 0454 loss_train: 0.9543 acc_train: 0.7571 loss_val: 0.8709 acc_val: 0.8120 time: 0.0185s\n",
            "38\n",
            "Epoch: 0455 loss_train: 1.0203 acc_train: 0.6929 loss_val: 0.8695 acc_val: 0.8120 time: 0.0185s\n",
            "39\n",
            "Epoch: 0456 loss_train: 0.9441 acc_train: 0.7429 loss_val: 0.8666 acc_val: 0.8100 time: 0.0185s\n",
            "40\n",
            "Epoch: 0457 loss_train: 0.9853 acc_train: 0.7286 loss_val: 0.8631 acc_val: 0.8140 time: 0.0180s\n",
            "0\n",
            "Epoch: 0458 loss_train: 0.9156 acc_train: 0.7071 loss_val: 0.8638 acc_val: 0.8160 time: 0.0183s\n",
            "0\n",
            "Epoch: 0459 loss_train: 0.9286 acc_train: 0.6857 loss_val: 0.8683 acc_val: 0.8160 time: 0.0183s\n",
            "1\n",
            "Epoch: 0460 loss_train: 0.8613 acc_train: 0.7786 loss_val: 0.8716 acc_val: 0.8200 time: 0.0209s\n",
            "2\n",
            "Epoch: 0461 loss_train: 0.9379 acc_train: 0.7429 loss_val: 0.8757 acc_val: 0.8100 time: 0.0189s\n",
            "3\n",
            "Epoch: 0462 loss_train: 0.8483 acc_train: 0.6929 loss_val: 0.8793 acc_val: 0.8080 time: 0.0183s\n",
            "4\n",
            "Epoch: 0463 loss_train: 0.9004 acc_train: 0.7786 loss_val: 0.8787 acc_val: 0.8100 time: 0.0186s\n",
            "5\n",
            "Epoch: 0464 loss_train: 0.9456 acc_train: 0.7071 loss_val: 0.8765 acc_val: 0.8160 time: 0.0187s\n",
            "6\n",
            "Epoch: 0465 loss_train: 0.9450 acc_train: 0.7143 loss_val: 0.8725 acc_val: 0.8160 time: 0.0184s\n",
            "7\n",
            "Epoch: 0466 loss_train: 0.9077 acc_train: 0.7714 loss_val: 0.8671 acc_val: 0.8200 time: 0.0207s\n",
            "8\n",
            "Epoch: 0467 loss_train: 0.8731 acc_train: 0.7929 loss_val: 0.8638 acc_val: 0.8180 time: 0.0184s\n",
            "9\n",
            "Epoch: 0468 loss_train: 0.9158 acc_train: 0.7286 loss_val: 0.8627 acc_val: 0.8120 time: 0.0189s\n",
            "10\n",
            "Epoch: 0469 loss_train: 0.8992 acc_train: 0.7357 loss_val: 0.8658 acc_val: 0.8100 time: 0.0192s\n",
            "0\n",
            "Epoch: 0470 loss_train: 1.0358 acc_train: 0.7000 loss_val: 0.8669 acc_val: 0.8120 time: 0.0217s\n",
            "1\n",
            "Epoch: 0471 loss_train: 0.9257 acc_train: 0.7286 loss_val: 0.8601 acc_val: 0.8220 time: 0.0185s\n",
            "2\n",
            "Epoch: 0472 loss_train: 0.8831 acc_train: 0.7214 loss_val: 0.8555 acc_val: 0.8300 time: 0.0183s\n",
            "0\n",
            "Epoch: 0473 loss_train: 0.8762 acc_train: 0.7500 loss_val: 0.8522 acc_val: 0.8260 time: 0.0182s\n",
            "0\n",
            "Epoch: 0474 loss_train: 0.9509 acc_train: 0.7500 loss_val: 0.8542 acc_val: 0.8220 time: 0.0184s\n",
            "0\n",
            "Epoch: 0475 loss_train: 1.0160 acc_train: 0.7071 loss_val: 0.8611 acc_val: 0.8160 time: 0.0184s\n",
            "1\n",
            "Epoch: 0476 loss_train: 0.9942 acc_train: 0.6857 loss_val: 0.8697 acc_val: 0.8160 time: 0.0233s\n",
            "2\n",
            "Epoch: 0477 loss_train: 0.9255 acc_train: 0.7714 loss_val: 0.8776 acc_val: 0.8060 time: 0.0189s\n",
            "3\n",
            "Epoch: 0478 loss_train: 0.9003 acc_train: 0.7286 loss_val: 0.8797 acc_val: 0.8060 time: 0.0187s\n",
            "4\n",
            "Epoch: 0479 loss_train: 0.8810 acc_train: 0.7286 loss_val: 0.8777 acc_val: 0.8120 time: 0.0189s\n",
            "5\n",
            "Epoch: 0480 loss_train: 0.9307 acc_train: 0.7643 loss_val: 0.8760 acc_val: 0.8140 time: 0.0203s\n",
            "6\n",
            "Epoch: 0481 loss_train: 0.8521 acc_train: 0.8143 loss_val: 0.8732 acc_val: 0.8120 time: 0.0185s\n",
            "7\n",
            "Epoch: 0482 loss_train: 0.9013 acc_train: 0.7071 loss_val: 0.8700 acc_val: 0.8200 time: 0.0187s\n",
            "8\n",
            "Epoch: 0483 loss_train: 0.9445 acc_train: 0.7357 loss_val: 0.8689 acc_val: 0.8240 time: 0.0184s\n",
            "9\n",
            "Epoch: 0484 loss_train: 0.9648 acc_train: 0.7214 loss_val: 0.8667 acc_val: 0.8280 time: 0.0188s\n",
            "10\n",
            "Epoch: 0485 loss_train: 0.9368 acc_train: 0.7357 loss_val: 0.8656 acc_val: 0.8280 time: 0.0196s\n",
            "11\n",
            "Epoch: 0486 loss_train: 0.8547 acc_train: 0.7857 loss_val: 0.8613 acc_val: 0.8300 time: 0.0183s\n",
            "12\n",
            "Epoch: 0487 loss_train: 0.8539 acc_train: 0.7786 loss_val: 0.8577 acc_val: 0.8300 time: 0.0184s\n",
            "13\n",
            "Epoch: 0488 loss_train: 0.8819 acc_train: 0.7643 loss_val: 0.8544 acc_val: 0.8300 time: 0.0204s\n",
            "14\n",
            "Epoch: 0489 loss_train: 0.7791 acc_train: 0.7429 loss_val: 0.8503 acc_val: 0.8240 time: 0.0185s\n",
            "15\n",
            "Epoch: 0490 loss_train: 0.9423 acc_train: 0.7071 loss_val: 0.8477 acc_val: 0.8220 time: 0.0197s\n",
            "0\n",
            "Epoch: 0491 loss_train: 0.9948 acc_train: 0.6786 loss_val: 0.8485 acc_val: 0.8200 time: 0.0181s\n",
            "0\n",
            "Epoch: 0492 loss_train: 0.9423 acc_train: 0.7214 loss_val: 0.8528 acc_val: 0.8220 time: 0.0185s\n",
            "1\n",
            "Epoch: 0493 loss_train: 0.8513 acc_train: 0.7786 loss_val: 0.8569 acc_val: 0.8180 time: 0.0184s\n",
            "2\n",
            "Epoch: 0494 loss_train: 0.9187 acc_train: 0.7143 loss_val: 0.8629 acc_val: 0.8120 time: 0.0185s\n",
            "3\n",
            "Epoch: 0495 loss_train: 0.9468 acc_train: 0.7071 loss_val: 0.8673 acc_val: 0.8140 time: 0.0186s\n",
            "4\n",
            "Epoch: 0496 loss_train: 0.9152 acc_train: 0.7500 loss_val: 0.8742 acc_val: 0.8100 time: 0.0183s\n",
            "5\n",
            "Epoch: 0497 loss_train: 0.8659 acc_train: 0.7571 loss_val: 0.8818 acc_val: 0.8100 time: 0.0194s\n",
            "6\n",
            "Epoch: 0498 loss_train: 0.8880 acc_train: 0.7571 loss_val: 0.8871 acc_val: 0.8080 time: 0.0184s\n",
            "7\n",
            "Epoch: 0499 loss_train: 0.9072 acc_train: 0.7571 loss_val: 0.8817 acc_val: 0.8100 time: 0.0199s\n",
            "8\n",
            "Epoch: 0500 loss_train: 0.8950 acc_train: 0.7714 loss_val: 0.8763 acc_val: 0.8080 time: 0.0184s\n",
            "9\n",
            "Epoch: 0501 loss_train: 0.9131 acc_train: 0.7357 loss_val: 0.8701 acc_val: 0.8080 time: 0.0183s\n",
            "10\n",
            "Epoch: 0502 loss_train: 0.9008 acc_train: 0.7500 loss_val: 0.8657 acc_val: 0.8060 time: 0.0184s\n",
            "11\n",
            "Epoch: 0503 loss_train: 0.8674 acc_train: 0.7714 loss_val: 0.8617 acc_val: 0.8120 time: 0.0186s\n",
            "12\n",
            "Epoch: 0504 loss_train: 0.8915 acc_train: 0.7857 loss_val: 0.8561 acc_val: 0.8180 time: 0.0183s\n",
            "13\n",
            "Epoch: 0505 loss_train: 0.8796 acc_train: 0.7571 loss_val: 0.8512 acc_val: 0.8200 time: 0.0185s\n",
            "14\n",
            "Epoch: 0506 loss_train: 0.8938 acc_train: 0.7643 loss_val: 0.8462 acc_val: 0.8280 time: 0.0187s\n",
            "15\n",
            "Epoch: 0507 loss_train: 0.8137 acc_train: 0.8286 loss_val: 0.8431 acc_val: 0.8240 time: 0.0180s\n",
            "0\n",
            "Epoch: 0508 loss_train: 0.9155 acc_train: 0.7214 loss_val: 0.8464 acc_val: 0.8200 time: 0.0183s\n",
            "0\n",
            "Epoch: 0509 loss_train: 0.8393 acc_train: 0.7714 loss_val: 0.8519 acc_val: 0.8180 time: 0.0211s\n",
            "1\n",
            "Epoch: 0510 loss_train: 0.9705 acc_train: 0.7429 loss_val: 0.8617 acc_val: 0.8160 time: 0.0190s\n",
            "2\n",
            "Epoch: 0511 loss_train: 0.8135 acc_train: 0.7857 loss_val: 0.8713 acc_val: 0.8040 time: 0.0196s\n",
            "3\n",
            "Epoch: 0512 loss_train: 0.9125 acc_train: 0.7000 loss_val: 0.8748 acc_val: 0.8120 time: 0.0186s\n",
            "4\n",
            "Epoch: 0513 loss_train: 0.9243 acc_train: 0.7571 loss_val: 0.8766 acc_val: 0.8120 time: 0.0196s\n",
            "5\n",
            "Epoch: 0514 loss_train: 0.9369 acc_train: 0.6929 loss_val: 0.8730 acc_val: 0.8080 time: 0.0196s\n",
            "6\n",
            "Epoch: 0515 loss_train: 0.9143 acc_train: 0.7071 loss_val: 0.8703 acc_val: 0.8060 time: 0.0183s\n",
            "7\n",
            "Epoch: 0516 loss_train: 0.8791 acc_train: 0.7857 loss_val: 0.8651 acc_val: 0.8080 time: 0.0183s\n",
            "8\n",
            "Epoch: 0517 loss_train: 0.8121 acc_train: 0.7571 loss_val: 0.8617 acc_val: 0.8040 time: 0.0186s\n",
            "9\n",
            "Epoch: 0518 loss_train: 0.8845 acc_train: 0.7643 loss_val: 0.8584 acc_val: 0.8000 time: 0.0183s\n",
            "10\n",
            "Epoch: 0519 loss_train: 0.9220 acc_train: 0.7714 loss_val: 0.8555 acc_val: 0.8100 time: 0.0200s\n",
            "11\n",
            "Epoch: 0520 loss_train: 0.8917 acc_train: 0.7357 loss_val: 0.8518 acc_val: 0.8120 time: 0.0185s\n",
            "12\n",
            "Epoch: 0521 loss_train: 0.9269 acc_train: 0.7071 loss_val: 0.8486 acc_val: 0.8120 time: 0.0192s\n",
            "13\n",
            "Epoch: 0522 loss_train: 0.8366 acc_train: 0.7286 loss_val: 0.8450 acc_val: 0.8140 time: 0.0192s\n",
            "14\n",
            "Epoch: 0523 loss_train: 0.8627 acc_train: 0.7357 loss_val: 0.8426 acc_val: 0.8160 time: 0.0183s\n",
            "15\n",
            "Epoch: 0524 loss_train: 0.9527 acc_train: 0.7214 loss_val: 0.8417 acc_val: 0.8180 time: 0.0192s\n",
            "0\n",
            "Epoch: 0525 loss_train: 0.8551 acc_train: 0.7786 loss_val: 0.8422 acc_val: 0.8200 time: 0.0181s\n",
            "0\n",
            "Epoch: 0526 loss_train: 0.9095 acc_train: 0.7286 loss_val: 0.8440 acc_val: 0.8220 time: 0.0198s\n",
            "1\n",
            "Epoch: 0527 loss_train: 0.8176 acc_train: 0.7786 loss_val: 0.8459 acc_val: 0.8220 time: 0.0186s\n",
            "2\n",
            "Epoch: 0528 loss_train: 0.8305 acc_train: 0.7714 loss_val: 0.8498 acc_val: 0.8200 time: 0.0184s\n",
            "3\n",
            "Epoch: 0529 loss_train: 0.9147 acc_train: 0.7071 loss_val: 0.8553 acc_val: 0.8200 time: 0.0209s\n",
            "4\n",
            "Epoch: 0530 loss_train: 0.8700 acc_train: 0.7286 loss_val: 0.8623 acc_val: 0.8160 time: 0.0185s\n",
            "5\n",
            "Epoch: 0531 loss_train: 0.8861 acc_train: 0.7500 loss_val: 0.8668 acc_val: 0.8100 time: 0.0183s\n",
            "6\n",
            "Epoch: 0532 loss_train: 0.8631 acc_train: 0.7643 loss_val: 0.8683 acc_val: 0.8120 time: 0.0182s\n",
            "7\n",
            "Epoch: 0533 loss_train: 0.8978 acc_train: 0.7429 loss_val: 0.8651 acc_val: 0.8120 time: 0.0197s\n",
            "8\n",
            "Epoch: 0534 loss_train: 0.9316 acc_train: 0.7500 loss_val: 0.8615 acc_val: 0.8160 time: 0.0183s\n",
            "9\n",
            "Epoch: 0535 loss_train: 0.8837 acc_train: 0.7857 loss_val: 0.8564 acc_val: 0.8100 time: 0.0184s\n",
            "10\n",
            "Epoch: 0536 loss_train: 0.8528 acc_train: 0.7857 loss_val: 0.8488 acc_val: 0.8200 time: 0.0184s\n",
            "11\n",
            "Epoch: 0537 loss_train: 0.8652 acc_train: 0.7643 loss_val: 0.8450 acc_val: 0.8180 time: 0.0183s\n",
            "12\n",
            "Epoch: 0538 loss_train: 0.9539 acc_train: 0.7071 loss_val: 0.8455 acc_val: 0.8160 time: 0.0184s\n",
            "13\n",
            "Epoch: 0539 loss_train: 0.9145 acc_train: 0.7429 loss_val: 0.8494 acc_val: 0.8120 time: 0.0199s\n",
            "14\n",
            "Epoch: 0540 loss_train: 0.8357 acc_train: 0.7857 loss_val: 0.8496 acc_val: 0.8080 time: 0.0197s\n",
            "15\n",
            "Epoch: 0541 loss_train: 0.8634 acc_train: 0.7786 loss_val: 0.8485 acc_val: 0.8160 time: 0.0184s\n",
            "16\n",
            "Epoch: 0542 loss_train: 0.8757 acc_train: 0.7714 loss_val: 0.8486 acc_val: 0.8180 time: 0.0184s\n",
            "17\n",
            "Epoch: 0543 loss_train: 0.8051 acc_train: 0.8143 loss_val: 0.8482 acc_val: 0.8180 time: 0.0183s\n",
            "18\n",
            "Epoch: 0544 loss_train: 0.8320 acc_train: 0.7286 loss_val: 0.8485 acc_val: 0.8160 time: 0.0185s\n",
            "19\n",
            "Epoch: 0545 loss_train: 0.9025 acc_train: 0.7643 loss_val: 0.8514 acc_val: 0.8220 time: 0.0195s\n",
            "20\n",
            "Epoch: 0546 loss_train: 0.8883 acc_train: 0.7500 loss_val: 0.8566 acc_val: 0.8200 time: 0.0189s\n",
            "21\n",
            "Epoch: 0547 loss_train: 0.8614 acc_train: 0.8143 loss_val: 0.8607 acc_val: 0.8120 time: 0.0183s\n",
            "22\n",
            "Epoch: 0548 loss_train: 0.8764 acc_train: 0.7571 loss_val: 0.8606 acc_val: 0.8100 time: 0.0184s\n",
            "23\n",
            "Epoch: 0549 loss_train: 0.9844 acc_train: 0.7143 loss_val: 0.8577 acc_val: 0.8100 time: 0.0190s\n",
            "24\n",
            "Epoch: 0550 loss_train: 0.9038 acc_train: 0.7286 loss_val: 0.8499 acc_val: 0.8180 time: 0.0191s\n",
            "25\n",
            "Epoch: 0551 loss_train: 0.7915 acc_train: 0.8071 loss_val: 0.8423 acc_val: 0.8200 time: 0.0189s\n",
            "26\n",
            "Epoch: 0552 loss_train: 0.8700 acc_train: 0.7643 loss_val: 0.8400 acc_val: 0.8180 time: 0.0187s\n",
            "27\n",
            "Epoch: 0553 loss_train: 0.8093 acc_train: 0.7786 loss_val: 0.8380 acc_val: 0.8160 time: 0.0185s\n",
            "0\n",
            "Epoch: 0554 loss_train: 0.8840 acc_train: 0.7643 loss_val: 0.8334 acc_val: 0.8180 time: 0.0183s\n",
            "0\n",
            "Epoch: 0555 loss_train: 0.7686 acc_train: 0.8143 loss_val: 0.8268 acc_val: 0.8200 time: 0.0187s\n",
            "0\n",
            "Epoch: 0556 loss_train: 0.8765 acc_train: 0.6929 loss_val: 0.8258 acc_val: 0.8240 time: 0.0181s\n",
            "0\n",
            "Epoch: 0557 loss_train: 0.7849 acc_train: 0.7714 loss_val: 0.8285 acc_val: 0.8220 time: 0.0180s\n",
            "0\n",
            "Epoch: 0558 loss_train: 0.9435 acc_train: 0.7357 loss_val: 0.8334 acc_val: 0.8240 time: 0.0184s\n",
            "1\n",
            "Epoch: 0559 loss_train: 0.9851 acc_train: 0.7071 loss_val: 0.8393 acc_val: 0.8200 time: 0.0198s\n",
            "2\n",
            "Epoch: 0560 loss_train: 0.9140 acc_train: 0.7500 loss_val: 0.8431 acc_val: 0.8120 time: 0.0184s\n",
            "3\n",
            "Epoch: 0561 loss_train: 0.8816 acc_train: 0.7643 loss_val: 0.8420 acc_val: 0.8200 time: 0.0184s\n",
            "4\n",
            "Epoch: 0562 loss_train: 0.9116 acc_train: 0.7357 loss_val: 0.8430 acc_val: 0.8220 time: 0.0184s\n",
            "5\n",
            "Epoch: 0563 loss_train: 0.8581 acc_train: 0.7714 loss_val: 0.8450 acc_val: 0.8160 time: 0.0183s\n",
            "6\n",
            "Epoch: 0564 loss_train: 0.8894 acc_train: 0.7214 loss_val: 0.8477 acc_val: 0.8160 time: 0.0183s\n",
            "7\n",
            "Epoch: 0565 loss_train: 0.8612 acc_train: 0.8071 loss_val: 0.8483 acc_val: 0.8100 time: 0.0187s\n",
            "8\n",
            "Epoch: 0566 loss_train: 0.8177 acc_train: 0.7929 loss_val: 0.8484 acc_val: 0.8140 time: 0.0183s\n",
            "9\n",
            "Epoch: 0567 loss_train: 0.7942 acc_train: 0.7929 loss_val: 0.8430 acc_val: 0.8120 time: 0.0184s\n",
            "10\n",
            "Epoch: 0568 loss_train: 0.8024 acc_train: 0.8143 loss_val: 0.8377 acc_val: 0.8080 time: 0.0183s\n",
            "11\n",
            "Epoch: 0569 loss_train: 0.8898 acc_train: 0.7214 loss_val: 0.8355 acc_val: 0.8140 time: 0.0187s\n",
            "12\n",
            "Epoch: 0570 loss_train: 0.8754 acc_train: 0.7357 loss_val: 0.8393 acc_val: 0.8140 time: 0.0196s\n",
            "13\n",
            "Epoch: 0571 loss_train: 0.8288 acc_train: 0.8071 loss_val: 0.8423 acc_val: 0.8060 time: 0.0212s\n",
            "14\n",
            "Epoch: 0572 loss_train: 0.8972 acc_train: 0.7500 loss_val: 0.8493 acc_val: 0.8060 time: 0.0218s\n",
            "15\n",
            "Epoch: 0573 loss_train: 0.9184 acc_train: 0.7357 loss_val: 0.8555 acc_val: 0.8020 time: 0.0184s\n",
            "16\n",
            "Epoch: 0574 loss_train: 0.8358 acc_train: 0.7429 loss_val: 0.8586 acc_val: 0.8040 time: 0.0184s\n",
            "17\n",
            "Epoch: 0575 loss_train: 0.8925 acc_train: 0.7429 loss_val: 0.8570 acc_val: 0.8040 time: 0.0187s\n",
            "18\n",
            "Epoch: 0576 loss_train: 0.8616 acc_train: 0.7643 loss_val: 0.8513 acc_val: 0.8100 time: 0.0187s\n",
            "19\n",
            "Epoch: 0577 loss_train: 0.8138 acc_train: 0.7714 loss_val: 0.8430 acc_val: 0.8080 time: 0.0185s\n",
            "20\n",
            "Epoch: 0578 loss_train: 0.7997 acc_train: 0.8071 loss_val: 0.8313 acc_val: 0.8140 time: 0.0183s\n",
            "21\n",
            "Epoch: 0579 loss_train: 0.8918 acc_train: 0.7357 loss_val: 0.8219 acc_val: 0.8220 time: 0.0203s\n",
            "22\n",
            "Epoch: 0580 loss_train: 0.8868 acc_train: 0.7643 loss_val: 0.8132 acc_val: 0.8240 time: 0.0209s\n",
            "0\n",
            "Epoch: 0581 loss_train: 0.8776 acc_train: 0.7643 loss_val: 0.8129 acc_val: 0.8180 time: 0.0183s\n",
            "0\n",
            "Epoch: 0582 loss_train: 0.9124 acc_train: 0.7429 loss_val: 0.8181 acc_val: 0.8100 time: 0.0181s\n",
            "0\n",
            "Epoch: 0583 loss_train: 0.8954 acc_train: 0.7500 loss_val: 0.8256 acc_val: 0.8080 time: 0.0186s\n",
            "1\n",
            "Epoch: 0584 loss_train: 0.9692 acc_train: 0.6786 loss_val: 0.8355 acc_val: 0.8100 time: 0.0186s\n",
            "2\n",
            "Epoch: 0585 loss_train: 0.8363 acc_train: 0.7571 loss_val: 0.8445 acc_val: 0.8080 time: 0.0184s\n",
            "3\n",
            "Epoch: 0586 loss_train: 0.8497 acc_train: 0.7643 loss_val: 0.8521 acc_val: 0.8020 time: 0.0184s\n",
            "4\n",
            "Epoch: 0587 loss_train: 0.8204 acc_train: 0.8000 loss_val: 0.8562 acc_val: 0.8040 time: 0.0185s\n",
            "5\n",
            "Epoch: 0588 loss_train: 0.9660 acc_train: 0.6857 loss_val: 0.8562 acc_val: 0.8020 time: 0.0183s\n",
            "6\n",
            "Epoch: 0589 loss_train: 0.8860 acc_train: 0.7643 loss_val: 0.8548 acc_val: 0.8020 time: 0.0196s\n",
            "7\n",
            "Epoch: 0590 loss_train: 1.0150 acc_train: 0.6929 loss_val: 0.8531 acc_val: 0.8040 time: 0.0185s\n",
            "8\n",
            "Epoch: 0591 loss_train: 0.8597 acc_train: 0.7643 loss_val: 0.8526 acc_val: 0.8040 time: 0.0184s\n",
            "9\n",
            "Epoch: 0592 loss_train: 0.8495 acc_train: 0.7714 loss_val: 0.8514 acc_val: 0.8080 time: 0.0195s\n",
            "10\n",
            "Epoch: 0593 loss_train: 0.9047 acc_train: 0.7357 loss_val: 0.8502 acc_val: 0.8160 time: 0.0184s\n",
            "11\n",
            "Epoch: 0594 loss_train: 0.8034 acc_train: 0.7786 loss_val: 0.8463 acc_val: 0.8100 time: 0.0186s\n",
            "12\n",
            "Epoch: 0595 loss_train: 0.8512 acc_train: 0.7786 loss_val: 0.8458 acc_val: 0.8120 time: 0.0185s\n",
            "13\n",
            "Epoch: 0596 loss_train: 0.9138 acc_train: 0.7357 loss_val: 0.8448 acc_val: 0.8120 time: 0.0185s\n",
            "14\n",
            "Epoch: 0597 loss_train: 0.9953 acc_train: 0.7143 loss_val: 0.8435 acc_val: 0.8120 time: 0.0189s\n",
            "15\n",
            "Epoch: 0598 loss_train: 0.8899 acc_train: 0.7357 loss_val: 0.8411 acc_val: 0.8120 time: 0.0184s\n",
            "16\n",
            "Epoch: 0599 loss_train: 0.8707 acc_train: 0.7643 loss_val: 0.8392 acc_val: 0.8120 time: 0.0194s\n",
            "17\n",
            "Epoch: 0600 loss_train: 0.8435 acc_train: 0.7571 loss_val: 0.8354 acc_val: 0.8140 time: 0.0187s\n",
            "18\n",
            "Epoch: 0601 loss_train: 0.9243 acc_train: 0.7429 loss_val: 0.8324 acc_val: 0.8040 time: 0.0184s\n",
            "19\n",
            "Epoch: 0602 loss_train: 0.8227 acc_train: 0.7714 loss_val: 0.8328 acc_val: 0.8100 time: 0.0190s\n",
            "20\n",
            "Epoch: 0603 loss_train: 0.8246 acc_train: 0.8143 loss_val: 0.8358 acc_val: 0.8040 time: 0.0184s\n",
            "21\n",
            "Epoch: 0604 loss_train: 0.8400 acc_train: 0.7571 loss_val: 0.8384 acc_val: 0.8000 time: 0.0198s\n",
            "22\n",
            "Epoch: 0605 loss_train: 0.8908 acc_train: 0.7714 loss_val: 0.8435 acc_val: 0.8000 time: 0.0192s\n",
            "23\n",
            "Epoch: 0606 loss_train: 0.9097 acc_train: 0.7500 loss_val: 0.8463 acc_val: 0.8000 time: 0.0217s\n",
            "24\n",
            "Epoch: 0607 loss_train: 0.7583 acc_train: 0.8000 loss_val: 0.8456 acc_val: 0.8020 time: 0.0192s\n",
            "25\n",
            "Epoch: 0608 loss_train: 0.9308 acc_train: 0.7500 loss_val: 0.8426 acc_val: 0.8060 time: 0.0187s\n",
            "26\n",
            "Epoch: 0609 loss_train: 0.7475 acc_train: 0.8429 loss_val: 0.8395 acc_val: 0.8060 time: 0.0223s\n",
            "27\n",
            "Epoch: 0610 loss_train: 0.9234 acc_train: 0.7286 loss_val: 0.8357 acc_val: 0.8000 time: 0.0199s\n",
            "28\n",
            "Epoch: 0611 loss_train: 0.9543 acc_train: 0.7429 loss_val: 0.8334 acc_val: 0.8060 time: 0.0185s\n",
            "29\n",
            "Epoch: 0612 loss_train: 0.9412 acc_train: 0.7357 loss_val: 0.8295 acc_val: 0.8120 time: 0.0188s\n",
            "30\n",
            "Epoch: 0613 loss_train: 0.8954 acc_train: 0.7429 loss_val: 0.8266 acc_val: 0.8100 time: 0.0185s\n",
            "31\n",
            "Epoch: 0614 loss_train: 0.9883 acc_train: 0.6929 loss_val: 0.8299 acc_val: 0.8120 time: 0.0183s\n",
            "32\n",
            "Epoch: 0615 loss_train: 0.9288 acc_train: 0.7429 loss_val: 0.8361 acc_val: 0.8140 time: 0.0185s\n",
            "33\n",
            "Epoch: 0616 loss_train: 0.9070 acc_train: 0.7071 loss_val: 0.8447 acc_val: 0.8120 time: 0.0183s\n",
            "34\n",
            "Epoch: 0617 loss_train: 0.9180 acc_train: 0.7929 loss_val: 0.8537 acc_val: 0.8120 time: 0.0184s\n",
            "35\n",
            "Epoch: 0618 loss_train: 0.7818 acc_train: 0.8286 loss_val: 0.8625 acc_val: 0.8120 time: 0.0192s\n",
            "36\n",
            "Epoch: 0619 loss_train: 0.9502 acc_train: 0.7929 loss_val: 0.8639 acc_val: 0.8140 time: 0.0202s\n",
            "37\n",
            "Epoch: 0620 loss_train: 0.9952 acc_train: 0.6857 loss_val: 0.8587 acc_val: 0.8160 time: 0.0233s\n",
            "38\n",
            "Epoch: 0621 loss_train: 0.8811 acc_train: 0.7357 loss_val: 0.8471 acc_val: 0.8100 time: 0.0204s\n",
            "39\n",
            "Epoch: 0622 loss_train: 0.8113 acc_train: 0.7857 loss_val: 0.8341 acc_val: 0.8220 time: 0.0210s\n",
            "40\n",
            "Epoch: 0623 loss_train: 0.8722 acc_train: 0.7786 loss_val: 0.8274 acc_val: 0.8180 time: 0.0193s\n",
            "41\n",
            "Epoch: 0624 loss_train: 0.9251 acc_train: 0.7357 loss_val: 0.8216 acc_val: 0.8160 time: 0.0190s\n",
            "42\n",
            "Epoch: 0625 loss_train: 0.8669 acc_train: 0.7571 loss_val: 0.8215 acc_val: 0.8140 time: 0.0183s\n",
            "43\n",
            "Epoch: 0626 loss_train: 0.8570 acc_train: 0.8143 loss_val: 0.8239 acc_val: 0.8160 time: 0.0195s\n",
            "44\n",
            "Epoch: 0627 loss_train: 0.8298 acc_train: 0.7857 loss_val: 0.8261 acc_val: 0.8180 time: 0.0190s\n",
            "45\n",
            "Epoch: 0628 loss_train: 0.8913 acc_train: 0.7643 loss_val: 0.8295 acc_val: 0.8140 time: 0.0200s\n",
            "46\n",
            "Epoch: 0629 loss_train: 0.8896 acc_train: 0.7929 loss_val: 0.8370 acc_val: 0.8080 time: 0.0193s\n",
            "47\n",
            "Epoch: 0630 loss_train: 0.8180 acc_train: 0.7786 loss_val: 0.8439 acc_val: 0.8120 time: 0.0200s\n",
            "48\n",
            "Epoch: 0631 loss_train: 0.8401 acc_train: 0.7786 loss_val: 0.8443 acc_val: 0.8020 time: 0.0181s\n",
            "49\n",
            "Epoch: 0632 loss_train: 0.8194 acc_train: 0.7429 loss_val: 0.8413 acc_val: 0.8040 time: 0.0188s\n",
            "50\n",
            "Epoch: 0633 loss_train: 0.8570 acc_train: 0.6929 loss_val: 0.8380 acc_val: 0.8020 time: 0.0183s\n",
            "51\n",
            "Epoch: 0634 loss_train: 0.8403 acc_train: 0.7714 loss_val: 0.8380 acc_val: 0.8060 time: 0.0184s\n",
            "52\n",
            "Epoch: 0635 loss_train: 0.8808 acc_train: 0.7500 loss_val: 0.8375 acc_val: 0.8020 time: 0.0184s\n",
            "53\n",
            "Epoch: 0636 loss_train: 0.8092 acc_train: 0.7929 loss_val: 0.8375 acc_val: 0.8040 time: 0.0183s\n",
            "54\n",
            "Epoch: 0637 loss_train: 0.8686 acc_train: 0.7214 loss_val: 0.8358 acc_val: 0.8100 time: 0.0184s\n",
            "55\n",
            "Epoch: 0638 loss_train: 0.9198 acc_train: 0.7571 loss_val: 0.8299 acc_val: 0.8140 time: 0.0185s\n",
            "56\n",
            "Epoch: 0639 loss_train: 0.8755 acc_train: 0.7429 loss_val: 0.8240 acc_val: 0.8200 time: 0.0197s\n",
            "57\n",
            "Epoch: 0640 loss_train: 0.8871 acc_train: 0.7357 loss_val: 0.8204 acc_val: 0.8200 time: 0.0185s\n",
            "58\n",
            "Epoch: 0641 loss_train: 0.9315 acc_train: 0.7643 loss_val: 0.8214 acc_val: 0.8200 time: 0.0183s\n",
            "59\n",
            "Epoch: 0642 loss_train: 0.7959 acc_train: 0.7429 loss_val: 0.8194 acc_val: 0.8260 time: 0.0184s\n",
            "60\n",
            "Epoch: 0643 loss_train: 0.9074 acc_train: 0.7500 loss_val: 0.8216 acc_val: 0.8220 time: 0.0183s\n",
            "61\n",
            "Epoch: 0644 loss_train: 0.8514 acc_train: 0.7429 loss_val: 0.8218 acc_val: 0.8200 time: 0.0183s\n",
            "62\n",
            "Epoch: 0645 loss_train: 0.8797 acc_train: 0.7500 loss_val: 0.8267 acc_val: 0.8180 time: 0.0184s\n",
            "63\n",
            "Epoch: 0646 loss_train: 0.9389 acc_train: 0.7429 loss_val: 0.8308 acc_val: 0.8180 time: 0.0185s\n",
            "64\n",
            "Epoch: 0647 loss_train: 0.8775 acc_train: 0.7357 loss_val: 0.8294 acc_val: 0.8200 time: 0.0187s\n",
            "65\n",
            "Epoch: 0648 loss_train: 0.8667 acc_train: 0.8000 loss_val: 0.8296 acc_val: 0.8120 time: 0.0186s\n",
            "66\n",
            "Epoch: 0649 loss_train: 0.8784 acc_train: 0.7357 loss_val: 0.8285 acc_val: 0.8080 time: 0.0199s\n",
            "67\n",
            "Epoch: 0650 loss_train: 0.8425 acc_train: 0.7786 loss_val: 0.8298 acc_val: 0.8080 time: 0.0212s\n",
            "68\n",
            "Epoch: 0651 loss_train: 0.8819 acc_train: 0.7643 loss_val: 0.8306 acc_val: 0.8080 time: 0.0184s\n",
            "69\n",
            "Epoch: 0652 loss_train: 0.8822 acc_train: 0.7714 loss_val: 0.8302 acc_val: 0.8080 time: 0.0203s\n",
            "70\n",
            "Epoch: 0653 loss_train: 0.8051 acc_train: 0.8214 loss_val: 0.8281 acc_val: 0.8100 time: 0.0190s\n",
            "71\n",
            "Epoch: 0654 loss_train: 0.9619 acc_train: 0.7071 loss_val: 0.8263 acc_val: 0.8140 time: 0.0179s\n",
            "72\n",
            "Epoch: 0655 loss_train: 0.8102 acc_train: 0.7929 loss_val: 0.8269 acc_val: 0.8100 time: 0.0184s\n",
            "73\n",
            "Epoch: 0656 loss_train: 0.8441 acc_train: 0.7714 loss_val: 0.8294 acc_val: 0.8100 time: 0.0185s\n",
            "74\n",
            "Epoch: 0657 loss_train: 0.9450 acc_train: 0.7214 loss_val: 0.8405 acc_val: 0.8040 time: 0.0185s\n",
            "75\n",
            "Epoch: 0658 loss_train: 0.7624 acc_train: 0.7714 loss_val: 0.8487 acc_val: 0.8080 time: 0.0191s\n",
            "76\n",
            "Epoch: 0659 loss_train: 0.7917 acc_train: 0.8286 loss_val: 0.8563 acc_val: 0.8080 time: 0.0200s\n",
            "77\n",
            "Epoch: 0660 loss_train: 0.8216 acc_train: 0.7929 loss_val: 0.8582 acc_val: 0.8080 time: 0.0185s\n",
            "78\n",
            "Epoch: 0661 loss_train: 0.8904 acc_train: 0.7143 loss_val: 0.8589 acc_val: 0.8100 time: 0.0187s\n",
            "79\n",
            "Epoch: 0662 loss_train: 0.8731 acc_train: 0.7214 loss_val: 0.8520 acc_val: 0.8100 time: 0.0213s\n",
            "80\n",
            "Epoch: 0663 loss_train: 0.8225 acc_train: 0.7643 loss_val: 0.8442 acc_val: 0.8060 time: 0.0183s\n",
            "81\n",
            "Epoch: 0664 loss_train: 0.8873 acc_train: 0.6929 loss_val: 0.8343 acc_val: 0.8040 time: 0.0184s\n",
            "82\n",
            "Epoch: 0665 loss_train: 0.8343 acc_train: 0.7500 loss_val: 0.8244 acc_val: 0.8100 time: 0.0188s\n",
            "83\n",
            "Epoch: 0666 loss_train: 0.8618 acc_train: 0.7857 loss_val: 0.8157 acc_val: 0.8160 time: 0.0203s\n",
            "84\n",
            "Epoch: 0667 loss_train: 0.9089 acc_train: 0.7500 loss_val: 0.8110 acc_val: 0.8180 time: 0.0189s\n",
            "85\n",
            "Epoch: 0668 loss_train: 0.9289 acc_train: 0.7214 loss_val: 0.8067 acc_val: 0.8180 time: 0.0188s\n",
            "0\n",
            "Epoch: 0669 loss_train: 0.8286 acc_train: 0.7714 loss_val: 0.8068 acc_val: 0.8180 time: 0.0202s\n",
            "0\n",
            "Epoch: 0670 loss_train: 0.8954 acc_train: 0.7357 loss_val: 0.8112 acc_val: 0.8180 time: 0.0192s\n",
            "1\n",
            "Epoch: 0671 loss_train: 0.8173 acc_train: 0.7571 loss_val: 0.8184 acc_val: 0.8160 time: 0.0189s\n",
            "2\n",
            "Epoch: 0672 loss_train: 0.8102 acc_train: 0.7643 loss_val: 0.8288 acc_val: 0.8100 time: 0.0184s\n",
            "3\n",
            "Epoch: 0673 loss_train: 0.8172 acc_train: 0.7857 loss_val: 0.8392 acc_val: 0.8120 time: 0.0183s\n",
            "4\n",
            "Epoch: 0674 loss_train: 0.8616 acc_train: 0.7357 loss_val: 0.8511 acc_val: 0.7960 time: 0.0184s\n",
            "5\n",
            "Epoch: 0675 loss_train: 0.9247 acc_train: 0.7500 loss_val: 0.8630 acc_val: 0.7980 time: 0.0185s\n",
            "6\n",
            "Epoch: 0676 loss_train: 0.9422 acc_train: 0.7286 loss_val: 0.8746 acc_val: 0.8020 time: 0.0184s\n",
            "7\n",
            "Epoch: 0677 loss_train: 0.9384 acc_train: 0.7643 loss_val: 0.8782 acc_val: 0.8020 time: 0.0185s\n",
            "8\n",
            "Epoch: 0678 loss_train: 0.8195 acc_train: 0.7714 loss_val: 0.8730 acc_val: 0.8040 time: 0.0185s\n",
            "9\n",
            "Epoch: 0679 loss_train: 0.8568 acc_train: 0.7929 loss_val: 0.8619 acc_val: 0.7960 time: 0.0191s\n",
            "10\n",
            "Epoch: 0680 loss_train: 0.8376 acc_train: 0.8071 loss_val: 0.8488 acc_val: 0.8000 time: 0.0207s\n",
            "11\n",
            "Epoch: 0681 loss_train: 0.9023 acc_train: 0.7857 loss_val: 0.8347 acc_val: 0.8020 time: 0.0184s\n",
            "12\n",
            "Epoch: 0682 loss_train: 0.8283 acc_train: 0.7714 loss_val: 0.8238 acc_val: 0.8140 time: 0.0184s\n",
            "13\n",
            "Epoch: 0683 loss_train: 0.8466 acc_train: 0.7643 loss_val: 0.8143 acc_val: 0.8180 time: 0.0187s\n",
            "14\n",
            "Epoch: 0684 loss_train: 0.7453 acc_train: 0.8357 loss_val: 0.8072 acc_val: 0.8180 time: 0.0188s\n",
            "15\n",
            "Epoch: 0685 loss_train: 0.8725 acc_train: 0.7357 loss_val: 0.8028 acc_val: 0.8180 time: 0.0217s\n",
            "16\n",
            "Epoch: 0686 loss_train: 0.8688 acc_train: 0.7571 loss_val: 0.8017 acc_val: 0.8140 time: 0.0186s\n",
            "0\n",
            "Epoch: 0687 loss_train: 0.9369 acc_train: 0.7071 loss_val: 0.8024 acc_val: 0.8160 time: 0.0181s\n",
            "0\n",
            "Epoch: 0688 loss_train: 0.8894 acc_train: 0.7429 loss_val: 0.8070 acc_val: 0.8140 time: 0.0190s\n",
            "1\n",
            "Epoch: 0689 loss_train: 0.7891 acc_train: 0.7714 loss_val: 0.8096 acc_val: 0.8140 time: 0.0210s\n",
            "2\n",
            "Epoch: 0690 loss_train: 0.7708 acc_train: 0.7857 loss_val: 0.8133 acc_val: 0.8140 time: 0.0184s\n",
            "3\n",
            "Epoch: 0691 loss_train: 0.8591 acc_train: 0.7786 loss_val: 0.8177 acc_val: 0.8080 time: 0.0197s\n",
            "4\n",
            "Epoch: 0692 loss_train: 0.9116 acc_train: 0.7214 loss_val: 0.8271 acc_val: 0.8000 time: 0.0197s\n",
            "5\n",
            "Epoch: 0693 loss_train: 0.9307 acc_train: 0.7357 loss_val: 0.8375 acc_val: 0.7960 time: 0.0181s\n",
            "6\n",
            "Epoch: 0694 loss_train: 0.8872 acc_train: 0.7643 loss_val: 0.8468 acc_val: 0.7980 time: 0.0188s\n",
            "7\n",
            "Epoch: 0695 loss_train: 0.8415 acc_train: 0.8214 loss_val: 0.8504 acc_val: 0.7980 time: 0.0189s\n",
            "8\n",
            "Epoch: 0696 loss_train: 0.8847 acc_train: 0.7714 loss_val: 0.8514 acc_val: 0.7960 time: 0.0186s\n",
            "9\n",
            "Epoch: 0697 loss_train: 0.8549 acc_train: 0.7857 loss_val: 0.8479 acc_val: 0.8040 time: 0.0197s\n",
            "10\n",
            "Epoch: 0698 loss_train: 0.8997 acc_train: 0.7429 loss_val: 0.8474 acc_val: 0.8040 time: 0.0184s\n",
            "11\n",
            "Epoch: 0699 loss_train: 0.8883 acc_train: 0.7714 loss_val: 0.8438 acc_val: 0.8020 time: 0.0205s\n",
            "12\n",
            "Epoch: 0700 loss_train: 0.8346 acc_train: 0.8214 loss_val: 0.8370 acc_val: 0.8080 time: 0.0185s\n",
            "13\n",
            "Epoch: 0701 loss_train: 0.9009 acc_train: 0.7714 loss_val: 0.8308 acc_val: 0.8180 time: 0.0185s\n",
            "14\n",
            "Epoch: 0702 loss_train: 0.8972 acc_train: 0.7571 loss_val: 0.8259 acc_val: 0.8220 time: 0.0185s\n",
            "15\n",
            "Epoch: 0703 loss_train: 0.7602 acc_train: 0.7786 loss_val: 0.8204 acc_val: 0.8200 time: 0.0185s\n",
            "16\n",
            "Epoch: 0704 loss_train: 0.9086 acc_train: 0.7786 loss_val: 0.8178 acc_val: 0.8200 time: 0.0183s\n",
            "17\n",
            "Epoch: 0705 loss_train: 0.9152 acc_train: 0.7000 loss_val: 0.8188 acc_val: 0.8120 time: 0.0185s\n",
            "18\n",
            "Epoch: 0706 loss_train: 0.9055 acc_train: 0.7071 loss_val: 0.8189 acc_val: 0.8040 time: 0.0182s\n",
            "19\n",
            "Epoch: 0707 loss_train: 0.8310 acc_train: 0.7929 loss_val: 0.8199 acc_val: 0.8040 time: 0.0191s\n",
            "20\n",
            "Epoch: 0708 loss_train: 0.8427 acc_train: 0.8000 loss_val: 0.8224 acc_val: 0.8020 time: 0.0198s\n",
            "21\n",
            "Epoch: 0709 loss_train: 0.8153 acc_train: 0.8000 loss_val: 0.8228 acc_val: 0.8000 time: 0.0195s\n",
            "22\n",
            "Epoch: 0710 loss_train: 0.8187 acc_train: 0.7857 loss_val: 0.8199 acc_val: 0.8020 time: 0.0198s\n",
            "23\n",
            "Epoch: 0711 loss_train: 0.9054 acc_train: 0.6857 loss_val: 0.8179 acc_val: 0.8020 time: 0.0198s\n",
            "24\n",
            "Epoch: 0712 loss_train: 0.9363 acc_train: 0.7071 loss_val: 0.8135 acc_val: 0.8080 time: 0.0184s\n",
            "25\n",
            "Epoch: 0713 loss_train: 0.8494 acc_train: 0.7429 loss_val: 0.8102 acc_val: 0.8240 time: 0.0194s\n",
            "26\n",
            "Epoch: 0714 loss_train: 0.8611 acc_train: 0.7714 loss_val: 0.8078 acc_val: 0.8240 time: 0.0185s\n",
            "27\n",
            "Epoch: 0715 loss_train: 0.8549 acc_train: 0.7714 loss_val: 0.8058 acc_val: 0.8240 time: 0.0199s\n",
            "28\n",
            "Epoch: 0716 loss_train: 0.7554 acc_train: 0.8143 loss_val: 0.8067 acc_val: 0.8240 time: 0.0200s\n",
            "29\n",
            "Epoch: 0717 loss_train: 0.8385 acc_train: 0.8000 loss_val: 0.8104 acc_val: 0.8200 time: 0.0187s\n",
            "30\n",
            "Epoch: 0718 loss_train: 0.8011 acc_train: 0.7857 loss_val: 0.8174 acc_val: 0.8220 time: 0.0184s\n",
            "31\n",
            "Epoch: 0719 loss_train: 0.8140 acc_train: 0.8214 loss_val: 0.8233 acc_val: 0.8180 time: 0.0223s\n",
            "32\n",
            "Epoch: 0720 loss_train: 0.8443 acc_train: 0.7786 loss_val: 0.8302 acc_val: 0.8160 time: 0.0185s\n",
            "33\n",
            "Epoch: 0721 loss_train: 0.7960 acc_train: 0.7714 loss_val: 0.8353 acc_val: 0.8040 time: 0.0184s\n",
            "34\n",
            "Epoch: 0722 loss_train: 1.0092 acc_train: 0.6643 loss_val: 0.8420 acc_val: 0.8100 time: 0.0193s\n",
            "35\n",
            "Epoch: 0723 loss_train: 0.8578 acc_train: 0.7571 loss_val: 0.8494 acc_val: 0.8040 time: 0.0187s\n",
            "36\n",
            "Epoch: 0724 loss_train: 0.9486 acc_train: 0.7000 loss_val: 0.8538 acc_val: 0.8040 time: 0.0184s\n",
            "37\n",
            "Epoch: 0725 loss_train: 0.9175 acc_train: 0.7571 loss_val: 0.8540 acc_val: 0.8040 time: 0.0183s\n",
            "38\n",
            "Epoch: 0726 loss_train: 0.8395 acc_train: 0.7643 loss_val: 0.8495 acc_val: 0.8000 time: 0.0185s\n",
            "39\n",
            "Epoch: 0727 loss_train: 0.7805 acc_train: 0.8071 loss_val: 0.8408 acc_val: 0.7960 time: 0.0185s\n",
            "40\n",
            "Epoch: 0728 loss_train: 0.9361 acc_train: 0.7143 loss_val: 0.8297 acc_val: 0.8000 time: 0.0182s\n",
            "41\n",
            "Epoch: 0729 loss_train: 0.6878 acc_train: 0.8286 loss_val: 0.8167 acc_val: 0.8080 time: 0.0196s\n",
            "42\n",
            "Epoch: 0730 loss_train: 0.8775 acc_train: 0.7500 loss_val: 0.8098 acc_val: 0.8180 time: 0.0222s\n",
            "43\n",
            "Epoch: 0731 loss_train: 0.8705 acc_train: 0.7214 loss_val: 0.8113 acc_val: 0.8100 time: 0.0184s\n",
            "44\n",
            "Epoch: 0732 loss_train: 0.7708 acc_train: 0.8429 loss_val: 0.8080 acc_val: 0.8140 time: 0.0185s\n",
            "45\n",
            "Epoch: 0733 loss_train: 0.7820 acc_train: 0.7857 loss_val: 0.8038 acc_val: 0.8120 time: 0.0182s\n",
            "46\n",
            "Epoch: 0734 loss_train: 0.8596 acc_train: 0.7714 loss_val: 0.7988 acc_val: 0.8160 time: 0.0187s\n",
            "47\n",
            "Epoch: 0735 loss_train: 0.8558 acc_train: 0.7714 loss_val: 0.7982 acc_val: 0.8160 time: 0.0195s\n",
            "0\n",
            "Epoch: 0736 loss_train: 0.8849 acc_train: 0.7571 loss_val: 0.8006 acc_val: 0.8180 time: 0.0181s\n",
            "0\n",
            "Epoch: 0737 loss_train: 0.9418 acc_train: 0.7143 loss_val: 0.8070 acc_val: 0.8220 time: 0.0183s\n",
            "1\n",
            "Epoch: 0738 loss_train: 0.8010 acc_train: 0.7857 loss_val: 0.8162 acc_val: 0.8160 time: 0.0195s\n",
            "2\n",
            "Epoch: 0739 loss_train: 0.8593 acc_train: 0.7643 loss_val: 0.8242 acc_val: 0.8020 time: 0.0204s\n",
            "3\n",
            "Epoch: 0740 loss_train: 0.8203 acc_train: 0.7714 loss_val: 0.8288 acc_val: 0.8040 time: 0.0185s\n",
            "4\n",
            "Epoch: 0741 loss_train: 0.7250 acc_train: 0.8000 loss_val: 0.8296 acc_val: 0.8060 time: 0.0184s\n",
            "5\n",
            "Epoch: 0742 loss_train: 0.8979 acc_train: 0.7571 loss_val: 0.8261 acc_val: 0.8100 time: 0.0184s\n",
            "6\n",
            "Epoch: 0743 loss_train: 0.7994 acc_train: 0.7643 loss_val: 0.8201 acc_val: 0.8060 time: 0.0183s\n",
            "7\n",
            "Epoch: 0744 loss_train: 0.8172 acc_train: 0.7571 loss_val: 0.8122 acc_val: 0.8060 time: 0.0185s\n",
            "8\n",
            "Epoch: 0745 loss_train: 0.8229 acc_train: 0.7643 loss_val: 0.8037 acc_val: 0.8120 time: 0.0183s\n",
            "9\n",
            "Epoch: 0746 loss_train: 0.8564 acc_train: 0.7786 loss_val: 0.7991 acc_val: 0.8180 time: 0.0185s\n",
            "10\n",
            "Epoch: 0747 loss_train: 0.8502 acc_train: 0.7714 loss_val: 0.7961 acc_val: 0.8160 time: 0.0183s\n",
            "11\n",
            "Epoch: 0748 loss_train: 0.8530 acc_train: 0.7643 loss_val: 0.7937 acc_val: 0.8140 time: 0.0181s\n",
            "0\n",
            "Epoch: 0749 loss_train: 0.8323 acc_train: 0.7357 loss_val: 0.7951 acc_val: 0.8140 time: 0.0194s\n",
            "0\n",
            "Epoch: 0750 loss_train: 0.8392 acc_train: 0.7571 loss_val: 0.7982 acc_val: 0.8100 time: 0.0215s\n",
            "1\n",
            "Epoch: 0751 loss_train: 0.8679 acc_train: 0.7429 loss_val: 0.8054 acc_val: 0.8140 time: 0.0187s\n",
            "2\n",
            "Epoch: 0752 loss_train: 0.7563 acc_train: 0.7786 loss_val: 0.8181 acc_val: 0.8100 time: 0.0190s\n",
            "3\n",
            "Epoch: 0753 loss_train: 0.8400 acc_train: 0.7929 loss_val: 0.8304 acc_val: 0.8040 time: 0.0188s\n",
            "4\n",
            "Epoch: 0754 loss_train: 0.8066 acc_train: 0.8000 loss_val: 0.8404 acc_val: 0.7960 time: 0.0183s\n",
            "5\n",
            "Epoch: 0755 loss_train: 0.8577 acc_train: 0.7571 loss_val: 0.8428 acc_val: 0.7980 time: 0.0184s\n",
            "6\n",
            "Epoch: 0756 loss_train: 0.8784 acc_train: 0.7500 loss_val: 0.8380 acc_val: 0.8060 time: 0.0193s\n",
            "7\n",
            "Epoch: 0757 loss_train: 0.7958 acc_train: 0.8071 loss_val: 0.8325 acc_val: 0.8060 time: 0.0191s\n",
            "8\n",
            "Epoch: 0758 loss_train: 0.8968 acc_train: 0.7929 loss_val: 0.8232 acc_val: 0.8060 time: 0.0188s\n",
            "9\n",
            "Epoch: 0759 loss_train: 0.8674 acc_train: 0.7429 loss_val: 0.8119 acc_val: 0.8080 time: 0.0203s\n",
            "10\n",
            "Epoch: 0760 loss_train: 0.7875 acc_train: 0.8071 loss_val: 0.8021 acc_val: 0.8100 time: 0.0189s\n",
            "11\n",
            "Epoch: 0761 loss_train: 0.8784 acc_train: 0.7643 loss_val: 0.8016 acc_val: 0.8180 time: 0.0186s\n",
            "12\n",
            "Epoch: 0762 loss_train: 0.8693 acc_train: 0.7643 loss_val: 0.8023 acc_val: 0.8180 time: 0.0192s\n",
            "13\n",
            "Epoch: 0763 loss_train: 0.9615 acc_train: 0.7214 loss_val: 0.8040 acc_val: 0.8200 time: 0.0220s\n",
            "14\n",
            "Epoch: 0764 loss_train: 0.9005 acc_train: 0.7714 loss_val: 0.8068 acc_val: 0.8160 time: 0.0184s\n",
            "15\n",
            "Epoch: 0765 loss_train: 0.8647 acc_train: 0.7643 loss_val: 0.8131 acc_val: 0.8060 time: 0.0184s\n",
            "16\n",
            "Epoch: 0766 loss_train: 0.8909 acc_train: 0.7643 loss_val: 0.8186 acc_val: 0.8080 time: 0.0192s\n",
            "17\n",
            "Epoch: 0767 loss_train: 0.7853 acc_train: 0.7786 loss_val: 0.8268 acc_val: 0.8000 time: 0.0183s\n",
            "18\n",
            "Epoch: 0768 loss_train: 0.7923 acc_train: 0.7857 loss_val: 0.8382 acc_val: 0.7940 time: 0.0186s\n",
            "19\n",
            "Epoch: 0769 loss_train: 0.8482 acc_train: 0.7857 loss_val: 0.8468 acc_val: 0.7920 time: 0.0212s\n",
            "20\n",
            "Epoch: 0770 loss_train: 0.7734 acc_train: 0.7571 loss_val: 0.8472 acc_val: 0.7880 time: 0.0186s\n",
            "21\n",
            "Epoch: 0771 loss_train: 0.9313 acc_train: 0.7214 loss_val: 0.8434 acc_val: 0.7900 time: 0.0187s\n",
            "22\n",
            "Epoch: 0772 loss_train: 0.8407 acc_train: 0.7714 loss_val: 0.8343 acc_val: 0.7960 time: 0.0190s\n",
            "23\n",
            "Epoch: 0773 loss_train: 0.8358 acc_train: 0.7714 loss_val: 0.8237 acc_val: 0.8060 time: 0.0198s\n",
            "24\n",
            "Epoch: 0774 loss_train: 0.8247 acc_train: 0.7643 loss_val: 0.8143 acc_val: 0.8180 time: 0.0187s\n",
            "25\n",
            "Epoch: 0775 loss_train: 0.7950 acc_train: 0.8071 loss_val: 0.8078 acc_val: 0.8200 time: 0.0185s\n",
            "26\n",
            "Epoch: 0776 loss_train: 0.8672 acc_train: 0.7286 loss_val: 0.8032 acc_val: 0.8180 time: 0.0185s\n",
            "27\n",
            "Epoch: 0777 loss_train: 0.9167 acc_train: 0.7500 loss_val: 0.8003 acc_val: 0.8240 time: 0.0182s\n",
            "28\n",
            "Epoch: 0778 loss_train: 0.9392 acc_train: 0.7143 loss_val: 0.8012 acc_val: 0.8200 time: 0.0182s\n",
            "29\n",
            "Epoch: 0779 loss_train: 0.8661 acc_train: 0.7929 loss_val: 0.8019 acc_val: 0.8180 time: 0.0197s\n",
            "30\n",
            "Epoch: 0780 loss_train: 0.9107 acc_train: 0.7000 loss_val: 0.8071 acc_val: 0.8140 time: 0.0186s\n",
            "31\n",
            "Epoch: 0781 loss_train: 0.8741 acc_train: 0.7643 loss_val: 0.8121 acc_val: 0.8120 time: 0.0197s\n",
            "32\n",
            "Epoch: 0782 loss_train: 0.8564 acc_train: 0.7286 loss_val: 0.8206 acc_val: 0.8020 time: 0.0210s\n",
            "33\n",
            "Epoch: 0783 loss_train: 0.8244 acc_train: 0.7500 loss_val: 0.8297 acc_val: 0.8000 time: 0.0185s\n",
            "34\n",
            "Epoch: 0784 loss_train: 0.8503 acc_train: 0.7429 loss_val: 0.8391 acc_val: 0.7960 time: 0.0185s\n",
            "35\n",
            "Epoch: 0785 loss_train: 0.8279 acc_train: 0.8143 loss_val: 0.8441 acc_val: 0.7900 time: 0.0185s\n",
            "36\n",
            "Epoch: 0786 loss_train: 0.9446 acc_train: 0.7286 loss_val: 0.8459 acc_val: 0.7940 time: 0.0183s\n",
            "37\n",
            "Epoch: 0787 loss_train: 0.8459 acc_train: 0.7857 loss_val: 0.8362 acc_val: 0.8000 time: 0.0183s\n",
            "38\n",
            "Epoch: 0788 loss_train: 0.8938 acc_train: 0.7643 loss_val: 0.8217 acc_val: 0.8080 time: 0.0188s\n",
            "39\n",
            "Epoch: 0789 loss_train: 0.7836 acc_train: 0.7643 loss_val: 0.8081 acc_val: 0.8200 time: 0.0202s\n",
            "40\n",
            "Epoch: 0790 loss_train: 0.8954 acc_train: 0.6714 loss_val: 0.8017 acc_val: 0.8260 time: 0.0193s\n",
            "41\n",
            "Epoch: 0791 loss_train: 0.8650 acc_train: 0.7643 loss_val: 0.7973 acc_val: 0.8240 time: 0.0185s\n",
            "42\n",
            "Epoch: 0792 loss_train: 0.8358 acc_train: 0.7714 loss_val: 0.7962 acc_val: 0.8220 time: 0.0183s\n",
            "43\n",
            "Epoch: 0793 loss_train: 0.7899 acc_train: 0.7786 loss_val: 0.7944 acc_val: 0.8200 time: 0.0183s\n",
            "44\n",
            "Epoch: 0794 loss_train: 0.7890 acc_train: 0.7643 loss_val: 0.7975 acc_val: 0.8120 time: 0.0188s\n",
            "45\n",
            "Epoch: 0795 loss_train: 0.8475 acc_train: 0.7714 loss_val: 0.8008 acc_val: 0.8140 time: 0.0186s\n",
            "46\n",
            "Epoch: 0796 loss_train: 0.7996 acc_train: 0.7857 loss_val: 0.8082 acc_val: 0.8120 time: 0.0185s\n",
            "47\n",
            "Epoch: 0797 loss_train: 0.7855 acc_train: 0.7786 loss_val: 0.8175 acc_val: 0.8040 time: 0.0184s\n",
            "48\n",
            "Epoch: 0798 loss_train: 0.9173 acc_train: 0.7643 loss_val: 0.8265 acc_val: 0.7940 time: 0.0183s\n",
            "49\n",
            "Epoch: 0799 loss_train: 0.8624 acc_train: 0.7643 loss_val: 0.8273 acc_val: 0.7960 time: 0.0194s\n",
            "50\n",
            "Epoch: 0800 loss_train: 0.9135 acc_train: 0.6929 loss_val: 0.8286 acc_val: 0.8020 time: 0.0210s\n",
            "51\n",
            "Epoch: 0801 loss_train: 0.9911 acc_train: 0.6857 loss_val: 0.8317 acc_val: 0.8020 time: 0.0190s\n",
            "52\n",
            "Epoch: 0802 loss_train: 0.8928 acc_train: 0.7214 loss_val: 0.8321 acc_val: 0.8100 time: 0.0197s\n",
            "53\n",
            "Epoch: 0803 loss_train: 0.8147 acc_train: 0.8143 loss_val: 0.8297 acc_val: 0.8140 time: 0.0190s\n",
            "54\n",
            "Epoch: 0804 loss_train: 0.8505 acc_train: 0.7786 loss_val: 0.8323 acc_val: 0.8060 time: 0.0190s\n",
            "55\n",
            "Epoch: 0805 loss_train: 0.8595 acc_train: 0.7714 loss_val: 0.8382 acc_val: 0.8060 time: 0.0200s\n",
            "56\n",
            "Epoch: 0806 loss_train: 0.8543 acc_train: 0.8143 loss_val: 0.8385 acc_val: 0.8020 time: 0.0185s\n",
            "57\n",
            "Epoch: 0807 loss_train: 0.9270 acc_train: 0.7500 loss_val: 0.8341 acc_val: 0.8000 time: 0.0188s\n",
            "58\n",
            "Epoch: 0808 loss_train: 0.8085 acc_train: 0.7857 loss_val: 0.8257 acc_val: 0.8020 time: 0.0213s\n",
            "59\n",
            "Epoch: 0809 loss_train: 0.8717 acc_train: 0.7571 loss_val: 0.8171 acc_val: 0.8080 time: 0.0212s\n",
            "60\n",
            "Epoch: 0810 loss_train: 0.8404 acc_train: 0.7929 loss_val: 0.8123 acc_val: 0.8120 time: 0.0187s\n",
            "61\n",
            "Epoch: 0811 loss_train: 0.8069 acc_train: 0.8286 loss_val: 0.8100 acc_val: 0.8100 time: 0.0224s\n",
            "62\n",
            "Epoch: 0812 loss_train: 0.8264 acc_train: 0.8000 loss_val: 0.8101 acc_val: 0.8100 time: 0.0203s\n",
            "63\n",
            "Epoch: 0813 loss_train: 0.8228 acc_train: 0.7857 loss_val: 0.8107 acc_val: 0.8120 time: 0.0187s\n",
            "64\n",
            "Epoch: 0814 loss_train: 0.7747 acc_train: 0.7929 loss_val: 0.8129 acc_val: 0.8080 time: 0.0185s\n",
            "65\n",
            "Epoch: 0815 loss_train: 0.8365 acc_train: 0.7429 loss_val: 0.8166 acc_val: 0.8080 time: 0.0184s\n",
            "66\n",
            "Epoch: 0816 loss_train: 0.8391 acc_train: 0.7286 loss_val: 0.8206 acc_val: 0.8040 time: 0.0184s\n",
            "67\n",
            "Epoch: 0817 loss_train: 0.8926 acc_train: 0.7143 loss_val: 0.8316 acc_val: 0.7920 time: 0.0183s\n",
            "68\n",
            "Epoch: 0818 loss_train: 0.8810 acc_train: 0.7429 loss_val: 0.8358 acc_val: 0.7920 time: 0.0185s\n",
            "69\n",
            "Epoch: 0819 loss_train: 0.9406 acc_train: 0.6929 loss_val: 0.8360 acc_val: 0.7940 time: 0.0210s\n",
            "70\n",
            "Epoch: 0820 loss_train: 0.8634 acc_train: 0.8071 loss_val: 0.8336 acc_val: 0.7920 time: 0.0185s\n",
            "71\n",
            "Epoch: 0821 loss_train: 0.8926 acc_train: 0.7357 loss_val: 0.8310 acc_val: 0.7960 time: 0.0184s\n",
            "72\n",
            "Epoch: 0822 loss_train: 0.9013 acc_train: 0.7143 loss_val: 0.8249 acc_val: 0.8100 time: 0.0186s\n",
            "73\n",
            "Epoch: 0823 loss_train: 0.8490 acc_train: 0.7929 loss_val: 0.8182 acc_val: 0.8160 time: 0.0183s\n",
            "74\n",
            "Epoch: 0824 loss_train: 0.8650 acc_train: 0.7714 loss_val: 0.8125 acc_val: 0.8160 time: 0.0183s\n",
            "75\n",
            "Epoch: 0825 loss_train: 0.9138 acc_train: 0.7214 loss_val: 0.8089 acc_val: 0.8220 time: 0.0183s\n",
            "76\n",
            "Epoch: 0826 loss_train: 0.9212 acc_train: 0.7357 loss_val: 0.8073 acc_val: 0.8300 time: 0.0184s\n",
            "77\n",
            "Epoch: 0827 loss_train: 0.8397 acc_train: 0.7714 loss_val: 0.8075 acc_val: 0.8280 time: 0.0182s\n",
            "78\n",
            "Epoch: 0828 loss_train: 0.7193 acc_train: 0.8500 loss_val: 0.8085 acc_val: 0.8240 time: 0.0186s\n",
            "79\n",
            "Epoch: 0829 loss_train: 0.9339 acc_train: 0.7643 loss_val: 0.8125 acc_val: 0.8200 time: 0.0185s\n",
            "80\n",
            "Epoch: 0830 loss_train: 0.9414 acc_train: 0.7071 loss_val: 0.8192 acc_val: 0.8000 time: 0.0197s\n",
            "81\n",
            "Epoch: 0831 loss_train: 0.8638 acc_train: 0.7929 loss_val: 0.8288 acc_val: 0.8000 time: 0.0184s\n",
            "82\n",
            "Epoch: 0832 loss_train: 0.8344 acc_train: 0.7286 loss_val: 0.8390 acc_val: 0.7980 time: 0.0186s\n",
            "83\n",
            "Epoch: 0833 loss_train: 0.8274 acc_train: 0.7429 loss_val: 0.8443 acc_val: 0.7940 time: 0.0183s\n",
            "84\n",
            "Epoch: 0834 loss_train: 0.8819 acc_train: 0.7357 loss_val: 0.8460 acc_val: 0.7940 time: 0.0184s\n",
            "85\n",
            "Epoch: 0835 loss_train: 0.8163 acc_train: 0.8000 loss_val: 0.8417 acc_val: 0.7940 time: 0.0190s\n",
            "86\n",
            "Epoch: 0836 loss_train: 0.8418 acc_train: 0.7571 loss_val: 0.8295 acc_val: 0.7940 time: 0.0189s\n",
            "87\n",
            "Epoch: 0837 loss_train: 0.8438 acc_train: 0.7643 loss_val: 0.8172 acc_val: 0.8020 time: 0.0218s\n",
            "88\n",
            "Epoch: 0838 loss_train: 0.8775 acc_train: 0.8000 loss_val: 0.8069 acc_val: 0.8120 time: 0.0184s\n",
            "89\n",
            "Epoch: 0839 loss_train: 0.8550 acc_train: 0.7643 loss_val: 0.8007 acc_val: 0.8140 time: 0.0195s\n",
            "90\n",
            "Epoch: 0840 loss_train: 0.8054 acc_train: 0.7714 loss_val: 0.7976 acc_val: 0.8180 time: 0.0187s\n",
            "91\n",
            "Epoch: 0841 loss_train: 1.0141 acc_train: 0.6643 loss_val: 0.7979 acc_val: 0.8180 time: 0.0179s\n",
            "92\n",
            "Epoch: 0842 loss_train: 0.8464 acc_train: 0.7714 loss_val: 0.8003 acc_val: 0.8180 time: 0.0187s\n",
            "93\n",
            "Epoch: 0843 loss_train: 0.9144 acc_train: 0.7571 loss_val: 0.8067 acc_val: 0.8200 time: 0.0183s\n",
            "94\n",
            "Epoch: 0844 loss_train: 0.9007 acc_train: 0.7143 loss_val: 0.8167 acc_val: 0.8160 time: 0.0183s\n",
            "95\n",
            "Epoch: 0845 loss_train: 0.8187 acc_train: 0.7714 loss_val: 0.8253 acc_val: 0.8140 time: 0.0185s\n",
            "96\n",
            "Epoch: 0846 loss_train: 0.7835 acc_train: 0.8214 loss_val: 0.8318 acc_val: 0.8140 time: 0.0182s\n",
            "97\n",
            "Epoch: 0847 loss_train: 0.7741 acc_train: 0.8143 loss_val: 0.8339 acc_val: 0.8100 time: 0.0185s\n",
            "98\n",
            "Epoch: 0848 loss_train: 0.7905 acc_train: 0.8000 loss_val: 0.8322 acc_val: 0.8040 time: 0.0193s\n",
            "99\n",
            "Epoch: 0849 loss_train: 0.8725 acc_train: 0.7929 loss_val: 0.8275 acc_val: 0.8020 time: 0.0186s\n",
            "100\n",
            "Epoch: 0850 loss_train: 0.9501 acc_train: 0.7000 loss_val: 0.8230 acc_val: 0.8080 time: 0.0222s\n",
            "101\n",
            "Epoch: 0851 loss_train: 0.8304 acc_train: 0.7500 loss_val: 0.8149 acc_val: 0.8180 time: 0.0189s\n",
            "102\n",
            "Epoch: 0852 loss_train: 0.7741 acc_train: 0.8143 loss_val: 0.8066 acc_val: 0.8220 time: 0.0187s\n",
            "103\n",
            "Epoch: 0853 loss_train: 0.8973 acc_train: 0.7143 loss_val: 0.8003 acc_val: 0.8240 time: 0.0187s\n",
            "104\n",
            "Epoch: 0854 loss_train: 0.8648 acc_train: 0.7643 loss_val: 0.7970 acc_val: 0.8240 time: 0.0187s\n",
            "105\n",
            "Epoch: 0855 loss_train: 0.8217 acc_train: 0.7714 loss_val: 0.7964 acc_val: 0.8240 time: 0.0192s\n",
            "106\n",
            "Epoch: 0856 loss_train: 0.7706 acc_train: 0.7929 loss_val: 0.7991 acc_val: 0.8220 time: 0.0186s\n",
            "107\n",
            "Epoch: 0857 loss_train: 0.8130 acc_train: 0.7929 loss_val: 0.8037 acc_val: 0.8200 time: 0.0184s\n",
            "108\n",
            "Epoch: 0858 loss_train: 0.8500 acc_train: 0.7786 loss_val: 0.8074 acc_val: 0.8200 time: 0.0183s\n",
            "109\n",
            "Epoch: 0859 loss_train: 0.8550 acc_train: 0.7500 loss_val: 0.8112 acc_val: 0.8100 time: 0.0260s\n",
            "110\n",
            "Epoch: 0860 loss_train: 0.8589 acc_train: 0.7714 loss_val: 0.8160 acc_val: 0.8040 time: 0.0190s\n",
            "111\n",
            "Epoch: 0861 loss_train: 0.8526 acc_train: 0.7571 loss_val: 0.8179 acc_val: 0.8120 time: 0.0184s\n",
            "112\n",
            "Epoch: 0862 loss_train: 0.8198 acc_train: 0.8143 loss_val: 0.8183 acc_val: 0.8140 time: 0.0183s\n",
            "113\n",
            "Epoch: 0863 loss_train: 0.9119 acc_train: 0.6786 loss_val: 0.8180 acc_val: 0.8180 time: 0.0184s\n",
            "114\n",
            "Epoch: 0864 loss_train: 0.7813 acc_train: 0.8286 loss_val: 0.8160 acc_val: 0.8200 time: 0.0185s\n",
            "115\n",
            "Epoch: 0865 loss_train: 0.7608 acc_train: 0.8143 loss_val: 0.8185 acc_val: 0.8100 time: 0.0190s\n",
            "116\n",
            "Epoch: 0866 loss_train: 0.7978 acc_train: 0.8071 loss_val: 0.8182 acc_val: 0.8080 time: 0.0183s\n",
            "117\n",
            "Epoch: 0867 loss_train: 0.8393 acc_train: 0.7714 loss_val: 0.8157 acc_val: 0.8120 time: 0.0183s\n",
            "118\n",
            "Epoch: 0868 loss_train: 0.7953 acc_train: 0.8214 loss_val: 0.8106 acc_val: 0.8140 time: 0.0183s\n",
            "119\n",
            "Epoch: 0869 loss_train: 0.8463 acc_train: 0.7429 loss_val: 0.8049 acc_val: 0.8220 time: 0.0193s\n",
            "120\n",
            "Epoch: 0870 loss_train: 0.7751 acc_train: 0.8000 loss_val: 0.8033 acc_val: 0.8140 time: 0.0199s\n",
            "121\n",
            "Epoch: 0871 loss_train: 0.7683 acc_train: 0.8214 loss_val: 0.8026 acc_val: 0.8060 time: 0.0184s\n",
            "122\n",
            "Epoch: 0872 loss_train: 0.8570 acc_train: 0.7714 loss_val: 0.8038 acc_val: 0.8060 time: 0.0186s\n",
            "123\n",
            "Epoch: 0873 loss_train: 0.8160 acc_train: 0.7500 loss_val: 0.8079 acc_val: 0.8040 time: 0.0182s\n",
            "124\n",
            "Epoch: 0874 loss_train: 0.8247 acc_train: 0.7357 loss_val: 0.8122 acc_val: 0.8080 time: 0.0184s\n",
            "125\n",
            "Epoch: 0875 loss_train: 0.7159 acc_train: 0.8429 loss_val: 0.8142 acc_val: 0.8120 time: 0.0183s\n",
            "126\n",
            "Epoch: 0876 loss_train: 0.8488 acc_train: 0.7786 loss_val: 0.8164 acc_val: 0.8180 time: 0.0193s\n",
            "127\n",
            "Epoch: 0877 loss_train: 0.8623 acc_train: 0.7500 loss_val: 0.8205 acc_val: 0.8180 time: 0.0183s\n",
            "128\n",
            "Epoch: 0878 loss_train: 0.8321 acc_train: 0.7500 loss_val: 0.8259 acc_val: 0.8120 time: 0.0184s\n",
            "129\n",
            "Epoch: 0879 loss_train: 0.9749 acc_train: 0.7571 loss_val: 0.8291 acc_val: 0.8100 time: 0.0206s\n",
            "130\n",
            "Epoch: 0880 loss_train: 0.9306 acc_train: 0.7500 loss_val: 0.8287 acc_val: 0.8060 time: 0.0204s\n",
            "131\n",
            "Epoch: 0881 loss_train: 0.9276 acc_train: 0.7429 loss_val: 0.8289 acc_val: 0.8080 time: 0.0194s\n",
            "132\n",
            "Epoch: 0882 loss_train: 0.7983 acc_train: 0.7786 loss_val: 0.8250 acc_val: 0.8140 time: 0.0180s\n",
            "133\n",
            "Epoch: 0883 loss_train: 0.8097 acc_train: 0.7857 loss_val: 0.8229 acc_val: 0.8060 time: 0.0186s\n",
            "134\n",
            "Epoch: 0884 loss_train: 0.8701 acc_train: 0.7786 loss_val: 0.8208 acc_val: 0.7960 time: 0.0185s\n",
            "135\n",
            "Epoch: 0885 loss_train: 0.8270 acc_train: 0.8071 loss_val: 0.8171 acc_val: 0.7980 time: 0.0184s\n",
            "136\n",
            "Epoch: 0886 loss_train: 0.8263 acc_train: 0.7714 loss_val: 0.8118 acc_val: 0.8020 time: 0.0194s\n",
            "137\n",
            "Epoch: 0887 loss_train: 0.8563 acc_train: 0.8000 loss_val: 0.8043 acc_val: 0.8040 time: 0.0184s\n",
            "138\n",
            "Epoch: 0888 loss_train: 0.8265 acc_train: 0.7643 loss_val: 0.7955 acc_val: 0.8160 time: 0.0185s\n",
            "139\n",
            "Epoch: 0889 loss_train: 0.8454 acc_train: 0.7571 loss_val: 0.7900 acc_val: 0.8220 time: 0.0192s\n",
            "140\n",
            "Epoch: 0890 loss_train: 0.8471 acc_train: 0.7500 loss_val: 0.7891 acc_val: 0.8260 time: 0.0181s\n",
            "0\n",
            "Epoch: 0891 loss_train: 0.7600 acc_train: 0.7714 loss_val: 0.7895 acc_val: 0.8280 time: 0.0181s\n",
            "0\n",
            "Epoch: 0892 loss_train: 0.8610 acc_train: 0.7857 loss_val: 0.7935 acc_val: 0.8260 time: 0.0230s\n",
            "1\n",
            "Epoch: 0893 loss_train: 0.9191 acc_train: 0.6786 loss_val: 0.8003 acc_val: 0.8240 time: 0.0183s\n",
            "2\n",
            "Epoch: 0894 loss_train: 0.8848 acc_train: 0.7786 loss_val: 0.8043 acc_val: 0.8200 time: 0.0191s\n",
            "3\n",
            "Epoch: 0895 loss_train: 0.7974 acc_train: 0.7786 loss_val: 0.8120 acc_val: 0.8180 time: 0.0183s\n",
            "4\n",
            "Epoch: 0896 loss_train: 0.8974 acc_train: 0.7143 loss_val: 0.8196 acc_val: 0.8080 time: 0.0185s\n",
            "5\n",
            "Epoch: 0897 loss_train: 0.7401 acc_train: 0.7929 loss_val: 0.8264 acc_val: 0.8000 time: 0.0184s\n",
            "6\n",
            "Epoch: 0898 loss_train: 0.7552 acc_train: 0.8357 loss_val: 0.8266 acc_val: 0.8020 time: 0.0184s\n",
            "7\n",
            "Epoch: 0899 loss_train: 0.7920 acc_train: 0.8143 loss_val: 0.8235 acc_val: 0.8060 time: 0.0200s\n",
            "8\n",
            "Epoch: 0900 loss_train: 0.8663 acc_train: 0.7357 loss_val: 0.8134 acc_val: 0.8100 time: 0.0190s\n",
            "9\n",
            "Epoch: 0901 loss_train: 0.7694 acc_train: 0.7643 loss_val: 0.8061 acc_val: 0.8160 time: 0.0188s\n",
            "10\n",
            "Epoch: 0902 loss_train: 0.7986 acc_train: 0.7429 loss_val: 0.8001 acc_val: 0.8220 time: 0.0204s\n",
            "11\n",
            "Epoch: 0903 loss_train: 0.7839 acc_train: 0.8000 loss_val: 0.7949 acc_val: 0.8240 time: 0.0188s\n",
            "12\n",
            "Epoch: 0904 loss_train: 0.9081 acc_train: 0.7357 loss_val: 0.7926 acc_val: 0.8280 time: 0.0187s\n",
            "13\n",
            "Epoch: 0905 loss_train: 0.8590 acc_train: 0.7714 loss_val: 0.7926 acc_val: 0.8260 time: 0.0185s\n",
            "14\n",
            "Epoch: 0906 loss_train: 0.8019 acc_train: 0.7857 loss_val: 0.7932 acc_val: 0.8220 time: 0.0184s\n",
            "15\n",
            "Epoch: 0907 loss_train: 0.8352 acc_train: 0.7643 loss_val: 0.7937 acc_val: 0.8280 time: 0.0218s\n",
            "16\n",
            "Epoch: 0908 loss_train: 0.7309 acc_train: 0.8071 loss_val: 0.7919 acc_val: 0.8240 time: 0.0194s\n",
            "17\n",
            "Epoch: 0909 loss_train: 0.7508 acc_train: 0.7714 loss_val: 0.7918 acc_val: 0.8240 time: 0.0241s\n",
            "18\n",
            "Epoch: 0910 loss_train: 0.7336 acc_train: 0.8214 loss_val: 0.7952 acc_val: 0.8160 time: 0.0188s\n",
            "19\n",
            "Epoch: 0911 loss_train: 0.8899 acc_train: 0.7286 loss_val: 0.8003 acc_val: 0.8140 time: 0.0184s\n",
            "20\n",
            "Epoch: 0912 loss_train: 0.8087 acc_train: 0.7857 loss_val: 0.8056 acc_val: 0.8100 time: 0.0206s\n",
            "21\n",
            "Epoch: 0913 loss_train: 0.8438 acc_train: 0.7571 loss_val: 0.8085 acc_val: 0.8080 time: 0.0187s\n",
            "22\n",
            "Epoch: 0914 loss_train: 0.7959 acc_train: 0.8000 loss_val: 0.8052 acc_val: 0.8080 time: 0.0187s\n",
            "23\n",
            "Epoch: 0915 loss_train: 0.8166 acc_train: 0.8357 loss_val: 0.8016 acc_val: 0.8040 time: 0.0182s\n",
            "24\n",
            "Epoch: 0916 loss_train: 0.8322 acc_train: 0.7929 loss_val: 0.8000 acc_val: 0.8060 time: 0.0185s\n",
            "25\n",
            "Epoch: 0917 loss_train: 0.9664 acc_train: 0.6929 loss_val: 0.8026 acc_val: 0.8040 time: 0.0183s\n",
            "26\n",
            "Epoch: 0918 loss_train: 0.9123 acc_train: 0.7071 loss_val: 0.8063 acc_val: 0.8020 time: 0.0183s\n",
            "27\n",
            "Epoch: 0919 loss_train: 0.8026 acc_train: 0.7857 loss_val: 0.8101 acc_val: 0.8000 time: 0.0205s\n",
            "28\n",
            "Epoch: 0920 loss_train: 0.8184 acc_train: 0.8000 loss_val: 0.8132 acc_val: 0.8000 time: 0.0186s\n",
            "29\n",
            "Epoch: 0921 loss_train: 0.8440 acc_train: 0.8000 loss_val: 0.8145 acc_val: 0.8040 time: 0.0183s\n",
            "30\n",
            "Epoch: 0922 loss_train: 0.8683 acc_train: 0.7643 loss_val: 0.8164 acc_val: 0.8020 time: 0.0183s\n",
            "31\n",
            "Epoch: 0923 loss_train: 0.9046 acc_train: 0.7357 loss_val: 0.8202 acc_val: 0.8020 time: 0.0184s\n",
            "32\n",
            "Epoch: 0924 loss_train: 0.7957 acc_train: 0.7786 loss_val: 0.8230 acc_val: 0.8020 time: 0.0185s\n",
            "33\n",
            "Epoch: 0925 loss_train: 0.8421 acc_train: 0.7286 loss_val: 0.8242 acc_val: 0.8060 time: 0.0178s\n",
            "34\n",
            "Epoch: 0926 loss_train: 0.8533 acc_train: 0.8143 loss_val: 0.8210 acc_val: 0.8120 time: 0.0183s\n",
            "35\n",
            "Epoch: 0927 loss_train: 0.8006 acc_train: 0.7643 loss_val: 0.8170 acc_val: 0.8100 time: 0.0180s\n",
            "36\n",
            "Epoch: 0928 loss_train: 0.7937 acc_train: 0.8000 loss_val: 0.8120 acc_val: 0.8120 time: 0.0183s\n",
            "37\n",
            "Epoch: 0929 loss_train: 0.8297 acc_train: 0.7929 loss_val: 0.8046 acc_val: 0.8180 time: 0.0187s\n",
            "38\n",
            "Epoch: 0930 loss_train: 0.8854 acc_train: 0.7429 loss_val: 0.7976 acc_val: 0.8260 time: 0.0220s\n",
            "39\n",
            "Epoch: 0931 loss_train: 0.6936 acc_train: 0.8000 loss_val: 0.7949 acc_val: 0.8240 time: 0.0184s\n",
            "40\n",
            "Epoch: 0932 loss_train: 0.8020 acc_train: 0.8143 loss_val: 0.7965 acc_val: 0.8240 time: 0.0186s\n",
            "41\n",
            "Epoch: 0933 loss_train: 0.7747 acc_train: 0.7786 loss_val: 0.7994 acc_val: 0.8080 time: 0.0186s\n",
            "42\n",
            "Epoch: 0934 loss_train: 0.8447 acc_train: 0.7786 loss_val: 0.8019 acc_val: 0.8080 time: 0.0182s\n",
            "43\n",
            "Epoch: 0935 loss_train: 0.7847 acc_train: 0.8143 loss_val: 0.8052 acc_val: 0.8060 time: 0.0189s\n",
            "44\n",
            "Epoch: 0936 loss_train: 0.7644 acc_train: 0.7786 loss_val: 0.8110 acc_val: 0.8000 time: 0.0185s\n",
            "45\n",
            "Epoch: 0937 loss_train: 0.8600 acc_train: 0.7786 loss_val: 0.8123 acc_val: 0.8020 time: 0.0199s\n",
            "46\n",
            "Epoch: 0938 loss_train: 0.8057 acc_train: 0.7571 loss_val: 0.8137 acc_val: 0.8020 time: 0.0189s\n",
            "47\n",
            "Epoch: 0939 loss_train: 0.8153 acc_train: 0.8071 loss_val: 0.8172 acc_val: 0.8000 time: 0.0199s\n",
            "48\n",
            "Epoch: 0940 loss_train: 0.8715 acc_train: 0.7857 loss_val: 0.8189 acc_val: 0.8000 time: 0.0192s\n",
            "49\n",
            "Epoch: 0941 loss_train: 0.7407 acc_train: 0.8286 loss_val: 0.8221 acc_val: 0.8020 time: 0.0187s\n",
            "50\n",
            "Epoch: 0942 loss_train: 0.8992 acc_train: 0.7500 loss_val: 0.8231 acc_val: 0.8020 time: 0.0189s\n",
            "51\n",
            "Epoch: 0943 loss_train: 0.7307 acc_train: 0.8286 loss_val: 0.8173 acc_val: 0.8080 time: 0.0193s\n",
            "52\n",
            "Epoch: 0944 loss_train: 0.7887 acc_train: 0.7929 loss_val: 0.8104 acc_val: 0.8100 time: 0.0187s\n",
            "53\n",
            "Epoch: 0945 loss_train: 0.7297 acc_train: 0.8500 loss_val: 0.8041 acc_val: 0.8120 time: 0.0190s\n",
            "54\n",
            "Epoch: 0946 loss_train: 0.8131 acc_train: 0.7786 loss_val: 0.8006 acc_val: 0.8160 time: 0.0185s\n",
            "55\n",
            "Epoch: 0947 loss_train: 0.7929 acc_train: 0.8071 loss_val: 0.7986 acc_val: 0.8200 time: 0.0185s\n",
            "56\n",
            "Epoch: 0948 loss_train: 0.8864 acc_train: 0.6929 loss_val: 0.8020 acc_val: 0.8200 time: 0.0183s\n",
            "57\n",
            "Epoch: 0949 loss_train: 0.7596 acc_train: 0.8071 loss_val: 0.8029 acc_val: 0.8160 time: 0.0213s\n",
            "58\n",
            "Epoch: 0950 loss_train: 0.8944 acc_train: 0.7714 loss_val: 0.8028 acc_val: 0.8100 time: 0.0210s\n",
            "59\n",
            "Epoch: 0951 loss_train: 0.9109 acc_train: 0.7500 loss_val: 0.8060 acc_val: 0.8140 time: 0.0189s\n",
            "60\n",
            "Epoch: 0952 loss_train: 0.8352 acc_train: 0.7857 loss_val: 0.8087 acc_val: 0.8120 time: 0.0187s\n",
            "61\n",
            "Epoch: 0953 loss_train: 0.8230 acc_train: 0.8214 loss_val: 0.8100 acc_val: 0.8100 time: 0.0188s\n",
            "62\n",
            "Epoch: 0954 loss_train: 0.8056 acc_train: 0.7643 loss_val: 0.8105 acc_val: 0.8120 time: 0.0185s\n",
            "63\n",
            "Epoch: 0955 loss_train: 0.8930 acc_train: 0.7571 loss_val: 0.8103 acc_val: 0.8060 time: 0.0218s\n",
            "64\n",
            "Epoch: 0956 loss_train: 0.8236 acc_train: 0.7643 loss_val: 0.8089 acc_val: 0.8080 time: 0.0196s\n",
            "65\n",
            "Epoch: 0957 loss_train: 0.8996 acc_train: 0.7500 loss_val: 0.8126 acc_val: 0.8060 time: 0.0184s\n",
            "66\n",
            "Epoch: 0958 loss_train: 0.8819 acc_train: 0.7500 loss_val: 0.8193 acc_val: 0.8020 time: 0.0190s\n",
            "67\n",
            "Epoch: 0959 loss_train: 0.8907 acc_train: 0.7500 loss_val: 0.8183 acc_val: 0.8060 time: 0.0193s\n",
            "68\n",
            "Epoch: 0960 loss_train: 0.8960 acc_train: 0.7214 loss_val: 0.8171 acc_val: 0.8100 time: 0.0190s\n",
            "69\n",
            "Epoch: 0961 loss_train: 0.8364 acc_train: 0.7714 loss_val: 0.8140 acc_val: 0.8140 time: 0.0183s\n",
            "70\n",
            "Epoch: 0962 loss_train: 0.8785 acc_train: 0.7500 loss_val: 0.8102 acc_val: 0.8140 time: 0.0183s\n",
            "71\n",
            "Epoch: 0963 loss_train: 0.8308 acc_train: 0.7500 loss_val: 0.8064 acc_val: 0.8180 time: 0.0203s\n",
            "72\n",
            "Epoch: 0964 loss_train: 0.9240 acc_train: 0.7500 loss_val: 0.8045 acc_val: 0.8200 time: 0.0195s\n",
            "73\n",
            "Epoch: 0965 loss_train: 0.7906 acc_train: 0.8214 loss_val: 0.8069 acc_val: 0.8160 time: 0.0185s\n",
            "74\n",
            "Epoch: 0966 loss_train: 0.8792 acc_train: 0.7357 loss_val: 0.8072 acc_val: 0.8160 time: 0.0184s\n",
            "75\n",
            "Epoch: 0967 loss_train: 0.8150 acc_train: 0.7929 loss_val: 0.8060 acc_val: 0.8160 time: 0.0184s\n",
            "76\n",
            "Epoch: 0968 loss_train: 0.7821 acc_train: 0.8286 loss_val: 0.8064 acc_val: 0.8140 time: 0.0190s\n",
            "77\n",
            "Epoch: 0969 loss_train: 0.8715 acc_train: 0.7929 loss_val: 0.8049 acc_val: 0.8180 time: 0.0199s\n",
            "78\n",
            "Epoch: 0970 loss_train: 0.7834 acc_train: 0.8214 loss_val: 0.8027 acc_val: 0.8180 time: 0.0201s\n",
            "79\n",
            "Epoch: 0971 loss_train: 0.9380 acc_train: 0.6857 loss_val: 0.7989 acc_val: 0.8140 time: 0.0188s\n",
            "80\n",
            "Epoch: 0972 loss_train: 0.7926 acc_train: 0.7857 loss_val: 0.7989 acc_val: 0.8120 time: 0.0184s\n",
            "81\n",
            "Epoch: 0973 loss_train: 0.8638 acc_train: 0.7786 loss_val: 0.8000 acc_val: 0.8140 time: 0.0189s\n",
            "82\n",
            "Epoch: 0974 loss_train: 0.7322 acc_train: 0.8214 loss_val: 0.8011 acc_val: 0.8140 time: 0.0185s\n",
            "83\n",
            "Epoch: 0975 loss_train: 0.7978 acc_train: 0.8000 loss_val: 0.8035 acc_val: 0.8120 time: 0.0185s\n",
            "84\n",
            "Epoch: 0976 loss_train: 0.8191 acc_train: 0.7714 loss_val: 0.8078 acc_val: 0.8140 time: 0.0185s\n",
            "85\n",
            "Epoch: 0977 loss_train: 0.8729 acc_train: 0.7714 loss_val: 0.8120 acc_val: 0.8160 time: 0.0184s\n",
            "86\n",
            "Epoch: 0978 loss_train: 0.9084 acc_train: 0.7357 loss_val: 0.8178 acc_val: 0.8160 time: 0.0207s\n",
            "87\n",
            "Epoch: 0979 loss_train: 0.7778 acc_train: 0.8000 loss_val: 0.8226 acc_val: 0.8160 time: 0.0219s\n",
            "88\n",
            "Epoch: 0980 loss_train: 0.8128 acc_train: 0.7714 loss_val: 0.8257 acc_val: 0.8160 time: 0.0205s\n",
            "89\n",
            "Epoch: 0981 loss_train: 0.7981 acc_train: 0.8143 loss_val: 0.8259 acc_val: 0.8100 time: 0.0186s\n",
            "90\n",
            "Epoch: 0982 loss_train: 0.7709 acc_train: 0.8071 loss_val: 0.8270 acc_val: 0.8020 time: 0.0195s\n",
            "91\n",
            "Epoch: 0983 loss_train: 0.7948 acc_train: 0.8214 loss_val: 0.8240 acc_val: 0.8000 time: 0.0188s\n",
            "92\n",
            "Epoch: 0984 loss_train: 0.8279 acc_train: 0.7357 loss_val: 0.8195 acc_val: 0.8000 time: 0.0184s\n",
            "93\n",
            "Epoch: 0985 loss_train: 0.8721 acc_train: 0.7929 loss_val: 0.8162 acc_val: 0.7980 time: 0.0198s\n",
            "94\n",
            "Epoch: 0986 loss_train: 0.9648 acc_train: 0.6714 loss_val: 0.8107 acc_val: 0.8040 time: 0.0187s\n",
            "95\n",
            "Epoch: 0987 loss_train: 0.7645 acc_train: 0.8071 loss_val: 0.8028 acc_val: 0.8080 time: 0.0190s\n",
            "96\n",
            "Epoch: 0988 loss_train: 0.7986 acc_train: 0.7429 loss_val: 0.7956 acc_val: 0.8220 time: 0.0189s\n",
            "97\n",
            "Epoch: 0989 loss_train: 0.8509 acc_train: 0.7643 loss_val: 0.7900 acc_val: 0.8180 time: 0.0213s\n",
            "98\n",
            "Epoch: 0990 loss_train: 0.8088 acc_train: 0.7643 loss_val: 0.7839 acc_val: 0.8260 time: 0.0193s\n",
            "99\n",
            "Epoch: 0991 loss_train: 0.8013 acc_train: 0.7714 loss_val: 0.7798 acc_val: 0.8240 time: 0.0183s\n",
            "0\n",
            "Epoch: 0992 loss_train: 0.8915 acc_train: 0.7214 loss_val: 0.7824 acc_val: 0.8260 time: 0.0195s\n",
            "0\n",
            "Epoch: 0993 loss_train: 0.7462 acc_train: 0.7857 loss_val: 0.7881 acc_val: 0.8260 time: 0.0186s\n",
            "1\n",
            "Epoch: 0994 loss_train: 0.7147 acc_train: 0.8286 loss_val: 0.7915 acc_val: 0.8240 time: 0.0184s\n",
            "2\n",
            "Epoch: 0995 loss_train: 0.8477 acc_train: 0.7357 loss_val: 0.7986 acc_val: 0.8220 time: 0.0183s\n",
            "3\n",
            "Epoch: 0996 loss_train: 0.8931 acc_train: 0.7429 loss_val: 0.8102 acc_val: 0.8060 time: 0.0188s\n",
            "4\n",
            "Epoch: 0997 loss_train: 0.8191 acc_train: 0.7643 loss_val: 0.8226 acc_val: 0.8040 time: 0.0192s\n",
            "5\n",
            "Epoch: 0998 loss_train: 0.9018 acc_train: 0.7643 loss_val: 0.8307 acc_val: 0.8000 time: 0.0187s\n",
            "6\n",
            "Epoch: 0999 loss_train: 0.8662 acc_train: 0.7643 loss_val: 0.8422 acc_val: 0.7940 time: 0.0214s\n",
            "7\n",
            "Epoch: 1000 loss_train: 0.7925 acc_train: 0.7786 loss_val: 0.8517 acc_val: 0.7940 time: 0.0182s\n",
            "8\n",
            "Epoch: 1001 loss_train: 0.8379 acc_train: 0.7714 loss_val: 0.8512 acc_val: 0.7940 time: 0.0186s\n",
            "9\n",
            "Epoch: 1002 loss_train: 0.8453 acc_train: 0.7571 loss_val: 0.8426 acc_val: 0.7960 time: 0.0187s\n",
            "10\n",
            "Epoch: 1003 loss_train: 0.9239 acc_train: 0.7571 loss_val: 0.8256 acc_val: 0.8020 time: 0.0203s\n",
            "11\n",
            "Epoch: 1004 loss_train: 0.7912 acc_train: 0.7929 loss_val: 0.8071 acc_val: 0.8080 time: 0.0183s\n",
            "12\n",
            "Epoch: 1005 loss_train: 0.8413 acc_train: 0.7357 loss_val: 0.7911 acc_val: 0.8220 time: 0.0183s\n",
            "13\n",
            "Epoch: 1006 loss_train: 0.8230 acc_train: 0.7643 loss_val: 0.7813 acc_val: 0.8320 time: 0.0187s\n",
            "14\n",
            "Epoch: 1007 loss_train: 0.7955 acc_train: 0.8286 loss_val: 0.7755 acc_val: 0.8280 time: 0.0201s\n",
            "0\n",
            "Epoch: 1008 loss_train: 0.8125 acc_train: 0.7429 loss_val: 0.7743 acc_val: 0.8260 time: 0.0183s\n",
            "0\n",
            "Epoch: 1009 loss_train: 0.8233 acc_train: 0.7643 loss_val: 0.7753 acc_val: 0.8260 time: 0.0196s\n",
            "0\n",
            "Epoch: 1010 loss_train: 0.7501 acc_train: 0.7929 loss_val: 0.7765 acc_val: 0.8220 time: 0.0183s\n",
            "1\n",
            "Epoch: 1011 loss_train: 0.7974 acc_train: 0.7429 loss_val: 0.7816 acc_val: 0.8240 time: 0.0200s\n",
            "2\n",
            "Epoch: 1012 loss_train: 0.7889 acc_train: 0.7929 loss_val: 0.7925 acc_val: 0.8260 time: 0.0185s\n",
            "3\n",
            "Epoch: 1013 loss_train: 0.7658 acc_train: 0.8000 loss_val: 0.8035 acc_val: 0.8200 time: 0.0182s\n",
            "4\n",
            "Epoch: 1014 loss_train: 0.7553 acc_train: 0.7786 loss_val: 0.8151 acc_val: 0.8100 time: 0.0183s\n",
            "5\n",
            "Epoch: 1015 loss_train: 0.8188 acc_train: 0.7571 loss_val: 0.8338 acc_val: 0.8020 time: 0.0202s\n",
            "6\n",
            "Epoch: 1016 loss_train: 0.8360 acc_train: 0.7429 loss_val: 0.8455 acc_val: 0.7960 time: 0.0185s\n",
            "7\n",
            "Epoch: 1017 loss_train: 0.7979 acc_train: 0.8071 loss_val: 0.8460 acc_val: 0.7940 time: 0.0186s\n",
            "8\n",
            "Epoch: 1018 loss_train: 0.8839 acc_train: 0.7071 loss_val: 0.8386 acc_val: 0.7940 time: 0.0187s\n",
            "9\n",
            "Epoch: 1019 loss_train: 0.8071 acc_train: 0.7857 loss_val: 0.8280 acc_val: 0.7980 time: 0.0209s\n",
            "10\n",
            "Epoch: 1020 loss_train: 0.8123 acc_train: 0.8143 loss_val: 0.8158 acc_val: 0.8020 time: 0.0192s\n",
            "11\n",
            "Epoch: 1021 loss_train: 0.8415 acc_train: 0.7571 loss_val: 0.8046 acc_val: 0.8080 time: 0.0188s\n",
            "12\n",
            "Epoch: 1022 loss_train: 0.7864 acc_train: 0.7714 loss_val: 0.7938 acc_val: 0.8140 time: 0.0189s\n",
            "13\n",
            "Epoch: 1023 loss_train: 0.7469 acc_train: 0.7714 loss_val: 0.7844 acc_val: 0.8220 time: 0.0189s\n",
            "14\n",
            "Epoch: 1024 loss_train: 0.8161 acc_train: 0.7929 loss_val: 0.7766 acc_val: 0.8260 time: 0.0188s\n",
            "15\n",
            "Epoch: 1025 loss_train: 0.8116 acc_train: 0.7714 loss_val: 0.7715 acc_val: 0.8300 time: 0.0183s\n",
            "16\n",
            "Epoch: 1026 loss_train: 0.8485 acc_train: 0.8071 loss_val: 0.7717 acc_val: 0.8280 time: 0.0181s\n",
            "0\n",
            "Epoch: 1027 loss_train: 0.8807 acc_train: 0.7714 loss_val: 0.7750 acc_val: 0.8240 time: 0.0200s\n",
            "1\n",
            "Epoch: 1028 loss_train: 0.8120 acc_train: 0.7786 loss_val: 0.7823 acc_val: 0.8200 time: 0.0184s\n",
            "2\n",
            "Epoch: 1029 loss_train: 0.8728 acc_train: 0.7571 loss_val: 0.7919 acc_val: 0.8180 time: 0.0208s\n",
            "3\n",
            "Epoch: 1030 loss_train: 0.7478 acc_train: 0.8071 loss_val: 0.8042 acc_val: 0.8060 time: 0.0184s\n",
            "4\n",
            "Epoch: 1031 loss_train: 0.8964 acc_train: 0.7143 loss_val: 0.8169 acc_val: 0.8060 time: 0.0185s\n",
            "5\n",
            "Epoch: 1032 loss_train: 0.8197 acc_train: 0.7857 loss_val: 0.8254 acc_val: 0.8020 time: 0.0185s\n",
            "6\n",
            "Epoch: 1033 loss_train: 0.8529 acc_train: 0.7286 loss_val: 0.8308 acc_val: 0.8060 time: 0.0183s\n",
            "7\n",
            "Epoch: 1034 loss_train: 0.8434 acc_train: 0.7786 loss_val: 0.8319 acc_val: 0.8060 time: 0.0197s\n",
            "8\n",
            "Epoch: 1035 loss_train: 0.8332 acc_train: 0.7857 loss_val: 0.8282 acc_val: 0.8040 time: 0.0183s\n",
            "9\n",
            "Epoch: 1036 loss_train: 0.8071 acc_train: 0.7857 loss_val: 0.8208 acc_val: 0.8020 time: 0.0192s\n",
            "10\n",
            "Epoch: 1037 loss_train: 0.7785 acc_train: 0.7643 loss_val: 0.8108 acc_val: 0.8080 time: 0.0184s\n",
            "11\n",
            "Epoch: 1038 loss_train: 0.7686 acc_train: 0.8429 loss_val: 0.7975 acc_val: 0.8140 time: 0.0185s\n",
            "12\n",
            "Epoch: 1039 loss_train: 0.8240 acc_train: 0.7786 loss_val: 0.7870 acc_val: 0.8160 time: 0.0194s\n",
            "13\n",
            "Epoch: 1040 loss_train: 0.8604 acc_train: 0.7643 loss_val: 0.7835 acc_val: 0.8280 time: 0.0183s\n",
            "14\n",
            "Epoch: 1041 loss_train: 0.8575 acc_train: 0.7643 loss_val: 0.7847 acc_val: 0.8240 time: 0.0183s\n",
            "15\n",
            "Epoch: 1042 loss_train: 0.8230 acc_train: 0.7714 loss_val: 0.7842 acc_val: 0.8240 time: 0.0190s\n",
            "16\n",
            "Epoch: 1043 loss_train: 0.9185 acc_train: 0.6857 loss_val: 0.7870 acc_val: 0.8200 time: 0.0208s\n",
            "17\n",
            "Epoch: 1044 loss_train: 0.8038 acc_train: 0.8000 loss_val: 0.7918 acc_val: 0.8160 time: 0.0206s\n",
            "18\n",
            "Epoch: 1045 loss_train: 0.8286 acc_train: 0.7857 loss_val: 0.7935 acc_val: 0.8180 time: 0.0185s\n",
            "19\n",
            "Epoch: 1046 loss_train: 0.8511 acc_train: 0.7714 loss_val: 0.7976 acc_val: 0.8100 time: 0.0184s\n",
            "20\n",
            "Epoch: 1047 loss_train: 0.7841 acc_train: 0.7786 loss_val: 0.8062 acc_val: 0.8020 time: 0.0195s\n",
            "21\n",
            "Epoch: 1048 loss_train: 0.8279 acc_train: 0.7571 loss_val: 0.8105 acc_val: 0.8020 time: 0.0184s\n",
            "22\n",
            "Epoch: 1049 loss_train: 0.8346 acc_train: 0.7429 loss_val: 0.8127 acc_val: 0.8020 time: 0.0196s\n",
            "23\n",
            "Epoch: 1050 loss_train: 0.7054 acc_train: 0.8143 loss_val: 0.8147 acc_val: 0.8020 time: 0.0196s\n",
            "24\n",
            "Epoch: 1051 loss_train: 0.8795 acc_train: 0.7643 loss_val: 0.8143 acc_val: 0.8040 time: 0.0213s\n",
            "25\n",
            "Epoch: 1052 loss_train: 0.8449 acc_train: 0.7714 loss_val: 0.8093 acc_val: 0.8080 time: 0.0187s\n",
            "26\n",
            "Epoch: 1053 loss_train: 0.8145 acc_train: 0.8000 loss_val: 0.7977 acc_val: 0.8140 time: 0.0184s\n",
            "27\n",
            "Epoch: 1054 loss_train: 0.7934 acc_train: 0.7857 loss_val: 0.7902 acc_val: 0.8180 time: 0.0186s\n",
            "28\n",
            "Epoch: 1055 loss_train: 0.7840 acc_train: 0.8000 loss_val: 0.7872 acc_val: 0.8180 time: 0.0195s\n",
            "29\n",
            "Epoch: 1056 loss_train: 0.8629 acc_train: 0.7714 loss_val: 0.7862 acc_val: 0.8220 time: 0.0188s\n",
            "30\n",
            "Epoch: 1057 loss_train: 0.7390 acc_train: 0.8214 loss_val: 0.7882 acc_val: 0.8200 time: 0.0189s\n",
            "31\n",
            "Epoch: 1058 loss_train: 0.8617 acc_train: 0.7500 loss_val: 0.7886 acc_val: 0.8180 time: 0.0185s\n",
            "32\n",
            "Epoch: 1059 loss_train: 0.7736 acc_train: 0.7714 loss_val: 0.7875 acc_val: 0.8180 time: 0.0194s\n",
            "33\n",
            "Epoch: 1060 loss_train: 0.8823 acc_train: 0.7143 loss_val: 0.7867 acc_val: 0.8240 time: 0.0213s\n",
            "34\n",
            "Epoch: 1061 loss_train: 0.8864 acc_train: 0.7429 loss_val: 0.7920 acc_val: 0.8140 time: 0.0188s\n",
            "35\n",
            "Epoch: 1062 loss_train: 0.8314 acc_train: 0.7929 loss_val: 0.8003 acc_val: 0.8100 time: 0.0187s\n",
            "36\n",
            "Epoch: 1063 loss_train: 0.7815 acc_train: 0.7929 loss_val: 0.8092 acc_val: 0.8080 time: 0.0185s\n",
            "37\n",
            "Epoch: 1064 loss_train: 0.7696 acc_train: 0.8000 loss_val: 0.8183 acc_val: 0.8020 time: 0.0188s\n",
            "38\n",
            "Epoch: 1065 loss_train: 0.8096 acc_train: 0.7929 loss_val: 0.8195 acc_val: 0.8040 time: 0.0186s\n",
            "39\n",
            "Epoch: 1066 loss_train: 0.8590 acc_train: 0.7786 loss_val: 0.8154 acc_val: 0.8000 time: 0.0190s\n",
            "40\n",
            "Epoch: 1067 loss_train: 0.7869 acc_train: 0.8000 loss_val: 0.8102 acc_val: 0.8020 time: 0.0183s\n",
            "41\n",
            "Epoch: 1068 loss_train: 0.8940 acc_train: 0.7500 loss_val: 0.8022 acc_val: 0.8060 time: 0.0184s\n",
            "42\n",
            "Epoch: 1069 loss_train: 0.7985 acc_train: 0.8214 loss_val: 0.7940 acc_val: 0.8060 time: 0.0193s\n",
            "43\n",
            "Epoch: 1070 loss_train: 0.9092 acc_train: 0.7143 loss_val: 0.7906 acc_val: 0.8100 time: 0.0207s\n",
            "44\n",
            "Epoch: 1071 loss_train: 0.7794 acc_train: 0.8143 loss_val: 0.7890 acc_val: 0.8200 time: 0.0184s\n",
            "45\n",
            "Epoch: 1072 loss_train: 0.7414 acc_train: 0.8429 loss_val: 0.7884 acc_val: 0.8200 time: 0.0186s\n",
            "46\n",
            "Epoch: 1073 loss_train: 0.8454 acc_train: 0.7571 loss_val: 0.7916 acc_val: 0.8220 time: 0.0184s\n",
            "47\n",
            "Epoch: 1074 loss_train: 0.8061 acc_train: 0.7857 loss_val: 0.7945 acc_val: 0.8160 time: 0.0184s\n",
            "48\n",
            "Epoch: 1075 loss_train: 0.8320 acc_train: 0.7500 loss_val: 0.7932 acc_val: 0.8180 time: 0.0183s\n",
            "49\n",
            "Epoch: 1076 loss_train: 0.9205 acc_train: 0.7429 loss_val: 0.7922 acc_val: 0.8120 time: 0.0179s\n",
            "50\n",
            "Epoch: 1077 loss_train: 0.8077 acc_train: 0.7786 loss_val: 0.7917 acc_val: 0.8060 time: 0.0185s\n",
            "51\n",
            "Epoch: 1078 loss_train: 0.8334 acc_train: 0.7571 loss_val: 0.7948 acc_val: 0.8080 time: 0.0195s\n",
            "52\n",
            "Epoch: 1079 loss_train: 0.7359 acc_train: 0.8429 loss_val: 0.7976 acc_val: 0.8040 time: 0.0222s\n",
            "53\n",
            "Epoch: 1080 loss_train: 0.8466 acc_train: 0.7500 loss_val: 0.7997 acc_val: 0.8020 time: 0.0207s\n",
            "54\n",
            "Epoch: 1081 loss_train: 0.8518 acc_train: 0.7500 loss_val: 0.7997 acc_val: 0.7980 time: 0.0189s\n",
            "55\n",
            "Epoch: 1082 loss_train: 0.7554 acc_train: 0.8286 loss_val: 0.7946 acc_val: 0.8020 time: 0.0185s\n",
            "56\n",
            "Epoch: 1083 loss_train: 0.8531 acc_train: 0.8000 loss_val: 0.7885 acc_val: 0.8060 time: 0.0181s\n",
            "57\n",
            "Epoch: 1084 loss_train: 0.8352 acc_train: 0.7857 loss_val: 0.7836 acc_val: 0.8120 time: 0.0185s\n",
            "58\n",
            "Epoch: 1085 loss_train: 0.8741 acc_train: 0.7857 loss_val: 0.7820 acc_val: 0.8160 time: 0.0186s\n",
            "59\n",
            "Epoch: 1086 loss_train: 0.7953 acc_train: 0.8071 loss_val: 0.7832 acc_val: 0.8180 time: 0.0202s\n",
            "60\n",
            "Epoch: 1087 loss_train: 0.7757 acc_train: 0.7714 loss_val: 0.7825 acc_val: 0.8200 time: 0.0188s\n",
            "61\n",
            "Epoch: 1088 loss_train: 0.8093 acc_train: 0.7857 loss_val: 0.7863 acc_val: 0.8240 time: 0.0187s\n",
            "62\n",
            "Epoch: 1089 loss_train: 0.7885 acc_train: 0.7929 loss_val: 0.7905 acc_val: 0.8180 time: 0.0199s\n",
            "63\n",
            "Epoch: 1090 loss_train: 0.8418 acc_train: 0.7714 loss_val: 0.7965 acc_val: 0.8160 time: 0.0184s\n",
            "64\n",
            "Epoch: 1091 loss_train: 0.8826 acc_train: 0.7857 loss_val: 0.7978 acc_val: 0.8140 time: 0.0194s\n",
            "65\n",
            "Epoch: 1092 loss_train: 0.8344 acc_train: 0.7643 loss_val: 0.8005 acc_val: 0.8100 time: 0.0185s\n",
            "66\n",
            "Epoch: 1093 loss_train: 0.8236 acc_train: 0.7571 loss_val: 0.8049 acc_val: 0.8100 time: 0.0185s\n",
            "67\n",
            "Epoch: 1094 loss_train: 0.8664 acc_train: 0.7357 loss_val: 0.8070 acc_val: 0.8040 time: 0.0185s\n",
            "68\n",
            "Epoch: 1095 loss_train: 0.9014 acc_train: 0.7500 loss_val: 0.8066 acc_val: 0.8020 time: 0.0186s\n",
            "69\n",
            "Epoch: 1096 loss_train: 0.8171 acc_train: 0.7857 loss_val: 0.8035 acc_val: 0.8020 time: 0.0188s\n",
            "70\n",
            "Epoch: 1097 loss_train: 0.7820 acc_train: 0.8071 loss_val: 0.7954 acc_val: 0.8020 time: 0.0187s\n",
            "71\n",
            "Epoch: 1098 loss_train: 0.8176 acc_train: 0.7786 loss_val: 0.7874 acc_val: 0.8100 time: 0.0193s\n",
            "72\n",
            "Epoch: 1099 loss_train: 0.8334 acc_train: 0.7643 loss_val: 0.7799 acc_val: 0.8140 time: 0.0238s\n",
            "73\n",
            "Epoch: 1100 loss_train: 0.8716 acc_train: 0.8000 loss_val: 0.7762 acc_val: 0.8160 time: 0.0188s\n",
            "74\n",
            "Epoch: 1101 loss_train: 0.9308 acc_train: 0.7143 loss_val: 0.7791 acc_val: 0.8100 time: 0.0185s\n",
            "75\n",
            "Epoch: 1102 loss_train: 0.7498 acc_train: 0.7929 loss_val: 0.7832 acc_val: 0.8060 time: 0.0191s\n",
            "76\n",
            "Epoch: 1103 loss_train: 0.8149 acc_train: 0.7643 loss_val: 0.7846 acc_val: 0.8100 time: 0.0187s\n",
            "77\n",
            "Epoch: 1104 loss_train: 0.7760 acc_train: 0.7857 loss_val: 0.7882 acc_val: 0.8120 time: 0.0185s\n",
            "78\n",
            "Epoch: 1105 loss_train: 0.8929 acc_train: 0.7143 loss_val: 0.7911 acc_val: 0.8120 time: 0.0187s\n",
            "79\n",
            "Epoch: 1106 loss_train: 0.8459 acc_train: 0.7429 loss_val: 0.7941 acc_val: 0.8100 time: 0.0187s\n",
            "80\n",
            "Epoch: 1107 loss_train: 0.8412 acc_train: 0.7643 loss_val: 0.7937 acc_val: 0.8080 time: 0.0183s\n",
            "81\n",
            "Epoch: 1108 loss_train: 0.8068 acc_train: 0.7714 loss_val: 0.7945 acc_val: 0.8080 time: 0.0185s\n",
            "82\n",
            "Epoch: 1109 loss_train: 0.8416 acc_train: 0.7929 loss_val: 0.7962 acc_val: 0.8100 time: 0.0192s\n",
            "83\n",
            "Epoch: 1110 loss_train: 0.7795 acc_train: 0.8286 loss_val: 0.7937 acc_val: 0.8060 time: 0.0205s\n",
            "84\n",
            "Epoch: 1111 loss_train: 0.7890 acc_train: 0.7643 loss_val: 0.7896 acc_val: 0.8060 time: 0.0187s\n",
            "85\n",
            "Epoch: 1112 loss_train: 0.8224 acc_train: 0.7429 loss_val: 0.7871 acc_val: 0.8060 time: 0.0188s\n",
            "86\n",
            "Epoch: 1113 loss_train: 0.9140 acc_train: 0.7429 loss_val: 0.7821 acc_val: 0.8100 time: 0.0188s\n",
            "87\n",
            "Epoch: 1114 loss_train: 0.8920 acc_train: 0.7571 loss_val: 0.7786 acc_val: 0.8120 time: 0.0188s\n",
            "88\n",
            "Epoch: 1115 loss_train: 0.7791 acc_train: 0.7714 loss_val: 0.7757 acc_val: 0.8140 time: 0.0184s\n",
            "89\n",
            "Epoch: 1116 loss_train: 0.8398 acc_train: 0.7857 loss_val: 0.7794 acc_val: 0.8140 time: 0.0186s\n",
            "90\n",
            "Epoch: 1117 loss_train: 0.7714 acc_train: 0.8214 loss_val: 0.7865 acc_val: 0.8140 time: 0.0189s\n",
            "91\n",
            "Epoch: 1118 loss_train: 0.8759 acc_train: 0.8143 loss_val: 0.7949 acc_val: 0.8120 time: 0.0182s\n",
            "92\n",
            "Epoch: 1119 loss_train: 0.9057 acc_train: 0.7500 loss_val: 0.8048 acc_val: 0.8060 time: 0.0192s\n",
            "93\n",
            "Epoch: 1120 loss_train: 0.7365 acc_train: 0.8214 loss_val: 0.8106 acc_val: 0.8040 time: 0.0196s\n",
            "94\n",
            "Epoch: 1121 loss_train: 0.7498 acc_train: 0.7929 loss_val: 0.8137 acc_val: 0.8020 time: 0.0183s\n",
            "95\n",
            "Epoch: 1122 loss_train: 0.7594 acc_train: 0.8143 loss_val: 0.8104 acc_val: 0.8000 time: 0.0204s\n",
            "96\n",
            "Epoch: 1123 loss_train: 0.8572 acc_train: 0.7429 loss_val: 0.8079 acc_val: 0.8020 time: 0.0188s\n",
            "97\n",
            "Epoch: 1124 loss_train: 0.7972 acc_train: 0.7571 loss_val: 0.8034 acc_val: 0.8040 time: 0.0186s\n",
            "98\n",
            "Epoch: 1125 loss_train: 0.8157 acc_train: 0.7571 loss_val: 0.7938 acc_val: 0.8020 time: 0.0184s\n",
            "99\n",
            "Epoch: 1126 loss_train: 0.9027 acc_train: 0.7214 loss_val: 0.7860 acc_val: 0.8060 time: 0.0197s\n",
            "100\n",
            "Epoch: 1127 loss_train: 0.8600 acc_train: 0.7429 loss_val: 0.7819 acc_val: 0.8120 time: 0.0183s\n",
            "101\n",
            "Epoch: 1128 loss_train: 0.7027 acc_train: 0.8214 loss_val: 0.7796 acc_val: 0.8100 time: 0.0182s\n",
            "102\n",
            "Epoch: 1129 loss_train: 0.8230 acc_train: 0.7571 loss_val: 0.7785 acc_val: 0.8180 time: 0.0201s\n",
            "103\n",
            "Epoch: 1130 loss_train: 0.8581 acc_train: 0.7500 loss_val: 0.7811 acc_val: 0.8140 time: 0.0209s\n",
            "104\n",
            "Epoch: 1131 loss_train: 0.9079 acc_train: 0.7357 loss_val: 0.7849 acc_val: 0.8180 time: 0.0189s\n",
            "105\n",
            "Epoch: 1132 loss_train: 0.9138 acc_train: 0.7143 loss_val: 0.7883 acc_val: 0.8140 time: 0.0190s\n",
            "106\n",
            "Epoch: 1133 loss_train: 0.6709 acc_train: 0.8214 loss_val: 0.7884 acc_val: 0.8180 time: 0.0206s\n",
            "107\n",
            "Epoch: 1134 loss_train: 0.7814 acc_train: 0.8000 loss_val: 0.7889 acc_val: 0.8200 time: 0.0188s\n",
            "108\n",
            "Epoch: 1135 loss_train: 0.8157 acc_train: 0.7786 loss_val: 0.7910 acc_val: 0.8180 time: 0.0188s\n",
            "109\n",
            "Epoch: 1136 loss_train: 0.7595 acc_train: 0.8500 loss_val: 0.7935 acc_val: 0.8140 time: 0.0185s\n",
            "110\n",
            "Epoch: 1137 loss_train: 0.7584 acc_train: 0.8214 loss_val: 0.7940 acc_val: 0.8100 time: 0.0184s\n",
            "111\n",
            "Epoch: 1138 loss_train: 0.7384 acc_train: 0.8500 loss_val: 0.7910 acc_val: 0.8080 time: 0.0192s\n",
            "112\n",
            "Epoch: 1139 loss_train: 0.7588 acc_train: 0.8357 loss_val: 0.7894 acc_val: 0.8140 time: 0.0212s\n",
            "113\n",
            "Epoch: 1140 loss_train: 0.7684 acc_train: 0.8214 loss_val: 0.7862 acc_val: 0.8140 time: 0.0185s\n",
            "114\n",
            "Epoch: 1141 loss_train: 0.8397 acc_train: 0.7000 loss_val: 0.7877 acc_val: 0.8160 time: 0.0184s\n",
            "115\n",
            "Epoch: 1142 loss_train: 0.7686 acc_train: 0.8000 loss_val: 0.7890 acc_val: 0.8160 time: 0.0196s\n",
            "116\n",
            "Epoch: 1143 loss_train: 0.8541 acc_train: 0.7357 loss_val: 0.7937 acc_val: 0.8180 time: 0.0185s\n",
            "117\n",
            "Epoch: 1144 loss_train: 0.6734 acc_train: 0.8071 loss_val: 0.7952 acc_val: 0.8140 time: 0.0184s\n",
            "118\n",
            "Epoch: 1145 loss_train: 0.8304 acc_train: 0.7857 loss_val: 0.7957 acc_val: 0.8140 time: 0.0198s\n",
            "119\n",
            "Epoch: 1146 loss_train: 0.7254 acc_train: 0.8214 loss_val: 0.7969 acc_val: 0.8120 time: 0.0189s\n",
            "120\n",
            "Epoch: 1147 loss_train: 0.7367 acc_train: 0.8143 loss_val: 0.7977 acc_val: 0.8060 time: 0.0202s\n",
            "121\n",
            "Epoch: 1148 loss_train: 0.8064 acc_train: 0.7571 loss_val: 0.8008 acc_val: 0.8080 time: 0.0185s\n",
            "122\n",
            "Epoch: 1149 loss_train: 0.7394 acc_train: 0.7714 loss_val: 0.7989 acc_val: 0.8040 time: 0.0192s\n",
            "123\n",
            "Epoch: 1150 loss_train: 0.7489 acc_train: 0.8143 loss_val: 0.7941 acc_val: 0.8100 time: 0.0204s\n",
            "124\n",
            "Epoch: 1151 loss_train: 0.7897 acc_train: 0.7857 loss_val: 0.7876 acc_val: 0.8140 time: 0.0185s\n",
            "125\n",
            "Epoch: 1152 loss_train: 0.9176 acc_train: 0.7143 loss_val: 0.7849 acc_val: 0.8180 time: 0.0187s\n",
            "126\n",
            "Epoch: 1153 loss_train: 0.8555 acc_train: 0.7500 loss_val: 0.7876 acc_val: 0.8220 time: 0.0183s\n",
            "127\n",
            "Epoch: 1154 loss_train: 0.8622 acc_train: 0.7500 loss_val: 0.7952 acc_val: 0.8200 time: 0.0185s\n",
            "128\n",
            "Epoch: 1155 loss_train: 0.8503 acc_train: 0.7857 loss_val: 0.8036 acc_val: 0.8120 time: 0.0182s\n",
            "129\n",
            "Epoch: 1156 loss_train: 0.7962 acc_train: 0.8214 loss_val: 0.8114 acc_val: 0.8120 time: 0.0184s\n",
            "130\n",
            "Epoch: 1157 loss_train: 0.8351 acc_train: 0.7857 loss_val: 0.8275 acc_val: 0.8040 time: 0.0184s\n",
            "131\n",
            "Epoch: 1158 loss_train: 0.7747 acc_train: 0.8214 loss_val: 0.8435 acc_val: 0.7960 time: 0.0183s\n",
            "132\n",
            "Epoch: 1159 loss_train: 0.8428 acc_train: 0.8214 loss_val: 0.8493 acc_val: 0.8000 time: 0.0191s\n",
            "133\n",
            "Epoch: 1160 loss_train: 0.8824 acc_train: 0.7429 loss_val: 0.8450 acc_val: 0.7980 time: 0.0203s\n",
            "134\n",
            "Epoch: 1161 loss_train: 0.7978 acc_train: 0.7643 loss_val: 0.8305 acc_val: 0.7960 time: 0.0195s\n",
            "135\n",
            "Epoch: 1162 loss_train: 0.7813 acc_train: 0.7786 loss_val: 0.8125 acc_val: 0.7980 time: 0.0199s\n",
            "136\n",
            "Epoch: 1163 loss_train: 0.8714 acc_train: 0.8000 loss_val: 0.7957 acc_val: 0.8040 time: 0.0201s\n",
            "137\n",
            "Epoch: 1164 loss_train: 0.8212 acc_train: 0.7714 loss_val: 0.7808 acc_val: 0.8080 time: 0.0189s\n",
            "138\n",
            "Epoch: 1165 loss_train: 0.7354 acc_train: 0.7929 loss_val: 0.7708 acc_val: 0.8140 time: 0.0195s\n",
            "139\n",
            "Epoch: 1166 loss_train: 0.8279 acc_train: 0.7429 loss_val: 0.7655 acc_val: 0.8220 time: 0.0181s\n",
            "0\n",
            "Epoch: 1167 loss_train: 0.8375 acc_train: 0.7857 loss_val: 0.7608 acc_val: 0.8240 time: 0.0181s\n",
            "0\n",
            "Epoch: 1168 loss_train: 0.8081 acc_train: 0.7714 loss_val: 0.7594 acc_val: 0.8220 time: 0.0181s\n",
            "0\n",
            "Epoch: 1169 loss_train: 0.8991 acc_train: 0.7571 loss_val: 0.7654 acc_val: 0.8320 time: 0.0207s\n",
            "0\n",
            "Epoch: 1170 loss_train: 0.7922 acc_train: 0.7571 loss_val: 0.7764 acc_val: 0.8240 time: 0.0196s\n",
            "0\n",
            "Epoch: 1171 loss_train: 0.8451 acc_train: 0.7643 loss_val: 0.7927 acc_val: 0.8220 time: 0.0184s\n",
            "1\n",
            "Epoch: 1172 loss_train: 0.8100 acc_train: 0.8000 loss_val: 0.8095 acc_val: 0.8120 time: 0.0184s\n",
            "2\n",
            "Epoch: 1173 loss_train: 0.7276 acc_train: 0.8286 loss_val: 0.8227 acc_val: 0.8020 time: 0.0186s\n",
            "3\n",
            "Epoch: 1174 loss_train: 0.8163 acc_train: 0.7857 loss_val: 0.8257 acc_val: 0.7960 time: 0.0184s\n",
            "4\n",
            "Epoch: 1175 loss_train: 0.7799 acc_train: 0.7786 loss_val: 0.8262 acc_val: 0.7980 time: 0.0183s\n",
            "5\n",
            "Epoch: 1176 loss_train: 0.8111 acc_train: 0.7714 loss_val: 0.8249 acc_val: 0.7980 time: 0.0187s\n",
            "6\n",
            "Epoch: 1177 loss_train: 0.7634 acc_train: 0.8357 loss_val: 0.8176 acc_val: 0.7980 time: 0.0197s\n",
            "7\n",
            "Epoch: 1178 loss_train: 0.7836 acc_train: 0.8143 loss_val: 0.8122 acc_val: 0.8000 time: 0.0199s\n",
            "8\n",
            "Epoch: 1179 loss_train: 0.7623 acc_train: 0.8071 loss_val: 0.8035 acc_val: 0.8000 time: 0.0223s\n",
            "9\n",
            "Epoch: 1180 loss_train: 0.8852 acc_train: 0.7929 loss_val: 0.7960 acc_val: 0.8040 time: 0.0201s\n",
            "10\n",
            "Epoch: 1181 loss_train: 0.7752 acc_train: 0.8000 loss_val: 0.7890 acc_val: 0.8120 time: 0.0184s\n",
            "11\n",
            "Epoch: 1182 loss_train: 0.7635 acc_train: 0.8071 loss_val: 0.7835 acc_val: 0.8160 time: 0.0189s\n",
            "12\n",
            "Epoch: 1183 loss_train: 0.8635 acc_train: 0.7643 loss_val: 0.7821 acc_val: 0.8180 time: 0.0192s\n",
            "13\n",
            "Epoch: 1184 loss_train: 0.8300 acc_train: 0.7643 loss_val: 0.7881 acc_val: 0.8280 time: 0.0184s\n",
            "14\n",
            "Epoch: 1185 loss_train: 0.8024 acc_train: 0.7786 loss_val: 0.7984 acc_val: 0.8160 time: 0.0196s\n",
            "15\n",
            "Epoch: 1186 loss_train: 0.7870 acc_train: 0.7786 loss_val: 0.8077 acc_val: 0.8160 time: 0.0185s\n",
            "16\n",
            "Epoch: 1187 loss_train: 0.8882 acc_train: 0.7429 loss_val: 0.8149 acc_val: 0.8120 time: 0.0184s\n",
            "17\n",
            "Epoch: 1188 loss_train: 0.8260 acc_train: 0.7500 loss_val: 0.8198 acc_val: 0.8100 time: 0.0184s\n",
            "18\n",
            "Epoch: 1189 loss_train: 0.8276 acc_train: 0.7786 loss_val: 0.8206 acc_val: 0.8060 time: 0.0199s\n",
            "19\n",
            "Epoch: 1190 loss_train: 0.8117 acc_train: 0.7714 loss_val: 0.8203 acc_val: 0.8040 time: 0.0201s\n",
            "20\n",
            "Epoch: 1191 loss_train: 0.9190 acc_train: 0.7500 loss_val: 0.8155 acc_val: 0.8040 time: 0.0185s\n",
            "21\n",
            "Epoch: 1192 loss_train: 0.6971 acc_train: 0.8357 loss_val: 0.8127 acc_val: 0.8040 time: 0.0183s\n",
            "22\n",
            "Epoch: 1193 loss_train: 0.7434 acc_train: 0.8143 loss_val: 0.8076 acc_val: 0.8020 time: 0.0183s\n",
            "23\n",
            "Epoch: 1194 loss_train: 0.8252 acc_train: 0.7857 loss_val: 0.8054 acc_val: 0.8040 time: 0.0195s\n",
            "24\n",
            "Epoch: 1195 loss_train: 0.7682 acc_train: 0.7714 loss_val: 0.8019 acc_val: 0.8020 time: 0.0210s\n",
            "25\n",
            "Epoch: 1196 loss_train: 0.7855 acc_train: 0.8000 loss_val: 0.7958 acc_val: 0.8020 time: 0.0185s\n",
            "26\n",
            "Epoch: 1197 loss_train: 0.8680 acc_train: 0.7643 loss_val: 0.7916 acc_val: 0.8000 time: 0.0183s\n",
            "27\n",
            "Epoch: 1198 loss_train: 0.8618 acc_train: 0.7714 loss_val: 0.7860 acc_val: 0.8100 time: 0.0184s\n",
            "28\n",
            "Epoch: 1199 loss_train: 0.7667 acc_train: 0.7500 loss_val: 0.7825 acc_val: 0.8140 time: 0.0186s\n",
            "29\n",
            "Epoch: 1200 loss_train: 0.9045 acc_train: 0.7429 loss_val: 0.7779 acc_val: 0.8180 time: 0.0217s\n",
            "30\n",
            "Epoch: 1201 loss_train: 0.7577 acc_train: 0.7786 loss_val: 0.7724 acc_val: 0.8160 time: 0.0202s\n",
            "31\n",
            "Epoch: 1202 loss_train: 0.8421 acc_train: 0.7429 loss_val: 0.7695 acc_val: 0.8180 time: 0.0198s\n",
            "32\n",
            "Epoch: 1203 loss_train: 0.8254 acc_train: 0.7429 loss_val: 0.7701 acc_val: 0.8220 time: 0.0184s\n",
            "33\n",
            "Epoch: 1204 loss_train: 0.7994 acc_train: 0.7786 loss_val: 0.7739 acc_val: 0.8220 time: 0.0196s\n",
            "34\n",
            "Epoch: 1205 loss_train: 0.8338 acc_train: 0.7357 loss_val: 0.7784 acc_val: 0.8220 time: 0.0184s\n",
            "35\n",
            "Epoch: 1206 loss_train: 0.8644 acc_train: 0.7429 loss_val: 0.7822 acc_val: 0.8180 time: 0.0183s\n",
            "36\n",
            "Epoch: 1207 loss_train: 0.8628 acc_train: 0.7571 loss_val: 0.7873 acc_val: 0.8180 time: 0.0183s\n",
            "37\n",
            "Epoch: 1208 loss_train: 0.7614 acc_train: 0.8429 loss_val: 0.7924 acc_val: 0.8120 time: 0.0192s\n",
            "38\n",
            "Epoch: 1209 loss_train: 0.8427 acc_train: 0.7357 loss_val: 0.7988 acc_val: 0.8040 time: 0.0191s\n",
            "39\n",
            "Epoch: 1210 loss_train: 0.7324 acc_train: 0.8286 loss_val: 0.8024 acc_val: 0.8060 time: 0.0199s\n",
            "40\n",
            "Epoch: 1211 loss_train: 0.8846 acc_train: 0.7571 loss_val: 0.8023 acc_val: 0.8040 time: 0.0190s\n",
            "41\n",
            "Epoch: 1212 loss_train: 0.8884 acc_train: 0.8000 loss_val: 0.8020 acc_val: 0.8100 time: 0.0189s\n",
            "42\n",
            "Epoch: 1213 loss_train: 0.7276 acc_train: 0.8143 loss_val: 0.8023 acc_val: 0.8100 time: 0.0188s\n",
            "43\n",
            "Epoch: 1214 loss_train: 0.9006 acc_train: 0.7286 loss_val: 0.8039 acc_val: 0.8060 time: 0.0189s\n",
            "44\n",
            "Epoch: 1215 loss_train: 0.8387 acc_train: 0.7857 loss_val: 0.8024 acc_val: 0.8000 time: 0.0183s\n",
            "45\n",
            "Epoch: 1216 loss_train: 0.8459 acc_train: 0.8071 loss_val: 0.7977 acc_val: 0.8060 time: 0.0185s\n",
            "46\n",
            "Epoch: 1217 loss_train: 0.8629 acc_train: 0.7714 loss_val: 0.7914 acc_val: 0.8160 time: 0.0184s\n",
            "47\n",
            "Epoch: 1218 loss_train: 0.8238 acc_train: 0.7714 loss_val: 0.7888 acc_val: 0.8180 time: 0.0184s\n",
            "48\n",
            "Epoch: 1219 loss_train: 0.8106 acc_train: 0.7714 loss_val: 0.7826 acc_val: 0.8200 time: 0.0185s\n",
            "49\n",
            "Epoch: 1220 loss_train: 0.9004 acc_train: 0.7643 loss_val: 0.7773 acc_val: 0.8140 time: 0.0210s\n",
            "50\n",
            "Epoch: 1221 loss_train: 0.6930 acc_train: 0.8071 loss_val: 0.7742 acc_val: 0.8220 time: 0.0187s\n",
            "51\n",
            "Epoch: 1222 loss_train: 0.8456 acc_train: 0.7786 loss_val: 0.7748 acc_val: 0.8240 time: 0.0186s\n",
            "52\n",
            "Epoch: 1223 loss_train: 0.8308 acc_train: 0.7571 loss_val: 0.7771 acc_val: 0.8200 time: 0.0185s\n",
            "53\n",
            "Epoch: 1224 loss_train: 0.7807 acc_train: 0.7786 loss_val: 0.7856 acc_val: 0.8120 time: 0.0184s\n",
            "54\n",
            "Epoch: 1225 loss_train: 0.9203 acc_train: 0.7214 loss_val: 0.7974 acc_val: 0.8080 time: 0.0200s\n",
            "55\n",
            "Epoch: 1226 loss_train: 0.8384 acc_train: 0.8214 loss_val: 0.8067 acc_val: 0.8120 time: 0.0194s\n",
            "56\n",
            "Epoch: 1227 loss_train: 0.8747 acc_train: 0.7429 loss_val: 0.8110 acc_val: 0.8080 time: 0.0184s\n",
            "57\n",
            "Epoch: 1228 loss_train: 0.8372 acc_train: 0.7643 loss_val: 0.8128 acc_val: 0.8040 time: 0.0183s\n",
            "58\n",
            "Epoch: 1229 loss_train: 0.8796 acc_train: 0.7714 loss_val: 0.8097 acc_val: 0.8080 time: 0.0184s\n",
            "59\n",
            "Epoch: 1230 loss_train: 0.7964 acc_train: 0.7786 loss_val: 0.8055 acc_val: 0.8060 time: 0.0220s\n",
            "60\n",
            "Epoch: 1231 loss_train: 0.7490 acc_train: 0.8214 loss_val: 0.8015 acc_val: 0.8040 time: 0.0190s\n",
            "61\n",
            "Epoch: 1232 loss_train: 0.7939 acc_train: 0.7929 loss_val: 0.7990 acc_val: 0.8020 time: 0.0187s\n",
            "62\n",
            "Epoch: 1233 loss_train: 0.7152 acc_train: 0.8286 loss_val: 0.7926 acc_val: 0.8080 time: 0.0187s\n",
            "63\n",
            "Epoch: 1234 loss_train: 0.8787 acc_train: 0.7286 loss_val: 0.7855 acc_val: 0.8160 time: 0.0198s\n",
            "64\n",
            "Epoch: 1235 loss_train: 0.8663 acc_train: 0.7571 loss_val: 0.7794 acc_val: 0.8180 time: 0.0193s\n",
            "65\n",
            "Epoch: 1236 loss_train: 0.8431 acc_train: 0.7500 loss_val: 0.7759 acc_val: 0.8180 time: 0.0188s\n",
            "66\n",
            "Epoch: 1237 loss_train: 0.8831 acc_train: 0.7500 loss_val: 0.7730 acc_val: 0.8180 time: 0.0207s\n",
            "67\n",
            "Epoch: 1238 loss_train: 0.8650 acc_train: 0.7429 loss_val: 0.7710 acc_val: 0.8140 time: 0.0214s\n",
            "68\n",
            "Epoch: 1239 loss_train: 0.7808 acc_train: 0.7857 loss_val: 0.7711 acc_val: 0.8160 time: 0.0187s\n",
            "69\n",
            "Epoch: 1240 loss_train: 0.7342 acc_train: 0.8214 loss_val: 0.7715 acc_val: 0.8080 time: 0.0193s\n",
            "70\n",
            "Epoch: 1241 loss_train: 0.6942 acc_train: 0.8500 loss_val: 0.7759 acc_val: 0.8080 time: 0.0198s\n",
            "71\n",
            "Epoch: 1242 loss_train: 0.8172 acc_train: 0.7857 loss_val: 0.7821 acc_val: 0.8100 time: 0.0188s\n",
            "72\n",
            "Epoch: 1243 loss_train: 0.7518 acc_train: 0.7929 loss_val: 0.7869 acc_val: 0.8100 time: 0.0218s\n",
            "73\n",
            "Epoch: 1244 loss_train: 0.7646 acc_train: 0.8143 loss_val: 0.7892 acc_val: 0.8100 time: 0.0185s\n",
            "74\n",
            "Epoch: 1245 loss_train: 0.6871 acc_train: 0.8214 loss_val: 0.7916 acc_val: 0.8120 time: 0.0184s\n",
            "75\n",
            "Epoch: 1246 loss_train: 0.8711 acc_train: 0.7500 loss_val: 0.7946 acc_val: 0.8100 time: 0.0183s\n",
            "76\n",
            "Epoch: 1247 loss_train: 0.8161 acc_train: 0.8071 loss_val: 0.7989 acc_val: 0.8080 time: 0.0183s\n",
            "77\n",
            "Epoch: 1248 loss_train: 0.7883 acc_train: 0.7429 loss_val: 0.8032 acc_val: 0.8080 time: 0.0182s\n",
            "78\n",
            "Epoch: 1249 loss_train: 0.8038 acc_train: 0.8143 loss_val: 0.8106 acc_val: 0.8120 time: 0.0185s\n",
            "79\n",
            "Epoch: 1250 loss_train: 0.7704 acc_train: 0.7929 loss_val: 0.8112 acc_val: 0.8100 time: 0.0213s\n",
            "80\n",
            "Epoch: 1251 loss_train: 0.8150 acc_train: 0.7929 loss_val: 0.8094 acc_val: 0.8080 time: 0.0221s\n",
            "81\n",
            "Epoch: 1252 loss_train: 0.7365 acc_train: 0.8143 loss_val: 0.8071 acc_val: 0.8100 time: 0.0199s\n",
            "82\n",
            "Epoch: 1253 loss_train: 0.7709 acc_train: 0.8571 loss_val: 0.7985 acc_val: 0.8080 time: 0.0194s\n",
            "83\n",
            "Epoch: 1254 loss_train: 0.8049 acc_train: 0.7929 loss_val: 0.7928 acc_val: 0.8100 time: 0.0186s\n",
            "84\n",
            "Epoch: 1255 loss_train: 0.7798 acc_train: 0.7643 loss_val: 0.7887 acc_val: 0.8080 time: 0.0191s\n",
            "85\n",
            "Epoch: 1256 loss_train: 0.8099 acc_train: 0.7929 loss_val: 0.7882 acc_val: 0.8040 time: 0.0184s\n",
            "86\n",
            "Epoch: 1257 loss_train: 0.7116 acc_train: 0.8429 loss_val: 0.7846 acc_val: 0.8080 time: 0.0184s\n",
            "87\n",
            "Epoch: 1258 loss_train: 0.9022 acc_train: 0.7429 loss_val: 0.7846 acc_val: 0.8080 time: 0.0183s\n",
            "88\n",
            "Epoch: 1259 loss_train: 0.7476 acc_train: 0.8214 loss_val: 0.7791 acc_val: 0.8140 time: 0.0192s\n",
            "89\n",
            "Epoch: 1260 loss_train: 0.8578 acc_train: 0.7571 loss_val: 0.7753 acc_val: 0.8180 time: 0.0193s\n",
            "90\n",
            "Epoch: 1261 loss_train: 0.7874 acc_train: 0.8000 loss_val: 0.7757 acc_val: 0.8160 time: 0.0187s\n",
            "91\n",
            "Epoch: 1262 loss_train: 0.7538 acc_train: 0.8000 loss_val: 0.7768 acc_val: 0.8200 time: 0.0195s\n",
            "92\n",
            "Epoch: 1263 loss_train: 0.8819 acc_train: 0.7214 loss_val: 0.7789 acc_val: 0.8140 time: 0.0186s\n",
            "93\n",
            "Epoch: 1264 loss_train: 0.8019 acc_train: 0.7786 loss_val: 0.7840 acc_val: 0.8140 time: 0.0190s\n",
            "94\n",
            "Epoch: 1265 loss_train: 0.8199 acc_train: 0.7857 loss_val: 0.7910 acc_val: 0.8080 time: 0.0185s\n",
            "95\n",
            "Epoch: 1266 loss_train: 0.8259 acc_train: 0.7857 loss_val: 0.7952 acc_val: 0.8080 time: 0.0185s\n",
            "96\n",
            "Epoch: 1267 loss_train: 0.8650 acc_train: 0.7714 loss_val: 0.7985 acc_val: 0.8020 time: 0.0185s\n",
            "97\n",
            "Epoch: 1268 loss_train: 0.7705 acc_train: 0.7857 loss_val: 0.8000 acc_val: 0.8020 time: 0.0184s\n",
            "98\n",
            "Epoch: 1269 loss_train: 0.7724 acc_train: 0.8143 loss_val: 0.7964 acc_val: 0.8000 time: 0.0191s\n",
            "99\n",
            "Epoch: 1270 loss_train: 0.7939 acc_train: 0.7857 loss_val: 0.7925 acc_val: 0.7960 time: 0.0217s\n",
            "100\n",
            "Epoch: 1271 loss_train: 0.8737 acc_train: 0.7571 loss_val: 0.7895 acc_val: 0.8000 time: 0.0183s\n",
            "101\n",
            "Epoch: 1272 loss_train: 0.8767 acc_train: 0.7571 loss_val: 0.7881 acc_val: 0.8020 time: 0.0183s\n",
            "102\n",
            "Epoch: 1273 loss_train: 0.8065 acc_train: 0.8143 loss_val: 0.7872 acc_val: 0.7980 time: 0.0184s\n",
            "103\n",
            "Epoch: 1274 loss_train: 0.7656 acc_train: 0.8286 loss_val: 0.7861 acc_val: 0.8020 time: 0.0183s\n",
            "104\n",
            "Epoch: 1275 loss_train: 0.8487 acc_train: 0.7643 loss_val: 0.7856 acc_val: 0.8040 time: 0.0186s\n",
            "105\n",
            "Epoch: 1276 loss_train: 0.7337 acc_train: 0.7929 loss_val: 0.7867 acc_val: 0.8060 time: 0.0187s\n",
            "106\n",
            "Epoch: 1277 loss_train: 0.8124 acc_train: 0.7929 loss_val: 0.7915 acc_val: 0.8060 time: 0.0184s\n",
            "107\n",
            "Epoch: 1278 loss_train: 0.8640 acc_train: 0.7714 loss_val: 0.7993 acc_val: 0.8120 time: 0.0183s\n",
            "108\n",
            "Epoch: 1279 loss_train: 0.8611 acc_train: 0.7643 loss_val: 0.8067 acc_val: 0.8080 time: 0.0184s\n",
            "109\n",
            "Epoch: 1280 loss_train: 0.8250 acc_train: 0.7714 loss_val: 0.8111 acc_val: 0.8060 time: 0.0206s\n",
            "110\n",
            "Epoch: 1281 loss_train: 0.7034 acc_train: 0.8286 loss_val: 0.8092 acc_val: 0.8080 time: 0.0195s\n",
            "111\n",
            "Epoch: 1282 loss_train: 0.9182 acc_train: 0.7429 loss_val: 0.8039 acc_val: 0.8140 time: 0.0184s\n",
            "112\n",
            "Epoch: 1283 loss_train: 0.8936 acc_train: 0.7286 loss_val: 0.8005 acc_val: 0.8120 time: 0.0196s\n",
            "113\n",
            "Epoch: 1284 loss_train: 0.7416 acc_train: 0.8071 loss_val: 0.7935 acc_val: 0.8140 time: 0.0183s\n",
            "114\n",
            "Epoch: 1285 loss_train: 0.7714 acc_train: 0.7929 loss_val: 0.7894 acc_val: 0.8120 time: 0.0181s\n",
            "115\n",
            "Epoch: 1286 loss_train: 0.7322 acc_train: 0.8071 loss_val: 0.7854 acc_val: 0.8100 time: 0.0186s\n",
            "116\n",
            "Epoch: 1287 loss_train: 0.7695 acc_train: 0.8357 loss_val: 0.7858 acc_val: 0.8080 time: 0.0182s\n",
            "117\n",
            "Epoch: 1288 loss_train: 0.7078 acc_train: 0.8357 loss_val: 0.7863 acc_val: 0.8100 time: 0.0185s\n",
            "118\n",
            "Epoch: 1289 loss_train: 0.8300 acc_train: 0.7857 loss_val: 0.7888 acc_val: 0.8080 time: 0.0187s\n",
            "119\n",
            "Epoch: 1290 loss_train: 0.7877 acc_train: 0.8000 loss_val: 0.7922 acc_val: 0.8020 time: 0.0201s\n",
            "120\n",
            "Epoch: 1291 loss_train: 0.8757 acc_train: 0.7500 loss_val: 0.7913 acc_val: 0.8020 time: 0.0224s\n",
            "121\n",
            "Epoch: 1292 loss_train: 0.7924 acc_train: 0.8071 loss_val: 0.7927 acc_val: 0.8080 time: 0.0189s\n",
            "122\n",
            "Epoch: 1293 loss_train: 0.8232 acc_train: 0.7929 loss_val: 0.7958 acc_val: 0.8120 time: 0.0201s\n",
            "123\n",
            "Epoch: 1294 loss_train: 0.7538 acc_train: 0.8286 loss_val: 0.8021 acc_val: 0.8160 time: 0.0193s\n",
            "124\n",
            "Epoch: 1295 loss_train: 0.8633 acc_train: 0.7643 loss_val: 0.8062 acc_val: 0.8140 time: 0.0186s\n",
            "125\n",
            "Epoch: 1296 loss_train: 0.8726 acc_train: 0.7429 loss_val: 0.8094 acc_val: 0.8120 time: 0.0183s\n",
            "126\n",
            "Epoch: 1297 loss_train: 0.7941 acc_train: 0.7571 loss_val: 0.8088 acc_val: 0.8040 time: 0.0184s\n",
            "127\n",
            "Epoch: 1298 loss_train: 0.8532 acc_train: 0.7643 loss_val: 0.8018 acc_val: 0.8100 time: 0.0183s\n",
            "128\n",
            "Epoch: 1299 loss_train: 0.7994 acc_train: 0.8071 loss_val: 0.7936 acc_val: 0.8140 time: 0.0187s\n",
            "129\n",
            "Epoch: 1300 loss_train: 0.8544 acc_train: 0.8286 loss_val: 0.7854 acc_val: 0.8220 time: 0.0197s\n",
            "130\n",
            "Epoch: 1301 loss_train: 0.7284 acc_train: 0.8000 loss_val: 0.7807 acc_val: 0.8160 time: 0.0182s\n",
            "131\n",
            "Epoch: 1302 loss_train: 0.8010 acc_train: 0.8143 loss_val: 0.7804 acc_val: 0.8140 time: 0.0183s\n",
            "132\n",
            "Epoch: 1303 loss_train: 0.8191 acc_train: 0.7857 loss_val: 0.7810 acc_val: 0.8060 time: 0.0186s\n",
            "133\n",
            "Epoch: 1304 loss_train: 0.6847 acc_train: 0.8286 loss_val: 0.7824 acc_val: 0.8080 time: 0.0184s\n",
            "134\n",
            "Epoch: 1305 loss_train: 0.8991 acc_train: 0.7357 loss_val: 0.7836 acc_val: 0.8060 time: 0.0179s\n",
            "135\n",
            "Epoch: 1306 loss_train: 0.8165 acc_train: 0.7571 loss_val: 0.7892 acc_val: 0.8060 time: 0.0196s\n",
            "136\n",
            "Epoch: 1307 loss_train: 0.8339 acc_train: 0.7500 loss_val: 0.7973 acc_val: 0.8000 time: 0.0184s\n",
            "137\n",
            "Epoch: 1308 loss_train: 0.8172 acc_train: 0.7643 loss_val: 0.8042 acc_val: 0.7960 time: 0.0184s\n",
            "138\n",
            "Epoch: 1309 loss_train: 0.7244 acc_train: 0.8214 loss_val: 0.8082 acc_val: 0.7940 time: 0.0185s\n",
            "139\n",
            "Epoch: 1310 loss_train: 0.8588 acc_train: 0.7214 loss_val: 0.8064 acc_val: 0.8000 time: 0.0203s\n",
            "140\n",
            "Epoch: 1311 loss_train: 0.7496 acc_train: 0.8286 loss_val: 0.8035 acc_val: 0.8020 time: 0.0182s\n",
            "141\n",
            "Epoch: 1312 loss_train: 0.8973 acc_train: 0.7143 loss_val: 0.7960 acc_val: 0.8100 time: 0.0184s\n",
            "142\n",
            "Epoch: 1313 loss_train: 0.7872 acc_train: 0.8071 loss_val: 0.7916 acc_val: 0.8160 time: 0.0182s\n",
            "143\n",
            "Epoch: 1314 loss_train: 0.8590 acc_train: 0.7214 loss_val: 0.7864 acc_val: 0.8200 time: 0.0184s\n",
            "144\n",
            "Epoch: 1315 loss_train: 0.7286 acc_train: 0.8214 loss_val: 0.7833 acc_val: 0.8220 time: 0.0184s\n",
            "145\n",
            "Epoch: 1316 loss_train: 0.8004 acc_train: 0.7857 loss_val: 0.7808 acc_val: 0.8180 time: 0.0189s\n",
            "146\n",
            "Epoch: 1317 loss_train: 0.7479 acc_train: 0.8143 loss_val: 0.7776 acc_val: 0.8160 time: 0.0189s\n",
            "147\n",
            "Epoch: 1318 loss_train: 0.6505 acc_train: 0.8571 loss_val: 0.7755 acc_val: 0.8200 time: 0.0188s\n",
            "148\n",
            "Epoch: 1319 loss_train: 0.7917 acc_train: 0.7786 loss_val: 0.7759 acc_val: 0.8180 time: 0.0213s\n",
            "149\n",
            "Epoch: 1320 loss_train: 0.7720 acc_train: 0.8071 loss_val: 0.7787 acc_val: 0.8180 time: 0.0212s\n",
            "150\n",
            "Epoch: 1321 loss_train: 0.8328 acc_train: 0.7357 loss_val: 0.7794 acc_val: 0.8120 time: 0.0187s\n",
            "151\n",
            "Epoch: 1322 loss_train: 0.8758 acc_train: 0.7429 loss_val: 0.7861 acc_val: 0.8080 time: 0.0183s\n",
            "152\n",
            "Epoch: 1323 loss_train: 0.8554 acc_train: 0.7929 loss_val: 0.7995 acc_val: 0.8020 time: 0.0183s\n",
            "153\n",
            "Epoch: 1324 loss_train: 0.8000 acc_train: 0.7929 loss_val: 0.8148 acc_val: 0.8000 time: 0.0184s\n",
            "154\n",
            "Epoch: 1325 loss_train: 0.7280 acc_train: 0.8143 loss_val: 0.8243 acc_val: 0.8020 time: 0.0184s\n",
            "155\n",
            "Epoch: 1326 loss_train: 0.8359 acc_train: 0.7429 loss_val: 0.8294 acc_val: 0.7980 time: 0.0182s\n",
            "156\n",
            "Epoch: 1327 loss_train: 0.7573 acc_train: 0.8143 loss_val: 0.8243 acc_val: 0.7960 time: 0.0183s\n",
            "157\n",
            "Epoch: 1328 loss_train: 0.8258 acc_train: 0.7714 loss_val: 0.8143 acc_val: 0.7940 time: 0.0182s\n",
            "158\n",
            "Epoch: 1329 loss_train: 0.8634 acc_train: 0.7714 loss_val: 0.8035 acc_val: 0.8040 time: 0.0184s\n",
            "159\n",
            "Epoch: 1330 loss_train: 0.8313 acc_train: 0.7929 loss_val: 0.7941 acc_val: 0.8080 time: 0.0196s\n",
            "160\n",
            "Epoch: 1331 loss_train: 0.9391 acc_train: 0.7286 loss_val: 0.7835 acc_val: 0.8120 time: 0.0185s\n",
            "161\n",
            "Epoch: 1332 loss_train: 0.8032 acc_train: 0.7786 loss_val: 0.7790 acc_val: 0.8100 time: 0.0183s\n",
            "162\n",
            "Epoch: 1333 loss_train: 0.8580 acc_train: 0.7500 loss_val: 0.7807 acc_val: 0.8120 time: 0.0184s\n",
            "163\n",
            "Epoch: 1334 loss_train: 0.8436 acc_train: 0.7857 loss_val: 0.7847 acc_val: 0.8140 time: 0.0186s\n",
            "164\n",
            "Epoch: 1335 loss_train: 0.7401 acc_train: 0.8571 loss_val: 0.7896 acc_val: 0.8140 time: 0.0182s\n",
            "165\n",
            "Epoch: 1336 loss_train: 0.8247 acc_train: 0.7857 loss_val: 0.8011 acc_val: 0.8100 time: 0.0183s\n",
            "166\n",
            "Epoch: 1337 loss_train: 0.8359 acc_train: 0.7429 loss_val: 0.8129 acc_val: 0.8060 time: 0.0183s\n",
            "167\n",
            "Epoch: 1338 loss_train: 0.7774 acc_train: 0.8214 loss_val: 0.8216 acc_val: 0.8020 time: 0.0185s\n",
            "168\n",
            "Epoch: 1339 loss_train: 0.8717 acc_train: 0.7571 loss_val: 0.8241 acc_val: 0.7960 time: 0.0191s\n",
            "169\n",
            "Epoch: 1340 loss_train: 0.8705 acc_train: 0.7357 loss_val: 0.8234 acc_val: 0.7960 time: 0.0214s\n",
            "170\n",
            "Epoch: 1341 loss_train: 0.7763 acc_train: 0.8143 loss_val: 0.8163 acc_val: 0.8000 time: 0.0188s\n",
            "171\n",
            "Epoch: 1342 loss_train: 0.7740 acc_train: 0.7929 loss_val: 0.8072 acc_val: 0.8000 time: 0.0191s\n",
            "172\n",
            "Epoch: 1343 loss_train: 0.7688 acc_train: 0.8000 loss_val: 0.7969 acc_val: 0.8060 time: 0.0249s\n",
            "173\n",
            "Epoch: 1344 loss_train: 0.8654 acc_train: 0.7643 loss_val: 0.7888 acc_val: 0.8080 time: 0.0189s\n",
            "174\n",
            "Epoch: 1345 loss_train: 0.8185 acc_train: 0.7929 loss_val: 0.7820 acc_val: 0.8100 time: 0.0187s\n",
            "175\n",
            "Epoch: 1346 loss_train: 0.7649 acc_train: 0.8071 loss_val: 0.7751 acc_val: 0.8160 time: 0.0183s\n",
            "176\n",
            "Epoch: 1347 loss_train: 0.8793 acc_train: 0.7357 loss_val: 0.7732 acc_val: 0.8160 time: 0.0200s\n",
            "177\n",
            "Epoch: 1348 loss_train: 0.8010 acc_train: 0.7500 loss_val: 0.7741 acc_val: 0.8180 time: 0.0191s\n",
            "178\n",
            "Epoch: 1349 loss_train: 0.7476 acc_train: 0.8214 loss_val: 0.7739 acc_val: 0.8200 time: 0.0192s\n",
            "179\n",
            "Epoch: 1350 loss_train: 0.7464 acc_train: 0.8214 loss_val: 0.7719 acc_val: 0.8200 time: 0.0198s\n",
            "180\n",
            "Epoch: 1351 loss_train: 0.9375 acc_train: 0.7500 loss_val: 0.7708 acc_val: 0.8240 time: 0.0185s\n",
            "181\n",
            "Epoch: 1352 loss_train: 0.8035 acc_train: 0.7643 loss_val: 0.7747 acc_val: 0.8240 time: 0.0184s\n",
            "182\n",
            "Epoch: 1353 loss_train: 0.8457 acc_train: 0.7429 loss_val: 0.7804 acc_val: 0.8240 time: 0.0185s\n",
            "183\n",
            "Epoch: 1354 loss_train: 0.7662 acc_train: 0.7786 loss_val: 0.7874 acc_val: 0.8120 time: 0.0185s\n",
            "184\n",
            "Epoch: 1355 loss_train: 0.8232 acc_train: 0.7857 loss_val: 0.7951 acc_val: 0.8080 time: 0.0183s\n",
            "185\n",
            "Epoch: 1356 loss_train: 0.7851 acc_train: 0.8071 loss_val: 0.8038 acc_val: 0.8080 time: 0.0183s\n",
            "186\n",
            "Epoch: 1357 loss_train: 0.7604 acc_train: 0.8500 loss_val: 0.8053 acc_val: 0.8020 time: 0.0187s\n",
            "187\n",
            "Epoch: 1358 loss_train: 0.7961 acc_train: 0.7714 loss_val: 0.8058 acc_val: 0.8000 time: 0.0183s\n",
            "188\n",
            "Epoch: 1359 loss_train: 0.7710 acc_train: 0.8429 loss_val: 0.8038 acc_val: 0.8040 time: 0.0187s\n",
            "189\n",
            "Epoch: 1360 loss_train: 0.7361 acc_train: 0.8214 loss_val: 0.7966 acc_val: 0.8080 time: 0.0222s\n",
            "190\n",
            "Epoch: 1361 loss_train: 0.7983 acc_train: 0.8143 loss_val: 0.7883 acc_val: 0.8020 time: 0.0185s\n",
            "191\n",
            "Epoch: 1362 loss_train: 0.8456 acc_train: 0.7857 loss_val: 0.7836 acc_val: 0.8100 time: 0.0185s\n",
            "192\n",
            "Epoch: 1363 loss_train: 0.8066 acc_train: 0.7214 loss_val: 0.7835 acc_val: 0.8120 time: 0.0188s\n",
            "193\n",
            "Epoch: 1364 loss_train: 0.7738 acc_train: 0.7714 loss_val: 0.7857 acc_val: 0.8080 time: 0.0185s\n",
            "194\n",
            "Epoch: 1365 loss_train: 0.8234 acc_train: 0.8000 loss_val: 0.7863 acc_val: 0.8160 time: 0.0198s\n",
            "195\n",
            "Epoch: 1366 loss_train: 0.8061 acc_train: 0.7643 loss_val: 0.7864 acc_val: 0.8140 time: 0.0186s\n",
            "196\n",
            "Epoch: 1367 loss_train: 0.8007 acc_train: 0.7786 loss_val: 0.7870 acc_val: 0.8160 time: 0.0186s\n",
            "197\n",
            "Epoch: 1368 loss_train: 0.7576 acc_train: 0.8214 loss_val: 0.7902 acc_val: 0.8160 time: 0.0184s\n",
            "198\n",
            "Epoch: 1369 loss_train: 0.8259 acc_train: 0.7857 loss_val: 0.7930 acc_val: 0.8180 time: 0.0204s\n",
            "199\n",
            "Early stop! Min loss:  0.7594117522239685 , Max accuracy:  0.8320000000000001\n",
            "Early stop model validation loss:  0.7594117522239685 , accuracy:  0.8220000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 29.4196s\n",
            "Loading 1167th epoch\n",
            "Test set results: loss= 0.7220 accuracy= 0.8490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8490, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEF7IU9_kBdG",
        "outputId": "b3e94c50-1f26-48c2-93c1-762f7718877c"
      },
      "source": [
        "Train(sample=1) #pubmed\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 5.1453 acc_train: 0.4333 loss_val: 1.1968 acc_val: 0.4160 time: 0.0599s\n",
            "0\n",
            "Epoch: 0002 loss_train: 3.4067 acc_train: 0.4333 loss_val: 1.4196 acc_val: 0.3880 time: 0.0548s\n",
            "0\n",
            "Epoch: 0003 loss_train: 2.7950 acc_train: 0.4667 loss_val: 1.6425 acc_val: 0.3880 time: 0.0549s\n",
            "1\n",
            "Epoch: 0004 loss_train: 1.7118 acc_train: 0.5667 loss_val: 1.6792 acc_val: 0.3880 time: 0.0534s\n",
            "2\n",
            "Epoch: 0005 loss_train: 3.7000 acc_train: 0.2500 loss_val: 1.4013 acc_val: 0.3880 time: 0.0528s\n",
            "3\n",
            "Epoch: 0006 loss_train: 2.2906 acc_train: 0.3333 loss_val: 1.1400 acc_val: 0.3880 time: 0.0523s\n",
            "4\n",
            "Epoch: 0007 loss_train: 1.5729 acc_train: 0.4333 loss_val: 1.1003 acc_val: 0.3880 time: 0.0520s\n",
            "0\n",
            "Epoch: 0008 loss_train: 2.1167 acc_train: 0.3333 loss_val: 1.3157 acc_val: 0.1960 time: 0.0519s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.7456 acc_train: 0.3333 loss_val: 2.3260 acc_val: 0.1960 time: 0.0528s\n",
            "1\n",
            "Epoch: 0010 loss_train: 1.9141 acc_train: 0.3667 loss_val: 2.3858 acc_val: 0.1960 time: 0.0523s\n",
            "2\n",
            "Epoch: 0011 loss_train: 2.0584 acc_train: 0.3500 loss_val: 1.8388 acc_val: 0.1960 time: 0.0523s\n",
            "3\n",
            "Epoch: 0012 loss_train: 1.6637 acc_train: 0.3500 loss_val: 1.6028 acc_val: 0.1960 time: 0.0521s\n",
            "4\n",
            "Epoch: 0013 loss_train: 1.6547 acc_train: 0.4000 loss_val: 1.6152 acc_val: 0.3940 time: 0.0524s\n",
            "5\n",
            "Epoch: 0014 loss_train: 1.6511 acc_train: 0.4500 loss_val: 1.4111 acc_val: 0.3880 time: 0.0521s\n",
            "6\n",
            "Epoch: 0015 loss_train: 1.5342 acc_train: 0.4500 loss_val: 1.1957 acc_val: 0.3880 time: 0.0521s\n",
            "7\n",
            "Epoch: 0016 loss_train: 1.5173 acc_train: 0.4833 loss_val: 1.1046 acc_val: 0.3880 time: 0.0520s\n",
            "8\n",
            "Epoch: 0017 loss_train: 1.5555 acc_train: 0.4333 loss_val: 1.0793 acc_val: 0.3880 time: 0.0525s\n",
            "9\n",
            "Epoch: 0018 loss_train: 1.2799 acc_train: 0.4667 loss_val: 1.0744 acc_val: 0.3880 time: 0.0518s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.5115 acc_train: 0.3667 loss_val: 1.0790 acc_val: 0.3880 time: 0.0516s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.5499 acc_train: 0.4833 loss_val: 1.1257 acc_val: 0.3880 time: 0.0521s\n",
            "1\n",
            "Epoch: 0021 loss_train: 1.3241 acc_train: 0.5333 loss_val: 1.1529 acc_val: 0.3880 time: 0.0534s\n",
            "2\n",
            "Epoch: 0022 loss_train: 1.3770 acc_train: 0.5167 loss_val: 1.2147 acc_val: 0.3880 time: 0.0524s\n",
            "3\n",
            "Epoch: 0023 loss_train: 1.5231 acc_train: 0.4167 loss_val: 1.1851 acc_val: 0.3880 time: 0.0523s\n",
            "4\n",
            "Epoch: 0024 loss_train: 1.3899 acc_train: 0.3833 loss_val: 1.1994 acc_val: 0.3880 time: 0.0522s\n",
            "5\n",
            "Epoch: 0025 loss_train: 1.3058 acc_train: 0.5000 loss_val: 1.1807 acc_val: 0.3880 time: 0.0536s\n",
            "6\n",
            "Epoch: 0026 loss_train: 1.4024 acc_train: 0.5000 loss_val: 1.1141 acc_val: 0.3880 time: 0.0523s\n",
            "7\n",
            "Epoch: 0027 loss_train: 1.4302 acc_train: 0.4333 loss_val: 1.0567 acc_val: 0.3880 time: 0.0520s\n",
            "8\n",
            "Epoch: 0028 loss_train: 1.6305 acc_train: 0.5333 loss_val: 1.0826 acc_val: 0.4200 time: 0.0519s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.2315 acc_train: 0.5167 loss_val: 1.1638 acc_val: 0.4160 time: 0.0542s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.4596 acc_train: 0.3667 loss_val: 1.2393 acc_val: 0.4160 time: 0.0523s\n",
            "1\n",
            "Epoch: 0031 loss_train: 1.5252 acc_train: 0.5333 loss_val: 1.2436 acc_val: 0.4160 time: 0.0521s\n",
            "2\n",
            "Epoch: 0032 loss_train: 1.2098 acc_train: 0.6333 loss_val: 1.2131 acc_val: 0.4160 time: 0.0523s\n",
            "3\n",
            "Epoch: 0033 loss_train: 1.3829 acc_train: 0.5500 loss_val: 1.0945 acc_val: 0.4160 time: 0.0523s\n",
            "4\n",
            "Epoch: 0034 loss_train: 1.3681 acc_train: 0.5833 loss_val: 1.0301 acc_val: 0.4180 time: 0.0534s\n",
            "5\n",
            "Epoch: 0035 loss_train: 1.0665 acc_train: 0.5500 loss_val: 1.0651 acc_val: 0.5140 time: 0.0518s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.0356 acc_train: 0.6333 loss_val: 1.1176 acc_val: 0.1960 time: 0.0551s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.2157 acc_train: 0.4833 loss_val: 1.1268 acc_val: 0.1960 time: 0.0546s\n",
            "1\n",
            "Epoch: 0038 loss_train: 1.3394 acc_train: 0.5000 loss_val: 1.0763 acc_val: 0.5600 time: 0.0521s\n",
            "2\n",
            "Epoch: 0039 loss_train: 1.5893 acc_train: 0.4667 loss_val: 1.0282 acc_val: 0.4200 time: 0.0525s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.3824 acc_train: 0.3667 loss_val: 1.0685 acc_val: 0.4160 time: 0.0517s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.2542 acc_train: 0.5667 loss_val: 1.1670 acc_val: 0.4160 time: 0.0523s\n",
            "1\n",
            "Epoch: 0042 loss_train: 1.6093 acc_train: 0.4500 loss_val: 1.1558 acc_val: 0.4160 time: 0.0529s\n",
            "2\n",
            "Epoch: 0043 loss_train: 1.2250 acc_train: 0.4833 loss_val: 2.4365 acc_val: 0.3880 time: 0.0522s\n",
            "3\n",
            "Epoch: 0044 loss_train: 1.2188 acc_train: 0.5667 loss_val: 2.6225 acc_val: 0.3880 time: 0.0522s\n",
            "4\n",
            "Epoch: 0045 loss_train: 1.3407 acc_train: 0.5000 loss_val: 1.6252 acc_val: 0.3880 time: 0.0524s\n",
            "5\n",
            "Epoch: 0046 loss_train: 1.2283 acc_train: 0.4667 loss_val: 1.1152 acc_val: 0.3880 time: 0.0520s\n",
            "6\n",
            "Epoch: 0047 loss_train: 1.0839 acc_train: 0.5833 loss_val: 1.0169 acc_val: 0.4680 time: 0.0526s\n",
            "7\n",
            "Epoch: 0048 loss_train: 1.4799 acc_train: 0.4667 loss_val: 1.0136 acc_val: 0.6240 time: 0.0518s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.2942 acc_train: 0.5667 loss_val: 1.0166 acc_val: 0.3900 time: 0.0519s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.1085 acc_train: 0.5833 loss_val: 1.0660 acc_val: 0.3880 time: 0.0521s\n",
            "1\n",
            "Epoch: 0051 loss_train: 0.9731 acc_train: 0.6000 loss_val: 1.1626 acc_val: 0.3880 time: 0.0521s\n",
            "2\n",
            "Epoch: 0052 loss_train: 0.8360 acc_train: 0.6000 loss_val: 1.2793 acc_val: 0.3880 time: 0.0522s\n",
            "3\n",
            "Epoch: 0053 loss_train: 1.1652 acc_train: 0.5667 loss_val: 1.3405 acc_val: 0.5260 time: 0.0525s\n",
            "4\n",
            "Epoch: 0054 loss_train: 1.2432 acc_train: 0.5000 loss_val: 1.4917 acc_val: 0.4180 time: 0.0520s\n",
            "5\n",
            "Epoch: 0055 loss_train: 1.2268 acc_train: 0.7333 loss_val: 1.4872 acc_val: 0.4160 time: 0.0522s\n",
            "6\n",
            "Epoch: 0056 loss_train: 1.0540 acc_train: 0.6167 loss_val: 1.5377 acc_val: 0.4160 time: 0.0520s\n",
            "7\n",
            "Epoch: 0057 loss_train: 0.8498 acc_train: 0.7000 loss_val: 1.4854 acc_val: 0.4160 time: 0.0533s\n",
            "8\n",
            "Epoch: 0058 loss_train: 1.2052 acc_train: 0.6167 loss_val: 1.2947 acc_val: 0.4160 time: 0.0520s\n",
            "9\n",
            "Epoch: 0059 loss_train: 1.1655 acc_train: 0.6333 loss_val: 1.1029 acc_val: 0.4180 time: 0.0521s\n",
            "10\n",
            "Epoch: 0060 loss_train: 0.9978 acc_train: 0.6333 loss_val: 0.9728 acc_val: 0.4200 time: 0.0522s\n",
            "11\n",
            "Epoch: 0061 loss_train: 0.8942 acc_train: 0.7833 loss_val: 0.9303 acc_val: 0.6420 time: 0.0528s\n",
            "0\n",
            "Epoch: 0062 loss_train: 0.9429 acc_train: 0.6500 loss_val: 0.9521 acc_val: 0.4240 time: 0.0518s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.1159 acc_train: 0.6167 loss_val: 0.9294 acc_val: 0.4340 time: 0.0520s\n",
            "1\n",
            "Epoch: 0064 loss_train: 1.4317 acc_train: 0.6000 loss_val: 0.9018 acc_val: 0.5780 time: 0.0516s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.1815 acc_train: 0.5833 loss_val: 0.8857 acc_val: 0.8000 time: 0.0521s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.0831 acc_train: 0.6500 loss_val: 0.8868 acc_val: 0.7940 time: 0.0520s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.0817 acc_train: 0.6333 loss_val: 0.8956 acc_val: 0.5360 time: 0.0521s\n",
            "1\n",
            "Epoch: 0068 loss_train: 0.8813 acc_train: 0.7000 loss_val: 0.9353 acc_val: 0.4240 time: 0.0522s\n",
            "2\n",
            "Epoch: 0069 loss_train: 0.8585 acc_train: 0.7000 loss_val: 1.0451 acc_val: 0.4040 time: 0.0523s\n",
            "3\n",
            "Epoch: 0070 loss_train: 1.2033 acc_train: 0.6000 loss_val: 1.1223 acc_val: 0.4020 time: 0.0532s\n",
            "4\n",
            "Epoch: 0071 loss_train: 0.7952 acc_train: 0.6500 loss_val: 1.1383 acc_val: 0.4060 time: 0.0524s\n",
            "5\n",
            "Epoch: 0072 loss_train: 0.7691 acc_train: 0.7333 loss_val: 1.1084 acc_val: 0.4080 time: 0.0522s\n",
            "6\n",
            "Epoch: 0073 loss_train: 0.7070 acc_train: 0.7167 loss_val: 0.9972 acc_val: 0.4220 time: 0.0524s\n",
            "7\n",
            "Epoch: 0074 loss_train: 0.8804 acc_train: 0.6833 loss_val: 0.8522 acc_val: 0.5300 time: 0.0521s\n",
            "8\n",
            "Epoch: 0075 loss_train: 1.2865 acc_train: 0.5833 loss_val: 0.7778 acc_val: 0.7240 time: 0.0518s\n",
            "0\n",
            "Epoch: 0076 loss_train: 0.7998 acc_train: 0.6500 loss_val: 0.7535 acc_val: 0.7600 time: 0.0522s\n",
            "0\n",
            "Epoch: 0077 loss_train: 0.9658 acc_train: 0.6167 loss_val: 0.7433 acc_val: 0.7300 time: 0.0518s\n",
            "0\n",
            "Epoch: 0078 loss_train: 0.6924 acc_train: 0.7500 loss_val: 0.7362 acc_val: 0.7260 time: 0.0517s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.0696 acc_train: 0.6500 loss_val: 0.7155 acc_val: 0.6820 time: 0.0519s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.0823 acc_train: 0.6667 loss_val: 0.7049 acc_val: 0.6180 time: 0.0518s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.2832 acc_train: 0.5667 loss_val: 0.7021 acc_val: 0.6260 time: 0.0519s\n",
            "0\n",
            "Epoch: 0082 loss_train: 0.9671 acc_train: 0.6667 loss_val: 0.6973 acc_val: 0.6720 time: 0.0517s\n",
            "0\n",
            "Epoch: 0083 loss_train: 0.9226 acc_train: 0.6500 loss_val: 0.7064 acc_val: 0.7280 time: 0.0522s\n",
            "0\n",
            "Epoch: 0084 loss_train: 0.7152 acc_train: 0.7333 loss_val: 0.6974 acc_val: 0.7980 time: 0.0525s\n",
            "1\n",
            "Epoch: 0085 loss_train: 0.8984 acc_train: 0.7333 loss_val: 0.6846 acc_val: 0.8040 time: 0.0525s\n",
            "2\n",
            "Epoch: 0086 loss_train: 1.2064 acc_train: 0.6333 loss_val: 0.6693 acc_val: 0.7660 time: 0.0517s\n",
            "0\n",
            "Epoch: 0087 loss_train: 0.9143 acc_train: 0.7000 loss_val: 0.6911 acc_val: 0.6980 time: 0.0519s\n",
            "0\n",
            "Epoch: 0088 loss_train: 0.7031 acc_train: 0.7667 loss_val: 0.6454 acc_val: 0.7300 time: 0.0520s\n",
            "1\n",
            "Epoch: 0089 loss_train: 0.6924 acc_train: 0.7333 loss_val: 0.5957 acc_val: 0.8180 time: 0.0520s\n",
            "0\n",
            "Epoch: 0090 loss_train: 0.7237 acc_train: 0.7000 loss_val: 0.6483 acc_val: 0.6700 time: 0.0518s\n",
            "0\n",
            "Epoch: 0091 loss_train: 0.8727 acc_train: 0.6667 loss_val: 0.7762 acc_val: 0.6020 time: 0.0521s\n",
            "1\n",
            "Epoch: 0092 loss_train: 0.9642 acc_train: 0.7500 loss_val: 0.8635 acc_val: 0.5780 time: 0.0520s\n",
            "2\n",
            "Epoch: 0093 loss_train: 0.8799 acc_train: 0.7167 loss_val: 0.7810 acc_val: 0.5940 time: 0.0525s\n",
            "3\n",
            "Epoch: 0094 loss_train: 1.1996 acc_train: 0.5833 loss_val: 0.6600 acc_val: 0.6280 time: 0.0569s\n",
            "4\n",
            "Epoch: 0095 loss_train: 1.4764 acc_train: 0.5500 loss_val: 0.5825 acc_val: 0.7340 time: 0.0547s\n",
            "5\n",
            "Epoch: 0096 loss_train: 0.6764 acc_train: 0.7167 loss_val: 0.5659 acc_val: 0.8180 time: 0.0523s\n",
            "0\n",
            "Epoch: 0097 loss_train: 0.9995 acc_train: 0.6333 loss_val: 0.5814 acc_val: 0.7960 time: 0.0519s\n",
            "0\n",
            "Epoch: 0098 loss_train: 0.9678 acc_train: 0.6500 loss_val: 0.5796 acc_val: 0.8020 time: 0.0525s\n",
            "1\n",
            "Epoch: 0099 loss_train: 0.7906 acc_train: 0.7167 loss_val: 0.5775 acc_val: 0.8120 time: 0.0522s\n",
            "2\n",
            "Epoch: 0100 loss_train: 0.8926 acc_train: 0.6333 loss_val: 0.6203 acc_val: 0.7260 time: 0.0521s\n",
            "3\n",
            "Epoch: 0101 loss_train: 0.9066 acc_train: 0.6333 loss_val: 0.6634 acc_val: 0.6520 time: 0.0527s\n",
            "4\n",
            "Epoch: 0102 loss_train: 0.6683 acc_train: 0.7333 loss_val: 0.7369 acc_val: 0.6040 time: 0.0526s\n",
            "5\n",
            "Epoch: 0103 loss_train: 0.8374 acc_train: 0.7500 loss_val: 0.7590 acc_val: 0.5920 time: 0.0525s\n",
            "6\n",
            "Epoch: 0104 loss_train: 0.8401 acc_train: 0.6833 loss_val: 0.6191 acc_val: 0.6760 time: 0.0524s\n",
            "7\n",
            "Epoch: 0105 loss_train: 0.9915 acc_train: 0.5833 loss_val: 0.5338 acc_val: 0.8020 time: 0.0539s\n",
            "8\n",
            "Epoch: 0106 loss_train: 0.6889 acc_train: 0.7833 loss_val: 0.5409 acc_val: 0.8000 time: 0.0517s\n",
            "0\n",
            "Epoch: 0107 loss_train: 0.8404 acc_train: 0.7833 loss_val: 0.6237 acc_val: 0.7360 time: 0.0521s\n",
            "1\n",
            "Epoch: 0108 loss_train: 0.7471 acc_train: 0.6500 loss_val: 0.7258 acc_val: 0.6680 time: 0.0521s\n",
            "2\n",
            "Epoch: 0109 loss_train: 0.7904 acc_train: 0.7333 loss_val: 0.7589 acc_val: 0.6600 time: 0.0528s\n",
            "3\n",
            "Epoch: 0110 loss_train: 1.0414 acc_train: 0.7333 loss_val: 0.7094 acc_val: 0.6960 time: 0.0521s\n",
            "4\n",
            "Epoch: 0111 loss_train: 1.0536 acc_train: 0.6667 loss_val: 0.5869 acc_val: 0.7700 time: 0.0521s\n",
            "5\n",
            "Epoch: 0112 loss_train: 0.9200 acc_train: 0.6833 loss_val: 0.5309 acc_val: 0.7900 time: 0.0525s\n",
            "6\n",
            "Epoch: 0113 loss_train: 0.6919 acc_train: 0.6667 loss_val: 0.4957 acc_val: 0.8140 time: 0.0531s\n",
            "0\n",
            "Epoch: 0114 loss_train: 0.8066 acc_train: 0.7000 loss_val: 0.5089 acc_val: 0.8020 time: 0.0518s\n",
            "0\n",
            "Epoch: 0115 loss_train: 0.8935 acc_train: 0.7333 loss_val: 0.5234 acc_val: 0.7740 time: 0.0521s\n",
            "1\n",
            "Epoch: 0116 loss_train: 0.8031 acc_train: 0.7167 loss_val: 0.5189 acc_val: 0.7980 time: 0.0525s\n",
            "2\n",
            "Epoch: 0117 loss_train: 0.8469 acc_train: 0.6667 loss_val: 0.5112 acc_val: 0.8140 time: 0.0542s\n",
            "3\n",
            "Epoch: 0118 loss_train: 0.7600 acc_train: 0.7833 loss_val: 0.5174 acc_val: 0.8340 time: 0.0520s\n",
            "4\n",
            "Epoch: 0119 loss_train: 0.8254 acc_train: 0.7000 loss_val: 0.5473 acc_val: 0.8140 time: 0.0521s\n",
            "0\n",
            "Epoch: 0120 loss_train: 0.7559 acc_train: 0.6833 loss_val: 0.5622 acc_val: 0.8080 time: 0.0539s\n",
            "1\n",
            "Epoch: 0121 loss_train: 1.0912 acc_train: 0.6333 loss_val: 0.5601 acc_val: 0.7860 time: 0.0525s\n",
            "2\n",
            "Epoch: 0122 loss_train: 0.7941 acc_train: 0.6333 loss_val: 0.6165 acc_val: 0.7800 time: 0.0524s\n",
            "3\n",
            "Epoch: 0123 loss_train: 0.9367 acc_train: 0.7167 loss_val: 0.7651 acc_val: 0.7640 time: 0.0521s\n",
            "4\n",
            "Epoch: 0124 loss_train: 0.8561 acc_train: 0.7333 loss_val: 0.9094 acc_val: 0.7220 time: 0.0523s\n",
            "5\n",
            "Epoch: 0125 loss_train: 0.8232 acc_train: 0.7833 loss_val: 0.9070 acc_val: 0.7340 time: 0.0524s\n",
            "6\n",
            "Epoch: 0126 loss_train: 0.9103 acc_train: 0.6833 loss_val: 0.7485 acc_val: 0.7900 time: 0.0521s\n",
            "7\n",
            "Epoch: 0127 loss_train: 1.1517 acc_train: 0.7167 loss_val: 0.7348 acc_val: 0.7940 time: 0.0521s\n",
            "8\n",
            "Epoch: 0128 loss_train: 0.7561 acc_train: 0.7000 loss_val: 0.8366 acc_val: 0.7660 time: 0.0531s\n",
            "9\n",
            "Epoch: 0129 loss_train: 1.0603 acc_train: 0.7000 loss_val: 0.8546 acc_val: 0.7460 time: 0.0527s\n",
            "10\n",
            "Epoch: 0130 loss_train: 0.8819 acc_train: 0.6667 loss_val: 0.8012 acc_val: 0.7660 time: 0.0521s\n",
            "11\n",
            "Epoch: 0131 loss_train: 0.6324 acc_train: 0.7833 loss_val: 0.7105 acc_val: 0.8020 time: 0.0520s\n",
            "12\n",
            "Epoch: 0132 loss_train: 0.9239 acc_train: 0.7667 loss_val: 0.6297 acc_val: 0.8020 time: 0.0525s\n",
            "13\n",
            "Epoch: 0133 loss_train: 1.0108 acc_train: 0.6167 loss_val: 0.6077 acc_val: 0.7900 time: 0.0527s\n",
            "14\n",
            "Epoch: 0134 loss_train: 1.0842 acc_train: 0.7167 loss_val: 0.6069 acc_val: 0.7800 time: 0.0520s\n",
            "15\n",
            "Epoch: 0135 loss_train: 0.9689 acc_train: 0.7333 loss_val: 0.6017 acc_val: 0.7860 time: 0.0520s\n",
            "16\n",
            "Epoch: 0136 loss_train: 0.8537 acc_train: 0.6833 loss_val: 0.6217 acc_val: 0.7760 time: 0.0520s\n",
            "17\n",
            "Epoch: 0137 loss_train: 1.0812 acc_train: 0.6833 loss_val: 0.6014 acc_val: 0.7800 time: 0.0529s\n",
            "18\n",
            "Epoch: 0138 loss_train: 0.7941 acc_train: 0.7167 loss_val: 0.5828 acc_val: 0.7880 time: 0.0522s\n",
            "19\n",
            "Epoch: 0139 loss_train: 1.0547 acc_train: 0.7167 loss_val: 0.5742 acc_val: 0.8120 time: 0.0522s\n",
            "20\n",
            "Epoch: 0140 loss_train: 1.0094 acc_train: 0.6333 loss_val: 0.6469 acc_val: 0.7900 time: 0.0520s\n",
            "21\n",
            "Epoch: 0141 loss_train: 0.9070 acc_train: 0.7500 loss_val: 0.6647 acc_val: 0.7800 time: 0.0527s\n",
            "22\n",
            "Epoch: 0142 loss_train: 0.8175 acc_train: 0.7000 loss_val: 0.6605 acc_val: 0.7860 time: 0.0530s\n",
            "23\n",
            "Epoch: 0143 loss_train: 0.7873 acc_train: 0.7167 loss_val: 0.6406 acc_val: 0.7900 time: 0.0519s\n",
            "24\n",
            "Epoch: 0144 loss_train: 0.7305 acc_train: 0.7500 loss_val: 0.6313 acc_val: 0.7980 time: 0.0534s\n",
            "25\n",
            "Epoch: 0145 loss_train: 0.7587 acc_train: 0.8000 loss_val: 0.6224 acc_val: 0.7800 time: 0.0523s\n",
            "26\n",
            "Epoch: 0146 loss_train: 0.5683 acc_train: 0.7667 loss_val: 0.5993 acc_val: 0.7980 time: 0.0520s\n",
            "27\n",
            "Epoch: 0147 loss_train: 0.7206 acc_train: 0.6500 loss_val: 0.5461 acc_val: 0.8020 time: 0.0520s\n",
            "28\n",
            "Epoch: 0148 loss_train: 0.5957 acc_train: 0.7333 loss_val: 0.5296 acc_val: 0.8100 time: 0.0528s\n",
            "29\n",
            "Epoch: 0149 loss_train: 0.5495 acc_train: 0.7833 loss_val: 0.5246 acc_val: 0.8120 time: 0.0526s\n",
            "30\n",
            "Epoch: 0150 loss_train: 0.8473 acc_train: 0.7667 loss_val: 0.5175 acc_val: 0.8160 time: 0.0520s\n",
            "31\n",
            "Epoch: 0151 loss_train: 0.8093 acc_train: 0.7167 loss_val: 0.5194 acc_val: 0.8260 time: 0.0521s\n",
            "32\n",
            "Epoch: 0152 loss_train: 0.5067 acc_train: 0.8167 loss_val: 0.5335 acc_val: 0.8340 time: 0.0522s\n",
            "33\n",
            "Epoch: 0153 loss_train: 0.5587 acc_train: 0.7333 loss_val: 0.5571 acc_val: 0.8180 time: 0.0528s\n",
            "0\n",
            "Epoch: 0154 loss_train: 0.8529 acc_train: 0.7667 loss_val: 0.5857 acc_val: 0.8160 time: 0.0526s\n",
            "1\n",
            "Epoch: 0155 loss_train: 0.5621 acc_train: 0.7833 loss_val: 0.5930 acc_val: 0.8200 time: 0.0523s\n",
            "2\n",
            "Epoch: 0156 loss_train: 0.6154 acc_train: 0.7667 loss_val: 0.6166 acc_val: 0.8200 time: 0.0521s\n",
            "3\n",
            "Epoch: 0157 loss_train: 0.5829 acc_train: 0.8500 loss_val: 0.6556 acc_val: 0.8240 time: 0.0526s\n",
            "4\n",
            "Epoch: 0158 loss_train: 1.0290 acc_train: 0.6833 loss_val: 0.6184 acc_val: 0.8200 time: 0.0521s\n",
            "5\n",
            "Epoch: 0159 loss_train: 0.8733 acc_train: 0.7667 loss_val: 0.6009 acc_val: 0.8280 time: 0.0522s\n",
            "6\n",
            "Epoch: 0160 loss_train: 0.7902 acc_train: 0.7500 loss_val: 0.5994 acc_val: 0.8220 time: 0.0522s\n",
            "7\n",
            "Epoch: 0161 loss_train: 0.7867 acc_train: 0.7167 loss_val: 0.6077 acc_val: 0.8180 time: 0.0525s\n",
            "8\n",
            "Epoch: 0162 loss_train: 0.4960 acc_train: 0.8167 loss_val: 0.6298 acc_val: 0.8120 time: 0.0521s\n",
            "9\n",
            "Epoch: 0163 loss_train: 0.9256 acc_train: 0.7000 loss_val: 0.6155 acc_val: 0.8200 time: 0.0525s\n",
            "10\n",
            "Epoch: 0164 loss_train: 0.6483 acc_train: 0.7833 loss_val: 0.5966 acc_val: 0.8120 time: 0.0525s\n",
            "11\n",
            "Epoch: 0165 loss_train: 1.0309 acc_train: 0.7500 loss_val: 0.5917 acc_val: 0.7960 time: 0.0524s\n",
            "12\n",
            "Epoch: 0166 loss_train: 1.2076 acc_train: 0.6667 loss_val: 0.5835 acc_val: 0.7920 time: 0.0523s\n",
            "13\n",
            "Epoch: 0167 loss_train: 0.9906 acc_train: 0.6500 loss_val: 0.5673 acc_val: 0.7740 time: 0.0525s\n",
            "14\n",
            "Epoch: 0168 loss_train: 0.9146 acc_train: 0.6833 loss_val: 0.5512 acc_val: 0.7780 time: 0.0522s\n",
            "15\n",
            "Epoch: 0169 loss_train: 0.7636 acc_train: 0.6500 loss_val: 0.5361 acc_val: 0.7940 time: 0.0523s\n",
            "16\n",
            "Epoch: 0170 loss_train: 0.9157 acc_train: 0.6333 loss_val: 0.5263 acc_val: 0.8100 time: 0.0522s\n",
            "17\n",
            "Epoch: 0171 loss_train: 0.8683 acc_train: 0.6667 loss_val: 0.5479 acc_val: 0.8100 time: 0.0519s\n",
            "18\n",
            "Epoch: 0172 loss_train: 0.6062 acc_train: 0.7667 loss_val: 0.5900 acc_val: 0.8060 time: 0.0520s\n",
            "19\n",
            "Epoch: 0173 loss_train: 1.0192 acc_train: 0.5500 loss_val: 0.5807 acc_val: 0.8160 time: 0.0530s\n",
            "20\n",
            "Epoch: 0174 loss_train: 0.6049 acc_train: 0.7667 loss_val: 0.5868 acc_val: 0.8200 time: 0.0523s\n",
            "21\n",
            "Epoch: 0175 loss_train: 0.9351 acc_train: 0.6667 loss_val: 0.5622 acc_val: 0.8220 time: 0.0522s\n",
            "22\n",
            "Epoch: 0176 loss_train: 0.5309 acc_train: 0.8167 loss_val: 0.5508 acc_val: 0.8280 time: 0.0531s\n",
            "23\n",
            "Epoch: 0177 loss_train: 0.7386 acc_train: 0.8167 loss_val: 0.5626 acc_val: 0.8200 time: 0.0535s\n",
            "24\n",
            "Epoch: 0178 loss_train: 1.1751 acc_train: 0.6500 loss_val: 0.6199 acc_val: 0.8100 time: 0.0523s\n",
            "25\n",
            "Epoch: 0179 loss_train: 0.9347 acc_train: 0.7500 loss_val: 0.7044 acc_val: 0.7980 time: 0.0522s\n",
            "26\n",
            "Epoch: 0180 loss_train: 0.8288 acc_train: 0.6667 loss_val: 0.8157 acc_val: 0.7740 time: 0.0522s\n",
            "27\n",
            "Epoch: 0181 loss_train: 0.6342 acc_train: 0.7500 loss_val: 0.9035 acc_val: 0.7660 time: 0.0539s\n",
            "28\n",
            "Epoch: 0182 loss_train: 0.9962 acc_train: 0.6833 loss_val: 0.9179 acc_val: 0.7620 time: 0.0521s\n",
            "29\n",
            "Epoch: 0183 loss_train: 0.8296 acc_train: 0.6667 loss_val: 0.8126 acc_val: 0.7880 time: 0.0521s\n",
            "30\n",
            "Epoch: 0184 loss_train: 0.6628 acc_train: 0.7333 loss_val: 0.6897 acc_val: 0.8140 time: 0.0521s\n",
            "31\n",
            "Epoch: 0185 loss_train: 0.7309 acc_train: 0.7333 loss_val: 0.5964 acc_val: 0.8040 time: 0.0525s\n",
            "32\n",
            "Epoch: 0186 loss_train: 0.5703 acc_train: 0.8000 loss_val: 0.6158 acc_val: 0.7800 time: 0.0541s\n",
            "33\n",
            "Epoch: 0187 loss_train: 0.7839 acc_train: 0.7333 loss_val: 0.7003 acc_val: 0.7280 time: 0.0521s\n",
            "34\n",
            "Epoch: 0188 loss_train: 1.0664 acc_train: 0.7333 loss_val: 0.6248 acc_val: 0.7480 time: 0.0520s\n",
            "35\n",
            "Epoch: 0189 loss_train: 0.5805 acc_train: 0.7667 loss_val: 0.5596 acc_val: 0.7860 time: 0.0524s\n",
            "36\n",
            "Epoch: 0190 loss_train: 0.9941 acc_train: 0.6833 loss_val: 0.5332 acc_val: 0.8220 time: 0.0532s\n",
            "37\n",
            "Epoch: 0191 loss_train: 0.9140 acc_train: 0.6667 loss_val: 0.5871 acc_val: 0.8220 time: 0.0520s\n",
            "38\n",
            "Epoch: 0192 loss_train: 0.8604 acc_train: 0.7667 loss_val: 0.6851 acc_val: 0.7800 time: 0.0516s\n",
            "39\n",
            "Epoch: 0193 loss_train: 0.8262 acc_train: 0.7333 loss_val: 0.7950 acc_val: 0.7540 time: 0.0526s\n",
            "40\n",
            "Epoch: 0194 loss_train: 0.5410 acc_train: 0.8000 loss_val: 0.8307 acc_val: 0.7440 time: 0.0526s\n",
            "41\n",
            "Epoch: 0195 loss_train: 1.0560 acc_train: 0.6167 loss_val: 0.7373 acc_val: 0.7540 time: 0.0522s\n",
            "42\n",
            "Epoch: 0196 loss_train: 0.8149 acc_train: 0.7000 loss_val: 0.6703 acc_val: 0.7780 time: 0.0523s\n",
            "43\n",
            "Epoch: 0197 loss_train: 0.6792 acc_train: 0.7000 loss_val: 0.6190 acc_val: 0.7920 time: 0.0529s\n",
            "44\n",
            "Epoch: 0198 loss_train: 0.6859 acc_train: 0.7667 loss_val: 0.5911 acc_val: 0.7880 time: 0.0522s\n",
            "45\n",
            "Epoch: 0199 loss_train: 1.0402 acc_train: 0.7667 loss_val: 0.6387 acc_val: 0.7400 time: 0.0519s\n",
            "46\n",
            "Epoch: 0200 loss_train: 0.9595 acc_train: 0.7333 loss_val: 0.7248 acc_val: 0.7060 time: 0.0521s\n",
            "47\n",
            "Epoch: 0201 loss_train: 0.8756 acc_train: 0.6333 loss_val: 0.7718 acc_val: 0.6900 time: 0.0526s\n",
            "48\n",
            "Epoch: 0202 loss_train: 1.0229 acc_train: 0.6667 loss_val: 0.6369 acc_val: 0.7520 time: 0.0525s\n",
            "49\n",
            "Epoch: 0203 loss_train: 0.9872 acc_train: 0.6833 loss_val: 0.6846 acc_val: 0.7500 time: 0.0521s\n",
            "50\n",
            "Epoch: 0204 loss_train: 0.7947 acc_train: 0.8000 loss_val: 0.7887 acc_val: 0.7320 time: 0.0522s\n",
            "51\n",
            "Epoch: 0205 loss_train: 1.1194 acc_train: 0.7167 loss_val: 0.7774 acc_val: 0.7340 time: 0.0524s\n",
            "52\n",
            "Epoch: 0206 loss_train: 0.4270 acc_train: 0.8667 loss_val: 0.7734 acc_val: 0.7420 time: 0.0520s\n",
            "53\n",
            "Epoch: 0207 loss_train: 1.0967 acc_train: 0.6333 loss_val: 0.7036 acc_val: 0.7460 time: 0.0523s\n",
            "54\n",
            "Epoch: 0208 loss_train: 0.7202 acc_train: 0.7167 loss_val: 0.6538 acc_val: 0.7480 time: 0.0524s\n",
            "55\n",
            "Epoch: 0209 loss_train: 0.9473 acc_train: 0.6500 loss_val: 0.6183 acc_val: 0.7840 time: 0.0523s\n",
            "56\n",
            "Epoch: 0210 loss_train: 1.1696 acc_train: 0.6833 loss_val: 0.6220 acc_val: 0.7820 time: 0.0521s\n",
            "57\n",
            "Epoch: 0211 loss_train: 0.6464 acc_train: 0.6833 loss_val: 0.6650 acc_val: 0.7760 time: 0.0522s\n",
            "58\n",
            "Epoch: 0212 loss_train: 0.8087 acc_train: 0.7833 loss_val: 0.6804 acc_val: 0.7700 time: 0.0521s\n",
            "59\n",
            "Epoch: 0213 loss_train: 0.9789 acc_train: 0.6167 loss_val: 0.6900 acc_val: 0.7620 time: 0.0529s\n",
            "60\n",
            "Epoch: 0214 loss_train: 1.2334 acc_train: 0.7500 loss_val: 0.6856 acc_val: 0.7480 time: 0.0525s\n",
            "61\n",
            "Epoch: 0215 loss_train: 0.8682 acc_train: 0.7333 loss_val: 0.6543 acc_val: 0.7780 time: 0.0541s\n",
            "62\n",
            "Epoch: 0216 loss_train: 0.8031 acc_train: 0.8000 loss_val: 0.6606 acc_val: 0.7860 time: 0.0525s\n",
            "63\n",
            "Epoch: 0217 loss_train: 0.6639 acc_train: 0.7333 loss_val: 0.6416 acc_val: 0.7880 time: 0.0522s\n",
            "64\n",
            "Epoch: 0218 loss_train: 0.6003 acc_train: 0.8000 loss_val: 0.5868 acc_val: 0.7960 time: 0.0524s\n",
            "65\n",
            "Epoch: 0219 loss_train: 1.0940 acc_train: 0.7167 loss_val: 0.5395 acc_val: 0.8120 time: 0.0520s\n",
            "66\n",
            "Epoch: 0220 loss_train: 0.7982 acc_train: 0.7833 loss_val: 0.5282 acc_val: 0.8180 time: 0.0521s\n",
            "67\n",
            "Epoch: 0221 loss_train: 0.6996 acc_train: 0.7833 loss_val: 0.5547 acc_val: 0.8140 time: 0.0524s\n",
            "68\n",
            "Epoch: 0222 loss_train: 0.8892 acc_train: 0.7667 loss_val: 0.5904 acc_val: 0.7920 time: 0.0530s\n",
            "69\n",
            "Epoch: 0223 loss_train: 1.2387 acc_train: 0.6167 loss_val: 0.5880 acc_val: 0.7900 time: 0.0521s\n",
            "70\n",
            "Epoch: 0224 loss_train: 1.1487 acc_train: 0.6500 loss_val: 0.5807 acc_val: 0.8040 time: 0.0520s\n",
            "71\n",
            "Epoch: 0225 loss_train: 0.8792 acc_train: 0.7333 loss_val: 0.6523 acc_val: 0.7860 time: 0.0523s\n",
            "72\n",
            "Epoch: 0226 loss_train: 0.9520 acc_train: 0.6833 loss_val: 0.7573 acc_val: 0.7500 time: 0.0529s\n",
            "73\n",
            "Epoch: 0227 loss_train: 0.9749 acc_train: 0.6333 loss_val: 0.8514 acc_val: 0.7080 time: 0.0522s\n",
            "74\n",
            "Epoch: 0228 loss_train: 0.9289 acc_train: 0.7167 loss_val: 0.8650 acc_val: 0.7040 time: 0.0522s\n",
            "75\n",
            "Epoch: 0229 loss_train: 0.8708 acc_train: 0.7500 loss_val: 0.8210 acc_val: 0.7240 time: 0.0523s\n",
            "76\n",
            "Epoch: 0230 loss_train: 0.8333 acc_train: 0.7000 loss_val: 0.8427 acc_val: 0.7200 time: 0.0531s\n",
            "77\n",
            "Epoch: 0231 loss_train: 0.9372 acc_train: 0.6667 loss_val: 0.7971 acc_val: 0.7320 time: 0.0526s\n",
            "78\n",
            "Epoch: 0232 loss_train: 0.9163 acc_train: 0.6833 loss_val: 0.7587 acc_val: 0.7600 time: 0.0542s\n",
            "79\n",
            "Epoch: 0233 loss_train: 1.1123 acc_train: 0.6833 loss_val: 0.7449 acc_val: 0.7660 time: 0.0524s\n",
            "80\n",
            "Epoch: 0234 loss_train: 1.0850 acc_train: 0.7167 loss_val: 0.7263 acc_val: 0.7780 time: 0.0521s\n",
            "81\n",
            "Epoch: 0235 loss_train: 2.5103 acc_train: 0.7000 loss_val: 0.7375 acc_val: 0.7780 time: 0.0524s\n",
            "82\n",
            "Epoch: 0236 loss_train: 1.0667 acc_train: 0.6833 loss_val: 0.7083 acc_val: 0.7780 time: 0.0524s\n",
            "83\n",
            "Epoch: 0237 loss_train: 1.0197 acc_train: 0.7167 loss_val: 0.6656 acc_val: 0.8020 time: 0.0530s\n",
            "84\n",
            "Epoch: 0238 loss_train: 0.9731 acc_train: 0.7333 loss_val: 0.6360 acc_val: 0.8080 time: 0.0521s\n",
            "85\n",
            "Epoch: 0239 loss_train: 0.9514 acc_train: 0.7667 loss_val: 0.6134 acc_val: 0.8140 time: 0.0523s\n",
            "86\n",
            "Epoch: 0240 loss_train: 0.9625 acc_train: 0.7000 loss_val: 0.6444 acc_val: 0.8040 time: 0.0522s\n",
            "87\n",
            "Epoch: 0241 loss_train: 1.1086 acc_train: 0.7500 loss_val: 0.6648 acc_val: 0.8020 time: 0.0524s\n",
            "88\n",
            "Epoch: 0242 loss_train: 1.1061 acc_train: 0.6667 loss_val: 0.7180 acc_val: 0.7840 time: 0.0522s\n",
            "89\n",
            "Epoch: 0243 loss_train: 1.0300 acc_train: 0.6500 loss_val: 0.7412 acc_val: 0.7740 time: 0.0522s\n",
            "90\n",
            "Epoch: 0244 loss_train: 0.9802 acc_train: 0.6667 loss_val: 0.7355 acc_val: 0.7780 time: 0.0521s\n",
            "91\n",
            "Epoch: 0245 loss_train: 1.0928 acc_train: 0.6500 loss_val: 0.6853 acc_val: 0.7920 time: 0.0530s\n",
            "92\n",
            "Epoch: 0246 loss_train: 0.6892 acc_train: 0.7333 loss_val: 0.6530 acc_val: 0.8040 time: 0.0535s\n",
            "93\n",
            "Epoch: 0247 loss_train: 1.0740 acc_train: 0.6333 loss_val: 0.6306 acc_val: 0.8120 time: 0.0520s\n",
            "94\n",
            "Epoch: 0248 loss_train: 0.5907 acc_train: 0.8167 loss_val: 0.6573 acc_val: 0.8100 time: 0.0522s\n",
            "95\n",
            "Epoch: 0249 loss_train: 1.3925 acc_train: 0.6667 loss_val: 0.7214 acc_val: 0.8040 time: 0.0527s\n",
            "96\n",
            "Epoch: 0250 loss_train: 0.9752 acc_train: 0.6833 loss_val: 0.7303 acc_val: 0.7980 time: 0.0553s\n",
            "97\n",
            "Epoch: 0251 loss_train: 1.2378 acc_train: 0.6667 loss_val: 0.6263 acc_val: 0.8280 time: 0.0532s\n",
            "98\n",
            "Epoch: 0252 loss_train: 0.7703 acc_train: 0.7833 loss_val: 0.5843 acc_val: 0.8200 time: 0.0520s\n",
            "99\n",
            "Early stop! Min loss:  0.49568673968315125 , Max accuracy:  0.834\n",
            "Early stop model validation loss:  0.49568673968315125 , accuracy:  0.8140000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 13.8749s\n",
            "Loading 112th epoch\n",
            "Test set results: loss= 0.5298 accuracy= 0.7950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7950, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sttg1cakhlX",
        "outputId": "04af2dbf-6879-4184-9a3c-4b84ce941f18"
      },
      "source": [
        "Train(sample=1) #citeseer\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.9370 acc_train: 0.1667 loss_val: 1.8103 acc_val: 0.2320 time: 0.0518s\n",
            "0\n",
            "Epoch: 0002 loss_train: 1.9388 acc_train: 0.1667 loss_val: 1.8078 acc_val: 0.2320 time: 0.0439s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.9432 acc_train: 0.1667 loss_val: 1.8055 acc_val: 0.2320 time: 0.0442s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.9475 acc_train: 0.1667 loss_val: 1.8033 acc_val: 0.2320 time: 0.0441s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.9508 acc_train: 0.1667 loss_val: 1.8013 acc_val: 0.2320 time: 0.0446s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.9580 acc_train: 0.1667 loss_val: 1.7996 acc_val: 0.2320 time: 0.0428s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.9669 acc_train: 0.1667 loss_val: 1.7983 acc_val: 0.2320 time: 0.0425s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.9745 acc_train: 0.1667 loss_val: 1.7978 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.9845 acc_train: 0.1667 loss_val: 1.7977 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.9943 acc_train: 0.1667 loss_val: 1.7979 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0011 loss_train: 2.0061 acc_train: 0.1667 loss_val: 1.7982 acc_val: 0.2320 time: 0.0426s\n",
            "0\n",
            "Epoch: 0012 loss_train: 2.0194 acc_train: 0.1667 loss_val: 1.7987 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0013 loss_train: 2.0325 acc_train: 0.1667 loss_val: 1.7995 acc_val: 0.2320 time: 0.0439s\n",
            "0\n",
            "Epoch: 0014 loss_train: 2.0501 acc_train: 0.1667 loss_val: 1.8005 acc_val: 0.2320 time: 0.0431s\n",
            "0\n",
            "Epoch: 0015 loss_train: 2.0596 acc_train: 0.1667 loss_val: 1.8020 acc_val: 0.2320 time: 0.0431s\n",
            "0\n",
            "Epoch: 0016 loss_train: 2.0755 acc_train: 0.1667 loss_val: 1.8038 acc_val: 0.2320 time: 0.0446s\n",
            "0\n",
            "Epoch: 0017 loss_train: 2.0952 acc_train: 0.1667 loss_val: 1.8059 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0018 loss_train: 2.1127 acc_train: 0.1667 loss_val: 1.8083 acc_val: 0.2320 time: 0.0425s\n",
            "0\n",
            "Epoch: 0019 loss_train: 2.1229 acc_train: 0.1667 loss_val: 1.8111 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0020 loss_train: 2.1421 acc_train: 0.1667 loss_val: 1.8145 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0021 loss_train: 2.1509 acc_train: 0.1667 loss_val: 1.8190 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0022 loss_train: 2.1761 acc_train: 0.1667 loss_val: 1.8236 acc_val: 0.2320 time: 0.0425s\n",
            "0\n",
            "Epoch: 0023 loss_train: 2.1846 acc_train: 0.1667 loss_val: 1.8285 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0024 loss_train: 2.1974 acc_train: 0.1667 loss_val: 1.8343 acc_val: 0.2320 time: 0.0426s\n",
            "0\n",
            "Epoch: 0025 loss_train: 2.2072 acc_train: 0.1667 loss_val: 1.8408 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0026 loss_train: 2.2187 acc_train: 0.1667 loss_val: 1.8478 acc_val: 0.2320 time: 0.0449s\n",
            "0\n",
            "Epoch: 0027 loss_train: 2.2326 acc_train: 0.1667 loss_val: 1.8554 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0028 loss_train: 2.2360 acc_train: 0.1667 loss_val: 1.8640 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0029 loss_train: 2.2438 acc_train: 0.1667 loss_val: 1.8723 acc_val: 0.2320 time: 0.0428s\n",
            "0\n",
            "Epoch: 0030 loss_train: 2.2536 acc_train: 0.1667 loss_val: 1.8801 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0031 loss_train: 2.2613 acc_train: 0.1667 loss_val: 1.8881 acc_val: 0.2320 time: 0.0437s\n",
            "0\n",
            "Epoch: 0032 loss_train: 2.2620 acc_train: 0.1667 loss_val: 1.8946 acc_val: 0.2320 time: 0.0436s\n",
            "0\n",
            "Epoch: 0033 loss_train: 2.2667 acc_train: 0.1667 loss_val: 1.9017 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0034 loss_train: 2.2655 acc_train: 0.1667 loss_val: 1.9076 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0035 loss_train: 2.2660 acc_train: 0.1667 loss_val: 1.9120 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0036 loss_train: 2.2886 acc_train: 0.1667 loss_val: 1.9126 acc_val: 0.2320 time: 0.0447s\n",
            "0\n",
            "Epoch: 0037 loss_train: 2.2769 acc_train: 0.1667 loss_val: 1.9096 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0038 loss_train: 2.2823 acc_train: 0.1667 loss_val: 1.9036 acc_val: 0.2320 time: 0.0417s\n",
            "0\n",
            "Epoch: 0039 loss_train: 2.2726 acc_train: 0.1667 loss_val: 1.8967 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0040 loss_train: 2.2602 acc_train: 0.1667 loss_val: 1.8898 acc_val: 0.2320 time: 0.0418s\n",
            "0\n",
            "Epoch: 0041 loss_train: 2.2544 acc_train: 0.1667 loss_val: 1.8824 acc_val: 0.2320 time: 0.0445s\n",
            "0\n",
            "Epoch: 0042 loss_train: 2.2671 acc_train: 0.1667 loss_val: 1.8764 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0043 loss_train: 2.2453 acc_train: 0.1667 loss_val: 1.8707 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0044 loss_train: 2.2443 acc_train: 0.1667 loss_val: 1.8658 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0045 loss_train: 2.2378 acc_train: 0.1667 loss_val: 1.8622 acc_val: 0.2320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0046 loss_train: 2.2373 acc_train: 0.1667 loss_val: 1.8590 acc_val: 0.2320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0047 loss_train: 2.2307 acc_train: 0.1667 loss_val: 1.8564 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0048 loss_train: 2.2253 acc_train: 0.1667 loss_val: 1.8560 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0049 loss_train: 2.2124 acc_train: 0.1667 loss_val: 1.8573 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0050 loss_train: 2.2044 acc_train: 0.1667 loss_val: 1.8607 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0051 loss_train: 2.2241 acc_train: 0.1667 loss_val: 1.8631 acc_val: 0.2320 time: 0.0455s\n",
            "0\n",
            "Epoch: 0052 loss_train: 2.2255 acc_train: 0.1667 loss_val: 1.8655 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0053 loss_train: 2.2145 acc_train: 0.1667 loss_val: 1.8678 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0054 loss_train: 2.2019 acc_train: 0.1667 loss_val: 1.8698 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0055 loss_train: 2.2088 acc_train: 0.1667 loss_val: 1.8711 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0056 loss_train: 2.2139 acc_train: 0.1667 loss_val: 1.8720 acc_val: 0.2320 time: 0.0428s\n",
            "0\n",
            "Epoch: 0057 loss_train: 2.1944 acc_train: 0.1667 loss_val: 1.8726 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0058 loss_train: 2.2005 acc_train: 0.1667 loss_val: 1.8708 acc_val: 0.2320 time: 0.0431s\n",
            "0\n",
            "Epoch: 0059 loss_train: 2.1992 acc_train: 0.1667 loss_val: 1.8664 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0060 loss_train: 2.1892 acc_train: 0.1667 loss_val: 1.8610 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0061 loss_train: 2.1789 acc_train: 0.1667 loss_val: 1.8553 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0062 loss_train: 2.1807 acc_train: 0.1667 loss_val: 1.8500 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0063 loss_train: 2.1741 acc_train: 0.1667 loss_val: 1.8454 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0064 loss_train: 2.1745 acc_train: 0.1667 loss_val: 1.8405 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0065 loss_train: 2.1808 acc_train: 0.1667 loss_val: 1.8363 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0066 loss_train: 2.1691 acc_train: 0.1667 loss_val: 1.8333 acc_val: 0.2320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0067 loss_train: 2.1688 acc_train: 0.1667 loss_val: 1.8304 acc_val: 0.2320 time: 0.0425s\n",
            "0\n",
            "Epoch: 0068 loss_train: 2.1318 acc_train: 0.1667 loss_val: 1.8315 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0069 loss_train: 2.1612 acc_train: 0.1667 loss_val: 1.8334 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0070 loss_train: 2.1548 acc_train: 0.1667 loss_val: 1.8358 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0071 loss_train: 2.1494 acc_train: 0.1667 loss_val: 1.8370 acc_val: 0.2320 time: 0.0448s\n",
            "0\n",
            "Epoch: 0072 loss_train: 2.1195 acc_train: 0.1667 loss_val: 1.8368 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0073 loss_train: 2.1205 acc_train: 0.1667 loss_val: 1.8364 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0074 loss_train: 2.1499 acc_train: 0.1667 loss_val: 1.8345 acc_val: 0.2320 time: 0.0424s\n",
            "0\n",
            "Epoch: 0075 loss_train: 2.1235 acc_train: 0.1667 loss_val: 1.8304 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0076 loss_train: 2.1198 acc_train: 0.1667 loss_val: 1.8242 acc_val: 0.2320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0077 loss_train: 2.0874 acc_train: 0.1667 loss_val: 1.8178 acc_val: 0.2320 time: 0.0427s\n",
            "0\n",
            "Epoch: 0078 loss_train: 2.1054 acc_train: 0.1667 loss_val: 1.8133 acc_val: 0.2320 time: 0.0441s\n",
            "0\n",
            "Epoch: 0079 loss_train: 2.0832 acc_train: 0.1667 loss_val: 1.8135 acc_val: 0.2320 time: 0.0426s\n",
            "0\n",
            "Epoch: 0080 loss_train: 2.0508 acc_train: 0.1667 loss_val: 1.8160 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0081 loss_train: 2.0898 acc_train: 0.1667 loss_val: 1.8176 acc_val: 0.2320 time: 0.0440s\n",
            "0\n",
            "Epoch: 0082 loss_train: 2.0656 acc_train: 0.1833 loss_val: 1.8200 acc_val: 0.2320 time: 0.0437s\n",
            "0\n",
            "Epoch: 0083 loss_train: 2.0913 acc_train: 0.1667 loss_val: 1.8180 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0084 loss_train: 2.0095 acc_train: 0.1667 loss_val: 1.8172 acc_val: 0.2320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0085 loss_train: 2.0369 acc_train: 0.1667 loss_val: 1.8147 acc_val: 0.2320 time: 0.0425s\n",
            "0\n",
            "Epoch: 0086 loss_train: 2.0542 acc_train: 0.1667 loss_val: 1.8071 acc_val: 0.2320 time: 0.0444s\n",
            "0\n",
            "Epoch: 0087 loss_train: 2.0362 acc_train: 0.1667 loss_val: 1.7971 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0088 loss_train: 2.0057 acc_train: 0.1750 loss_val: 1.7872 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0089 loss_train: 2.0166 acc_train: 0.1667 loss_val: 1.7805 acc_val: 0.2320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.9922 acc_train: 0.2000 loss_val: 1.7757 acc_val: 0.2320 time: 0.0418s\n",
            "0\n",
            "Epoch: 0091 loss_train: 2.0095 acc_train: 0.1667 loss_val: 1.7699 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.9580 acc_train: 0.2167 loss_val: 1.7709 acc_val: 0.2320 time: 0.0418s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.9544 acc_train: 0.1917 loss_val: 1.7741 acc_val: 0.2320 time: 0.0426s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.9500 acc_train: 0.1833 loss_val: 1.7775 acc_val: 0.2320 time: 0.0417s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.8979 acc_train: 0.2083 loss_val: 1.7795 acc_val: 0.2320 time: 0.0422s\n",
            "0\n",
            "Epoch: 0096 loss_train: 2.0124 acc_train: 0.1750 loss_val: 1.7791 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.9351 acc_train: 0.2250 loss_val: 1.7773 acc_val: 0.2320 time: 0.0433s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.9654 acc_train: 0.1750 loss_val: 1.7726 acc_val: 0.2320 time: 0.0429s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.9291 acc_train: 0.1833 loss_val: 1.7650 acc_val: 0.2320 time: 0.0423s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.9440 acc_train: 0.1917 loss_val: 1.7540 acc_val: 0.2320 time: 0.0419s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.9160 acc_train: 0.2000 loss_val: 1.7436 acc_val: 0.2320 time: 0.0441s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.8685 acc_train: 0.2083 loss_val: 1.7374 acc_val: 0.2320 time: 0.0419s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.8690 acc_train: 0.2083 loss_val: 1.7348 acc_val: 0.2340 time: 0.0426s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.8953 acc_train: 0.2083 loss_val: 1.7361 acc_val: 0.2340 time: 0.0440s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.8569 acc_train: 0.2167 loss_val: 1.7399 acc_val: 0.2340 time: 0.0426s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.8683 acc_train: 0.2333 loss_val: 1.7446 acc_val: 0.2340 time: 0.0429s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.8066 acc_train: 0.2083 loss_val: 1.7462 acc_val: 0.2340 time: 0.0425s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.8202 acc_train: 0.2250 loss_val: 1.7427 acc_val: 0.2340 time: 0.0422s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.8513 acc_train: 0.2333 loss_val: 1.7368 acc_val: 0.2340 time: 0.0430s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.7953 acc_train: 0.2583 loss_val: 1.7246 acc_val: 0.2340 time: 0.0431s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.8277 acc_train: 0.2250 loss_val: 1.7135 acc_val: 0.2340 time: 0.0429s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.8294 acc_train: 0.2250 loss_val: 1.7024 acc_val: 0.2340 time: 0.0426s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.7540 acc_train: 0.3000 loss_val: 1.6980 acc_val: 0.2340 time: 0.0418s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.7693 acc_train: 0.2417 loss_val: 1.6985 acc_val: 0.2340 time: 0.0421s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.7791 acc_train: 0.2833 loss_val: 1.6976 acc_val: 0.2340 time: 0.0449s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.7829 acc_train: 0.2667 loss_val: 1.6891 acc_val: 0.2340 time: 0.0423s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.7526 acc_train: 0.2917 loss_val: 1.6823 acc_val: 0.2340 time: 0.0420s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.7699 acc_train: 0.2833 loss_val: 1.6768 acc_val: 0.2340 time: 0.0419s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.7303 acc_train: 0.2833 loss_val: 1.6717 acc_val: 0.2340 time: 0.0419s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.7703 acc_train: 0.2750 loss_val: 1.6664 acc_val: 0.2360 time: 0.0419s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.7508 acc_train: 0.2833 loss_val: 1.6615 acc_val: 0.2360 time: 0.0426s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.7346 acc_train: 0.3000 loss_val: 1.6603 acc_val: 0.2360 time: 0.0418s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.6791 acc_train: 0.3667 loss_val: 1.6641 acc_val: 0.2360 time: 0.0419s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.7100 acc_train: 0.3167 loss_val: 1.6622 acc_val: 0.2360 time: 0.0421s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.7179 acc_train: 0.3250 loss_val: 1.6607 acc_val: 0.2360 time: 0.0441s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.6627 acc_train: 0.3250 loss_val: 1.6568 acc_val: 0.2360 time: 0.0436s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.7099 acc_train: 0.3333 loss_val: 1.6517 acc_val: 0.2380 time: 0.0419s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.6480 acc_train: 0.2917 loss_val: 1.6455 acc_val: 0.2380 time: 0.0421s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.7013 acc_train: 0.2833 loss_val: 1.6329 acc_val: 0.2400 time: 0.0421s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.6747 acc_train: 0.3500 loss_val: 1.6203 acc_val: 0.2400 time: 0.0421s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.6311 acc_train: 0.3667 loss_val: 1.6103 acc_val: 0.2400 time: 0.0422s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.5894 acc_train: 0.3583 loss_val: 1.6047 acc_val: 0.2400 time: 0.0420s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.6160 acc_train: 0.3583 loss_val: 1.6027 acc_val: 0.2420 time: 0.0419s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.5433 acc_train: 0.4250 loss_val: 1.6044 acc_val: 0.2420 time: 0.0418s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.6001 acc_train: 0.3667 loss_val: 1.6083 acc_val: 0.2420 time: 0.0427s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.6273 acc_train: 0.3250 loss_val: 1.6096 acc_val: 0.2420 time: 0.0431s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.6121 acc_train: 0.3833 loss_val: 1.6045 acc_val: 0.2420 time: 0.0422s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.5627 acc_train: 0.3750 loss_val: 1.5971 acc_val: 0.2440 time: 0.0425s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.6058 acc_train: 0.3833 loss_val: 1.5870 acc_val: 0.2440 time: 0.0419s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.5294 acc_train: 0.4500 loss_val: 1.5797 acc_val: 0.2460 time: 0.0419s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.5632 acc_train: 0.4083 loss_val: 1.5761 acc_val: 0.2460 time: 0.0424s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.5331 acc_train: 0.4500 loss_val: 1.5810 acc_val: 0.2440 time: 0.0419s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.5143 acc_train: 0.4750 loss_val: 1.5898 acc_val: 0.2440 time: 0.0421s\n",
            "1\n",
            "Epoch: 0144 loss_train: 1.5164 acc_train: 0.4167 loss_val: 1.5951 acc_val: 0.2440 time: 0.0420s\n",
            "2\n",
            "Epoch: 0145 loss_train: 1.5227 acc_train: 0.4000 loss_val: 1.5903 acc_val: 0.2460 time: 0.0422s\n",
            "3\n",
            "Epoch: 0146 loss_train: 1.4972 acc_train: 0.4250 loss_val: 1.5843 acc_val: 0.2460 time: 0.0431s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.5179 acc_train: 0.4000 loss_val: 1.5730 acc_val: 0.2460 time: 0.0423s\n",
            "0\n",
            "Epoch: 0148 loss_train: 1.4454 acc_train: 0.4667 loss_val: 1.5623 acc_val: 0.2480 time: 0.0418s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.5129 acc_train: 0.4917 loss_val: 1.5578 acc_val: 0.2480 time: 0.0419s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.4991 acc_train: 0.4583 loss_val: 1.5522 acc_val: 0.2520 time: 0.0421s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.4760 acc_train: 0.4667 loss_val: 1.5427 acc_val: 0.2560 time: 0.0421s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.4851 acc_train: 0.4750 loss_val: 1.5344 acc_val: 0.2580 time: 0.0422s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.3814 acc_train: 0.5500 loss_val: 1.5323 acc_val: 0.2580 time: 0.0418s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.4230 acc_train: 0.4833 loss_val: 1.5259 acc_val: 0.2600 time: 0.0420s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.4274 acc_train: 0.4667 loss_val: 1.5209 acc_val: 0.2600 time: 0.0418s\n",
            "0\n",
            "Epoch: 0156 loss_train: 1.3364 acc_train: 0.5500 loss_val: 1.5215 acc_val: 0.2580 time: 0.0422s\n",
            "0\n",
            "Epoch: 0157 loss_train: 1.4443 acc_train: 0.5000 loss_val: 1.5153 acc_val: 0.2620 time: 0.0420s\n",
            "1\n",
            "Epoch: 0158 loss_train: 1.4035 acc_train: 0.5167 loss_val: 1.5146 acc_val: 0.2700 time: 0.0427s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.4474 acc_train: 0.4833 loss_val: 1.5125 acc_val: 0.2760 time: 0.0423s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.4671 acc_train: 0.4417 loss_val: 1.5109 acc_val: 0.2760 time: 0.0422s\n",
            "0\n",
            "Epoch: 0161 loss_train: 1.4124 acc_train: 0.4667 loss_val: 1.5135 acc_val: 0.2760 time: 0.0425s\n",
            "0\n",
            "Epoch: 0162 loss_train: 1.3956 acc_train: 0.5167 loss_val: 1.5153 acc_val: 0.2660 time: 0.0422s\n",
            "0\n",
            "Epoch: 0163 loss_train: 1.4789 acc_train: 0.4833 loss_val: 1.5089 acc_val: 0.2680 time: 0.0421s\n",
            "1\n",
            "Epoch: 0164 loss_train: 1.3433 acc_train: 0.5000 loss_val: 1.4984 acc_val: 0.2780 time: 0.0420s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.3945 acc_train: 0.4917 loss_val: 1.4804 acc_val: 0.2940 time: 0.0420s\n",
            "0\n",
            "Epoch: 0166 loss_train: 1.3217 acc_train: 0.5750 loss_val: 1.4657 acc_val: 0.3100 time: 0.0429s\n",
            "0\n",
            "Epoch: 0167 loss_train: 1.3609 acc_train: 0.5417 loss_val: 1.4556 acc_val: 0.3120 time: 0.0423s\n",
            "0\n",
            "Epoch: 0168 loss_train: 1.3341 acc_train: 0.5167 loss_val: 1.4532 acc_val: 0.3140 time: 0.0426s\n",
            "0\n",
            "Epoch: 0169 loss_train: 1.3513 acc_train: 0.5083 loss_val: 1.4505 acc_val: 0.3140 time: 0.0420s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.3726 acc_train: 0.5333 loss_val: 1.4485 acc_val: 0.3160 time: 0.0419s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.2849 acc_train: 0.6000 loss_val: 1.4513 acc_val: 0.3220 time: 0.0423s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.2706 acc_train: 0.5750 loss_val: 1.4571 acc_val: 0.3160 time: 0.0423s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.2124 acc_train: 0.5917 loss_val: 1.4615 acc_val: 0.3160 time: 0.0423s\n",
            "1\n",
            "Epoch: 0174 loss_train: 1.3018 acc_train: 0.5500 loss_val: 1.4592 acc_val: 0.3260 time: 0.0427s\n",
            "2\n",
            "Epoch: 0175 loss_train: 1.3621 acc_train: 0.5417 loss_val: 1.4445 acc_val: 0.3320 time: 0.0431s\n",
            "0\n",
            "Epoch: 0176 loss_train: 1.2432 acc_train: 0.6333 loss_val: 1.4353 acc_val: 0.3480 time: 0.0435s\n",
            "0\n",
            "Epoch: 0177 loss_train: 1.3028 acc_train: 0.5917 loss_val: 1.4283 acc_val: 0.3560 time: 0.0418s\n",
            "0\n",
            "Epoch: 0178 loss_train: 1.2908 acc_train: 0.5917 loss_val: 1.4135 acc_val: 0.3700 time: 0.0419s\n",
            "0\n",
            "Epoch: 0179 loss_train: 1.3048 acc_train: 0.6000 loss_val: 1.3994 acc_val: 0.3800 time: 0.0421s\n",
            "0\n",
            "Epoch: 0180 loss_train: 1.3743 acc_train: 0.5333 loss_val: 1.3861 acc_val: 0.3920 time: 0.0420s\n",
            "0\n",
            "Epoch: 0181 loss_train: 1.2867 acc_train: 0.5667 loss_val: 1.3787 acc_val: 0.4000 time: 0.0423s\n",
            "0\n",
            "Epoch: 0182 loss_train: 1.2426 acc_train: 0.5917 loss_val: 1.3771 acc_val: 0.4080 time: 0.0420s\n",
            "0\n",
            "Epoch: 0183 loss_train: 1.2026 acc_train: 0.6333 loss_val: 1.3813 acc_val: 0.4120 time: 0.0419s\n",
            "0\n",
            "Epoch: 0184 loss_train: 1.2635 acc_train: 0.5833 loss_val: 1.3849 acc_val: 0.4180 time: 0.0421s\n",
            "0\n",
            "Epoch: 0185 loss_train: 1.0996 acc_train: 0.7167 loss_val: 1.3935 acc_val: 0.3980 time: 0.0421s\n",
            "0\n",
            "Epoch: 0186 loss_train: 1.2601 acc_train: 0.5750 loss_val: 1.3988 acc_val: 0.3900 time: 0.0433s\n",
            "1\n",
            "Epoch: 0187 loss_train: 1.2509 acc_train: 0.6083 loss_val: 1.3967 acc_val: 0.3880 time: 0.0423s\n",
            "2\n",
            "Epoch: 0188 loss_train: 1.2129 acc_train: 0.6000 loss_val: 1.3879 acc_val: 0.3940 time: 0.0425s\n",
            "3\n",
            "Epoch: 0189 loss_train: 1.2154 acc_train: 0.5833 loss_val: 1.3701 acc_val: 0.4100 time: 0.0421s\n",
            "4\n",
            "Epoch: 0190 loss_train: 1.2608 acc_train: 0.5917 loss_val: 1.3546 acc_val: 0.4160 time: 0.0425s\n",
            "0\n",
            "Epoch: 0191 loss_train: 1.3181 acc_train: 0.5250 loss_val: 1.3415 acc_val: 0.4160 time: 0.0427s\n",
            "0\n",
            "Epoch: 0192 loss_train: 1.2208 acc_train: 0.6000 loss_val: 1.3361 acc_val: 0.4260 time: 0.0420s\n",
            "0\n",
            "Epoch: 0193 loss_train: 1.2005 acc_train: 0.6417 loss_val: 1.3383 acc_val: 0.4200 time: 0.0419s\n",
            "0\n",
            "Epoch: 0194 loss_train: 1.1868 acc_train: 0.6583 loss_val: 1.3408 acc_val: 0.4200 time: 0.0424s\n",
            "1\n",
            "Epoch: 0195 loss_train: 1.1316 acc_train: 0.6833 loss_val: 1.3470 acc_val: 0.4080 time: 0.0423s\n",
            "2\n",
            "Epoch: 0196 loss_train: 1.2095 acc_train: 0.6333 loss_val: 1.3458 acc_val: 0.4080 time: 0.0433s\n",
            "3\n",
            "Epoch: 0197 loss_train: 1.1583 acc_train: 0.6500 loss_val: 1.3464 acc_val: 0.4140 time: 0.0437s\n",
            "4\n",
            "Epoch: 0198 loss_train: 1.2063 acc_train: 0.6000 loss_val: 1.3409 acc_val: 0.4220 time: 0.0427s\n",
            "5\n",
            "Epoch: 0199 loss_train: 1.2001 acc_train: 0.6083 loss_val: 1.3323 acc_val: 0.4280 time: 0.0433s\n",
            "6\n",
            "Epoch: 0200 loss_train: 1.2092 acc_train: 0.6250 loss_val: 1.3236 acc_val: 0.4340 time: 0.0418s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.1835 acc_train: 0.6250 loss_val: 1.3158 acc_val: 0.4400 time: 0.0429s\n",
            "0\n",
            "Epoch: 0202 loss_train: 1.2192 acc_train: 0.6083 loss_val: 1.3032 acc_val: 0.4480 time: 0.0419s\n",
            "0\n",
            "Epoch: 0203 loss_train: 1.1118 acc_train: 0.6833 loss_val: 1.2951 acc_val: 0.4560 time: 0.0421s\n",
            "0\n",
            "Epoch: 0204 loss_train: 1.1680 acc_train: 0.7000 loss_val: 1.2899 acc_val: 0.4620 time: 0.0422s\n",
            "0\n",
            "Epoch: 0205 loss_train: 1.1580 acc_train: 0.6500 loss_val: 1.2888 acc_val: 0.4660 time: 0.0421s\n",
            "0\n",
            "Epoch: 0206 loss_train: 1.1583 acc_train: 0.6667 loss_val: 1.2897 acc_val: 0.4560 time: 0.0424s\n",
            "0\n",
            "Epoch: 0207 loss_train: 1.1979 acc_train: 0.6417 loss_val: 1.2883 acc_val: 0.4520 time: 0.0425s\n",
            "1\n",
            "Epoch: 0208 loss_train: 1.1822 acc_train: 0.6667 loss_val: 1.2844 acc_val: 0.4500 time: 0.0419s\n",
            "0\n",
            "Epoch: 0209 loss_train: 1.1663 acc_train: 0.6500 loss_val: 1.2791 acc_val: 0.4520 time: 0.0423s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.1862 acc_train: 0.7000 loss_val: 1.2698 acc_val: 0.4520 time: 0.0419s\n",
            "0\n",
            "Epoch: 0211 loss_train: 1.1521 acc_train: 0.6333 loss_val: 1.2607 acc_val: 0.4620 time: 0.0424s\n",
            "0\n",
            "Epoch: 0212 loss_train: 1.1459 acc_train: 0.6417 loss_val: 1.2522 acc_val: 0.4880 time: 0.0426s\n",
            "0\n",
            "Epoch: 0213 loss_train: 1.1573 acc_train: 0.6333 loss_val: 1.2437 acc_val: 0.5100 time: 0.0418s\n",
            "0\n",
            "Epoch: 0214 loss_train: 1.1615 acc_train: 0.6500 loss_val: 1.2341 acc_val: 0.5260 time: 0.0420s\n",
            "0\n",
            "Epoch: 0215 loss_train: 1.0318 acc_train: 0.7250 loss_val: 1.2284 acc_val: 0.5340 time: 0.0424s\n",
            "0\n",
            "Epoch: 0216 loss_train: 1.0235 acc_train: 0.7833 loss_val: 1.2267 acc_val: 0.5340 time: 0.0423s\n",
            "0\n",
            "Epoch: 0217 loss_train: 1.1119 acc_train: 0.6750 loss_val: 1.2275 acc_val: 0.5300 time: 0.0422s\n",
            "0\n",
            "Epoch: 0218 loss_train: 1.0318 acc_train: 0.7167 loss_val: 1.2286 acc_val: 0.5280 time: 0.0425s\n",
            "1\n",
            "Epoch: 0219 loss_train: 1.1026 acc_train: 0.7167 loss_val: 1.2327 acc_val: 0.5160 time: 0.0421s\n",
            "2\n",
            "Epoch: 0220 loss_train: 1.1652 acc_train: 0.6750 loss_val: 1.2326 acc_val: 0.5140 time: 0.0436s\n",
            "3\n",
            "Epoch: 0221 loss_train: 1.1193 acc_train: 0.6583 loss_val: 1.2308 acc_val: 0.5080 time: 0.0420s\n",
            "4\n",
            "Epoch: 0222 loss_train: 1.1396 acc_train: 0.6500 loss_val: 1.2227 acc_val: 0.5120 time: 0.0427s\n",
            "5\n",
            "Epoch: 0223 loss_train: 1.0828 acc_train: 0.7000 loss_val: 1.2130 acc_val: 0.5220 time: 0.0427s\n",
            "0\n",
            "Epoch: 0224 loss_train: 1.0260 acc_train: 0.6750 loss_val: 1.2016 acc_val: 0.5360 time: 0.0427s\n",
            "0\n",
            "Epoch: 0225 loss_train: 1.0171 acc_train: 0.7167 loss_val: 1.1944 acc_val: 0.5440 time: 0.0425s\n",
            "0\n",
            "Epoch: 0226 loss_train: 1.0472 acc_train: 0.7083 loss_val: 1.1863 acc_val: 0.5600 time: 0.0421s\n",
            "0\n",
            "Epoch: 0227 loss_train: 1.0146 acc_train: 0.7667 loss_val: 1.1809 acc_val: 0.5600 time: 0.0419s\n",
            "0\n",
            "Epoch: 0228 loss_train: 0.9605 acc_train: 0.7667 loss_val: 1.1804 acc_val: 0.5580 time: 0.0420s\n",
            "0\n",
            "Epoch: 0229 loss_train: 1.1081 acc_train: 0.6833 loss_val: 1.1835 acc_val: 0.5560 time: 0.0420s\n",
            "0\n",
            "Epoch: 0230 loss_train: 1.0338 acc_train: 0.7250 loss_val: 1.1839 acc_val: 0.5540 time: 0.0426s\n",
            "1\n",
            "Epoch: 0231 loss_train: 1.0614 acc_train: 0.7000 loss_val: 1.1837 acc_val: 0.5560 time: 0.0424s\n",
            "2\n",
            "Epoch: 0232 loss_train: 1.0457 acc_train: 0.7333 loss_val: 1.1779 acc_val: 0.5560 time: 0.0423s\n",
            "3\n",
            "Epoch: 0233 loss_train: 1.0203 acc_train: 0.7583 loss_val: 1.1747 acc_val: 0.5520 time: 0.0433s\n",
            "0\n",
            "Epoch: 0234 loss_train: 1.0179 acc_train: 0.7750 loss_val: 1.1733 acc_val: 0.5520 time: 0.0419s\n",
            "0\n",
            "Epoch: 0235 loss_train: 0.9586 acc_train: 0.7583 loss_val: 1.1711 acc_val: 0.5520 time: 0.0442s\n",
            "0\n",
            "Epoch: 0236 loss_train: 1.0102 acc_train: 0.6917 loss_val: 1.1661 acc_val: 0.5540 time: 0.0420s\n",
            "0\n",
            "Epoch: 0237 loss_train: 1.0477 acc_train: 0.6750 loss_val: 1.1590 acc_val: 0.5600 time: 0.0420s\n",
            "0\n",
            "Epoch: 0238 loss_train: 1.0352 acc_train: 0.7417 loss_val: 1.1515 acc_val: 0.5680 time: 0.0418s\n",
            "0\n",
            "Epoch: 0239 loss_train: 1.0387 acc_train: 0.7167 loss_val: 1.1420 acc_val: 0.5760 time: 0.0428s\n",
            "0\n",
            "Epoch: 0240 loss_train: 1.0188 acc_train: 0.7417 loss_val: 1.1357 acc_val: 0.5860 time: 0.0425s\n",
            "0\n",
            "Epoch: 0241 loss_train: 0.8900 acc_train: 0.8250 loss_val: 1.1342 acc_val: 0.5940 time: 0.0419s\n",
            "0\n",
            "Epoch: 0242 loss_train: 0.9852 acc_train: 0.7333 loss_val: 1.1346 acc_val: 0.5880 time: 0.0419s\n",
            "0\n",
            "Epoch: 0243 loss_train: 1.0763 acc_train: 0.7250 loss_val: 1.1362 acc_val: 0.5860 time: 0.0423s\n",
            "1\n",
            "Epoch: 0244 loss_train: 0.9694 acc_train: 0.7750 loss_val: 1.1378 acc_val: 0.5820 time: 0.0421s\n",
            "2\n",
            "Epoch: 0245 loss_train: 0.9552 acc_train: 0.8000 loss_val: 1.1359 acc_val: 0.5860 time: 0.0428s\n",
            "3\n",
            "Epoch: 0246 loss_train: 1.0545 acc_train: 0.7083 loss_val: 1.1273 acc_val: 0.5900 time: 0.0424s\n",
            "4\n",
            "Epoch: 0247 loss_train: 0.9146 acc_train: 0.7750 loss_val: 1.1208 acc_val: 0.5880 time: 0.0420s\n",
            "0\n",
            "Epoch: 0248 loss_train: 1.0157 acc_train: 0.7167 loss_val: 1.1154 acc_val: 0.5780 time: 0.0422s\n",
            "0\n",
            "Epoch: 0249 loss_train: 0.9361 acc_train: 0.7583 loss_val: 1.1073 acc_val: 0.5840 time: 0.0419s\n",
            "0\n",
            "Epoch: 0250 loss_train: 1.0027 acc_train: 0.7333 loss_val: 1.1023 acc_val: 0.6040 time: 0.0424s\n",
            "0\n",
            "Epoch: 0251 loss_train: 0.9675 acc_train: 0.7250 loss_val: 1.0983 acc_val: 0.6180 time: 0.0418s\n",
            "0\n",
            "Epoch: 0252 loss_train: 0.9655 acc_train: 0.7833 loss_val: 1.0980 acc_val: 0.6420 time: 0.0419s\n",
            "0\n",
            "Epoch: 0253 loss_train: 1.0566 acc_train: 0.7083 loss_val: 1.0954 acc_val: 0.6540 time: 0.0419s\n",
            "0\n",
            "Epoch: 0254 loss_train: 1.0264 acc_train: 0.7083 loss_val: 1.0935 acc_val: 0.6700 time: 0.0421s\n",
            "0\n",
            "Epoch: 0255 loss_train: 0.9482 acc_train: 0.8250 loss_val: 1.0923 acc_val: 0.6740 time: 0.0430s\n",
            "0\n",
            "Epoch: 0256 loss_train: 0.9579 acc_train: 0.7667 loss_val: 1.0867 acc_val: 0.6780 time: 0.0420s\n",
            "0\n",
            "Epoch: 0257 loss_train: 0.9675 acc_train: 0.7750 loss_val: 1.0766 acc_val: 0.6740 time: 0.0418s\n",
            "0\n",
            "Epoch: 0258 loss_train: 0.9280 acc_train: 0.8000 loss_val: 1.0629 acc_val: 0.6840 time: 0.0420s\n",
            "0\n",
            "Epoch: 0259 loss_train: 1.0473 acc_train: 0.7250 loss_val: 1.0523 acc_val: 0.6840 time: 0.0434s\n",
            "0\n",
            "Epoch: 0260 loss_train: 0.8887 acc_train: 0.8000 loss_val: 1.0438 acc_val: 0.6780 time: 0.0438s\n",
            "0\n",
            "Epoch: 0261 loss_train: 1.0278 acc_train: 0.7500 loss_val: 1.0390 acc_val: 0.6860 time: 0.0420s\n",
            "0\n",
            "Epoch: 0262 loss_train: 0.9151 acc_train: 0.7500 loss_val: 1.0360 acc_val: 0.6960 time: 0.0420s\n",
            "0\n",
            "Epoch: 0263 loss_train: 0.8879 acc_train: 0.8333 loss_val: 1.0349 acc_val: 0.6960 time: 0.0419s\n",
            "0\n",
            "Epoch: 0264 loss_train: 0.9882 acc_train: 0.7500 loss_val: 1.0373 acc_val: 0.7000 time: 0.0421s\n",
            "0\n",
            "Epoch: 0265 loss_train: 0.8709 acc_train: 0.8000 loss_val: 1.0366 acc_val: 0.7020 time: 0.0425s\n",
            "0\n",
            "Epoch: 0266 loss_train: 0.9454 acc_train: 0.7500 loss_val: 1.0341 acc_val: 0.6980 time: 0.0426s\n",
            "0\n",
            "Epoch: 0267 loss_train: 0.9105 acc_train: 0.7667 loss_val: 1.0316 acc_val: 0.6960 time: 0.0419s\n",
            "0\n",
            "Epoch: 0268 loss_train: 0.8446 acc_train: 0.8500 loss_val: 1.0300 acc_val: 0.6900 time: 0.0418s\n",
            "0\n",
            "Epoch: 0269 loss_train: 0.8428 acc_train: 0.8333 loss_val: 1.0251 acc_val: 0.6820 time: 0.0418s\n",
            "0\n",
            "Epoch: 0270 loss_train: 0.8363 acc_train: 0.8083 loss_val: 1.0207 acc_val: 0.6880 time: 0.0423s\n",
            "0\n",
            "Epoch: 0271 loss_train: 0.8372 acc_train: 0.8500 loss_val: 1.0186 acc_val: 0.6880 time: 0.0419s\n",
            "0\n",
            "Epoch: 0272 loss_train: 0.9685 acc_train: 0.7333 loss_val: 1.0149 acc_val: 0.7020 time: 0.0419s\n",
            "0\n",
            "Epoch: 0273 loss_train: 0.9572 acc_train: 0.7500 loss_val: 1.0146 acc_val: 0.7100 time: 0.0419s\n",
            "0\n",
            "Epoch: 0274 loss_train: 0.8816 acc_train: 0.8250 loss_val: 1.0174 acc_val: 0.7120 time: 0.0419s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.8266 acc_train: 0.8500 loss_val: 1.0192 acc_val: 0.7240 time: 0.0443s\n",
            "0\n",
            "Epoch: 0276 loss_train: 0.8875 acc_train: 0.8083 loss_val: 1.0218 acc_val: 0.7300 time: 0.0427s\n",
            "0\n",
            "Epoch: 0277 loss_train: 0.9302 acc_train: 0.7750 loss_val: 1.0241 acc_val: 0.7260 time: 0.0426s\n",
            "0\n",
            "Epoch: 0278 loss_train: 0.8770 acc_train: 0.8167 loss_val: 1.0221 acc_val: 0.7260 time: 0.0440s\n",
            "1\n",
            "Epoch: 0279 loss_train: 0.8927 acc_train: 0.8167 loss_val: 1.0188 acc_val: 0.7300 time: 0.0435s\n",
            "2\n",
            "Epoch: 0280 loss_train: 0.9552 acc_train: 0.7917 loss_val: 1.0155 acc_val: 0.7300 time: 0.0434s\n",
            "0\n",
            "Epoch: 0281 loss_train: 0.8674 acc_train: 0.8000 loss_val: 1.0112 acc_val: 0.7200 time: 0.0421s\n",
            "0\n",
            "Epoch: 0282 loss_train: 0.8262 acc_train: 0.8500 loss_val: 1.0027 acc_val: 0.7180 time: 0.0421s\n",
            "0\n",
            "Epoch: 0283 loss_train: 0.8706 acc_train: 0.7750 loss_val: 0.9962 acc_val: 0.7340 time: 0.0419s\n",
            "0\n",
            "Epoch: 0284 loss_train: 0.8817 acc_train: 0.8000 loss_val: 0.9904 acc_val: 0.7280 time: 0.0419s\n",
            "0\n",
            "Epoch: 0285 loss_train: 0.8994 acc_train: 0.7750 loss_val: 0.9834 acc_val: 0.7320 time: 0.0428s\n",
            "0\n",
            "Epoch: 0286 loss_train: 0.8897 acc_train: 0.8083 loss_val: 0.9778 acc_val: 0.7340 time: 0.0430s\n",
            "0\n",
            "Epoch: 0287 loss_train: 0.8485 acc_train: 0.8417 loss_val: 0.9770 acc_val: 0.7320 time: 0.0421s\n",
            "0\n",
            "Epoch: 0288 loss_train: 0.8641 acc_train: 0.8333 loss_val: 0.9807 acc_val: 0.7300 time: 0.0420s\n",
            "0\n",
            "Epoch: 0289 loss_train: 0.9106 acc_train: 0.7917 loss_val: 0.9874 acc_val: 0.7300 time: 0.0431s\n",
            "1\n",
            "Epoch: 0290 loss_train: 1.0097 acc_train: 0.7083 loss_val: 0.9918 acc_val: 0.7320 time: 0.0426s\n",
            "2\n",
            "Epoch: 0291 loss_train: 0.8524 acc_train: 0.8250 loss_val: 0.9922 acc_val: 0.7320 time: 0.0421s\n",
            "3\n",
            "Epoch: 0292 loss_train: 0.9012 acc_train: 0.8250 loss_val: 0.9864 acc_val: 0.7320 time: 0.0421s\n",
            "4\n",
            "Epoch: 0293 loss_train: 0.8552 acc_train: 0.8250 loss_val: 0.9811 acc_val: 0.7380 time: 0.0430s\n",
            "5\n",
            "Epoch: 0294 loss_train: 0.8497 acc_train: 0.7917 loss_val: 0.9730 acc_val: 0.7360 time: 0.0438s\n",
            "0\n",
            "Epoch: 0295 loss_train: 0.9054 acc_train: 0.7917 loss_val: 0.9694 acc_val: 0.7380 time: 0.0426s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.8608 acc_train: 0.7750 loss_val: 0.9666 acc_val: 0.7360 time: 0.0423s\n",
            "0\n",
            "Epoch: 0297 loss_train: 0.8940 acc_train: 0.7833 loss_val: 0.9688 acc_val: 0.7340 time: 0.0420s\n",
            "0\n",
            "Epoch: 0298 loss_train: 0.8852 acc_train: 0.8250 loss_val: 0.9711 acc_val: 0.7320 time: 0.0429s\n",
            "1\n",
            "Epoch: 0299 loss_train: 0.8330 acc_train: 0.8000 loss_val: 0.9729 acc_val: 0.7300 time: 0.0420s\n",
            "2\n",
            "Epoch: 0300 loss_train: 0.9083 acc_train: 0.7667 loss_val: 0.9770 acc_val: 0.7260 time: 0.0428s\n",
            "3\n",
            "Epoch: 0301 loss_train: 0.9443 acc_train: 0.7833 loss_val: 0.9779 acc_val: 0.7260 time: 0.0421s\n",
            "4\n",
            "Epoch: 0302 loss_train: 0.9554 acc_train: 0.7500 loss_val: 0.9806 acc_val: 0.7360 time: 0.0421s\n",
            "5\n",
            "Epoch: 0303 loss_train: 0.9158 acc_train: 0.8167 loss_val: 0.9781 acc_val: 0.7420 time: 0.0420s\n",
            "6\n",
            "Epoch: 0304 loss_train: 0.8484 acc_train: 0.8583 loss_val: 0.9705 acc_val: 0.7400 time: 0.0425s\n",
            "0\n",
            "Epoch: 0305 loss_train: 0.8260 acc_train: 0.8250 loss_val: 0.9628 acc_val: 0.7420 time: 0.0443s\n",
            "1\n",
            "Epoch: 0306 loss_train: 0.8407 acc_train: 0.8250 loss_val: 0.9583 acc_val: 0.7340 time: 0.0418s\n",
            "0\n",
            "Epoch: 0307 loss_train: 0.8104 acc_train: 0.8417 loss_val: 0.9551 acc_val: 0.7380 time: 0.0424s\n",
            "0\n",
            "Epoch: 0308 loss_train: 0.8607 acc_train: 0.8000 loss_val: 0.9569 acc_val: 0.7340 time: 0.0422s\n",
            "0\n",
            "Epoch: 0309 loss_train: 0.8630 acc_train: 0.7917 loss_val: 0.9584 acc_val: 0.7340 time: 0.0423s\n",
            "1\n",
            "Epoch: 0310 loss_train: 0.8236 acc_train: 0.8083 loss_val: 0.9617 acc_val: 0.7320 time: 0.0428s\n",
            "2\n",
            "Epoch: 0311 loss_train: 0.9072 acc_train: 0.7750 loss_val: 0.9716 acc_val: 0.7260 time: 0.0422s\n",
            "3\n",
            "Epoch: 0312 loss_train: 0.8655 acc_train: 0.8000 loss_val: 0.9763 acc_val: 0.7180 time: 0.0424s\n",
            "4\n",
            "Epoch: 0313 loss_train: 0.8110 acc_train: 0.8083 loss_val: 0.9715 acc_val: 0.7220 time: 0.0434s\n",
            "5\n",
            "Epoch: 0314 loss_train: 0.8219 acc_train: 0.8583 loss_val: 0.9636 acc_val: 0.7300 time: 0.0426s\n",
            "6\n",
            "Epoch: 0315 loss_train: 0.8592 acc_train: 0.8167 loss_val: 0.9538 acc_val: 0.7320 time: 0.0430s\n",
            "7\n",
            "Epoch: 0316 loss_train: 0.8726 acc_train: 0.8083 loss_val: 0.9455 acc_val: 0.7380 time: 0.0419s\n",
            "0\n",
            "Epoch: 0317 loss_train: 0.8854 acc_train: 0.8083 loss_val: 0.9417 acc_val: 0.7400 time: 0.0419s\n",
            "0\n",
            "Epoch: 0318 loss_train: 0.7975 acc_train: 0.8250 loss_val: 0.9399 acc_val: 0.7400 time: 0.0419s\n",
            "0\n",
            "Epoch: 0319 loss_train: 0.9004 acc_train: 0.7917 loss_val: 0.9402 acc_val: 0.7420 time: 0.0428s\n",
            "0\n",
            "Epoch: 0320 loss_train: 0.9239 acc_train: 0.8167 loss_val: 0.9399 acc_val: 0.7460 time: 0.0432s\n",
            "0\n",
            "Epoch: 0321 loss_train: 0.8543 acc_train: 0.7750 loss_val: 0.9418 acc_val: 0.7420 time: 0.0428s\n",
            "0\n",
            "Epoch: 0322 loss_train: 0.7858 acc_train: 0.8417 loss_val: 0.9438 acc_val: 0.7380 time: 0.0427s\n",
            "1\n",
            "Epoch: 0323 loss_train: 0.9087 acc_train: 0.7750 loss_val: 0.9490 acc_val: 0.7300 time: 0.0421s\n",
            "2\n",
            "Epoch: 0324 loss_train: 0.8226 acc_train: 0.7833 loss_val: 0.9526 acc_val: 0.7340 time: 0.0423s\n",
            "3\n",
            "Epoch: 0325 loss_train: 0.8948 acc_train: 0.7750 loss_val: 0.9540 acc_val: 0.7300 time: 0.0437s\n",
            "4\n",
            "Epoch: 0326 loss_train: 0.8213 acc_train: 0.8417 loss_val: 0.9518 acc_val: 0.7300 time: 0.0425s\n",
            "5\n",
            "Epoch: 0327 loss_train: 0.8505 acc_train: 0.7833 loss_val: 0.9494 acc_val: 0.7300 time: 0.0421s\n",
            "6\n",
            "Epoch: 0328 loss_train: 0.7876 acc_train: 0.8500 loss_val: 0.9463 acc_val: 0.7340 time: 0.0422s\n",
            "7\n",
            "Epoch: 0329 loss_train: 0.8271 acc_train: 0.8250 loss_val: 0.9486 acc_val: 0.7340 time: 0.0421s\n",
            "8\n",
            "Epoch: 0330 loss_train: 0.8966 acc_train: 0.8000 loss_val: 0.9501 acc_val: 0.7280 time: 0.0502s\n",
            "9\n",
            "Epoch: 0331 loss_train: 0.8825 acc_train: 0.7917 loss_val: 0.9480 acc_val: 0.7340 time: 0.0435s\n",
            "10\n",
            "Epoch: 0332 loss_train: 0.7973 acc_train: 0.8583 loss_val: 0.9450 acc_val: 0.7320 time: 0.0436s\n",
            "11\n",
            "Epoch: 0333 loss_train: 0.8519 acc_train: 0.8250 loss_val: 0.9438 acc_val: 0.7280 time: 0.0423s\n",
            "12\n",
            "Epoch: 0334 loss_train: 0.8339 acc_train: 0.8167 loss_val: 0.9434 acc_val: 0.7300 time: 0.0424s\n",
            "13\n",
            "Epoch: 0335 loss_train: 0.7959 acc_train: 0.8250 loss_val: 0.9417 acc_val: 0.7320 time: 0.0447s\n",
            "14\n",
            "Epoch: 0336 loss_train: 0.9327 acc_train: 0.7583 loss_val: 0.9394 acc_val: 0.7320 time: 0.0424s\n",
            "15\n",
            "Epoch: 0337 loss_train: 0.8304 acc_train: 0.8167 loss_val: 0.9353 acc_val: 0.7300 time: 0.0446s\n",
            "0\n",
            "Epoch: 0338 loss_train: 0.8038 acc_train: 0.8167 loss_val: 0.9328 acc_val: 0.7340 time: 0.0435s\n",
            "0\n",
            "Epoch: 0339 loss_train: 0.8439 acc_train: 0.8083 loss_val: 0.9317 acc_val: 0.7340 time: 0.0426s\n",
            "0\n",
            "Epoch: 0340 loss_train: 0.7845 acc_train: 0.8250 loss_val: 0.9358 acc_val: 0.7380 time: 0.0424s\n",
            "0\n",
            "Epoch: 0341 loss_train: 0.8033 acc_train: 0.8250 loss_val: 0.9389 acc_val: 0.7320 time: 0.0435s\n",
            "1\n",
            "Epoch: 0342 loss_train: 0.7664 acc_train: 0.8500 loss_val: 0.9364 acc_val: 0.7400 time: 0.0427s\n",
            "2\n",
            "Epoch: 0343 loss_train: 0.8555 acc_train: 0.8250 loss_val: 0.9311 acc_val: 0.7460 time: 0.0496s\n",
            "3\n",
            "Epoch: 0344 loss_train: 0.8708 acc_train: 0.7917 loss_val: 0.9290 acc_val: 0.7460 time: 0.0420s\n",
            "0\n",
            "Epoch: 0345 loss_train: 0.8024 acc_train: 0.8167 loss_val: 0.9298 acc_val: 0.7420 time: 0.0419s\n",
            "0\n",
            "Epoch: 0346 loss_train: 0.7913 acc_train: 0.8417 loss_val: 0.9289 acc_val: 0.7320 time: 0.0433s\n",
            "1\n",
            "Epoch: 0347 loss_train: 0.8268 acc_train: 0.8167 loss_val: 0.9292 acc_val: 0.7340 time: 0.0424s\n",
            "0\n",
            "Epoch: 0348 loss_train: 0.8355 acc_train: 0.7500 loss_val: 0.9320 acc_val: 0.7340 time: 0.0437s\n",
            "1\n",
            "Epoch: 0349 loss_train: 0.8628 acc_train: 0.7833 loss_val: 0.9330 acc_val: 0.7340 time: 0.0426s\n",
            "2\n",
            "Epoch: 0350 loss_train: 0.8339 acc_train: 0.8083 loss_val: 0.9349 acc_val: 0.7360 time: 0.0423s\n",
            "3\n",
            "Epoch: 0351 loss_train: 0.7988 acc_train: 0.8417 loss_val: 0.9365 acc_val: 0.7360 time: 0.0422s\n",
            "4\n",
            "Epoch: 0352 loss_train: 0.8237 acc_train: 0.8000 loss_val: 0.9362 acc_val: 0.7340 time: 0.0422s\n",
            "5\n",
            "Epoch: 0353 loss_train: 0.8743 acc_train: 0.8000 loss_val: 0.9310 acc_val: 0.7300 time: 0.0427s\n",
            "6\n",
            "Epoch: 0354 loss_train: 0.8293 acc_train: 0.8333 loss_val: 0.9273 acc_val: 0.7320 time: 0.0422s\n",
            "7\n",
            "Epoch: 0355 loss_train: 0.8780 acc_train: 0.8167 loss_val: 0.9225 acc_val: 0.7340 time: 0.0421s\n",
            "0\n",
            "Epoch: 0356 loss_train: 0.8328 acc_train: 0.8250 loss_val: 0.9209 acc_val: 0.7300 time: 0.0422s\n",
            "0\n",
            "Epoch: 0357 loss_train: 0.8530 acc_train: 0.7667 loss_val: 0.9221 acc_val: 0.7340 time: 0.0420s\n",
            "0\n",
            "Epoch: 0358 loss_train: 0.7840 acc_train: 0.8250 loss_val: 0.9256 acc_val: 0.7340 time: 0.0426s\n",
            "1\n",
            "Epoch: 0359 loss_train: 0.7841 acc_train: 0.8000 loss_val: 0.9298 acc_val: 0.7300 time: 0.0423s\n",
            "2\n",
            "Epoch: 0360 loss_train: 0.8977 acc_train: 0.7917 loss_val: 0.9332 acc_val: 0.7300 time: 0.0427s\n",
            "3\n",
            "Epoch: 0361 loss_train: 0.7707 acc_train: 0.8750 loss_val: 0.9323 acc_val: 0.7320 time: 0.0423s\n",
            "4\n",
            "Epoch: 0362 loss_train: 0.8674 acc_train: 0.7750 loss_val: 0.9313 acc_val: 0.7320 time: 0.0423s\n",
            "5\n",
            "Epoch: 0363 loss_train: 0.8460 acc_train: 0.7833 loss_val: 0.9279 acc_val: 0.7300 time: 0.0463s\n",
            "6\n",
            "Epoch: 0364 loss_train: 0.8385 acc_train: 0.7833 loss_val: 0.9247 acc_val: 0.7300 time: 0.0423s\n",
            "7\n",
            "Epoch: 0365 loss_train: 0.7807 acc_train: 0.8417 loss_val: 0.9184 acc_val: 0.7300 time: 0.0421s\n",
            "8\n",
            "Epoch: 0366 loss_train: 0.8945 acc_train: 0.7750 loss_val: 0.9150 acc_val: 0.7280 time: 0.0418s\n",
            "0\n",
            "Epoch: 0367 loss_train: 0.8032 acc_train: 0.8000 loss_val: 0.9127 acc_val: 0.7340 time: 0.0418s\n",
            "0\n",
            "Epoch: 0368 loss_train: 0.7338 acc_train: 0.8167 loss_val: 0.9141 acc_val: 0.7300 time: 0.0424s\n",
            "0\n",
            "Epoch: 0369 loss_train: 0.7956 acc_train: 0.8750 loss_val: 0.9191 acc_val: 0.7280 time: 0.0419s\n",
            "1\n",
            "Epoch: 0370 loss_train: 0.7953 acc_train: 0.8333 loss_val: 0.9227 acc_val: 0.7260 time: 0.0422s\n",
            "2\n",
            "Epoch: 0371 loss_train: 0.8469 acc_train: 0.7583 loss_val: 0.9295 acc_val: 0.7300 time: 0.0420s\n",
            "3\n",
            "Epoch: 0372 loss_train: 0.7109 acc_train: 0.8667 loss_val: 0.9337 acc_val: 0.7380 time: 0.0425s\n",
            "4\n",
            "Epoch: 0373 loss_train: 0.8692 acc_train: 0.7667 loss_val: 0.9375 acc_val: 0.7420 time: 0.0441s\n",
            "5\n",
            "Epoch: 0374 loss_train: 0.7685 acc_train: 0.8167 loss_val: 0.9394 acc_val: 0.7380 time: 0.0423s\n",
            "6\n",
            "Epoch: 0375 loss_train: 0.8104 acc_train: 0.8500 loss_val: 0.9377 acc_val: 0.7500 time: 0.0439s\n",
            "7\n",
            "Epoch: 0376 loss_train: 0.9008 acc_train: 0.7583 loss_val: 0.9373 acc_val: 0.7420 time: 0.0422s\n",
            "0\n",
            "Epoch: 0377 loss_train: 0.7645 acc_train: 0.8667 loss_val: 0.9362 acc_val: 0.7320 time: 0.0421s\n",
            "1\n",
            "Epoch: 0378 loss_train: 0.8358 acc_train: 0.8000 loss_val: 0.9339 acc_val: 0.7340 time: 0.0436s\n",
            "2\n",
            "Epoch: 0379 loss_train: 0.8484 acc_train: 0.8083 loss_val: 0.9301 acc_val: 0.7280 time: 0.0418s\n",
            "3\n",
            "Epoch: 0380 loss_train: 0.7114 acc_train: 0.9000 loss_val: 0.9232 acc_val: 0.7320 time: 0.0422s\n",
            "4\n",
            "Epoch: 0381 loss_train: 0.8522 acc_train: 0.7500 loss_val: 0.9147 acc_val: 0.7340 time: 0.0421s\n",
            "5\n",
            "Epoch: 0382 loss_train: 0.7988 acc_train: 0.8083 loss_val: 0.9097 acc_val: 0.7360 time: 0.0428s\n",
            "6\n",
            "Epoch: 0383 loss_train: 0.7533 acc_train: 0.8500 loss_val: 0.9063 acc_val: 0.7420 time: 0.0427s\n",
            "0\n",
            "Epoch: 0384 loss_train: 0.8216 acc_train: 0.7917 loss_val: 0.9070 acc_val: 0.7380 time: 0.0420s\n",
            "0\n",
            "Epoch: 0385 loss_train: 0.8729 acc_train: 0.7750 loss_val: 0.9103 acc_val: 0.7360 time: 0.0425s\n",
            "1\n",
            "Epoch: 0386 loss_train: 0.8103 acc_train: 0.7917 loss_val: 0.9152 acc_val: 0.7320 time: 0.0444s\n",
            "2\n",
            "Epoch: 0387 loss_train: 0.8012 acc_train: 0.8083 loss_val: 0.9222 acc_val: 0.7220 time: 0.0421s\n",
            "3\n",
            "Epoch: 0388 loss_train: 0.7621 acc_train: 0.8500 loss_val: 0.9255 acc_val: 0.7280 time: 0.0428s\n",
            "4\n",
            "Epoch: 0389 loss_train: 0.7628 acc_train: 0.8500 loss_val: 0.9238 acc_val: 0.7260 time: 0.0423s\n",
            "5\n",
            "Epoch: 0390 loss_train: 0.7395 acc_train: 0.8417 loss_val: 0.9200 acc_val: 0.7300 time: 0.0424s\n",
            "6\n",
            "Epoch: 0391 loss_train: 0.8092 acc_train: 0.8250 loss_val: 0.9143 acc_val: 0.7340 time: 0.0422s\n",
            "7\n",
            "Epoch: 0392 loss_train: 0.7149 acc_train: 0.8750 loss_val: 0.9095 acc_val: 0.7400 time: 0.0421s\n",
            "8\n",
            "Epoch: 0393 loss_train: 0.7820 acc_train: 0.8333 loss_val: 0.9069 acc_val: 0.7460 time: 0.0430s\n",
            "9\n",
            "Epoch: 0394 loss_train: 0.7284 acc_train: 0.8500 loss_val: 0.9056 acc_val: 0.7420 time: 0.0424s\n",
            "10\n",
            "Epoch: 0395 loss_train: 0.7435 acc_train: 0.8333 loss_val: 0.9075 acc_val: 0.7460 time: 0.0419s\n",
            "0\n",
            "Epoch: 0396 loss_train: 0.6850 acc_train: 0.9083 loss_val: 0.9123 acc_val: 0.7480 time: 0.0421s\n",
            "1\n",
            "Epoch: 0397 loss_train: 0.7725 acc_train: 0.8167 loss_val: 0.9188 acc_val: 0.7460 time: 0.0421s\n",
            "2\n",
            "Epoch: 0398 loss_train: 0.7792 acc_train: 0.8583 loss_val: 0.9219 acc_val: 0.7400 time: 0.0437s\n",
            "3\n",
            "Epoch: 0399 loss_train: 0.8501 acc_train: 0.7583 loss_val: 0.9237 acc_val: 0.7360 time: 0.0424s\n",
            "4\n",
            "Epoch: 0400 loss_train: 0.7873 acc_train: 0.8583 loss_val: 0.9219 acc_val: 0.7300 time: 0.0420s\n",
            "5\n",
            "Epoch: 0401 loss_train: 0.7721 acc_train: 0.8417 loss_val: 0.9157 acc_val: 0.7320 time: 0.0437s\n",
            "6\n",
            "Epoch: 0402 loss_train: 0.7957 acc_train: 0.8417 loss_val: 0.9093 acc_val: 0.7300 time: 0.0423s\n",
            "7\n",
            "Epoch: 0403 loss_train: 0.7862 acc_train: 0.8250 loss_val: 0.9062 acc_val: 0.7340 time: 0.0440s\n",
            "8\n",
            "Epoch: 0404 loss_train: 0.7342 acc_train: 0.8250 loss_val: 0.9060 acc_val: 0.7340 time: 0.0421s\n",
            "9\n",
            "Epoch: 0405 loss_train: 0.7243 acc_train: 0.8833 loss_val: 0.9083 acc_val: 0.7280 time: 0.0422s\n",
            "10\n",
            "Epoch: 0406 loss_train: 0.8115 acc_train: 0.8417 loss_val: 0.9138 acc_val: 0.7200 time: 0.0422s\n",
            "11\n",
            "Epoch: 0407 loss_train: 0.7707 acc_train: 0.8417 loss_val: 0.9169 acc_val: 0.7200 time: 0.0422s\n",
            "12\n",
            "Epoch: 0408 loss_train: 0.7371 acc_train: 0.8417 loss_val: 0.9154 acc_val: 0.7220 time: 0.0469s\n",
            "13\n",
            "Epoch: 0409 loss_train: 0.7532 acc_train: 0.8583 loss_val: 0.9121 acc_val: 0.7300 time: 0.0430s\n",
            "14\n",
            "Epoch: 0410 loss_train: 0.7600 acc_train: 0.8417 loss_val: 0.9113 acc_val: 0.7340 time: 0.0425s\n",
            "15\n",
            "Epoch: 0411 loss_train: 0.6933 acc_train: 0.8500 loss_val: 0.9122 acc_val: 0.7320 time: 0.0423s\n",
            "16\n",
            "Epoch: 0412 loss_train: 0.8233 acc_train: 0.7917 loss_val: 0.9109 acc_val: 0.7340 time: 0.0427s\n",
            "17\n",
            "Epoch: 0413 loss_train: 0.7647 acc_train: 0.8750 loss_val: 0.9067 acc_val: 0.7360 time: 0.0430s\n",
            "18\n",
            "Epoch: 0414 loss_train: 0.7863 acc_train: 0.8333 loss_val: 0.9042 acc_val: 0.7400 time: 0.0422s\n",
            "19\n",
            "Epoch: 0415 loss_train: 0.8439 acc_train: 0.8417 loss_val: 0.9030 acc_val: 0.7420 time: 0.0421s\n",
            "0\n",
            "Epoch: 0416 loss_train: 0.6757 acc_train: 0.8417 loss_val: 0.9019 acc_val: 0.7440 time: 0.0421s\n",
            "0\n",
            "Epoch: 0417 loss_train: 0.7465 acc_train: 0.8500 loss_val: 0.9028 acc_val: 0.7360 time: 0.0421s\n",
            "0\n",
            "Epoch: 0418 loss_train: 0.8774 acc_train: 0.7750 loss_val: 0.9048 acc_val: 0.7300 time: 0.0427s\n",
            "1\n",
            "Epoch: 0419 loss_train: 0.7352 acc_train: 0.8750 loss_val: 0.9077 acc_val: 0.7280 time: 0.0424s\n",
            "2\n",
            "Epoch: 0420 loss_train: 0.7583 acc_train: 0.8333 loss_val: 0.9099 acc_val: 0.7300 time: 0.0422s\n",
            "3\n",
            "Epoch: 0421 loss_train: 0.7223 acc_train: 0.8833 loss_val: 0.9096 acc_val: 0.7260 time: 0.0422s\n",
            "4\n",
            "Epoch: 0422 loss_train: 0.6901 acc_train: 0.8667 loss_val: 0.9085 acc_val: 0.7340 time: 0.0421s\n",
            "5\n",
            "Epoch: 0423 loss_train: 0.8153 acc_train: 0.7750 loss_val: 0.9087 acc_val: 0.7340 time: 0.0431s\n",
            "6\n",
            "Epoch: 0424 loss_train: 0.8175 acc_train: 0.8167 loss_val: 0.9083 acc_val: 0.7320 time: 0.0423s\n",
            "7\n",
            "Epoch: 0425 loss_train: 0.8203 acc_train: 0.8417 loss_val: 0.9060 acc_val: 0.7400 time: 0.0421s\n",
            "8\n",
            "Epoch: 0426 loss_train: 0.7065 acc_train: 0.8083 loss_val: 0.9031 acc_val: 0.7420 time: 0.0424s\n",
            "9\n",
            "Epoch: 0427 loss_train: 0.8427 acc_train: 0.7917 loss_val: 0.8983 acc_val: 0.7500 time: 0.0418s\n",
            "10\n",
            "Epoch: 0428 loss_train: 0.8430 acc_train: 0.7417 loss_val: 0.8957 acc_val: 0.7480 time: 0.0429s\n",
            "0\n",
            "Epoch: 0429 loss_train: 0.7894 acc_train: 0.8417 loss_val: 0.8987 acc_val: 0.7460 time: 0.0420s\n",
            "0\n",
            "Epoch: 0430 loss_train: 0.7767 acc_train: 0.8333 loss_val: 0.9035 acc_val: 0.7340 time: 0.0431s\n",
            "1\n",
            "Epoch: 0431 loss_train: 0.7803 acc_train: 0.8583 loss_val: 0.9117 acc_val: 0.7260 time: 0.0440s\n",
            "2\n",
            "Epoch: 0432 loss_train: 0.7583 acc_train: 0.8417 loss_val: 0.9137 acc_val: 0.7280 time: 0.0426s\n",
            "3\n",
            "Epoch: 0433 loss_train: 0.7766 acc_train: 0.8500 loss_val: 0.9107 acc_val: 0.7320 time: 0.0441s\n",
            "4\n",
            "Epoch: 0434 loss_train: 0.7919 acc_train: 0.7917 loss_val: 0.9028 acc_val: 0.7380 time: 0.0425s\n",
            "5\n",
            "Epoch: 0435 loss_train: 0.7205 acc_train: 0.8667 loss_val: 0.8968 acc_val: 0.7380 time: 0.0424s\n",
            "6\n",
            "Epoch: 0436 loss_train: 0.8488 acc_train: 0.7917 loss_val: 0.8945 acc_val: 0.7400 time: 0.0422s\n",
            "7\n",
            "Epoch: 0437 loss_train: 0.7871 acc_train: 0.8250 loss_val: 0.8970 acc_val: 0.7400 time: 0.0420s\n",
            "0\n",
            "Epoch: 0438 loss_train: 0.7713 acc_train: 0.8167 loss_val: 0.8995 acc_val: 0.7440 time: 0.0427s\n",
            "1\n",
            "Epoch: 0439 loss_train: 0.8040 acc_train: 0.8333 loss_val: 0.9030 acc_val: 0.7400 time: 0.0423s\n",
            "2\n",
            "Epoch: 0440 loss_train: 0.7925 acc_train: 0.8000 loss_val: 0.9060 acc_val: 0.7380 time: 0.0452s\n",
            "3\n",
            "Epoch: 0441 loss_train: 0.7522 acc_train: 0.8333 loss_val: 0.9075 acc_val: 0.7420 time: 0.0430s\n",
            "4\n",
            "Epoch: 0442 loss_train: 0.7707 acc_train: 0.8333 loss_val: 0.9047 acc_val: 0.7420 time: 0.0424s\n",
            "5\n",
            "Epoch: 0443 loss_train: 0.8233 acc_train: 0.8250 loss_val: 0.9052 acc_val: 0.7400 time: 0.0431s\n",
            "6\n",
            "Epoch: 0444 loss_train: 0.8889 acc_train: 0.7583 loss_val: 0.9024 acc_val: 0.7420 time: 0.0423s\n",
            "7\n",
            "Epoch: 0445 loss_train: 0.7440 acc_train: 0.8417 loss_val: 0.9021 acc_val: 0.7400 time: 0.0424s\n",
            "8\n",
            "Epoch: 0446 loss_train: 0.7844 acc_train: 0.7917 loss_val: 0.8992 acc_val: 0.7360 time: 0.0424s\n",
            "9\n",
            "Epoch: 0447 loss_train: 0.7632 acc_train: 0.8250 loss_val: 0.8944 acc_val: 0.7400 time: 0.0422s\n",
            "10\n",
            "Epoch: 0448 loss_train: 0.7555 acc_train: 0.8000 loss_val: 0.8902 acc_val: 0.7400 time: 0.0424s\n",
            "0\n",
            "Epoch: 0449 loss_train: 0.7686 acc_train: 0.8250 loss_val: 0.8915 acc_val: 0.7320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0450 loss_train: 0.7926 acc_train: 0.7917 loss_val: 0.8972 acc_val: 0.7340 time: 0.0433s\n",
            "1\n",
            "Epoch: 0451 loss_train: 0.7319 acc_train: 0.7833 loss_val: 0.9036 acc_val: 0.7320 time: 0.0423s\n",
            "2\n",
            "Epoch: 0452 loss_train: 0.7421 acc_train: 0.8333 loss_val: 0.9064 acc_val: 0.7340 time: 0.0437s\n",
            "3\n",
            "Epoch: 0453 loss_train: 0.7948 acc_train: 0.8167 loss_val: 0.9094 acc_val: 0.7360 time: 0.0429s\n",
            "4\n",
            "Epoch: 0454 loss_train: 0.7234 acc_train: 0.8417 loss_val: 0.9038 acc_val: 0.7420 time: 0.0423s\n",
            "5\n",
            "Epoch: 0455 loss_train: 0.8097 acc_train: 0.8167 loss_val: 0.9013 acc_val: 0.7420 time: 0.0420s\n",
            "6\n",
            "Epoch: 0456 loss_train: 0.7388 acc_train: 0.8333 loss_val: 0.9005 acc_val: 0.7400 time: 0.0423s\n",
            "7\n",
            "Epoch: 0457 loss_train: 0.7666 acc_train: 0.8333 loss_val: 0.8981 acc_val: 0.7460 time: 0.0421s\n",
            "8\n",
            "Epoch: 0458 loss_train: 0.7294 acc_train: 0.8250 loss_val: 0.8974 acc_val: 0.7480 time: 0.0433s\n",
            "9\n",
            "Epoch: 0459 loss_train: 0.8088 acc_train: 0.8250 loss_val: 0.8968 acc_val: 0.7460 time: 0.0421s\n",
            "10\n",
            "Epoch: 0460 loss_train: 0.8061 acc_train: 0.8167 loss_val: 0.8994 acc_val: 0.7420 time: 0.0428s\n",
            "11\n",
            "Epoch: 0461 loss_train: 0.7447 acc_train: 0.8750 loss_val: 0.9020 acc_val: 0.7400 time: 0.0423s\n",
            "12\n",
            "Epoch: 0462 loss_train: 0.7572 acc_train: 0.8583 loss_val: 0.9046 acc_val: 0.7340 time: 0.0425s\n",
            "13\n",
            "Epoch: 0463 loss_train: 0.6856 acc_train: 0.9083 loss_val: 0.9037 acc_val: 0.7380 time: 0.0432s\n",
            "14\n",
            "Epoch: 0464 loss_train: 0.7633 acc_train: 0.8167 loss_val: 0.9023 acc_val: 0.7380 time: 0.0430s\n",
            "15\n",
            "Epoch: 0465 loss_train: 0.6607 acc_train: 0.8750 loss_val: 0.9044 acc_val: 0.7380 time: 0.0428s\n",
            "16\n",
            "Epoch: 0466 loss_train: 0.6905 acc_train: 0.8583 loss_val: 0.9086 acc_val: 0.7360 time: 0.0423s\n",
            "17\n",
            "Epoch: 0467 loss_train: 0.7831 acc_train: 0.7917 loss_val: 0.9081 acc_val: 0.7340 time: 0.0424s\n",
            "18\n",
            "Epoch: 0468 loss_train: 0.6995 acc_train: 0.8417 loss_val: 0.9047 acc_val: 0.7400 time: 0.0442s\n",
            "19\n",
            "Epoch: 0469 loss_train: 0.7774 acc_train: 0.8250 loss_val: 0.8993 acc_val: 0.7400 time: 0.0422s\n",
            "20\n",
            "Epoch: 0470 loss_train: 0.7331 acc_train: 0.8500 loss_val: 0.8942 acc_val: 0.7420 time: 0.0423s\n",
            "21\n",
            "Epoch: 0471 loss_train: 0.7084 acc_train: 0.8750 loss_val: 0.8936 acc_val: 0.7400 time: 0.0434s\n",
            "22\n",
            "Epoch: 0472 loss_train: 0.7551 acc_train: 0.8417 loss_val: 0.8951 acc_val: 0.7360 time: 0.0423s\n",
            "23\n",
            "Epoch: 0473 loss_train: 0.7439 acc_train: 0.8583 loss_val: 0.8935 acc_val: 0.7420 time: 0.0442s\n",
            "24\n",
            "Epoch: 0474 loss_train: 0.7893 acc_train: 0.8167 loss_val: 0.8943 acc_val: 0.7360 time: 0.0428s\n",
            "25\n",
            "Epoch: 0475 loss_train: 0.7566 acc_train: 0.8167 loss_val: 0.8936 acc_val: 0.7340 time: 0.0446s\n",
            "26\n",
            "Epoch: 0476 loss_train: 0.7702 acc_train: 0.7917 loss_val: 0.8931 acc_val: 0.7380 time: 0.0423s\n",
            "27\n",
            "Epoch: 0477 loss_train: 0.7952 acc_train: 0.8083 loss_val: 0.8934 acc_val: 0.7380 time: 0.0422s\n",
            "28\n",
            "Epoch: 0478 loss_train: 0.7416 acc_train: 0.8333 loss_val: 0.8943 acc_val: 0.7340 time: 0.0434s\n",
            "29\n",
            "Epoch: 0479 loss_train: 0.7644 acc_train: 0.8250 loss_val: 0.8976 acc_val: 0.7380 time: 0.0422s\n",
            "30\n",
            "Epoch: 0480 loss_train: 0.7296 acc_train: 0.8500 loss_val: 0.9020 acc_val: 0.7400 time: 0.0422s\n",
            "31\n",
            "Epoch: 0481 loss_train: 0.7270 acc_train: 0.8333 loss_val: 0.9045 acc_val: 0.7420 time: 0.0421s\n",
            "32\n",
            "Epoch: 0482 loss_train: 0.7879 acc_train: 0.8167 loss_val: 0.9045 acc_val: 0.7440 time: 0.0423s\n",
            "33\n",
            "Epoch: 0483 loss_train: 0.7304 acc_train: 0.8250 loss_val: 0.9005 acc_val: 0.7380 time: 0.0452s\n",
            "34\n",
            "Epoch: 0484 loss_train: 0.7961 acc_train: 0.7667 loss_val: 0.8995 acc_val: 0.7380 time: 0.0422s\n",
            "35\n",
            "Epoch: 0485 loss_train: 0.6646 acc_train: 0.8833 loss_val: 0.8945 acc_val: 0.7340 time: 0.0421s\n",
            "36\n",
            "Epoch: 0486 loss_train: 0.7544 acc_train: 0.8417 loss_val: 0.8930 acc_val: 0.7340 time: 0.0421s\n",
            "37\n",
            "Epoch: 0487 loss_train: 0.7708 acc_train: 0.8333 loss_val: 0.8901 acc_val: 0.7280 time: 0.0434s\n",
            "38\n",
            "Epoch: 0488 loss_train: 0.6963 acc_train: 0.8333 loss_val: 0.8897 acc_val: 0.7260 time: 0.0428s\n",
            "0\n",
            "Epoch: 0489 loss_train: 0.7441 acc_train: 0.8333 loss_val: 0.8909 acc_val: 0.7320 time: 0.0420s\n",
            "0\n",
            "Epoch: 0490 loss_train: 0.7933 acc_train: 0.8083 loss_val: 0.8934 acc_val: 0.7360 time: 0.0421s\n",
            "1\n",
            "Epoch: 0491 loss_train: 0.6906 acc_train: 0.8583 loss_val: 0.8937 acc_val: 0.7460 time: 0.0421s\n",
            "2\n",
            "Epoch: 0492 loss_train: 0.7141 acc_train: 0.8167 loss_val: 0.8922 acc_val: 0.7420 time: 0.0422s\n",
            "3\n",
            "Epoch: 0493 loss_train: 0.6778 acc_train: 0.8750 loss_val: 0.8908 acc_val: 0.7420 time: 0.0437s\n",
            "4\n",
            "Epoch: 0494 loss_train: 0.7153 acc_train: 0.8667 loss_val: 0.8885 acc_val: 0.7420 time: 0.0436s\n",
            "5\n",
            "Epoch: 0495 loss_train: 0.7194 acc_train: 0.8500 loss_val: 0.8884 acc_val: 0.7420 time: 0.0420s\n",
            "0\n",
            "Epoch: 0496 loss_train: 0.6399 acc_train: 0.8583 loss_val: 0.8921 acc_val: 0.7380 time: 0.0421s\n",
            "0\n",
            "Epoch: 0497 loss_train: 0.8022 acc_train: 0.8167 loss_val: 0.8984 acc_val: 0.7380 time: 0.0429s\n",
            "1\n",
            "Epoch: 0498 loss_train: 0.7820 acc_train: 0.8167 loss_val: 0.9039 acc_val: 0.7300 time: 0.0425s\n",
            "2\n",
            "Epoch: 0499 loss_train: 0.8108 acc_train: 0.8000 loss_val: 0.9103 acc_val: 0.7240 time: 0.0422s\n",
            "3\n",
            "Epoch: 0500 loss_train: 0.8224 acc_train: 0.8083 loss_val: 0.9068 acc_val: 0.7260 time: 0.0423s\n",
            "4\n",
            "Epoch: 0501 loss_train: 0.7240 acc_train: 0.8417 loss_val: 0.8984 acc_val: 0.7360 time: 0.0424s\n",
            "5\n",
            "Epoch: 0502 loss_train: 0.7833 acc_train: 0.7917 loss_val: 0.8916 acc_val: 0.7420 time: 0.0420s\n",
            "6\n",
            "Epoch: 0503 loss_train: 0.7091 acc_train: 0.8833 loss_val: 0.8886 acc_val: 0.7480 time: 0.0431s\n",
            "7\n",
            "Epoch: 0504 loss_train: 0.7616 acc_train: 0.8083 loss_val: 0.8866 acc_val: 0.7480 time: 0.0426s\n",
            "8\n",
            "Epoch: 0505 loss_train: 0.7615 acc_train: 0.8333 loss_val: 0.8846 acc_val: 0.7520 time: 0.0419s\n",
            "0\n",
            "Epoch: 0506 loss_train: 0.7196 acc_train: 0.8250 loss_val: 0.8812 acc_val: 0.7540 time: 0.0420s\n",
            "0\n",
            "Epoch: 0507 loss_train: 0.8110 acc_train: 0.8167 loss_val: 0.8771 acc_val: 0.7500 time: 0.0422s\n",
            "0\n",
            "Epoch: 0508 loss_train: 0.7419 acc_train: 0.8333 loss_val: 0.8774 acc_val: 0.7400 time: 0.0447s\n",
            "0\n",
            "Epoch: 0509 loss_train: 0.7163 acc_train: 0.8750 loss_val: 0.8834 acc_val: 0.7260 time: 0.0430s\n",
            "1\n",
            "Epoch: 0510 loss_train: 0.7855 acc_train: 0.8250 loss_val: 0.8955 acc_val: 0.7280 time: 0.0428s\n",
            "2\n",
            "Epoch: 0511 loss_train: 0.7246 acc_train: 0.8250 loss_val: 0.9045 acc_val: 0.7240 time: 0.0423s\n",
            "3\n",
            "Epoch: 0512 loss_train: 0.7612 acc_train: 0.8250 loss_val: 0.9057 acc_val: 0.7240 time: 0.0422s\n",
            "4\n",
            "Epoch: 0513 loss_train: 0.7301 acc_train: 0.8000 loss_val: 0.8994 acc_val: 0.7240 time: 0.0431s\n",
            "5\n",
            "Epoch: 0514 loss_train: 0.6484 acc_train: 0.8833 loss_val: 0.8885 acc_val: 0.7440 time: 0.0425s\n",
            "6\n",
            "Epoch: 0515 loss_train: 0.7592 acc_train: 0.8417 loss_val: 0.8824 acc_val: 0.7520 time: 0.0423s\n",
            "7\n",
            "Epoch: 0516 loss_train: 0.7859 acc_train: 0.8250 loss_val: 0.8811 acc_val: 0.7520 time: 0.0422s\n",
            "8\n",
            "Epoch: 0517 loss_train: 0.7359 acc_train: 0.8417 loss_val: 0.8797 acc_val: 0.7500 time: 0.0424s\n",
            "9\n",
            "Epoch: 0518 loss_train: 0.7579 acc_train: 0.8500 loss_val: 0.8778 acc_val: 0.7480 time: 0.0453s\n",
            "10\n",
            "Epoch: 0519 loss_train: 0.6362 acc_train: 0.8917 loss_val: 0.8790 acc_val: 0.7500 time: 0.0435s\n",
            "11\n",
            "Epoch: 0520 loss_train: 0.7536 acc_train: 0.8417 loss_val: 0.8831 acc_val: 0.7400 time: 0.0430s\n",
            "12\n",
            "Epoch: 0521 loss_train: 0.7391 acc_train: 0.8250 loss_val: 0.8895 acc_val: 0.7340 time: 0.0424s\n",
            "13\n",
            "Epoch: 0522 loss_train: 0.7632 acc_train: 0.8250 loss_val: 0.8912 acc_val: 0.7280 time: 0.0425s\n",
            "14\n",
            "Epoch: 0523 loss_train: 0.6582 acc_train: 0.8917 loss_val: 0.8877 acc_val: 0.7260 time: 0.0444s\n",
            "15\n",
            "Epoch: 0524 loss_train: 0.6655 acc_train: 0.8583 loss_val: 0.8819 acc_val: 0.7280 time: 0.0437s\n",
            "16\n",
            "Epoch: 0525 loss_train: 0.6910 acc_train: 0.8417 loss_val: 0.8744 acc_val: 0.7380 time: 0.0427s\n",
            "17\n",
            "Epoch: 0526 loss_train: 0.8080 acc_train: 0.7833 loss_val: 0.8729 acc_val: 0.7420 time: 0.0424s\n",
            "0\n",
            "Epoch: 0527 loss_train: 0.8212 acc_train: 0.8000 loss_val: 0.8732 acc_val: 0.7460 time: 0.0423s\n",
            "0\n",
            "Epoch: 0528 loss_train: 0.7788 acc_train: 0.8250 loss_val: 0.8747 acc_val: 0.7440 time: 0.0430s\n",
            "1\n",
            "Epoch: 0529 loss_train: 0.7460 acc_train: 0.8333 loss_val: 0.8751 acc_val: 0.7460 time: 0.0440s\n",
            "2\n",
            "Epoch: 0530 loss_train: 0.6622 acc_train: 0.8833 loss_val: 0.8767 acc_val: 0.7380 time: 0.0423s\n",
            "3\n",
            "Epoch: 0531 loss_train: 0.6912 acc_train: 0.8333 loss_val: 0.8806 acc_val: 0.7480 time: 0.0425s\n",
            "4\n",
            "Epoch: 0532 loss_train: 0.7625 acc_train: 0.8333 loss_val: 0.8864 acc_val: 0.7460 time: 0.0422s\n",
            "5\n",
            "Epoch: 0533 loss_train: 0.6946 acc_train: 0.8667 loss_val: 0.8934 acc_val: 0.7340 time: 0.0437s\n",
            "6\n",
            "Epoch: 0534 loss_train: 0.7424 acc_train: 0.8417 loss_val: 0.9011 acc_val: 0.7340 time: 0.0422s\n",
            "7\n",
            "Epoch: 0535 loss_train: 0.6858 acc_train: 0.8500 loss_val: 0.9081 acc_val: 0.7340 time: 0.0423s\n",
            "8\n",
            "Epoch: 0536 loss_train: 0.8116 acc_train: 0.8083 loss_val: 0.9041 acc_val: 0.7340 time: 0.0421s\n",
            "9\n",
            "Epoch: 0537 loss_train: 0.7786 acc_train: 0.8083 loss_val: 0.8964 acc_val: 0.7340 time: 0.0421s\n",
            "10\n",
            "Epoch: 0538 loss_train: 0.8199 acc_train: 0.8083 loss_val: 0.8872 acc_val: 0.7360 time: 0.0453s\n",
            "11\n",
            "Epoch: 0539 loss_train: 0.6702 acc_train: 0.8500 loss_val: 0.8785 acc_val: 0.7360 time: 0.0423s\n",
            "12\n",
            "Epoch: 0540 loss_train: 0.7160 acc_train: 0.8167 loss_val: 0.8703 acc_val: 0.7440 time: 0.0428s\n",
            "13\n",
            "Epoch: 0541 loss_train: 0.7931 acc_train: 0.8167 loss_val: 0.8655 acc_val: 0.7480 time: 0.0426s\n",
            "0\n",
            "Epoch: 0542 loss_train: 0.8019 acc_train: 0.8167 loss_val: 0.8676 acc_val: 0.7480 time: 0.0420s\n",
            "0\n",
            "Epoch: 0543 loss_train: 0.7198 acc_train: 0.8250 loss_val: 0.8751 acc_val: 0.7440 time: 0.0427s\n",
            "1\n",
            "Epoch: 0544 loss_train: 0.7086 acc_train: 0.8333 loss_val: 0.8870 acc_val: 0.7400 time: 0.0425s\n",
            "2\n",
            "Epoch: 0545 loss_train: 0.7622 acc_train: 0.8500 loss_val: 0.9021 acc_val: 0.7340 time: 0.0421s\n",
            "3\n",
            "Epoch: 0546 loss_train: 0.6965 acc_train: 0.8583 loss_val: 0.9153 acc_val: 0.7280 time: 0.0431s\n",
            "4\n",
            "Epoch: 0547 loss_train: 0.7369 acc_train: 0.8167 loss_val: 0.9173 acc_val: 0.7320 time: 0.0420s\n",
            "5\n",
            "Epoch: 0548 loss_train: 0.7508 acc_train: 0.8417 loss_val: 0.9085 acc_val: 0.7380 time: 0.0434s\n",
            "6\n",
            "Epoch: 0549 loss_train: 0.7443 acc_train: 0.8333 loss_val: 0.8931 acc_val: 0.7400 time: 0.0427s\n",
            "7\n",
            "Epoch: 0550 loss_train: 0.7295 acc_train: 0.8167 loss_val: 0.8805 acc_val: 0.7460 time: 0.0447s\n",
            "8\n",
            "Epoch: 0551 loss_train: 0.6753 acc_train: 0.8583 loss_val: 0.8723 acc_val: 0.7500 time: 0.0421s\n",
            "9\n",
            "Epoch: 0552 loss_train: 0.8240 acc_train: 0.8000 loss_val: 0.8686 acc_val: 0.7520 time: 0.0422s\n",
            "10\n",
            "Epoch: 0553 loss_train: 0.8159 acc_train: 0.8167 loss_val: 0.8657 acc_val: 0.7520 time: 0.0430s\n",
            "11\n",
            "Epoch: 0554 loss_train: 0.6901 acc_train: 0.8417 loss_val: 0.8652 acc_val: 0.7520 time: 0.0422s\n",
            "12\n",
            "Epoch: 0555 loss_train: 0.7844 acc_train: 0.8250 loss_val: 0.8667 acc_val: 0.7520 time: 0.0419s\n",
            "0\n",
            "Epoch: 0556 loss_train: 0.7546 acc_train: 0.8250 loss_val: 0.8708 acc_val: 0.7420 time: 0.0421s\n",
            "1\n",
            "Epoch: 0557 loss_train: 0.6971 acc_train: 0.8250 loss_val: 0.8800 acc_val: 0.7400 time: 0.0421s\n",
            "2\n",
            "Epoch: 0558 loss_train: 0.7312 acc_train: 0.8333 loss_val: 0.8917 acc_val: 0.7340 time: 0.0450s\n",
            "3\n",
            "Epoch: 0559 loss_train: 0.6612 acc_train: 0.8917 loss_val: 0.8967 acc_val: 0.7340 time: 0.0427s\n",
            "4\n",
            "Epoch: 0560 loss_train: 0.7235 acc_train: 0.8333 loss_val: 0.8928 acc_val: 0.7360 time: 0.0423s\n",
            "5\n",
            "Epoch: 0561 loss_train: 0.6372 acc_train: 0.8750 loss_val: 0.8864 acc_val: 0.7380 time: 0.0424s\n",
            "6\n",
            "Epoch: 0562 loss_train: 0.7352 acc_train: 0.8083 loss_val: 0.8831 acc_val: 0.7420 time: 0.0419s\n",
            "7\n",
            "Epoch: 0563 loss_train: 0.7348 acc_train: 0.8083 loss_val: 0.8835 acc_val: 0.7440 time: 0.0427s\n",
            "8\n",
            "Epoch: 0564 loss_train: 0.7825 acc_train: 0.8000 loss_val: 0.8822 acc_val: 0.7460 time: 0.0429s\n",
            "9\n",
            "Epoch: 0565 loss_train: 0.7663 acc_train: 0.7917 loss_val: 0.8783 acc_val: 0.7400 time: 0.0424s\n",
            "10\n",
            "Epoch: 0566 loss_train: 0.7605 acc_train: 0.8083 loss_val: 0.8772 acc_val: 0.7440 time: 0.0423s\n",
            "11\n",
            "Epoch: 0567 loss_train: 0.7173 acc_train: 0.8417 loss_val: 0.8763 acc_val: 0.7500 time: 0.0422s\n",
            "12\n",
            "Epoch: 0568 loss_train: 0.7203 acc_train: 0.8250 loss_val: 0.8731 acc_val: 0.7480 time: 0.0432s\n",
            "13\n",
            "Epoch: 0569 loss_train: 0.7313 acc_train: 0.8250 loss_val: 0.8741 acc_val: 0.7480 time: 0.0427s\n",
            "14\n",
            "Epoch: 0570 loss_train: 0.6752 acc_train: 0.8583 loss_val: 0.8797 acc_val: 0.7300 time: 0.0426s\n",
            "15\n",
            "Epoch: 0571 loss_train: 0.7613 acc_train: 0.8667 loss_val: 0.8893 acc_val: 0.7240 time: 0.0422s\n",
            "16\n",
            "Epoch: 0572 loss_train: 0.6684 acc_train: 0.8583 loss_val: 0.9010 acc_val: 0.7200 time: 0.0419s\n",
            "17\n",
            "Epoch: 0573 loss_train: 0.7063 acc_train: 0.8167 loss_val: 0.9131 acc_val: 0.7280 time: 0.0457s\n",
            "18\n",
            "Epoch: 0574 loss_train: 0.6865 acc_train: 0.8583 loss_val: 0.9142 acc_val: 0.7220 time: 0.0427s\n",
            "19\n",
            "Epoch: 0575 loss_train: 0.6831 acc_train: 0.8417 loss_val: 0.9044 acc_val: 0.7220 time: 0.0427s\n",
            "20\n",
            "Epoch: 0576 loss_train: 0.8201 acc_train: 0.8250 loss_val: 0.8949 acc_val: 0.7360 time: 0.0423s\n",
            "21\n",
            "Epoch: 0577 loss_train: 0.7183 acc_train: 0.8583 loss_val: 0.8890 acc_val: 0.7400 time: 0.0425s\n",
            "22\n",
            "Epoch: 0578 loss_train: 0.6999 acc_train: 0.8750 loss_val: 0.8869 acc_val: 0.7440 time: 0.0444s\n",
            "23\n",
            "Epoch: 0579 loss_train: 0.7179 acc_train: 0.9000 loss_val: 0.8834 acc_val: 0.7440 time: 0.0427s\n",
            "24\n",
            "Epoch: 0580 loss_train: 0.7494 acc_train: 0.7667 loss_val: 0.8792 acc_val: 0.7420 time: 0.0422s\n",
            "25\n",
            "Epoch: 0581 loss_train: 0.7109 acc_train: 0.8583 loss_val: 0.8736 acc_val: 0.7520 time: 0.0429s\n",
            "26\n",
            "Epoch: 0582 loss_train: 0.6600 acc_train: 0.9083 loss_val: 0.8717 acc_val: 0.7460 time: 0.0420s\n",
            "27\n",
            "Epoch: 0583 loss_train: 0.7923 acc_train: 0.8417 loss_val: 0.8769 acc_val: 0.7400 time: 0.0438s\n",
            "28\n",
            "Epoch: 0584 loss_train: 0.7263 acc_train: 0.8083 loss_val: 0.8884 acc_val: 0.7280 time: 0.0423s\n",
            "29\n",
            "Epoch: 0585 loss_train: 0.7717 acc_train: 0.8083 loss_val: 0.9038 acc_val: 0.7260 time: 0.0427s\n",
            "30\n",
            "Epoch: 0586 loss_train: 0.7240 acc_train: 0.8417 loss_val: 0.9115 acc_val: 0.7280 time: 0.0431s\n",
            "31\n",
            "Epoch: 0587 loss_train: 0.6920 acc_train: 0.8583 loss_val: 0.9087 acc_val: 0.7240 time: 0.0427s\n",
            "32\n",
            "Epoch: 0588 loss_train: 0.6537 acc_train: 0.8667 loss_val: 0.9002 acc_val: 0.7240 time: 0.0444s\n",
            "33\n",
            "Epoch: 0589 loss_train: 0.8329 acc_train: 0.7833 loss_val: 0.8876 acc_val: 0.7300 time: 0.0425s\n",
            "34\n",
            "Epoch: 0590 loss_train: 0.7408 acc_train: 0.8000 loss_val: 0.8813 acc_val: 0.7480 time: 0.0428s\n",
            "35\n",
            "Epoch: 0591 loss_train: 0.6924 acc_train: 0.8583 loss_val: 0.8777 acc_val: 0.7440 time: 0.0421s\n",
            "36\n",
            "Epoch: 0592 loss_train: 0.7727 acc_train: 0.8000 loss_val: 0.8761 acc_val: 0.7420 time: 0.0423s\n",
            "37\n",
            "Epoch: 0593 loss_train: 0.8025 acc_train: 0.7667 loss_val: 0.8769 acc_val: 0.7460 time: 0.0447s\n",
            "38\n",
            "Epoch: 0594 loss_train: 0.6999 acc_train: 0.8583 loss_val: 0.8777 acc_val: 0.7500 time: 0.0424s\n",
            "39\n",
            "Epoch: 0595 loss_train: 0.7537 acc_train: 0.8333 loss_val: 0.8810 acc_val: 0.7480 time: 0.0430s\n",
            "40\n",
            "Epoch: 0596 loss_train: 0.7146 acc_train: 0.8333 loss_val: 0.8877 acc_val: 0.7360 time: 0.0427s\n",
            "41\n",
            "Epoch: 0597 loss_train: 0.7224 acc_train: 0.8583 loss_val: 0.8958 acc_val: 0.7340 time: 0.0425s\n",
            "42\n",
            "Epoch: 0598 loss_train: 0.6271 acc_train: 0.8833 loss_val: 0.9007 acc_val: 0.7280 time: 0.0433s\n",
            "43\n",
            "Epoch: 0599 loss_train: 0.7549 acc_train: 0.8083 loss_val: 0.9006 acc_val: 0.7240 time: 0.0424s\n",
            "44\n",
            "Epoch: 0600 loss_train: 0.7735 acc_train: 0.8083 loss_val: 0.8994 acc_val: 0.7220 time: 0.0424s\n",
            "45\n",
            "Epoch: 0601 loss_train: 0.8549 acc_train: 0.7750 loss_val: 0.8923 acc_val: 0.7240 time: 0.0422s\n",
            "46\n",
            "Epoch: 0602 loss_train: 0.7250 acc_train: 0.8333 loss_val: 0.8836 acc_val: 0.7300 time: 0.0423s\n",
            "47\n",
            "Epoch: 0603 loss_train: 0.7541 acc_train: 0.8000 loss_val: 0.8805 acc_val: 0.7340 time: 0.0445s\n",
            "48\n",
            "Epoch: 0604 loss_train: 0.6916 acc_train: 0.8500 loss_val: 0.8811 acc_val: 0.7380 time: 0.0423s\n",
            "49\n",
            "Epoch: 0605 loss_train: 0.7759 acc_train: 0.8333 loss_val: 0.8809 acc_val: 0.7400 time: 0.0418s\n",
            "50\n",
            "Epoch: 0606 loss_train: 0.7356 acc_train: 0.8667 loss_val: 0.8759 acc_val: 0.7360 time: 0.0429s\n",
            "51\n",
            "Epoch: 0607 loss_train: 0.6579 acc_train: 0.9000 loss_val: 0.8726 acc_val: 0.7400 time: 0.0423s\n",
            "52\n",
            "Epoch: 0608 loss_train: 0.7048 acc_train: 0.8083 loss_val: 0.8712 acc_val: 0.7400 time: 0.0433s\n",
            "53\n",
            "Epoch: 0609 loss_train: 0.6453 acc_train: 0.8833 loss_val: 0.8691 acc_val: 0.7400 time: 0.0429s\n",
            "54\n",
            "Epoch: 0610 loss_train: 0.7654 acc_train: 0.8167 loss_val: 0.8699 acc_val: 0.7420 time: 0.0422s\n",
            "55\n",
            "Epoch: 0611 loss_train: 0.7743 acc_train: 0.8167 loss_val: 0.8708 acc_val: 0.7460 time: 0.0424s\n",
            "56\n",
            "Epoch: 0612 loss_train: 0.6628 acc_train: 0.8500 loss_val: 0.8708 acc_val: 0.7440 time: 0.0421s\n",
            "57\n",
            "Epoch: 0613 loss_train: 0.6639 acc_train: 0.8333 loss_val: 0.8715 acc_val: 0.7480 time: 0.0432s\n",
            "58\n",
            "Epoch: 0614 loss_train: 0.7280 acc_train: 0.8333 loss_val: 0.8741 acc_val: 0.7420 time: 0.0428s\n",
            "59\n",
            "Epoch: 0615 loss_train: 0.7806 acc_train: 0.8417 loss_val: 0.8808 acc_val: 0.7440 time: 0.0443s\n",
            "60\n",
            "Epoch: 0616 loss_train: 0.6387 acc_train: 0.8917 loss_val: 0.8853 acc_val: 0.7420 time: 0.0422s\n",
            "61\n",
            "Epoch: 0617 loss_train: 0.7225 acc_train: 0.8417 loss_val: 0.8859 acc_val: 0.7380 time: 0.0423s\n",
            "62\n",
            "Epoch: 0618 loss_train: 0.6864 acc_train: 0.8750 loss_val: 0.8836 acc_val: 0.7380 time: 0.0438s\n",
            "63\n",
            "Epoch: 0619 loss_train: 0.6514 acc_train: 0.8083 loss_val: 0.8782 acc_val: 0.7440 time: 0.0434s\n",
            "64\n",
            "Epoch: 0620 loss_train: 0.6945 acc_train: 0.8500 loss_val: 0.8711 acc_val: 0.7420 time: 0.0423s\n",
            "65\n",
            "Epoch: 0621 loss_train: 0.7599 acc_train: 0.8083 loss_val: 0.8635 acc_val: 0.7440 time: 0.0426s\n",
            "66\n",
            "Epoch: 0622 loss_train: 0.6936 acc_train: 0.8667 loss_val: 0.8616 acc_val: 0.7420 time: 0.0420s\n",
            "0\n",
            "Epoch: 0623 loss_train: 0.6677 acc_train: 0.8250 loss_val: 0.8615 acc_val: 0.7420 time: 0.0438s\n",
            "0\n",
            "Epoch: 0624 loss_train: 0.8018 acc_train: 0.8083 loss_val: 0.8654 acc_val: 0.7380 time: 0.0425s\n",
            "0\n",
            "Epoch: 0625 loss_train: 0.7901 acc_train: 0.8000 loss_val: 0.8711 acc_val: 0.7380 time: 0.0425s\n",
            "1\n",
            "Epoch: 0626 loss_train: 0.6977 acc_train: 0.8667 loss_val: 0.8766 acc_val: 0.7420 time: 0.0421s\n",
            "2\n",
            "Epoch: 0627 loss_train: 0.6781 acc_train: 0.8833 loss_val: 0.8825 acc_val: 0.7360 time: 0.0424s\n",
            "3\n",
            "Epoch: 0628 loss_train: 0.6958 acc_train: 0.8333 loss_val: 0.8861 acc_val: 0.7380 time: 0.0435s\n",
            "4\n",
            "Epoch: 0629 loss_train: 0.7622 acc_train: 0.8083 loss_val: 0.8876 acc_val: 0.7400 time: 0.0442s\n",
            "5\n",
            "Epoch: 0630 loss_train: 0.7272 acc_train: 0.8333 loss_val: 0.8856 acc_val: 0.7400 time: 0.0424s\n",
            "6\n",
            "Epoch: 0631 loss_train: 0.6845 acc_train: 0.8417 loss_val: 0.8782 acc_val: 0.7420 time: 0.0432s\n",
            "7\n",
            "Epoch: 0632 loss_train: 0.6555 acc_train: 0.8750 loss_val: 0.8696 acc_val: 0.7400 time: 0.0423s\n",
            "8\n",
            "Epoch: 0633 loss_train: 0.7156 acc_train: 0.8750 loss_val: 0.8621 acc_val: 0.7440 time: 0.0430s\n",
            "9\n",
            "Epoch: 0634 loss_train: 0.7610 acc_train: 0.8250 loss_val: 0.8594 acc_val: 0.7440 time: 0.0424s\n",
            "10\n",
            "Epoch: 0635 loss_train: 0.7298 acc_train: 0.8583 loss_val: 0.8579 acc_val: 0.7400 time: 0.0419s\n",
            "0\n",
            "Epoch: 0636 loss_train: 0.7092 acc_train: 0.8500 loss_val: 0.8578 acc_val: 0.7400 time: 0.0422s\n",
            "0\n",
            "Epoch: 0637 loss_train: 0.8074 acc_train: 0.7917 loss_val: 0.8589 acc_val: 0.7340 time: 0.0429s\n",
            "0\n",
            "Epoch: 0638 loss_train: 0.7361 acc_train: 0.8583 loss_val: 0.8577 acc_val: 0.7380 time: 0.0430s\n",
            "1\n",
            "Epoch: 0639 loss_train: 0.7594 acc_train: 0.7917 loss_val: 0.8588 acc_val: 0.7380 time: 0.0423s\n",
            "0\n",
            "Epoch: 0640 loss_train: 0.6234 acc_train: 0.9000 loss_val: 0.8605 acc_val: 0.7380 time: 0.0425s\n",
            "1\n",
            "Epoch: 0641 loss_train: 0.6991 acc_train: 0.8583 loss_val: 0.8648 acc_val: 0.7400 time: 0.0421s\n",
            "2\n",
            "Epoch: 0642 loss_train: 0.6824 acc_train: 0.8750 loss_val: 0.8712 acc_val: 0.7420 time: 0.0421s\n",
            "3\n",
            "Epoch: 0643 loss_train: 0.7505 acc_train: 0.8500 loss_val: 0.8795 acc_val: 0.7380 time: 0.0437s\n",
            "4\n",
            "Epoch: 0644 loss_train: 0.6482 acc_train: 0.8750 loss_val: 0.8868 acc_val: 0.7340 time: 0.0437s\n",
            "5\n",
            "Epoch: 0645 loss_train: 0.7634 acc_train: 0.8500 loss_val: 0.8940 acc_val: 0.7400 time: 0.0425s\n",
            "6\n",
            "Epoch: 0646 loss_train: 0.6835 acc_train: 0.8667 loss_val: 0.8903 acc_val: 0.7360 time: 0.0422s\n",
            "7\n",
            "Epoch: 0647 loss_train: 0.6918 acc_train: 0.8417 loss_val: 0.8831 acc_val: 0.7300 time: 0.0425s\n",
            "8\n",
            "Epoch: 0648 loss_train: 0.7115 acc_train: 0.8500 loss_val: 0.8729 acc_val: 0.7300 time: 0.0428s\n",
            "9\n",
            "Epoch: 0649 loss_train: 0.7435 acc_train: 0.8167 loss_val: 0.8672 acc_val: 0.7360 time: 0.0422s\n",
            "10\n",
            "Epoch: 0650 loss_train: 0.6729 acc_train: 0.8917 loss_val: 0.8668 acc_val: 0.7340 time: 0.0423s\n",
            "11\n",
            "Epoch: 0651 loss_train: 0.7192 acc_train: 0.8417 loss_val: 0.8687 acc_val: 0.7320 time: 0.0422s\n",
            "12\n",
            "Epoch: 0652 loss_train: 0.7518 acc_train: 0.7833 loss_val: 0.8687 acc_val: 0.7340 time: 0.0420s\n",
            "13\n",
            "Epoch: 0653 loss_train: 0.8029 acc_train: 0.7917 loss_val: 0.8654 acc_val: 0.7360 time: 0.0456s\n",
            "14\n",
            "Epoch: 0654 loss_train: 0.6873 acc_train: 0.8500 loss_val: 0.8636 acc_val: 0.7360 time: 0.0436s\n",
            "15\n",
            "Epoch: 0655 loss_train: 0.7429 acc_train: 0.8250 loss_val: 0.8660 acc_val: 0.7460 time: 0.0432s\n",
            "16\n",
            "Epoch: 0656 loss_train: 0.7338 acc_train: 0.8500 loss_val: 0.8745 acc_val: 0.7440 time: 0.0422s\n",
            "17\n",
            "Epoch: 0657 loss_train: 0.6375 acc_train: 0.8417 loss_val: 0.8793 acc_val: 0.7400 time: 0.0416s\n",
            "18\n",
            "Epoch: 0658 loss_train: 0.7142 acc_train: 0.8500 loss_val: 0.8827 acc_val: 0.7380 time: 0.0435s\n",
            "19\n",
            "Epoch: 0659 loss_train: 0.7438 acc_train: 0.8250 loss_val: 0.8819 acc_val: 0.7380 time: 0.0436s\n",
            "20\n",
            "Epoch: 0660 loss_train: 0.7324 acc_train: 0.8417 loss_val: 0.8780 acc_val: 0.7380 time: 0.0426s\n",
            "21\n",
            "Epoch: 0661 loss_train: 0.7181 acc_train: 0.8500 loss_val: 0.8725 acc_val: 0.7400 time: 0.0422s\n",
            "22\n",
            "Epoch: 0662 loss_train: 0.6799 acc_train: 0.8500 loss_val: 0.8696 acc_val: 0.7320 time: 0.0422s\n",
            "23\n",
            "Epoch: 0663 loss_train: 0.6549 acc_train: 0.8750 loss_val: 0.8685 acc_val: 0.7320 time: 0.0427s\n",
            "24\n",
            "Epoch: 0664 loss_train: 0.8550 acc_train: 0.8083 loss_val: 0.8666 acc_val: 0.7260 time: 0.0421s\n",
            "25\n",
            "Epoch: 0665 loss_train: 0.7875 acc_train: 0.8083 loss_val: 0.8625 acc_val: 0.7340 time: 0.0422s\n",
            "26\n",
            "Epoch: 0666 loss_train: 0.8078 acc_train: 0.8000 loss_val: 0.8608 acc_val: 0.7320 time: 0.0422s\n",
            "27\n",
            "Epoch: 0667 loss_train: 0.7026 acc_train: 0.8583 loss_val: 0.8619 acc_val: 0.7400 time: 0.0435s\n",
            "28\n",
            "Epoch: 0668 loss_train: 0.7092 acc_train: 0.8583 loss_val: 0.8659 acc_val: 0.7500 time: 0.0434s\n",
            "29\n",
            "Epoch: 0669 loss_train: 0.7484 acc_train: 0.8167 loss_val: 0.8722 acc_val: 0.7420 time: 0.0421s\n",
            "30\n",
            "Epoch: 0670 loss_train: 0.7103 acc_train: 0.8417 loss_val: 0.8777 acc_val: 0.7440 time: 0.0426s\n",
            "31\n",
            "Epoch: 0671 loss_train: 0.6561 acc_train: 0.8917 loss_val: 0.8852 acc_val: 0.7420 time: 0.0424s\n",
            "32\n",
            "Epoch: 0672 loss_train: 0.7493 acc_train: 0.8083 loss_val: 0.8944 acc_val: 0.7340 time: 0.0423s\n",
            "33\n",
            "Epoch: 0673 loss_train: 0.8454 acc_train: 0.7750 loss_val: 0.9000 acc_val: 0.7300 time: 0.0446s\n",
            "34\n",
            "Epoch: 0674 loss_train: 0.7805 acc_train: 0.7917 loss_val: 0.8973 acc_val: 0.7280 time: 0.0422s\n",
            "35\n",
            "Epoch: 0675 loss_train: 0.7881 acc_train: 0.7917 loss_val: 0.8918 acc_val: 0.7260 time: 0.0422s\n",
            "36\n",
            "Epoch: 0676 loss_train: 0.7937 acc_train: 0.8000 loss_val: 0.8842 acc_val: 0.7200 time: 0.0427s\n",
            "37\n",
            "Epoch: 0677 loss_train: 0.7130 acc_train: 0.8250 loss_val: 0.8767 acc_val: 0.7240 time: 0.0427s\n",
            "38\n",
            "Epoch: 0678 loss_train: 0.7287 acc_train: 0.8167 loss_val: 0.8690 acc_val: 0.7280 time: 0.0442s\n",
            "39\n",
            "Epoch: 0679 loss_train: 0.6911 acc_train: 0.8417 loss_val: 0.8634 acc_val: 0.7320 time: 0.0421s\n",
            "40\n",
            "Epoch: 0680 loss_train: 0.6242 acc_train: 0.8750 loss_val: 0.8603 acc_val: 0.7320 time: 0.0423s\n",
            "41\n",
            "Epoch: 0681 loss_train: 0.8321 acc_train: 0.7667 loss_val: 0.8637 acc_val: 0.7360 time: 0.0425s\n",
            "42\n",
            "Epoch: 0682 loss_train: 0.7708 acc_train: 0.8000 loss_val: 0.8722 acc_val: 0.7400 time: 0.0423s\n",
            "43\n",
            "Epoch: 0683 loss_train: 0.6456 acc_train: 0.8500 loss_val: 0.8819 acc_val: 0.7360 time: 0.0437s\n",
            "44\n",
            "Epoch: 0684 loss_train: 0.6925 acc_train: 0.8750 loss_val: 0.8897 acc_val: 0.7340 time: 0.0422s\n",
            "45\n",
            "Epoch: 0685 loss_train: 0.6643 acc_train: 0.8833 loss_val: 0.8938 acc_val: 0.7280 time: 0.0422s\n",
            "46\n",
            "Epoch: 0686 loss_train: 0.6774 acc_train: 0.8333 loss_val: 0.8923 acc_val: 0.7340 time: 0.0422s\n",
            "47\n",
            "Epoch: 0687 loss_train: 0.7463 acc_train: 0.8250 loss_val: 0.8849 acc_val: 0.7420 time: 0.0422s\n",
            "48\n",
            "Epoch: 0688 loss_train: 0.7666 acc_train: 0.8000 loss_val: 0.8782 acc_val: 0.7380 time: 0.0435s\n",
            "49\n",
            "Epoch: 0689 loss_train: 0.7820 acc_train: 0.7917 loss_val: 0.8693 acc_val: 0.7460 time: 0.0421s\n",
            "50\n",
            "Epoch: 0690 loss_train: 0.6751 acc_train: 0.8667 loss_val: 0.8610 acc_val: 0.7400 time: 0.0422s\n",
            "51\n",
            "Epoch: 0691 loss_train: 0.7482 acc_train: 0.8083 loss_val: 0.8569 acc_val: 0.7380 time: 0.0423s\n",
            "52\n",
            "Epoch: 0692 loss_train: 0.6798 acc_train: 0.8750 loss_val: 0.8530 acc_val: 0.7420 time: 0.0421s\n",
            "0\n",
            "Epoch: 0693 loss_train: 0.6653 acc_train: 0.8500 loss_val: 0.8545 acc_val: 0.7420 time: 0.0477s\n",
            "0\n",
            "Epoch: 0694 loss_train: 0.7223 acc_train: 0.8167 loss_val: 0.8593 acc_val: 0.7400 time: 0.0429s\n",
            "1\n",
            "Epoch: 0695 loss_train: 0.6888 acc_train: 0.8500 loss_val: 0.8674 acc_val: 0.7400 time: 0.0423s\n",
            "2\n",
            "Epoch: 0696 loss_train: 0.6751 acc_train: 0.8250 loss_val: 0.8780 acc_val: 0.7400 time: 0.0422s\n",
            "3\n",
            "Epoch: 0697 loss_train: 0.7936 acc_train: 0.7833 loss_val: 0.8912 acc_val: 0.7340 time: 0.0422s\n",
            "4\n",
            "Epoch: 0698 loss_train: 0.6885 acc_train: 0.8583 loss_val: 0.9047 acc_val: 0.7340 time: 0.0488s\n",
            "5\n",
            "Epoch: 0699 loss_train: 0.7031 acc_train: 0.8417 loss_val: 0.9050 acc_val: 0.7320 time: 0.0429s\n",
            "6\n",
            "Epoch: 0700 loss_train: 0.7510 acc_train: 0.8417 loss_val: 0.9019 acc_val: 0.7340 time: 0.0428s\n",
            "7\n",
            "Epoch: 0701 loss_train: 0.6588 acc_train: 0.8417 loss_val: 0.8901 acc_val: 0.7360 time: 0.0424s\n",
            "8\n",
            "Epoch: 0702 loss_train: 0.6981 acc_train: 0.8750 loss_val: 0.8752 acc_val: 0.7340 time: 0.0445s\n",
            "9\n",
            "Epoch: 0703 loss_train: 0.7230 acc_train: 0.8333 loss_val: 0.8639 acc_val: 0.7440 time: 0.0444s\n",
            "10\n",
            "Epoch: 0704 loss_train: 0.7446 acc_train: 0.8083 loss_val: 0.8586 acc_val: 0.7480 time: 0.0422s\n",
            "11\n",
            "Epoch: 0705 loss_train: 0.7855 acc_train: 0.8417 loss_val: 0.8580 acc_val: 0.7480 time: 0.0424s\n",
            "12\n",
            "Epoch: 0706 loss_train: 0.7123 acc_train: 0.8500 loss_val: 0.8592 acc_val: 0.7500 time: 0.0423s\n",
            "13\n",
            "Epoch: 0707 loss_train: 0.6707 acc_train: 0.8500 loss_val: 0.8649 acc_val: 0.7400 time: 0.0423s\n",
            "14\n",
            "Epoch: 0708 loss_train: 0.7479 acc_train: 0.8333 loss_val: 0.8761 acc_val: 0.7380 time: 0.0439s\n",
            "15\n",
            "Epoch: 0709 loss_train: 0.7270 acc_train: 0.8083 loss_val: 0.8894 acc_val: 0.7260 time: 0.0422s\n",
            "16\n",
            "Epoch: 0710 loss_train: 0.7566 acc_train: 0.8417 loss_val: 0.8984 acc_val: 0.7200 time: 0.0423s\n",
            "17\n",
            "Epoch: 0711 loss_train: 0.7245 acc_train: 0.8000 loss_val: 0.9012 acc_val: 0.7180 time: 0.0420s\n",
            "18\n",
            "Epoch: 0712 loss_train: 0.7809 acc_train: 0.8167 loss_val: 0.8907 acc_val: 0.7260 time: 0.0427s\n",
            "19\n",
            "Epoch: 0713 loss_train: 0.6775 acc_train: 0.8917 loss_val: 0.8747 acc_val: 0.7320 time: 0.0431s\n",
            "20\n",
            "Epoch: 0714 loss_train: 0.7198 acc_train: 0.8583 loss_val: 0.8620 acc_val: 0.7460 time: 0.0421s\n",
            "21\n",
            "Epoch: 0715 loss_train: 0.6747 acc_train: 0.8333 loss_val: 0.8559 acc_val: 0.7500 time: 0.0428s\n",
            "22\n",
            "Epoch: 0716 loss_train: 0.6657 acc_train: 0.8583 loss_val: 0.8525 acc_val: 0.7500 time: 0.0422s\n",
            "23\n",
            "Epoch: 0717 loss_train: 0.6939 acc_train: 0.8500 loss_val: 0.8521 acc_val: 0.7540 time: 0.0421s\n",
            "0\n",
            "Epoch: 0718 loss_train: 0.7211 acc_train: 0.8583 loss_val: 0.8535 acc_val: 0.7500 time: 0.0432s\n",
            "0\n",
            "Epoch: 0719 loss_train: 0.7984 acc_train: 0.8000 loss_val: 0.8575 acc_val: 0.7440 time: 0.0427s\n",
            "1\n",
            "Epoch: 0720 loss_train: 0.7208 acc_train: 0.8333 loss_val: 0.8651 acc_val: 0.7440 time: 0.0456s\n",
            "2\n",
            "Epoch: 0721 loss_train: 0.6578 acc_train: 0.8667 loss_val: 0.8734 acc_val: 0.7360 time: 0.0463s\n",
            "3\n",
            "Epoch: 0722 loss_train: 0.6715 acc_train: 0.8000 loss_val: 0.8779 acc_val: 0.7320 time: 0.0435s\n",
            "4\n",
            "Epoch: 0723 loss_train: 0.6709 acc_train: 0.8750 loss_val: 0.8819 acc_val: 0.7260 time: 0.0429s\n",
            "5\n",
            "Epoch: 0724 loss_train: 0.6959 acc_train: 0.8750 loss_val: 0.8872 acc_val: 0.7300 time: 0.0427s\n",
            "6\n",
            "Epoch: 0725 loss_train: 0.7073 acc_train: 0.8167 loss_val: 0.8869 acc_val: 0.7300 time: 0.0428s\n",
            "7\n",
            "Epoch: 0726 loss_train: 0.6687 acc_train: 0.8750 loss_val: 0.8803 acc_val: 0.7300 time: 0.0425s\n",
            "8\n",
            "Epoch: 0727 loss_train: 0.6686 acc_train: 0.8750 loss_val: 0.8726 acc_val: 0.7400 time: 0.0422s\n",
            "9\n",
            "Epoch: 0728 loss_train: 0.7678 acc_train: 0.7917 loss_val: 0.8674 acc_val: 0.7420 time: 0.0435s\n",
            "10\n",
            "Epoch: 0729 loss_train: 0.6984 acc_train: 0.8417 loss_val: 0.8656 acc_val: 0.7440 time: 0.0424s\n",
            "11\n",
            "Epoch: 0730 loss_train: 0.6402 acc_train: 0.8667 loss_val: 0.8634 acc_val: 0.7440 time: 0.0422s\n",
            "12\n",
            "Epoch: 0731 loss_train: 0.6818 acc_train: 0.8583 loss_val: 0.8597 acc_val: 0.7480 time: 0.0428s\n",
            "13\n",
            "Epoch: 0732 loss_train: 0.6785 acc_train: 0.8583 loss_val: 0.8592 acc_val: 0.7480 time: 0.0422s\n",
            "14\n",
            "Epoch: 0733 loss_train: 0.6397 acc_train: 0.8667 loss_val: 0.8600 acc_val: 0.7500 time: 0.0443s\n",
            "15\n",
            "Epoch: 0734 loss_train: 0.8141 acc_train: 0.7583 loss_val: 0.8649 acc_val: 0.7460 time: 0.0431s\n",
            "16\n",
            "Epoch: 0735 loss_train: 0.8083 acc_train: 0.8083 loss_val: 0.8741 acc_val: 0.7360 time: 0.0423s\n",
            "17\n",
            "Epoch: 0736 loss_train: 0.6975 acc_train: 0.8750 loss_val: 0.8851 acc_val: 0.7300 time: 0.0421s\n",
            "18\n",
            "Epoch: 0737 loss_train: 0.6926 acc_train: 0.8833 loss_val: 0.8919 acc_val: 0.7280 time: 0.0420s\n",
            "19\n",
            "Epoch: 0738 loss_train: 0.7426 acc_train: 0.8083 loss_val: 0.8946 acc_val: 0.7300 time: 0.0442s\n",
            "20\n",
            "Epoch: 0739 loss_train: 0.7367 acc_train: 0.8750 loss_val: 0.8902 acc_val: 0.7300 time: 0.0423s\n",
            "21\n",
            "Epoch: 0740 loss_train: 0.7543 acc_train: 0.8333 loss_val: 0.8831 acc_val: 0.7380 time: 0.0432s\n",
            "22\n",
            "Epoch: 0741 loss_train: 0.7167 acc_train: 0.8583 loss_val: 0.8751 acc_val: 0.7420 time: 0.0417s\n",
            "23\n",
            "Epoch: 0742 loss_train: 0.6629 acc_train: 0.8667 loss_val: 0.8688 acc_val: 0.7400 time: 0.0420s\n",
            "24\n",
            "Epoch: 0743 loss_train: 0.7238 acc_train: 0.8167 loss_val: 0.8628 acc_val: 0.7380 time: 0.0448s\n",
            "25\n",
            "Epoch: 0744 loss_train: 0.6849 acc_train: 0.8917 loss_val: 0.8597 acc_val: 0.7440 time: 0.0424s\n",
            "26\n",
            "Epoch: 0745 loss_train: 0.6867 acc_train: 0.8333 loss_val: 0.8606 acc_val: 0.7460 time: 0.0423s\n",
            "27\n",
            "Epoch: 0746 loss_train: 0.6561 acc_train: 0.8833 loss_val: 0.8621 acc_val: 0.7340 time: 0.0436s\n",
            "28\n",
            "Epoch: 0747 loss_train: 0.6379 acc_train: 0.8583 loss_val: 0.8677 acc_val: 0.7320 time: 0.0422s\n",
            "29\n",
            "Epoch: 0748 loss_train: 0.7626 acc_train: 0.7750 loss_val: 0.8741 acc_val: 0.7260 time: 0.0431s\n",
            "30\n",
            "Epoch: 0749 loss_train: 0.6651 acc_train: 0.8167 loss_val: 0.8773 acc_val: 0.7240 time: 0.0422s\n",
            "31\n",
            "Epoch: 0750 loss_train: 0.7370 acc_train: 0.8333 loss_val: 0.8814 acc_val: 0.7300 time: 0.0448s\n",
            "32\n",
            "Epoch: 0751 loss_train: 0.6622 acc_train: 0.8750 loss_val: 0.8802 acc_val: 0.7360 time: 0.0421s\n",
            "33\n",
            "Epoch: 0752 loss_train: 0.7137 acc_train: 0.8250 loss_val: 0.8756 acc_val: 0.7320 time: 0.0421s\n",
            "34\n",
            "Epoch: 0753 loss_train: 0.6877 acc_train: 0.8667 loss_val: 0.8746 acc_val: 0.7360 time: 0.0428s\n",
            "35\n",
            "Epoch: 0754 loss_train: 0.6407 acc_train: 0.8917 loss_val: 0.8739 acc_val: 0.7400 time: 0.0422s\n",
            "36\n",
            "Epoch: 0755 loss_train: 0.6403 acc_train: 0.8750 loss_val: 0.8732 acc_val: 0.7440 time: 0.0422s\n",
            "37\n",
            "Epoch: 0756 loss_train: 0.7385 acc_train: 0.8167 loss_val: 0.8695 acc_val: 0.7420 time: 0.0426s\n",
            "38\n",
            "Epoch: 0757 loss_train: 0.7045 acc_train: 0.8750 loss_val: 0.8672 acc_val: 0.7420 time: 0.0420s\n",
            "39\n",
            "Epoch: 0758 loss_train: 0.6402 acc_train: 0.8667 loss_val: 0.8642 acc_val: 0.7480 time: 0.0443s\n",
            "40\n",
            "Epoch: 0759 loss_train: 0.6252 acc_train: 0.8750 loss_val: 0.8650 acc_val: 0.7420 time: 0.0427s\n",
            "41\n",
            "Epoch: 0760 loss_train: 0.7023 acc_train: 0.8083 loss_val: 0.8671 acc_val: 0.7380 time: 0.0425s\n",
            "42\n",
            "Epoch: 0761 loss_train: 0.7164 acc_train: 0.8250 loss_val: 0.8705 acc_val: 0.7320 time: 0.0425s\n",
            "43\n",
            "Epoch: 0762 loss_train: 0.7041 acc_train: 0.8083 loss_val: 0.8750 acc_val: 0.7300 time: 0.0425s\n",
            "44\n",
            "Epoch: 0763 loss_train: 0.7081 acc_train: 0.8583 loss_val: 0.8762 acc_val: 0.7360 time: 0.0428s\n",
            "45\n",
            "Epoch: 0764 loss_train: 0.6917 acc_train: 0.8250 loss_val: 0.8730 acc_val: 0.7380 time: 0.0422s\n",
            "46\n",
            "Epoch: 0765 loss_train: 0.7721 acc_train: 0.8417 loss_val: 0.8676 acc_val: 0.7380 time: 0.0429s\n",
            "47\n",
            "Epoch: 0766 loss_train: 0.7044 acc_train: 0.8333 loss_val: 0.8662 acc_val: 0.7380 time: 0.0434s\n",
            "48\n",
            "Epoch: 0767 loss_train: 0.6783 acc_train: 0.8500 loss_val: 0.8661 acc_val: 0.7380 time: 0.0423s\n",
            "49\n",
            "Epoch: 0768 loss_train: 0.7506 acc_train: 0.8250 loss_val: 0.8629 acc_val: 0.7360 time: 0.0458s\n",
            "50\n",
            "Epoch: 0769 loss_train: 0.7138 acc_train: 0.8833 loss_val: 0.8599 acc_val: 0.7440 time: 0.0440s\n",
            "51\n",
            "Epoch: 0770 loss_train: 0.7162 acc_train: 0.8417 loss_val: 0.8597 acc_val: 0.7440 time: 0.0422s\n",
            "52\n",
            "Epoch: 0771 loss_train: 0.6503 acc_train: 0.8667 loss_val: 0.8622 acc_val: 0.7460 time: 0.0423s\n",
            "53\n",
            "Epoch: 0772 loss_train: 0.7725 acc_train: 0.8167 loss_val: 0.8701 acc_val: 0.7480 time: 0.0431s\n",
            "54\n",
            "Epoch: 0773 loss_train: 0.7221 acc_train: 0.8000 loss_val: 0.8825 acc_val: 0.7400 time: 0.0440s\n",
            "55\n",
            "Epoch: 0774 loss_train: 0.7258 acc_train: 0.8250 loss_val: 0.8972 acc_val: 0.7340 time: 0.0423s\n",
            "56\n",
            "Epoch: 0775 loss_train: 0.7026 acc_train: 0.8250 loss_val: 0.9106 acc_val: 0.7340 time: 0.0421s\n",
            "57\n",
            "Epoch: 0776 loss_train: 0.7005 acc_train: 0.8500 loss_val: 0.9176 acc_val: 0.7320 time: 0.0423s\n",
            "58\n",
            "Epoch: 0777 loss_train: 0.6873 acc_train: 0.8333 loss_val: 0.9128 acc_val: 0.7340 time: 0.0429s\n",
            "59\n",
            "Epoch: 0778 loss_train: 0.7369 acc_train: 0.8333 loss_val: 0.8983 acc_val: 0.7320 time: 0.0446s\n",
            "60\n",
            "Epoch: 0779 loss_train: 0.7233 acc_train: 0.8250 loss_val: 0.8750 acc_val: 0.7400 time: 0.0427s\n",
            "61\n",
            "Epoch: 0780 loss_train: 0.6623 acc_train: 0.8500 loss_val: 0.8579 acc_val: 0.7480 time: 0.0429s\n",
            "62\n",
            "Epoch: 0781 loss_train: 0.7505 acc_train: 0.8417 loss_val: 0.8513 acc_val: 0.7500 time: 0.0436s\n",
            "63\n",
            "Epoch: 0782 loss_train: 0.6924 acc_train: 0.8667 loss_val: 0.8521 acc_val: 0.7500 time: 0.0422s\n",
            "0\n",
            "Epoch: 0783 loss_train: 0.6941 acc_train: 0.8417 loss_val: 0.8581 acc_val: 0.7480 time: 0.0442s\n",
            "1\n",
            "Epoch: 0784 loss_train: 0.6963 acc_train: 0.8583 loss_val: 0.8679 acc_val: 0.7500 time: 0.0437s\n",
            "2\n",
            "Epoch: 0785 loss_train: 0.6591 acc_train: 0.8750 loss_val: 0.8770 acc_val: 0.7460 time: 0.0425s\n",
            "3\n",
            "Epoch: 0786 loss_train: 0.7781 acc_train: 0.8083 loss_val: 0.8867 acc_val: 0.7360 time: 0.0433s\n",
            "4\n",
            "Epoch: 0787 loss_train: 0.7015 acc_train: 0.8667 loss_val: 0.8964 acc_val: 0.7240 time: 0.0423s\n",
            "5\n",
            "Epoch: 0788 loss_train: 0.6527 acc_train: 0.8750 loss_val: 0.9004 acc_val: 0.7280 time: 0.0438s\n",
            "6\n",
            "Epoch: 0789 loss_train: 0.6559 acc_train: 0.8500 loss_val: 0.9032 acc_val: 0.7320 time: 0.0427s\n",
            "7\n",
            "Epoch: 0790 loss_train: 0.6720 acc_train: 0.8167 loss_val: 0.8980 acc_val: 0.7340 time: 0.0422s\n",
            "8\n",
            "Epoch: 0791 loss_train: 0.6788 acc_train: 0.8750 loss_val: 0.8861 acc_val: 0.7340 time: 0.0424s\n",
            "9\n",
            "Epoch: 0792 loss_train: 0.6692 acc_train: 0.8667 loss_val: 0.8731 acc_val: 0.7400 time: 0.0421s\n",
            "10\n",
            "Epoch: 0793 loss_train: 0.8110 acc_train: 0.7833 loss_val: 0.8647 acc_val: 0.7460 time: 0.0433s\n",
            "11\n",
            "Epoch: 0794 loss_train: 0.6424 acc_train: 0.8667 loss_val: 0.8563 acc_val: 0.7500 time: 0.0423s\n",
            "12\n",
            "Epoch: 0795 loss_train: 0.6639 acc_train: 0.8750 loss_val: 0.8520 acc_val: 0.7520 time: 0.0428s\n",
            "13\n",
            "Epoch: 0796 loss_train: 0.6438 acc_train: 0.8667 loss_val: 0.8514 acc_val: 0.7520 time: 0.0438s\n",
            "14\n",
            "Epoch: 0797 loss_train: 0.6414 acc_train: 0.9167 loss_val: 0.8513 acc_val: 0.7520 time: 0.0430s\n",
            "15\n",
            "Epoch: 0798 loss_train: 0.7281 acc_train: 0.8583 loss_val: 0.8537 acc_val: 0.7480 time: 0.0439s\n",
            "16\n",
            "Epoch: 0799 loss_train: 0.5868 acc_train: 0.8750 loss_val: 0.8593 acc_val: 0.7420 time: 0.0428s\n",
            "17\n",
            "Epoch: 0800 loss_train: 0.6711 acc_train: 0.8500 loss_val: 0.8716 acc_val: 0.7420 time: 0.0428s\n",
            "18\n",
            "Epoch: 0801 loss_train: 0.6480 acc_train: 0.8667 loss_val: 0.8803 acc_val: 0.7360 time: 0.0430s\n",
            "19\n",
            "Epoch: 0802 loss_train: 0.7153 acc_train: 0.8750 loss_val: 0.8881 acc_val: 0.7340 time: 0.0422s\n",
            "20\n",
            "Epoch: 0803 loss_train: 0.7999 acc_train: 0.8000 loss_val: 0.8880 acc_val: 0.7380 time: 0.0432s\n",
            "21\n",
            "Epoch: 0804 loss_train: 0.7141 acc_train: 0.8417 loss_val: 0.8862 acc_val: 0.7380 time: 0.0428s\n",
            "22\n",
            "Epoch: 0805 loss_train: 0.7568 acc_train: 0.8333 loss_val: 0.8781 acc_val: 0.7360 time: 0.0426s\n",
            "23\n",
            "Epoch: 0806 loss_train: 0.7506 acc_train: 0.8333 loss_val: 0.8705 acc_val: 0.7380 time: 0.0429s\n",
            "24\n",
            "Epoch: 0807 loss_train: 0.6761 acc_train: 0.8250 loss_val: 0.8693 acc_val: 0.7360 time: 0.0434s\n",
            "25\n",
            "Epoch: 0808 loss_train: 0.7390 acc_train: 0.8833 loss_val: 0.8700 acc_val: 0.7420 time: 0.0441s\n",
            "26\n",
            "Epoch: 0809 loss_train: 0.6958 acc_train: 0.8750 loss_val: 0.8710 acc_val: 0.7440 time: 0.0437s\n",
            "27\n",
            "Epoch: 0810 loss_train: 0.6841 acc_train: 0.8833 loss_val: 0.8669 acc_val: 0.7480 time: 0.0445s\n",
            "28\n",
            "Epoch: 0811 loss_train: 0.6883 acc_train: 0.8417 loss_val: 0.8632 acc_val: 0.7420 time: 0.0425s\n",
            "29\n",
            "Epoch: 0812 loss_train: 0.8167 acc_train: 0.8083 loss_val: 0.8617 acc_val: 0.7380 time: 0.0438s\n",
            "30\n",
            "Epoch: 0813 loss_train: 0.7921 acc_train: 0.8333 loss_val: 0.8640 acc_val: 0.7360 time: 0.0436s\n",
            "31\n",
            "Epoch: 0814 loss_train: 0.7342 acc_train: 0.8583 loss_val: 0.8644 acc_val: 0.7340 time: 0.0426s\n",
            "32\n",
            "Epoch: 0815 loss_train: 0.7263 acc_train: 0.8667 loss_val: 0.8642 acc_val: 0.7360 time: 0.0423s\n",
            "33\n",
            "Epoch: 0816 loss_train: 0.7865 acc_train: 0.7750 loss_val: 0.8658 acc_val: 0.7400 time: 0.0427s\n",
            "34\n",
            "Epoch: 0817 loss_train: 0.6571 acc_train: 0.8667 loss_val: 0.8672 acc_val: 0.7420 time: 0.0423s\n",
            "35\n",
            "Epoch: 0818 loss_train: 0.7232 acc_train: 0.8417 loss_val: 0.8688 acc_val: 0.7420 time: 0.0449s\n",
            "36\n",
            "Epoch: 0819 loss_train: 0.7540 acc_train: 0.8167 loss_val: 0.8689 acc_val: 0.7420 time: 0.0429s\n",
            "37\n",
            "Epoch: 0820 loss_train: 0.7257 acc_train: 0.8083 loss_val: 0.8654 acc_val: 0.7460 time: 0.0424s\n",
            "38\n",
            "Epoch: 0821 loss_train: 0.6575 acc_train: 0.8750 loss_val: 0.8660 acc_val: 0.7400 time: 0.0424s\n",
            "39\n",
            "Epoch: 0822 loss_train: 0.6573 acc_train: 0.8833 loss_val: 0.8669 acc_val: 0.7420 time: 0.0426s\n",
            "40\n",
            "Epoch: 0823 loss_train: 0.7019 acc_train: 0.8083 loss_val: 0.8682 acc_val: 0.7420 time: 0.0439s\n",
            "41\n",
            "Epoch: 0824 loss_train: 0.7054 acc_train: 0.8250 loss_val: 0.8683 acc_val: 0.7460 time: 0.0421s\n",
            "42\n",
            "Epoch: 0825 loss_train: 0.7337 acc_train: 0.8500 loss_val: 0.8688 acc_val: 0.7400 time: 0.0423s\n",
            "43\n",
            "Epoch: 0826 loss_train: 0.6501 acc_train: 0.8750 loss_val: 0.8680 acc_val: 0.7400 time: 0.0424s\n",
            "44\n",
            "Epoch: 0827 loss_train: 0.7314 acc_train: 0.8500 loss_val: 0.8653 acc_val: 0.7420 time: 0.0424s\n",
            "45\n",
            "Epoch: 0828 loss_train: 0.7201 acc_train: 0.8333 loss_val: 0.8630 acc_val: 0.7440 time: 0.0446s\n",
            "46\n",
            "Epoch: 0829 loss_train: 0.7120 acc_train: 0.8750 loss_val: 0.8622 acc_val: 0.7500 time: 0.0423s\n",
            "47\n",
            "Epoch: 0830 loss_train: 0.6761 acc_train: 0.8333 loss_val: 0.8602 acc_val: 0.7480 time: 0.0422s\n",
            "48\n",
            "Epoch: 0831 loss_train: 0.6918 acc_train: 0.8417 loss_val: 0.8625 acc_val: 0.7420 time: 0.0427s\n",
            "49\n",
            "Epoch: 0832 loss_train: 0.7828 acc_train: 0.7917 loss_val: 0.8672 acc_val: 0.7480 time: 0.0421s\n",
            "50\n",
            "Epoch: 0833 loss_train: 0.7361 acc_train: 0.7917 loss_val: 0.8703 acc_val: 0.7400 time: 0.0439s\n",
            "51\n",
            "Epoch: 0834 loss_train: 0.6397 acc_train: 0.8833 loss_val: 0.8706 acc_val: 0.7340 time: 0.0427s\n",
            "52\n",
            "Epoch: 0835 loss_train: 0.6873 acc_train: 0.8333 loss_val: 0.8706 acc_val: 0.7360 time: 0.0427s\n",
            "53\n",
            "Epoch: 0836 loss_train: 0.6377 acc_train: 0.8667 loss_val: 0.8682 acc_val: 0.7340 time: 0.0441s\n",
            "54\n",
            "Epoch: 0837 loss_train: 0.6328 acc_train: 0.8583 loss_val: 0.8669 acc_val: 0.7320 time: 0.0426s\n",
            "55\n",
            "Epoch: 0838 loss_train: 0.7711 acc_train: 0.8250 loss_val: 0.8697 acc_val: 0.7240 time: 0.0451s\n",
            "56\n",
            "Epoch: 0839 loss_train: 0.7507 acc_train: 0.8250 loss_val: 0.8705 acc_val: 0.7260 time: 0.0423s\n",
            "57\n",
            "Epoch: 0840 loss_train: 0.7271 acc_train: 0.8250 loss_val: 0.8706 acc_val: 0.7240 time: 0.0422s\n",
            "58\n",
            "Epoch: 0841 loss_train: 0.6981 acc_train: 0.8750 loss_val: 0.8696 acc_val: 0.7300 time: 0.0422s\n",
            "59\n",
            "Epoch: 0842 loss_train: 0.7167 acc_train: 0.8417 loss_val: 0.8687 acc_val: 0.7320 time: 0.0425s\n",
            "60\n",
            "Epoch: 0843 loss_train: 0.6978 acc_train: 0.8333 loss_val: 0.8680 acc_val: 0.7340 time: 0.0440s\n",
            "61\n",
            "Epoch: 0844 loss_train: 0.6177 acc_train: 0.9083 loss_val: 0.8707 acc_val: 0.7340 time: 0.0420s\n",
            "62\n",
            "Epoch: 0845 loss_train: 0.7833 acc_train: 0.8083 loss_val: 0.8778 acc_val: 0.7340 time: 0.0421s\n",
            "63\n",
            "Epoch: 0846 loss_train: 0.6602 acc_train: 0.8917 loss_val: 0.8848 acc_val: 0.7340 time: 0.0421s\n",
            "64\n",
            "Epoch: 0847 loss_train: 0.7332 acc_train: 0.8083 loss_val: 0.8882 acc_val: 0.7300 time: 0.0421s\n",
            "65\n",
            "Epoch: 0848 loss_train: 0.7783 acc_train: 0.8083 loss_val: 0.8892 acc_val: 0.7320 time: 0.0430s\n",
            "66\n",
            "Epoch: 0849 loss_train: 0.7760 acc_train: 0.7917 loss_val: 0.8922 acc_val: 0.7360 time: 0.0422s\n",
            "67\n",
            "Epoch: 0850 loss_train: 0.6692 acc_train: 0.8750 loss_val: 0.8908 acc_val: 0.7320 time: 0.0422s\n",
            "68\n",
            "Epoch: 0851 loss_train: 0.6748 acc_train: 0.8583 loss_val: 0.8854 acc_val: 0.7280 time: 0.0419s\n",
            "69\n",
            "Epoch: 0852 loss_train: 0.6143 acc_train: 0.8583 loss_val: 0.8761 acc_val: 0.7300 time: 0.0422s\n",
            "70\n",
            "Epoch: 0853 loss_train: 0.6994 acc_train: 0.8333 loss_val: 0.8684 acc_val: 0.7340 time: 0.0429s\n",
            "71\n",
            "Epoch: 0854 loss_train: 0.7050 acc_train: 0.8583 loss_val: 0.8645 acc_val: 0.7360 time: 0.0423s\n",
            "72\n",
            "Epoch: 0855 loss_train: 0.7340 acc_train: 0.8250 loss_val: 0.8639 acc_val: 0.7400 time: 0.0429s\n",
            "73\n",
            "Epoch: 0856 loss_train: 0.6335 acc_train: 0.8667 loss_val: 0.8648 acc_val: 0.7400 time: 0.0422s\n",
            "74\n",
            "Epoch: 0857 loss_train: 0.7174 acc_train: 0.8500 loss_val: 0.8704 acc_val: 0.7360 time: 0.0421s\n",
            "75\n",
            "Epoch: 0858 loss_train: 0.6706 acc_train: 0.8417 loss_val: 0.8778 acc_val: 0.7320 time: 0.0431s\n",
            "76\n",
            "Epoch: 0859 loss_train: 0.7417 acc_train: 0.8333 loss_val: 0.8822 acc_val: 0.7340 time: 0.0427s\n",
            "77\n",
            "Epoch: 0860 loss_train: 0.6864 acc_train: 0.8417 loss_val: 0.8815 acc_val: 0.7340 time: 0.0429s\n",
            "78\n",
            "Epoch: 0861 loss_train: 0.5969 acc_train: 0.8917 loss_val: 0.8759 acc_val: 0.7360 time: 0.0422s\n",
            "79\n",
            "Epoch: 0862 loss_train: 0.6766 acc_train: 0.8833 loss_val: 0.8711 acc_val: 0.7320 time: 0.0421s\n",
            "80\n",
            "Epoch: 0863 loss_train: 0.7183 acc_train: 0.8000 loss_val: 0.8661 acc_val: 0.7260 time: 0.0474s\n",
            "81\n",
            "Epoch: 0864 loss_train: 0.6620 acc_train: 0.8417 loss_val: 0.8665 acc_val: 0.7300 time: 0.0424s\n",
            "82\n",
            "Epoch: 0865 loss_train: 0.6306 acc_train: 0.8583 loss_val: 0.8680 acc_val: 0.7340 time: 0.0422s\n",
            "83\n",
            "Epoch: 0866 loss_train: 0.7341 acc_train: 0.8167 loss_val: 0.8699 acc_val: 0.7340 time: 0.0424s\n",
            "84\n",
            "Epoch: 0867 loss_train: 0.7235 acc_train: 0.7833 loss_val: 0.8711 acc_val: 0.7340 time: 0.0421s\n",
            "85\n",
            "Epoch: 0868 loss_train: 0.7331 acc_train: 0.8000 loss_val: 0.8753 acc_val: 0.7320 time: 0.0464s\n",
            "86\n",
            "Epoch: 0869 loss_train: 0.6249 acc_train: 0.9000 loss_val: 0.8815 acc_val: 0.7300 time: 0.0422s\n",
            "87\n",
            "Epoch: 0870 loss_train: 0.7140 acc_train: 0.8333 loss_val: 0.8858 acc_val: 0.7300 time: 0.0421s\n",
            "88\n",
            "Epoch: 0871 loss_train: 0.6418 acc_train: 0.8500 loss_val: 0.8858 acc_val: 0.7320 time: 0.0422s\n",
            "89\n",
            "Epoch: 0872 loss_train: 0.7292 acc_train: 0.8333 loss_val: 0.8814 acc_val: 0.7320 time: 0.0422s\n",
            "90\n",
            "Epoch: 0873 loss_train: 0.7298 acc_train: 0.8500 loss_val: 0.8732 acc_val: 0.7360 time: 0.0441s\n",
            "91\n",
            "Epoch: 0874 loss_train: 0.6511 acc_train: 0.8833 loss_val: 0.8637 acc_val: 0.7400 time: 0.0432s\n",
            "92\n",
            "Epoch: 0875 loss_train: 0.6859 acc_train: 0.8583 loss_val: 0.8609 acc_val: 0.7440 time: 0.0444s\n",
            "93\n",
            "Epoch: 0876 loss_train: 0.7152 acc_train: 0.8667 loss_val: 0.8606 acc_val: 0.7440 time: 0.0431s\n",
            "94\n",
            "Epoch: 0877 loss_train: 0.7579 acc_train: 0.7500 loss_val: 0.8621 acc_val: 0.7440 time: 0.0427s\n",
            "95\n",
            "Epoch: 0878 loss_train: 0.7139 acc_train: 0.8333 loss_val: 0.8671 acc_val: 0.7420 time: 0.0451s\n",
            "96\n",
            "Epoch: 0879 loss_train: 0.6372 acc_train: 0.8500 loss_val: 0.8725 acc_val: 0.7420 time: 0.0427s\n",
            "97\n",
            "Epoch: 0880 loss_train: 0.7225 acc_train: 0.8500 loss_val: 0.8777 acc_val: 0.7340 time: 0.0435s\n",
            "98\n",
            "Epoch: 0881 loss_train: 0.7346 acc_train: 0.8417 loss_val: 0.8815 acc_val: 0.7300 time: 0.0424s\n",
            "99\n",
            "Epoch: 0882 loss_train: 0.7387 acc_train: 0.8667 loss_val: 0.8761 acc_val: 0.7360 time: 0.0423s\n",
            "100\n",
            "Epoch: 0883 loss_train: 0.6338 acc_train: 0.8667 loss_val: 0.8686 acc_val: 0.7360 time: 0.0435s\n",
            "101\n",
            "Epoch: 0884 loss_train: 0.7827 acc_train: 0.8000 loss_val: 0.8634 acc_val: 0.7420 time: 0.0421s\n",
            "102\n",
            "Epoch: 0885 loss_train: 0.7177 acc_train: 0.8833 loss_val: 0.8609 acc_val: 0.7460 time: 0.0421s\n",
            "103\n",
            "Epoch: 0886 loss_train: 0.6130 acc_train: 0.8917 loss_val: 0.8592 acc_val: 0.7460 time: 0.0421s\n",
            "104\n",
            "Epoch: 0887 loss_train: 0.7583 acc_train: 0.8167 loss_val: 0.8593 acc_val: 0.7460 time: 0.0421s\n",
            "105\n",
            "Epoch: 0888 loss_train: 0.6793 acc_train: 0.8667 loss_val: 0.8634 acc_val: 0.7420 time: 0.0431s\n",
            "106\n",
            "Epoch: 0889 loss_train: 0.6829 acc_train: 0.8500 loss_val: 0.8710 acc_val: 0.7480 time: 0.0417s\n",
            "107\n",
            "Epoch: 0890 loss_train: 0.7269 acc_train: 0.8333 loss_val: 0.8795 acc_val: 0.7340 time: 0.0421s\n",
            "108\n",
            "Epoch: 0891 loss_train: 0.5859 acc_train: 0.9167 loss_val: 0.8844 acc_val: 0.7360 time: 0.0425s\n",
            "109\n",
            "Epoch: 0892 loss_train: 0.7169 acc_train: 0.8500 loss_val: 0.8844 acc_val: 0.7400 time: 0.0422s\n",
            "110\n",
            "Epoch: 0893 loss_train: 0.7434 acc_train: 0.8500 loss_val: 0.8766 acc_val: 0.7420 time: 0.0429s\n",
            "111\n",
            "Epoch: 0894 loss_train: 0.6746 acc_train: 0.8167 loss_val: 0.8673 acc_val: 0.7500 time: 0.0425s\n",
            "112\n",
            "Epoch: 0895 loss_train: 0.6611 acc_train: 0.8500 loss_val: 0.8582 acc_val: 0.7460 time: 0.0422s\n",
            "113\n",
            "Epoch: 0896 loss_train: 0.7590 acc_train: 0.8250 loss_val: 0.8526 acc_val: 0.7420 time: 0.0422s\n",
            "114\n",
            "Epoch: 0897 loss_train: 0.6824 acc_train: 0.8250 loss_val: 0.8511 acc_val: 0.7480 time: 0.0421s\n",
            "115\n",
            "Epoch: 0898 loss_train: 0.6591 acc_train: 0.8667 loss_val: 0.8520 acc_val: 0.7480 time: 0.0426s\n",
            "0\n",
            "Epoch: 0899 loss_train: 0.6465 acc_train: 0.8583 loss_val: 0.8550 acc_val: 0.7440 time: 0.0425s\n",
            "1\n",
            "Epoch: 0900 loss_train: 0.6971 acc_train: 0.8333 loss_val: 0.8605 acc_val: 0.7480 time: 0.0431s\n",
            "2\n",
            "Epoch: 0901 loss_train: 0.7082 acc_train: 0.8583 loss_val: 0.8701 acc_val: 0.7420 time: 0.0421s\n",
            "3\n",
            "Epoch: 0902 loss_train: 0.7046 acc_train: 0.8167 loss_val: 0.8751 acc_val: 0.7360 time: 0.0432s\n",
            "4\n",
            "Epoch: 0903 loss_train: 0.7148 acc_train: 0.8417 loss_val: 0.8779 acc_val: 0.7340 time: 0.0427s\n",
            "5\n",
            "Epoch: 0904 loss_train: 0.6537 acc_train: 0.9083 loss_val: 0.8755 acc_val: 0.7380 time: 0.0421s\n",
            "6\n",
            "Epoch: 0905 loss_train: 0.7649 acc_train: 0.8333 loss_val: 0.8756 acc_val: 0.7380 time: 0.0423s\n",
            "7\n",
            "Epoch: 0906 loss_train: 0.6837 acc_train: 0.8500 loss_val: 0.8717 acc_val: 0.7420 time: 0.0428s\n",
            "8\n",
            "Epoch: 0907 loss_train: 0.6260 acc_train: 0.8750 loss_val: 0.8680 acc_val: 0.7440 time: 0.0421s\n",
            "9\n",
            "Epoch: 0908 loss_train: 0.7403 acc_train: 0.8333 loss_val: 0.8663 acc_val: 0.7460 time: 0.0431s\n",
            "10\n",
            "Epoch: 0909 loss_train: 0.7358 acc_train: 0.8417 loss_val: 0.8634 acc_val: 0.7460 time: 0.0427s\n",
            "11\n",
            "Epoch: 0910 loss_train: 0.6846 acc_train: 0.8750 loss_val: 0.8629 acc_val: 0.7460 time: 0.0425s\n",
            "12\n",
            "Epoch: 0911 loss_train: 0.7150 acc_train: 0.8000 loss_val: 0.8590 acc_val: 0.7360 time: 0.0422s\n",
            "13\n",
            "Epoch: 0912 loss_train: 0.7359 acc_train: 0.8333 loss_val: 0.8610 acc_val: 0.7400 time: 0.0425s\n",
            "14\n",
            "Epoch: 0913 loss_train: 0.6889 acc_train: 0.8583 loss_val: 0.8682 acc_val: 0.7400 time: 0.0428s\n",
            "15\n",
            "Epoch: 0914 loss_train: 0.6432 acc_train: 0.8833 loss_val: 0.8743 acc_val: 0.7360 time: 0.0421s\n",
            "16\n",
            "Epoch: 0915 loss_train: 0.7213 acc_train: 0.8417 loss_val: 0.8774 acc_val: 0.7340 time: 0.0422s\n",
            "17\n",
            "Epoch: 0916 loss_train: 0.5809 acc_train: 0.9083 loss_val: 0.8805 acc_val: 0.7360 time: 0.0421s\n",
            "18\n",
            "Epoch: 0917 loss_train: 0.6643 acc_train: 0.8750 loss_val: 0.8808 acc_val: 0.7320 time: 0.0435s\n",
            "19\n",
            "Epoch: 0918 loss_train: 0.6280 acc_train: 0.8750 loss_val: 0.8776 acc_val: 0.7380 time: 0.0441s\n",
            "20\n",
            "Epoch: 0919 loss_train: 0.6801 acc_train: 0.8667 loss_val: 0.8684 acc_val: 0.7420 time: 0.0422s\n",
            "21\n",
            "Epoch: 0920 loss_train: 0.6807 acc_train: 0.8417 loss_val: 0.8629 acc_val: 0.7480 time: 0.0422s\n",
            "22\n",
            "Epoch: 0921 loss_train: 0.7207 acc_train: 0.8250 loss_val: 0.8584 acc_val: 0.7460 time: 0.0425s\n",
            "23\n",
            "Epoch: 0922 loss_train: 0.6874 acc_train: 0.8250 loss_val: 0.8526 acc_val: 0.7540 time: 0.0423s\n",
            "24\n",
            "Epoch: 0923 loss_train: 0.7326 acc_train: 0.8333 loss_val: 0.8507 acc_val: 0.7520 time: 0.0478s\n",
            "0\n",
            "Epoch: 0924 loss_train: 0.7249 acc_train: 0.8083 loss_val: 0.8509 acc_val: 0.7500 time: 0.0426s\n",
            "0\n",
            "Epoch: 0925 loss_train: 0.6939 acc_train: 0.8667 loss_val: 0.8532 acc_val: 0.7460 time: 0.0428s\n",
            "1\n",
            "Epoch: 0926 loss_train: 0.7967 acc_train: 0.7917 loss_val: 0.8551 acc_val: 0.7440 time: 0.0423s\n",
            "2\n",
            "Epoch: 0927 loss_train: 0.7029 acc_train: 0.8333 loss_val: 0.8596 acc_val: 0.7420 time: 0.0424s\n",
            "3\n",
            "Epoch: 0928 loss_train: 0.7260 acc_train: 0.8583 loss_val: 0.8680 acc_val: 0.7380 time: 0.0432s\n",
            "4\n",
            "Epoch: 0929 loss_train: 0.6595 acc_train: 0.8750 loss_val: 0.8746 acc_val: 0.7340 time: 0.0421s\n",
            "5\n",
            "Epoch: 0930 loss_train: 0.7148 acc_train: 0.8250 loss_val: 0.8830 acc_val: 0.7380 time: 0.0436s\n",
            "6\n",
            "Epoch: 0931 loss_train: 0.6842 acc_train: 0.8583 loss_val: 0.8867 acc_val: 0.7380 time: 0.0424s\n",
            "7\n",
            "Epoch: 0932 loss_train: 0.7125 acc_train: 0.8250 loss_val: 0.8839 acc_val: 0.7400 time: 0.0423s\n",
            "8\n",
            "Epoch: 0933 loss_train: 0.6455 acc_train: 0.9000 loss_val: 0.8795 acc_val: 0.7420 time: 0.0469s\n",
            "9\n",
            "Epoch: 0934 loss_train: 0.6339 acc_train: 0.8833 loss_val: 0.8728 acc_val: 0.7460 time: 0.0421s\n",
            "10\n",
            "Epoch: 0935 loss_train: 0.6569 acc_train: 0.8667 loss_val: 0.8675 acc_val: 0.7480 time: 0.0428s\n",
            "11\n",
            "Epoch: 0936 loss_train: 0.7893 acc_train: 0.8417 loss_val: 0.8640 acc_val: 0.7420 time: 0.0424s\n",
            "12\n",
            "Epoch: 0937 loss_train: 0.7705 acc_train: 0.8417 loss_val: 0.8635 acc_val: 0.7400 time: 0.0422s\n",
            "13\n",
            "Epoch: 0938 loss_train: 0.6463 acc_train: 0.8750 loss_val: 0.8624 acc_val: 0.7380 time: 0.0451s\n",
            "14\n",
            "Epoch: 0939 loss_train: 0.6910 acc_train: 0.8500 loss_val: 0.8652 acc_val: 0.7340 time: 0.0423s\n",
            "15\n",
            "Epoch: 0940 loss_train: 0.6670 acc_train: 0.8833 loss_val: 0.8686 acc_val: 0.7320 time: 0.0423s\n",
            "16\n",
            "Epoch: 0941 loss_train: 0.7748 acc_train: 0.8417 loss_val: 0.8698 acc_val: 0.7320 time: 0.0431s\n",
            "17\n",
            "Epoch: 0942 loss_train: 0.6412 acc_train: 0.8750 loss_val: 0.8695 acc_val: 0.7360 time: 0.0437s\n",
            "18\n",
            "Epoch: 0943 loss_train: 0.7008 acc_train: 0.8333 loss_val: 0.8677 acc_val: 0.7380 time: 0.0442s\n",
            "19\n",
            "Epoch: 0944 loss_train: 0.7579 acc_train: 0.8000 loss_val: 0.8656 acc_val: 0.7400 time: 0.0424s\n",
            "20\n",
            "Epoch: 0945 loss_train: 0.7655 acc_train: 0.8333 loss_val: 0.8639 acc_val: 0.7440 time: 0.0438s\n",
            "21\n",
            "Epoch: 0946 loss_train: 0.7135 acc_train: 0.8667 loss_val: 0.8630 acc_val: 0.7460 time: 0.0427s\n",
            "22\n",
            "Epoch: 0947 loss_train: 0.6613 acc_train: 0.8917 loss_val: 0.8618 acc_val: 0.7420 time: 0.0447s\n",
            "23\n",
            "Epoch: 0948 loss_train: 0.7800 acc_train: 0.8250 loss_val: 0.8653 acc_val: 0.7360 time: 0.0458s\n",
            "24\n",
            "Epoch: 0949 loss_train: 0.6980 acc_train: 0.8250 loss_val: 0.8712 acc_val: 0.7360 time: 0.0429s\n",
            "25\n",
            "Epoch: 0950 loss_train: 0.7012 acc_train: 0.8833 loss_val: 0.8775 acc_val: 0.7320 time: 0.0431s\n",
            "26\n",
            "Epoch: 0951 loss_train: 0.7553 acc_train: 0.8333 loss_val: 0.8801 acc_val: 0.7300 time: 0.0422s\n",
            "27\n",
            "Epoch: 0952 loss_train: 0.7568 acc_train: 0.8167 loss_val: 0.8776 acc_val: 0.7300 time: 0.0423s\n",
            "28\n",
            "Epoch: 0953 loss_train: 0.7480 acc_train: 0.8167 loss_val: 0.8770 acc_val: 0.7300 time: 0.0425s\n",
            "29\n",
            "Epoch: 0954 loss_train: 0.7127 acc_train: 0.8417 loss_val: 0.8735 acc_val: 0.7360 time: 0.0422s\n",
            "30\n",
            "Epoch: 0955 loss_train: 0.6871 acc_train: 0.8500 loss_val: 0.8692 acc_val: 0.7420 time: 0.0428s\n",
            "31\n",
            "Epoch: 0956 loss_train: 0.6972 acc_train: 0.8333 loss_val: 0.8657 acc_val: 0.7400 time: 0.0424s\n",
            "32\n",
            "Epoch: 0957 loss_train: 0.6573 acc_train: 0.9083 loss_val: 0.8651 acc_val: 0.7400 time: 0.0428s\n",
            "33\n",
            "Epoch: 0958 loss_train: 0.8402 acc_train: 0.8250 loss_val: 0.8646 acc_val: 0.7420 time: 0.0447s\n",
            "34\n",
            "Epoch: 0959 loss_train: 0.7362 acc_train: 0.8250 loss_val: 0.8664 acc_val: 0.7400 time: 0.0422s\n",
            "35\n",
            "Epoch: 0960 loss_train: 0.7178 acc_train: 0.8667 loss_val: 0.8704 acc_val: 0.7440 time: 0.0423s\n",
            "36\n",
            "Epoch: 0961 loss_train: 0.6383 acc_train: 0.8500 loss_val: 0.8749 acc_val: 0.7440 time: 0.0424s\n",
            "37\n",
            "Epoch: 0962 loss_train: 0.7989 acc_train: 0.8250 loss_val: 0.8763 acc_val: 0.7400 time: 0.0424s\n",
            "38\n",
            "Epoch: 0963 loss_train: 0.7465 acc_train: 0.8167 loss_val: 0.8772 acc_val: 0.7380 time: 0.0430s\n",
            "39\n",
            "Epoch: 0964 loss_train: 0.6925 acc_train: 0.8417 loss_val: 0.8778 acc_val: 0.7400 time: 0.0422s\n",
            "40\n",
            "Epoch: 0965 loss_train: 0.6535 acc_train: 0.8833 loss_val: 0.8800 acc_val: 0.7340 time: 0.0422s\n",
            "41\n",
            "Epoch: 0966 loss_train: 0.6972 acc_train: 0.8917 loss_val: 0.8809 acc_val: 0.7400 time: 0.0426s\n",
            "42\n",
            "Epoch: 0967 loss_train: 0.6778 acc_train: 0.8417 loss_val: 0.8832 acc_val: 0.7380 time: 0.0429s\n",
            "43\n",
            "Epoch: 0968 loss_train: 0.7509 acc_train: 0.8000 loss_val: 0.8840 acc_val: 0.7360 time: 0.0432s\n",
            "44\n",
            "Epoch: 0969 loss_train: 0.6789 acc_train: 0.8333 loss_val: 0.8781 acc_val: 0.7380 time: 0.0436s\n",
            "45\n",
            "Epoch: 0970 loss_train: 0.5792 acc_train: 0.8917 loss_val: 0.8746 acc_val: 0.7360 time: 0.0436s\n",
            "46\n",
            "Epoch: 0971 loss_train: 0.6445 acc_train: 0.8250 loss_val: 0.8671 acc_val: 0.7340 time: 0.0424s\n",
            "47\n",
            "Epoch: 0972 loss_train: 0.7323 acc_train: 0.8167 loss_val: 0.8606 acc_val: 0.7360 time: 0.0421s\n",
            "48\n",
            "Epoch: 0973 loss_train: 0.7053 acc_train: 0.8083 loss_val: 0.8578 acc_val: 0.7320 time: 0.0436s\n",
            "49\n",
            "Epoch: 0974 loss_train: 0.7630 acc_train: 0.8000 loss_val: 0.8539 acc_val: 0.7340 time: 0.0427s\n",
            "50\n",
            "Epoch: 0975 loss_train: 0.7201 acc_train: 0.8250 loss_val: 0.8517 acc_val: 0.7340 time: 0.0426s\n",
            "51\n",
            "Epoch: 0976 loss_train: 0.7359 acc_train: 0.8000 loss_val: 0.8527 acc_val: 0.7380 time: 0.0428s\n",
            "52\n",
            "Epoch: 0977 loss_train: 0.6978 acc_train: 0.8167 loss_val: 0.8583 acc_val: 0.7420 time: 0.0421s\n",
            "53\n",
            "Epoch: 0978 loss_train: 0.6739 acc_train: 0.8583 loss_val: 0.8650 acc_val: 0.7400 time: 0.0436s\n",
            "54\n",
            "Epoch: 0979 loss_train: 0.6978 acc_train: 0.8750 loss_val: 0.8731 acc_val: 0.7420 time: 0.0421s\n",
            "55\n",
            "Epoch: 0980 loss_train: 0.6762 acc_train: 0.8583 loss_val: 0.8821 acc_val: 0.7320 time: 0.0421s\n",
            "56\n",
            "Epoch: 0981 loss_train: 0.6283 acc_train: 0.8667 loss_val: 0.8872 acc_val: 0.7260 time: 0.0422s\n",
            "57\n",
            "Epoch: 0982 loss_train: 0.7045 acc_train: 0.8250 loss_val: 0.8858 acc_val: 0.7300 time: 0.0422s\n",
            "58\n",
            "Epoch: 0983 loss_train: 0.6687 acc_train: 0.8583 loss_val: 0.8794 acc_val: 0.7320 time: 0.0466s\n",
            "59\n",
            "Epoch: 0984 loss_train: 0.6967 acc_train: 0.8250 loss_val: 0.8704 acc_val: 0.7360 time: 0.0422s\n",
            "60\n",
            "Epoch: 0985 loss_train: 0.7246 acc_train: 0.8167 loss_val: 0.8627 acc_val: 0.7400 time: 0.0422s\n",
            "61\n",
            "Epoch: 0986 loss_train: 0.7215 acc_train: 0.8083 loss_val: 0.8564 acc_val: 0.7460 time: 0.0423s\n",
            "62\n",
            "Epoch: 0987 loss_train: 0.6544 acc_train: 0.8667 loss_val: 0.8543 acc_val: 0.7400 time: 0.0423s\n",
            "63\n",
            "Epoch: 0988 loss_train: 0.7429 acc_train: 0.8333 loss_val: 0.8546 acc_val: 0.7380 time: 0.0439s\n",
            "64\n",
            "Epoch: 0989 loss_train: 0.6797 acc_train: 0.8583 loss_val: 0.8582 acc_val: 0.7340 time: 0.0424s\n",
            "65\n",
            "Epoch: 0990 loss_train: 0.6963 acc_train: 0.8667 loss_val: 0.8622 acc_val: 0.7320 time: 0.0430s\n",
            "66\n",
            "Epoch: 0991 loss_train: 0.6410 acc_train: 0.8833 loss_val: 0.8668 acc_val: 0.7400 time: 0.0423s\n",
            "67\n",
            "Epoch: 0992 loss_train: 0.7010 acc_train: 0.8417 loss_val: 0.8670 acc_val: 0.7360 time: 0.0422s\n",
            "68\n",
            "Epoch: 0993 loss_train: 0.7643 acc_train: 0.8167 loss_val: 0.8683 acc_val: 0.7380 time: 0.0434s\n",
            "69\n",
            "Epoch: 0994 loss_train: 0.7368 acc_train: 0.8500 loss_val: 0.8680 acc_val: 0.7440 time: 0.0432s\n",
            "70\n",
            "Epoch: 0995 loss_train: 0.7139 acc_train: 0.8417 loss_val: 0.8665 acc_val: 0.7420 time: 0.0429s\n",
            "71\n",
            "Epoch: 0996 loss_train: 0.6598 acc_train: 0.8583 loss_val: 0.8633 acc_val: 0.7420 time: 0.0425s\n",
            "72\n",
            "Epoch: 0997 loss_train: 0.6470 acc_train: 0.8750 loss_val: 0.8609 acc_val: 0.7440 time: 0.0421s\n",
            "73\n",
            "Epoch: 0998 loss_train: 0.6885 acc_train: 0.8333 loss_val: 0.8575 acc_val: 0.7440 time: 0.0446s\n",
            "74\n",
            "Epoch: 0999 loss_train: 0.6992 acc_train: 0.8250 loss_val: 0.8583 acc_val: 0.7360 time: 0.0423s\n",
            "75\n",
            "Epoch: 1000 loss_train: 0.6498 acc_train: 0.8000 loss_val: 0.8614 acc_val: 0.7280 time: 0.0423s\n",
            "76\n",
            "Epoch: 1001 loss_train: 0.7696 acc_train: 0.8167 loss_val: 0.8667 acc_val: 0.7260 time: 0.0420s\n",
            "77\n",
            "Epoch: 1002 loss_train: 0.6668 acc_train: 0.8333 loss_val: 0.8710 acc_val: 0.7300 time: 0.0424s\n",
            "78\n",
            "Epoch: 1003 loss_train: 0.6706 acc_train: 0.8083 loss_val: 0.8717 acc_val: 0.7380 time: 0.0435s\n",
            "79\n",
            "Epoch: 1004 loss_train: 0.7129 acc_train: 0.8667 loss_val: 0.8735 acc_val: 0.7340 time: 0.0422s\n",
            "80\n",
            "Epoch: 1005 loss_train: 0.7493 acc_train: 0.8583 loss_val: 0.8743 acc_val: 0.7360 time: 0.0426s\n",
            "81\n",
            "Epoch: 1006 loss_train: 0.7241 acc_train: 0.8417 loss_val: 0.8675 acc_val: 0.7340 time: 0.0423s\n",
            "82\n",
            "Epoch: 1007 loss_train: 0.6586 acc_train: 0.8583 loss_val: 0.8643 acc_val: 0.7400 time: 0.0424s\n",
            "83\n",
            "Epoch: 1008 loss_train: 0.7356 acc_train: 0.8500 loss_val: 0.8610 acc_val: 0.7400 time: 0.0430s\n",
            "84\n",
            "Epoch: 1009 loss_train: 0.7072 acc_train: 0.8750 loss_val: 0.8609 acc_val: 0.7420 time: 0.0424s\n",
            "85\n",
            "Epoch: 1010 loss_train: 0.6681 acc_train: 0.8250 loss_val: 0.8611 acc_val: 0.7440 time: 0.0428s\n",
            "86\n",
            "Epoch: 1011 loss_train: 0.6841 acc_train: 0.8667 loss_val: 0.8588 acc_val: 0.7460 time: 0.0427s\n",
            "87\n",
            "Epoch: 1012 loss_train: 0.7226 acc_train: 0.8167 loss_val: 0.8593 acc_val: 0.7380 time: 0.0427s\n",
            "88\n",
            "Epoch: 1013 loss_train: 0.7100 acc_train: 0.8167 loss_val: 0.8626 acc_val: 0.7380 time: 0.0439s\n",
            "89\n",
            "Epoch: 1014 loss_train: 0.7228 acc_train: 0.8583 loss_val: 0.8687 acc_val: 0.7360 time: 0.0423s\n",
            "90\n",
            "Epoch: 1015 loss_train: 0.7023 acc_train: 0.8667 loss_val: 0.8763 acc_val: 0.7360 time: 0.0418s\n",
            "91\n",
            "Epoch: 1016 loss_train: 0.7941 acc_train: 0.8250 loss_val: 0.8861 acc_val: 0.7340 time: 0.0422s\n",
            "92\n",
            "Epoch: 1017 loss_train: 0.6218 acc_train: 0.8750 loss_val: 0.8924 acc_val: 0.7240 time: 0.0431s\n",
            "93\n",
            "Epoch: 1018 loss_train: 0.7429 acc_train: 0.8000 loss_val: 0.8864 acc_val: 0.7320 time: 0.0455s\n",
            "94\n",
            "Epoch: 1019 loss_train: 0.7040 acc_train: 0.8417 loss_val: 0.8751 acc_val: 0.7300 time: 0.0433s\n",
            "95\n",
            "Epoch: 1020 loss_train: 0.6387 acc_train: 0.8583 loss_val: 0.8653 acc_val: 0.7380 time: 0.0422s\n",
            "96\n",
            "Epoch: 1021 loss_train: 0.5818 acc_train: 0.8833 loss_val: 0.8592 acc_val: 0.7400 time: 0.0421s\n",
            "97\n",
            "Epoch: 1022 loss_train: 0.6541 acc_train: 0.8417 loss_val: 0.8545 acc_val: 0.7400 time: 0.0423s\n",
            "98\n",
            "Epoch: 1023 loss_train: 0.6914 acc_train: 0.8250 loss_val: 0.8533 acc_val: 0.7440 time: 0.0438s\n",
            "99\n",
            "Epoch: 1024 loss_train: 0.6506 acc_train: 0.8500 loss_val: 0.8532 acc_val: 0.7420 time: 0.0422s\n",
            "100\n",
            "Epoch: 1025 loss_train: 0.6739 acc_train: 0.8417 loss_val: 0.8563 acc_val: 0.7400 time: 0.0421s\n",
            "101\n",
            "Epoch: 1026 loss_train: 0.6242 acc_train: 0.8500 loss_val: 0.8599 acc_val: 0.7340 time: 0.0427s\n",
            "102\n",
            "Epoch: 1027 loss_train: 0.6069 acc_train: 0.8667 loss_val: 0.8668 acc_val: 0.7360 time: 0.0447s\n",
            "103\n",
            "Epoch: 1028 loss_train: 0.7404 acc_train: 0.8083 loss_val: 0.8753 acc_val: 0.7340 time: 0.0442s\n",
            "104\n",
            "Epoch: 1029 loss_train: 0.6710 acc_train: 0.8667 loss_val: 0.8864 acc_val: 0.7300 time: 0.0426s\n",
            "105\n",
            "Epoch: 1030 loss_train: 0.7473 acc_train: 0.8083 loss_val: 0.8909 acc_val: 0.7340 time: 0.0427s\n",
            "106\n",
            "Epoch: 1031 loss_train: 0.6572 acc_train: 0.8500 loss_val: 0.8878 acc_val: 0.7280 time: 0.0422s\n",
            "107\n",
            "Epoch: 1032 loss_train: 0.6901 acc_train: 0.8500 loss_val: 0.8730 acc_val: 0.7300 time: 0.0423s\n",
            "108\n",
            "Epoch: 1033 loss_train: 0.6620 acc_train: 0.8333 loss_val: 0.8605 acc_val: 0.7360 time: 0.0430s\n",
            "109\n",
            "Epoch: 1034 loss_train: 0.7829 acc_train: 0.8083 loss_val: 0.8534 acc_val: 0.7340 time: 0.0434s\n",
            "110\n",
            "Epoch: 1035 loss_train: 0.7117 acc_train: 0.8583 loss_val: 0.8507 acc_val: 0.7360 time: 0.0435s\n",
            "111\n",
            "Epoch: 1036 loss_train: 0.7195 acc_train: 0.8500 loss_val: 0.8505 acc_val: 0.7420 time: 0.0422s\n",
            "112\n",
            "Epoch: 1037 loss_train: 0.7022 acc_train: 0.8417 loss_val: 0.8568 acc_val: 0.7380 time: 0.0419s\n",
            "0\n",
            "Epoch: 1038 loss_train: 0.6467 acc_train: 0.9000 loss_val: 0.8617 acc_val: 0.7340 time: 0.0438s\n",
            "1\n",
            "Epoch: 1039 loss_train: 0.7789 acc_train: 0.8167 loss_val: 0.8682 acc_val: 0.7300 time: 0.0426s\n",
            "2\n",
            "Epoch: 1040 loss_train: 0.6435 acc_train: 0.8833 loss_val: 0.8762 acc_val: 0.7220 time: 0.0427s\n",
            "3\n",
            "Epoch: 1041 loss_train: 0.7073 acc_train: 0.8083 loss_val: 0.8813 acc_val: 0.7220 time: 0.0422s\n",
            "4\n",
            "Epoch: 1042 loss_train: 0.7046 acc_train: 0.8250 loss_val: 0.8852 acc_val: 0.7260 time: 0.0429s\n",
            "5\n",
            "Epoch: 1043 loss_train: 0.7242 acc_train: 0.8500 loss_val: 0.8832 acc_val: 0.7280 time: 0.0436s\n",
            "6\n",
            "Epoch: 1044 loss_train: 0.6552 acc_train: 0.8833 loss_val: 0.8768 acc_val: 0.7260 time: 0.0423s\n",
            "7\n",
            "Epoch: 1045 loss_train: 0.5943 acc_train: 0.9417 loss_val: 0.8694 acc_val: 0.7260 time: 0.0423s\n",
            "8\n",
            "Epoch: 1046 loss_train: 0.5600 acc_train: 0.8917 loss_val: 0.8629 acc_val: 0.7340 time: 0.0421s\n",
            "9\n",
            "Epoch: 1047 loss_train: 0.6619 acc_train: 0.8667 loss_val: 0.8583 acc_val: 0.7400 time: 0.0448s\n",
            "10\n",
            "Epoch: 1048 loss_train: 0.7066 acc_train: 0.8500 loss_val: 0.8574 acc_val: 0.7400 time: 0.0435s\n",
            "11\n",
            "Epoch: 1049 loss_train: 0.6865 acc_train: 0.8750 loss_val: 0.8602 acc_val: 0.7360 time: 0.0430s\n",
            "12\n",
            "Epoch: 1050 loss_train: 0.6839 acc_train: 0.8417 loss_val: 0.8652 acc_val: 0.7340 time: 0.0428s\n",
            "13\n",
            "Epoch: 1051 loss_train: 0.6503 acc_train: 0.8667 loss_val: 0.8716 acc_val: 0.7260 time: 0.0428s\n",
            "14\n",
            "Epoch: 1052 loss_train: 0.6708 acc_train: 0.8167 loss_val: 0.8760 acc_val: 0.7200 time: 0.0422s\n",
            "15\n",
            "Epoch: 1053 loss_train: 0.6599 acc_train: 0.8750 loss_val: 0.8778 acc_val: 0.7220 time: 0.0480s\n",
            "16\n",
            "Epoch: 1054 loss_train: 0.6793 acc_train: 0.8417 loss_val: 0.8758 acc_val: 0.7180 time: 0.0426s\n",
            "17\n",
            "Epoch: 1055 loss_train: 0.7165 acc_train: 0.8333 loss_val: 0.8762 acc_val: 0.7260 time: 0.0427s\n",
            "18\n",
            "Epoch: 1056 loss_train: 0.6899 acc_train: 0.8750 loss_val: 0.8767 acc_val: 0.7380 time: 0.0422s\n",
            "19\n",
            "Epoch: 1057 loss_train: 0.7589 acc_train: 0.8250 loss_val: 0.8757 acc_val: 0.7360 time: 0.0433s\n",
            "20\n",
            "Epoch: 1058 loss_train: 0.7376 acc_train: 0.8250 loss_val: 0.8765 acc_val: 0.7380 time: 0.0437s\n",
            "21\n",
            "Epoch: 1059 loss_train: 0.7109 acc_train: 0.8833 loss_val: 0.8718 acc_val: 0.7400 time: 0.0421s\n",
            "22\n",
            "Epoch: 1060 loss_train: 0.6595 acc_train: 0.8750 loss_val: 0.8682 acc_val: 0.7420 time: 0.0424s\n",
            "23\n",
            "Epoch: 1061 loss_train: 0.5994 acc_train: 0.8667 loss_val: 0.8661 acc_val: 0.7440 time: 0.0423s\n",
            "24\n",
            "Epoch: 1062 loss_train: 0.7330 acc_train: 0.8333 loss_val: 0.8648 acc_val: 0.7340 time: 0.0423s\n",
            "25\n",
            "Epoch: 1063 loss_train: 0.6465 acc_train: 0.8583 loss_val: 0.8649 acc_val: 0.7320 time: 0.0430s\n",
            "26\n",
            "Epoch: 1064 loss_train: 0.6879 acc_train: 0.8750 loss_val: 0.8659 acc_val: 0.7280 time: 0.0422s\n",
            "27\n",
            "Epoch: 1065 loss_train: 0.7022 acc_train: 0.8250 loss_val: 0.8711 acc_val: 0.7300 time: 0.0424s\n",
            "28\n",
            "Epoch: 1066 loss_train: 0.7559 acc_train: 0.8167 loss_val: 0.8706 acc_val: 0.7320 time: 0.0424s\n",
            "29\n",
            "Epoch: 1067 loss_train: 0.6451 acc_train: 0.8500 loss_val: 0.8645 acc_val: 0.7320 time: 0.0421s\n",
            "30\n",
            "Epoch: 1068 loss_train: 0.6856 acc_train: 0.8500 loss_val: 0.8589 acc_val: 0.7340 time: 0.0444s\n",
            "31\n",
            "Epoch: 1069 loss_train: 0.7484 acc_train: 0.8083 loss_val: 0.8559 acc_val: 0.7500 time: 0.0442s\n",
            "32\n",
            "Epoch: 1070 loss_train: 0.7122 acc_train: 0.8250 loss_val: 0.8563 acc_val: 0.7520 time: 0.0421s\n",
            "33\n",
            "Epoch: 1071 loss_train: 0.6646 acc_train: 0.8667 loss_val: 0.8601 acc_val: 0.7540 time: 0.0422s\n",
            "34\n",
            "Epoch: 1072 loss_train: 0.6257 acc_train: 0.9000 loss_val: 0.8633 acc_val: 0.7520 time: 0.0424s\n",
            "0\n",
            "Epoch: 1073 loss_train: 0.6722 acc_train: 0.8333 loss_val: 0.8657 acc_val: 0.7500 time: 0.0433s\n",
            "1\n",
            "Epoch: 1074 loss_train: 0.7382 acc_train: 0.8583 loss_val: 0.8692 acc_val: 0.7440 time: 0.0427s\n",
            "2\n",
            "Epoch: 1075 loss_train: 0.7316 acc_train: 0.8250 loss_val: 0.8727 acc_val: 0.7440 time: 0.0427s\n",
            "3\n",
            "Epoch: 1076 loss_train: 0.6549 acc_train: 0.8500 loss_val: 0.8758 acc_val: 0.7380 time: 0.0423s\n",
            "4\n",
            "Epoch: 1077 loss_train: 0.7211 acc_train: 0.8583 loss_val: 0.8758 acc_val: 0.7340 time: 0.0423s\n",
            "5\n",
            "Epoch: 1078 loss_train: 0.7910 acc_train: 0.7833 loss_val: 0.8701 acc_val: 0.7400 time: 0.0434s\n",
            "6\n",
            "Epoch: 1079 loss_train: 0.7532 acc_train: 0.8500 loss_val: 0.8662 acc_val: 0.7400 time: 0.0422s\n",
            "7\n",
            "Epoch: 1080 loss_train: 0.7175 acc_train: 0.8333 loss_val: 0.8619 acc_val: 0.7400 time: 0.0441s\n",
            "8\n",
            "Epoch: 1081 loss_train: 0.6954 acc_train: 0.8417 loss_val: 0.8641 acc_val: 0.7420 time: 0.0422s\n",
            "9\n",
            "Epoch: 1082 loss_train: 0.5782 acc_train: 0.9000 loss_val: 0.8676 acc_val: 0.7420 time: 0.0423s\n",
            "10\n",
            "Epoch: 1083 loss_train: 0.7684 acc_train: 0.8167 loss_val: 0.8715 acc_val: 0.7360 time: 0.0435s\n",
            "11\n",
            "Epoch: 1084 loss_train: 0.7209 acc_train: 0.8417 loss_val: 0.8737 acc_val: 0.7340 time: 0.0424s\n",
            "12\n",
            "Epoch: 1085 loss_train: 0.6413 acc_train: 0.9083 loss_val: 0.8733 acc_val: 0.7340 time: 0.0425s\n",
            "13\n",
            "Epoch: 1086 loss_train: 0.6141 acc_train: 0.8833 loss_val: 0.8725 acc_val: 0.7400 time: 0.0422s\n",
            "14\n",
            "Epoch: 1087 loss_train: 0.7269 acc_train: 0.8000 loss_val: 0.8738 acc_val: 0.7400 time: 0.0422s\n",
            "15\n",
            "Epoch: 1088 loss_train: 0.6033 acc_train: 0.8583 loss_val: 0.8710 acc_val: 0.7400 time: 0.0443s\n",
            "16\n",
            "Epoch: 1089 loss_train: 0.6983 acc_train: 0.8417 loss_val: 0.8692 acc_val: 0.7400 time: 0.0423s\n",
            "17\n",
            "Epoch: 1090 loss_train: 0.7081 acc_train: 0.8417 loss_val: 0.8650 acc_val: 0.7420 time: 0.0443s\n",
            "18\n",
            "Epoch: 1091 loss_train: 0.6640 acc_train: 0.8833 loss_val: 0.8601 acc_val: 0.7480 time: 0.0433s\n",
            "19\n",
            "Epoch: 1092 loss_train: 0.6971 acc_train: 0.8667 loss_val: 0.8575 acc_val: 0.7520 time: 0.0427s\n",
            "20\n",
            "Epoch: 1093 loss_train: 0.7066 acc_train: 0.8583 loss_val: 0.8588 acc_val: 0.7440 time: 0.0455s\n",
            "21\n",
            "Epoch: 1094 loss_train: 0.6870 acc_train: 0.8583 loss_val: 0.8612 acc_val: 0.7460 time: 0.0429s\n",
            "22\n",
            "Epoch: 1095 loss_train: 0.7866 acc_train: 0.8083 loss_val: 0.8665 acc_val: 0.7460 time: 0.0428s\n",
            "23\n",
            "Epoch: 1096 loss_train: 0.7030 acc_train: 0.8500 loss_val: 0.8726 acc_val: 0.7440 time: 0.0423s\n",
            "24\n",
            "Epoch: 1097 loss_train: 0.6125 acc_train: 0.9000 loss_val: 0.8810 acc_val: 0.7360 time: 0.0421s\n",
            "25\n",
            "Epoch: 1098 loss_train: 0.6813 acc_train: 0.8667 loss_val: 0.8875 acc_val: 0.7340 time: 0.0447s\n",
            "26\n",
            "Epoch: 1099 loss_train: 0.6440 acc_train: 0.8833 loss_val: 0.8901 acc_val: 0.7300 time: 0.0427s\n",
            "27\n",
            "Epoch: 1100 loss_train: 0.6710 acc_train: 0.8583 loss_val: 0.8874 acc_val: 0.7320 time: 0.0421s\n",
            "28\n",
            "Epoch: 1101 loss_train: 0.7109 acc_train: 0.8750 loss_val: 0.8834 acc_val: 0.7320 time: 0.0416s\n",
            "29\n",
            "Epoch: 1102 loss_train: 0.6330 acc_train: 0.8750 loss_val: 0.8797 acc_val: 0.7320 time: 0.0431s\n",
            "30\n",
            "Epoch: 1103 loss_train: 0.7691 acc_train: 0.8417 loss_val: 0.8706 acc_val: 0.7420 time: 0.0455s\n",
            "31\n",
            "Epoch: 1104 loss_train: 0.7416 acc_train: 0.8250 loss_val: 0.8669 acc_val: 0.7400 time: 0.0423s\n",
            "32\n",
            "Epoch: 1105 loss_train: 0.7507 acc_train: 0.7667 loss_val: 0.8656 acc_val: 0.7440 time: 0.0424s\n",
            "33\n",
            "Epoch: 1106 loss_train: 0.7088 acc_train: 0.8583 loss_val: 0.8649 acc_val: 0.7440 time: 0.0420s\n",
            "34\n",
            "Epoch: 1107 loss_train: 0.7085 acc_train: 0.8500 loss_val: 0.8649 acc_val: 0.7440 time: 0.0424s\n",
            "35\n",
            "Epoch: 1108 loss_train: 0.6217 acc_train: 0.8917 loss_val: 0.8661 acc_val: 0.7400 time: 0.0459s\n",
            "36\n",
            "Epoch: 1109 loss_train: 0.7540 acc_train: 0.8083 loss_val: 0.8713 acc_val: 0.7420 time: 0.0425s\n",
            "37\n",
            "Epoch: 1110 loss_train: 0.7023 acc_train: 0.8167 loss_val: 0.8753 acc_val: 0.7400 time: 0.0423s\n",
            "38\n",
            "Epoch: 1111 loss_train: 0.6469 acc_train: 0.8500 loss_val: 0.8786 acc_val: 0.7360 time: 0.0422s\n",
            "39\n",
            "Epoch: 1112 loss_train: 0.7817 acc_train: 0.8417 loss_val: 0.8802 acc_val: 0.7360 time: 0.0422s\n",
            "40\n",
            "Epoch: 1113 loss_train: 0.7915 acc_train: 0.8083 loss_val: 0.8761 acc_val: 0.7340 time: 0.0451s\n",
            "41\n",
            "Epoch: 1114 loss_train: 0.6780 acc_train: 0.8833 loss_val: 0.8719 acc_val: 0.7360 time: 0.0444s\n",
            "42\n",
            "Epoch: 1115 loss_train: 0.6599 acc_train: 0.8667 loss_val: 0.8669 acc_val: 0.7460 time: 0.0428s\n",
            "43\n",
            "Epoch: 1116 loss_train: 0.6852 acc_train: 0.8833 loss_val: 0.8623 acc_val: 0.7440 time: 0.0425s\n",
            "44\n",
            "Epoch: 1117 loss_train: 0.6438 acc_train: 0.8417 loss_val: 0.8640 acc_val: 0.7480 time: 0.0423s\n",
            "45\n",
            "Epoch: 1118 loss_train: 0.6681 acc_train: 0.8500 loss_val: 0.8689 acc_val: 0.7460 time: 0.0438s\n",
            "46\n",
            "Epoch: 1119 loss_train: 0.7197 acc_train: 0.8333 loss_val: 0.8735 acc_val: 0.7440 time: 0.0422s\n",
            "47\n",
            "Epoch: 1120 loss_train: 0.7089 acc_train: 0.8417 loss_val: 0.8783 acc_val: 0.7400 time: 0.0422s\n",
            "48\n",
            "Epoch: 1121 loss_train: 0.6306 acc_train: 0.8250 loss_val: 0.8802 acc_val: 0.7420 time: 0.0423s\n",
            "49\n",
            "Epoch: 1122 loss_train: 0.7670 acc_train: 0.8500 loss_val: 0.8831 acc_val: 0.7400 time: 0.0431s\n",
            "50\n",
            "Epoch: 1123 loss_train: 0.7715 acc_train: 0.8167 loss_val: 0.8892 acc_val: 0.7280 time: 0.0435s\n",
            "51\n",
            "Epoch: 1124 loss_train: 0.7768 acc_train: 0.8000 loss_val: 0.8920 acc_val: 0.7220 time: 0.0441s\n",
            "52\n",
            "Epoch: 1125 loss_train: 0.7480 acc_train: 0.8000 loss_val: 0.8922 acc_val: 0.7260 time: 0.0432s\n",
            "53\n",
            "Epoch: 1126 loss_train: 0.6669 acc_train: 0.8667 loss_val: 0.8841 acc_val: 0.7360 time: 0.0428s\n",
            "54\n",
            "Epoch: 1127 loss_train: 0.7034 acc_train: 0.8417 loss_val: 0.8752 acc_val: 0.7400 time: 0.0427s\n",
            "55\n",
            "Epoch: 1128 loss_train: 0.6838 acc_train: 0.8750 loss_val: 0.8658 acc_val: 0.7380 time: 0.0457s\n",
            "56\n",
            "Epoch: 1129 loss_train: 0.7235 acc_train: 0.8417 loss_val: 0.8590 acc_val: 0.7460 time: 0.0425s\n",
            "57\n",
            "Epoch: 1130 loss_train: 0.7341 acc_train: 0.8417 loss_val: 0.8562 acc_val: 0.7460 time: 0.0422s\n",
            "58\n",
            "Epoch: 1131 loss_train: 0.5980 acc_train: 0.9083 loss_val: 0.8556 acc_val: 0.7400 time: 0.0422s\n",
            "59\n",
            "Epoch: 1132 loss_train: 0.7218 acc_train: 0.8000 loss_val: 0.8566 acc_val: 0.7380 time: 0.0421s\n",
            "60\n",
            "Epoch: 1133 loss_train: 0.6078 acc_train: 0.9000 loss_val: 0.8611 acc_val: 0.7300 time: 0.0446s\n",
            "61\n",
            "Epoch: 1134 loss_train: 0.6611 acc_train: 0.8500 loss_val: 0.8670 acc_val: 0.7260 time: 0.0421s\n",
            "62\n",
            "Epoch: 1135 loss_train: 0.6035 acc_train: 0.8917 loss_val: 0.8736 acc_val: 0.7280 time: 0.0423s\n",
            "63\n",
            "Epoch: 1136 loss_train: 0.6674 acc_train: 0.8417 loss_val: 0.8747 acc_val: 0.7280 time: 0.0425s\n",
            "64\n",
            "Epoch: 1137 loss_train: 0.7803 acc_train: 0.7917 loss_val: 0.8694 acc_val: 0.7380 time: 0.0421s\n",
            "65\n",
            "Epoch: 1138 loss_train: 0.6293 acc_train: 0.8500 loss_val: 0.8646 acc_val: 0.7400 time: 0.0431s\n",
            "66\n",
            "Epoch: 1139 loss_train: 0.6682 acc_train: 0.9000 loss_val: 0.8633 acc_val: 0.7440 time: 0.0422s\n",
            "67\n",
            "Epoch: 1140 loss_train: 0.7088 acc_train: 0.8250 loss_val: 0.8644 acc_val: 0.7480 time: 0.0426s\n",
            "68\n",
            "Epoch: 1141 loss_train: 0.7291 acc_train: 0.8333 loss_val: 0.8649 acc_val: 0.7460 time: 0.0424s\n",
            "69\n",
            "Epoch: 1142 loss_train: 0.6568 acc_train: 0.8417 loss_val: 0.8637 acc_val: 0.7420 time: 0.0424s\n",
            "70\n",
            "Epoch: 1143 loss_train: 0.6251 acc_train: 0.9167 loss_val: 0.8633 acc_val: 0.7380 time: 0.0444s\n",
            "71\n",
            "Epoch: 1144 loss_train: 0.7368 acc_train: 0.8417 loss_val: 0.8677 acc_val: 0.7380 time: 0.0424s\n",
            "72\n",
            "Epoch: 1145 loss_train: 0.7033 acc_train: 0.8250 loss_val: 0.8729 acc_val: 0.7420 time: 0.0421s\n",
            "73\n",
            "Epoch: 1146 loss_train: 0.6789 acc_train: 0.8917 loss_val: 0.8802 acc_val: 0.7300 time: 0.0424s\n",
            "74\n",
            "Epoch: 1147 loss_train: 0.5942 acc_train: 0.8833 loss_val: 0.8825 acc_val: 0.7280 time: 0.0434s\n",
            "75\n",
            "Epoch: 1148 loss_train: 0.6814 acc_train: 0.8667 loss_val: 0.8741 acc_val: 0.7300 time: 0.0435s\n",
            "76\n",
            "Epoch: 1149 loss_train: 0.7528 acc_train: 0.8333 loss_val: 0.8625 acc_val: 0.7360 time: 0.0431s\n",
            "77\n",
            "Epoch: 1150 loss_train: 0.6588 acc_train: 0.8667 loss_val: 0.8531 acc_val: 0.7400 time: 0.0432s\n",
            "78\n",
            "Epoch: 1151 loss_train: 0.7530 acc_train: 0.8083 loss_val: 0.8478 acc_val: 0.7480 time: 0.0421s\n",
            "79\n",
            "Epoch: 1152 loss_train: 0.6875 acc_train: 0.8500 loss_val: 0.8483 acc_val: 0.7520 time: 0.0420s\n",
            "0\n",
            "Epoch: 1153 loss_train: 0.6981 acc_train: 0.8667 loss_val: 0.8526 acc_val: 0.7480 time: 0.0435s\n",
            "1\n",
            "Epoch: 1154 loss_train: 0.6867 acc_train: 0.8500 loss_val: 0.8596 acc_val: 0.7460 time: 0.0421s\n",
            "2\n",
            "Epoch: 1155 loss_train: 0.6554 acc_train: 0.8750 loss_val: 0.8662 acc_val: 0.7380 time: 0.0421s\n",
            "3\n",
            "Epoch: 1156 loss_train: 0.6437 acc_train: 0.9000 loss_val: 0.8723 acc_val: 0.7380 time: 0.0421s\n",
            "4\n",
            "Epoch: 1157 loss_train: 0.6788 acc_train: 0.8750 loss_val: 0.8811 acc_val: 0.7360 time: 0.0423s\n",
            "5\n",
            "Epoch: 1158 loss_train: 0.6482 acc_train: 0.8583 loss_val: 0.8911 acc_val: 0.7280 time: 0.0433s\n",
            "6\n",
            "Epoch: 1159 loss_train: 0.6013 acc_train: 0.8917 loss_val: 0.8935 acc_val: 0.7240 time: 0.0428s\n",
            "7\n",
            "Epoch: 1160 loss_train: 0.6525 acc_train: 0.8917 loss_val: 0.8914 acc_val: 0.7200 time: 0.0426s\n",
            "8\n",
            "Epoch: 1161 loss_train: 0.6470 acc_train: 0.8667 loss_val: 0.8799 acc_val: 0.7200 time: 0.0434s\n",
            "9\n",
            "Epoch: 1162 loss_train: 0.7330 acc_train: 0.8417 loss_val: 0.8693 acc_val: 0.7220 time: 0.0424s\n",
            "10\n",
            "Epoch: 1163 loss_train: 0.6791 acc_train: 0.8833 loss_val: 0.8570 acc_val: 0.7280 time: 0.0430s\n",
            "11\n",
            "Epoch: 1164 loss_train: 0.7780 acc_train: 0.7917 loss_val: 0.8504 acc_val: 0.7420 time: 0.0430s\n",
            "12\n",
            "Epoch: 1165 loss_train: 0.7028 acc_train: 0.8667 loss_val: 0.8496 acc_val: 0.7420 time: 0.0427s\n",
            "13\n",
            "Epoch: 1166 loss_train: 0.6996 acc_train: 0.8333 loss_val: 0.8531 acc_val: 0.7480 time: 0.0424s\n",
            "14\n",
            "Epoch: 1167 loss_train: 0.6148 acc_train: 0.9167 loss_val: 0.8572 acc_val: 0.7460 time: 0.0422s\n",
            "15\n",
            "Epoch: 1168 loss_train: 0.7818 acc_train: 0.7750 loss_val: 0.8606 acc_val: 0.7360 time: 0.0444s\n",
            "16\n",
            "Epoch: 1169 loss_train: 0.6953 acc_train: 0.8583 loss_val: 0.8660 acc_val: 0.7360 time: 0.0426s\n",
            "17\n",
            "Epoch: 1170 loss_train: 0.6640 acc_train: 0.8250 loss_val: 0.8708 acc_val: 0.7300 time: 0.0422s\n",
            "18\n",
            "Epoch: 1171 loss_train: 0.6183 acc_train: 0.9083 loss_val: 0.8762 acc_val: 0.7280 time: 0.0430s\n",
            "19\n",
            "Epoch: 1172 loss_train: 0.6902 acc_train: 0.8500 loss_val: 0.8845 acc_val: 0.7280 time: 0.0420s\n",
            "20\n",
            "Epoch: 1173 loss_train: 0.6365 acc_train: 0.8583 loss_val: 0.8902 acc_val: 0.7200 time: 0.0451s\n",
            "21\n",
            "Epoch: 1174 loss_train: 0.7495 acc_train: 0.8083 loss_val: 0.8889 acc_val: 0.7220 time: 0.0427s\n",
            "22\n",
            "Epoch: 1175 loss_train: 0.6646 acc_train: 0.8500 loss_val: 0.8829 acc_val: 0.7260 time: 0.0425s\n",
            "23\n",
            "Epoch: 1176 loss_train: 0.6585 acc_train: 0.8500 loss_val: 0.8719 acc_val: 0.7300 time: 0.0421s\n",
            "24\n",
            "Epoch: 1177 loss_train: 0.6873 acc_train: 0.8417 loss_val: 0.8606 acc_val: 0.7380 time: 0.0424s\n",
            "25\n",
            "Epoch: 1178 loss_train: 0.7583 acc_train: 0.7917 loss_val: 0.8565 acc_val: 0.7340 time: 0.0441s\n",
            "26\n",
            "Epoch: 1179 loss_train: 0.6716 acc_train: 0.8833 loss_val: 0.8572 acc_val: 0.7400 time: 0.0421s\n",
            "27\n",
            "Epoch: 1180 loss_train: 0.7602 acc_train: 0.8333 loss_val: 0.8603 acc_val: 0.7400 time: 0.0423s\n",
            "28\n",
            "Epoch: 1181 loss_train: 0.6930 acc_train: 0.8250 loss_val: 0.8645 acc_val: 0.7380 time: 0.0424s\n",
            "29\n",
            "Epoch: 1182 loss_train: 0.6793 acc_train: 0.8583 loss_val: 0.8682 acc_val: 0.7400 time: 0.0422s\n",
            "30\n",
            "Epoch: 1183 loss_train: 0.6542 acc_train: 0.8583 loss_val: 0.8749 acc_val: 0.7380 time: 0.0444s\n",
            "31\n",
            "Epoch: 1184 loss_train: 0.6829 acc_train: 0.8750 loss_val: 0.8820 acc_val: 0.7340 time: 0.0434s\n",
            "32\n",
            "Epoch: 1185 loss_train: 0.6622 acc_train: 0.8000 loss_val: 0.8891 acc_val: 0.7280 time: 0.0436s\n",
            "33\n",
            "Epoch: 1186 loss_train: 0.7207 acc_train: 0.8500 loss_val: 0.8895 acc_val: 0.7240 time: 0.0425s\n",
            "34\n",
            "Epoch: 1187 loss_train: 0.6633 acc_train: 0.8750 loss_val: 0.8843 acc_val: 0.7260 time: 0.0423s\n",
            "35\n",
            "Epoch: 1188 loss_train: 0.6753 acc_train: 0.8583 loss_val: 0.8828 acc_val: 0.7280 time: 0.0438s\n",
            "36\n",
            "Epoch: 1189 loss_train: 0.7397 acc_train: 0.7917 loss_val: 0.8783 acc_val: 0.7280 time: 0.0423s\n",
            "37\n",
            "Epoch: 1190 loss_train: 0.6433 acc_train: 0.8083 loss_val: 0.8691 acc_val: 0.7280 time: 0.0423s\n",
            "38\n",
            "Epoch: 1191 loss_train: 0.7139 acc_train: 0.8167 loss_val: 0.8621 acc_val: 0.7320 time: 0.0428s\n",
            "39\n",
            "Epoch: 1192 loss_train: 0.7088 acc_train: 0.8500 loss_val: 0.8561 acc_val: 0.7400 time: 0.0432s\n",
            "40\n",
            "Epoch: 1193 loss_train: 0.6509 acc_train: 0.8917 loss_val: 0.8497 acc_val: 0.7400 time: 0.0449s\n",
            "41\n",
            "Epoch: 1194 loss_train: 0.6636 acc_train: 0.8833 loss_val: 0.8460 acc_val: 0.7480 time: 0.0426s\n",
            "42\n",
            "Epoch: 1195 loss_train: 0.7289 acc_train: 0.8000 loss_val: 0.8459 acc_val: 0.7520 time: 0.0452s\n",
            "0\n",
            "Epoch: 1196 loss_train: 0.7430 acc_train: 0.8167 loss_val: 0.8487 acc_val: 0.7540 time: 0.0422s\n",
            "0\n",
            "Epoch: 1197 loss_train: 0.7278 acc_train: 0.7917 loss_val: 0.8554 acc_val: 0.7460 time: 0.0425s\n",
            "0\n",
            "Epoch: 1198 loss_train: 0.6236 acc_train: 0.8917 loss_val: 0.8646 acc_val: 0.7440 time: 0.0427s\n",
            "1\n",
            "Epoch: 1199 loss_train: 0.5777 acc_train: 0.8667 loss_val: 0.8752 acc_val: 0.7380 time: 0.0421s\n",
            "2\n",
            "Epoch: 1200 loss_train: 0.5861 acc_train: 0.8833 loss_val: 0.8829 acc_val: 0.7320 time: 0.0425s\n",
            "3\n",
            "Epoch: 1201 loss_train: 0.6604 acc_train: 0.8583 loss_val: 0.8872 acc_val: 0.7320 time: 0.0421s\n",
            "4\n",
            "Epoch: 1202 loss_train: 0.7039 acc_train: 0.8500 loss_val: 0.8886 acc_val: 0.7300 time: 0.0421s\n",
            "5\n",
            "Epoch: 1203 loss_train: 0.7175 acc_train: 0.8083 loss_val: 0.8860 acc_val: 0.7220 time: 0.0439s\n",
            "6\n",
            "Epoch: 1204 loss_train: 0.7364 acc_train: 0.8083 loss_val: 0.8761 acc_val: 0.7300 time: 0.0424s\n",
            "7\n",
            "Epoch: 1205 loss_train: 0.6526 acc_train: 0.8500 loss_val: 0.8631 acc_val: 0.7300 time: 0.0423s\n",
            "8\n",
            "Epoch: 1206 loss_train: 0.6413 acc_train: 0.8417 loss_val: 0.8525 acc_val: 0.7460 time: 0.0422s\n",
            "9\n",
            "Epoch: 1207 loss_train: 0.6414 acc_train: 0.8583 loss_val: 0.8482 acc_val: 0.7460 time: 0.0424s\n",
            "10\n",
            "Epoch: 1208 loss_train: 0.6691 acc_train: 0.8333 loss_val: 0.8487 acc_val: 0.7480 time: 0.0444s\n",
            "11\n",
            "Epoch: 1209 loss_train: 0.7468 acc_train: 0.8000 loss_val: 0.8495 acc_val: 0.7460 time: 0.0421s\n",
            "12\n",
            "Epoch: 1210 loss_train: 0.6631 acc_train: 0.8667 loss_val: 0.8517 acc_val: 0.7440 time: 0.0423s\n",
            "13\n",
            "Epoch: 1211 loss_train: 0.6908 acc_train: 0.8500 loss_val: 0.8565 acc_val: 0.7360 time: 0.0422s\n",
            "14\n",
            "Epoch: 1212 loss_train: 0.6039 acc_train: 0.9167 loss_val: 0.8622 acc_val: 0.7320 time: 0.0422s\n",
            "15\n",
            "Epoch: 1213 loss_train: 0.6848 acc_train: 0.8917 loss_val: 0.8686 acc_val: 0.7300 time: 0.0456s\n",
            "16\n",
            "Epoch: 1214 loss_train: 0.6781 acc_train: 0.8333 loss_val: 0.8733 acc_val: 0.7300 time: 0.0432s\n",
            "17\n",
            "Epoch: 1215 loss_train: 0.7288 acc_train: 0.8500 loss_val: 0.8736 acc_val: 0.7360 time: 0.0437s\n",
            "18\n",
            "Epoch: 1216 loss_train: 0.6684 acc_train: 0.8833 loss_val: 0.8713 acc_val: 0.7380 time: 0.0425s\n",
            "19\n",
            "Epoch: 1217 loss_train: 0.7283 acc_train: 0.8417 loss_val: 0.8720 acc_val: 0.7360 time: 0.0421s\n",
            "20\n",
            "Epoch: 1218 loss_train: 0.6546 acc_train: 0.8583 loss_val: 0.8704 acc_val: 0.7360 time: 0.0463s\n",
            "21\n",
            "Epoch: 1219 loss_train: 0.7231 acc_train: 0.8583 loss_val: 0.8694 acc_val: 0.7380 time: 0.0428s\n",
            "22\n",
            "Epoch: 1220 loss_train: 0.7456 acc_train: 0.8333 loss_val: 0.8679 acc_val: 0.7380 time: 0.0422s\n",
            "23\n",
            "Epoch: 1221 loss_train: 0.7096 acc_train: 0.8583 loss_val: 0.8677 acc_val: 0.7380 time: 0.0423s\n",
            "24\n",
            "Epoch: 1222 loss_train: 0.7398 acc_train: 0.7833 loss_val: 0.8670 acc_val: 0.7380 time: 0.0422s\n",
            "25\n",
            "Epoch: 1223 loss_train: 0.7343 acc_train: 0.7917 loss_val: 0.8697 acc_val: 0.7360 time: 0.0438s\n",
            "26\n",
            "Epoch: 1224 loss_train: 0.7140 acc_train: 0.8417 loss_val: 0.8731 acc_val: 0.7340 time: 0.0422s\n",
            "27\n",
            "Epoch: 1225 loss_train: 0.7214 acc_train: 0.8500 loss_val: 0.8730 acc_val: 0.7340 time: 0.0421s\n",
            "28\n",
            "Epoch: 1226 loss_train: 0.6124 acc_train: 0.8750 loss_val: 0.8735 acc_val: 0.7340 time: 0.0423s\n",
            "29\n",
            "Epoch: 1227 loss_train: 0.6904 acc_train: 0.8500 loss_val: 0.8740 acc_val: 0.7320 time: 0.0423s\n",
            "30\n",
            "Epoch: 1228 loss_train: 0.7190 acc_train: 0.8667 loss_val: 0.8690 acc_val: 0.7380 time: 0.0430s\n",
            "31\n",
            "Epoch: 1229 loss_train: 0.7386 acc_train: 0.8083 loss_val: 0.8654 acc_val: 0.7400 time: 0.0422s\n",
            "32\n",
            "Epoch: 1230 loss_train: 0.7235 acc_train: 0.8250 loss_val: 0.8637 acc_val: 0.7400 time: 0.0420s\n",
            "33\n",
            "Epoch: 1231 loss_train: 0.6215 acc_train: 0.8917 loss_val: 0.8605 acc_val: 0.7420 time: 0.0429s\n",
            "34\n",
            "Epoch: 1232 loss_train: 0.6861 acc_train: 0.8583 loss_val: 0.8616 acc_val: 0.7440 time: 0.0429s\n",
            "35\n",
            "Epoch: 1233 loss_train: 0.7236 acc_train: 0.8167 loss_val: 0.8638 acc_val: 0.7400 time: 0.0474s\n",
            "36\n",
            "Epoch: 1234 loss_train: 0.7027 acc_train: 0.8250 loss_val: 0.8696 acc_val: 0.7440 time: 0.0428s\n",
            "37\n",
            "Epoch: 1235 loss_train: 0.6833 acc_train: 0.8333 loss_val: 0.8782 acc_val: 0.7400 time: 0.0440s\n",
            "38\n",
            "Epoch: 1236 loss_train: 0.7135 acc_train: 0.8333 loss_val: 0.8830 acc_val: 0.7360 time: 0.0424s\n",
            "39\n",
            "Epoch: 1237 loss_train: 0.7014 acc_train: 0.8500 loss_val: 0.8813 acc_val: 0.7340 time: 0.0426s\n",
            "40\n",
            "Epoch: 1238 loss_train: 0.7149 acc_train: 0.8167 loss_val: 0.8803 acc_val: 0.7320 time: 0.0429s\n",
            "41\n",
            "Epoch: 1239 loss_train: 0.6594 acc_train: 0.8583 loss_val: 0.8758 acc_val: 0.7320 time: 0.0422s\n",
            "42\n",
            "Epoch: 1240 loss_train: 0.7079 acc_train: 0.8667 loss_val: 0.8716 acc_val: 0.7340 time: 0.0425s\n",
            "43\n",
            "Epoch: 1241 loss_train: 0.5901 acc_train: 0.8917 loss_val: 0.8662 acc_val: 0.7400 time: 0.0430s\n",
            "44\n",
            "Epoch: 1242 loss_train: 0.8033 acc_train: 0.8417 loss_val: 0.8612 acc_val: 0.7380 time: 0.0422s\n",
            "45\n",
            "Epoch: 1243 loss_train: 0.6847 acc_train: 0.8583 loss_val: 0.8592 acc_val: 0.7380 time: 0.0429s\n",
            "46\n",
            "Epoch: 1244 loss_train: 0.6876 acc_train: 0.8500 loss_val: 0.8596 acc_val: 0.7440 time: 0.0422s\n",
            "47\n",
            "Epoch: 1245 loss_train: 0.7363 acc_train: 0.8250 loss_val: 0.8613 acc_val: 0.7440 time: 0.0426s\n",
            "48\n",
            "Epoch: 1246 loss_train: 0.5750 acc_train: 0.9250 loss_val: 0.8622 acc_val: 0.7440 time: 0.0435s\n",
            "49\n",
            "Epoch: 1247 loss_train: 0.7869 acc_train: 0.8083 loss_val: 0.8630 acc_val: 0.7460 time: 0.0422s\n",
            "50\n",
            "Epoch: 1248 loss_train: 0.6595 acc_train: 0.8833 loss_val: 0.8651 acc_val: 0.7420 time: 0.0446s\n",
            "51\n",
            "Epoch: 1249 loss_train: 0.6595 acc_train: 0.8583 loss_val: 0.8663 acc_val: 0.7440 time: 0.0427s\n",
            "52\n",
            "Epoch: 1250 loss_train: 0.7454 acc_train: 0.8500 loss_val: 0.8692 acc_val: 0.7440 time: 0.0424s\n",
            "53\n",
            "Epoch: 1251 loss_train: 0.7293 acc_train: 0.8250 loss_val: 0.8756 acc_val: 0.7380 time: 0.0422s\n",
            "54\n",
            "Epoch: 1252 loss_train: 0.7079 acc_train: 0.8417 loss_val: 0.8801 acc_val: 0.7400 time: 0.0433s\n",
            "55\n",
            "Epoch: 1253 loss_train: 0.6984 acc_train: 0.8167 loss_val: 0.8805 acc_val: 0.7400 time: 0.0434s\n",
            "56\n",
            "Epoch: 1254 loss_train: 0.7406 acc_train: 0.8333 loss_val: 0.8792 acc_val: 0.7340 time: 0.0423s\n",
            "57\n",
            "Epoch: 1255 loss_train: 0.7270 acc_train: 0.8250 loss_val: 0.8793 acc_val: 0.7340 time: 0.0422s\n",
            "58\n",
            "Epoch: 1256 loss_train: 0.7810 acc_train: 0.8000 loss_val: 0.8746 acc_val: 0.7360 time: 0.0422s\n",
            "59\n",
            "Epoch: 1257 loss_train: 0.6675 acc_train: 0.8583 loss_val: 0.8695 acc_val: 0.7380 time: 0.0426s\n",
            "60\n",
            "Epoch: 1258 loss_train: 0.6706 acc_train: 0.8750 loss_val: 0.8632 acc_val: 0.7440 time: 0.0453s\n",
            "61\n",
            "Epoch: 1259 loss_train: 0.6211 acc_train: 0.9000 loss_val: 0.8593 acc_val: 0.7420 time: 0.0445s\n",
            "62\n",
            "Epoch: 1260 loss_train: 0.6568 acc_train: 0.8500 loss_val: 0.8562 acc_val: 0.7420 time: 0.0423s\n",
            "63\n",
            "Epoch: 1261 loss_train: 0.6801 acc_train: 0.8667 loss_val: 0.8546 acc_val: 0.7420 time: 0.0416s\n",
            "64\n",
            "Epoch: 1262 loss_train: 0.7525 acc_train: 0.8333 loss_val: 0.8549 acc_val: 0.7420 time: 0.0422s\n",
            "65\n",
            "Epoch: 1263 loss_train: 0.6939 acc_train: 0.8667 loss_val: 0.8553 acc_val: 0.7400 time: 0.0435s\n",
            "66\n",
            "Epoch: 1264 loss_train: 0.6515 acc_train: 0.8250 loss_val: 0.8588 acc_val: 0.7380 time: 0.0431s\n",
            "67\n",
            "Epoch: 1265 loss_train: 0.6890 acc_train: 0.8333 loss_val: 0.8662 acc_val: 0.7320 time: 0.0429s\n",
            "68\n",
            "Epoch: 1266 loss_train: 0.6292 acc_train: 0.9167 loss_val: 0.8719 acc_val: 0.7340 time: 0.0428s\n",
            "69\n",
            "Epoch: 1267 loss_train: 0.6601 acc_train: 0.8583 loss_val: 0.8710 acc_val: 0.7360 time: 0.0421s\n",
            "70\n",
            "Epoch: 1268 loss_train: 0.7019 acc_train: 0.8417 loss_val: 0.8680 acc_val: 0.7440 time: 0.0429s\n",
            "71\n",
            "Epoch: 1269 loss_train: 0.7018 acc_train: 0.8167 loss_val: 0.8638 acc_val: 0.7360 time: 0.0421s\n",
            "72\n",
            "Epoch: 1270 loss_train: 0.6627 acc_train: 0.8583 loss_val: 0.8607 acc_val: 0.7400 time: 0.0422s\n",
            "73\n",
            "Epoch: 1271 loss_train: 0.7071 acc_train: 0.8417 loss_val: 0.8592 acc_val: 0.7440 time: 0.0422s\n",
            "74\n",
            "Epoch: 1272 loss_train: 0.6334 acc_train: 0.8833 loss_val: 0.8583 acc_val: 0.7460 time: 0.0433s\n",
            "75\n",
            "Epoch: 1273 loss_train: 0.6449 acc_train: 0.8417 loss_val: 0.8590 acc_val: 0.7520 time: 0.0445s\n",
            "76\n",
            "Epoch: 1274 loss_train: 0.7271 acc_train: 0.8583 loss_val: 0.8616 acc_val: 0.7460 time: 0.0423s\n",
            "77\n",
            "Epoch: 1275 loss_train: 0.6836 acc_train: 0.8750 loss_val: 0.8632 acc_val: 0.7420 time: 0.0422s\n",
            "78\n",
            "Epoch: 1276 loss_train: 0.6639 acc_train: 0.8667 loss_val: 0.8641 acc_val: 0.7400 time: 0.0432s\n",
            "79\n",
            "Epoch: 1277 loss_train: 0.7645 acc_train: 0.8167 loss_val: 0.8628 acc_val: 0.7400 time: 0.0429s\n",
            "80\n",
            "Epoch: 1278 loss_train: 0.7353 acc_train: 0.8500 loss_val: 0.8648 acc_val: 0.7380 time: 0.0433s\n",
            "81\n",
            "Epoch: 1279 loss_train: 0.6539 acc_train: 0.8250 loss_val: 0.8665 acc_val: 0.7340 time: 0.0424s\n",
            "82\n",
            "Epoch: 1280 loss_train: 0.7151 acc_train: 0.8333 loss_val: 0.8679 acc_val: 0.7320 time: 0.0433s\n",
            "83\n",
            "Epoch: 1281 loss_train: 0.7314 acc_train: 0.8250 loss_val: 0.8668 acc_val: 0.7320 time: 0.0423s\n",
            "84\n",
            "Epoch: 1282 loss_train: 0.6735 acc_train: 0.8583 loss_val: 0.8643 acc_val: 0.7360 time: 0.0425s\n",
            "85\n",
            "Epoch: 1283 loss_train: 0.6566 acc_train: 0.8917 loss_val: 0.8625 acc_val: 0.7360 time: 0.0439s\n",
            "86\n",
            "Epoch: 1284 loss_train: 0.7396 acc_train: 0.8500 loss_val: 0.8629 acc_val: 0.7360 time: 0.0435s\n",
            "87\n",
            "Epoch: 1285 loss_train: 0.6935 acc_train: 0.8750 loss_val: 0.8654 acc_val: 0.7340 time: 0.0427s\n",
            "88\n",
            "Epoch: 1286 loss_train: 0.6715 acc_train: 0.8750 loss_val: 0.8665 acc_val: 0.7400 time: 0.0420s\n",
            "89\n",
            "Epoch: 1287 loss_train: 0.7265 acc_train: 0.8667 loss_val: 0.8698 acc_val: 0.7360 time: 0.0423s\n",
            "90\n",
            "Epoch: 1288 loss_train: 0.8111 acc_train: 0.7833 loss_val: 0.8759 acc_val: 0.7360 time: 0.0452s\n",
            "91\n",
            "Epoch: 1289 loss_train: 0.7169 acc_train: 0.8250 loss_val: 0.8791 acc_val: 0.7340 time: 0.0421s\n",
            "92\n",
            "Epoch: 1290 loss_train: 0.6686 acc_train: 0.8667 loss_val: 0.8765 acc_val: 0.7360 time: 0.0421s\n",
            "93\n",
            "Epoch: 1291 loss_train: 0.7006 acc_train: 0.8083 loss_val: 0.8728 acc_val: 0.7360 time: 0.0419s\n",
            "94\n",
            "Epoch: 1292 loss_train: 0.7729 acc_train: 0.8250 loss_val: 0.8693 acc_val: 0.7380 time: 0.0421s\n",
            "95\n",
            "Epoch: 1293 loss_train: 0.6692 acc_train: 0.8417 loss_val: 0.8623 acc_val: 0.7440 time: 0.0447s\n",
            "96\n",
            "Epoch: 1294 loss_train: 0.6903 acc_train: 0.8667 loss_val: 0.8558 acc_val: 0.7440 time: 0.0426s\n",
            "97\n",
            "Epoch: 1295 loss_train: 0.6133 acc_train: 0.9000 loss_val: 0.8526 acc_val: 0.7420 time: 0.0425s\n",
            "98\n",
            "Epoch: 1296 loss_train: 0.7229 acc_train: 0.8667 loss_val: 0.8514 acc_val: 0.7440 time: 0.0432s\n",
            "99\n",
            "Epoch: 1297 loss_train: 0.6545 acc_train: 0.8500 loss_val: 0.8520 acc_val: 0.7440 time: 0.0421s\n",
            "100\n",
            "Epoch: 1298 loss_train: 0.7578 acc_train: 0.8250 loss_val: 0.8538 acc_val: 0.7400 time: 0.0445s\n",
            "101\n",
            "Epoch: 1299 loss_train: 0.6866 acc_train: 0.8500 loss_val: 0.8580 acc_val: 0.7400 time: 0.0429s\n",
            "102\n",
            "Epoch: 1300 loss_train: 0.7284 acc_train: 0.8333 loss_val: 0.8669 acc_val: 0.7300 time: 0.0427s\n",
            "103\n",
            "Epoch: 1301 loss_train: 0.6490 acc_train: 0.8583 loss_val: 0.8758 acc_val: 0.7360 time: 0.0425s\n",
            "104\n",
            "Epoch: 1302 loss_train: 0.7588 acc_train: 0.8250 loss_val: 0.8810 acc_val: 0.7400 time: 0.0422s\n",
            "105\n",
            "Epoch: 1303 loss_train: 0.6363 acc_train: 0.8750 loss_val: 0.8849 acc_val: 0.7380 time: 0.0437s\n",
            "106\n",
            "Epoch: 1304 loss_train: 0.6878 acc_train: 0.8333 loss_val: 0.8846 acc_val: 0.7400 time: 0.0433s\n",
            "107\n",
            "Epoch: 1305 loss_train: 0.7179 acc_train: 0.8583 loss_val: 0.8771 acc_val: 0.7400 time: 0.0421s\n",
            "108\n",
            "Epoch: 1306 loss_train: 0.7380 acc_train: 0.8417 loss_val: 0.8663 acc_val: 0.7420 time: 0.0422s\n",
            "109\n",
            "Epoch: 1307 loss_train: 0.7151 acc_train: 0.8500 loss_val: 0.8581 acc_val: 0.7460 time: 0.0437s\n",
            "110\n",
            "Epoch: 1308 loss_train: 0.8410 acc_train: 0.7750 loss_val: 0.8528 acc_val: 0.7480 time: 0.0445s\n",
            "111\n",
            "Epoch: 1309 loss_train: 0.7681 acc_train: 0.8083 loss_val: 0.8491 acc_val: 0.7480 time: 0.0422s\n",
            "112\n",
            "Epoch: 1310 loss_train: 0.7914 acc_train: 0.8250 loss_val: 0.8506 acc_val: 0.7440 time: 0.0422s\n",
            "113\n",
            "Epoch: 1311 loss_train: 0.6450 acc_train: 0.8833 loss_val: 0.8592 acc_val: 0.7320 time: 0.0423s\n",
            "114\n",
            "Epoch: 1312 loss_train: 0.7012 acc_train: 0.8333 loss_val: 0.8677 acc_val: 0.7320 time: 0.0429s\n",
            "115\n",
            "Epoch: 1313 loss_train: 0.7343 acc_train: 0.8083 loss_val: 0.8751 acc_val: 0.7260 time: 0.0430s\n",
            "116\n",
            "Epoch: 1314 loss_train: 0.7084 acc_train: 0.8500 loss_val: 0.8823 acc_val: 0.7280 time: 0.0422s\n",
            "117\n",
            "Epoch: 1315 loss_train: 0.6804 acc_train: 0.8667 loss_val: 0.8833 acc_val: 0.7200 time: 0.0423s\n",
            "118\n",
            "Epoch: 1316 loss_train: 0.6970 acc_train: 0.8000 loss_val: 0.8823 acc_val: 0.7300 time: 0.0424s\n",
            "119\n",
            "Epoch: 1317 loss_train: 0.7179 acc_train: 0.8333 loss_val: 0.8790 acc_val: 0.7320 time: 0.0421s\n",
            "120\n",
            "Epoch: 1318 loss_train: 0.7207 acc_train: 0.8167 loss_val: 0.8742 acc_val: 0.7320 time: 0.0434s\n",
            "121\n",
            "Epoch: 1319 loss_train: 0.7298 acc_train: 0.8333 loss_val: 0.8691 acc_val: 0.7420 time: 0.0426s\n",
            "122\n",
            "Epoch: 1320 loss_train: 0.7156 acc_train: 0.8417 loss_val: 0.8677 acc_val: 0.7400 time: 0.0431s\n",
            "123\n",
            "Epoch: 1321 loss_train: 0.7456 acc_train: 0.8500 loss_val: 0.8632 acc_val: 0.7420 time: 0.0451s\n",
            "124\n",
            "Epoch: 1322 loss_train: 0.6343 acc_train: 0.8667 loss_val: 0.8598 acc_val: 0.7400 time: 0.0428s\n",
            "125\n",
            "Epoch: 1323 loss_train: 0.6818 acc_train: 0.8833 loss_val: 0.8562 acc_val: 0.7420 time: 0.0447s\n",
            "126\n",
            "Epoch: 1324 loss_train: 0.5927 acc_train: 0.8750 loss_val: 0.8543 acc_val: 0.7440 time: 0.0422s\n",
            "127\n",
            "Epoch: 1325 loss_train: 0.6783 acc_train: 0.8667 loss_val: 0.8528 acc_val: 0.7420 time: 0.0422s\n",
            "128\n",
            "Epoch: 1326 loss_train: 0.6436 acc_train: 0.8667 loss_val: 0.8551 acc_val: 0.7360 time: 0.0429s\n",
            "129\n",
            "Epoch: 1327 loss_train: 0.7274 acc_train: 0.8417 loss_val: 0.8596 acc_val: 0.7360 time: 0.0429s\n",
            "130\n",
            "Epoch: 1328 loss_train: 0.6926 acc_train: 0.8583 loss_val: 0.8634 acc_val: 0.7380 time: 0.0451s\n",
            "131\n",
            "Epoch: 1329 loss_train: 0.6654 acc_train: 0.8583 loss_val: 0.8656 acc_val: 0.7380 time: 0.0423s\n",
            "132\n",
            "Epoch: 1330 loss_train: 0.7471 acc_train: 0.8500 loss_val: 0.8715 acc_val: 0.7400 time: 0.0424s\n",
            "133\n",
            "Epoch: 1331 loss_train: 0.7274 acc_train: 0.8333 loss_val: 0.8779 acc_val: 0.7420 time: 0.0427s\n",
            "134\n",
            "Epoch: 1332 loss_train: 0.6887 acc_train: 0.8583 loss_val: 0.8788 acc_val: 0.7420 time: 0.0424s\n",
            "135\n",
            "Epoch: 1333 loss_train: 0.7712 acc_train: 0.8083 loss_val: 0.8767 acc_val: 0.7380 time: 0.0436s\n",
            "136\n",
            "Epoch: 1334 loss_train: 0.6742 acc_train: 0.8500 loss_val: 0.8767 acc_val: 0.7380 time: 0.0433s\n",
            "137\n",
            "Epoch: 1335 loss_train: 0.7109 acc_train: 0.8583 loss_val: 0.8752 acc_val: 0.7380 time: 0.0435s\n",
            "138\n",
            "Epoch: 1336 loss_train: 0.7266 acc_train: 0.7833 loss_val: 0.8746 acc_val: 0.7400 time: 0.0426s\n",
            "139\n",
            "Epoch: 1337 loss_train: 0.6558 acc_train: 0.8583 loss_val: 0.8738 acc_val: 0.7400 time: 0.0424s\n",
            "140\n",
            "Epoch: 1338 loss_train: 0.7108 acc_train: 0.8417 loss_val: 0.8716 acc_val: 0.7420 time: 0.0448s\n",
            "141\n",
            "Epoch: 1339 loss_train: 0.6156 acc_train: 0.8667 loss_val: 0.8670 acc_val: 0.7420 time: 0.0422s\n",
            "142\n",
            "Epoch: 1340 loss_train: 0.7421 acc_train: 0.8083 loss_val: 0.8598 acc_val: 0.7420 time: 0.0422s\n",
            "143\n",
            "Epoch: 1341 loss_train: 0.6518 acc_train: 0.8750 loss_val: 0.8563 acc_val: 0.7400 time: 0.0423s\n",
            "144\n",
            "Epoch: 1342 loss_train: 0.7437 acc_train: 0.8167 loss_val: 0.8561 acc_val: 0.7460 time: 0.0423s\n",
            "145\n",
            "Epoch: 1343 loss_train: 0.6791 acc_train: 0.8917 loss_val: 0.8592 acc_val: 0.7460 time: 0.0446s\n",
            "146\n",
            "Epoch: 1344 loss_train: 0.6065 acc_train: 0.8833 loss_val: 0.8611 acc_val: 0.7460 time: 0.0437s\n",
            "147\n",
            "Epoch: 1345 loss_train: 0.6935 acc_train: 0.8417 loss_val: 0.8644 acc_val: 0.7440 time: 0.0421s\n",
            "148\n",
            "Epoch: 1346 loss_train: 0.5041 acc_train: 0.9250 loss_val: 0.8670 acc_val: 0.7440 time: 0.0429s\n",
            "149\n",
            "Epoch: 1347 loss_train: 0.6728 acc_train: 0.8833 loss_val: 0.8675 acc_val: 0.7440 time: 0.0432s\n",
            "150\n",
            "Epoch: 1348 loss_train: 0.6874 acc_train: 0.8333 loss_val: 0.8690 acc_val: 0.7420 time: 0.0441s\n",
            "151\n",
            "Epoch: 1349 loss_train: 0.6378 acc_train: 0.8500 loss_val: 0.8738 acc_val: 0.7380 time: 0.0435s\n",
            "152\n",
            "Epoch: 1350 loss_train: 0.7509 acc_train: 0.8333 loss_val: 0.8771 acc_val: 0.7340 time: 0.0437s\n",
            "153\n",
            "Epoch: 1351 loss_train: 0.5775 acc_train: 0.9083 loss_val: 0.8792 acc_val: 0.7280 time: 0.0429s\n",
            "154\n",
            "Epoch: 1352 loss_train: 0.6951 acc_train: 0.8583 loss_val: 0.8756 acc_val: 0.7340 time: 0.0424s\n",
            "155\n",
            "Epoch: 1353 loss_train: 0.7182 acc_train: 0.8750 loss_val: 0.8752 acc_val: 0.7320 time: 0.0456s\n",
            "156\n",
            "Epoch: 1354 loss_train: 0.6434 acc_train: 0.8583 loss_val: 0.8785 acc_val: 0.7320 time: 0.0422s\n",
            "157\n",
            "Epoch: 1355 loss_train: 0.7128 acc_train: 0.8583 loss_val: 0.8798 acc_val: 0.7380 time: 0.0425s\n",
            "158\n",
            "Epoch: 1356 loss_train: 0.7054 acc_train: 0.8250 loss_val: 0.8811 acc_val: 0.7420 time: 0.0422s\n",
            "159\n",
            "Epoch: 1357 loss_train: 0.6711 acc_train: 0.8583 loss_val: 0.8801 acc_val: 0.7420 time: 0.0423s\n",
            "160\n",
            "Epoch: 1358 loss_train: 0.7818 acc_train: 0.7833 loss_val: 0.8721 acc_val: 0.7380 time: 0.0433s\n",
            "161\n",
            "Epoch: 1359 loss_train: 0.7081 acc_train: 0.8667 loss_val: 0.8662 acc_val: 0.7420 time: 0.0428s\n",
            "162\n",
            "Epoch: 1360 loss_train: 0.7308 acc_train: 0.8167 loss_val: 0.8616 acc_val: 0.7400 time: 0.0443s\n",
            "163\n",
            "Epoch: 1361 loss_train: 0.7687 acc_train: 0.8083 loss_val: 0.8627 acc_val: 0.7420 time: 0.0430s\n",
            "164\n",
            "Epoch: 1362 loss_train: 0.6302 acc_train: 0.8750 loss_val: 0.8675 acc_val: 0.7400 time: 0.0424s\n",
            "165\n",
            "Epoch: 1363 loss_train: 0.6660 acc_train: 0.8250 loss_val: 0.8728 acc_val: 0.7420 time: 0.0429s\n",
            "166\n",
            "Epoch: 1364 loss_train: 0.6837 acc_train: 0.8583 loss_val: 0.8775 acc_val: 0.7380 time: 0.0423s\n",
            "167\n",
            "Epoch: 1365 loss_train: 0.6663 acc_train: 0.8667 loss_val: 0.8779 acc_val: 0.7360 time: 0.0419s\n",
            "168\n",
            "Epoch: 1366 loss_train: 0.6460 acc_train: 0.8833 loss_val: 0.8745 acc_val: 0.7300 time: 0.0422s\n",
            "169\n",
            "Epoch: 1367 loss_train: 0.7019 acc_train: 0.8667 loss_val: 0.8698 acc_val: 0.7280 time: 0.0423s\n",
            "170\n",
            "Epoch: 1368 loss_train: 0.6715 acc_train: 0.8583 loss_val: 0.8654 acc_val: 0.7320 time: 0.0447s\n",
            "171\n",
            "Epoch: 1369 loss_train: 0.6710 acc_train: 0.8500 loss_val: 0.8615 acc_val: 0.7380 time: 0.0429s\n",
            "172\n",
            "Epoch: 1370 loss_train: 0.7339 acc_train: 0.8250 loss_val: 0.8589 acc_val: 0.7380 time: 0.0428s\n",
            "173\n",
            "Epoch: 1371 loss_train: 0.6985 acc_train: 0.8917 loss_val: 0.8598 acc_val: 0.7400 time: 0.0442s\n",
            "174\n",
            "Epoch: 1372 loss_train: 0.6370 acc_train: 0.8750 loss_val: 0.8628 acc_val: 0.7420 time: 0.0429s\n",
            "175\n",
            "Epoch: 1373 loss_train: 0.7308 acc_train: 0.7833 loss_val: 0.8677 acc_val: 0.7400 time: 0.0435s\n",
            "176\n",
            "Epoch: 1374 loss_train: 0.6000 acc_train: 0.8833 loss_val: 0.8729 acc_val: 0.7420 time: 0.0426s\n",
            "177\n",
            "Epoch: 1375 loss_train: 0.6574 acc_train: 0.8750 loss_val: 0.8734 acc_val: 0.7400 time: 0.0425s\n",
            "178\n",
            "Epoch: 1376 loss_train: 0.6085 acc_train: 0.8667 loss_val: 0.8725 acc_val: 0.7320 time: 0.0421s\n",
            "179\n",
            "Epoch: 1377 loss_train: 0.7739 acc_train: 0.8167 loss_val: 0.8719 acc_val: 0.7360 time: 0.0422s\n",
            "180\n",
            "Epoch: 1378 loss_train: 0.7160 acc_train: 0.8000 loss_val: 0.8692 acc_val: 0.7380 time: 0.0431s\n",
            "181\n",
            "Epoch: 1379 loss_train: 0.7608 acc_train: 0.8000 loss_val: 0.8660 acc_val: 0.7420 time: 0.0420s\n",
            "182\n",
            "Epoch: 1380 loss_train: 0.7038 acc_train: 0.8667 loss_val: 0.8629 acc_val: 0.7400 time: 0.0422s\n",
            "183\n",
            "Epoch: 1381 loss_train: 0.7538 acc_train: 0.8167 loss_val: 0.8624 acc_val: 0.7340 time: 0.0423s\n",
            "184\n",
            "Epoch: 1382 loss_train: 0.7397 acc_train: 0.8167 loss_val: 0.8637 acc_val: 0.7380 time: 0.0425s\n",
            "185\n",
            "Epoch: 1383 loss_train: 0.7378 acc_train: 0.8333 loss_val: 0.8674 acc_val: 0.7380 time: 0.0465s\n",
            "186\n",
            "Epoch: 1384 loss_train: 0.6487 acc_train: 0.8583 loss_val: 0.8696 acc_val: 0.7340 time: 0.0421s\n",
            "187\n",
            "Epoch: 1385 loss_train: 0.7186 acc_train: 0.8250 loss_val: 0.8661 acc_val: 0.7380 time: 0.0425s\n",
            "188\n",
            "Epoch: 1386 loss_train: 0.7122 acc_train: 0.8250 loss_val: 0.8613 acc_val: 0.7380 time: 0.0423s\n",
            "189\n",
            "Epoch: 1387 loss_train: 0.7471 acc_train: 0.7917 loss_val: 0.8581 acc_val: 0.7380 time: 0.0439s\n",
            "190\n",
            "Epoch: 1388 loss_train: 0.7803 acc_train: 0.8167 loss_val: 0.8558 acc_val: 0.7400 time: 0.0433s\n",
            "191\n",
            "Epoch: 1389 loss_train: 0.6405 acc_train: 0.8583 loss_val: 0.8573 acc_val: 0.7460 time: 0.0422s\n",
            "192\n",
            "Epoch: 1390 loss_train: 0.6971 acc_train: 0.8583 loss_val: 0.8610 acc_val: 0.7480 time: 0.0424s\n",
            "193\n",
            "Epoch: 1391 loss_train: 0.6599 acc_train: 0.8500 loss_val: 0.8663 acc_val: 0.7420 time: 0.0422s\n",
            "194\n",
            "Epoch: 1392 loss_train: 0.6548 acc_train: 0.8667 loss_val: 0.8716 acc_val: 0.7360 time: 0.0423s\n",
            "195\n",
            "Epoch: 1393 loss_train: 0.6585 acc_train: 0.8583 loss_val: 0.8806 acc_val: 0.7340 time: 0.0465s\n",
            "196\n",
            "Epoch: 1394 loss_train: 0.5832 acc_train: 0.9000 loss_val: 0.8857 acc_val: 0.7320 time: 0.0447s\n",
            "197\n",
            "Epoch: 1395 loss_train: 0.6930 acc_train: 0.8333 loss_val: 0.8866 acc_val: 0.7360 time: 0.0435s\n",
            "198\n",
            "Epoch: 1396 loss_train: 0.6665 acc_train: 0.8333 loss_val: 0.8825 acc_val: 0.7380 time: 0.0422s\n",
            "199\n",
            "Early stop! Min loss:  0.8459194898605347 , Max accuracy:  0.754\n",
            "Early stop model validation loss:  0.8459194898605347 , accuracy:  0.752\n",
            "Optimization Finished!\n",
            "Total time elapsed: 63.5133s\n",
            "Loading 1194th epoch\n",
            "Test set results: loss= 0.8240 accuracy= 0.7440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7440, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv96U6qslXCK",
        "outputId": "c8fa82d3-85aa-46e1-f402-a370d67f2a7d"
      },
      "source": [
        "args['tem'] = 1\n",
        "Train() #cora\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.0481 acc_train: 0.1286 loss_val: 2.0268 acc_val: 0.1140 time: 0.0504s\n",
            "0\n",
            "Epoch: 0002 loss_train: 2.0404 acc_train: 0.1429 loss_val: 2.0219 acc_val: 0.1140 time: 0.0465s\n",
            "0\n",
            "Epoch: 0003 loss_train: 2.0317 acc_train: 0.1500 loss_val: 2.0167 acc_val: 0.1140 time: 0.0449s\n",
            "0\n",
            "Epoch: 0004 loss_train: 2.0274 acc_train: 0.1571 loss_val: 2.0115 acc_val: 0.1140 time: 0.0461s\n",
            "0\n",
            "Epoch: 0005 loss_train: 2.0212 acc_train: 0.1500 loss_val: 2.0060 acc_val: 0.1140 time: 0.0443s\n",
            "0\n",
            "Epoch: 0006 loss_train: 2.0120 acc_train: 0.1286 loss_val: 2.0006 acc_val: 0.1140 time: 0.0445s\n",
            "0\n",
            "Epoch: 0007 loss_train: 2.0082 acc_train: 0.1357 loss_val: 1.9954 acc_val: 0.1140 time: 0.0453s\n",
            "0\n",
            "Epoch: 0008 loss_train: 2.0019 acc_train: 0.1429 loss_val: 1.9904 acc_val: 0.1140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.9954 acc_train: 0.1286 loss_val: 1.9854 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.9902 acc_train: 0.1429 loss_val: 1.9805 acc_val: 0.1140 time: 0.0458s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.9906 acc_train: 0.1643 loss_val: 1.9759 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0012 loss_train: 1.9825 acc_train: 0.1571 loss_val: 1.9714 acc_val: 0.1140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0013 loss_train: 1.9731 acc_train: 0.1500 loss_val: 1.9672 acc_val: 0.1140 time: 0.0442s\n",
            "0\n",
            "Epoch: 0014 loss_train: 1.9734 acc_train: 0.1357 loss_val: 1.9633 acc_val: 0.1140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0015 loss_train: 1.9673 acc_train: 0.1286 loss_val: 1.9595 acc_val: 0.1140 time: 0.0452s\n",
            "0\n",
            "Epoch: 0016 loss_train: 1.9630 acc_train: 0.1571 loss_val: 1.9559 acc_val: 0.1140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0017 loss_train: 1.9617 acc_train: 0.1500 loss_val: 1.9526 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.9566 acc_train: 0.1500 loss_val: 1.9492 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.9495 acc_train: 0.1714 loss_val: 1.9461 acc_val: 0.1140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.9560 acc_train: 0.1429 loss_val: 1.9432 acc_val: 0.1140 time: 0.0445s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.9490 acc_train: 0.1786 loss_val: 1.9411 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.9507 acc_train: 0.1429 loss_val: 1.9389 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0023 loss_train: 1.9421 acc_train: 0.1429 loss_val: 1.9372 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.9415 acc_train: 0.2000 loss_val: 1.9352 acc_val: 0.1140 time: 0.0474s\n",
            "0\n",
            "Epoch: 0025 loss_train: 1.9507 acc_train: 0.1214 loss_val: 1.9336 acc_val: 0.1140 time: 0.0446s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.9325 acc_train: 0.2000 loss_val: 1.9319 acc_val: 0.1140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0027 loss_train: 1.9415 acc_train: 0.1357 loss_val: 1.9303 acc_val: 0.1140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.9367 acc_train: 0.1357 loss_val: 1.9282 acc_val: 0.1140 time: 0.0450s\n",
            "0\n",
            "Epoch: 0029 loss_train: 1.9295 acc_train: 0.1786 loss_val: 1.9256 acc_val: 0.1180 time: 0.0439s\n",
            "0\n",
            "Epoch: 0030 loss_train: 1.9314 acc_train: 0.1500 loss_val: 1.9235 acc_val: 0.1240 time: 0.0446s\n",
            "0\n",
            "Epoch: 0031 loss_train: 1.9197 acc_train: 0.2071 loss_val: 1.9216 acc_val: 0.1280 time: 0.0438s\n",
            "0\n",
            "Epoch: 0032 loss_train: 1.9228 acc_train: 0.2429 loss_val: 1.9202 acc_val: 0.1320 time: 0.0436s\n",
            "0\n",
            "Epoch: 0033 loss_train: 1.9299 acc_train: 0.1500 loss_val: 1.9192 acc_val: 0.1340 time: 0.0442s\n",
            "0\n",
            "Epoch: 0034 loss_train: 1.9203 acc_train: 0.2214 loss_val: 1.9186 acc_val: 0.1320 time: 0.0437s\n",
            "0\n",
            "Epoch: 0035 loss_train: 1.9143 acc_train: 0.2500 loss_val: 1.9177 acc_val: 0.1340 time: 0.0456s\n",
            "0\n",
            "Epoch: 0036 loss_train: 1.9151 acc_train: 0.2500 loss_val: 1.9172 acc_val: 0.1360 time: 0.0440s\n",
            "0\n",
            "Epoch: 0037 loss_train: 1.9007 acc_train: 0.2357 loss_val: 1.9166 acc_val: 0.1380 time: 0.0436s\n",
            "0\n",
            "Epoch: 0038 loss_train: 1.8983 acc_train: 0.2214 loss_val: 1.9150 acc_val: 0.1600 time: 0.0437s\n",
            "0\n",
            "Epoch: 0039 loss_train: 1.9124 acc_train: 0.2714 loss_val: 1.9134 acc_val: 0.1880 time: 0.0447s\n",
            "0\n",
            "Epoch: 0040 loss_train: 1.9079 acc_train: 0.2929 loss_val: 1.9116 acc_val: 0.2240 time: 0.0445s\n",
            "0\n",
            "Epoch: 0041 loss_train: 1.8941 acc_train: 0.3143 loss_val: 1.9091 acc_val: 0.2620 time: 0.0455s\n",
            "0\n",
            "Epoch: 0042 loss_train: 1.8948 acc_train: 0.2857 loss_val: 1.9058 acc_val: 0.3540 time: 0.0452s\n",
            "0\n",
            "Epoch: 0043 loss_train: 1.8863 acc_train: 0.3000 loss_val: 1.9022 acc_val: 0.4100 time: 0.0450s\n",
            "0\n",
            "Epoch: 0044 loss_train: 1.8906 acc_train: 0.3357 loss_val: 1.8993 acc_val: 0.4380 time: 0.0439s\n",
            "0\n",
            "Epoch: 0045 loss_train: 1.8891 acc_train: 0.3214 loss_val: 1.8967 acc_val: 0.4220 time: 0.0442s\n",
            "0\n",
            "Epoch: 0046 loss_train: 1.8738 acc_train: 0.2714 loss_val: 1.8945 acc_val: 0.4200 time: 0.0436s\n",
            "0\n",
            "Epoch: 0047 loss_train: 1.8774 acc_train: 0.3429 loss_val: 1.8926 acc_val: 0.4140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0048 loss_train: 1.8677 acc_train: 0.3357 loss_val: 1.8910 acc_val: 0.3980 time: 0.0474s\n",
            "0\n",
            "Epoch: 0049 loss_train: 1.8586 acc_train: 0.3714 loss_val: 1.8877 acc_val: 0.4380 time: 0.0437s\n",
            "0\n",
            "Epoch: 0050 loss_train: 1.8605 acc_train: 0.3857 loss_val: 1.8845 acc_val: 0.4960 time: 0.0456s\n",
            "0\n",
            "Epoch: 0051 loss_train: 1.8624 acc_train: 0.4000 loss_val: 1.8802 acc_val: 0.5800 time: 0.0435s\n",
            "0\n",
            "Epoch: 0052 loss_train: 1.8578 acc_train: 0.3214 loss_val: 1.8766 acc_val: 0.6520 time: 0.0436s\n",
            "0\n",
            "Epoch: 0053 loss_train: 1.8480 acc_train: 0.3500 loss_val: 1.8734 acc_val: 0.6880 time: 0.0437s\n",
            "0\n",
            "Epoch: 0054 loss_train: 1.8408 acc_train: 0.3357 loss_val: 1.8716 acc_val: 0.6820 time: 0.0450s\n",
            "0\n",
            "Epoch: 0055 loss_train: 1.8290 acc_train: 0.4286 loss_val: 1.8684 acc_val: 0.6660 time: 0.0456s\n",
            "0\n",
            "Epoch: 0056 loss_train: 1.8229 acc_train: 0.3929 loss_val: 1.8639 acc_val: 0.6800 time: 0.0439s\n",
            "0\n",
            "Epoch: 0057 loss_train: 1.8284 acc_train: 0.3500 loss_val: 1.8591 acc_val: 0.7040 time: 0.0442s\n",
            "0\n",
            "Epoch: 0058 loss_train: 1.8263 acc_train: 0.4071 loss_val: 1.8546 acc_val: 0.7160 time: 0.0442s\n",
            "0\n",
            "Epoch: 0059 loss_train: 1.8084 acc_train: 0.3786 loss_val: 1.8488 acc_val: 0.7380 time: 0.0441s\n",
            "0\n",
            "Epoch: 0060 loss_train: 1.7987 acc_train: 0.4000 loss_val: 1.8422 acc_val: 0.7520 time: 0.0450s\n",
            "0\n",
            "Epoch: 0061 loss_train: 1.7891 acc_train: 0.4429 loss_val: 1.8342 acc_val: 0.7420 time: 0.0442s\n",
            "0\n",
            "Epoch: 0062 loss_train: 1.7822 acc_train: 0.4286 loss_val: 1.8261 acc_val: 0.7400 time: 0.0438s\n",
            "0\n",
            "Epoch: 0063 loss_train: 1.7936 acc_train: 0.3929 loss_val: 1.8181 acc_val: 0.7440 time: 0.0441s\n",
            "0\n",
            "Epoch: 0064 loss_train: 1.7841 acc_train: 0.4714 loss_val: 1.8121 acc_val: 0.7380 time: 0.0436s\n",
            "0\n",
            "Epoch: 0065 loss_train: 1.7602 acc_train: 0.4714 loss_val: 1.8063 acc_val: 0.7300 time: 0.0448s\n",
            "0\n",
            "Epoch: 0066 loss_train: 1.7615 acc_train: 0.5071 loss_val: 1.8012 acc_val: 0.7420 time: 0.0443s\n",
            "0\n",
            "Epoch: 0067 loss_train: 1.7434 acc_train: 0.4714 loss_val: 1.7966 acc_val: 0.7420 time: 0.0440s\n",
            "0\n",
            "Epoch: 0068 loss_train: 1.7565 acc_train: 0.4214 loss_val: 1.7920 acc_val: 0.7480 time: 0.0441s\n",
            "0\n",
            "Epoch: 0069 loss_train: 1.7222 acc_train: 0.4214 loss_val: 1.7865 acc_val: 0.7480 time: 0.0453s\n",
            "0\n",
            "Epoch: 0070 loss_train: 1.7278 acc_train: 0.4500 loss_val: 1.7813 acc_val: 0.7580 time: 0.0447s\n",
            "0\n",
            "Epoch: 0071 loss_train: 1.7169 acc_train: 0.4500 loss_val: 1.7757 acc_val: 0.7560 time: 0.0447s\n",
            "0\n",
            "Epoch: 0072 loss_train: 1.7367 acc_train: 0.3571 loss_val: 1.7702 acc_val: 0.7500 time: 0.0437s\n",
            "0\n",
            "Epoch: 0073 loss_train: 1.6987 acc_train: 0.4571 loss_val: 1.7651 acc_val: 0.7620 time: 0.0436s\n",
            "0\n",
            "Epoch: 0074 loss_train: 1.7112 acc_train: 0.4714 loss_val: 1.7605 acc_val: 0.7680 time: 0.0446s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.6858 acc_train: 0.4643 loss_val: 1.7558 acc_val: 0.7720 time: 0.0453s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.6779 acc_train: 0.5357 loss_val: 1.7502 acc_val: 0.7840 time: 0.0442s\n",
            "0\n",
            "Epoch: 0077 loss_train: 1.6665 acc_train: 0.5571 loss_val: 1.7437 acc_val: 0.7820 time: 0.0448s\n",
            "0\n",
            "Epoch: 0078 loss_train: 1.6607 acc_train: 0.5143 loss_val: 1.7355 acc_val: 0.7880 time: 0.0448s\n",
            "0\n",
            "Epoch: 0079 loss_train: 1.6502 acc_train: 0.5286 loss_val: 1.7263 acc_val: 0.8020 time: 0.0444s\n",
            "0\n",
            "Epoch: 0080 loss_train: 1.6689 acc_train: 0.5357 loss_val: 1.7169 acc_val: 0.7940 time: 0.0447s\n",
            "0\n",
            "Epoch: 0081 loss_train: 1.6365 acc_train: 0.5500 loss_val: 1.7070 acc_val: 0.7800 time: 0.0450s\n",
            "0\n",
            "Epoch: 0082 loss_train: 1.6331 acc_train: 0.5357 loss_val: 1.6966 acc_val: 0.7640 time: 0.0439s\n",
            "0\n",
            "Epoch: 0083 loss_train: 1.6341 acc_train: 0.5500 loss_val: 1.6882 acc_val: 0.7600 time: 0.0442s\n",
            "0\n",
            "Epoch: 0084 loss_train: 1.5953 acc_train: 0.5857 loss_val: 1.6792 acc_val: 0.7720 time: 0.0440s\n",
            "0\n",
            "Epoch: 0085 loss_train: 1.6133 acc_train: 0.5143 loss_val: 1.6706 acc_val: 0.7800 time: 0.0445s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.5952 acc_train: 0.5643 loss_val: 1.6626 acc_val: 0.7880 time: 0.0445s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.5565 acc_train: 0.6000 loss_val: 1.6531 acc_val: 0.7960 time: 0.0439s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.5803 acc_train: 0.5214 loss_val: 1.6430 acc_val: 0.7940 time: 0.0440s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.5738 acc_train: 0.5929 loss_val: 1.6337 acc_val: 0.7940 time: 0.0438s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.5554 acc_train: 0.6071 loss_val: 1.6232 acc_val: 0.8000 time: 0.0509s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.5305 acc_train: 0.5786 loss_val: 1.6145 acc_val: 0.7940 time: 0.0452s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.5349 acc_train: 0.5571 loss_val: 1.6070 acc_val: 0.7860 time: 0.0445s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.5282 acc_train: 0.6286 loss_val: 1.6010 acc_val: 0.7880 time: 0.0438s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.5248 acc_train: 0.4429 loss_val: 1.5947 acc_val: 0.7920 time: 0.0446s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.5529 acc_train: 0.5500 loss_val: 1.5873 acc_val: 0.7960 time: 0.0478s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.4912 acc_train: 0.5929 loss_val: 1.5785 acc_val: 0.7900 time: 0.0439s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.5285 acc_train: 0.5643 loss_val: 1.5690 acc_val: 0.7920 time: 0.0437s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.4952 acc_train: 0.5786 loss_val: 1.5605 acc_val: 0.7940 time: 0.0437s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.4892 acc_train: 0.5357 loss_val: 1.5520 acc_val: 0.7940 time: 0.0442s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.5166 acc_train: 0.5643 loss_val: 1.5432 acc_val: 0.7920 time: 0.0450s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.4589 acc_train: 0.6500 loss_val: 1.5341 acc_val: 0.7900 time: 0.0438s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.4716 acc_train: 0.6000 loss_val: 1.5245 acc_val: 0.7920 time: 0.0439s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.4608 acc_train: 0.6143 loss_val: 1.5130 acc_val: 0.7980 time: 0.0437s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.4434 acc_train: 0.6857 loss_val: 1.5009 acc_val: 0.8000 time: 0.0440s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.4404 acc_train: 0.6000 loss_val: 1.4886 acc_val: 0.8080 time: 0.0443s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.4400 acc_train: 0.6214 loss_val: 1.4766 acc_val: 0.8040 time: 0.0436s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.4343 acc_train: 0.6714 loss_val: 1.4686 acc_val: 0.7980 time: 0.0436s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.4181 acc_train: 0.6714 loss_val: 1.4631 acc_val: 0.7980 time: 0.0437s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.3946 acc_train: 0.6429 loss_val: 1.4599 acc_val: 0.7980 time: 0.0448s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.3921 acc_train: 0.6071 loss_val: 1.4527 acc_val: 0.8020 time: 0.0494s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.4059 acc_train: 0.6643 loss_val: 1.4441 acc_val: 0.8020 time: 0.0438s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.4264 acc_train: 0.5857 loss_val: 1.4390 acc_val: 0.8020 time: 0.0438s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.3842 acc_train: 0.5786 loss_val: 1.4345 acc_val: 0.7940 time: 0.0459s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.4119 acc_train: 0.6071 loss_val: 1.4286 acc_val: 0.7960 time: 0.0472s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.3793 acc_train: 0.6786 loss_val: 1.4210 acc_val: 0.8000 time: 0.0450s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.3461 acc_train: 0.6714 loss_val: 1.4098 acc_val: 0.8040 time: 0.0438s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.3824 acc_train: 0.6071 loss_val: 1.3969 acc_val: 0.8020 time: 0.0439s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.3618 acc_train: 0.6357 loss_val: 1.3838 acc_val: 0.8060 time: 0.0438s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.3672 acc_train: 0.6929 loss_val: 1.3733 acc_val: 0.8040 time: 0.0488s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.3690 acc_train: 0.6143 loss_val: 1.3635 acc_val: 0.8060 time: 0.0443s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.3282 acc_train: 0.6714 loss_val: 1.3546 acc_val: 0.8080 time: 0.0453s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.3263 acc_train: 0.6429 loss_val: 1.3472 acc_val: 0.8060 time: 0.0444s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.3272 acc_train: 0.7286 loss_val: 1.3443 acc_val: 0.8080 time: 0.0437s\n",
            "0\n",
            "Epoch: 0124 loss_train: 1.3220 acc_train: 0.7214 loss_val: 1.3407 acc_val: 0.8100 time: 0.0460s\n",
            "0\n",
            "Epoch: 0125 loss_train: 1.3101 acc_train: 0.6929 loss_val: 1.3377 acc_val: 0.8080 time: 0.0439s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.3245 acc_train: 0.6143 loss_val: 1.3334 acc_val: 0.8100 time: 0.0438s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.2941 acc_train: 0.7000 loss_val: 1.3259 acc_val: 0.8100 time: 0.0437s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.2837 acc_train: 0.6929 loss_val: 1.3169 acc_val: 0.8120 time: 0.0452s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.3260 acc_train: 0.6786 loss_val: 1.3096 acc_val: 0.8100 time: 0.0448s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.2973 acc_train: 0.6857 loss_val: 1.3025 acc_val: 0.7980 time: 0.0478s\n",
            "0\n",
            "Epoch: 0131 loss_train: 1.3025 acc_train: 0.6071 loss_val: 1.2963 acc_val: 0.8020 time: 0.0442s\n",
            "0\n",
            "Epoch: 0132 loss_train: 1.2491 acc_train: 0.7143 loss_val: 1.2887 acc_val: 0.7980 time: 0.0439s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.2879 acc_train: 0.6643 loss_val: 1.2832 acc_val: 0.8020 time: 0.0443s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.2862 acc_train: 0.6643 loss_val: 1.2786 acc_val: 0.8000 time: 0.0458s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.2849 acc_train: 0.6000 loss_val: 1.2777 acc_val: 0.8060 time: 0.0440s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.2207 acc_train: 0.6786 loss_val: 1.2737 acc_val: 0.8060 time: 0.0439s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.2579 acc_train: 0.7571 loss_val: 1.2661 acc_val: 0.8060 time: 0.0439s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.2838 acc_train: 0.6500 loss_val: 1.2601 acc_val: 0.8060 time: 0.0445s\n",
            "0\n",
            "Epoch: 0139 loss_train: 1.2317 acc_train: 0.6714 loss_val: 1.2515 acc_val: 0.8120 time: 0.0467s\n",
            "0\n",
            "Epoch: 0140 loss_train: 1.2690 acc_train: 0.7286 loss_val: 1.2419 acc_val: 0.8120 time: 0.0448s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.2620 acc_train: 0.7071 loss_val: 1.2316 acc_val: 0.8100 time: 0.0450s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.2101 acc_train: 0.7214 loss_val: 1.2219 acc_val: 0.8120 time: 0.0450s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.2616 acc_train: 0.6214 loss_val: 1.2193 acc_val: 0.8120 time: 0.0440s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.2400 acc_train: 0.6786 loss_val: 1.2187 acc_val: 0.8060 time: 0.0449s\n",
            "0\n",
            "Epoch: 0145 loss_train: 1.2220 acc_train: 0.7143 loss_val: 1.2185 acc_val: 0.8040 time: 0.0438s\n",
            "0\n",
            "Epoch: 0146 loss_train: 1.2653 acc_train: 0.6929 loss_val: 1.2198 acc_val: 0.8020 time: 0.0453s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.2145 acc_train: 0.7000 loss_val: 1.2155 acc_val: 0.8040 time: 0.0452s\n",
            "1\n",
            "Epoch: 0148 loss_train: 1.2496 acc_train: 0.7214 loss_val: 1.2081 acc_val: 0.8080 time: 0.0435s\n",
            "0\n",
            "Epoch: 0149 loss_train: 1.2244 acc_train: 0.6500 loss_val: 1.2006 acc_val: 0.8080 time: 0.0456s\n",
            "0\n",
            "Epoch: 0150 loss_train: 1.2474 acc_train: 0.6643 loss_val: 1.1957 acc_val: 0.8120 time: 0.0438s\n",
            "0\n",
            "Epoch: 0151 loss_train: 1.2090 acc_train: 0.6786 loss_val: 1.1915 acc_val: 0.8040 time: 0.0451s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.2197 acc_train: 0.6929 loss_val: 1.1874 acc_val: 0.8040 time: 0.0440s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.2030 acc_train: 0.7500 loss_val: 1.1849 acc_val: 0.7980 time: 0.0455s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.2928 acc_train: 0.6857 loss_val: 1.1849 acc_val: 0.8020 time: 0.0446s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.2067 acc_train: 0.7000 loss_val: 1.1838 acc_val: 0.8000 time: 0.0440s\n",
            "0\n",
            "Epoch: 0156 loss_train: 1.1981 acc_train: 0.6429 loss_val: 1.1756 acc_val: 0.8040 time: 0.0438s\n",
            "0\n",
            "Epoch: 0157 loss_train: 1.2165 acc_train: 0.6571 loss_val: 1.1681 acc_val: 0.8080 time: 0.0442s\n",
            "0\n",
            "Epoch: 0158 loss_train: 1.1991 acc_train: 0.6786 loss_val: 1.1594 acc_val: 0.8120 time: 0.0435s\n",
            "0\n",
            "Epoch: 0159 loss_train: 1.1898 acc_train: 0.7000 loss_val: 1.1538 acc_val: 0.8140 time: 0.0448s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.1972 acc_train: 0.7214 loss_val: 1.1453 acc_val: 0.8140 time: 0.0443s\n",
            "0\n",
            "Epoch: 0161 loss_train: 1.1915 acc_train: 0.7143 loss_val: 1.1386 acc_val: 0.8180 time: 0.0444s\n",
            "0\n",
            "Epoch: 0162 loss_train: 1.2229 acc_train: 0.7214 loss_val: 1.1342 acc_val: 0.8140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0163 loss_train: 1.1957 acc_train: 0.6714 loss_val: 1.1316 acc_val: 0.8120 time: 0.0467s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.1984 acc_train: 0.7000 loss_val: 1.1351 acc_val: 0.8080 time: 0.0448s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.1927 acc_train: 0.6714 loss_val: 1.1379 acc_val: 0.8060 time: 0.0445s\n",
            "1\n",
            "Epoch: 0166 loss_train: 1.1672 acc_train: 0.6643 loss_val: 1.1376 acc_val: 0.8040 time: 0.0445s\n",
            "2\n",
            "Epoch: 0167 loss_train: 1.1849 acc_train: 0.7429 loss_val: 1.1348 acc_val: 0.8020 time: 0.0441s\n",
            "3\n",
            "Epoch: 0168 loss_train: 1.1443 acc_train: 0.7286 loss_val: 1.1309 acc_val: 0.8100 time: 0.0444s\n",
            "4\n",
            "Epoch: 0169 loss_train: 1.1884 acc_train: 0.7429 loss_val: 1.1296 acc_val: 0.8060 time: 0.0461s\n",
            "0\n",
            "Epoch: 0170 loss_train: 1.1805 acc_train: 0.7429 loss_val: 1.1261 acc_val: 0.8080 time: 0.0471s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.1419 acc_train: 0.7000 loss_val: 1.1186 acc_val: 0.8100 time: 0.0446s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.2040 acc_train: 0.6786 loss_val: 1.1083 acc_val: 0.8100 time: 0.0465s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.1250 acc_train: 0.7286 loss_val: 1.0979 acc_val: 0.8160 time: 0.0449s\n",
            "0\n",
            "Epoch: 0174 loss_train: 1.1953 acc_train: 0.6643 loss_val: 1.0884 acc_val: 0.8140 time: 0.0450s\n",
            "0\n",
            "Epoch: 0175 loss_train: 1.1803 acc_train: 0.7071 loss_val: 1.0838 acc_val: 0.8140 time: 0.0441s\n",
            "0\n",
            "Epoch: 0176 loss_train: 1.1683 acc_train: 0.7143 loss_val: 1.0828 acc_val: 0.8160 time: 0.0438s\n",
            "0\n",
            "Epoch: 0177 loss_train: 1.1966 acc_train: 0.6357 loss_val: 1.0864 acc_val: 0.8140 time: 0.0437s\n",
            "0\n",
            "Epoch: 0178 loss_train: 1.1498 acc_train: 0.7714 loss_val: 1.0907 acc_val: 0.8160 time: 0.0450s\n",
            "1\n",
            "Epoch: 0179 loss_train: 1.1206 acc_train: 0.7143 loss_val: 1.0909 acc_val: 0.8140 time: 0.0440s\n",
            "2\n",
            "Epoch: 0180 loss_train: 1.1262 acc_train: 0.7571 loss_val: 1.0886 acc_val: 0.8140 time: 0.0444s\n",
            "3\n",
            "Epoch: 0181 loss_train: 1.1403 acc_train: 0.7500 loss_val: 1.0883 acc_val: 0.8120 time: 0.0441s\n",
            "4\n",
            "Epoch: 0182 loss_train: 1.1396 acc_train: 0.7643 loss_val: 1.0864 acc_val: 0.8140 time: 0.0454s\n",
            "5\n",
            "Epoch: 0183 loss_train: 1.1079 acc_train: 0.7643 loss_val: 1.0812 acc_val: 0.8100 time: 0.0466s\n",
            "6\n",
            "Epoch: 0184 loss_train: 1.1334 acc_train: 0.7786 loss_val: 1.0755 acc_val: 0.8140 time: 0.0440s\n",
            "0\n",
            "Epoch: 0185 loss_train: 1.1649 acc_train: 0.6929 loss_val: 1.0708 acc_val: 0.8100 time: 0.0441s\n",
            "0\n",
            "Epoch: 0186 loss_train: 1.1098 acc_train: 0.7857 loss_val: 1.0649 acc_val: 0.8060 time: 0.0448s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.1442 acc_train: 0.7286 loss_val: 1.0580 acc_val: 0.8060 time: 0.0436s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.1198 acc_train: 0.7500 loss_val: 1.0553 acc_val: 0.8080 time: 0.0447s\n",
            "0\n",
            "Epoch: 0189 loss_train: 1.1033 acc_train: 0.7071 loss_val: 1.0529 acc_val: 0.8160 time: 0.0439s\n",
            "0\n",
            "Epoch: 0190 loss_train: 1.1501 acc_train: 0.7000 loss_val: 1.0533 acc_val: 0.8180 time: 0.0440s\n",
            "0\n",
            "Epoch: 0191 loss_train: 1.1673 acc_train: 0.7643 loss_val: 1.0592 acc_val: 0.8120 time: 0.0439s\n",
            "0\n",
            "Epoch: 0192 loss_train: 1.1240 acc_train: 0.6929 loss_val: 1.0677 acc_val: 0.8040 time: 0.0440s\n",
            "1\n",
            "Epoch: 0193 loss_train: 1.0999 acc_train: 0.7714 loss_val: 1.0685 acc_val: 0.8040 time: 0.0462s\n",
            "2\n",
            "Epoch: 0194 loss_train: 1.1116 acc_train: 0.7214 loss_val: 1.0624 acc_val: 0.8100 time: 0.0442s\n",
            "3\n",
            "Epoch: 0195 loss_train: 1.1421 acc_train: 0.7000 loss_val: 1.0565 acc_val: 0.8120 time: 0.0442s\n",
            "4\n",
            "Epoch: 0196 loss_train: 1.1158 acc_train: 0.6786 loss_val: 1.0496 acc_val: 0.8140 time: 0.0443s\n",
            "5\n",
            "Epoch: 0197 loss_train: 1.1198 acc_train: 0.7714 loss_val: 1.0397 acc_val: 0.8080 time: 0.0447s\n",
            "0\n",
            "Epoch: 0198 loss_train: 1.1073 acc_train: 0.7714 loss_val: 1.0315 acc_val: 0.8120 time: 0.0452s\n",
            "0\n",
            "Epoch: 0199 loss_train: 1.0966 acc_train: 0.6714 loss_val: 1.0262 acc_val: 0.8180 time: 0.0436s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.1364 acc_train: 0.7286 loss_val: 1.0277 acc_val: 0.8140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.1305 acc_train: 0.6643 loss_val: 1.0353 acc_val: 0.8120 time: 0.0442s\n",
            "1\n",
            "Epoch: 0202 loss_train: 1.1150 acc_train: 0.7143 loss_val: 1.0410 acc_val: 0.8060 time: 0.0442s\n",
            "2\n",
            "Epoch: 0203 loss_train: 1.1470 acc_train: 0.7714 loss_val: 1.0420 acc_val: 0.8000 time: 0.0545s\n",
            "3\n",
            "Epoch: 0204 loss_train: 1.1001 acc_train: 0.7429 loss_val: 1.0404 acc_val: 0.8020 time: 0.0450s\n",
            "4\n",
            "Epoch: 0205 loss_train: 1.1519 acc_train: 0.7143 loss_val: 1.0381 acc_val: 0.8060 time: 0.0440s\n",
            "5\n",
            "Epoch: 0206 loss_train: 1.1178 acc_train: 0.7500 loss_val: 1.0313 acc_val: 0.8080 time: 0.0446s\n",
            "6\n",
            "Epoch: 0207 loss_train: 1.1361 acc_train: 0.7000 loss_val: 1.0241 acc_val: 0.8120 time: 0.0468s\n",
            "7\n",
            "Epoch: 0208 loss_train: 1.1256 acc_train: 0.7214 loss_val: 1.0195 acc_val: 0.8200 time: 0.0456s\n",
            "0\n",
            "Epoch: 0209 loss_train: 1.0901 acc_train: 0.7286 loss_val: 1.0164 acc_val: 0.8200 time: 0.0450s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.1030 acc_train: 0.7286 loss_val: 1.0161 acc_val: 0.8120 time: 0.0449s\n",
            "0\n",
            "Epoch: 0211 loss_train: 1.1525 acc_train: 0.7214 loss_val: 1.0205 acc_val: 0.8100 time: 0.0444s\n",
            "0\n",
            "Epoch: 0212 loss_train: 1.0535 acc_train: 0.7357 loss_val: 1.0232 acc_val: 0.8060 time: 0.0438s\n",
            "1\n",
            "Epoch: 0213 loss_train: 1.0962 acc_train: 0.7429 loss_val: 1.0208 acc_val: 0.8080 time: 0.0459s\n",
            "2\n",
            "Epoch: 0214 loss_train: 1.1033 acc_train: 0.7143 loss_val: 1.0172 acc_val: 0.8060 time: 0.0468s\n",
            "3\n",
            "Epoch: 0215 loss_train: 1.0636 acc_train: 0.7786 loss_val: 1.0093 acc_val: 0.8100 time: 0.0442s\n",
            "4\n",
            "Epoch: 0216 loss_train: 1.0899 acc_train: 0.7286 loss_val: 0.9994 acc_val: 0.8200 time: 0.0469s\n",
            "0\n",
            "Epoch: 0217 loss_train: 1.0732 acc_train: 0.7571 loss_val: 0.9921 acc_val: 0.8220 time: 0.0447s\n",
            "0\n",
            "Epoch: 0218 loss_train: 1.0720 acc_train: 0.7429 loss_val: 0.9891 acc_val: 0.8200 time: 0.0462s\n",
            "0\n",
            "Epoch: 0219 loss_train: 1.0522 acc_train: 0.7143 loss_val: 0.9904 acc_val: 0.8180 time: 0.0437s\n",
            "0\n",
            "Epoch: 0220 loss_train: 1.1256 acc_train: 0.7786 loss_val: 0.9953 acc_val: 0.8160 time: 0.0443s\n",
            "1\n",
            "Epoch: 0221 loss_train: 1.1029 acc_train: 0.7143 loss_val: 1.0036 acc_val: 0.8120 time: 0.0441s\n",
            "2\n",
            "Epoch: 0222 loss_train: 1.0680 acc_train: 0.7500 loss_val: 1.0075 acc_val: 0.8060 time: 0.0442s\n",
            "3\n",
            "Epoch: 0223 loss_train: 1.0813 acc_train: 0.7571 loss_val: 1.0043 acc_val: 0.8080 time: 0.0449s\n",
            "4\n",
            "Epoch: 0224 loss_train: 1.1026 acc_train: 0.7143 loss_val: 1.0021 acc_val: 0.8140 time: 0.0440s\n",
            "5\n",
            "Epoch: 0225 loss_train: 1.0616 acc_train: 0.7357 loss_val: 0.9959 acc_val: 0.8180 time: 0.0442s\n",
            "6\n",
            "Epoch: 0226 loss_train: 1.0755 acc_train: 0.7643 loss_val: 0.9890 acc_val: 0.8160 time: 0.0441s\n",
            "7\n",
            "Epoch: 0227 loss_train: 1.0812 acc_train: 0.7143 loss_val: 0.9794 acc_val: 0.8200 time: 0.0449s\n",
            "0\n",
            "Epoch: 0228 loss_train: 1.0432 acc_train: 0.7714 loss_val: 0.9747 acc_val: 0.8200 time: 0.0445s\n",
            "0\n",
            "Epoch: 0229 loss_train: 1.0689 acc_train: 0.7500 loss_val: 0.9737 acc_val: 0.8140 time: 0.0436s\n",
            "0\n",
            "Epoch: 0230 loss_train: 1.1272 acc_train: 0.6857 loss_val: 0.9789 acc_val: 0.8100 time: 0.0437s\n",
            "0\n",
            "Epoch: 0231 loss_train: 1.1008 acc_train: 0.7500 loss_val: 0.9885 acc_val: 0.8100 time: 0.0454s\n",
            "1\n",
            "Epoch: 0232 loss_train: 1.0772 acc_train: 0.7071 loss_val: 0.9950 acc_val: 0.8080 time: 0.0466s\n",
            "2\n",
            "Epoch: 0233 loss_train: 1.0623 acc_train: 0.7357 loss_val: 0.9955 acc_val: 0.8140 time: 0.0455s\n",
            "3\n",
            "Epoch: 0234 loss_train: 1.0433 acc_train: 0.7643 loss_val: 0.9924 acc_val: 0.8180 time: 0.0441s\n",
            "4\n",
            "Epoch: 0235 loss_train: 1.0767 acc_train: 0.7143 loss_val: 0.9838 acc_val: 0.8140 time: 0.0455s\n",
            "5\n",
            "Epoch: 0236 loss_train: 1.0081 acc_train: 0.7214 loss_val: 0.9738 acc_val: 0.8160 time: 0.0442s\n",
            "6\n",
            "Epoch: 0237 loss_train: 1.0292 acc_train: 0.7429 loss_val: 0.9668 acc_val: 0.8160 time: 0.0449s\n",
            "7\n",
            "Epoch: 0238 loss_train: 1.0989 acc_train: 0.7429 loss_val: 0.9637 acc_val: 0.8120 time: 0.0465s\n",
            "0\n",
            "Epoch: 0239 loss_train: 1.0750 acc_train: 0.7786 loss_val: 0.9633 acc_val: 0.8100 time: 0.0447s\n",
            "0\n",
            "Epoch: 0240 loss_train: 1.1141 acc_train: 0.7143 loss_val: 0.9656 acc_val: 0.8140 time: 0.0438s\n",
            "0\n",
            "Epoch: 0241 loss_train: 1.0775 acc_train: 0.7286 loss_val: 0.9696 acc_val: 0.8120 time: 0.0442s\n",
            "1\n",
            "Epoch: 0242 loss_train: 1.0395 acc_train: 0.7857 loss_val: 0.9732 acc_val: 0.8220 time: 0.0483s\n",
            "2\n",
            "Epoch: 0243 loss_train: 1.0693 acc_train: 0.7429 loss_val: 0.9726 acc_val: 0.8220 time: 0.0452s\n",
            "0\n",
            "Epoch: 0244 loss_train: 1.0348 acc_train: 0.7429 loss_val: 0.9701 acc_val: 0.8220 time: 0.0444s\n",
            "0\n",
            "Epoch: 0245 loss_train: 1.0525 acc_train: 0.7214 loss_val: 0.9668 acc_val: 0.8200 time: 0.0468s\n",
            "0\n",
            "Epoch: 0246 loss_train: 1.0312 acc_train: 0.7714 loss_val: 0.9624 acc_val: 0.8180 time: 0.0442s\n",
            "1\n",
            "Epoch: 0247 loss_train: 1.0735 acc_train: 0.7643 loss_val: 0.9557 acc_val: 0.8220 time: 0.0440s\n",
            "0\n",
            "Epoch: 0248 loss_train: 1.0427 acc_train: 0.7643 loss_val: 0.9510 acc_val: 0.8200 time: 0.0449s\n",
            "0\n",
            "Epoch: 0249 loss_train: 1.0325 acc_train: 0.7571 loss_val: 0.9493 acc_val: 0.8180 time: 0.0437s\n",
            "0\n",
            "Epoch: 0250 loss_train: 1.0724 acc_train: 0.7714 loss_val: 0.9514 acc_val: 0.8120 time: 0.0437s\n",
            "0\n",
            "Epoch: 0251 loss_train: 1.0603 acc_train: 0.7786 loss_val: 0.9527 acc_val: 0.8140 time: 0.0442s\n",
            "1\n",
            "Epoch: 0252 loss_train: 1.0570 acc_train: 0.7429 loss_val: 0.9535 acc_val: 0.8120 time: 0.0467s\n",
            "2\n",
            "Epoch: 0253 loss_train: 0.9838 acc_train: 0.8214 loss_val: 0.9513 acc_val: 0.8140 time: 0.0453s\n",
            "3\n",
            "Epoch: 0254 loss_train: 0.9952 acc_train: 0.8214 loss_val: 0.9509 acc_val: 0.8200 time: 0.0448s\n",
            "4\n",
            "Epoch: 0255 loss_train: 1.0509 acc_train: 0.8071 loss_val: 0.9516 acc_val: 0.8240 time: 0.0477s\n",
            "5\n",
            "Epoch: 0256 loss_train: 1.0231 acc_train: 0.7429 loss_val: 0.9497 acc_val: 0.8260 time: 0.0462s\n",
            "0\n",
            "Epoch: 0257 loss_train: 1.0460 acc_train: 0.7929 loss_val: 0.9458 acc_val: 0.8240 time: 0.0447s\n",
            "0\n",
            "Epoch: 0258 loss_train: 1.0671 acc_train: 0.7429 loss_val: 0.9418 acc_val: 0.8220 time: 0.0445s\n",
            "0\n",
            "Epoch: 0259 loss_train: 1.0733 acc_train: 0.7286 loss_val: 0.9431 acc_val: 0.8200 time: 0.0450s\n",
            "0\n",
            "Epoch: 0260 loss_train: 1.0274 acc_train: 0.7643 loss_val: 0.9446 acc_val: 0.8200 time: 0.0443s\n",
            "1\n",
            "Epoch: 0261 loss_train: 1.0783 acc_train: 0.7429 loss_val: 0.9472 acc_val: 0.8180 time: 0.0443s\n",
            "2\n",
            "Epoch: 0262 loss_train: 1.0494 acc_train: 0.7714 loss_val: 0.9484 acc_val: 0.8180 time: 0.0440s\n",
            "3\n",
            "Epoch: 0263 loss_train: 1.0510 acc_train: 0.7571 loss_val: 0.9515 acc_val: 0.8140 time: 0.0465s\n",
            "4\n",
            "Epoch: 0264 loss_train: 1.0319 acc_train: 0.8000 loss_val: 0.9512 acc_val: 0.8160 time: 0.0458s\n",
            "5\n",
            "Epoch: 0265 loss_train: 1.0429 acc_train: 0.8429 loss_val: 0.9451 acc_val: 0.8200 time: 0.0447s\n",
            "6\n",
            "Epoch: 0266 loss_train: 1.0372 acc_train: 0.7286 loss_val: 0.9378 acc_val: 0.8220 time: 0.0440s\n",
            "7\n",
            "Epoch: 0267 loss_train: 1.0768 acc_train: 0.7929 loss_val: 0.9299 acc_val: 0.8220 time: 0.0438s\n",
            "0\n",
            "Epoch: 0268 loss_train: 1.0300 acc_train: 0.8000 loss_val: 0.9234 acc_val: 0.8180 time: 0.0454s\n",
            "0\n",
            "Epoch: 0269 loss_train: 1.0684 acc_train: 0.7571 loss_val: 0.9235 acc_val: 0.8140 time: 0.0444s\n",
            "0\n",
            "Epoch: 0270 loss_train: 1.0474 acc_train: 0.7714 loss_val: 0.9269 acc_val: 0.8160 time: 0.0446s\n",
            "1\n",
            "Epoch: 0271 loss_train: 1.0358 acc_train: 0.7786 loss_val: 0.9316 acc_val: 0.8140 time: 0.0462s\n",
            "2\n",
            "Epoch: 0272 loss_train: 1.0335 acc_train: 0.7429 loss_val: 0.9339 acc_val: 0.8140 time: 0.0438s\n",
            "3\n",
            "Epoch: 0273 loss_train: 1.0457 acc_train: 0.7571 loss_val: 0.9345 acc_val: 0.8100 time: 0.0449s\n",
            "4\n",
            "Epoch: 0274 loss_train: 1.0761 acc_train: 0.7143 loss_val: 0.9350 acc_val: 0.8120 time: 0.0440s\n",
            "5\n",
            "Epoch: 0275 loss_train: 1.0480 acc_train: 0.7929 loss_val: 0.9326 acc_val: 0.8140 time: 0.0493s\n",
            "6\n",
            "Epoch: 0276 loss_train: 1.0220 acc_train: 0.7357 loss_val: 0.9287 acc_val: 0.8200 time: 0.0440s\n",
            "7\n",
            "Epoch: 0277 loss_train: 1.0310 acc_train: 0.6929 loss_val: 0.9228 acc_val: 0.8200 time: 0.0457s\n",
            "8\n",
            "Epoch: 0278 loss_train: 1.0211 acc_train: 0.7500 loss_val: 0.9167 acc_val: 0.8220 time: 0.0448s\n",
            "0\n",
            "Epoch: 0279 loss_train: 1.0406 acc_train: 0.7429 loss_val: 0.9132 acc_val: 0.8220 time: 0.0443s\n",
            "0\n",
            "Epoch: 0280 loss_train: 1.0356 acc_train: 0.7857 loss_val: 0.9155 acc_val: 0.8200 time: 0.0438s\n",
            "0\n",
            "Epoch: 0281 loss_train: 1.0110 acc_train: 0.7643 loss_val: 0.9172 acc_val: 0.8240 time: 0.0454s\n",
            "1\n",
            "Epoch: 0282 loss_train: 1.0222 acc_train: 0.7643 loss_val: 0.9203 acc_val: 0.8220 time: 0.0441s\n",
            "2\n",
            "Epoch: 0283 loss_train: 1.0705 acc_train: 0.7357 loss_val: 0.9228 acc_val: 0.8100 time: 0.0458s\n",
            "3\n",
            "Epoch: 0284 loss_train: 0.9925 acc_train: 0.7929 loss_val: 0.9221 acc_val: 0.8080 time: 0.0443s\n",
            "4\n",
            "Epoch: 0285 loss_train: 0.9710 acc_train: 0.8214 loss_val: 0.9142 acc_val: 0.8100 time: 0.0459s\n",
            "5\n",
            "Epoch: 0286 loss_train: 0.9814 acc_train: 0.7786 loss_val: 0.9055 acc_val: 0.8200 time: 0.0457s\n",
            "6\n",
            "Epoch: 0287 loss_train: 1.0112 acc_train: 0.7500 loss_val: 0.8993 acc_val: 0.8240 time: 0.0447s\n",
            "0\n",
            "Epoch: 0288 loss_train: 0.9583 acc_train: 0.8286 loss_val: 0.8960 acc_val: 0.8260 time: 0.0461s\n",
            "0\n",
            "Epoch: 0289 loss_train: 1.0414 acc_train: 0.7357 loss_val: 0.9012 acc_val: 0.8280 time: 0.0439s\n",
            "0\n",
            "Epoch: 0290 loss_train: 1.0476 acc_train: 0.7071 loss_val: 0.9097 acc_val: 0.8260 time: 0.0459s\n",
            "0\n",
            "Epoch: 0291 loss_train: 1.0051 acc_train: 0.7786 loss_val: 0.9145 acc_val: 0.8260 time: 0.0443s\n",
            "1\n",
            "Epoch: 0292 loss_train: 0.9993 acc_train: 0.8143 loss_val: 0.9119 acc_val: 0.8200 time: 0.0445s\n",
            "2\n",
            "Epoch: 0293 loss_train: 1.0463 acc_train: 0.7357 loss_val: 0.9121 acc_val: 0.8120 time: 0.0453s\n",
            "3\n",
            "Epoch: 0294 loss_train: 1.0026 acc_train: 0.7643 loss_val: 0.9111 acc_val: 0.8080 time: 0.0459s\n",
            "4\n",
            "Epoch: 0295 loss_train: 0.9986 acc_train: 0.8071 loss_val: 0.9102 acc_val: 0.8120 time: 0.0447s\n",
            "5\n",
            "Epoch: 0296 loss_train: 1.0103 acc_train: 0.8143 loss_val: 0.9108 acc_val: 0.8140 time: 0.0445s\n",
            "6\n",
            "Epoch: 0297 loss_train: 0.9794 acc_train: 0.8357 loss_val: 0.9114 acc_val: 0.8100 time: 0.0442s\n",
            "7\n",
            "Epoch: 0298 loss_train: 1.0243 acc_train: 0.7500 loss_val: 0.9093 acc_val: 0.8200 time: 0.0479s\n",
            "8\n",
            "Epoch: 0299 loss_train: 0.9988 acc_train: 0.8071 loss_val: 0.9044 acc_val: 0.8160 time: 0.0465s\n",
            "9\n",
            "Epoch: 0300 loss_train: 1.0271 acc_train: 0.7214 loss_val: 0.8974 acc_val: 0.8240 time: 0.0448s\n",
            "10\n",
            "Epoch: 0301 loss_train: 1.0025 acc_train: 0.7714 loss_val: 0.8899 acc_val: 0.8240 time: 0.0455s\n",
            "11\n",
            "Epoch: 0302 loss_train: 1.0282 acc_train: 0.7286 loss_val: 0.8868 acc_val: 0.8220 time: 0.0440s\n",
            "0\n",
            "Epoch: 0303 loss_train: 1.0412 acc_train: 0.6857 loss_val: 0.8864 acc_val: 0.8220 time: 0.0455s\n",
            "0\n",
            "Epoch: 0304 loss_train: 1.0227 acc_train: 0.7571 loss_val: 0.8897 acc_val: 0.8220 time: 0.0452s\n",
            "0\n",
            "Epoch: 0305 loss_train: 1.0412 acc_train: 0.7500 loss_val: 0.8953 acc_val: 0.8200 time: 0.0444s\n",
            "1\n",
            "Epoch: 0306 loss_train: 0.9955 acc_train: 0.8000 loss_val: 0.9058 acc_val: 0.8180 time: 0.0439s\n",
            "2\n",
            "Epoch: 0307 loss_train: 1.0534 acc_train: 0.7286 loss_val: 0.9125 acc_val: 0.8160 time: 0.0446s\n",
            "3\n",
            "Epoch: 0308 loss_train: 0.9971 acc_train: 0.7714 loss_val: 0.9146 acc_val: 0.8120 time: 0.0472s\n",
            "4\n",
            "Epoch: 0309 loss_train: 1.0030 acc_train: 0.8071 loss_val: 0.9096 acc_val: 0.8140 time: 0.0461s\n",
            "5\n",
            "Epoch: 0310 loss_train: 1.0018 acc_train: 0.7143 loss_val: 0.9005 acc_val: 0.8140 time: 0.0449s\n",
            "6\n",
            "Epoch: 0311 loss_train: 0.9489 acc_train: 0.8286 loss_val: 0.8895 acc_val: 0.8200 time: 0.0455s\n",
            "7\n",
            "Epoch: 0312 loss_train: 0.9887 acc_train: 0.8071 loss_val: 0.8817 acc_val: 0.8240 time: 0.0446s\n",
            "8\n",
            "Epoch: 0313 loss_train: 0.9720 acc_train: 0.7143 loss_val: 0.8790 acc_val: 0.8260 time: 0.0468s\n",
            "0\n",
            "Epoch: 0314 loss_train: 0.9791 acc_train: 0.7643 loss_val: 0.8819 acc_val: 0.8220 time: 0.0470s\n",
            "0\n",
            "Epoch: 0315 loss_train: 1.0172 acc_train: 0.8286 loss_val: 0.8831 acc_val: 0.8260 time: 0.0448s\n",
            "1\n",
            "Epoch: 0316 loss_train: 0.9770 acc_train: 0.7857 loss_val: 0.8868 acc_val: 0.8300 time: 0.0444s\n",
            "2\n",
            "Epoch: 0317 loss_train: 1.0063 acc_train: 0.7286 loss_val: 0.8863 acc_val: 0.8240 time: 0.0445s\n",
            "0\n",
            "Epoch: 0318 loss_train: 1.0356 acc_train: 0.7357 loss_val: 0.8818 acc_val: 0.8180 time: 0.0448s\n",
            "1\n",
            "Epoch: 0319 loss_train: 0.9687 acc_train: 0.7714 loss_val: 0.8789 acc_val: 0.8240 time: 0.0489s\n",
            "2\n",
            "Epoch: 0320 loss_train: 1.0184 acc_train: 0.7214 loss_val: 0.8818 acc_val: 0.8220 time: 0.0438s\n",
            "0\n",
            "Epoch: 0321 loss_train: 0.9791 acc_train: 0.8571 loss_val: 0.8865 acc_val: 0.8220 time: 0.0445s\n",
            "1\n",
            "Epoch: 0322 loss_train: 0.9387 acc_train: 0.8071 loss_val: 0.8877 acc_val: 0.8220 time: 0.0440s\n",
            "2\n",
            "Epoch: 0323 loss_train: 0.9860 acc_train: 0.8286 loss_val: 0.8868 acc_val: 0.8200 time: 0.0455s\n",
            "3\n",
            "Epoch: 0324 loss_train: 1.0351 acc_train: 0.7357 loss_val: 0.8882 acc_val: 0.8200 time: 0.0477s\n",
            "4\n",
            "Epoch: 0325 loss_train: 1.0184 acc_train: 0.7500 loss_val: 0.8870 acc_val: 0.8240 time: 0.0454s\n",
            "5\n",
            "Epoch: 0326 loss_train: 0.9441 acc_train: 0.8214 loss_val: 0.8843 acc_val: 0.8280 time: 0.0455s\n",
            "6\n",
            "Epoch: 0327 loss_train: 1.0105 acc_train: 0.7643 loss_val: 0.8812 acc_val: 0.8220 time: 0.0447s\n",
            "7\n",
            "Epoch: 0328 loss_train: 1.0042 acc_train: 0.7357 loss_val: 0.8797 acc_val: 0.8220 time: 0.0460s\n",
            "8\n",
            "Epoch: 0329 loss_train: 0.9645 acc_train: 0.8000 loss_val: 0.8785 acc_val: 0.8200 time: 0.0445s\n",
            "9\n",
            "Epoch: 0330 loss_train: 0.9388 acc_train: 0.8429 loss_val: 0.8761 acc_val: 0.8200 time: 0.0451s\n",
            "0\n",
            "Epoch: 0331 loss_train: 1.0331 acc_train: 0.7643 loss_val: 0.8768 acc_val: 0.8220 time: 0.0453s\n",
            "0\n",
            "Epoch: 0332 loss_train: 0.9687 acc_train: 0.8286 loss_val: 0.8771 acc_val: 0.8200 time: 0.0456s\n",
            "1\n",
            "Epoch: 0333 loss_train: 1.0425 acc_train: 0.7786 loss_val: 0.8805 acc_val: 0.8180 time: 0.0465s\n",
            "2\n",
            "Epoch: 0334 loss_train: 0.9950 acc_train: 0.7143 loss_val: 0.8863 acc_val: 0.8140 time: 0.0444s\n",
            "3\n",
            "Epoch: 0335 loss_train: 0.9977 acc_train: 0.8071 loss_val: 0.8932 acc_val: 0.8120 time: 0.0445s\n",
            "4\n",
            "Epoch: 0336 loss_train: 0.9922 acc_train: 0.7929 loss_val: 0.8927 acc_val: 0.8180 time: 0.0453s\n",
            "5\n",
            "Epoch: 0337 loss_train: 0.9908 acc_train: 0.7929 loss_val: 0.8883 acc_val: 0.8200 time: 0.0442s\n",
            "6\n",
            "Epoch: 0338 loss_train: 0.9821 acc_train: 0.7857 loss_val: 0.8799 acc_val: 0.8200 time: 0.0463s\n",
            "7\n",
            "Epoch: 0339 loss_train: 0.9703 acc_train: 0.7643 loss_val: 0.8746 acc_val: 0.8180 time: 0.0445s\n",
            "8\n",
            "Epoch: 0340 loss_train: 0.9420 acc_train: 0.8357 loss_val: 0.8682 acc_val: 0.8240 time: 0.0465s\n",
            "0\n",
            "Epoch: 0341 loss_train: 0.9677 acc_train: 0.7786 loss_val: 0.8660 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0342 loss_train: 0.9588 acc_train: 0.7714 loss_val: 0.8658 acc_val: 0.8240 time: 0.0444s\n",
            "0\n",
            "Epoch: 0343 loss_train: 0.9832 acc_train: 0.8071 loss_val: 0.8669 acc_val: 0.8180 time: 0.0450s\n",
            "0\n",
            "Epoch: 0344 loss_train: 1.0108 acc_train: 0.7786 loss_val: 0.8718 acc_val: 0.8100 time: 0.0448s\n",
            "1\n",
            "Epoch: 0345 loss_train: 0.9844 acc_train: 0.8143 loss_val: 0.8779 acc_val: 0.8160 time: 0.0441s\n",
            "2\n",
            "Epoch: 0346 loss_train: 1.0314 acc_train: 0.7643 loss_val: 0.8801 acc_val: 0.8180 time: 0.0442s\n",
            "3\n",
            "Epoch: 0347 loss_train: 1.0035 acc_train: 0.7643 loss_val: 0.8784 acc_val: 0.8280 time: 0.0440s\n",
            "4\n",
            "Epoch: 0348 loss_train: 0.9904 acc_train: 0.7357 loss_val: 0.8753 acc_val: 0.8220 time: 0.0463s\n",
            "5\n",
            "Epoch: 0349 loss_train: 0.9810 acc_train: 0.7714 loss_val: 0.8747 acc_val: 0.8180 time: 0.0441s\n",
            "6\n",
            "Epoch: 0350 loss_train: 0.9297 acc_train: 0.8286 loss_val: 0.8702 acc_val: 0.8160 time: 0.0441s\n",
            "7\n",
            "Epoch: 0351 loss_train: 1.0158 acc_train: 0.8071 loss_val: 0.8673 acc_val: 0.8200 time: 0.0445s\n",
            "8\n",
            "Epoch: 0352 loss_train: 0.9704 acc_train: 0.7786 loss_val: 0.8671 acc_val: 0.8160 time: 0.0446s\n",
            "9\n",
            "Epoch: 0353 loss_train: 0.9954 acc_train: 0.7786 loss_val: 0.8691 acc_val: 0.8180 time: 0.0456s\n",
            "10\n",
            "Epoch: 0354 loss_train: 0.9647 acc_train: 0.8143 loss_val: 0.8678 acc_val: 0.8180 time: 0.0441s\n",
            "11\n",
            "Epoch: 0355 loss_train: 0.9721 acc_train: 0.7786 loss_val: 0.8669 acc_val: 0.8200 time: 0.0440s\n",
            "12\n",
            "Epoch: 0356 loss_train: 0.9453 acc_train: 0.7857 loss_val: 0.8637 acc_val: 0.8240 time: 0.0442s\n",
            "13\n",
            "Epoch: 0357 loss_train: 0.9848 acc_train: 0.7500 loss_val: 0.8604 acc_val: 0.8300 time: 0.0440s\n",
            "0\n",
            "Epoch: 0358 loss_train: 1.0286 acc_train: 0.7286 loss_val: 0.8592 acc_val: 0.8280 time: 0.0456s\n",
            "0\n",
            "Epoch: 0359 loss_train: 0.9404 acc_train: 0.8143 loss_val: 0.8585 acc_val: 0.8280 time: 0.0436s\n",
            "0\n",
            "Epoch: 0360 loss_train: 0.9800 acc_train: 0.7571 loss_val: 0.8609 acc_val: 0.8180 time: 0.0448s\n",
            "0\n",
            "Epoch: 0361 loss_train: 0.9927 acc_train: 0.7571 loss_val: 0.8638 acc_val: 0.8180 time: 0.0440s\n",
            "1\n",
            "Epoch: 0362 loss_train: 0.9865 acc_train: 0.7429 loss_val: 0.8657 acc_val: 0.8140 time: 0.0468s\n",
            "2\n",
            "Epoch: 0363 loss_train: 1.0044 acc_train: 0.7786 loss_val: 0.8674 acc_val: 0.8140 time: 0.0463s\n",
            "3\n",
            "Epoch: 0364 loss_train: 0.9871 acc_train: 0.8143 loss_val: 0.8657 acc_val: 0.8160 time: 0.0459s\n",
            "4\n",
            "Epoch: 0365 loss_train: 0.9794 acc_train: 0.7786 loss_val: 0.8661 acc_val: 0.8180 time: 0.0440s\n",
            "5\n",
            "Epoch: 0366 loss_train: 0.9436 acc_train: 0.8214 loss_val: 0.8666 acc_val: 0.8180 time: 0.0442s\n",
            "6\n",
            "Epoch: 0367 loss_train: 0.9954 acc_train: 0.8357 loss_val: 0.8692 acc_val: 0.8260 time: 0.0440s\n",
            "7\n",
            "Epoch: 0368 loss_train: 0.9641 acc_train: 0.7786 loss_val: 0.8700 acc_val: 0.8240 time: 0.0452s\n",
            "8\n",
            "Epoch: 0369 loss_train: 0.9209 acc_train: 0.7857 loss_val: 0.8663 acc_val: 0.8240 time: 0.0440s\n",
            "9\n",
            "Epoch: 0370 loss_train: 0.9852 acc_train: 0.7571 loss_val: 0.8642 acc_val: 0.8200 time: 0.0443s\n",
            "10\n",
            "Epoch: 0371 loss_train: 0.9957 acc_train: 0.7429 loss_val: 0.8598 acc_val: 0.8220 time: 0.0441s\n",
            "11\n",
            "Epoch: 0372 loss_train: 0.9845 acc_train: 0.7929 loss_val: 0.8597 acc_val: 0.8220 time: 0.0452s\n",
            "12\n",
            "Epoch: 0373 loss_train: 0.9348 acc_train: 0.7857 loss_val: 0.8623 acc_val: 0.8220 time: 0.0449s\n",
            "13\n",
            "Epoch: 0374 loss_train: 0.9707 acc_train: 0.7857 loss_val: 0.8643 acc_val: 0.8260 time: 0.0464s\n",
            "14\n",
            "Epoch: 0375 loss_train: 0.9532 acc_train: 0.7500 loss_val: 0.8665 acc_val: 0.8220 time: 0.0440s\n",
            "15\n",
            "Epoch: 0376 loss_train: 0.9717 acc_train: 0.7643 loss_val: 0.8672 acc_val: 0.8220 time: 0.0442s\n",
            "16\n",
            "Epoch: 0377 loss_train: 0.9297 acc_train: 0.7786 loss_val: 0.8649 acc_val: 0.8240 time: 0.0444s\n",
            "17\n",
            "Epoch: 0378 loss_train: 0.9098 acc_train: 0.7929 loss_val: 0.8568 acc_val: 0.8260 time: 0.0466s\n",
            "18\n",
            "Epoch: 0379 loss_train: 0.9638 acc_train: 0.7929 loss_val: 0.8503 acc_val: 0.8240 time: 0.0438s\n",
            "0\n",
            "Epoch: 0380 loss_train: 0.9682 acc_train: 0.7857 loss_val: 0.8469 acc_val: 0.8160 time: 0.0436s\n",
            "0\n",
            "Epoch: 0381 loss_train: 0.9722 acc_train: 0.7357 loss_val: 0.8443 acc_val: 0.8140 time: 0.0439s\n",
            "0\n",
            "Epoch: 0382 loss_train: 0.9456 acc_train: 0.7500 loss_val: 0.8444 acc_val: 0.8160 time: 0.0439s\n",
            "0\n",
            "Epoch: 0383 loss_train: 0.9551 acc_train: 0.8357 loss_val: 0.8477 acc_val: 0.8200 time: 0.0471s\n",
            "1\n",
            "Epoch: 0384 loss_train: 0.9730 acc_train: 0.8000 loss_val: 0.8530 acc_val: 0.8180 time: 0.0453s\n",
            "2\n",
            "Epoch: 0385 loss_train: 0.9627 acc_train: 0.7429 loss_val: 0.8589 acc_val: 0.8220 time: 0.0450s\n",
            "3\n",
            "Epoch: 0386 loss_train: 1.0037 acc_train: 0.7643 loss_val: 0.8639 acc_val: 0.8180 time: 0.0443s\n",
            "4\n",
            "Epoch: 0387 loss_train: 0.9414 acc_train: 0.8071 loss_val: 0.8634 acc_val: 0.8260 time: 0.0460s\n",
            "5\n",
            "Epoch: 0388 loss_train: 0.9555 acc_train: 0.8000 loss_val: 0.8573 acc_val: 0.8320 time: 0.0455s\n",
            "6\n",
            "Epoch: 0389 loss_train: 0.9890 acc_train: 0.8286 loss_val: 0.8491 acc_val: 0.8320 time: 0.0441s\n",
            "0\n",
            "Epoch: 0390 loss_train: 0.9504 acc_train: 0.8286 loss_val: 0.8406 acc_val: 0.8300 time: 0.0446s\n",
            "0\n",
            "Epoch: 0391 loss_train: 0.9707 acc_train: 0.7357 loss_val: 0.8347 acc_val: 0.8240 time: 0.0440s\n",
            "0\n",
            "Epoch: 0392 loss_train: 0.9830 acc_train: 0.7714 loss_val: 0.8354 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0393 loss_train: 1.0071 acc_train: 0.7643 loss_val: 0.8424 acc_val: 0.8140 time: 0.0463s\n",
            "1\n",
            "Epoch: 0394 loss_train: 0.9808 acc_train: 0.7571 loss_val: 0.8489 acc_val: 0.8160 time: 0.0444s\n",
            "2\n",
            "Epoch: 0395 loss_train: 0.9891 acc_train: 0.7643 loss_val: 0.8568 acc_val: 0.8100 time: 0.0471s\n",
            "3\n",
            "Epoch: 0396 loss_train: 0.9755 acc_train: 0.7643 loss_val: 0.8604 acc_val: 0.8140 time: 0.0456s\n",
            "4\n",
            "Epoch: 0397 loss_train: 0.9768 acc_train: 0.8429 loss_val: 0.8591 acc_val: 0.8240 time: 0.0452s\n",
            "5\n",
            "Epoch: 0398 loss_train: 0.9230 acc_train: 0.8643 loss_val: 0.8566 acc_val: 0.8320 time: 0.0451s\n",
            "6\n",
            "Epoch: 0399 loss_train: 0.9323 acc_train: 0.8000 loss_val: 0.8517 acc_val: 0.8300 time: 0.0445s\n",
            "0\n",
            "Epoch: 0400 loss_train: 0.9817 acc_train: 0.7214 loss_val: 0.8426 acc_val: 0.8300 time: 0.0441s\n",
            "1\n",
            "Epoch: 0401 loss_train: 0.9250 acc_train: 0.8643 loss_val: 0.8345 acc_val: 0.8240 time: 0.0441s\n",
            "2\n",
            "Epoch: 0402 loss_train: 0.9923 acc_train: 0.7214 loss_val: 0.8315 acc_val: 0.8260 time: 0.0441s\n",
            "0\n",
            "Epoch: 0403 loss_train: 0.9845 acc_train: 0.8071 loss_val: 0.8363 acc_val: 0.8160 time: 0.0453s\n",
            "0\n",
            "Epoch: 0404 loss_train: 0.9569 acc_train: 0.7857 loss_val: 0.8451 acc_val: 0.8140 time: 0.0475s\n",
            "1\n",
            "Epoch: 0405 loss_train: 0.9551 acc_train: 0.8071 loss_val: 0.8504 acc_val: 0.8160 time: 0.0445s\n",
            "2\n",
            "Epoch: 0406 loss_train: 0.9464 acc_train: 0.8429 loss_val: 0.8526 acc_val: 0.8200 time: 0.0441s\n",
            "3\n",
            "Epoch: 0407 loss_train: 0.9368 acc_train: 0.8643 loss_val: 0.8523 acc_val: 0.8200 time: 0.0443s\n",
            "4\n",
            "Epoch: 0408 loss_train: 0.9830 acc_train: 0.7643 loss_val: 0.8495 acc_val: 0.8280 time: 0.0454s\n",
            "5\n",
            "Epoch: 0409 loss_train: 0.9754 acc_train: 0.7714 loss_val: 0.8462 acc_val: 0.8280 time: 0.0445s\n",
            "6\n",
            "Epoch: 0410 loss_train: 0.9770 acc_train: 0.7214 loss_val: 0.8439 acc_val: 0.8220 time: 0.0445s\n",
            "7\n",
            "Epoch: 0411 loss_train: 0.9978 acc_train: 0.7714 loss_val: 0.8445 acc_val: 0.8200 time: 0.0487s\n",
            "8\n",
            "Epoch: 0412 loss_train: 0.9249 acc_train: 0.8000 loss_val: 0.8435 acc_val: 0.8200 time: 0.0445s\n",
            "9\n",
            "Epoch: 0413 loss_train: 0.9404 acc_train: 0.7857 loss_val: 0.8436 acc_val: 0.8160 time: 0.0445s\n",
            "10\n",
            "Epoch: 0414 loss_train: 0.9493 acc_train: 0.8143 loss_val: 0.8444 acc_val: 0.8140 time: 0.0445s\n",
            "11\n",
            "Epoch: 0415 loss_train: 0.9206 acc_train: 0.8071 loss_val: 0.8461 acc_val: 0.8220 time: 0.0442s\n",
            "12\n",
            "Epoch: 0416 loss_train: 0.8924 acc_train: 0.8500 loss_val: 0.8482 acc_val: 0.8260 time: 0.0441s\n",
            "13\n",
            "Epoch: 0417 loss_train: 0.9544 acc_train: 0.8500 loss_val: 0.8483 acc_val: 0.8260 time: 0.0441s\n",
            "14\n",
            "Epoch: 0418 loss_train: 0.9745 acc_train: 0.8071 loss_val: 0.8462 acc_val: 0.8260 time: 0.0449s\n",
            "15\n",
            "Epoch: 0419 loss_train: 0.9417 acc_train: 0.8357 loss_val: 0.8389 acc_val: 0.8240 time: 0.0457s\n",
            "16\n",
            "Epoch: 0420 loss_train: 0.9552 acc_train: 0.8071 loss_val: 0.8335 acc_val: 0.8240 time: 0.0442s\n",
            "17\n",
            "Epoch: 0421 loss_train: 0.9648 acc_train: 0.7286 loss_val: 0.8313 acc_val: 0.8160 time: 0.0443s\n",
            "18\n",
            "Epoch: 0422 loss_train: 0.9779 acc_train: 0.8286 loss_val: 0.8304 acc_val: 0.8180 time: 0.0440s\n",
            "0\n",
            "Epoch: 0423 loss_train: 0.9533 acc_train: 0.8357 loss_val: 0.8304 acc_val: 0.8140 time: 0.0448s\n",
            "0\n",
            "Epoch: 0424 loss_train: 0.9721 acc_train: 0.8143 loss_val: 0.8314 acc_val: 0.8140 time: 0.0435s\n",
            "0\n",
            "Epoch: 0425 loss_train: 0.9143 acc_train: 0.8286 loss_val: 0.8330 acc_val: 0.8180 time: 0.0445s\n",
            "1\n",
            "Epoch: 0426 loss_train: 0.9469 acc_train: 0.8214 loss_val: 0.8362 acc_val: 0.8180 time: 0.0495s\n",
            "2\n",
            "Epoch: 0427 loss_train: 0.9485 acc_train: 0.8357 loss_val: 0.8403 acc_val: 0.8160 time: 0.0446s\n",
            "3\n",
            "Epoch: 0428 loss_train: 0.9845 acc_train: 0.7714 loss_val: 0.8469 acc_val: 0.8260 time: 0.0463s\n",
            "4\n",
            "Epoch: 0429 loss_train: 0.9198 acc_train: 0.8143 loss_val: 0.8505 acc_val: 0.8300 time: 0.0453s\n",
            "5\n",
            "Epoch: 0430 loss_train: 0.9673 acc_train: 0.7857 loss_val: 0.8519 acc_val: 0.8280 time: 0.0454s\n",
            "6\n",
            "Epoch: 0431 loss_train: 1.0042 acc_train: 0.7429 loss_val: 0.8509 acc_val: 0.8140 time: 0.0447s\n",
            "7\n",
            "Epoch: 0432 loss_train: 0.9425 acc_train: 0.7643 loss_val: 0.8459 acc_val: 0.8080 time: 0.0448s\n",
            "8\n",
            "Epoch: 0433 loss_train: 0.9676 acc_train: 0.7857 loss_val: 0.8361 acc_val: 0.8100 time: 0.0460s\n",
            "9\n",
            "Epoch: 0434 loss_train: 0.9556 acc_train: 0.8214 loss_val: 0.8265 acc_val: 0.8140 time: 0.0452s\n",
            "10\n",
            "Epoch: 0435 loss_train: 0.9772 acc_train: 0.8000 loss_val: 0.8213 acc_val: 0.8160 time: 0.0438s\n",
            "0\n",
            "Epoch: 0436 loss_train: 0.9424 acc_train: 0.8071 loss_val: 0.8223 acc_val: 0.8240 time: 0.0444s\n",
            "0\n",
            "Epoch: 0437 loss_train: 0.9046 acc_train: 0.7929 loss_val: 0.8260 acc_val: 0.8280 time: 0.0455s\n",
            "1\n",
            "Epoch: 0438 loss_train: 0.9427 acc_train: 0.7857 loss_val: 0.8323 acc_val: 0.8280 time: 0.0450s\n",
            "2\n",
            "Epoch: 0439 loss_train: 0.9316 acc_train: 0.8071 loss_val: 0.8387 acc_val: 0.8240 time: 0.0443s\n",
            "3\n",
            "Epoch: 0440 loss_train: 0.9979 acc_train: 0.7214 loss_val: 0.8443 acc_val: 0.8220 time: 0.0442s\n",
            "4\n",
            "Epoch: 0441 loss_train: 0.9703 acc_train: 0.7571 loss_val: 0.8475 acc_val: 0.8140 time: 0.0483s\n",
            "5\n",
            "Epoch: 0442 loss_train: 0.9389 acc_train: 0.7857 loss_val: 0.8457 acc_val: 0.8100 time: 0.0445s\n",
            "6\n",
            "Epoch: 0443 loss_train: 0.9321 acc_train: 0.7929 loss_val: 0.8441 acc_val: 0.8140 time: 0.0447s\n",
            "7\n",
            "Epoch: 0444 loss_train: 0.9510 acc_train: 0.8071 loss_val: 0.8370 acc_val: 0.8140 time: 0.0447s\n",
            "8\n",
            "Epoch: 0445 loss_train: 0.9180 acc_train: 0.7929 loss_val: 0.8287 acc_val: 0.8180 time: 0.0440s\n",
            "9\n",
            "Epoch: 0446 loss_train: 0.9512 acc_train: 0.7214 loss_val: 0.8211 acc_val: 0.8180 time: 0.0445s\n",
            "10\n",
            "Epoch: 0447 loss_train: 0.9361 acc_train: 0.7857 loss_val: 0.8188 acc_val: 0.8240 time: 0.0453s\n",
            "0\n",
            "Epoch: 0448 loss_train: 0.9333 acc_train: 0.8143 loss_val: 0.8180 acc_val: 0.8240 time: 0.0446s\n",
            "0\n",
            "Epoch: 0449 loss_train: 0.9292 acc_train: 0.8214 loss_val: 0.8192 acc_val: 0.8300 time: 0.0439s\n",
            "0\n",
            "Epoch: 0450 loss_train: 0.9379 acc_train: 0.7500 loss_val: 0.8262 acc_val: 0.8260 time: 0.0442s\n",
            "1\n",
            "Epoch: 0451 loss_train: 0.9633 acc_train: 0.7571 loss_val: 0.8343 acc_val: 0.8240 time: 0.0446s\n",
            "2\n",
            "Epoch: 0452 loss_train: 0.9265 acc_train: 0.8000 loss_val: 0.8440 acc_val: 0.8160 time: 0.0453s\n",
            "3\n",
            "Epoch: 0453 loss_train: 0.9699 acc_train: 0.7929 loss_val: 0.8505 acc_val: 0.8080 time: 0.0454s\n",
            "4\n",
            "Epoch: 0454 loss_train: 0.9199 acc_train: 0.7929 loss_val: 0.8510 acc_val: 0.8100 time: 0.0469s\n",
            "5\n",
            "Epoch: 0455 loss_train: 0.9366 acc_train: 0.7929 loss_val: 0.8459 acc_val: 0.8120 time: 0.0454s\n",
            "6\n",
            "Epoch: 0456 loss_train: 0.9031 acc_train: 0.8000 loss_val: 0.8363 acc_val: 0.8160 time: 0.0463s\n",
            "7\n",
            "Epoch: 0457 loss_train: 0.9272 acc_train: 0.8143 loss_val: 0.8285 acc_val: 0.8240 time: 0.0442s\n",
            "8\n",
            "Epoch: 0458 loss_train: 0.8748 acc_train: 0.8214 loss_val: 0.8205 acc_val: 0.8300 time: 0.0456s\n",
            "9\n",
            "Epoch: 0459 loss_train: 0.9476 acc_train: 0.8071 loss_val: 0.8161 acc_val: 0.8300 time: 0.0442s\n",
            "10\n",
            "Epoch: 0460 loss_train: 0.8927 acc_train: 0.8071 loss_val: 0.8146 acc_val: 0.8220 time: 0.0441s\n",
            "0\n",
            "Epoch: 0461 loss_train: 0.9511 acc_train: 0.7714 loss_val: 0.8175 acc_val: 0.8240 time: 0.0457s\n",
            "0\n",
            "Epoch: 0462 loss_train: 0.9252 acc_train: 0.8143 loss_val: 0.8214 acc_val: 0.8220 time: 0.0456s\n",
            "1\n",
            "Epoch: 0463 loss_train: 0.9553 acc_train: 0.8071 loss_val: 0.8273 acc_val: 0.8140 time: 0.0451s\n",
            "2\n",
            "Epoch: 0464 loss_train: 0.9078 acc_train: 0.8571 loss_val: 0.8304 acc_val: 0.8200 time: 0.0444s\n",
            "3\n",
            "Epoch: 0465 loss_train: 0.9449 acc_train: 0.8571 loss_val: 0.8312 acc_val: 0.8200 time: 0.0442s\n",
            "4\n",
            "Epoch: 0466 loss_train: 0.9380 acc_train: 0.7786 loss_val: 0.8316 acc_val: 0.8260 time: 0.0441s\n",
            "5\n",
            "Epoch: 0467 loss_train: 0.9485 acc_train: 0.7786 loss_val: 0.8288 acc_val: 0.8260 time: 0.0486s\n",
            "6\n",
            "Epoch: 0468 loss_train: 0.9647 acc_train: 0.7286 loss_val: 0.8244 acc_val: 0.8240 time: 0.0468s\n",
            "7\n",
            "Epoch: 0469 loss_train: 0.8789 acc_train: 0.8143 loss_val: 0.8173 acc_val: 0.8200 time: 0.0443s\n",
            "8\n",
            "Epoch: 0470 loss_train: 0.9588 acc_train: 0.7500 loss_val: 0.8144 acc_val: 0.8200 time: 0.0446s\n",
            "9\n",
            "Epoch: 0471 loss_train: 0.9325 acc_train: 0.7643 loss_val: 0.8144 acc_val: 0.8220 time: 0.0447s\n",
            "0\n",
            "Epoch: 0472 loss_train: 0.9146 acc_train: 0.8143 loss_val: 0.8143 acc_val: 0.8240 time: 0.0439s\n",
            "0\n",
            "Epoch: 0473 loss_train: 0.9697 acc_train: 0.7571 loss_val: 0.8177 acc_val: 0.8220 time: 0.0451s\n",
            "0\n",
            "Epoch: 0474 loss_train: 0.8482 acc_train: 0.8286 loss_val: 0.8152 acc_val: 0.8220 time: 0.0442s\n",
            "1\n",
            "Epoch: 0475 loss_train: 0.9415 acc_train: 0.7714 loss_val: 0.8145 acc_val: 0.8200 time: 0.0443s\n",
            "2\n",
            "Epoch: 0476 loss_train: 0.9197 acc_train: 0.7786 loss_val: 0.8145 acc_val: 0.8200 time: 0.0438s\n",
            "3\n",
            "Epoch: 0477 loss_train: 0.8836 acc_train: 0.8286 loss_val: 0.8125 acc_val: 0.8160 time: 0.0443s\n",
            "4\n",
            "Epoch: 0478 loss_train: 0.9161 acc_train: 0.7714 loss_val: 0.8130 acc_val: 0.8200 time: 0.0465s\n",
            "0\n",
            "Epoch: 0479 loss_train: 0.9239 acc_train: 0.7857 loss_val: 0.8170 acc_val: 0.8220 time: 0.0441s\n",
            "1\n",
            "Epoch: 0480 loss_train: 0.9205 acc_train: 0.7714 loss_val: 0.8235 acc_val: 0.8240 time: 0.0447s\n",
            "2\n",
            "Epoch: 0481 loss_train: 0.9402 acc_train: 0.7929 loss_val: 0.8274 acc_val: 0.8200 time: 0.0442s\n",
            "3\n",
            "Epoch: 0482 loss_train: 0.9397 acc_train: 0.8214 loss_val: 0.8278 acc_val: 0.8220 time: 0.0439s\n",
            "4\n",
            "Epoch: 0483 loss_train: 0.9158 acc_train: 0.8286 loss_val: 0.8247 acc_val: 0.8180 time: 0.0456s\n",
            "5\n",
            "Epoch: 0484 loss_train: 0.9064 acc_train: 0.8214 loss_val: 0.8228 acc_val: 0.8180 time: 0.0441s\n",
            "6\n",
            "Epoch: 0485 loss_train: 0.9354 acc_train: 0.8143 loss_val: 0.8165 acc_val: 0.8200 time: 0.0449s\n",
            "7\n",
            "Epoch: 0486 loss_train: 0.9384 acc_train: 0.8500 loss_val: 0.8096 acc_val: 0.8260 time: 0.0440s\n",
            "8\n",
            "Epoch: 0487 loss_train: 0.9301 acc_train: 0.8000 loss_val: 0.8037 acc_val: 0.8260 time: 0.0435s\n",
            "0\n",
            "Epoch: 0488 loss_train: 0.9405 acc_train: 0.8071 loss_val: 0.8027 acc_val: 0.8260 time: 0.0479s\n",
            "0\n",
            "Epoch: 0489 loss_train: 0.9177 acc_train: 0.8429 loss_val: 0.8039 acc_val: 0.8200 time: 0.0487s\n",
            "0\n",
            "Epoch: 0490 loss_train: 0.9045 acc_train: 0.8357 loss_val: 0.8068 acc_val: 0.8160 time: 0.0453s\n",
            "1\n",
            "Epoch: 0491 loss_train: 0.8988 acc_train: 0.8714 loss_val: 0.8101 acc_val: 0.8160 time: 0.0446s\n",
            "2\n",
            "Epoch: 0492 loss_train: 0.9091 acc_train: 0.8500 loss_val: 0.8106 acc_val: 0.8240 time: 0.0440s\n",
            "3\n",
            "Epoch: 0493 loss_train: 0.9391 acc_train: 0.7857 loss_val: 0.8168 acc_val: 0.8240 time: 0.0453s\n",
            "4\n",
            "Epoch: 0494 loss_train: 0.9056 acc_train: 0.7929 loss_val: 0.8188 acc_val: 0.8200 time: 0.0444s\n",
            "5\n",
            "Epoch: 0495 loss_train: 0.8723 acc_train: 0.7929 loss_val: 0.8129 acc_val: 0.8240 time: 0.0441s\n",
            "6\n",
            "Epoch: 0496 loss_train: 0.9016 acc_train: 0.7929 loss_val: 0.8051 acc_val: 0.8280 time: 0.0440s\n",
            "7\n",
            "Epoch: 0497 loss_train: 0.9158 acc_train: 0.8357 loss_val: 0.7996 acc_val: 0.8320 time: 0.0441s\n",
            "8\n",
            "Epoch: 0498 loss_train: 0.9771 acc_train: 0.7929 loss_val: 0.7978 acc_val: 0.8340 time: 0.0475s\n",
            "0\n",
            "Epoch: 0499 loss_train: 0.9425 acc_train: 0.7786 loss_val: 0.7961 acc_val: 0.8280 time: 0.0437s\n",
            "0\n",
            "Epoch: 0500 loss_train: 0.9138 acc_train: 0.7857 loss_val: 0.7987 acc_val: 0.8280 time: 0.0438s\n",
            "0\n",
            "Epoch: 0501 loss_train: 0.9429 acc_train: 0.7786 loss_val: 0.8079 acc_val: 0.8300 time: 0.0440s\n",
            "1\n",
            "Epoch: 0502 loss_train: 0.9294 acc_train: 0.8286 loss_val: 0.8176 acc_val: 0.8240 time: 0.0444s\n",
            "2\n",
            "Epoch: 0503 loss_train: 0.9360 acc_train: 0.8357 loss_val: 0.8243 acc_val: 0.8240 time: 0.0452s\n",
            "3\n",
            "Epoch: 0504 loss_train: 0.9841 acc_train: 0.7214 loss_val: 0.8275 acc_val: 0.8220 time: 0.0446s\n",
            "4\n",
            "Epoch: 0505 loss_train: 0.9348 acc_train: 0.8143 loss_val: 0.8199 acc_val: 0.8220 time: 0.0442s\n",
            "5\n",
            "Epoch: 0506 loss_train: 0.8940 acc_train: 0.8571 loss_val: 0.8074 acc_val: 0.8200 time: 0.0454s\n",
            "6\n",
            "Epoch: 0507 loss_train: 0.9307 acc_train: 0.7929 loss_val: 0.7996 acc_val: 0.8300 time: 0.0442s\n",
            "7\n",
            "Epoch: 0508 loss_train: 0.9234 acc_train: 0.7786 loss_val: 0.7957 acc_val: 0.8360 time: 0.0450s\n",
            "8\n",
            "Epoch: 0509 loss_train: 0.9384 acc_train: 0.8214 loss_val: 0.7939 acc_val: 0.8400 time: 0.0446s\n",
            "0\n",
            "Epoch: 0510 loss_train: 0.9162 acc_train: 0.8071 loss_val: 0.7936 acc_val: 0.8340 time: 0.0450s\n",
            "0\n",
            "Epoch: 0511 loss_train: 0.9661 acc_train: 0.8071 loss_val: 0.7979 acc_val: 0.8280 time: 0.0459s\n",
            "0\n",
            "Epoch: 0512 loss_train: 0.9323 acc_train: 0.8000 loss_val: 0.8079 acc_val: 0.8280 time: 0.0455s\n",
            "1\n",
            "Epoch: 0513 loss_train: 0.9282 acc_train: 0.7571 loss_val: 0.8157 acc_val: 0.8280 time: 0.0466s\n",
            "2\n",
            "Epoch: 0514 loss_train: 0.9260 acc_train: 0.8071 loss_val: 0.8196 acc_val: 0.8240 time: 0.0441s\n",
            "3\n",
            "Epoch: 0515 loss_train: 0.9872 acc_train: 0.7714 loss_val: 0.8224 acc_val: 0.8220 time: 0.0441s\n",
            "4\n",
            "Epoch: 0516 loss_train: 0.9340 acc_train: 0.7214 loss_val: 0.8204 acc_val: 0.8160 time: 0.0444s\n",
            "5\n",
            "Epoch: 0517 loss_train: 0.8989 acc_train: 0.8429 loss_val: 0.8165 acc_val: 0.8180 time: 0.0441s\n",
            "6\n",
            "Epoch: 0518 loss_train: 0.8837 acc_train: 0.8286 loss_val: 0.8071 acc_val: 0.8200 time: 0.0468s\n",
            "7\n",
            "Epoch: 0519 loss_train: 0.9415 acc_train: 0.7500 loss_val: 0.8007 acc_val: 0.8220 time: 0.0443s\n",
            "8\n",
            "Epoch: 0520 loss_train: 0.9072 acc_train: 0.8071 loss_val: 0.7993 acc_val: 0.8200 time: 0.0442s\n",
            "9\n",
            "Epoch: 0521 loss_train: 0.9223 acc_train: 0.7429 loss_val: 0.8010 acc_val: 0.8180 time: 0.0447s\n",
            "10\n",
            "Epoch: 0522 loss_train: 0.9676 acc_train: 0.7857 loss_val: 0.8031 acc_val: 0.8200 time: 0.0445s\n",
            "11\n",
            "Epoch: 0523 loss_train: 0.8834 acc_train: 0.8286 loss_val: 0.8052 acc_val: 0.8180 time: 0.0459s\n",
            "12\n",
            "Epoch: 0524 loss_train: 0.9227 acc_train: 0.8500 loss_val: 0.8100 acc_val: 0.8220 time: 0.0445s\n",
            "13\n",
            "Epoch: 0525 loss_train: 0.9214 acc_train: 0.8143 loss_val: 0.8147 acc_val: 0.8180 time: 0.0443s\n",
            "14\n",
            "Epoch: 0526 loss_train: 0.9675 acc_train: 0.8000 loss_val: 0.8176 acc_val: 0.8260 time: 0.0443s\n",
            "15\n",
            "Epoch: 0527 loss_train: 0.9165 acc_train: 0.8000 loss_val: 0.8156 acc_val: 0.8340 time: 0.0441s\n",
            "16\n",
            "Epoch: 0528 loss_train: 0.8950 acc_train: 0.8357 loss_val: 0.8122 acc_val: 0.8280 time: 0.0454s\n",
            "17\n",
            "Epoch: 0529 loss_train: 0.9222 acc_train: 0.7714 loss_val: 0.8058 acc_val: 0.8280 time: 0.0442s\n",
            "18\n",
            "Epoch: 0530 loss_train: 0.9014 acc_train: 0.7714 loss_val: 0.7997 acc_val: 0.8220 time: 0.0448s\n",
            "19\n",
            "Epoch: 0531 loss_train: 0.9045 acc_train: 0.8071 loss_val: 0.7934 acc_val: 0.8240 time: 0.0473s\n",
            "20\n",
            "Epoch: 0532 loss_train: 0.9368 acc_train: 0.8143 loss_val: 0.7910 acc_val: 0.8240 time: 0.0459s\n",
            "0\n",
            "Epoch: 0533 loss_train: 0.9311 acc_train: 0.7929 loss_val: 0.7931 acc_val: 0.8240 time: 0.0449s\n",
            "0\n",
            "Epoch: 0534 loss_train: 0.9549 acc_train: 0.7357 loss_val: 0.8005 acc_val: 0.8140 time: 0.0450s\n",
            "1\n",
            "Epoch: 0535 loss_train: 0.9359 acc_train: 0.8000 loss_val: 0.8097 acc_val: 0.8200 time: 0.0443s\n",
            "2\n",
            "Epoch: 0536 loss_train: 0.9288 acc_train: 0.8000 loss_val: 0.8170 acc_val: 0.8180 time: 0.0445s\n",
            "3\n",
            "Epoch: 0537 loss_train: 0.9210 acc_train: 0.7929 loss_val: 0.8208 acc_val: 0.8220 time: 0.0457s\n",
            "4\n",
            "Epoch: 0538 loss_train: 0.8885 acc_train: 0.8429 loss_val: 0.8174 acc_val: 0.8320 time: 0.0451s\n",
            "5\n",
            "Epoch: 0539 loss_train: 0.9135 acc_train: 0.8214 loss_val: 0.8091 acc_val: 0.8300 time: 0.0451s\n",
            "6\n",
            "Epoch: 0540 loss_train: 0.8977 acc_train: 0.8143 loss_val: 0.8019 acc_val: 0.8280 time: 0.0442s\n",
            "7\n",
            "Epoch: 0541 loss_train: 0.9506 acc_train: 0.7714 loss_val: 0.7978 acc_val: 0.8280 time: 0.0440s\n",
            "8\n",
            "Epoch: 0542 loss_train: 0.9157 acc_train: 0.7786 loss_val: 0.7959 acc_val: 0.8280 time: 0.0440s\n",
            "9\n",
            "Epoch: 0543 loss_train: 0.9390 acc_train: 0.7857 loss_val: 0.7949 acc_val: 0.8260 time: 0.0455s\n",
            "10\n",
            "Epoch: 0544 loss_train: 0.9407 acc_train: 0.7643 loss_val: 0.7970 acc_val: 0.8220 time: 0.0446s\n",
            "11\n",
            "Epoch: 0545 loss_train: 0.9315 acc_train: 0.8071 loss_val: 0.8024 acc_val: 0.8240 time: 0.0472s\n",
            "12\n",
            "Epoch: 0546 loss_train: 0.9520 acc_train: 0.8357 loss_val: 0.8098 acc_val: 0.8220 time: 0.0466s\n",
            "13\n",
            "Epoch: 0547 loss_train: 0.9322 acc_train: 0.8143 loss_val: 0.8127 acc_val: 0.8280 time: 0.0445s\n",
            "14\n",
            "Epoch: 0548 loss_train: 0.9139 acc_train: 0.7929 loss_val: 0.8134 acc_val: 0.8260 time: 0.0464s\n",
            "15\n",
            "Epoch: 0549 loss_train: 0.9360 acc_train: 0.7643 loss_val: 0.8115 acc_val: 0.8300 time: 0.0452s\n",
            "16\n",
            "Epoch: 0550 loss_train: 0.9042 acc_train: 0.7929 loss_val: 0.8109 acc_val: 0.8260 time: 0.0435s\n",
            "17\n",
            "Epoch: 0551 loss_train: 0.9288 acc_train: 0.8286 loss_val: 0.8083 acc_val: 0.8200 time: 0.0440s\n",
            "18\n",
            "Epoch: 0552 loss_train: 0.9236 acc_train: 0.7929 loss_val: 0.8030 acc_val: 0.8160 time: 0.0446s\n",
            "19\n",
            "Epoch: 0553 loss_train: 0.9409 acc_train: 0.7643 loss_val: 0.7954 acc_val: 0.8180 time: 0.0477s\n",
            "20\n",
            "Epoch: 0554 loss_train: 0.9087 acc_train: 0.8286 loss_val: 0.7917 acc_val: 0.8220 time: 0.0464s\n",
            "21\n",
            "Epoch: 0555 loss_train: 0.9051 acc_train: 0.8143 loss_val: 0.7906 acc_val: 0.8240 time: 0.0455s\n",
            "22\n",
            "Epoch: 0556 loss_train: 0.8790 acc_train: 0.8000 loss_val: 0.7932 acc_val: 0.8260 time: 0.0437s\n",
            "0\n",
            "Epoch: 0557 loss_train: 0.9086 acc_train: 0.8357 loss_val: 0.7968 acc_val: 0.8280 time: 0.0442s\n",
            "1\n",
            "Epoch: 0558 loss_train: 0.9277 acc_train: 0.7857 loss_val: 0.8005 acc_val: 0.8300 time: 0.0455s\n",
            "2\n",
            "Epoch: 0559 loss_train: 0.9190 acc_train: 0.8071 loss_val: 0.8057 acc_val: 0.8300 time: 0.0441s\n",
            "3\n",
            "Epoch: 0560 loss_train: 0.9301 acc_train: 0.8214 loss_val: 0.8081 acc_val: 0.8300 time: 0.0439s\n",
            "4\n",
            "Epoch: 0561 loss_train: 0.9052 acc_train: 0.8000 loss_val: 0.8067 acc_val: 0.8260 time: 0.0439s\n",
            "5\n",
            "Epoch: 0562 loss_train: 0.8912 acc_train: 0.8000 loss_val: 0.8022 acc_val: 0.8300 time: 0.0442s\n",
            "6\n",
            "Epoch: 0563 loss_train: 0.9010 acc_train: 0.7714 loss_val: 0.7969 acc_val: 0.8240 time: 0.0450s\n",
            "7\n",
            "Epoch: 0564 loss_train: 0.9048 acc_train: 0.7929 loss_val: 0.7949 acc_val: 0.8240 time: 0.0443s\n",
            "8\n",
            "Epoch: 0565 loss_train: 0.9301 acc_train: 0.8071 loss_val: 0.7941 acc_val: 0.8300 time: 0.0447s\n",
            "9\n",
            "Epoch: 0566 loss_train: 0.9275 acc_train: 0.8214 loss_val: 0.7949 acc_val: 0.8260 time: 0.0475s\n",
            "10\n",
            "Epoch: 0567 loss_train: 0.9029 acc_train: 0.8143 loss_val: 0.7966 acc_val: 0.8280 time: 0.0444s\n",
            "11\n",
            "Epoch: 0568 loss_train: 0.8941 acc_train: 0.8357 loss_val: 0.7976 acc_val: 0.8240 time: 0.0465s\n",
            "12\n",
            "Epoch: 0569 loss_train: 0.8990 acc_train: 0.7857 loss_val: 0.7972 acc_val: 0.8220 time: 0.0449s\n",
            "13\n",
            "Epoch: 0570 loss_train: 0.9384 acc_train: 0.7643 loss_val: 0.7991 acc_val: 0.8280 time: 0.0445s\n",
            "14\n",
            "Epoch: 0571 loss_train: 0.8952 acc_train: 0.8286 loss_val: 0.8031 acc_val: 0.8320 time: 0.0439s\n",
            "15\n",
            "Epoch: 0572 loss_train: 0.8853 acc_train: 0.8000 loss_val: 0.8039 acc_val: 0.8320 time: 0.0455s\n",
            "16\n",
            "Epoch: 0573 loss_train: 0.9104 acc_train: 0.8000 loss_val: 0.8027 acc_val: 0.8300 time: 0.0453s\n",
            "17\n",
            "Epoch: 0574 loss_train: 0.9273 acc_train: 0.7857 loss_val: 0.8018 acc_val: 0.8260 time: 0.0460s\n",
            "18\n",
            "Epoch: 0575 loss_train: 0.9176 acc_train: 0.8214 loss_val: 0.8010 acc_val: 0.8260 time: 0.0464s\n",
            "19\n",
            "Epoch: 0576 loss_train: 0.9081 acc_train: 0.8571 loss_val: 0.7982 acc_val: 0.8240 time: 0.0443s\n",
            "20\n",
            "Epoch: 0577 loss_train: 0.9089 acc_train: 0.7786 loss_val: 0.7961 acc_val: 0.8320 time: 0.0458s\n",
            "21\n",
            "Epoch: 0578 loss_train: 0.9060 acc_train: 0.8214 loss_val: 0.7952 acc_val: 0.8240 time: 0.0465s\n",
            "22\n",
            "Epoch: 0579 loss_train: 0.9026 acc_train: 0.8357 loss_val: 0.7963 acc_val: 0.8220 time: 0.0462s\n",
            "23\n",
            "Epoch: 0580 loss_train: 0.8915 acc_train: 0.7857 loss_val: 0.7982 acc_val: 0.8200 time: 0.0442s\n",
            "24\n",
            "Epoch: 0581 loss_train: 0.9777 acc_train: 0.7571 loss_val: 0.8031 acc_val: 0.8180 time: 0.0443s\n",
            "25\n",
            "Epoch: 0582 loss_train: 0.9169 acc_train: 0.8143 loss_val: 0.8034 acc_val: 0.8220 time: 0.0440s\n",
            "26\n",
            "Epoch: 0583 loss_train: 0.9172 acc_train: 0.8286 loss_val: 0.8010 acc_val: 0.8220 time: 0.0454s\n",
            "27\n",
            "Epoch: 0584 loss_train: 0.9293 acc_train: 0.7857 loss_val: 0.7993 acc_val: 0.8240 time: 0.0446s\n",
            "28\n",
            "Epoch: 0585 loss_train: 0.9248 acc_train: 0.8143 loss_val: 0.7982 acc_val: 0.8240 time: 0.0445s\n",
            "29\n",
            "Epoch: 0586 loss_train: 0.8699 acc_train: 0.8143 loss_val: 0.7967 acc_val: 0.8260 time: 0.0456s\n",
            "30\n",
            "Epoch: 0587 loss_train: 0.8783 acc_train: 0.8143 loss_val: 0.7961 acc_val: 0.8260 time: 0.0441s\n",
            "31\n",
            "Epoch: 0588 loss_train: 0.9089 acc_train: 0.7857 loss_val: 0.7958 acc_val: 0.8240 time: 0.0475s\n",
            "32\n",
            "Epoch: 0589 loss_train: 0.9200 acc_train: 0.8286 loss_val: 0.7974 acc_val: 0.8240 time: 0.0470s\n",
            "33\n",
            "Epoch: 0590 loss_train: 0.9437 acc_train: 0.7857 loss_val: 0.7966 acc_val: 0.8240 time: 0.0449s\n",
            "34\n",
            "Epoch: 0591 loss_train: 0.8954 acc_train: 0.7714 loss_val: 0.7967 acc_val: 0.8320 time: 0.0443s\n",
            "35\n",
            "Epoch: 0592 loss_train: 0.8893 acc_train: 0.7929 loss_val: 0.7999 acc_val: 0.8240 time: 0.0442s\n",
            "36\n",
            "Epoch: 0593 loss_train: 0.9184 acc_train: 0.7429 loss_val: 0.7999 acc_val: 0.8280 time: 0.0497s\n",
            "37\n",
            "Epoch: 0594 loss_train: 0.9618 acc_train: 0.7429 loss_val: 0.8003 acc_val: 0.8300 time: 0.0443s\n",
            "38\n",
            "Epoch: 0595 loss_train: 0.8791 acc_train: 0.8429 loss_val: 0.7991 acc_val: 0.8280 time: 0.0445s\n",
            "39\n",
            "Epoch: 0596 loss_train: 0.9286 acc_train: 0.7714 loss_val: 0.7951 acc_val: 0.8260 time: 0.0461s\n",
            "40\n",
            "Epoch: 0597 loss_train: 0.9463 acc_train: 0.7429 loss_val: 0.7933 acc_val: 0.8220 time: 0.0439s\n",
            "41\n",
            "Epoch: 0598 loss_train: 0.9238 acc_train: 0.8000 loss_val: 0.7923 acc_val: 0.8280 time: 0.0473s\n",
            "42\n",
            "Epoch: 0599 loss_train: 0.9031 acc_train: 0.8429 loss_val: 0.7924 acc_val: 0.8300 time: 0.0445s\n",
            "43\n",
            "Epoch: 0600 loss_train: 0.8983 acc_train: 0.8214 loss_val: 0.7913 acc_val: 0.8280 time: 0.0445s\n",
            "44\n",
            "Epoch: 0601 loss_train: 0.8937 acc_train: 0.8000 loss_val: 0.7914 acc_val: 0.8260 time: 0.0442s\n",
            "45\n",
            "Epoch: 0602 loss_train: 0.9079 acc_train: 0.7929 loss_val: 0.7904 acc_val: 0.8280 time: 0.0442s\n",
            "46\n",
            "Epoch: 0603 loss_train: 0.9006 acc_train: 0.8071 loss_val: 0.7910 acc_val: 0.8220 time: 0.0449s\n",
            "0\n",
            "Epoch: 0604 loss_train: 0.8846 acc_train: 0.8357 loss_val: 0.7949 acc_val: 0.8260 time: 0.0440s\n",
            "1\n",
            "Epoch: 0605 loss_train: 0.9064 acc_train: 0.8000 loss_val: 0.8003 acc_val: 0.8240 time: 0.0451s\n",
            "2\n",
            "Epoch: 0606 loss_train: 0.9409 acc_train: 0.7929 loss_val: 0.8035 acc_val: 0.8180 time: 0.0440s\n",
            "3\n",
            "Epoch: 0607 loss_train: 0.9260 acc_train: 0.8000 loss_val: 0.8026 acc_val: 0.8220 time: 0.0441s\n",
            "4\n",
            "Epoch: 0608 loss_train: 0.8897 acc_train: 0.8429 loss_val: 0.8007 acc_val: 0.8260 time: 0.0459s\n",
            "5\n",
            "Epoch: 0609 loss_train: 0.8860 acc_train: 0.8357 loss_val: 0.7975 acc_val: 0.8260 time: 0.0444s\n",
            "6\n",
            "Epoch: 0610 loss_train: 0.9015 acc_train: 0.8214 loss_val: 0.7925 acc_val: 0.8300 time: 0.0454s\n",
            "7\n",
            "Epoch: 0611 loss_train: 0.9546 acc_train: 0.7714 loss_val: 0.7915 acc_val: 0.8220 time: 0.0447s\n",
            "8\n",
            "Epoch: 0612 loss_train: 0.8984 acc_train: 0.8714 loss_val: 0.7895 acc_val: 0.8200 time: 0.0447s\n",
            "9\n",
            "Epoch: 0613 loss_train: 0.9606 acc_train: 0.8000 loss_val: 0.7893 acc_val: 0.8140 time: 0.0456s\n",
            "0\n",
            "Epoch: 0614 loss_train: 0.8404 acc_train: 0.8571 loss_val: 0.7905 acc_val: 0.8220 time: 0.0447s\n",
            "0\n",
            "Epoch: 0615 loss_train: 0.9379 acc_train: 0.8214 loss_val: 0.7941 acc_val: 0.8280 time: 0.0457s\n",
            "1\n",
            "Epoch: 0616 loss_train: 0.8753 acc_train: 0.7857 loss_val: 0.7972 acc_val: 0.8260 time: 0.0450s\n",
            "2\n",
            "Epoch: 0617 loss_train: 0.9046 acc_train: 0.8429 loss_val: 0.7991 acc_val: 0.8300 time: 0.0502s\n",
            "3\n",
            "Epoch: 0618 loss_train: 0.9309 acc_train: 0.8143 loss_val: 0.8008 acc_val: 0.8300 time: 0.0451s\n",
            "4\n",
            "Epoch: 0619 loss_train: 0.9177 acc_train: 0.8357 loss_val: 0.8008 acc_val: 0.8300 time: 0.0442s\n",
            "5\n",
            "Epoch: 0620 loss_train: 0.8919 acc_train: 0.8143 loss_val: 0.7986 acc_val: 0.8300 time: 0.0444s\n",
            "6\n",
            "Epoch: 0621 loss_train: 0.8962 acc_train: 0.8143 loss_val: 0.7957 acc_val: 0.8300 time: 0.0443s\n",
            "7\n",
            "Epoch: 0622 loss_train: 0.8840 acc_train: 0.8429 loss_val: 0.7913 acc_val: 0.8220 time: 0.0443s\n",
            "8\n",
            "Epoch: 0623 loss_train: 0.9475 acc_train: 0.7071 loss_val: 0.7896 acc_val: 0.8220 time: 0.0451s\n",
            "9\n",
            "Epoch: 0624 loss_train: 0.8889 acc_train: 0.8071 loss_val: 0.7906 acc_val: 0.8220 time: 0.0441s\n",
            "10\n",
            "Epoch: 0625 loss_train: 0.9109 acc_train: 0.8357 loss_val: 0.7898 acc_val: 0.8180 time: 0.0441s\n",
            "11\n",
            "Epoch: 0626 loss_train: 0.9110 acc_train: 0.7643 loss_val: 0.7897 acc_val: 0.8160 time: 0.0441s\n",
            "12\n",
            "Epoch: 0627 loss_train: 0.9258 acc_train: 0.8071 loss_val: 0.7903 acc_val: 0.8180 time: 0.0444s\n",
            "13\n",
            "Epoch: 0628 loss_train: 0.9099 acc_train: 0.8500 loss_val: 0.7909 acc_val: 0.8220 time: 0.0460s\n",
            "14\n",
            "Epoch: 0629 loss_train: 0.9132 acc_train: 0.7714 loss_val: 0.7927 acc_val: 0.8300 time: 0.0453s\n",
            "15\n",
            "Epoch: 0630 loss_train: 0.9135 acc_train: 0.8286 loss_val: 0.7957 acc_val: 0.8300 time: 0.0445s\n",
            "16\n",
            "Epoch: 0631 loss_train: 0.9006 acc_train: 0.8571 loss_val: 0.7969 acc_val: 0.8320 time: 0.0449s\n",
            "17\n",
            "Epoch: 0632 loss_train: 0.9079 acc_train: 0.7786 loss_val: 0.7997 acc_val: 0.8280 time: 0.0442s\n",
            "18\n",
            "Epoch: 0633 loss_train: 0.9456 acc_train: 0.7786 loss_val: 0.8024 acc_val: 0.8200 time: 0.0452s\n",
            "19\n",
            "Epoch: 0634 loss_train: 0.9251 acc_train: 0.7786 loss_val: 0.8057 acc_val: 0.8180 time: 0.0445s\n",
            "20\n",
            "Epoch: 0635 loss_train: 0.9147 acc_train: 0.7714 loss_val: 0.8058 acc_val: 0.8080 time: 0.0435s\n",
            "21\n",
            "Epoch: 0636 loss_train: 0.9031 acc_train: 0.8071 loss_val: 0.8022 acc_val: 0.8100 time: 0.0448s\n",
            "22\n",
            "Epoch: 0637 loss_train: 0.9604 acc_train: 0.7643 loss_val: 0.7992 acc_val: 0.8200 time: 0.0455s\n",
            "23\n",
            "Epoch: 0638 loss_train: 0.9389 acc_train: 0.7429 loss_val: 0.7944 acc_val: 0.8240 time: 0.0468s\n",
            "24\n",
            "Epoch: 0639 loss_train: 0.9085 acc_train: 0.8071 loss_val: 0.7916 acc_val: 0.8300 time: 0.0463s\n",
            "25\n",
            "Epoch: 0640 loss_train: 0.9096 acc_train: 0.8571 loss_val: 0.7883 acc_val: 0.8300 time: 0.0441s\n",
            "26\n",
            "Epoch: 0641 loss_train: 0.9518 acc_train: 0.7286 loss_val: 0.7890 acc_val: 0.8280 time: 0.0441s\n",
            "0\n",
            "Epoch: 0642 loss_train: 0.9203 acc_train: 0.7500 loss_val: 0.7922 acc_val: 0.8220 time: 0.0446s\n",
            "1\n",
            "Epoch: 0643 loss_train: 0.8732 acc_train: 0.8357 loss_val: 0.7974 acc_val: 0.8140 time: 0.0456s\n",
            "2\n",
            "Epoch: 0644 loss_train: 0.9095 acc_train: 0.8357 loss_val: 0.8023 acc_val: 0.8080 time: 0.0441s\n",
            "3\n",
            "Epoch: 0645 loss_train: 0.9003 acc_train: 0.8286 loss_val: 0.8046 acc_val: 0.8080 time: 0.0442s\n",
            "4\n",
            "Epoch: 0646 loss_train: 0.9398 acc_train: 0.7714 loss_val: 0.8043 acc_val: 0.8160 time: 0.0441s\n",
            "5\n",
            "Epoch: 0647 loss_train: 0.9537 acc_train: 0.7357 loss_val: 0.8026 acc_val: 0.8160 time: 0.0441s\n",
            "6\n",
            "Epoch: 0648 loss_train: 0.9213 acc_train: 0.7929 loss_val: 0.7994 acc_val: 0.8300 time: 0.0461s\n",
            "7\n",
            "Epoch: 0649 loss_train: 0.8852 acc_train: 0.8571 loss_val: 0.7972 acc_val: 0.8280 time: 0.0485s\n",
            "8\n",
            "Epoch: 0650 loss_train: 0.9487 acc_train: 0.7857 loss_val: 0.7958 acc_val: 0.8300 time: 0.0452s\n",
            "9\n",
            "Epoch: 0651 loss_train: 0.9156 acc_train: 0.8071 loss_val: 0.7937 acc_val: 0.8300 time: 0.0442s\n",
            "10\n",
            "Epoch: 0652 loss_train: 0.9759 acc_train: 0.7857 loss_val: 0.7957 acc_val: 0.8220 time: 0.0442s\n",
            "11\n",
            "Epoch: 0653 loss_train: 0.8961 acc_train: 0.7857 loss_val: 0.7978 acc_val: 0.8220 time: 0.0459s\n",
            "12\n",
            "Epoch: 0654 loss_train: 0.9461 acc_train: 0.8071 loss_val: 0.8005 acc_val: 0.8180 time: 0.0455s\n",
            "13\n",
            "Epoch: 0655 loss_train: 0.8847 acc_train: 0.8143 loss_val: 0.8022 acc_val: 0.8180 time: 0.0443s\n",
            "14\n",
            "Epoch: 0656 loss_train: 0.9191 acc_train: 0.8000 loss_val: 0.8019 acc_val: 0.8160 time: 0.0455s\n",
            "15\n",
            "Epoch: 0657 loss_train: 0.9005 acc_train: 0.8857 loss_val: 0.8015 acc_val: 0.8160 time: 0.0439s\n",
            "16\n",
            "Epoch: 0658 loss_train: 0.9359 acc_train: 0.7714 loss_val: 0.8011 acc_val: 0.8160 time: 0.0458s\n",
            "17\n",
            "Epoch: 0659 loss_train: 0.9056 acc_train: 0.7714 loss_val: 0.7988 acc_val: 0.8160 time: 0.0448s\n",
            "18\n",
            "Epoch: 0660 loss_train: 0.9172 acc_train: 0.8071 loss_val: 0.7942 acc_val: 0.8180 time: 0.0470s\n",
            "19\n",
            "Epoch: 0661 loss_train: 0.9218 acc_train: 0.8143 loss_val: 0.7910 acc_val: 0.8160 time: 0.0442s\n",
            "20\n",
            "Epoch: 0662 loss_train: 0.9006 acc_train: 0.7286 loss_val: 0.7897 acc_val: 0.8260 time: 0.0453s\n",
            "21\n",
            "Epoch: 0663 loss_train: 0.8805 acc_train: 0.7714 loss_val: 0.7917 acc_val: 0.8180 time: 0.0457s\n",
            "22\n",
            "Epoch: 0664 loss_train: 0.8932 acc_train: 0.8000 loss_val: 0.7950 acc_val: 0.8200 time: 0.0445s\n",
            "23\n",
            "Epoch: 0665 loss_train: 0.9401 acc_train: 0.7714 loss_val: 0.8042 acc_val: 0.8260 time: 0.0443s\n",
            "24\n",
            "Epoch: 0666 loss_train: 0.9056 acc_train: 0.7786 loss_val: 0.8080 acc_val: 0.8240 time: 0.0440s\n",
            "25\n",
            "Epoch: 0667 loss_train: 0.9016 acc_train: 0.8000 loss_val: 0.8070 acc_val: 0.8260 time: 0.0440s\n",
            "26\n",
            "Epoch: 0668 loss_train: 0.9109 acc_train: 0.7643 loss_val: 0.8030 acc_val: 0.8220 time: 0.0460s\n",
            "27\n",
            "Epoch: 0669 loss_train: 0.8976 acc_train: 0.7571 loss_val: 0.7966 acc_val: 0.8180 time: 0.0443s\n",
            "28\n",
            "Epoch: 0670 loss_train: 0.9102 acc_train: 0.7571 loss_val: 0.7933 acc_val: 0.8160 time: 0.0455s\n",
            "29\n",
            "Epoch: 0671 loss_train: 0.9225 acc_train: 0.8500 loss_val: 0.7941 acc_val: 0.8140 time: 0.0439s\n",
            "30\n",
            "Epoch: 0672 loss_train: 0.9409 acc_train: 0.7714 loss_val: 0.7983 acc_val: 0.8200 time: 0.0443s\n",
            "31\n",
            "Epoch: 0673 loss_train: 0.9166 acc_train: 0.8214 loss_val: 0.7996 acc_val: 0.8200 time: 0.0466s\n",
            "32\n",
            "Epoch: 0674 loss_train: 0.8703 acc_train: 0.8214 loss_val: 0.7987 acc_val: 0.8220 time: 0.0450s\n",
            "33\n",
            "Epoch: 0675 loss_train: 0.8839 acc_train: 0.8500 loss_val: 0.7978 acc_val: 0.8220 time: 0.0454s\n",
            "34\n",
            "Epoch: 0676 loss_train: 0.9143 acc_train: 0.7786 loss_val: 0.7988 acc_val: 0.8280 time: 0.0458s\n",
            "35\n",
            "Epoch: 0677 loss_train: 0.8921 acc_train: 0.7929 loss_val: 0.7984 acc_val: 0.8280 time: 0.0443s\n",
            "36\n",
            "Epoch: 0678 loss_train: 0.9382 acc_train: 0.8000 loss_val: 0.7971 acc_val: 0.8240 time: 0.0451s\n",
            "37\n",
            "Epoch: 0679 loss_train: 0.9158 acc_train: 0.7714 loss_val: 0.7968 acc_val: 0.8280 time: 0.0463s\n",
            "38\n",
            "Epoch: 0680 loss_train: 0.8998 acc_train: 0.7857 loss_val: 0.7953 acc_val: 0.8280 time: 0.0447s\n",
            "39\n",
            "Epoch: 0681 loss_train: 0.9138 acc_train: 0.8214 loss_val: 0.7929 acc_val: 0.8160 time: 0.0445s\n",
            "40\n",
            "Epoch: 0682 loss_train: 0.9224 acc_train: 0.8071 loss_val: 0.7926 acc_val: 0.8140 time: 0.0479s\n",
            "41\n",
            "Epoch: 0683 loss_train: 0.9116 acc_train: 0.8286 loss_val: 0.7943 acc_val: 0.8140 time: 0.0450s\n",
            "42\n",
            "Epoch: 0684 loss_train: 0.9658 acc_train: 0.7929 loss_val: 0.7955 acc_val: 0.8180 time: 0.0443s\n",
            "43\n",
            "Epoch: 0685 loss_train: 0.8933 acc_train: 0.7714 loss_val: 0.7974 acc_val: 0.8180 time: 0.0439s\n",
            "44\n",
            "Epoch: 0686 loss_train: 0.9507 acc_train: 0.7357 loss_val: 0.7993 acc_val: 0.8220 time: 0.0442s\n",
            "45\n",
            "Epoch: 0687 loss_train: 0.9197 acc_train: 0.8214 loss_val: 0.8006 acc_val: 0.8260 time: 0.0440s\n",
            "46\n",
            "Epoch: 0688 loss_train: 0.8716 acc_train: 0.8429 loss_val: 0.7976 acc_val: 0.8280 time: 0.0491s\n",
            "47\n",
            "Epoch: 0689 loss_train: 0.9277 acc_train: 0.8000 loss_val: 0.7972 acc_val: 0.8260 time: 0.0441s\n",
            "48\n",
            "Epoch: 0690 loss_train: 0.9059 acc_train: 0.8000 loss_val: 0.7992 acc_val: 0.8180 time: 0.0443s\n",
            "49\n",
            "Epoch: 0691 loss_train: 0.8617 acc_train: 0.7714 loss_val: 0.7982 acc_val: 0.8160 time: 0.0440s\n",
            "50\n",
            "Epoch: 0692 loss_train: 0.9254 acc_train: 0.7929 loss_val: 0.7969 acc_val: 0.8200 time: 0.0446s\n",
            "51\n",
            "Epoch: 0693 loss_train: 0.8900 acc_train: 0.8214 loss_val: 0.7955 acc_val: 0.8180 time: 0.0455s\n",
            "52\n",
            "Epoch: 0694 loss_train: 0.9120 acc_train: 0.8000 loss_val: 0.7942 acc_val: 0.8220 time: 0.0449s\n",
            "53\n",
            "Epoch: 0695 loss_train: 0.9248 acc_train: 0.7857 loss_val: 0.7953 acc_val: 0.8240 time: 0.0481s\n",
            "54\n",
            "Epoch: 0696 loss_train: 0.9761 acc_train: 0.8714 loss_val: 0.7980 acc_val: 0.8260 time: 0.0443s\n",
            "55\n",
            "Epoch: 0697 loss_train: 0.9083 acc_train: 0.8143 loss_val: 0.8000 acc_val: 0.8260 time: 0.0440s\n",
            "56\n",
            "Epoch: 0698 loss_train: 0.8661 acc_train: 0.8071 loss_val: 0.7997 acc_val: 0.8260 time: 0.0460s\n",
            "57\n",
            "Epoch: 0699 loss_train: 0.9070 acc_train: 0.8429 loss_val: 0.7986 acc_val: 0.8240 time: 0.0452s\n",
            "58\n",
            "Epoch: 0700 loss_train: 0.9181 acc_train: 0.7500 loss_val: 0.7973 acc_val: 0.8200 time: 0.0455s\n",
            "59\n",
            "Epoch: 0701 loss_train: 0.8821 acc_train: 0.7786 loss_val: 0.7947 acc_val: 0.8220 time: 0.0438s\n",
            "60\n",
            "Epoch: 0702 loss_train: 0.9101 acc_train: 0.8000 loss_val: 0.7915 acc_val: 0.8200 time: 0.0441s\n",
            "61\n",
            "Epoch: 0703 loss_train: 0.8938 acc_train: 0.7857 loss_val: 0.7901 acc_val: 0.8200 time: 0.0478s\n",
            "62\n",
            "Epoch: 0704 loss_train: 0.8984 acc_train: 0.8000 loss_val: 0.7912 acc_val: 0.8140 time: 0.0445s\n",
            "63\n",
            "Epoch: 0705 loss_train: 0.8812 acc_train: 0.7571 loss_val: 0.7938 acc_val: 0.8140 time: 0.0450s\n",
            "64\n",
            "Epoch: 0706 loss_train: 0.8984 acc_train: 0.8071 loss_val: 0.7963 acc_val: 0.8240 time: 0.0447s\n",
            "65\n",
            "Epoch: 0707 loss_train: 0.9540 acc_train: 0.7000 loss_val: 0.7995 acc_val: 0.8240 time: 0.0460s\n",
            "66\n",
            "Epoch: 0708 loss_train: 0.9100 acc_train: 0.7786 loss_val: 0.7990 acc_val: 0.8240 time: 0.0463s\n",
            "67\n",
            "Epoch: 0709 loss_train: 0.8823 acc_train: 0.8357 loss_val: 0.7968 acc_val: 0.8140 time: 0.0474s\n",
            "68\n",
            "Epoch: 0710 loss_train: 0.9334 acc_train: 0.7857 loss_val: 0.7951 acc_val: 0.8140 time: 0.0466s\n",
            "69\n",
            "Epoch: 0711 loss_train: 0.8969 acc_train: 0.7643 loss_val: 0.7940 acc_val: 0.8220 time: 0.0446s\n",
            "70\n",
            "Epoch: 0712 loss_train: 0.9009 acc_train: 0.7857 loss_val: 0.7948 acc_val: 0.8240 time: 0.0454s\n",
            "71\n",
            "Epoch: 0713 loss_train: 0.9330 acc_train: 0.7643 loss_val: 0.7963 acc_val: 0.8240 time: 0.0455s\n",
            "72\n",
            "Epoch: 0714 loss_train: 0.9153 acc_train: 0.7714 loss_val: 0.7967 acc_val: 0.8140 time: 0.0447s\n",
            "73\n",
            "Epoch: 0715 loss_train: 0.9143 acc_train: 0.7500 loss_val: 0.7941 acc_val: 0.8120 time: 0.0452s\n",
            "74\n",
            "Epoch: 0716 loss_train: 0.9025 acc_train: 0.8071 loss_val: 0.7906 acc_val: 0.8100 time: 0.0442s\n",
            "75\n",
            "Epoch: 0717 loss_train: 0.9217 acc_train: 0.7786 loss_val: 0.7906 acc_val: 0.8120 time: 0.0441s\n",
            "76\n",
            "Epoch: 0718 loss_train: 0.8714 acc_train: 0.8286 loss_val: 0.7903 acc_val: 0.8140 time: 0.0450s\n",
            "77\n",
            "Epoch: 0719 loss_train: 0.8735 acc_train: 0.8286 loss_val: 0.7925 acc_val: 0.8160 time: 0.0446s\n",
            "78\n",
            "Epoch: 0720 loss_train: 0.9205 acc_train: 0.8143 loss_val: 0.7958 acc_val: 0.8220 time: 0.0443s\n",
            "79\n",
            "Epoch: 0721 loss_train: 0.9273 acc_train: 0.7857 loss_val: 0.7967 acc_val: 0.8240 time: 0.0447s\n",
            "80\n",
            "Epoch: 0722 loss_train: 0.8925 acc_train: 0.8071 loss_val: 0.7964 acc_val: 0.8280 time: 0.0469s\n",
            "81\n",
            "Epoch: 0723 loss_train: 0.9187 acc_train: 0.7571 loss_val: 0.7929 acc_val: 0.8320 time: 0.0461s\n",
            "82\n",
            "Epoch: 0724 loss_train: 0.8973 acc_train: 0.7857 loss_val: 0.7888 acc_val: 0.8260 time: 0.0459s\n",
            "83\n",
            "Epoch: 0725 loss_train: 0.8971 acc_train: 0.8286 loss_val: 0.7850 acc_val: 0.8180 time: 0.0458s\n",
            "84\n",
            "Epoch: 0726 loss_train: 0.9121 acc_train: 0.7643 loss_val: 0.7850 acc_val: 0.8180 time: 0.0441s\n",
            "0\n",
            "Epoch: 0727 loss_train: 0.9095 acc_train: 0.7571 loss_val: 0.7873 acc_val: 0.8160 time: 0.0446s\n",
            "1\n",
            "Epoch: 0728 loss_train: 0.9338 acc_train: 0.7429 loss_val: 0.7918 acc_val: 0.8140 time: 0.0454s\n",
            "2\n",
            "Epoch: 0729 loss_train: 0.8984 acc_train: 0.7571 loss_val: 0.7992 acc_val: 0.8120 time: 0.0441s\n",
            "3\n",
            "Epoch: 0730 loss_train: 0.8852 acc_train: 0.8000 loss_val: 0.8066 acc_val: 0.8180 time: 0.0446s\n",
            "4\n",
            "Epoch: 0731 loss_train: 0.8661 acc_train: 0.8643 loss_val: 0.8126 acc_val: 0.8200 time: 0.0440s\n",
            "5\n",
            "Epoch: 0732 loss_train: 0.8904 acc_train: 0.8143 loss_val: 0.8133 acc_val: 0.8180 time: 0.0453s\n",
            "6\n",
            "Epoch: 0733 loss_train: 0.9363 acc_train: 0.7643 loss_val: 0.8020 acc_val: 0.8320 time: 0.0457s\n",
            "7\n",
            "Epoch: 0734 loss_train: 0.9234 acc_train: 0.8357 loss_val: 0.7898 acc_val: 0.8320 time: 0.0452s\n",
            "8\n",
            "Epoch: 0735 loss_train: 0.9160 acc_train: 0.8071 loss_val: 0.7819 acc_val: 0.8280 time: 0.0443s\n",
            "9\n",
            "Epoch: 0736 loss_train: 0.9002 acc_train: 0.8429 loss_val: 0.7796 acc_val: 0.8220 time: 0.0447s\n",
            "0\n",
            "Epoch: 0737 loss_train: 0.8839 acc_train: 0.8571 loss_val: 0.7847 acc_val: 0.8160 time: 0.0436s\n",
            "0\n",
            "Epoch: 0738 loss_train: 0.9319 acc_train: 0.8000 loss_val: 0.7945 acc_val: 0.8140 time: 0.0450s\n",
            "1\n",
            "Epoch: 0739 loss_train: 0.9074 acc_train: 0.8786 loss_val: 0.8013 acc_val: 0.8140 time: 0.0441s\n",
            "2\n",
            "Epoch: 0740 loss_train: 0.8900 acc_train: 0.8357 loss_val: 0.8056 acc_val: 0.8140 time: 0.0445s\n",
            "3\n",
            "Epoch: 0741 loss_train: 0.8791 acc_train: 0.8643 loss_val: 0.8060 acc_val: 0.8160 time: 0.0439s\n",
            "4\n",
            "Epoch: 0742 loss_train: 0.8946 acc_train: 0.8214 loss_val: 0.8037 acc_val: 0.8220 time: 0.0442s\n",
            "5\n",
            "Epoch: 0743 loss_train: 0.8770 acc_train: 0.8429 loss_val: 0.7957 acc_val: 0.8320 time: 0.0473s\n",
            "6\n",
            "Epoch: 0744 loss_train: 0.9398 acc_train: 0.7857 loss_val: 0.7890 acc_val: 0.8320 time: 0.0444s\n",
            "7\n",
            "Epoch: 0745 loss_train: 0.8951 acc_train: 0.7714 loss_val: 0.7816 acc_val: 0.8280 time: 0.0439s\n",
            "8\n",
            "Epoch: 0746 loss_train: 0.8681 acc_train: 0.8357 loss_val: 0.7773 acc_val: 0.8240 time: 0.0458s\n",
            "9\n",
            "Epoch: 0747 loss_train: 0.9492 acc_train: 0.7357 loss_val: 0.7783 acc_val: 0.8200 time: 0.0439s\n",
            "0\n",
            "Epoch: 0748 loss_train: 0.8778 acc_train: 0.8071 loss_val: 0.7813 acc_val: 0.8180 time: 0.0453s\n",
            "1\n",
            "Epoch: 0749 loss_train: 0.9090 acc_train: 0.8214 loss_val: 0.7842 acc_val: 0.8200 time: 0.0443s\n",
            "2\n",
            "Epoch: 0750 loss_train: 0.9384 acc_train: 0.7357 loss_val: 0.7891 acc_val: 0.8180 time: 0.0440s\n",
            "3\n",
            "Epoch: 0751 loss_train: 0.8909 acc_train: 0.8429 loss_val: 0.7924 acc_val: 0.8220 time: 0.0451s\n",
            "4\n",
            "Epoch: 0752 loss_train: 0.9208 acc_train: 0.8000 loss_val: 0.7975 acc_val: 0.8220 time: 0.0440s\n",
            "5\n",
            "Epoch: 0753 loss_train: 0.9317 acc_train: 0.7857 loss_val: 0.7992 acc_val: 0.8220 time: 0.0461s\n",
            "6\n",
            "Epoch: 0754 loss_train: 0.8817 acc_train: 0.7857 loss_val: 0.7967 acc_val: 0.8180 time: 0.0443s\n",
            "7\n",
            "Epoch: 0755 loss_train: 0.8870 acc_train: 0.8214 loss_val: 0.7919 acc_val: 0.8200 time: 0.0439s\n",
            "8\n",
            "Epoch: 0756 loss_train: 0.9313 acc_train: 0.8357 loss_val: 0.7857 acc_val: 0.8180 time: 0.0448s\n",
            "9\n",
            "Epoch: 0757 loss_train: 0.9196 acc_train: 0.7929 loss_val: 0.7819 acc_val: 0.8200 time: 0.0467s\n",
            "10\n",
            "Epoch: 0758 loss_train: 0.9351 acc_train: 0.8143 loss_val: 0.7831 acc_val: 0.8200 time: 0.0462s\n",
            "11\n",
            "Epoch: 0759 loss_train: 0.9408 acc_train: 0.7429 loss_val: 0.7860 acc_val: 0.8200 time: 0.0466s\n",
            "12\n",
            "Epoch: 0760 loss_train: 0.8909 acc_train: 0.8357 loss_val: 0.7899 acc_val: 0.8260 time: 0.0446s\n",
            "13\n",
            "Epoch: 0761 loss_train: 0.8850 acc_train: 0.8214 loss_val: 0.7930 acc_val: 0.8220 time: 0.0445s\n",
            "14\n",
            "Epoch: 0762 loss_train: 0.9573 acc_train: 0.8214 loss_val: 0.7929 acc_val: 0.8200 time: 0.0443s\n",
            "15\n",
            "Epoch: 0763 loss_train: 0.9109 acc_train: 0.8071 loss_val: 0.7902 acc_val: 0.8220 time: 0.0468s\n",
            "16\n",
            "Epoch: 0764 loss_train: 0.9126 acc_train: 0.8000 loss_val: 0.7884 acc_val: 0.8260 time: 0.0461s\n",
            "17\n",
            "Epoch: 0765 loss_train: 0.8827 acc_train: 0.8071 loss_val: 0.7887 acc_val: 0.8200 time: 0.0449s\n",
            "18\n",
            "Epoch: 0766 loss_train: 0.8977 acc_train: 0.7429 loss_val: 0.7881 acc_val: 0.8160 time: 0.0442s\n",
            "19\n",
            "Epoch: 0767 loss_train: 0.8865 acc_train: 0.8786 loss_val: 0.7863 acc_val: 0.8160 time: 0.0468s\n",
            "20\n",
            "Epoch: 0768 loss_train: 0.9230 acc_train: 0.8000 loss_val: 0.7874 acc_val: 0.8180 time: 0.0450s\n",
            "21\n",
            "Epoch: 0769 loss_train: 0.9294 acc_train: 0.8214 loss_val: 0.7867 acc_val: 0.8220 time: 0.0443s\n",
            "22\n",
            "Epoch: 0770 loss_train: 0.9066 acc_train: 0.7929 loss_val: 0.7865 acc_val: 0.8220 time: 0.0440s\n",
            "23\n",
            "Epoch: 0771 loss_train: 0.9168 acc_train: 0.7429 loss_val: 0.7904 acc_val: 0.8180 time: 0.0442s\n",
            "24\n",
            "Epoch: 0772 loss_train: 0.8875 acc_train: 0.8214 loss_val: 0.7926 acc_val: 0.8160 time: 0.0446s\n",
            "25\n",
            "Epoch: 0773 loss_train: 0.8684 acc_train: 0.8000 loss_val: 0.7922 acc_val: 0.8180 time: 0.0461s\n",
            "26\n",
            "Epoch: 0774 loss_train: 0.8751 acc_train: 0.8000 loss_val: 0.7892 acc_val: 0.8220 time: 0.0444s\n",
            "27\n",
            "Epoch: 0775 loss_train: 0.9536 acc_train: 0.7929 loss_val: 0.7876 acc_val: 0.8380 time: 0.0445s\n",
            "28\n",
            "Epoch: 0776 loss_train: 0.9264 acc_train: 0.7857 loss_val: 0.7890 acc_val: 0.8340 time: 0.0458s\n",
            "29\n",
            "Epoch: 0777 loss_train: 0.9039 acc_train: 0.7643 loss_val: 0.7914 acc_val: 0.8320 time: 0.0442s\n",
            "30\n",
            "Epoch: 0778 loss_train: 0.8659 acc_train: 0.8143 loss_val: 0.7922 acc_val: 0.8260 time: 0.0452s\n",
            "31\n",
            "Epoch: 0779 loss_train: 0.8455 acc_train: 0.8143 loss_val: 0.7923 acc_val: 0.8260 time: 0.0447s\n",
            "32\n",
            "Epoch: 0780 loss_train: 0.8745 acc_train: 0.8857 loss_val: 0.7949 acc_val: 0.8260 time: 0.0441s\n",
            "33\n",
            "Epoch: 0781 loss_train: 0.9544 acc_train: 0.8357 loss_val: 0.7989 acc_val: 0.8220 time: 0.0444s\n",
            "34\n",
            "Epoch: 0782 loss_train: 0.8807 acc_train: 0.8071 loss_val: 0.8022 acc_val: 0.8200 time: 0.0444s\n",
            "35\n",
            "Epoch: 0783 loss_train: 0.8953 acc_train: 0.8071 loss_val: 0.8012 acc_val: 0.8200 time: 0.0452s\n",
            "36\n",
            "Epoch: 0784 loss_train: 0.8585 acc_train: 0.8000 loss_val: 0.7959 acc_val: 0.8120 time: 0.0464s\n",
            "37\n",
            "Epoch: 0785 loss_train: 0.8954 acc_train: 0.7929 loss_val: 0.7892 acc_val: 0.8240 time: 0.0471s\n",
            "38\n",
            "Epoch: 0786 loss_train: 0.9054 acc_train: 0.8143 loss_val: 0.7857 acc_val: 0.8240 time: 0.0470s\n",
            "39\n",
            "Epoch: 0787 loss_train: 0.8651 acc_train: 0.8286 loss_val: 0.7835 acc_val: 0.8300 time: 0.0459s\n",
            "40\n",
            "Epoch: 0788 loss_train: 0.8952 acc_train: 0.7786 loss_val: 0.7815 acc_val: 0.8320 time: 0.0488s\n",
            "41\n",
            "Epoch: 0789 loss_train: 0.8655 acc_train: 0.8429 loss_val: 0.7808 acc_val: 0.8340 time: 0.0496s\n",
            "42\n",
            "Epoch: 0790 loss_train: 0.9079 acc_train: 0.8357 loss_val: 0.7840 acc_val: 0.8260 time: 0.0468s\n",
            "43\n",
            "Epoch: 0791 loss_train: 0.9331 acc_train: 0.8071 loss_val: 0.7915 acc_val: 0.8240 time: 0.0455s\n",
            "44\n",
            "Epoch: 0792 loss_train: 0.8753 acc_train: 0.8286 loss_val: 0.7991 acc_val: 0.8240 time: 0.0446s\n",
            "45\n",
            "Epoch: 0793 loss_train: 0.9191 acc_train: 0.8000 loss_val: 0.8008 acc_val: 0.8220 time: 0.0451s\n",
            "46\n",
            "Epoch: 0794 loss_train: 0.9269 acc_train: 0.7643 loss_val: 0.7976 acc_val: 0.8200 time: 0.0443s\n",
            "47\n",
            "Epoch: 0795 loss_train: 0.9254 acc_train: 0.7857 loss_val: 0.7948 acc_val: 0.8200 time: 0.0440s\n",
            "48\n",
            "Epoch: 0796 loss_train: 0.9050 acc_train: 0.8000 loss_val: 0.7928 acc_val: 0.8200 time: 0.0446s\n",
            "49\n",
            "Epoch: 0797 loss_train: 0.8780 acc_train: 0.8143 loss_val: 0.7898 acc_val: 0.8180 time: 0.0440s\n",
            "50\n",
            "Epoch: 0798 loss_train: 0.8962 acc_train: 0.8429 loss_val: 0.7878 acc_val: 0.8180 time: 0.0472s\n",
            "51\n",
            "Epoch: 0799 loss_train: 0.8727 acc_train: 0.8286 loss_val: 0.7883 acc_val: 0.8160 time: 0.0457s\n",
            "52\n",
            "Epoch: 0800 loss_train: 0.9056 acc_train: 0.7929 loss_val: 0.7928 acc_val: 0.8180 time: 0.0465s\n",
            "53\n",
            "Epoch: 0801 loss_train: 0.9080 acc_train: 0.7857 loss_val: 0.7961 acc_val: 0.8180 time: 0.0449s\n",
            "54\n",
            "Epoch: 0802 loss_train: 0.8759 acc_train: 0.8214 loss_val: 0.7955 acc_val: 0.8200 time: 0.0453s\n",
            "55\n",
            "Epoch: 0803 loss_train: 0.9460 acc_train: 0.7143 loss_val: 0.7919 acc_val: 0.8200 time: 0.0459s\n",
            "56\n",
            "Epoch: 0804 loss_train: 0.9143 acc_train: 0.8071 loss_val: 0.7934 acc_val: 0.8200 time: 0.0447s\n",
            "57\n",
            "Epoch: 0805 loss_train: 0.8655 acc_train: 0.8429 loss_val: 0.7936 acc_val: 0.8240 time: 0.0452s\n",
            "58\n",
            "Epoch: 0806 loss_train: 0.8736 acc_train: 0.7857 loss_val: 0.7906 acc_val: 0.8300 time: 0.0454s\n",
            "59\n",
            "Epoch: 0807 loss_train: 0.9083 acc_train: 0.7929 loss_val: 0.7873 acc_val: 0.8320 time: 0.0441s\n",
            "60\n",
            "Epoch: 0808 loss_train: 0.8900 acc_train: 0.8286 loss_val: 0.7839 acc_val: 0.8300 time: 0.0460s\n",
            "61\n",
            "Epoch: 0809 loss_train: 0.8805 acc_train: 0.8571 loss_val: 0.7840 acc_val: 0.8220 time: 0.0452s\n",
            "62\n",
            "Epoch: 0810 loss_train: 0.8916 acc_train: 0.8071 loss_val: 0.7877 acc_val: 0.8180 time: 0.0458s\n",
            "63\n",
            "Epoch: 0811 loss_train: 0.9048 acc_train: 0.7786 loss_val: 0.7929 acc_val: 0.8220 time: 0.0439s\n",
            "64\n",
            "Epoch: 0812 loss_train: 0.9070 acc_train: 0.8071 loss_val: 0.7965 acc_val: 0.8160 time: 0.0448s\n",
            "65\n",
            "Epoch: 0813 loss_train: 0.8665 acc_train: 0.8500 loss_val: 0.7981 acc_val: 0.8140 time: 0.0451s\n",
            "66\n",
            "Epoch: 0814 loss_train: 0.9278 acc_train: 0.7929 loss_val: 0.7966 acc_val: 0.8140 time: 0.0444s\n",
            "67\n",
            "Epoch: 0815 loss_train: 0.9068 acc_train: 0.8214 loss_val: 0.7936 acc_val: 0.8140 time: 0.0444s\n",
            "68\n",
            "Epoch: 0816 loss_train: 0.9208 acc_train: 0.7500 loss_val: 0.7905 acc_val: 0.8120 time: 0.0451s\n",
            "69\n",
            "Epoch: 0817 loss_train: 0.9030 acc_train: 0.8357 loss_val: 0.7868 acc_val: 0.8180 time: 0.0444s\n",
            "70\n",
            "Epoch: 0818 loss_train: 0.8959 acc_train: 0.8214 loss_val: 0.7840 acc_val: 0.8200 time: 0.0462s\n",
            "71\n",
            "Epoch: 0819 loss_train: 0.9267 acc_train: 0.7857 loss_val: 0.7834 acc_val: 0.8200 time: 0.0460s\n",
            "72\n",
            "Epoch: 0820 loss_train: 0.9077 acc_train: 0.7857 loss_val: 0.7846 acc_val: 0.8140 time: 0.0461s\n",
            "73\n",
            "Epoch: 0821 loss_train: 0.8417 acc_train: 0.8357 loss_val: 0.7853 acc_val: 0.8160 time: 0.0451s\n",
            "74\n",
            "Epoch: 0822 loss_train: 0.9136 acc_train: 0.8071 loss_val: 0.7862 acc_val: 0.8140 time: 0.0443s\n",
            "75\n",
            "Epoch: 0823 loss_train: 0.8848 acc_train: 0.8357 loss_val: 0.7860 acc_val: 0.8140 time: 0.0450s\n",
            "76\n",
            "Epoch: 0824 loss_train: 0.9021 acc_train: 0.8357 loss_val: 0.7881 acc_val: 0.8160 time: 0.0440s\n",
            "77\n",
            "Epoch: 0825 loss_train: 0.9194 acc_train: 0.8357 loss_val: 0.7895 acc_val: 0.8140 time: 0.0444s\n",
            "78\n",
            "Epoch: 0826 loss_train: 0.9198 acc_train: 0.8286 loss_val: 0.7926 acc_val: 0.8100 time: 0.0439s\n",
            "79\n",
            "Epoch: 0827 loss_train: 0.9186 acc_train: 0.8071 loss_val: 0.7954 acc_val: 0.8160 time: 0.0451s\n",
            "80\n",
            "Epoch: 0828 loss_train: 0.8844 acc_train: 0.8786 loss_val: 0.7946 acc_val: 0.8220 time: 0.0453s\n",
            "81\n",
            "Epoch: 0829 loss_train: 0.9325 acc_train: 0.8143 loss_val: 0.7944 acc_val: 0.8220 time: 0.0444s\n",
            "82\n",
            "Epoch: 0830 loss_train: 0.9280 acc_train: 0.8071 loss_val: 0.7937 acc_val: 0.8200 time: 0.0442s\n",
            "83\n",
            "Epoch: 0831 loss_train: 0.9371 acc_train: 0.7714 loss_val: 0.7951 acc_val: 0.8200 time: 0.0465s\n",
            "84\n",
            "Epoch: 0832 loss_train: 0.9154 acc_train: 0.8571 loss_val: 0.7946 acc_val: 0.8180 time: 0.0446s\n",
            "85\n",
            "Epoch: 0833 loss_train: 0.9392 acc_train: 0.7786 loss_val: 0.7923 acc_val: 0.8140 time: 0.0454s\n",
            "86\n",
            "Epoch: 0834 loss_train: 0.9078 acc_train: 0.8000 loss_val: 0.7888 acc_val: 0.8140 time: 0.0443s\n",
            "87\n",
            "Epoch: 0835 loss_train: 0.9323 acc_train: 0.7571 loss_val: 0.7877 acc_val: 0.8140 time: 0.0443s\n",
            "88\n",
            "Epoch: 0836 loss_train: 0.9051 acc_train: 0.8071 loss_val: 0.7859 acc_val: 0.8160 time: 0.0440s\n",
            "89\n",
            "Epoch: 0837 loss_train: 0.9023 acc_train: 0.8143 loss_val: 0.7846 acc_val: 0.8180 time: 0.0453s\n",
            "90\n",
            "Epoch: 0838 loss_train: 0.8734 acc_train: 0.7786 loss_val: 0.7851 acc_val: 0.8180 time: 0.0455s\n",
            "91\n",
            "Epoch: 0839 loss_train: 0.8723 acc_train: 0.8143 loss_val: 0.7862 acc_val: 0.8140 time: 0.0443s\n",
            "92\n",
            "Epoch: 0840 loss_train: 0.8997 acc_train: 0.8143 loss_val: 0.7890 acc_val: 0.8120 time: 0.0448s\n",
            "93\n",
            "Epoch: 0841 loss_train: 0.9139 acc_train: 0.8071 loss_val: 0.7904 acc_val: 0.8140 time: 0.0446s\n",
            "94\n",
            "Epoch: 0842 loss_train: 0.8907 acc_train: 0.8214 loss_val: 0.7898 acc_val: 0.8140 time: 0.0442s\n",
            "95\n",
            "Epoch: 0843 loss_train: 0.8750 acc_train: 0.7857 loss_val: 0.7894 acc_val: 0.8180 time: 0.0455s\n",
            "96\n",
            "Epoch: 0844 loss_train: 0.8851 acc_train: 0.8286 loss_val: 0.7887 acc_val: 0.8160 time: 0.0460s\n",
            "97\n",
            "Epoch: 0845 loss_train: 0.9059 acc_train: 0.8214 loss_val: 0.7887 acc_val: 0.8200 time: 0.0450s\n",
            "98\n",
            "Epoch: 0846 loss_train: 0.9233 acc_train: 0.7857 loss_val: 0.7888 acc_val: 0.8200 time: 0.0442s\n",
            "99\n",
            "Epoch: 0847 loss_train: 0.8860 acc_train: 0.8286 loss_val: 0.7888 acc_val: 0.8160 time: 0.0463s\n",
            "100\n",
            "Epoch: 0848 loss_train: 0.9679 acc_train: 0.7643 loss_val: 0.7904 acc_val: 0.8200 time: 0.0462s\n",
            "101\n",
            "Epoch: 0849 loss_train: 0.9099 acc_train: 0.7857 loss_val: 0.7893 acc_val: 0.8180 time: 0.0439s\n",
            "102\n",
            "Epoch: 0850 loss_train: 0.8541 acc_train: 0.8429 loss_val: 0.7872 acc_val: 0.8180 time: 0.0446s\n",
            "103\n",
            "Epoch: 0851 loss_train: 0.8641 acc_train: 0.8071 loss_val: 0.7853 acc_val: 0.8220 time: 0.0444s\n",
            "104\n",
            "Epoch: 0852 loss_train: 0.9151 acc_train: 0.8143 loss_val: 0.7832 acc_val: 0.8200 time: 0.0458s\n",
            "105\n",
            "Epoch: 0853 loss_train: 0.9123 acc_train: 0.7857 loss_val: 0.7820 acc_val: 0.8180 time: 0.0464s\n",
            "106\n",
            "Epoch: 0854 loss_train: 0.9357 acc_train: 0.7357 loss_val: 0.7857 acc_val: 0.8220 time: 0.0456s\n",
            "107\n",
            "Epoch: 0855 loss_train: 0.8866 acc_train: 0.7714 loss_val: 0.7897 acc_val: 0.8180 time: 0.0445s\n",
            "108\n",
            "Epoch: 0856 loss_train: 0.8958 acc_train: 0.8357 loss_val: 0.7920 acc_val: 0.8220 time: 0.0443s\n",
            "109\n",
            "Epoch: 0857 loss_train: 0.8812 acc_train: 0.8143 loss_val: 0.7941 acc_val: 0.8220 time: 0.0477s\n",
            "110\n",
            "Epoch: 0858 loss_train: 0.9064 acc_train: 0.8214 loss_val: 0.7966 acc_val: 0.8260 time: 0.0467s\n",
            "111\n",
            "Epoch: 0859 loss_train: 0.8688 acc_train: 0.8071 loss_val: 0.7974 acc_val: 0.8260 time: 0.0473s\n",
            "112\n",
            "Epoch: 0860 loss_train: 0.8828 acc_train: 0.7500 loss_val: 0.7972 acc_val: 0.8240 time: 0.0445s\n",
            "113\n",
            "Epoch: 0861 loss_train: 0.9109 acc_train: 0.8214 loss_val: 0.7949 acc_val: 0.8220 time: 0.0446s\n",
            "114\n",
            "Epoch: 0862 loss_train: 0.9045 acc_train: 0.8214 loss_val: 0.7914 acc_val: 0.8300 time: 0.0441s\n",
            "115\n",
            "Epoch: 0863 loss_train: 0.9203 acc_train: 0.8143 loss_val: 0.7869 acc_val: 0.8280 time: 0.0465s\n",
            "116\n",
            "Epoch: 0864 loss_train: 0.9179 acc_train: 0.7929 loss_val: 0.7849 acc_val: 0.8220 time: 0.0444s\n",
            "117\n",
            "Epoch: 0865 loss_train: 0.9005 acc_train: 0.7286 loss_val: 0.7843 acc_val: 0.8200 time: 0.0444s\n",
            "118\n",
            "Epoch: 0866 loss_train: 0.9212 acc_train: 0.8071 loss_val: 0.7861 acc_val: 0.8220 time: 0.0444s\n",
            "119\n",
            "Epoch: 0867 loss_train: 0.8754 acc_train: 0.8286 loss_val: 0.7877 acc_val: 0.8260 time: 0.0442s\n",
            "120\n",
            "Epoch: 0868 loss_train: 0.9473 acc_train: 0.7786 loss_val: 0.7928 acc_val: 0.8280 time: 0.0455s\n",
            "121\n",
            "Epoch: 0869 loss_train: 0.9102 acc_train: 0.7857 loss_val: 0.7962 acc_val: 0.8200 time: 0.0452s\n",
            "122\n",
            "Epoch: 0870 loss_train: 0.9205 acc_train: 0.7857 loss_val: 0.7970 acc_val: 0.8200 time: 0.0440s\n",
            "123\n",
            "Epoch: 0871 loss_train: 0.8974 acc_train: 0.8357 loss_val: 0.7943 acc_val: 0.8200 time: 0.0454s\n",
            "124\n",
            "Epoch: 0872 loss_train: 0.9198 acc_train: 0.8214 loss_val: 0.7893 acc_val: 0.8180 time: 0.0443s\n",
            "125\n",
            "Epoch: 0873 loss_train: 0.9049 acc_train: 0.7643 loss_val: 0.7849 acc_val: 0.8240 time: 0.0457s\n",
            "126\n",
            "Epoch: 0874 loss_train: 0.9118 acc_train: 0.8000 loss_val: 0.7843 acc_val: 0.8320 time: 0.0469s\n",
            "127\n",
            "Epoch: 0875 loss_train: 0.9317 acc_train: 0.8000 loss_val: 0.7866 acc_val: 0.8260 time: 0.0464s\n",
            "128\n",
            "Epoch: 0876 loss_train: 0.9302 acc_train: 0.7571 loss_val: 0.7892 acc_val: 0.8280 time: 0.0438s\n",
            "129\n",
            "Epoch: 0877 loss_train: 0.8876 acc_train: 0.7857 loss_val: 0.7910 acc_val: 0.8260 time: 0.0440s\n",
            "130\n",
            "Epoch: 0878 loss_train: 0.9131 acc_train: 0.7857 loss_val: 0.7929 acc_val: 0.8220 time: 0.0447s\n",
            "131\n",
            "Epoch: 0879 loss_train: 0.8870 acc_train: 0.8214 loss_val: 0.7917 acc_val: 0.8220 time: 0.0451s\n",
            "132\n",
            "Epoch: 0880 loss_train: 0.9269 acc_train: 0.8000 loss_val: 0.7905 acc_val: 0.8200 time: 0.0445s\n",
            "133\n",
            "Epoch: 0881 loss_train: 0.9067 acc_train: 0.8214 loss_val: 0.7896 acc_val: 0.8180 time: 0.0449s\n",
            "134\n",
            "Epoch: 0882 loss_train: 0.9544 acc_train: 0.7786 loss_val: 0.7865 acc_val: 0.8120 time: 0.0443s\n",
            "135\n",
            "Epoch: 0883 loss_train: 0.8805 acc_train: 0.7929 loss_val: 0.7851 acc_val: 0.8160 time: 0.0450s\n",
            "136\n",
            "Epoch: 0884 loss_train: 0.8921 acc_train: 0.7643 loss_val: 0.7848 acc_val: 0.8220 time: 0.0451s\n",
            "137\n",
            "Epoch: 0885 loss_train: 0.8778 acc_train: 0.8000 loss_val: 0.7846 acc_val: 0.8240 time: 0.0443s\n",
            "138\n",
            "Epoch: 0886 loss_train: 0.8940 acc_train: 0.8286 loss_val: 0.7860 acc_val: 0.8200 time: 0.0452s\n",
            "139\n",
            "Epoch: 0887 loss_train: 0.8990 acc_train: 0.8214 loss_val: 0.7853 acc_val: 0.8200 time: 0.0444s\n",
            "140\n",
            "Epoch: 0888 loss_train: 0.9216 acc_train: 0.7714 loss_val: 0.7861 acc_val: 0.8140 time: 0.0457s\n",
            "141\n",
            "Epoch: 0889 loss_train: 0.8696 acc_train: 0.8357 loss_val: 0.7840 acc_val: 0.8120 time: 0.0461s\n",
            "142\n",
            "Epoch: 0890 loss_train: 0.8877 acc_train: 0.8143 loss_val: 0.7829 acc_val: 0.8160 time: 0.0453s\n",
            "143\n",
            "Epoch: 0891 loss_train: 0.9025 acc_train: 0.8000 loss_val: 0.7866 acc_val: 0.8200 time: 0.0454s\n",
            "144\n",
            "Epoch: 0892 loss_train: 0.8839 acc_train: 0.8000 loss_val: 0.7877 acc_val: 0.8200 time: 0.0445s\n",
            "145\n",
            "Epoch: 0893 loss_train: 0.8662 acc_train: 0.8429 loss_val: 0.7898 acc_val: 0.8240 time: 0.0456s\n",
            "146\n",
            "Epoch: 0894 loss_train: 0.8912 acc_train: 0.8143 loss_val: 0.7921 acc_val: 0.8240 time: 0.0443s\n",
            "147\n",
            "Epoch: 0895 loss_train: 0.8881 acc_train: 0.8357 loss_val: 0.7911 acc_val: 0.8260 time: 0.0478s\n",
            "148\n",
            "Epoch: 0896 loss_train: 0.9009 acc_train: 0.8214 loss_val: 0.7891 acc_val: 0.8240 time: 0.0444s\n",
            "149\n",
            "Epoch: 0897 loss_train: 0.9091 acc_train: 0.8143 loss_val: 0.7851 acc_val: 0.8280 time: 0.0440s\n",
            "150\n",
            "Epoch: 0898 loss_train: 0.8681 acc_train: 0.8214 loss_val: 0.7824 acc_val: 0.8280 time: 0.0456s\n",
            "151\n",
            "Epoch: 0899 loss_train: 0.9188 acc_train: 0.7929 loss_val: 0.7820 acc_val: 0.8220 time: 0.0440s\n",
            "152\n",
            "Epoch: 0900 loss_train: 0.9202 acc_train: 0.8071 loss_val: 0.7860 acc_val: 0.8220 time: 0.0443s\n",
            "153\n",
            "Epoch: 0901 loss_train: 0.9351 acc_train: 0.8357 loss_val: 0.7901 acc_val: 0.8300 time: 0.0443s\n",
            "154\n",
            "Epoch: 0902 loss_train: 0.8887 acc_train: 0.7857 loss_val: 0.7909 acc_val: 0.8260 time: 0.0449s\n",
            "155\n",
            "Epoch: 0903 loss_train: 0.9528 acc_train: 0.7643 loss_val: 0.7884 acc_val: 0.8280 time: 0.0459s\n",
            "156\n",
            "Epoch: 0904 loss_train: 0.9012 acc_train: 0.7571 loss_val: 0.7863 acc_val: 0.8180 time: 0.0442s\n",
            "157\n",
            "Epoch: 0905 loss_train: 0.9123 acc_train: 0.7143 loss_val: 0.7875 acc_val: 0.8200 time: 0.0452s\n",
            "158\n",
            "Epoch: 0906 loss_train: 0.9202 acc_train: 0.8071 loss_val: 0.7905 acc_val: 0.8220 time: 0.0439s\n",
            "159\n",
            "Epoch: 0907 loss_train: 0.9374 acc_train: 0.7500 loss_val: 0.7921 acc_val: 0.8160 time: 0.0441s\n",
            "160\n",
            "Epoch: 0908 loss_train: 0.9039 acc_train: 0.7857 loss_val: 0.7902 acc_val: 0.8200 time: 0.0457s\n",
            "161\n",
            "Epoch: 0909 loss_train: 0.8940 acc_train: 0.8286 loss_val: 0.7887 acc_val: 0.8140 time: 0.0453s\n",
            "162\n",
            "Epoch: 0910 loss_train: 0.9124 acc_train: 0.7643 loss_val: 0.7883 acc_val: 0.8160 time: 0.0449s\n",
            "163\n",
            "Epoch: 0911 loss_train: 0.9113 acc_train: 0.8357 loss_val: 0.7892 acc_val: 0.8220 time: 0.0451s\n",
            "164\n",
            "Epoch: 0912 loss_train: 0.9445 acc_train: 0.8214 loss_val: 0.7907 acc_val: 0.8180 time: 0.0483s\n",
            "165\n",
            "Epoch: 0913 loss_train: 0.8789 acc_train: 0.7786 loss_val: 0.7906 acc_val: 0.8200 time: 0.0459s\n",
            "166\n",
            "Epoch: 0914 loss_train: 0.8946 acc_train: 0.8143 loss_val: 0.7888 acc_val: 0.8220 time: 0.0440s\n",
            "167\n",
            "Epoch: 0915 loss_train: 0.9624 acc_train: 0.7786 loss_val: 0.7873 acc_val: 0.8240 time: 0.0451s\n",
            "168\n",
            "Epoch: 0916 loss_train: 0.9190 acc_train: 0.7786 loss_val: 0.7882 acc_val: 0.8240 time: 0.0475s\n",
            "169\n",
            "Epoch: 0917 loss_train: 0.8849 acc_train: 0.8286 loss_val: 0.7879 acc_val: 0.8240 time: 0.0466s\n",
            "170\n",
            "Epoch: 0918 loss_train: 0.8942 acc_train: 0.8000 loss_val: 0.7878 acc_val: 0.8260 time: 0.0455s\n",
            "171\n",
            "Epoch: 0919 loss_train: 0.9259 acc_train: 0.7929 loss_val: 0.7882 acc_val: 0.8260 time: 0.0442s\n",
            "172\n",
            "Epoch: 0920 loss_train: 0.9096 acc_train: 0.8000 loss_val: 0.7889 acc_val: 0.8240 time: 0.0443s\n",
            "173\n",
            "Epoch: 0921 loss_train: 0.9220 acc_train: 0.7714 loss_val: 0.7884 acc_val: 0.8240 time: 0.0440s\n",
            "174\n",
            "Epoch: 0922 loss_train: 0.8939 acc_train: 0.8000 loss_val: 0.7859 acc_val: 0.8220 time: 0.0444s\n",
            "175\n",
            "Epoch: 0923 loss_train: 0.8584 acc_train: 0.8214 loss_val: 0.7822 acc_val: 0.8260 time: 0.0485s\n",
            "176\n",
            "Epoch: 0924 loss_train: 0.9362 acc_train: 0.8071 loss_val: 0.7788 acc_val: 0.8260 time: 0.0444s\n",
            "177\n",
            "Epoch: 0925 loss_train: 0.9398 acc_train: 0.7786 loss_val: 0.7762 acc_val: 0.8300 time: 0.0443s\n",
            "178\n",
            "Epoch: 0926 loss_train: 0.9680 acc_train: 0.7643 loss_val: 0.7801 acc_val: 0.8260 time: 0.0441s\n",
            "0\n",
            "Epoch: 0927 loss_train: 0.8917 acc_train: 0.7786 loss_val: 0.7841 acc_val: 0.8280 time: 0.0443s\n",
            "1\n",
            "Epoch: 0928 loss_train: 0.9103 acc_train: 0.8000 loss_val: 0.7888 acc_val: 0.8220 time: 0.0461s\n",
            "2\n",
            "Epoch: 0929 loss_train: 0.8969 acc_train: 0.8071 loss_val: 0.7948 acc_val: 0.8180 time: 0.0442s\n",
            "3\n",
            "Epoch: 0930 loss_train: 0.8614 acc_train: 0.8214 loss_val: 0.7971 acc_val: 0.8140 time: 0.0439s\n",
            "4\n",
            "Epoch: 0931 loss_train: 0.9133 acc_train: 0.7929 loss_val: 0.7964 acc_val: 0.8140 time: 0.0440s\n",
            "5\n",
            "Epoch: 0932 loss_train: 0.8952 acc_train: 0.8786 loss_val: 0.7930 acc_val: 0.8180 time: 0.0453s\n",
            "6\n",
            "Epoch: 0933 loss_train: 0.9276 acc_train: 0.8071 loss_val: 0.7884 acc_val: 0.8200 time: 0.0463s\n",
            "7\n",
            "Epoch: 0934 loss_train: 0.9224 acc_train: 0.8357 loss_val: 0.7853 acc_val: 0.8260 time: 0.0455s\n",
            "8\n",
            "Epoch: 0935 loss_train: 0.8849 acc_train: 0.8071 loss_val: 0.7820 acc_val: 0.8260 time: 0.0460s\n",
            "9\n",
            "Epoch: 0936 loss_train: 0.8998 acc_train: 0.7857 loss_val: 0.7774 acc_val: 0.8260 time: 0.0441s\n",
            "10\n",
            "Epoch: 0937 loss_train: 0.9182 acc_train: 0.7929 loss_val: 0.7772 acc_val: 0.8280 time: 0.0441s\n",
            "11\n",
            "Epoch: 0938 loss_train: 0.8907 acc_train: 0.8143 loss_val: 0.7798 acc_val: 0.8220 time: 0.0474s\n",
            "12\n",
            "Epoch: 0939 loss_train: 0.9316 acc_train: 0.8357 loss_val: 0.7821 acc_val: 0.8220 time: 0.0441s\n",
            "13\n",
            "Epoch: 0940 loss_train: 0.9748 acc_train: 0.7214 loss_val: 0.7829 acc_val: 0.8260 time: 0.0447s\n",
            "14\n",
            "Epoch: 0941 loss_train: 0.9624 acc_train: 0.7786 loss_val: 0.7878 acc_val: 0.8260 time: 0.0442s\n",
            "15\n",
            "Epoch: 0942 loss_train: 0.9255 acc_train: 0.7857 loss_val: 0.7920 acc_val: 0.8240 time: 0.0444s\n",
            "16\n",
            "Epoch: 0943 loss_train: 0.9057 acc_train: 0.7929 loss_val: 0.7948 acc_val: 0.8200 time: 0.0452s\n",
            "17\n",
            "Epoch: 0944 loss_train: 0.9213 acc_train: 0.7714 loss_val: 0.7998 acc_val: 0.8200 time: 0.0444s\n",
            "18\n",
            "Epoch: 0945 loss_train: 0.9399 acc_train: 0.8214 loss_val: 0.8028 acc_val: 0.8260 time: 0.0446s\n",
            "19\n",
            "Epoch: 0946 loss_train: 0.9006 acc_train: 0.8500 loss_val: 0.7998 acc_val: 0.8300 time: 0.0462s\n",
            "20\n",
            "Epoch: 0947 loss_train: 0.9259 acc_train: 0.7500 loss_val: 0.7932 acc_val: 0.8300 time: 0.0442s\n",
            "21\n",
            "Epoch: 0948 loss_train: 0.9328 acc_train: 0.8071 loss_val: 0.7886 acc_val: 0.8260 time: 0.0476s\n",
            "22\n",
            "Epoch: 0949 loss_train: 0.8893 acc_train: 0.8071 loss_val: 0.7839 acc_val: 0.8240 time: 0.0439s\n",
            "23\n",
            "Epoch: 0950 loss_train: 0.9140 acc_train: 0.7714 loss_val: 0.7800 acc_val: 0.8220 time: 0.0449s\n",
            "24\n",
            "Epoch: 0951 loss_train: 0.8877 acc_train: 0.8357 loss_val: 0.7793 acc_val: 0.8240 time: 0.0440s\n",
            "25\n",
            "Epoch: 0952 loss_train: 0.9187 acc_train: 0.7786 loss_val: 0.7782 acc_val: 0.8220 time: 0.0441s\n",
            "26\n",
            "Epoch: 0953 loss_train: 0.8938 acc_train: 0.8071 loss_val: 0.7786 acc_val: 0.8180 time: 0.0466s\n",
            "27\n",
            "Epoch: 0954 loss_train: 0.9090 acc_train: 0.8429 loss_val: 0.7800 acc_val: 0.8240 time: 0.0451s\n",
            "28\n",
            "Epoch: 0955 loss_train: 0.9398 acc_train: 0.7929 loss_val: 0.7849 acc_val: 0.8260 time: 0.0443s\n",
            "29\n",
            "Epoch: 0956 loss_train: 0.9085 acc_train: 0.8000 loss_val: 0.7903 acc_val: 0.8280 time: 0.0451s\n",
            "30\n",
            "Epoch: 0957 loss_train: 0.8924 acc_train: 0.7857 loss_val: 0.7941 acc_val: 0.8260 time: 0.0441s\n",
            "31\n",
            "Epoch: 0958 loss_train: 0.8886 acc_train: 0.8214 loss_val: 0.7983 acc_val: 0.8280 time: 0.0456s\n",
            "32\n",
            "Epoch: 0959 loss_train: 0.8937 acc_train: 0.8214 loss_val: 0.7993 acc_val: 0.8240 time: 0.0461s\n",
            "33\n",
            "Epoch: 0960 loss_train: 0.9078 acc_train: 0.7929 loss_val: 0.8017 acc_val: 0.8260 time: 0.0460s\n",
            "34\n",
            "Epoch: 0961 loss_train: 0.9314 acc_train: 0.7929 loss_val: 0.7976 acc_val: 0.8220 time: 0.0440s\n",
            "35\n",
            "Epoch: 0962 loss_train: 0.9191 acc_train: 0.8000 loss_val: 0.7928 acc_val: 0.8240 time: 0.0439s\n",
            "36\n",
            "Epoch: 0963 loss_train: 0.9217 acc_train: 0.8071 loss_val: 0.7871 acc_val: 0.8220 time: 0.0448s\n",
            "37\n",
            "Epoch: 0964 loss_train: 0.9036 acc_train: 0.8143 loss_val: 0.7817 acc_val: 0.8260 time: 0.0445s\n",
            "38\n",
            "Epoch: 0965 loss_train: 0.8582 acc_train: 0.8286 loss_val: 0.7775 acc_val: 0.8260 time: 0.0444s\n",
            "39\n",
            "Epoch: 0966 loss_train: 0.9027 acc_train: 0.7929 loss_val: 0.7770 acc_val: 0.8220 time: 0.0439s\n",
            "40\n",
            "Epoch: 0967 loss_train: 0.9027 acc_train: 0.7857 loss_val: 0.7799 acc_val: 0.8220 time: 0.0462s\n",
            "41\n",
            "Epoch: 0968 loss_train: 0.9112 acc_train: 0.7714 loss_val: 0.7868 acc_val: 0.8260 time: 0.0452s\n",
            "42\n",
            "Epoch: 0969 loss_train: 0.9248 acc_train: 0.7429 loss_val: 0.7943 acc_val: 0.8220 time: 0.0440s\n",
            "43\n",
            "Epoch: 0970 loss_train: 0.9635 acc_train: 0.7929 loss_val: 0.8006 acc_val: 0.8200 time: 0.0442s\n",
            "44\n",
            "Epoch: 0971 loss_train: 0.8503 acc_train: 0.8357 loss_val: 0.8011 acc_val: 0.8220 time: 0.0442s\n",
            "45\n",
            "Epoch: 0972 loss_train: 0.9153 acc_train: 0.8000 loss_val: 0.7968 acc_val: 0.8180 time: 0.0447s\n",
            "46\n",
            "Epoch: 0973 loss_train: 0.8599 acc_train: 0.8500 loss_val: 0.7895 acc_val: 0.8220 time: 0.0453s\n",
            "47\n",
            "Epoch: 0974 loss_train: 0.8907 acc_train: 0.8429 loss_val: 0.7838 acc_val: 0.8240 time: 0.0457s\n",
            "48\n",
            "Epoch: 0975 loss_train: 0.9031 acc_train: 0.8500 loss_val: 0.7810 acc_val: 0.8220 time: 0.0454s\n",
            "49\n",
            "Epoch: 0976 loss_train: 0.8879 acc_train: 0.8857 loss_val: 0.7793 acc_val: 0.8220 time: 0.0457s\n",
            "50\n",
            "Epoch: 0977 loss_train: 0.8891 acc_train: 0.7857 loss_val: 0.7813 acc_val: 0.8240 time: 0.0457s\n",
            "51\n",
            "Epoch: 0978 loss_train: 0.9048 acc_train: 0.7786 loss_val: 0.7857 acc_val: 0.8220 time: 0.0454s\n",
            "52\n",
            "Epoch: 0979 loss_train: 0.8877 acc_train: 0.8000 loss_val: 0.7909 acc_val: 0.8260 time: 0.0443s\n",
            "53\n",
            "Epoch: 0980 loss_train: 0.8669 acc_train: 0.8500 loss_val: 0.7892 acc_val: 0.8260 time: 0.0443s\n",
            "54\n",
            "Epoch: 0981 loss_train: 0.9183 acc_train: 0.7571 loss_val: 0.7905 acc_val: 0.8220 time: 0.0458s\n",
            "55\n",
            "Epoch: 0982 loss_train: 0.8667 acc_train: 0.8214 loss_val: 0.7903 acc_val: 0.8220 time: 0.0440s\n",
            "56\n",
            "Epoch: 0983 loss_train: 0.8953 acc_train: 0.8643 loss_val: 0.7895 acc_val: 0.8260 time: 0.0451s\n",
            "57\n",
            "Epoch: 0984 loss_train: 0.9265 acc_train: 0.7786 loss_val: 0.7907 acc_val: 0.8280 time: 0.0442s\n",
            "58\n",
            "Epoch: 0985 loss_train: 0.8954 acc_train: 0.8143 loss_val: 0.7888 acc_val: 0.8280 time: 0.0442s\n",
            "59\n",
            "Epoch: 0986 loss_train: 0.8772 acc_train: 0.8286 loss_val: 0.7869 acc_val: 0.8240 time: 0.0447s\n",
            "60\n",
            "Epoch: 0987 loss_train: 0.8627 acc_train: 0.8286 loss_val: 0.7862 acc_val: 0.8220 time: 0.0464s\n",
            "61\n",
            "Epoch: 0988 loss_train: 0.8767 acc_train: 0.8071 loss_val: 0.7860 acc_val: 0.8160 time: 0.0483s\n",
            "62\n",
            "Epoch: 0989 loss_train: 0.9250 acc_train: 0.7857 loss_val: 0.7868 acc_val: 0.8160 time: 0.0457s\n",
            "63\n",
            "Epoch: 0990 loss_train: 0.9022 acc_train: 0.8571 loss_val: 0.7923 acc_val: 0.8180 time: 0.0454s\n",
            "64\n",
            "Epoch: 0991 loss_train: 0.8716 acc_train: 0.8000 loss_val: 0.7945 acc_val: 0.8200 time: 0.0439s\n",
            "65\n",
            "Epoch: 0992 loss_train: 0.8974 acc_train: 0.7786 loss_val: 0.7971 acc_val: 0.8240 time: 0.0444s\n",
            "66\n",
            "Epoch: 0993 loss_train: 0.8827 acc_train: 0.8071 loss_val: 0.7979 acc_val: 0.8220 time: 0.0452s\n",
            "67\n",
            "Epoch: 0994 loss_train: 0.8983 acc_train: 0.8071 loss_val: 0.7923 acc_val: 0.8260 time: 0.0441s\n",
            "68\n",
            "Epoch: 0995 loss_train: 0.8975 acc_train: 0.7571 loss_val: 0.7869 acc_val: 0.8320 time: 0.0439s\n",
            "69\n",
            "Epoch: 0996 loss_train: 0.9129 acc_train: 0.8500 loss_val: 0.7834 acc_val: 0.8280 time: 0.0444s\n",
            "70\n",
            "Epoch: 0997 loss_train: 0.8955 acc_train: 0.7786 loss_val: 0.7807 acc_val: 0.8220 time: 0.0441s\n",
            "71\n",
            "Epoch: 0998 loss_train: 0.8657 acc_train: 0.8286 loss_val: 0.7785 acc_val: 0.8200 time: 0.0449s\n",
            "72\n",
            "Epoch: 0999 loss_train: 0.8869 acc_train: 0.8214 loss_val: 0.7786 acc_val: 0.8260 time: 0.0445s\n",
            "73\n",
            "Epoch: 1000 loss_train: 0.9207 acc_train: 0.7857 loss_val: 0.7821 acc_val: 0.8200 time: 0.0442s\n",
            "74\n",
            "Epoch: 1001 loss_train: 0.8684 acc_train: 0.8571 loss_val: 0.7865 acc_val: 0.8220 time: 0.0442s\n",
            "75\n",
            "Epoch: 1002 loss_train: 0.9318 acc_train: 0.7714 loss_val: 0.7924 acc_val: 0.8240 time: 0.0445s\n",
            "76\n",
            "Epoch: 1003 loss_train: 0.8821 acc_train: 0.7714 loss_val: 0.7961 acc_val: 0.8200 time: 0.0463s\n",
            "77\n",
            "Epoch: 1004 loss_train: 0.9156 acc_train: 0.7857 loss_val: 0.7995 acc_val: 0.8220 time: 0.0439s\n",
            "78\n",
            "Epoch: 1005 loss_train: 0.9248 acc_train: 0.8071 loss_val: 0.7976 acc_val: 0.8260 time: 0.0440s\n",
            "79\n",
            "Epoch: 1006 loss_train: 0.9312 acc_train: 0.7643 loss_val: 0.7931 acc_val: 0.8280 time: 0.0439s\n",
            "80\n",
            "Epoch: 1007 loss_train: 0.9148 acc_train: 0.8071 loss_val: 0.7884 acc_val: 0.8280 time: 0.0441s\n",
            "81\n",
            "Epoch: 1008 loss_train: 0.9329 acc_train: 0.7643 loss_val: 0.7848 acc_val: 0.8260 time: 0.0479s\n",
            "82\n",
            "Epoch: 1009 loss_train: 0.9535 acc_train: 0.7786 loss_val: 0.7838 acc_val: 0.8280 time: 0.0466s\n",
            "83\n",
            "Epoch: 1010 loss_train: 0.8571 acc_train: 0.8500 loss_val: 0.7856 acc_val: 0.8240 time: 0.0457s\n",
            "84\n",
            "Epoch: 1011 loss_train: 0.8830 acc_train: 0.8071 loss_val: 0.7880 acc_val: 0.8280 time: 0.0446s\n",
            "85\n",
            "Epoch: 1012 loss_train: 0.8951 acc_train: 0.8357 loss_val: 0.7890 acc_val: 0.8260 time: 0.0444s\n",
            "86\n",
            "Epoch: 1013 loss_train: 0.8962 acc_train: 0.8143 loss_val: 0.7879 acc_val: 0.8300 time: 0.0455s\n",
            "87\n",
            "Epoch: 1014 loss_train: 0.9163 acc_train: 0.8000 loss_val: 0.7855 acc_val: 0.8240 time: 0.0440s\n",
            "88\n",
            "Epoch: 1015 loss_train: 0.8867 acc_train: 0.7857 loss_val: 0.7846 acc_val: 0.8240 time: 0.0454s\n",
            "89\n",
            "Epoch: 1016 loss_train: 0.8735 acc_train: 0.8643 loss_val: 0.7844 acc_val: 0.8260 time: 0.0440s\n",
            "90\n",
            "Epoch: 1017 loss_train: 0.9084 acc_train: 0.7643 loss_val: 0.7847 acc_val: 0.8260 time: 0.0466s\n",
            "91\n",
            "Epoch: 1018 loss_train: 0.9276 acc_train: 0.8214 loss_val: 0.7853 acc_val: 0.8240 time: 0.0459s\n",
            "92\n",
            "Epoch: 1019 loss_train: 0.8638 acc_train: 0.8143 loss_val: 0.7863 acc_val: 0.8220 time: 0.0479s\n",
            "93\n",
            "Epoch: 1020 loss_train: 0.9281 acc_train: 0.8214 loss_val: 0.7915 acc_val: 0.8220 time: 0.0439s\n",
            "94\n",
            "Epoch: 1021 loss_train: 0.9016 acc_train: 0.7857 loss_val: 0.7994 acc_val: 0.8160 time: 0.0441s\n",
            "95\n",
            "Epoch: 1022 loss_train: 0.8430 acc_train: 0.8786 loss_val: 0.8028 acc_val: 0.8120 time: 0.0445s\n",
            "96\n",
            "Epoch: 1023 loss_train: 0.9542 acc_train: 0.7929 loss_val: 0.7999 acc_val: 0.8180 time: 0.0450s\n",
            "97\n",
            "Epoch: 1024 loss_train: 0.8938 acc_train: 0.8286 loss_val: 0.7952 acc_val: 0.8180 time: 0.0462s\n",
            "98\n",
            "Epoch: 1025 loss_train: 0.9006 acc_train: 0.7929 loss_val: 0.7913 acc_val: 0.8160 time: 0.0441s\n",
            "99\n",
            "Epoch: 1026 loss_train: 0.8822 acc_train: 0.8286 loss_val: 0.7864 acc_val: 0.8240 time: 0.0445s\n",
            "100\n",
            "Epoch: 1027 loss_train: 0.8904 acc_train: 0.7429 loss_val: 0.7820 acc_val: 0.8240 time: 0.0440s\n",
            "101\n",
            "Epoch: 1028 loss_train: 0.9189 acc_train: 0.7643 loss_val: 0.7801 acc_val: 0.8260 time: 0.0454s\n",
            "102\n",
            "Epoch: 1029 loss_train: 0.9034 acc_train: 0.7714 loss_val: 0.7789 acc_val: 0.8200 time: 0.0445s\n",
            "103\n",
            "Epoch: 1030 loss_train: 0.8970 acc_train: 0.7786 loss_val: 0.7784 acc_val: 0.8260 time: 0.0448s\n",
            "104\n",
            "Epoch: 1031 loss_train: 0.8969 acc_train: 0.8000 loss_val: 0.7803 acc_val: 0.8220 time: 0.0462s\n",
            "105\n",
            "Epoch: 1032 loss_train: 0.8971 acc_train: 0.7714 loss_val: 0.7835 acc_val: 0.8240 time: 0.0440s\n",
            "106\n",
            "Epoch: 1033 loss_train: 0.8811 acc_train: 0.8357 loss_val: 0.7872 acc_val: 0.8220 time: 0.0459s\n",
            "107\n",
            "Epoch: 1034 loss_train: 0.8916 acc_train: 0.7500 loss_val: 0.7891 acc_val: 0.8180 time: 0.0452s\n",
            "108\n",
            "Epoch: 1035 loss_train: 0.8790 acc_train: 0.8286 loss_val: 0.7870 acc_val: 0.8180 time: 0.0448s\n",
            "109\n",
            "Epoch: 1036 loss_train: 0.8926 acc_train: 0.8571 loss_val: 0.7848 acc_val: 0.8220 time: 0.0444s\n",
            "110\n",
            "Epoch: 1037 loss_train: 0.8652 acc_train: 0.8071 loss_val: 0.7821 acc_val: 0.8260 time: 0.0441s\n",
            "111\n",
            "Epoch: 1038 loss_train: 0.8837 acc_train: 0.8214 loss_val: 0.7812 acc_val: 0.8260 time: 0.0459s\n",
            "112\n",
            "Epoch: 1039 loss_train: 0.9545 acc_train: 0.7643 loss_val: 0.7828 acc_val: 0.8300 time: 0.0441s\n",
            "113\n",
            "Epoch: 1040 loss_train: 0.8847 acc_train: 0.7857 loss_val: 0.7846 acc_val: 0.8300 time: 0.0439s\n",
            "114\n",
            "Epoch: 1041 loss_train: 0.8612 acc_train: 0.8143 loss_val: 0.7889 acc_val: 0.8300 time: 0.0452s\n",
            "115\n",
            "Epoch: 1042 loss_train: 0.8703 acc_train: 0.8429 loss_val: 0.7932 acc_val: 0.8220 time: 0.0441s\n",
            "116\n",
            "Epoch: 1043 loss_train: 0.8595 acc_train: 0.7929 loss_val: 0.7952 acc_val: 0.8200 time: 0.0458s\n",
            "117\n",
            "Epoch: 1044 loss_train: 0.8855 acc_train: 0.8357 loss_val: 0.7929 acc_val: 0.8160 time: 0.0443s\n",
            "118\n",
            "Epoch: 1045 loss_train: 0.9069 acc_train: 0.8000 loss_val: 0.7912 acc_val: 0.8140 time: 0.0457s\n",
            "119\n",
            "Epoch: 1046 loss_train: 0.8871 acc_train: 0.7786 loss_val: 0.7901 acc_val: 0.8180 time: 0.0447s\n",
            "120\n",
            "Epoch: 1047 loss_train: 0.9273 acc_train: 0.8214 loss_val: 0.7890 acc_val: 0.8180 time: 0.0524s\n",
            "121\n",
            "Epoch: 1048 loss_train: 0.8565 acc_train: 0.8286 loss_val: 0.7897 acc_val: 0.8220 time: 0.0467s\n",
            "122\n",
            "Epoch: 1049 loss_train: 0.8909 acc_train: 0.8071 loss_val: 0.7908 acc_val: 0.8200 time: 0.0472s\n",
            "123\n",
            "Epoch: 1050 loss_train: 0.9156 acc_train: 0.8500 loss_val: 0.7918 acc_val: 0.8200 time: 0.0491s\n",
            "124\n",
            "Epoch: 1051 loss_train: 0.8979 acc_train: 0.7714 loss_val: 0.7922 acc_val: 0.8320 time: 0.0442s\n",
            "125\n",
            "Epoch: 1052 loss_train: 0.8710 acc_train: 0.7929 loss_val: 0.7918 acc_val: 0.8320 time: 0.0443s\n",
            "126\n",
            "Epoch: 1053 loss_train: 0.9039 acc_train: 0.8000 loss_val: 0.7908 acc_val: 0.8260 time: 0.0453s\n",
            "127\n",
            "Epoch: 1054 loss_train: 0.9093 acc_train: 0.7357 loss_val: 0.7889 acc_val: 0.8220 time: 0.0439s\n",
            "128\n",
            "Epoch: 1055 loss_train: 0.9146 acc_train: 0.7643 loss_val: 0.7856 acc_val: 0.8220 time: 0.0442s\n",
            "129\n",
            "Epoch: 1056 loss_train: 0.9004 acc_train: 0.7714 loss_val: 0.7854 acc_val: 0.8180 time: 0.0452s\n",
            "130\n",
            "Epoch: 1057 loss_train: 0.8845 acc_train: 0.8143 loss_val: 0.7872 acc_val: 0.8200 time: 0.0448s\n",
            "131\n",
            "Epoch: 1058 loss_train: 0.8666 acc_train: 0.8429 loss_val: 0.7902 acc_val: 0.8180 time: 0.0453s\n",
            "132\n",
            "Epoch: 1059 loss_train: 0.9254 acc_train: 0.7857 loss_val: 0.7933 acc_val: 0.8200 time: 0.0460s\n",
            "133\n",
            "Epoch: 1060 loss_train: 0.8903 acc_train: 0.7429 loss_val: 0.7934 acc_val: 0.8220 time: 0.0443s\n",
            "134\n",
            "Epoch: 1061 loss_train: 0.8661 acc_train: 0.7929 loss_val: 0.7915 acc_val: 0.8300 time: 0.0442s\n",
            "135\n",
            "Epoch: 1062 loss_train: 0.9198 acc_train: 0.7643 loss_val: 0.7883 acc_val: 0.8280 time: 0.0445s\n",
            "136\n",
            "Epoch: 1063 loss_train: 0.8966 acc_train: 0.8214 loss_val: 0.7858 acc_val: 0.8180 time: 0.0458s\n",
            "137\n",
            "Epoch: 1064 loss_train: 0.8935 acc_train: 0.8286 loss_val: 0.7839 acc_val: 0.8180 time: 0.0441s\n",
            "138\n",
            "Epoch: 1065 loss_train: 0.9287 acc_train: 0.7929 loss_val: 0.7859 acc_val: 0.8200 time: 0.0445s\n",
            "139\n",
            "Epoch: 1066 loss_train: 0.9009 acc_train: 0.8214 loss_val: 0.7867 acc_val: 0.8280 time: 0.0442s\n",
            "140\n",
            "Epoch: 1067 loss_train: 0.8753 acc_train: 0.8571 loss_val: 0.7885 acc_val: 0.8260 time: 0.0457s\n",
            "141\n",
            "Epoch: 1068 loss_train: 0.8819 acc_train: 0.8357 loss_val: 0.7900 acc_val: 0.8220 time: 0.0499s\n",
            "142\n",
            "Epoch: 1069 loss_train: 0.8879 acc_train: 0.7714 loss_val: 0.7913 acc_val: 0.8220 time: 0.0441s\n",
            "143\n",
            "Epoch: 1070 loss_train: 0.9010 acc_train: 0.8214 loss_val: 0.7909 acc_val: 0.8200 time: 0.0443s\n",
            "144\n",
            "Epoch: 1071 loss_train: 0.8943 acc_train: 0.8000 loss_val: 0.7918 acc_val: 0.8240 time: 0.0446s\n",
            "145\n",
            "Epoch: 1072 loss_train: 0.8564 acc_train: 0.8714 loss_val: 0.7916 acc_val: 0.8260 time: 0.0442s\n",
            "146\n",
            "Epoch: 1073 loss_train: 0.8857 acc_train: 0.8357 loss_val: 0.7926 acc_val: 0.8260 time: 0.0459s\n",
            "147\n",
            "Epoch: 1074 loss_train: 0.8777 acc_train: 0.8071 loss_val: 0.7944 acc_val: 0.8260 time: 0.0454s\n",
            "148\n",
            "Epoch: 1075 loss_train: 0.9023 acc_train: 0.8000 loss_val: 0.7963 acc_val: 0.8260 time: 0.0450s\n",
            "149\n",
            "Epoch: 1076 loss_train: 0.8784 acc_train: 0.8571 loss_val: 0.7962 acc_val: 0.8300 time: 0.0446s\n",
            "150\n",
            "Epoch: 1077 loss_train: 0.9074 acc_train: 0.8000 loss_val: 0.7911 acc_val: 0.8320 time: 0.0444s\n",
            "151\n",
            "Epoch: 1078 loss_train: 0.8700 acc_train: 0.8286 loss_val: 0.7878 acc_val: 0.8320 time: 0.0452s\n",
            "152\n",
            "Epoch: 1079 loss_train: 0.8728 acc_train: 0.8143 loss_val: 0.7846 acc_val: 0.8280 time: 0.0445s\n",
            "153\n",
            "Epoch: 1080 loss_train: 0.8703 acc_train: 0.8000 loss_val: 0.7830 acc_val: 0.8220 time: 0.0453s\n",
            "154\n",
            "Epoch: 1081 loss_train: 0.9095 acc_train: 0.8357 loss_val: 0.7821 acc_val: 0.8200 time: 0.0458s\n",
            "155\n",
            "Epoch: 1082 loss_train: 0.9203 acc_train: 0.8357 loss_val: 0.7843 acc_val: 0.8300 time: 0.0441s\n",
            "156\n",
            "Epoch: 1083 loss_train: 0.9026 acc_train: 0.8071 loss_val: 0.7866 acc_val: 0.8300 time: 0.0463s\n",
            "157\n",
            "Epoch: 1084 loss_train: 0.8877 acc_train: 0.7786 loss_val: 0.7908 acc_val: 0.8340 time: 0.0439s\n",
            "158\n",
            "Epoch: 1085 loss_train: 0.9000 acc_train: 0.8429 loss_val: 0.7941 acc_val: 0.8300 time: 0.0445s\n",
            "159\n",
            "Epoch: 1086 loss_train: 0.8784 acc_train: 0.8500 loss_val: 0.7943 acc_val: 0.8300 time: 0.0446s\n",
            "160\n",
            "Epoch: 1087 loss_train: 0.8469 acc_train: 0.8286 loss_val: 0.7927 acc_val: 0.8240 time: 0.0442s\n",
            "161\n",
            "Epoch: 1088 loss_train: 0.9080 acc_train: 0.8071 loss_val: 0.7907 acc_val: 0.8220 time: 0.0480s\n",
            "162\n",
            "Epoch: 1089 loss_train: 0.9424 acc_train: 0.7786 loss_val: 0.7912 acc_val: 0.8240 time: 0.0443s\n",
            "163\n",
            "Epoch: 1090 loss_train: 0.9052 acc_train: 0.8286 loss_val: 0.7941 acc_val: 0.8280 time: 0.0454s\n",
            "164\n",
            "Epoch: 1091 loss_train: 0.8995 acc_train: 0.8429 loss_val: 0.7955 acc_val: 0.8200 time: 0.0443s\n",
            "165\n",
            "Epoch: 1092 loss_train: 0.9035 acc_train: 0.8000 loss_val: 0.7976 acc_val: 0.8200 time: 0.0449s\n",
            "166\n",
            "Epoch: 1093 loss_train: 0.8855 acc_train: 0.8357 loss_val: 0.7943 acc_val: 0.8220 time: 0.0471s\n",
            "167\n",
            "Epoch: 1094 loss_train: 0.9209 acc_train: 0.8214 loss_val: 0.7901 acc_val: 0.8260 time: 0.0457s\n",
            "168\n",
            "Epoch: 1095 loss_train: 0.8585 acc_train: 0.8071 loss_val: 0.7878 acc_val: 0.8260 time: 0.0456s\n",
            "169\n",
            "Epoch: 1096 loss_train: 0.9300 acc_train: 0.8143 loss_val: 0.7872 acc_val: 0.8300 time: 0.0442s\n",
            "170\n",
            "Epoch: 1097 loss_train: 0.8780 acc_train: 0.8071 loss_val: 0.7877 acc_val: 0.8260 time: 0.0442s\n",
            "171\n",
            "Epoch: 1098 loss_train: 0.8632 acc_train: 0.8357 loss_val: 0.7874 acc_val: 0.8240 time: 0.0453s\n",
            "172\n",
            "Epoch: 1099 loss_train: 0.8851 acc_train: 0.8143 loss_val: 0.7884 acc_val: 0.8220 time: 0.0441s\n",
            "173\n",
            "Epoch: 1100 loss_train: 0.9052 acc_train: 0.8786 loss_val: 0.7914 acc_val: 0.8200 time: 0.0444s\n",
            "174\n",
            "Epoch: 1101 loss_train: 0.8658 acc_train: 0.8071 loss_val: 0.7952 acc_val: 0.8160 time: 0.0443s\n",
            "175\n",
            "Epoch: 1102 loss_train: 0.9071 acc_train: 0.8429 loss_val: 0.8011 acc_val: 0.8180 time: 0.0443s\n",
            "176\n",
            "Epoch: 1103 loss_train: 0.9262 acc_train: 0.8143 loss_val: 0.8044 acc_val: 0.8200 time: 0.0465s\n",
            "177\n",
            "Epoch: 1104 loss_train: 0.8984 acc_train: 0.8286 loss_val: 0.8017 acc_val: 0.8200 time: 0.0448s\n",
            "178\n",
            "Epoch: 1105 loss_train: 0.8788 acc_train: 0.8429 loss_val: 0.7931 acc_val: 0.8280 time: 0.0444s\n",
            "179\n",
            "Epoch: 1106 loss_train: 0.8686 acc_train: 0.7786 loss_val: 0.7845 acc_val: 0.8260 time: 0.0440s\n",
            "180\n",
            "Epoch: 1107 loss_train: 0.9293 acc_train: 0.7286 loss_val: 0.7797 acc_val: 0.8300 time: 0.0445s\n",
            "181\n",
            "Epoch: 1108 loss_train: 0.9173 acc_train: 0.7786 loss_val: 0.7783 acc_val: 0.8300 time: 0.0460s\n",
            "182\n",
            "Epoch: 1109 loss_train: 0.9017 acc_train: 0.8000 loss_val: 0.7810 acc_val: 0.8200 time: 0.0478s\n",
            "183\n",
            "Epoch: 1110 loss_train: 0.8938 acc_train: 0.8571 loss_val: 0.7857 acc_val: 0.8220 time: 0.0450s\n",
            "184\n",
            "Epoch: 1111 loss_train: 0.9479 acc_train: 0.8000 loss_val: 0.7917 acc_val: 0.8220 time: 0.0453s\n",
            "185\n",
            "Epoch: 1112 loss_train: 0.9286 acc_train: 0.7857 loss_val: 0.7981 acc_val: 0.8200 time: 0.0450s\n",
            "186\n",
            "Epoch: 1113 loss_train: 0.8998 acc_train: 0.8071 loss_val: 0.8027 acc_val: 0.8240 time: 0.0469s\n",
            "187\n",
            "Epoch: 1114 loss_train: 0.9183 acc_train: 0.8143 loss_val: 0.8063 acc_val: 0.8240 time: 0.0450s\n",
            "188\n",
            "Epoch: 1115 loss_train: 0.8511 acc_train: 0.8143 loss_val: 0.8044 acc_val: 0.8180 time: 0.0446s\n",
            "189\n",
            "Epoch: 1116 loss_train: 0.8818 acc_train: 0.8643 loss_val: 0.8008 acc_val: 0.8200 time: 0.0441s\n",
            "190\n",
            "Epoch: 1117 loss_train: 0.8855 acc_train: 0.8500 loss_val: 0.7958 acc_val: 0.8280 time: 0.0459s\n",
            "191\n",
            "Epoch: 1118 loss_train: 0.9574 acc_train: 0.7714 loss_val: 0.7934 acc_val: 0.8240 time: 0.0454s\n",
            "192\n",
            "Epoch: 1119 loss_train: 0.9154 acc_train: 0.8286 loss_val: 0.7937 acc_val: 0.8220 time: 0.0447s\n",
            "193\n",
            "Epoch: 1120 loss_train: 0.8897 acc_train: 0.7929 loss_val: 0.7928 acc_val: 0.8200 time: 0.0440s\n",
            "194\n",
            "Epoch: 1121 loss_train: 0.8858 acc_train: 0.8357 loss_val: 0.7923 acc_val: 0.8180 time: 0.0443s\n",
            "195\n",
            "Epoch: 1122 loss_train: 0.9012 acc_train: 0.8786 loss_val: 0.7931 acc_val: 0.8200 time: 0.0442s\n",
            "196\n",
            "Epoch: 1123 loss_train: 0.9340 acc_train: 0.7429 loss_val: 0.7916 acc_val: 0.8160 time: 0.0464s\n",
            "197\n",
            "Epoch: 1124 loss_train: 0.8585 acc_train: 0.8429 loss_val: 0.7895 acc_val: 0.8160 time: 0.0442s\n",
            "198\n",
            "Epoch: 1125 loss_train: 0.9099 acc_train: 0.8429 loss_val: 0.7861 acc_val: 0.8160 time: 0.0438s\n",
            "199\n",
            "Early stop! Min loss:  0.7762113809585571 , Max accuracy:  0.84\n",
            "Early stop model validation loss:  0.7762113809585571 , accuracy:  0.8300000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 53.7308s\n",
            "Loading 924th epoch\n",
            "Test set results: loss= 0.7475 accuracy= 0.8510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8510, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE-y_knFnlF4",
        "outputId": "ccdf0605-1b81-4815-9d84-25f7e0fd9493"
      },
      "source": [
        "args['tem'] = 1\n",
        "Train() #pubmed\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 5.7686 acc_train: 0.4333 loss_val: 1.9246 acc_val: 0.4160 time: 0.1542s\n",
            "0\n",
            "Epoch: 0002 loss_train: 3.1206 acc_train: 0.4167 loss_val: 1.1495 acc_val: 0.4160 time: 0.1465s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.4342 acc_train: 0.6000 loss_val: 1.0672 acc_val: 0.4160 time: 0.1449s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.4437 acc_train: 0.5167 loss_val: 1.4200 acc_val: 0.3880 time: 0.1444s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.5514 acc_train: 0.4500 loss_val: 1.5445 acc_val: 0.3880 time: 0.1459s\n",
            "1\n",
            "Epoch: 0006 loss_train: 1.6841 acc_train: 0.2833 loss_val: 1.2463 acc_val: 0.3880 time: 0.1452s\n",
            "2\n",
            "Epoch: 0007 loss_train: 1.4469 acc_train: 0.4167 loss_val: 1.0834 acc_val: 0.3880 time: 0.1455s\n",
            "3\n",
            "Epoch: 0008 loss_train: 1.3405 acc_train: 0.4000 loss_val: 1.0515 acc_val: 0.4800 time: 0.1447s\n",
            "4\n",
            "Epoch: 0009 loss_train: 1.3146 acc_train: 0.5167 loss_val: 1.0497 acc_val: 0.4160 time: 0.1449s\n",
            "0\n",
            "Epoch: 0010 loss_train: 1.2615 acc_train: 0.4333 loss_val: 1.0596 acc_val: 0.4280 time: 0.1444s\n",
            "0\n",
            "Epoch: 0011 loss_train: 1.2440 acc_train: 0.4667 loss_val: 1.0956 acc_val: 0.3880 time: 0.1458s\n",
            "1\n",
            "Epoch: 0012 loss_train: 1.1844 acc_train: 0.5833 loss_val: 1.2135 acc_val: 0.3880 time: 0.1458s\n",
            "2\n",
            "Epoch: 0013 loss_train: 1.2387 acc_train: 0.5000 loss_val: 1.3047 acc_val: 0.3880 time: 0.1460s\n",
            "3\n",
            "Epoch: 0014 loss_train: 1.3109 acc_train: 0.4833 loss_val: 1.2469 acc_val: 0.3880 time: 0.1451s\n",
            "4\n",
            "Epoch: 0015 loss_train: 1.3518 acc_train: 0.4833 loss_val: 1.1330 acc_val: 0.3880 time: 0.1450s\n",
            "5\n",
            "Epoch: 0016 loss_train: 1.1281 acc_train: 0.5833 loss_val: 1.0410 acc_val: 0.3880 time: 0.1455s\n",
            "6\n",
            "Epoch: 0017 loss_train: 1.1712 acc_train: 0.5167 loss_val: 0.9708 acc_val: 0.3940 time: 0.1450s\n",
            "0\n",
            "Epoch: 0018 loss_train: 1.3221 acc_train: 0.6333 loss_val: 0.9243 acc_val: 0.4340 time: 0.1448s\n",
            "0\n",
            "Epoch: 0019 loss_train: 1.2111 acc_train: 0.7167 loss_val: 0.8803 acc_val: 0.5640 time: 0.1446s\n",
            "0\n",
            "Epoch: 0020 loss_train: 1.3554 acc_train: 0.6333 loss_val: 0.8356 acc_val: 0.6480 time: 0.1443s\n",
            "0\n",
            "Epoch: 0021 loss_train: 1.0471 acc_train: 0.7000 loss_val: 0.8023 acc_val: 0.6760 time: 0.1449s\n",
            "0\n",
            "Epoch: 0022 loss_train: 1.0045 acc_train: 0.6667 loss_val: 0.7817 acc_val: 0.7000 time: 0.1445s\n",
            "0\n",
            "Epoch: 0023 loss_train: 0.9968 acc_train: 0.6500 loss_val: 0.7668 acc_val: 0.7220 time: 0.1451s\n",
            "0\n",
            "Epoch: 0024 loss_train: 1.1150 acc_train: 0.6500 loss_val: 0.7342 acc_val: 0.7260 time: 0.1446s\n",
            "0\n",
            "Epoch: 0025 loss_train: 0.9886 acc_train: 0.6000 loss_val: 0.7041 acc_val: 0.7460 time: 0.1450s\n",
            "0\n",
            "Epoch: 0026 loss_train: 1.0263 acc_train: 0.6167 loss_val: 0.6840 acc_val: 0.7520 time: 0.1444s\n",
            "0\n",
            "Epoch: 0027 loss_train: 0.8565 acc_train: 0.7333 loss_val: 0.6810 acc_val: 0.7520 time: 0.1450s\n",
            "0\n",
            "Epoch: 0028 loss_train: 1.0031 acc_train: 0.7167 loss_val: 0.6884 acc_val: 0.7380 time: 0.1449s\n",
            "0\n",
            "Epoch: 0029 loss_train: 0.9137 acc_train: 0.6833 loss_val: 0.6877 acc_val: 0.7420 time: 0.1451s\n",
            "1\n",
            "Epoch: 0030 loss_train: 1.1176 acc_train: 0.7000 loss_val: 0.6650 acc_val: 0.7460 time: 0.1446s\n",
            "2\n",
            "Epoch: 0031 loss_train: 0.8422 acc_train: 0.7500 loss_val: 0.6377 acc_val: 0.7620 time: 0.1448s\n",
            "0\n",
            "Epoch: 0032 loss_train: 0.9422 acc_train: 0.6833 loss_val: 0.6685 acc_val: 0.7580 time: 0.1442s\n",
            "0\n",
            "Epoch: 0033 loss_train: 0.9019 acc_train: 0.7500 loss_val: 0.7164 acc_val: 0.7440 time: 0.1465s\n",
            "1\n",
            "Epoch: 0034 loss_train: 0.9167 acc_train: 0.6500 loss_val: 0.7312 acc_val: 0.7400 time: 0.1456s\n",
            "2\n",
            "Epoch: 0035 loss_train: 0.9304 acc_train: 0.7500 loss_val: 0.6742 acc_val: 0.7560 time: 0.1457s\n",
            "3\n",
            "Epoch: 0036 loss_train: 0.8542 acc_train: 0.7500 loss_val: 0.6192 acc_val: 0.7760 time: 0.1454s\n",
            "4\n",
            "Epoch: 0037 loss_train: 0.8626 acc_train: 0.7833 loss_val: 0.5680 acc_val: 0.7840 time: 0.1452s\n",
            "0\n",
            "Epoch: 0038 loss_train: 0.8506 acc_train: 0.7833 loss_val: 0.5470 acc_val: 0.7960 time: 0.1450s\n",
            "0\n",
            "Epoch: 0039 loss_train: 0.7482 acc_train: 0.7167 loss_val: 0.5439 acc_val: 0.8040 time: 0.1451s\n",
            "0\n",
            "Epoch: 0040 loss_train: 0.7261 acc_train: 0.7667 loss_val: 0.5417 acc_val: 0.8080 time: 0.1443s\n",
            "0\n",
            "Epoch: 0041 loss_train: 0.8786 acc_train: 0.7500 loss_val: 0.5201 acc_val: 0.8140 time: 0.1465s\n",
            "0\n",
            "Epoch: 0042 loss_train: 0.8221 acc_train: 0.7500 loss_val: 0.5031 acc_val: 0.8300 time: 0.1444s\n",
            "0\n",
            "Epoch: 0043 loss_train: 0.7783 acc_train: 0.7500 loss_val: 0.4962 acc_val: 0.8380 time: 0.1449s\n",
            "0\n",
            "Epoch: 0044 loss_train: 0.6763 acc_train: 0.7667 loss_val: 0.5036 acc_val: 0.8260 time: 0.1447s\n",
            "0\n",
            "Epoch: 0045 loss_train: 0.7953 acc_train: 0.8000 loss_val: 0.5159 acc_val: 0.8160 time: 0.1463s\n",
            "1\n",
            "Epoch: 0046 loss_train: 0.8739 acc_train: 0.7500 loss_val: 0.5492 acc_val: 0.8040 time: 0.1447s\n",
            "2\n",
            "Epoch: 0047 loss_train: 0.7521 acc_train: 0.8000 loss_val: 0.5896 acc_val: 0.7920 time: 0.1463s\n",
            "3\n",
            "Epoch: 0048 loss_train: 0.6975 acc_train: 0.8333 loss_val: 0.6101 acc_val: 0.7880 time: 0.1448s\n",
            "4\n",
            "Epoch: 0049 loss_train: 0.7161 acc_train: 0.7667 loss_val: 0.6143 acc_val: 0.7840 time: 0.1451s\n",
            "5\n",
            "Epoch: 0050 loss_train: 0.7292 acc_train: 0.8500 loss_val: 0.5559 acc_val: 0.8040 time: 0.1452s\n",
            "6\n",
            "Epoch: 0051 loss_train: 0.7224 acc_train: 0.8500 loss_val: 0.5775 acc_val: 0.7980 time: 0.1455s\n",
            "7\n",
            "Epoch: 0052 loss_train: 0.7547 acc_train: 0.8000 loss_val: 0.5789 acc_val: 0.7980 time: 0.1449s\n",
            "8\n",
            "Epoch: 0053 loss_train: 0.8237 acc_train: 0.8333 loss_val: 0.5862 acc_val: 0.7960 time: 0.1454s\n",
            "9\n",
            "Epoch: 0054 loss_train: 0.7552 acc_train: 0.8667 loss_val: 0.5216 acc_val: 0.8220 time: 0.1450s\n",
            "10\n",
            "Epoch: 0055 loss_train: 0.7169 acc_train: 0.8000 loss_val: 0.4961 acc_val: 0.8340 time: 0.1453s\n",
            "11\n",
            "Epoch: 0056 loss_train: 0.7320 acc_train: 0.8333 loss_val: 0.5036 acc_val: 0.8400 time: 0.1443s\n",
            "0\n",
            "Epoch: 0057 loss_train: 0.7259 acc_train: 0.8500 loss_val: 0.4976 acc_val: 0.8320 time: 0.1457s\n",
            "0\n",
            "Epoch: 0058 loss_train: 0.7345 acc_train: 0.8333 loss_val: 0.5301 acc_val: 0.8200 time: 0.1452s\n",
            "1\n",
            "Epoch: 0059 loss_train: 0.7759 acc_train: 0.7167 loss_val: 0.5845 acc_val: 0.7940 time: 0.1462s\n",
            "2\n",
            "Epoch: 0060 loss_train: 0.7338 acc_train: 0.8167 loss_val: 0.6039 acc_val: 0.7920 time: 0.1448s\n",
            "3\n",
            "Epoch: 0061 loss_train: 0.7208 acc_train: 0.7167 loss_val: 0.6070 acc_val: 0.7980 time: 0.1477s\n",
            "4\n",
            "Epoch: 0062 loss_train: 0.6234 acc_train: 0.8167 loss_val: 0.5832 acc_val: 0.8040 time: 0.1451s\n",
            "5\n",
            "Epoch: 0063 loss_train: 0.7081 acc_train: 0.8500 loss_val: 0.5372 acc_val: 0.8140 time: 0.1471s\n",
            "6\n",
            "Epoch: 0064 loss_train: 0.6790 acc_train: 0.8167 loss_val: 0.5120 acc_val: 0.8280 time: 0.1449s\n",
            "7\n",
            "Epoch: 0065 loss_train: 0.5944 acc_train: 0.8333 loss_val: 0.5119 acc_val: 0.8260 time: 0.1462s\n",
            "8\n",
            "Epoch: 0066 loss_train: 0.7450 acc_train: 0.8333 loss_val: 0.4938 acc_val: 0.8340 time: 0.1444s\n",
            "9\n",
            "Epoch: 0067 loss_train: 0.6863 acc_train: 0.7833 loss_val: 0.4875 acc_val: 0.8420 time: 0.1446s\n",
            "0\n",
            "Epoch: 0068 loss_train: 0.6184 acc_train: 0.8667 loss_val: 0.4845 acc_val: 0.8480 time: 0.1447s\n",
            "0\n",
            "Epoch: 0069 loss_train: 0.5978 acc_train: 0.9333 loss_val: 0.4638 acc_val: 0.8440 time: 0.1459s\n",
            "0\n",
            "Epoch: 0070 loss_train: 0.6675 acc_train: 0.8167 loss_val: 0.4617 acc_val: 0.8400 time: 0.1447s\n",
            "0\n",
            "Epoch: 0071 loss_train: 0.6074 acc_train: 0.8667 loss_val: 0.4661 acc_val: 0.8380 time: 0.1458s\n",
            "0\n",
            "Epoch: 0072 loss_train: 0.6081 acc_train: 0.8333 loss_val: 0.5059 acc_val: 0.8260 time: 0.1448s\n",
            "1\n",
            "Epoch: 0073 loss_train: 0.5824 acc_train: 0.8333 loss_val: 0.5758 acc_val: 0.8260 time: 0.1456s\n",
            "2\n",
            "Epoch: 0074 loss_train: 0.6117 acc_train: 0.8500 loss_val: 0.6403 acc_val: 0.8120 time: 0.1451s\n",
            "3\n",
            "Epoch: 0075 loss_train: 0.5317 acc_train: 0.8667 loss_val: 0.6549 acc_val: 0.8160 time: 0.1456s\n",
            "4\n",
            "Epoch: 0076 loss_train: 0.5641 acc_train: 0.9000 loss_val: 0.6752 acc_val: 0.8160 time: 0.1450s\n",
            "5\n",
            "Epoch: 0077 loss_train: 0.6029 acc_train: 0.8333 loss_val: 0.6762 acc_val: 0.8100 time: 0.1449s\n",
            "6\n",
            "Epoch: 0078 loss_train: 0.6578 acc_train: 0.8667 loss_val: 0.6582 acc_val: 0.8040 time: 0.1450s\n",
            "7\n",
            "Epoch: 0079 loss_train: 0.6729 acc_train: 0.8333 loss_val: 0.6107 acc_val: 0.8140 time: 0.1452s\n",
            "8\n",
            "Epoch: 0080 loss_train: 0.5910 acc_train: 0.8500 loss_val: 0.5693 acc_val: 0.8300 time: 0.1450s\n",
            "9\n",
            "Epoch: 0081 loss_train: 0.6005 acc_train: 0.8667 loss_val: 0.5212 acc_val: 0.8360 time: 0.1455s\n",
            "10\n",
            "Epoch: 0082 loss_train: 0.6069 acc_train: 0.8500 loss_val: 0.4900 acc_val: 0.8320 time: 0.1448s\n",
            "11\n",
            "Epoch: 0083 loss_train: 0.5235 acc_train: 0.8667 loss_val: 0.4909 acc_val: 0.8300 time: 0.1455s\n",
            "12\n",
            "Epoch: 0084 loss_train: 0.5626 acc_train: 0.9167 loss_val: 0.5020 acc_val: 0.8260 time: 0.1455s\n",
            "13\n",
            "Epoch: 0085 loss_train: 0.5059 acc_train: 0.8833 loss_val: 0.5388 acc_val: 0.8220 time: 0.1452s\n",
            "14\n",
            "Epoch: 0086 loss_train: 0.6103 acc_train: 0.8667 loss_val: 0.5999 acc_val: 0.8100 time: 0.1451s\n",
            "15\n",
            "Epoch: 0087 loss_train: 0.5300 acc_train: 0.8833 loss_val: 0.6604 acc_val: 0.7960 time: 0.1452s\n",
            "16\n",
            "Epoch: 0088 loss_train: 0.5364 acc_train: 0.8833 loss_val: 0.7313 acc_val: 0.8040 time: 0.1455s\n",
            "17\n",
            "Epoch: 0089 loss_train: 0.6162 acc_train: 0.9000 loss_val: 0.6801 acc_val: 0.8120 time: 0.1457s\n",
            "18\n",
            "Epoch: 0090 loss_train: 0.5564 acc_train: 0.9167 loss_val: 0.6254 acc_val: 0.8180 time: 0.1469s\n",
            "19\n",
            "Epoch: 0091 loss_train: 0.5170 acc_train: 0.9000 loss_val: 0.5310 acc_val: 0.8360 time: 0.1450s\n",
            "20\n",
            "Epoch: 0092 loss_train: 0.5131 acc_train: 0.8667 loss_val: 0.5110 acc_val: 0.8300 time: 0.1449s\n",
            "21\n",
            "Epoch: 0093 loss_train: 0.5702 acc_train: 0.8667 loss_val: 0.5154 acc_val: 0.8180 time: 0.1460s\n",
            "22\n",
            "Epoch: 0094 loss_train: 0.5857 acc_train: 0.9000 loss_val: 0.5388 acc_val: 0.8260 time: 0.1447s\n",
            "23\n",
            "Epoch: 0095 loss_train: 0.5555 acc_train: 0.9000 loss_val: 0.5196 acc_val: 0.8240 time: 0.1459s\n",
            "24\n",
            "Epoch: 0096 loss_train: 0.5276 acc_train: 0.8833 loss_val: 0.5196 acc_val: 0.8180 time: 0.1448s\n",
            "25\n",
            "Epoch: 0097 loss_train: 0.5267 acc_train: 0.8667 loss_val: 0.5206 acc_val: 0.8240 time: 0.1463s\n",
            "26\n",
            "Epoch: 0098 loss_train: 0.6373 acc_train: 0.8333 loss_val: 0.5539 acc_val: 0.8280 time: 0.1454s\n",
            "27\n",
            "Epoch: 0099 loss_train: 0.5129 acc_train: 0.9000 loss_val: 0.6649 acc_val: 0.8240 time: 0.1457s\n",
            "28\n",
            "Epoch: 0100 loss_train: 0.5673 acc_train: 0.8833 loss_val: 0.7595 acc_val: 0.8180 time: 0.1454s\n",
            "29\n",
            "Epoch: 0101 loss_train: 0.5057 acc_train: 0.8833 loss_val: 0.8006 acc_val: 0.8200 time: 0.1450s\n",
            "30\n",
            "Epoch: 0102 loss_train: 0.5878 acc_train: 0.8833 loss_val: 0.6680 acc_val: 0.8200 time: 0.1449s\n",
            "31\n",
            "Epoch: 0103 loss_train: 0.5670 acc_train: 0.8333 loss_val: 0.5488 acc_val: 0.8400 time: 0.1452s\n",
            "32\n",
            "Epoch: 0104 loss_train: 0.5971 acc_train: 0.9333 loss_val: 0.5233 acc_val: 0.8380 time: 0.1455s\n",
            "33\n",
            "Epoch: 0105 loss_train: 0.5479 acc_train: 0.8833 loss_val: 0.5075 acc_val: 0.8320 time: 0.1449s\n",
            "34\n",
            "Epoch: 0106 loss_train: 0.5834 acc_train: 0.8000 loss_val: 0.5254 acc_val: 0.8240 time: 0.1450s\n",
            "35\n",
            "Epoch: 0107 loss_train: 0.5573 acc_train: 0.9333 loss_val: 0.5412 acc_val: 0.8320 time: 0.1450s\n",
            "36\n",
            "Epoch: 0108 loss_train: 0.5846 acc_train: 0.8833 loss_val: 0.6106 acc_val: 0.8120 time: 0.1451s\n",
            "37\n",
            "Epoch: 0109 loss_train: 0.5946 acc_train: 0.9000 loss_val: 0.6857 acc_val: 0.7940 time: 0.1472s\n",
            "38\n",
            "Epoch: 0110 loss_train: 0.5906 acc_train: 0.7667 loss_val: 0.6790 acc_val: 0.7980 time: 0.1453s\n",
            "39\n",
            "Epoch: 0111 loss_train: 0.6083 acc_train: 0.7500 loss_val: 0.5631 acc_val: 0.8240 time: 0.1455s\n",
            "40\n",
            "Epoch: 0112 loss_train: 0.6056 acc_train: 0.8000 loss_val: 0.5237 acc_val: 0.8320 time: 0.1448s\n",
            "41\n",
            "Epoch: 0113 loss_train: 0.5559 acc_train: 0.9000 loss_val: 0.5419 acc_val: 0.8380 time: 0.1450s\n",
            "42\n",
            "Epoch: 0114 loss_train: 0.5799 acc_train: 0.7833 loss_val: 0.5648 acc_val: 0.8320 time: 0.1461s\n",
            "43\n",
            "Epoch: 0115 loss_train: 0.6970 acc_train: 0.8167 loss_val: 0.5525 acc_val: 0.8260 time: 0.1450s\n",
            "44\n",
            "Epoch: 0116 loss_train: 0.5389 acc_train: 0.8833 loss_val: 0.5768 acc_val: 0.8160 time: 0.1456s\n",
            "45\n",
            "Epoch: 0117 loss_train: 0.5633 acc_train: 0.8167 loss_val: 0.5827 acc_val: 0.8160 time: 0.1454s\n",
            "46\n",
            "Epoch: 0118 loss_train: 0.5801 acc_train: 0.9000 loss_val: 0.5765 acc_val: 0.8180 time: 0.1454s\n",
            "47\n",
            "Epoch: 0119 loss_train: 0.5635 acc_train: 0.8500 loss_val: 0.5747 acc_val: 0.8240 time: 0.1452s\n",
            "48\n",
            "Epoch: 0120 loss_train: 0.5243 acc_train: 0.9000 loss_val: 0.5941 acc_val: 0.8180 time: 0.1458s\n",
            "49\n",
            "Epoch: 0121 loss_train: 0.5759 acc_train: 0.8333 loss_val: 0.6034 acc_val: 0.8260 time: 0.1447s\n",
            "50\n",
            "Epoch: 0122 loss_train: 0.5521 acc_train: 0.8667 loss_val: 0.5700 acc_val: 0.8340 time: 0.1448s\n",
            "51\n",
            "Epoch: 0123 loss_train: 0.5738 acc_train: 0.8500 loss_val: 0.5147 acc_val: 0.8300 time: 0.1458s\n",
            "52\n",
            "Epoch: 0124 loss_train: 0.6335 acc_train: 0.8333 loss_val: 0.5085 acc_val: 0.8360 time: 0.1457s\n",
            "53\n",
            "Epoch: 0125 loss_train: 0.6077 acc_train: 0.8833 loss_val: 0.5256 acc_val: 0.8380 time: 0.1455s\n",
            "54\n",
            "Epoch: 0126 loss_train: 0.5252 acc_train: 0.8833 loss_val: 0.5231 acc_val: 0.8360 time: 0.1455s\n",
            "55\n",
            "Epoch: 0127 loss_train: 0.5084 acc_train: 0.9000 loss_val: 0.5440 acc_val: 0.8340 time: 0.1449s\n",
            "56\n",
            "Epoch: 0128 loss_train: 0.6345 acc_train: 0.8333 loss_val: 0.6006 acc_val: 0.8260 time: 0.1449s\n",
            "57\n",
            "Epoch: 0129 loss_train: 0.5817 acc_train: 0.9000 loss_val: 0.6654 acc_val: 0.8080 time: 0.1454s\n",
            "58\n",
            "Epoch: 0130 loss_train: 0.6499 acc_train: 0.8333 loss_val: 0.6650 acc_val: 0.8100 time: 0.1460s\n",
            "59\n",
            "Epoch: 0131 loss_train: 0.6432 acc_train: 0.8333 loss_val: 0.6011 acc_val: 0.8180 time: 0.1450s\n",
            "60\n",
            "Epoch: 0132 loss_train: 0.6565 acc_train: 0.8333 loss_val: 0.5284 acc_val: 0.8340 time: 0.1452s\n",
            "61\n",
            "Epoch: 0133 loss_train: 0.5499 acc_train: 0.9000 loss_val: 0.5073 acc_val: 0.8080 time: 0.1452s\n",
            "62\n",
            "Epoch: 0134 loss_train: 0.5804 acc_train: 0.8500 loss_val: 0.5047 acc_val: 0.8160 time: 0.1450s\n",
            "63\n",
            "Epoch: 0135 loss_train: 0.5549 acc_train: 0.9167 loss_val: 0.5191 acc_val: 0.8300 time: 0.1448s\n",
            "64\n",
            "Epoch: 0136 loss_train: 0.6633 acc_train: 0.7833 loss_val: 0.5682 acc_val: 0.8180 time: 0.1445s\n",
            "65\n",
            "Epoch: 0137 loss_train: 0.6381 acc_train: 0.8333 loss_val: 0.6162 acc_val: 0.8140 time: 0.1452s\n",
            "66\n",
            "Epoch: 0138 loss_train: 0.5982 acc_train: 0.9000 loss_val: 0.6117 acc_val: 0.8160 time: 0.1481s\n",
            "67\n",
            "Epoch: 0139 loss_train: 0.7598 acc_train: 0.8167 loss_val: 0.5820 acc_val: 0.8320 time: 0.1450s\n",
            "68\n",
            "Epoch: 0140 loss_train: 0.6161 acc_train: 0.8500 loss_val: 0.5770 acc_val: 0.8320 time: 0.1447s\n",
            "69\n",
            "Epoch: 0141 loss_train: 0.6668 acc_train: 0.8667 loss_val: 0.6105 acc_val: 0.8200 time: 0.1451s\n",
            "70\n",
            "Epoch: 0142 loss_train: 0.6131 acc_train: 0.8500 loss_val: 0.6812 acc_val: 0.8120 time: 0.1449s\n",
            "71\n",
            "Epoch: 0143 loss_train: 0.6062 acc_train: 0.8667 loss_val: 0.6930 acc_val: 0.8100 time: 0.1450s\n",
            "72\n",
            "Epoch: 0144 loss_train: 0.5333 acc_train: 0.8500 loss_val: 0.7011 acc_val: 0.8140 time: 0.1447s\n",
            "73\n",
            "Epoch: 0145 loss_train: 0.5993 acc_train: 0.8167 loss_val: 0.6610 acc_val: 0.8160 time: 0.1450s\n",
            "74\n",
            "Epoch: 0146 loss_train: 0.5237 acc_train: 0.9167 loss_val: 0.6043 acc_val: 0.8280 time: 0.1450s\n",
            "75\n",
            "Epoch: 0147 loss_train: 0.6069 acc_train: 0.8833 loss_val: 0.5722 acc_val: 0.8300 time: 0.1448s\n",
            "76\n",
            "Epoch: 0148 loss_train: 0.5410 acc_train: 0.9167 loss_val: 0.5480 acc_val: 0.8280 time: 0.1452s\n",
            "77\n",
            "Epoch: 0149 loss_train: 0.5745 acc_train: 0.8333 loss_val: 0.5798 acc_val: 0.8180 time: 0.1449s\n",
            "78\n",
            "Epoch: 0150 loss_train: 0.5746 acc_train: 0.7667 loss_val: 0.6190 acc_val: 0.8120 time: 0.1452s\n",
            "79\n",
            "Epoch: 0151 loss_train: 0.6133 acc_train: 0.8167 loss_val: 0.6113 acc_val: 0.8160 time: 0.1465s\n",
            "80\n",
            "Epoch: 0152 loss_train: 0.7259 acc_train: 0.8333 loss_val: 0.5743 acc_val: 0.8260 time: 0.1452s\n",
            "81\n",
            "Epoch: 0153 loss_train: 0.5956 acc_train: 0.8500 loss_val: 0.5612 acc_val: 0.8280 time: 0.1459s\n",
            "82\n",
            "Epoch: 0154 loss_train: 0.5140 acc_train: 0.9000 loss_val: 0.6056 acc_val: 0.8300 time: 0.1457s\n",
            "83\n",
            "Epoch: 0155 loss_train: 0.5771 acc_train: 0.9167 loss_val: 0.6364 acc_val: 0.8300 time: 0.1455s\n",
            "84\n",
            "Epoch: 0156 loss_train: 0.5933 acc_train: 0.9000 loss_val: 0.6706 acc_val: 0.8240 time: 0.1448s\n",
            "85\n",
            "Epoch: 0157 loss_train: 0.5669 acc_train: 0.8833 loss_val: 0.6987 acc_val: 0.8080 time: 0.1457s\n",
            "86\n",
            "Epoch: 0158 loss_train: 0.6735 acc_train: 0.8333 loss_val: 0.6271 acc_val: 0.8200 time: 0.1443s\n",
            "87\n",
            "Epoch: 0159 loss_train: 0.6693 acc_train: 0.8167 loss_val: 0.5452 acc_val: 0.8400 time: 0.1452s\n",
            "88\n",
            "Epoch: 0160 loss_train: 0.5855 acc_train: 0.8833 loss_val: 0.5574 acc_val: 0.8300 time: 0.1447s\n",
            "89\n",
            "Epoch: 0161 loss_train: 0.6167 acc_train: 0.8667 loss_val: 0.6208 acc_val: 0.8080 time: 0.1451s\n",
            "90\n",
            "Epoch: 0162 loss_train: 0.5939 acc_train: 0.8167 loss_val: 0.7107 acc_val: 0.8100 time: 0.1461s\n",
            "91\n",
            "Epoch: 0163 loss_train: 0.5593 acc_train: 0.8333 loss_val: 0.7529 acc_val: 0.8140 time: 0.1459s\n",
            "92\n",
            "Epoch: 0164 loss_train: 0.6156 acc_train: 0.8667 loss_val: 0.6873 acc_val: 0.8160 time: 0.1470s\n",
            "93\n",
            "Epoch: 0165 loss_train: 0.6742 acc_train: 0.8500 loss_val: 0.6056 acc_val: 0.8160 time: 0.1456s\n",
            "94\n",
            "Epoch: 0166 loss_train: 0.5966 acc_train: 0.9000 loss_val: 0.5838 acc_val: 0.8200 time: 0.1471s\n",
            "95\n",
            "Epoch: 0167 loss_train: 0.6251 acc_train: 0.8333 loss_val: 0.5607 acc_val: 0.8180 time: 0.1455s\n",
            "96\n",
            "Epoch: 0168 loss_train: 0.6107 acc_train: 0.8000 loss_val: 0.5536 acc_val: 0.8220 time: 0.1450s\n",
            "97\n",
            "Epoch: 0169 loss_train: 0.6170 acc_train: 0.8667 loss_val: 0.5626 acc_val: 0.8140 time: 0.1452s\n",
            "98\n",
            "Epoch: 0170 loss_train: 0.6948 acc_train: 0.8500 loss_val: 0.5915 acc_val: 0.8200 time: 0.1452s\n",
            "99\n",
            "Early stop! Min loss:  0.4616774022579193 , Max accuracy:  0.848\n",
            "Early stop model validation loss:  0.4616774022579193 , accuracy:  0.84\n",
            "Optimization Finished!\n",
            "Total time elapsed: 25.2060s\n",
            "Loading 69th epoch\n",
            "Test set results: loss= 0.5226 accuracy= 0.8160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8160, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3NqfmHroERS",
        "outputId": "91c3435d-a91a-459f-f934-13f172bb2727"
      },
      "source": [
        "args['tem'] = 1\n",
        "Train() #citeseer\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.9351 acc_train: 0.1667 loss_val: 1.8103 acc_val: 0.2320 time: 0.1126s\n",
            "0\n",
            "Epoch: 0002 loss_train: 1.9367 acc_train: 0.1667 loss_val: 1.8078 acc_val: 0.2320 time: 0.1054s\n",
            "0\n",
            "Epoch: 0003 loss_train: 1.9444 acc_train: 0.1667 loss_val: 1.8057 acc_val: 0.2320 time: 0.1057s\n",
            "0\n",
            "Epoch: 0004 loss_train: 1.9490 acc_train: 0.1667 loss_val: 1.8041 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0005 loss_train: 1.9560 acc_train: 0.1667 loss_val: 1.8027 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0006 loss_train: 1.9643 acc_train: 0.1667 loss_val: 1.8014 acc_val: 0.2320 time: 0.1036s\n",
            "0\n",
            "Epoch: 0007 loss_train: 1.9737 acc_train: 0.1667 loss_val: 1.8003 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0008 loss_train: 1.9848 acc_train: 0.1667 loss_val: 1.7994 acc_val: 0.2320 time: 0.1038s\n",
            "0\n",
            "Epoch: 0009 loss_train: 1.9951 acc_train: 0.1667 loss_val: 1.7986 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0010 loss_train: 2.0089 acc_train: 0.1667 loss_val: 1.7982 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0011 loss_train: 2.0239 acc_train: 0.1667 loss_val: 1.7982 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0012 loss_train: 2.0394 acc_train: 0.1667 loss_val: 1.7987 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0013 loss_train: 2.0534 acc_train: 0.1667 loss_val: 1.7996 acc_val: 0.2320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0014 loss_train: 2.0700 acc_train: 0.1667 loss_val: 1.8011 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0015 loss_train: 2.0866 acc_train: 0.1667 loss_val: 1.8029 acc_val: 0.2320 time: 0.1054s\n",
            "0\n",
            "Epoch: 0016 loss_train: 2.1020 acc_train: 0.1667 loss_val: 1.8051 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0017 loss_train: 2.1215 acc_train: 0.1667 loss_val: 1.8079 acc_val: 0.2320 time: 0.1051s\n",
            "0\n",
            "Epoch: 0018 loss_train: 2.1405 acc_train: 0.1667 loss_val: 1.8110 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0019 loss_train: 2.1562 acc_train: 0.1667 loss_val: 1.8147 acc_val: 0.2320 time: 0.1045s\n",
            "0\n",
            "Epoch: 0020 loss_train: 2.1684 acc_train: 0.1667 loss_val: 1.8190 acc_val: 0.2320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0021 loss_train: 2.1853 acc_train: 0.1667 loss_val: 1.8240 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0022 loss_train: 2.1995 acc_train: 0.1667 loss_val: 1.8297 acc_val: 0.2320 time: 0.1076s\n",
            "0\n",
            "Epoch: 0023 loss_train: 2.2117 acc_train: 0.1667 loss_val: 1.8362 acc_val: 0.2320 time: 0.1061s\n",
            "0\n",
            "Epoch: 0024 loss_train: 2.2252 acc_train: 0.1667 loss_val: 1.8433 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0025 loss_train: 2.2327 acc_train: 0.1667 loss_val: 1.8513 acc_val: 0.2320 time: 0.1058s\n",
            "0\n",
            "Epoch: 0026 loss_train: 2.2377 acc_train: 0.1667 loss_val: 1.8606 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0027 loss_train: 2.2543 acc_train: 0.1667 loss_val: 1.8708 acc_val: 0.2320 time: 0.1048s\n",
            "0\n",
            "Epoch: 0028 loss_train: 2.2597 acc_train: 0.1667 loss_val: 1.8817 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0029 loss_train: 2.2631 acc_train: 0.1667 loss_val: 1.8915 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0030 loss_train: 2.2812 acc_train: 0.1667 loss_val: 1.8992 acc_val: 0.2320 time: 0.1068s\n",
            "0\n",
            "Epoch: 0031 loss_train: 2.2846 acc_train: 0.1667 loss_val: 1.9043 acc_val: 0.2320 time: 0.1045s\n",
            "0\n",
            "Epoch: 0032 loss_train: 2.2775 acc_train: 0.1667 loss_val: 1.9077 acc_val: 0.2320 time: 0.1052s\n",
            "0\n",
            "Epoch: 0033 loss_train: 2.2838 acc_train: 0.1667 loss_val: 1.9105 acc_val: 0.2320 time: 0.1050s\n",
            "0\n",
            "Epoch: 0034 loss_train: 2.2781 acc_train: 0.1667 loss_val: 1.9123 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0035 loss_train: 2.2815 acc_train: 0.1667 loss_val: 1.9114 acc_val: 0.2320 time: 0.1049s\n",
            "0\n",
            "Epoch: 0036 loss_train: 2.2778 acc_train: 0.1667 loss_val: 1.9087 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0037 loss_train: 2.2740 acc_train: 0.1667 loss_val: 1.9049 acc_val: 0.2320 time: 0.1055s\n",
            "0\n",
            "Epoch: 0038 loss_train: 2.2748 acc_train: 0.1667 loss_val: 1.8990 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0039 loss_train: 2.2605 acc_train: 0.1667 loss_val: 1.8922 acc_val: 0.2320 time: 0.1050s\n",
            "0\n",
            "Epoch: 0040 loss_train: 2.2672 acc_train: 0.1667 loss_val: 1.8854 acc_val: 0.2320 time: 0.1037s\n",
            "0\n",
            "Epoch: 0041 loss_train: 2.2499 acc_train: 0.1667 loss_val: 1.8787 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0042 loss_train: 2.2497 acc_train: 0.1667 loss_val: 1.8724 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0043 loss_train: 2.2465 acc_train: 0.1667 loss_val: 1.8676 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0044 loss_train: 2.2305 acc_train: 0.1667 loss_val: 1.8643 acc_val: 0.2320 time: 0.1087s\n",
            "0\n",
            "Epoch: 0045 loss_train: 2.2350 acc_train: 0.1667 loss_val: 1.8621 acc_val: 0.2320 time: 0.1056s\n",
            "0\n",
            "Epoch: 0046 loss_train: 2.2230 acc_train: 0.1667 loss_val: 1.8612 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0047 loss_train: 2.2164 acc_train: 0.1667 loss_val: 1.8625 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0048 loss_train: 2.2264 acc_train: 0.1667 loss_val: 1.8642 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0049 loss_train: 2.2163 acc_train: 0.1667 loss_val: 1.8665 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0050 loss_train: 2.2206 acc_train: 0.1667 loss_val: 1.8694 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0051 loss_train: 2.2111 acc_train: 0.1667 loss_val: 1.8724 acc_val: 0.2320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0052 loss_train: 2.2229 acc_train: 0.1667 loss_val: 1.8739 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0053 loss_train: 2.2178 acc_train: 0.1667 loss_val: 1.8740 acc_val: 0.2320 time: 0.1059s\n",
            "0\n",
            "Epoch: 0054 loss_train: 2.2031 acc_train: 0.1667 loss_val: 1.8730 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0055 loss_train: 2.2056 acc_train: 0.1667 loss_val: 1.8708 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0056 loss_train: 2.2069 acc_train: 0.1667 loss_val: 1.8666 acc_val: 0.2320 time: 0.1040s\n",
            "0\n",
            "Epoch: 0057 loss_train: 2.1825 acc_train: 0.1667 loss_val: 1.8626 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0058 loss_train: 2.1935 acc_train: 0.1667 loss_val: 1.8584 acc_val: 0.2320 time: 0.1045s\n",
            "0\n",
            "Epoch: 0059 loss_train: 2.1797 acc_train: 0.1667 loss_val: 1.8534 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0060 loss_train: 2.1856 acc_train: 0.1667 loss_val: 1.8486 acc_val: 0.2320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0061 loss_train: 2.1674 acc_train: 0.1667 loss_val: 1.8449 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0062 loss_train: 2.1620 acc_train: 0.1667 loss_val: 1.8421 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0063 loss_train: 2.1551 acc_train: 0.1667 loss_val: 1.8412 acc_val: 0.2320 time: 0.1057s\n",
            "0\n",
            "Epoch: 0064 loss_train: 2.1642 acc_train: 0.1667 loss_val: 1.8406 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0065 loss_train: 2.1573 acc_train: 0.1667 loss_val: 1.8399 acc_val: 0.2320 time: 0.1049s\n",
            "0\n",
            "Epoch: 0066 loss_train: 2.1500 acc_train: 0.1667 loss_val: 1.8389 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0067 loss_train: 2.1338 acc_train: 0.1667 loss_val: 1.8367 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0068 loss_train: 2.1181 acc_train: 0.1667 loss_val: 1.8330 acc_val: 0.2320 time: 0.1044s\n",
            "0\n",
            "Epoch: 0069 loss_train: 2.1172 acc_train: 0.1667 loss_val: 1.8303 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0070 loss_train: 2.1128 acc_train: 0.1750 loss_val: 1.8282 acc_val: 0.2320 time: 0.1117s\n",
            "0\n",
            "Epoch: 0071 loss_train: 2.1116 acc_train: 0.1667 loss_val: 1.8242 acc_val: 0.2320 time: 0.1045s\n",
            "0\n",
            "Epoch: 0072 loss_train: 2.0945 acc_train: 0.1833 loss_val: 1.8214 acc_val: 0.2320 time: 0.1054s\n",
            "0\n",
            "Epoch: 0073 loss_train: 2.1099 acc_train: 0.1667 loss_val: 1.8182 acc_val: 0.2320 time: 0.1050s\n",
            "0\n",
            "Epoch: 0074 loss_train: 2.0854 acc_train: 0.1667 loss_val: 1.8161 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0075 loss_train: 2.0902 acc_train: 0.1667 loss_val: 1.8136 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0076 loss_train: 2.0836 acc_train: 0.1667 loss_val: 1.8103 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0077 loss_train: 2.0619 acc_train: 0.1750 loss_val: 1.8077 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0078 loss_train: 2.0533 acc_train: 0.1750 loss_val: 1.8042 acc_val: 0.2320 time: 0.1053s\n",
            "0\n",
            "Epoch: 0079 loss_train: 2.0467 acc_train: 0.1750 loss_val: 1.8030 acc_val: 0.2320 time: 0.1049s\n",
            "0\n",
            "Epoch: 0080 loss_train: 2.0578 acc_train: 0.1750 loss_val: 1.8005 acc_val: 0.2320 time: 0.1036s\n",
            "0\n",
            "Epoch: 0081 loss_train: 2.0321 acc_train: 0.1750 loss_val: 1.7958 acc_val: 0.2320 time: 0.1047s\n",
            "0\n",
            "Epoch: 0082 loss_train: 2.0217 acc_train: 0.1750 loss_val: 1.7931 acc_val: 0.2320 time: 0.1038s\n",
            "0\n",
            "Epoch: 0083 loss_train: 2.0302 acc_train: 0.1750 loss_val: 1.7880 acc_val: 0.2320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0084 loss_train: 2.0069 acc_train: 0.1667 loss_val: 1.7831 acc_val: 0.2320 time: 0.1035s\n",
            "0\n",
            "Epoch: 0085 loss_train: 2.0004 acc_train: 0.1667 loss_val: 1.7763 acc_val: 0.2320 time: 0.1042s\n",
            "0\n",
            "Epoch: 0086 loss_train: 1.9839 acc_train: 0.2000 loss_val: 1.7722 acc_val: 0.2320 time: 0.1043s\n",
            "0\n",
            "Epoch: 0087 loss_train: 1.9770 acc_train: 0.1667 loss_val: 1.7702 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0088 loss_train: 1.9751 acc_train: 0.2083 loss_val: 1.7684 acc_val: 0.2320 time: 0.1039s\n",
            "0\n",
            "Epoch: 0089 loss_train: 1.9893 acc_train: 0.2000 loss_val: 1.7665 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0090 loss_train: 1.9729 acc_train: 0.1833 loss_val: 1.7626 acc_val: 0.2320 time: 0.1038s\n",
            "0\n",
            "Epoch: 0091 loss_train: 1.9625 acc_train: 0.1833 loss_val: 1.7551 acc_val: 0.2320 time: 0.1046s\n",
            "0\n",
            "Epoch: 0092 loss_train: 1.9209 acc_train: 0.2000 loss_val: 1.7488 acc_val: 0.2340 time: 0.1048s\n",
            "0\n",
            "Epoch: 0093 loss_train: 1.9306 acc_train: 0.2083 loss_val: 1.7454 acc_val: 0.2340 time: 0.1039s\n",
            "0\n",
            "Epoch: 0094 loss_train: 1.9122 acc_train: 0.2083 loss_val: 1.7419 acc_val: 0.2340 time: 0.1040s\n",
            "0\n",
            "Epoch: 0095 loss_train: 1.9086 acc_train: 0.1750 loss_val: 1.7370 acc_val: 0.2340 time: 0.1052s\n",
            "0\n",
            "Epoch: 0096 loss_train: 1.8978 acc_train: 0.2000 loss_val: 1.7349 acc_val: 0.2340 time: 0.1045s\n",
            "0\n",
            "Epoch: 0097 loss_train: 1.8879 acc_train: 0.1917 loss_val: 1.7323 acc_val: 0.2340 time: 0.1043s\n",
            "0\n",
            "Epoch: 0098 loss_train: 1.8603 acc_train: 0.1917 loss_val: 1.7296 acc_val: 0.2340 time: 0.1044s\n",
            "0\n",
            "Epoch: 0099 loss_train: 1.8462 acc_train: 0.2083 loss_val: 1.7273 acc_val: 0.2340 time: 0.1042s\n",
            "0\n",
            "Epoch: 0100 loss_train: 1.8687 acc_train: 0.2500 loss_val: 1.7230 acc_val: 0.2340 time: 0.1038s\n",
            "0\n",
            "Epoch: 0101 loss_train: 1.8352 acc_train: 0.2583 loss_val: 1.7197 acc_val: 0.2340 time: 0.1048s\n",
            "0\n",
            "Epoch: 0102 loss_train: 1.8452 acc_train: 0.2333 loss_val: 1.7106 acc_val: 0.2340 time: 0.1036s\n",
            "0\n",
            "Epoch: 0103 loss_train: 1.8059 acc_train: 0.2500 loss_val: 1.7048 acc_val: 0.2340 time: 0.1040s\n",
            "0\n",
            "Epoch: 0104 loss_train: 1.8133 acc_train: 0.2917 loss_val: 1.7012 acc_val: 0.2340 time: 0.1041s\n",
            "0\n",
            "Epoch: 0105 loss_train: 1.8197 acc_train: 0.2917 loss_val: 1.6986 acc_val: 0.2340 time: 0.1042s\n",
            "0\n",
            "Epoch: 0106 loss_train: 1.7946 acc_train: 0.2833 loss_val: 1.6953 acc_val: 0.2340 time: 0.1037s\n",
            "0\n",
            "Epoch: 0107 loss_train: 1.8093 acc_train: 0.2333 loss_val: 1.6908 acc_val: 0.2340 time: 0.1049s\n",
            "0\n",
            "Epoch: 0108 loss_train: 1.7969 acc_train: 0.2250 loss_val: 1.6863 acc_val: 0.2340 time: 0.1038s\n",
            "0\n",
            "Epoch: 0109 loss_train: 1.7807 acc_train: 0.2667 loss_val: 1.6824 acc_val: 0.2360 time: 0.1044s\n",
            "0\n",
            "Epoch: 0110 loss_train: 1.7862 acc_train: 0.2583 loss_val: 1.6782 acc_val: 0.2360 time: 0.1038s\n",
            "0\n",
            "Epoch: 0111 loss_train: 1.7793 acc_train: 0.2583 loss_val: 1.6753 acc_val: 0.2360 time: 0.1043s\n",
            "0\n",
            "Epoch: 0112 loss_train: 1.7481 acc_train: 0.3083 loss_val: 1.6713 acc_val: 0.2360 time: 0.1034s\n",
            "0\n",
            "Epoch: 0113 loss_train: 1.7161 acc_train: 0.2917 loss_val: 1.6693 acc_val: 0.2360 time: 0.1046s\n",
            "0\n",
            "Epoch: 0114 loss_train: 1.7267 acc_train: 0.2750 loss_val: 1.6676 acc_val: 0.2360 time: 0.1037s\n",
            "0\n",
            "Epoch: 0115 loss_train: 1.7431 acc_train: 0.3167 loss_val: 1.6636 acc_val: 0.2360 time: 0.1040s\n",
            "0\n",
            "Epoch: 0116 loss_train: 1.7121 acc_train: 0.3250 loss_val: 1.6562 acc_val: 0.2360 time: 0.1047s\n",
            "0\n",
            "Epoch: 0117 loss_train: 1.6733 acc_train: 0.3083 loss_val: 1.6520 acc_val: 0.2380 time: 0.1041s\n",
            "0\n",
            "Epoch: 0118 loss_train: 1.7200 acc_train: 0.2833 loss_val: 1.6439 acc_val: 0.2380 time: 0.1053s\n",
            "0\n",
            "Epoch: 0119 loss_train: 1.6891 acc_train: 0.3000 loss_val: 1.6374 acc_val: 0.2400 time: 0.1045s\n",
            "0\n",
            "Epoch: 0120 loss_train: 1.6902 acc_train: 0.3000 loss_val: 1.6332 acc_val: 0.2400 time: 0.1038s\n",
            "0\n",
            "Epoch: 0121 loss_train: 1.6713 acc_train: 0.3417 loss_val: 1.6355 acc_val: 0.2400 time: 0.1043s\n",
            "0\n",
            "Epoch: 0122 loss_train: 1.6600 acc_train: 0.3417 loss_val: 1.6417 acc_val: 0.2380 time: 0.1043s\n",
            "0\n",
            "Epoch: 0123 loss_train: 1.6454 acc_train: 0.3917 loss_val: 1.6453 acc_val: 0.2380 time: 0.1047s\n",
            "1\n",
            "Epoch: 0124 loss_train: 1.6275 acc_train: 0.3333 loss_val: 1.6380 acc_val: 0.2400 time: 0.1091s\n",
            "2\n",
            "Epoch: 0125 loss_train: 1.6846 acc_train: 0.2833 loss_val: 1.6250 acc_val: 0.2400 time: 0.1046s\n",
            "0\n",
            "Epoch: 0126 loss_train: 1.6297 acc_train: 0.3750 loss_val: 1.6149 acc_val: 0.2420 time: 0.1044s\n",
            "0\n",
            "Epoch: 0127 loss_train: 1.6190 acc_train: 0.3833 loss_val: 1.6111 acc_val: 0.2420 time: 0.1044s\n",
            "0\n",
            "Epoch: 0128 loss_train: 1.6251 acc_train: 0.3500 loss_val: 1.6137 acc_val: 0.2420 time: 0.1037s\n",
            "0\n",
            "Epoch: 0129 loss_train: 1.5819 acc_train: 0.4250 loss_val: 1.6214 acc_val: 0.2400 time: 0.1056s\n",
            "0\n",
            "Epoch: 0130 loss_train: 1.6017 acc_train: 0.3333 loss_val: 1.6208 acc_val: 0.2400 time: 0.1040s\n",
            "1\n",
            "Epoch: 0131 loss_train: 1.5778 acc_train: 0.4000 loss_val: 1.6106 acc_val: 0.2420 time: 0.1042s\n",
            "2\n",
            "Epoch: 0132 loss_train: 1.6151 acc_train: 0.3917 loss_val: 1.5947 acc_val: 0.2420 time: 0.1034s\n",
            "0\n",
            "Epoch: 0133 loss_train: 1.5635 acc_train: 0.3583 loss_val: 1.5860 acc_val: 0.2440 time: 0.1045s\n",
            "0\n",
            "Epoch: 0134 loss_train: 1.5620 acc_train: 0.4000 loss_val: 1.5835 acc_val: 0.2440 time: 0.1037s\n",
            "0\n",
            "Epoch: 0135 loss_train: 1.5506 acc_train: 0.4167 loss_val: 1.5883 acc_val: 0.2440 time: 0.1052s\n",
            "0\n",
            "Epoch: 0136 loss_train: 1.5735 acc_train: 0.4250 loss_val: 1.5905 acc_val: 0.2440 time: 0.1040s\n",
            "0\n",
            "Epoch: 0137 loss_train: 1.5501 acc_train: 0.3917 loss_val: 1.5922 acc_val: 0.2420 time: 0.1041s\n",
            "0\n",
            "Epoch: 0138 loss_train: 1.5643 acc_train: 0.4083 loss_val: 1.5922 acc_val: 0.2420 time: 0.1045s\n",
            "1\n",
            "Epoch: 0139 loss_train: 1.5603 acc_train: 0.4083 loss_val: 1.5847 acc_val: 0.2440 time: 0.1042s\n",
            "2\n",
            "Epoch: 0140 loss_train: 1.5274 acc_train: 0.4250 loss_val: 1.5738 acc_val: 0.2460 time: 0.1038s\n",
            "0\n",
            "Epoch: 0141 loss_train: 1.5364 acc_train: 0.5000 loss_val: 1.5639 acc_val: 0.2460 time: 0.1042s\n",
            "0\n",
            "Epoch: 0142 loss_train: 1.5170 acc_train: 0.4333 loss_val: 1.5602 acc_val: 0.2460 time: 0.1036s\n",
            "0\n",
            "Epoch: 0143 loss_train: 1.5073 acc_train: 0.4250 loss_val: 1.5578 acc_val: 0.2460 time: 0.1043s\n",
            "0\n",
            "Epoch: 0144 loss_train: 1.5120 acc_train: 0.4417 loss_val: 1.5526 acc_val: 0.2500 time: 0.1043s\n",
            "0\n",
            "Epoch: 0145 loss_train: 1.4914 acc_train: 0.4333 loss_val: 1.5531 acc_val: 0.2520 time: 0.1042s\n",
            "0\n",
            "Epoch: 0146 loss_train: 1.4950 acc_train: 0.4250 loss_val: 1.5574 acc_val: 0.2480 time: 0.1048s\n",
            "0\n",
            "Epoch: 0147 loss_train: 1.4882 acc_train: 0.4250 loss_val: 1.5566 acc_val: 0.2480 time: 0.1042s\n",
            "1\n",
            "Epoch: 0148 loss_train: 1.5020 acc_train: 0.4000 loss_val: 1.5528 acc_val: 0.2480 time: 0.1041s\n",
            "2\n",
            "Epoch: 0149 loss_train: 1.4661 acc_train: 0.4167 loss_val: 1.5535 acc_val: 0.2480 time: 0.1048s\n",
            "3\n",
            "Epoch: 0150 loss_train: 1.4657 acc_train: 0.4417 loss_val: 1.5470 acc_val: 0.2480 time: 0.1041s\n",
            "4\n",
            "Epoch: 0151 loss_train: 1.4934 acc_train: 0.4000 loss_val: 1.5334 acc_val: 0.2520 time: 0.1062s\n",
            "0\n",
            "Epoch: 0152 loss_train: 1.4453 acc_train: 0.5083 loss_val: 1.5273 acc_val: 0.2620 time: 0.1045s\n",
            "0\n",
            "Epoch: 0153 loss_train: 1.4216 acc_train: 0.5417 loss_val: 1.5272 acc_val: 0.2640 time: 0.1046s\n",
            "0\n",
            "Epoch: 0154 loss_train: 1.4251 acc_train: 0.5583 loss_val: 1.5284 acc_val: 0.2620 time: 0.1045s\n",
            "0\n",
            "Epoch: 0155 loss_train: 1.4028 acc_train: 0.4917 loss_val: 1.5315 acc_val: 0.2580 time: 0.1079s\n",
            "1\n",
            "Epoch: 0156 loss_train: 1.4768 acc_train: 0.4917 loss_val: 1.5319 acc_val: 0.2540 time: 0.1054s\n",
            "2\n",
            "Epoch: 0157 loss_train: 1.4490 acc_train: 0.3917 loss_val: 1.5297 acc_val: 0.2560 time: 0.1048s\n",
            "3\n",
            "Epoch: 0158 loss_train: 1.4492 acc_train: 0.4083 loss_val: 1.5239 acc_val: 0.2580 time: 0.1038s\n",
            "4\n",
            "Epoch: 0159 loss_train: 1.4398 acc_train: 0.5083 loss_val: 1.5159 acc_val: 0.2640 time: 0.1042s\n",
            "0\n",
            "Epoch: 0160 loss_train: 1.4131 acc_train: 0.4917 loss_val: 1.5100 acc_val: 0.2640 time: 0.1034s\n",
            "0\n",
            "Epoch: 0161 loss_train: 1.4115 acc_train: 0.5417 loss_val: 1.5069 acc_val: 0.2680 time: 0.1046s\n",
            "0\n",
            "Epoch: 0162 loss_train: 1.4168 acc_train: 0.4667 loss_val: 1.5007 acc_val: 0.2700 time: 0.1037s\n",
            "0\n",
            "Epoch: 0163 loss_train: 1.4058 acc_train: 0.4500 loss_val: 1.4892 acc_val: 0.2820 time: 0.1047s\n",
            "0\n",
            "Epoch: 0164 loss_train: 1.4096 acc_train: 0.4167 loss_val: 1.4869 acc_val: 0.2860 time: 0.1038s\n",
            "0\n",
            "Epoch: 0165 loss_train: 1.3633 acc_train: 0.5833 loss_val: 1.4926 acc_val: 0.2800 time: 0.1077s\n",
            "0\n",
            "Epoch: 0166 loss_train: 1.4219 acc_train: 0.4500 loss_val: 1.4959 acc_val: 0.2700 time: 0.1047s\n",
            "1\n",
            "Epoch: 0167 loss_train: 1.3983 acc_train: 0.5167 loss_val: 1.4994 acc_val: 0.2700 time: 0.1037s\n",
            "2\n",
            "Epoch: 0168 loss_train: 1.4034 acc_train: 0.4583 loss_val: 1.4964 acc_val: 0.2760 time: 0.1040s\n",
            "3\n",
            "Epoch: 0169 loss_train: 1.4593 acc_train: 0.3917 loss_val: 1.4834 acc_val: 0.2960 time: 0.1054s\n",
            "4\n",
            "Epoch: 0170 loss_train: 1.3367 acc_train: 0.5500 loss_val: 1.4711 acc_val: 0.3160 time: 0.1037s\n",
            "0\n",
            "Epoch: 0171 loss_train: 1.3847 acc_train: 0.5167 loss_val: 1.4636 acc_val: 0.3180 time: 0.1040s\n",
            "0\n",
            "Epoch: 0172 loss_train: 1.3439 acc_train: 0.5667 loss_val: 1.4635 acc_val: 0.3140 time: 0.1049s\n",
            "0\n",
            "Epoch: 0173 loss_train: 1.3241 acc_train: 0.5750 loss_val: 1.4748 acc_val: 0.2940 time: 0.1044s\n",
            "0\n",
            "Epoch: 0174 loss_train: 1.3319 acc_train: 0.5333 loss_val: 1.4810 acc_val: 0.2920 time: 0.1042s\n",
            "1\n",
            "Epoch: 0175 loss_train: 1.3781 acc_train: 0.5083 loss_val: 1.4803 acc_val: 0.2960 time: 0.1045s\n",
            "2\n",
            "Epoch: 0176 loss_train: 1.3283 acc_train: 0.5667 loss_val: 1.4780 acc_val: 0.3080 time: 0.1041s\n",
            "3\n",
            "Epoch: 0177 loss_train: 1.3577 acc_train: 0.5083 loss_val: 1.4661 acc_val: 0.3220 time: 0.1042s\n",
            "4\n",
            "Epoch: 0178 loss_train: 1.3492 acc_train: 0.5333 loss_val: 1.4504 acc_val: 0.3440 time: 0.1045s\n",
            "0\n",
            "Epoch: 0179 loss_train: 1.3228 acc_train: 0.5500 loss_val: 1.4361 acc_val: 0.3520 time: 0.1040s\n",
            "0\n",
            "Epoch: 0180 loss_train: 1.3171 acc_train: 0.6083 loss_val: 1.4291 acc_val: 0.3500 time: 0.1040s\n",
            "0\n",
            "Epoch: 0181 loss_train: 1.2895 acc_train: 0.5667 loss_val: 1.4320 acc_val: 0.3420 time: 0.1047s\n",
            "0\n",
            "Epoch: 0182 loss_train: 1.3210 acc_train: 0.5333 loss_val: 1.4376 acc_val: 0.3400 time: 0.1060s\n",
            "1\n",
            "Epoch: 0183 loss_train: 1.2817 acc_train: 0.5833 loss_val: 1.4424 acc_val: 0.3440 time: 0.1059s\n",
            "2\n",
            "Epoch: 0184 loss_train: 1.3203 acc_train: 0.6083 loss_val: 1.4416 acc_val: 0.3480 time: 0.1043s\n",
            "3\n",
            "Epoch: 0185 loss_train: 1.3125 acc_train: 0.6000 loss_val: 1.4367 acc_val: 0.3600 time: 0.1049s\n",
            "4\n",
            "Epoch: 0186 loss_train: 1.2586 acc_train: 0.5417 loss_val: 1.4320 acc_val: 0.3660 time: 0.1043s\n",
            "0\n",
            "Epoch: 0187 loss_train: 1.2675 acc_train: 0.6000 loss_val: 1.4241 acc_val: 0.3700 time: 0.1054s\n",
            "0\n",
            "Epoch: 0188 loss_train: 1.2855 acc_train: 0.6167 loss_val: 1.4186 acc_val: 0.3680 time: 0.1048s\n",
            "0\n",
            "Epoch: 0189 loss_train: 1.2464 acc_train: 0.5833 loss_val: 1.4166 acc_val: 0.3660 time: 0.1042s\n",
            "0\n",
            "Epoch: 0190 loss_train: 1.2465 acc_train: 0.5917 loss_val: 1.4157 acc_val: 0.3680 time: 0.1041s\n",
            "0\n",
            "Epoch: 0191 loss_train: 1.2533 acc_train: 0.6250 loss_val: 1.4121 acc_val: 0.3740 time: 0.1050s\n",
            "0\n",
            "Epoch: 0192 loss_train: 1.2869 acc_train: 0.5667 loss_val: 1.4067 acc_val: 0.3880 time: 0.1037s\n",
            "0\n",
            "Epoch: 0193 loss_train: 1.2897 acc_train: 0.5583 loss_val: 1.3987 acc_val: 0.4000 time: 0.1039s\n",
            "0\n",
            "Epoch: 0194 loss_train: 1.2664 acc_train: 0.5750 loss_val: 1.3928 acc_val: 0.4000 time: 0.1037s\n",
            "0\n",
            "Epoch: 0195 loss_train: 1.2348 acc_train: 0.6500 loss_val: 1.3892 acc_val: 0.4020 time: 0.1043s\n",
            "0\n",
            "Epoch: 0196 loss_train: 1.2566 acc_train: 0.5500 loss_val: 1.3872 acc_val: 0.4060 time: 0.1036s\n",
            "0\n",
            "Epoch: 0197 loss_train: 1.2422 acc_train: 0.6500 loss_val: 1.3871 acc_val: 0.4100 time: 0.1041s\n",
            "0\n",
            "Epoch: 0198 loss_train: 1.2014 acc_train: 0.6167 loss_val: 1.3872 acc_val: 0.4100 time: 0.1035s\n",
            "0\n",
            "Epoch: 0199 loss_train: 1.2163 acc_train: 0.6000 loss_val: 1.3853 acc_val: 0.4120 time: 0.1045s\n",
            "0\n",
            "Epoch: 0200 loss_train: 1.1992 acc_train: 0.6417 loss_val: 1.3785 acc_val: 0.4100 time: 0.1045s\n",
            "0\n",
            "Epoch: 0201 loss_train: 1.2219 acc_train: 0.6750 loss_val: 1.3703 acc_val: 0.4080 time: 0.1043s\n",
            "0\n",
            "Epoch: 0202 loss_train: 1.2568 acc_train: 0.5833 loss_val: 1.3616 acc_val: 0.4200 time: 0.1037s\n",
            "0\n",
            "Epoch: 0203 loss_train: 1.2384 acc_train: 0.6833 loss_val: 1.3575 acc_val: 0.4200 time: 0.1043s\n",
            "0\n",
            "Epoch: 0204 loss_train: 1.2677 acc_train: 0.5750 loss_val: 1.3529 acc_val: 0.4200 time: 0.1036s\n",
            "0\n",
            "Epoch: 0205 loss_train: 1.2366 acc_train: 0.6333 loss_val: 1.3518 acc_val: 0.4240 time: 0.1045s\n",
            "0\n",
            "Epoch: 0206 loss_train: 1.1915 acc_train: 0.6167 loss_val: 1.3535 acc_val: 0.4240 time: 0.1048s\n",
            "0\n",
            "Epoch: 0207 loss_train: 1.2030 acc_train: 0.6500 loss_val: 1.3574 acc_val: 0.4220 time: 0.1047s\n",
            "0\n",
            "Epoch: 0208 loss_train: 1.2232 acc_train: 0.6333 loss_val: 1.3556 acc_val: 0.4240 time: 0.1050s\n",
            "1\n",
            "Epoch: 0209 loss_train: 1.1895 acc_train: 0.6417 loss_val: 1.3475 acc_val: 0.4300 time: 0.1050s\n",
            "0\n",
            "Epoch: 0210 loss_train: 1.2178 acc_train: 0.6417 loss_val: 1.3397 acc_val: 0.4280 time: 0.1046s\n",
            "0\n",
            "Epoch: 0211 loss_train: 1.1969 acc_train: 0.6250 loss_val: 1.3387 acc_val: 0.4280 time: 0.1063s\n",
            "0\n",
            "Epoch: 0212 loss_train: 1.2584 acc_train: 0.5333 loss_val: 1.3394 acc_val: 0.4320 time: 0.1041s\n",
            "0\n",
            "Epoch: 0213 loss_train: 1.1948 acc_train: 0.6250 loss_val: 1.3415 acc_val: 0.4360 time: 0.1043s\n",
            "0\n",
            "Epoch: 0214 loss_train: 1.1952 acc_train: 0.6333 loss_val: 1.3421 acc_val: 0.4360 time: 0.1040s\n",
            "0\n",
            "Epoch: 0215 loss_train: 1.1810 acc_train: 0.7000 loss_val: 1.3332 acc_val: 0.4400 time: 0.1059s\n",
            "0\n",
            "Epoch: 0216 loss_train: 1.1501 acc_train: 0.7250 loss_val: 1.3204 acc_val: 0.4440 time: 0.1040s\n",
            "0\n",
            "Epoch: 0217 loss_train: 1.1679 acc_train: 0.7500 loss_val: 1.3069 acc_val: 0.4480 time: 0.1041s\n",
            "0\n",
            "Epoch: 0218 loss_train: 1.1728 acc_train: 0.6750 loss_val: 1.2994 acc_val: 0.4480 time: 0.1035s\n",
            "0\n",
            "Epoch: 0219 loss_train: 1.1728 acc_train: 0.6417 loss_val: 1.3021 acc_val: 0.4480 time: 0.1052s\n",
            "0\n",
            "Epoch: 0220 loss_train: 1.1780 acc_train: 0.6417 loss_val: 1.3082 acc_val: 0.4500 time: 0.1038s\n",
            "0\n",
            "Epoch: 0221 loss_train: 1.1938 acc_train: 0.6500 loss_val: 1.3151 acc_val: 0.4500 time: 0.1048s\n",
            "0\n",
            "Epoch: 0222 loss_train: 1.1399 acc_train: 0.6833 loss_val: 1.3197 acc_val: 0.4460 time: 0.1041s\n",
            "0\n",
            "Epoch: 0223 loss_train: 1.1550 acc_train: 0.6667 loss_val: 1.3154 acc_val: 0.4480 time: 0.1047s\n",
            "1\n",
            "Epoch: 0224 loss_train: 1.1855 acc_train: 0.6083 loss_val: 1.3054 acc_val: 0.4480 time: 0.1044s\n",
            "2\n",
            "Epoch: 0225 loss_train: 1.1304 acc_train: 0.6750 loss_val: 1.2950 acc_val: 0.4480 time: 0.1065s\n",
            "3\n",
            "Epoch: 0226 loss_train: 1.1569 acc_train: 0.6667 loss_val: 1.2873 acc_val: 0.4480 time: 0.1037s\n",
            "0\n",
            "Epoch: 0227 loss_train: 1.1659 acc_train: 0.6417 loss_val: 1.2875 acc_val: 0.4520 time: 0.1046s\n",
            "0\n",
            "Epoch: 0228 loss_train: 1.1699 acc_train: 0.6583 loss_val: 1.2903 acc_val: 0.4520 time: 0.1050s\n",
            "0\n",
            "Epoch: 0229 loss_train: 1.1195 acc_train: 0.6583 loss_val: 1.2900 acc_val: 0.4520 time: 0.1044s\n",
            "0\n",
            "Epoch: 0230 loss_train: 1.1001 acc_train: 0.6667 loss_val: 1.2892 acc_val: 0.4540 time: 0.1042s\n",
            "0\n",
            "Epoch: 0231 loss_train: 1.1504 acc_train: 0.6583 loss_val: 1.2852 acc_val: 0.4540 time: 0.1044s\n",
            "0\n",
            "Epoch: 0232 loss_train: 1.1645 acc_train: 0.6583 loss_val: 1.2752 acc_val: 0.4540 time: 0.1034s\n",
            "0\n",
            "Epoch: 0233 loss_train: 1.1354 acc_train: 0.6833 loss_val: 1.2641 acc_val: 0.4540 time: 0.1042s\n",
            "0\n",
            "Epoch: 0234 loss_train: 1.1274 acc_train: 0.6917 loss_val: 1.2556 acc_val: 0.4620 time: 0.1037s\n",
            "0\n",
            "Epoch: 0235 loss_train: 1.1183 acc_train: 0.6417 loss_val: 1.2541 acc_val: 0.4660 time: 0.1039s\n",
            "0\n",
            "Epoch: 0236 loss_train: 1.1310 acc_train: 0.7000 loss_val: 1.2602 acc_val: 0.4740 time: 0.1038s\n",
            "0\n",
            "Epoch: 0237 loss_train: 1.1564 acc_train: 0.6583 loss_val: 1.2633 acc_val: 0.4760 time: 0.1054s\n",
            "0\n",
            "Epoch: 0238 loss_train: 1.1421 acc_train: 0.7167 loss_val: 1.2673 acc_val: 0.4780 time: 0.1045s\n",
            "0\n",
            "Epoch: 0239 loss_train: 1.1209 acc_train: 0.6833 loss_val: 1.2679 acc_val: 0.4760 time: 0.1045s\n",
            "0\n",
            "Epoch: 0240 loss_train: 1.1726 acc_train: 0.7083 loss_val: 1.2584 acc_val: 0.4760 time: 0.1040s\n",
            "1\n",
            "Epoch: 0241 loss_train: 1.1447 acc_train: 0.7167 loss_val: 1.2462 acc_val: 0.4740 time: 0.1042s\n",
            "2\n",
            "Epoch: 0242 loss_train: 1.1179 acc_train: 0.6667 loss_val: 1.2364 acc_val: 0.4780 time: 0.1037s\n",
            "0\n",
            "Epoch: 0243 loss_train: 1.0837 acc_train: 0.7250 loss_val: 1.2272 acc_val: 0.4840 time: 0.1038s\n",
            "0\n",
            "Epoch: 0244 loss_train: 1.1180 acc_train: 0.7167 loss_val: 1.2252 acc_val: 0.4880 time: 0.1054s\n",
            "0\n",
            "Epoch: 0245 loss_train: 1.0735 acc_train: 0.7417 loss_val: 1.2279 acc_val: 0.4980 time: 0.1042s\n",
            "0\n",
            "Epoch: 0246 loss_train: 1.0840 acc_train: 0.7167 loss_val: 1.2347 acc_val: 0.5040 time: 0.1039s\n",
            "0\n",
            "Epoch: 0247 loss_train: 1.1113 acc_train: 0.6917 loss_val: 1.2412 acc_val: 0.5100 time: 0.1057s\n",
            "0\n",
            "Epoch: 0248 loss_train: 1.0733 acc_train: 0.7083 loss_val: 1.2406 acc_val: 0.5100 time: 0.1085s\n",
            "0\n",
            "Epoch: 0249 loss_train: 1.1076 acc_train: 0.6833 loss_val: 1.2350 acc_val: 0.5100 time: 0.1049s\n",
            "0\n",
            "Epoch: 0250 loss_train: 1.0628 acc_train: 0.7667 loss_val: 1.2256 acc_val: 0.5060 time: 0.1037s\n",
            "0\n",
            "Epoch: 0251 loss_train: 1.0813 acc_train: 0.6917 loss_val: 1.2130 acc_val: 0.5100 time: 0.1041s\n",
            "1\n",
            "Epoch: 0252 loss_train: 1.1063 acc_train: 0.7167 loss_val: 1.2052 acc_val: 0.5120 time: 0.1038s\n",
            "0\n",
            "Epoch: 0253 loss_train: 1.0606 acc_train: 0.7000 loss_val: 1.2063 acc_val: 0.5180 time: 0.1040s\n",
            "0\n",
            "Epoch: 0254 loss_train: 1.1226 acc_train: 0.7000 loss_val: 1.2082 acc_val: 0.5240 time: 0.1042s\n",
            "0\n",
            "Epoch: 0255 loss_train: 1.0550 acc_train: 0.7583 loss_val: 1.2117 acc_val: 0.5240 time: 0.1045s\n",
            "0\n",
            "Epoch: 0256 loss_train: 1.0107 acc_train: 0.8417 loss_val: 1.2112 acc_val: 0.5240 time: 0.1054s\n",
            "0\n",
            "Epoch: 0257 loss_train: 1.0238 acc_train: 0.7750 loss_val: 1.2101 acc_val: 0.5220 time: 0.1042s\n",
            "0\n",
            "Epoch: 0258 loss_train: 1.0644 acc_train: 0.7250 loss_val: 1.2049 acc_val: 0.5220 time: 0.1039s\n",
            "1\n",
            "Epoch: 0259 loss_train: 1.0725 acc_train: 0.7417 loss_val: 1.1984 acc_val: 0.5200 time: 0.1047s\n",
            "0\n",
            "Epoch: 0260 loss_train: 1.0731 acc_train: 0.6917 loss_val: 1.1890 acc_val: 0.5280 time: 0.1036s\n",
            "0\n",
            "Epoch: 0261 loss_train: 1.0869 acc_train: 0.6750 loss_val: 1.1838 acc_val: 0.5340 time: 0.1042s\n",
            "0\n",
            "Epoch: 0262 loss_train: 0.9817 acc_train: 0.8000 loss_val: 1.1874 acc_val: 0.5400 time: 0.1034s\n",
            "0\n",
            "Epoch: 0263 loss_train: 1.0264 acc_train: 0.7417 loss_val: 1.1915 acc_val: 0.5380 time: 0.1042s\n",
            "0\n",
            "Epoch: 0264 loss_train: 1.0392 acc_train: 0.7417 loss_val: 1.1952 acc_val: 0.5340 time: 0.1043s\n",
            "1\n",
            "Epoch: 0265 loss_train: 1.0641 acc_train: 0.7083 loss_val: 1.1939 acc_val: 0.5340 time: 0.1049s\n",
            "2\n",
            "Epoch: 0266 loss_train: 1.0367 acc_train: 0.7417 loss_val: 1.1875 acc_val: 0.5400 time: 0.1045s\n",
            "3\n",
            "Epoch: 0267 loss_train: 1.0453 acc_train: 0.6833 loss_val: 1.1849 acc_val: 0.5380 time: 0.1041s\n",
            "0\n",
            "Epoch: 0268 loss_train: 1.0597 acc_train: 0.6917 loss_val: 1.1791 acc_val: 0.5380 time: 0.1053s\n",
            "1\n",
            "Epoch: 0269 loss_train: 1.0534 acc_train: 0.7417 loss_val: 1.1766 acc_val: 0.5380 time: 0.1042s\n",
            "0\n",
            "Epoch: 0270 loss_train: 1.0943 acc_train: 0.7167 loss_val: 1.1767 acc_val: 0.5380 time: 0.1042s\n",
            "0\n",
            "Epoch: 0271 loss_train: 1.0491 acc_train: 0.7583 loss_val: 1.1773 acc_val: 0.5400 time: 0.1040s\n",
            "1\n",
            "Epoch: 0272 loss_train: 0.9664 acc_train: 0.7667 loss_val: 1.1763 acc_val: 0.5440 time: 0.1068s\n",
            "0\n",
            "Epoch: 0273 loss_train: 1.0223 acc_train: 0.7417 loss_val: 1.1727 acc_val: 0.5460 time: 0.1041s\n",
            "0\n",
            "Epoch: 0274 loss_train: 1.0476 acc_train: 0.7417 loss_val: 1.1663 acc_val: 0.5500 time: 0.1038s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.9913 acc_train: 0.7333 loss_val: 1.1586 acc_val: 0.5520 time: 0.1088s\n",
            "0\n",
            "Epoch: 0276 loss_train: 1.0538 acc_train: 0.7333 loss_val: 1.1525 acc_val: 0.5520 time: 0.1052s\n",
            "0\n",
            "Epoch: 0277 loss_train: 1.0433 acc_train: 0.7000 loss_val: 1.1535 acc_val: 0.5520 time: 0.1062s\n",
            "0\n",
            "Epoch: 0278 loss_train: 1.0534 acc_train: 0.7167 loss_val: 1.1619 acc_val: 0.5480 time: 0.1049s\n",
            "0\n",
            "Epoch: 0279 loss_train: 1.0318 acc_train: 0.7417 loss_val: 1.1687 acc_val: 0.5460 time: 0.1043s\n",
            "1\n",
            "Epoch: 0280 loss_train: 1.0398 acc_train: 0.7333 loss_val: 1.1652 acc_val: 0.5440 time: 0.1040s\n",
            "2\n",
            "Epoch: 0281 loss_train: 1.0453 acc_train: 0.8000 loss_val: 1.1624 acc_val: 0.5480 time: 0.1048s\n",
            "3\n",
            "Epoch: 0282 loss_train: 1.0388 acc_train: 0.7500 loss_val: 1.1589 acc_val: 0.5500 time: 0.1045s\n",
            "4\n",
            "Epoch: 0283 loss_train: 1.0221 acc_train: 0.7667 loss_val: 1.1566 acc_val: 0.5580 time: 0.1051s\n",
            "5\n",
            "Epoch: 0284 loss_train: 0.9668 acc_train: 0.7917 loss_val: 1.1527 acc_val: 0.5620 time: 0.1052s\n",
            "0\n",
            "Epoch: 0285 loss_train: 1.0286 acc_train: 0.7083 loss_val: 1.1477 acc_val: 0.5600 time: 0.1044s\n",
            "0\n",
            "Epoch: 0286 loss_train: 0.9929 acc_train: 0.7167 loss_val: 1.1437 acc_val: 0.5540 time: 0.1042s\n",
            "0\n",
            "Epoch: 0287 loss_train: 0.9818 acc_train: 0.7667 loss_val: 1.1444 acc_val: 0.5520 time: 0.1041s\n",
            "0\n",
            "Epoch: 0288 loss_train: 1.0162 acc_train: 0.7417 loss_val: 1.1537 acc_val: 0.5480 time: 0.1042s\n",
            "1\n",
            "Epoch: 0289 loss_train: 1.0103 acc_train: 0.7750 loss_val: 1.1627 acc_val: 0.5460 time: 0.1056s\n",
            "2\n",
            "Epoch: 0290 loss_train: 0.9804 acc_train: 0.7667 loss_val: 1.1627 acc_val: 0.5520 time: 0.1040s\n",
            "3\n",
            "Epoch: 0291 loss_train: 1.0198 acc_train: 0.8417 loss_val: 1.1559 acc_val: 0.5560 time: 0.1047s\n",
            "4\n",
            "Epoch: 0292 loss_train: 1.0051 acc_train: 0.7250 loss_val: 1.1495 acc_val: 0.5660 time: 0.1042s\n",
            "5\n",
            "Epoch: 0293 loss_train: 0.9685 acc_train: 0.8167 loss_val: 1.1398 acc_val: 0.5640 time: 0.1063s\n",
            "0\n",
            "Epoch: 0294 loss_train: 0.9704 acc_train: 0.8167 loss_val: 1.1289 acc_val: 0.5680 time: 0.1045s\n",
            "0\n",
            "Epoch: 0295 loss_train: 1.0154 acc_train: 0.7417 loss_val: 1.1240 acc_val: 0.5700 time: 0.1041s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.9871 acc_train: 0.7667 loss_val: 1.1301 acc_val: 0.5640 time: 0.1035s\n",
            "0\n",
            "Epoch: 0297 loss_train: 0.9681 acc_train: 0.7750 loss_val: 1.1370 acc_val: 0.5600 time: 0.1040s\n",
            "1\n",
            "Epoch: 0298 loss_train: 0.9889 acc_train: 0.7333 loss_val: 1.1414 acc_val: 0.5580 time: 0.1043s\n",
            "2\n",
            "Epoch: 0299 loss_train: 0.9952 acc_train: 0.7917 loss_val: 1.1393 acc_val: 0.5600 time: 0.1044s\n",
            "3\n",
            "Epoch: 0300 loss_train: 0.9486 acc_train: 0.7333 loss_val: 1.1378 acc_val: 0.5640 time: 0.1041s\n",
            "4\n",
            "Epoch: 0301 loss_train: 0.9945 acc_train: 0.7417 loss_val: 1.1352 acc_val: 0.5620 time: 0.1050s\n",
            "5\n",
            "Epoch: 0302 loss_train: 0.9465 acc_train: 0.7750 loss_val: 1.1317 acc_val: 0.5620 time: 0.1041s\n",
            "6\n",
            "Epoch: 0303 loss_train: 0.9783 acc_train: 0.7750 loss_val: 1.1297 acc_val: 0.5640 time: 0.1049s\n",
            "7\n",
            "Epoch: 0304 loss_train: 0.9823 acc_train: 0.7583 loss_val: 1.1269 acc_val: 0.5680 time: 0.1042s\n",
            "8\n",
            "Epoch: 0305 loss_train: 1.0269 acc_train: 0.7333 loss_val: 1.1278 acc_val: 0.5700 time: 0.1046s\n",
            "9\n",
            "Epoch: 0306 loss_train: 1.0135 acc_train: 0.7333 loss_val: 1.1303 acc_val: 0.5680 time: 0.1038s\n",
            "0\n",
            "Epoch: 0307 loss_train: 0.9966 acc_train: 0.7167 loss_val: 1.1310 acc_val: 0.5720 time: 0.1045s\n",
            "1\n",
            "Epoch: 0308 loss_train: 0.9868 acc_train: 0.7083 loss_val: 1.1259 acc_val: 0.5720 time: 0.1073s\n",
            "0\n",
            "Epoch: 0309 loss_train: 0.9864 acc_train: 0.7500 loss_val: 1.1199 acc_val: 0.5700 time: 0.1056s\n",
            "0\n",
            "Epoch: 0310 loss_train: 0.9848 acc_train: 0.7750 loss_val: 1.1162 acc_val: 0.5700 time: 0.1038s\n",
            "0\n",
            "Epoch: 0311 loss_train: 0.9766 acc_train: 0.8417 loss_val: 1.1169 acc_val: 0.5680 time: 0.1042s\n",
            "0\n",
            "Epoch: 0312 loss_train: 0.9777 acc_train: 0.7417 loss_val: 1.1215 acc_val: 0.5700 time: 0.1041s\n",
            "1\n",
            "Epoch: 0313 loss_train: 1.0141 acc_train: 0.8333 loss_val: 1.1240 acc_val: 0.5720 time: 0.1058s\n",
            "2\n",
            "Epoch: 0314 loss_train: 1.0109 acc_train: 0.7583 loss_val: 1.1260 acc_val: 0.5700 time: 0.1044s\n",
            "0\n",
            "Epoch: 0315 loss_train: 0.9530 acc_train: 0.7417 loss_val: 1.1227 acc_val: 0.5760 time: 0.1042s\n",
            "1\n",
            "Epoch: 0316 loss_train: 0.9649 acc_train: 0.7917 loss_val: 1.1192 acc_val: 0.5740 time: 0.1040s\n",
            "0\n",
            "Epoch: 0317 loss_train: 0.9541 acc_train: 0.7917 loss_val: 1.1142 acc_val: 0.5740 time: 0.1045s\n",
            "1\n",
            "Epoch: 0318 loss_train: 0.9695 acc_train: 0.7583 loss_val: 1.1126 acc_val: 0.5740 time: 0.1050s\n",
            "0\n",
            "Epoch: 0319 loss_train: 0.9703 acc_train: 0.7583 loss_val: 1.1117 acc_val: 0.5740 time: 0.1052s\n",
            "0\n",
            "Epoch: 0320 loss_train: 1.0060 acc_train: 0.7333 loss_val: 1.1147 acc_val: 0.5720 time: 0.1037s\n",
            "0\n",
            "Epoch: 0321 loss_train: 0.9658 acc_train: 0.7833 loss_val: 1.1186 acc_val: 0.5700 time: 0.1045s\n",
            "1\n",
            "Epoch: 0322 loss_train: 0.9788 acc_train: 0.7500 loss_val: 1.1195 acc_val: 0.5740 time: 0.1052s\n",
            "2\n",
            "Epoch: 0323 loss_train: 0.9749 acc_train: 0.7667 loss_val: 1.1211 acc_val: 0.5760 time: 0.1046s\n",
            "3\n",
            "Epoch: 0324 loss_train: 0.9409 acc_train: 0.8250 loss_val: 1.1204 acc_val: 0.5760 time: 0.1040s\n",
            "0\n",
            "Epoch: 0325 loss_train: 0.9902 acc_train: 0.7833 loss_val: 1.1174 acc_val: 0.5760 time: 0.1053s\n",
            "0\n",
            "Epoch: 0326 loss_train: 0.9442 acc_train: 0.8000 loss_val: 1.1156 acc_val: 0.5760 time: 0.1052s\n",
            "0\n",
            "Epoch: 0327 loss_train: 1.0137 acc_train: 0.7583 loss_val: 1.1122 acc_val: 0.5720 time: 0.1046s\n",
            "0\n",
            "Epoch: 0328 loss_train: 0.9859 acc_train: 0.7667 loss_val: 1.1080 acc_val: 0.5720 time: 0.1048s\n",
            "1\n",
            "Epoch: 0329 loss_train: 0.9840 acc_train: 0.7333 loss_val: 1.1076 acc_val: 0.5760 time: 0.1044s\n",
            "0\n",
            "Epoch: 0330 loss_train: 0.9836 acc_train: 0.7167 loss_val: 1.1087 acc_val: 0.5720 time: 0.1039s\n",
            "0\n",
            "Epoch: 0331 loss_train: 0.9225 acc_train: 0.7500 loss_val: 1.1079 acc_val: 0.5760 time: 0.1085s\n",
            "1\n",
            "Epoch: 0332 loss_train: 0.9457 acc_train: 0.8000 loss_val: 1.1104 acc_val: 0.5760 time: 0.1049s\n",
            "0\n",
            "Epoch: 0333 loss_train: 0.9877 acc_train: 0.8083 loss_val: 1.1092 acc_val: 0.5740 time: 0.1046s\n",
            "0\n",
            "Epoch: 0334 loss_train: 0.9691 acc_train: 0.7583 loss_val: 1.1020 acc_val: 0.5760 time: 0.1039s\n",
            "1\n",
            "Epoch: 0335 loss_train: 0.9361 acc_train: 0.7917 loss_val: 1.0958 acc_val: 0.5760 time: 0.1045s\n",
            "0\n",
            "Epoch: 0336 loss_train: 0.9081 acc_train: 0.8333 loss_val: 1.0939 acc_val: 0.5780 time: 0.1038s\n",
            "0\n",
            "Epoch: 0337 loss_train: 0.9045 acc_train: 0.8000 loss_val: 1.0967 acc_val: 0.5760 time: 0.1040s\n",
            "0\n",
            "Epoch: 0338 loss_train: 0.9262 acc_train: 0.7917 loss_val: 1.1006 acc_val: 0.5760 time: 0.1053s\n",
            "1\n",
            "Epoch: 0339 loss_train: 0.9674 acc_train: 0.6833 loss_val: 1.0983 acc_val: 0.5740 time: 0.1054s\n",
            "2\n",
            "Epoch: 0340 loss_train: 0.9639 acc_train: 0.7583 loss_val: 1.0946 acc_val: 0.5760 time: 0.1041s\n",
            "3\n",
            "Epoch: 0341 loss_train: 0.9415 acc_train: 0.7417 loss_val: 1.0940 acc_val: 0.5780 time: 0.1056s\n",
            "4\n",
            "Epoch: 0342 loss_train: 0.9287 acc_train: 0.7500 loss_val: 1.1012 acc_val: 0.5780 time: 0.1041s\n",
            "0\n",
            "Epoch: 0343 loss_train: 0.9371 acc_train: 0.8167 loss_val: 1.1040 acc_val: 0.5820 time: 0.1044s\n",
            "0\n",
            "Epoch: 0344 loss_train: 0.9145 acc_train: 0.7500 loss_val: 1.1011 acc_val: 0.5780 time: 0.1042s\n",
            "0\n",
            "Epoch: 0345 loss_train: 0.9648 acc_train: 0.7667 loss_val: 1.0960 acc_val: 0.5820 time: 0.1053s\n",
            "1\n",
            "Epoch: 0346 loss_train: 0.9499 acc_train: 0.7917 loss_val: 1.0942 acc_val: 0.5820 time: 0.1038s\n",
            "0\n",
            "Epoch: 0347 loss_train: 0.9830 acc_train: 0.7750 loss_val: 1.0936 acc_val: 0.5800 time: 0.1043s\n",
            "0\n",
            "Epoch: 0348 loss_train: 0.9086 acc_train: 0.7667 loss_val: 1.0964 acc_val: 0.5760 time: 0.1037s\n",
            "0\n",
            "Epoch: 0349 loss_train: 0.9002 acc_train: 0.7833 loss_val: 1.0984 acc_val: 0.5760 time: 0.1042s\n",
            "1\n",
            "Epoch: 0350 loss_train: 0.8688 acc_train: 0.8667 loss_val: 1.1012 acc_val: 0.5740 time: 0.1049s\n",
            "2\n",
            "Epoch: 0351 loss_train: 0.8944 acc_train: 0.7500 loss_val: 1.1041 acc_val: 0.5760 time: 0.1046s\n",
            "3\n",
            "Epoch: 0352 loss_train: 0.9654 acc_train: 0.7500 loss_val: 1.1001 acc_val: 0.5820 time: 0.1043s\n",
            "4\n",
            "Epoch: 0353 loss_train: 0.9433 acc_train: 0.7917 loss_val: 1.0899 acc_val: 0.5840 time: 0.1038s\n",
            "0\n",
            "Epoch: 0354 loss_train: 0.9016 acc_train: 0.8000 loss_val: 1.0834 acc_val: 0.5860 time: 0.1036s\n",
            "0\n",
            "Epoch: 0355 loss_train: 0.9167 acc_train: 0.8250 loss_val: 1.0855 acc_val: 0.5840 time: 0.1046s\n",
            "0\n",
            "Epoch: 0356 loss_train: 0.9303 acc_train: 0.7750 loss_val: 1.0902 acc_val: 0.5840 time: 0.1045s\n",
            "1\n",
            "Epoch: 0357 loss_train: 0.9476 acc_train: 0.7667 loss_val: 1.0972 acc_val: 0.5780 time: 0.1048s\n",
            "2\n",
            "Epoch: 0358 loss_train: 0.8933 acc_train: 0.8000 loss_val: 1.1069 acc_val: 0.5740 time: 0.1056s\n",
            "3\n",
            "Epoch: 0359 loss_train: 0.9205 acc_train: 0.7583 loss_val: 1.1138 acc_val: 0.5780 time: 0.1049s\n",
            "4\n",
            "Epoch: 0360 loss_train: 0.9686 acc_train: 0.7083 loss_val: 1.1112 acc_val: 0.5760 time: 0.1073s\n",
            "5\n",
            "Epoch: 0361 loss_train: 0.9209 acc_train: 0.7583 loss_val: 1.1048 acc_val: 0.5840 time: 0.1048s\n",
            "6\n",
            "Epoch: 0362 loss_train: 0.9232 acc_train: 0.7667 loss_val: 1.0985 acc_val: 0.5840 time: 0.1050s\n",
            "7\n",
            "Epoch: 0363 loss_train: 0.8832 acc_train: 0.8250 loss_val: 1.0927 acc_val: 0.5800 time: 0.1046s\n",
            "8\n",
            "Epoch: 0364 loss_train: 0.9373 acc_train: 0.7167 loss_val: 1.0864 acc_val: 0.5880 time: 0.1047s\n",
            "9\n",
            "Epoch: 0365 loss_train: 0.9016 acc_train: 0.7917 loss_val: 1.0843 acc_val: 0.5840 time: 0.1043s\n",
            "0\n",
            "Epoch: 0366 loss_train: 0.9350 acc_train: 0.8333 loss_val: 1.0886 acc_val: 0.5820 time: 0.1043s\n",
            "1\n",
            "Epoch: 0367 loss_train: 0.8564 acc_train: 0.7833 loss_val: 1.0954 acc_val: 0.5820 time: 0.1052s\n",
            "2\n",
            "Epoch: 0368 loss_train: 0.9507 acc_train: 0.7083 loss_val: 1.0976 acc_val: 0.5800 time: 0.1042s\n",
            "3\n",
            "Epoch: 0369 loss_train: 0.9295 acc_train: 0.8417 loss_val: 1.0928 acc_val: 0.5840 time: 0.1072s\n",
            "4\n",
            "Epoch: 0370 loss_train: 0.9028 acc_train: 0.7833 loss_val: 1.0877 acc_val: 0.5820 time: 0.1038s\n",
            "5\n",
            "Epoch: 0371 loss_train: 0.9322 acc_train: 0.8000 loss_val: 1.0876 acc_val: 0.5820 time: 0.1038s\n",
            "6\n",
            "Epoch: 0372 loss_train: 0.9335 acc_train: 0.7583 loss_val: 1.0879 acc_val: 0.5820 time: 0.1054s\n",
            "7\n",
            "Epoch: 0373 loss_train: 0.8951 acc_train: 0.8000 loss_val: 1.0914 acc_val: 0.5800 time: 0.1046s\n",
            "8\n",
            "Epoch: 0374 loss_train: 0.9051 acc_train: 0.8750 loss_val: 1.0964 acc_val: 0.5760 time: 0.1038s\n",
            "9\n",
            "Epoch: 0375 loss_train: 0.9047 acc_train: 0.8167 loss_val: 1.0978 acc_val: 0.5780 time: 0.1042s\n",
            "10\n",
            "Epoch: 0376 loss_train: 0.8870 acc_train: 0.7583 loss_val: 1.0962 acc_val: 0.5800 time: 0.1039s\n",
            "11\n",
            "Epoch: 0377 loss_train: 0.9062 acc_train: 0.8417 loss_val: 1.0937 acc_val: 0.5840 time: 0.1042s\n",
            "12\n",
            "Epoch: 0378 loss_train: 0.8925 acc_train: 0.8167 loss_val: 1.0893 acc_val: 0.5840 time: 0.1049s\n",
            "13\n",
            "Epoch: 0379 loss_train: 0.9142 acc_train: 0.7917 loss_val: 1.0845 acc_val: 0.5840 time: 0.1057s\n",
            "14\n",
            "Epoch: 0380 loss_train: 0.9075 acc_train: 0.8000 loss_val: 1.0811 acc_val: 0.5860 time: 0.1038s\n",
            "15\n",
            "Epoch: 0381 loss_train: 0.8909 acc_train: 0.8000 loss_val: 1.0815 acc_val: 0.5840 time: 0.1048s\n",
            "0\n",
            "Epoch: 0382 loss_train: 0.9144 acc_train: 0.8250 loss_val: 1.0838 acc_val: 0.5800 time: 0.1040s\n",
            "1\n",
            "Epoch: 0383 loss_train: 0.9288 acc_train: 0.8000 loss_val: 1.0861 acc_val: 0.5800 time: 0.1051s\n",
            "2\n",
            "Epoch: 0384 loss_train: 0.8777 acc_train: 0.8000 loss_val: 1.0845 acc_val: 0.5820 time: 0.1053s\n",
            "3\n",
            "Epoch: 0385 loss_train: 0.8806 acc_train: 0.7833 loss_val: 1.0866 acc_val: 0.5800 time: 0.1042s\n",
            "4\n",
            "Epoch: 0386 loss_train: 0.9112 acc_train: 0.8500 loss_val: 1.0925 acc_val: 0.5760 time: 0.1042s\n",
            "5\n",
            "Epoch: 0387 loss_train: 0.9036 acc_train: 0.6917 loss_val: 1.0952 acc_val: 0.5800 time: 0.1044s\n",
            "6\n",
            "Epoch: 0388 loss_train: 0.8925 acc_train: 0.8167 loss_val: 1.0941 acc_val: 0.5800 time: 0.1079s\n",
            "7\n",
            "Epoch: 0389 loss_train: 0.9257 acc_train: 0.7750 loss_val: 1.0854 acc_val: 0.5840 time: 0.1047s\n",
            "8\n",
            "Epoch: 0390 loss_train: 0.9112 acc_train: 0.8000 loss_val: 1.0784 acc_val: 0.5820 time: 0.1040s\n",
            "9\n",
            "Epoch: 0391 loss_train: 0.9036 acc_train: 0.7667 loss_val: 1.0793 acc_val: 0.5820 time: 0.1043s\n",
            "0\n",
            "Epoch: 0392 loss_train: 0.9090 acc_train: 0.7417 loss_val: 1.0847 acc_val: 0.5840 time: 0.1041s\n",
            "1\n",
            "Epoch: 0393 loss_train: 0.8901 acc_train: 0.8333 loss_val: 1.0910 acc_val: 0.5840 time: 0.1047s\n",
            "2\n",
            "Epoch: 0394 loss_train: 0.8405 acc_train: 0.8083 loss_val: 1.0963 acc_val: 0.5820 time: 0.1036s\n",
            "3\n",
            "Epoch: 0395 loss_train: 0.8830 acc_train: 0.8417 loss_val: 1.0962 acc_val: 0.5800 time: 0.1044s\n",
            "4\n",
            "Epoch: 0396 loss_train: 0.9134 acc_train: 0.8000 loss_val: 1.0932 acc_val: 0.5780 time: 0.1039s\n",
            "5\n",
            "Epoch: 0397 loss_train: 0.9101 acc_train: 0.7750 loss_val: 1.0869 acc_val: 0.5740 time: 0.1067s\n",
            "6\n",
            "Epoch: 0398 loss_train: 0.9324 acc_train: 0.8333 loss_val: 1.0778 acc_val: 0.5820 time: 0.1041s\n",
            "7\n",
            "Epoch: 0399 loss_train: 0.9305 acc_train: 0.8250 loss_val: 1.0734 acc_val: 0.5800 time: 0.1044s\n",
            "0\n",
            "Epoch: 0400 loss_train: 0.8829 acc_train: 0.8083 loss_val: 1.0773 acc_val: 0.5820 time: 0.1044s\n",
            "0\n",
            "Epoch: 0401 loss_train: 0.8872 acc_train: 0.8000 loss_val: 1.0859 acc_val: 0.5860 time: 0.1047s\n",
            "1\n",
            "Epoch: 0402 loss_train: 0.8883 acc_train: 0.8250 loss_val: 1.0919 acc_val: 0.5900 time: 0.1039s\n",
            "2\n",
            "Epoch: 0403 loss_train: 0.8630 acc_train: 0.7750 loss_val: 1.0926 acc_val: 0.5880 time: 0.1062s\n",
            "0\n",
            "Epoch: 0404 loss_train: 0.9100 acc_train: 0.7167 loss_val: 1.0894 acc_val: 0.5840 time: 0.1043s\n",
            "1\n",
            "Epoch: 0405 loss_train: 0.9090 acc_train: 0.7833 loss_val: 1.0840 acc_val: 0.5820 time: 0.1044s\n",
            "2\n",
            "Epoch: 0406 loss_train: 0.9135 acc_train: 0.7583 loss_val: 1.0777 acc_val: 0.5800 time: 0.1060s\n",
            "3\n",
            "Epoch: 0407 loss_train: 0.9091 acc_train: 0.7667 loss_val: 1.0758 acc_val: 0.5840 time: 0.1053s\n",
            "4\n",
            "Epoch: 0408 loss_train: 0.8450 acc_train: 0.8250 loss_val: 1.0819 acc_val: 0.5840 time: 0.1040s\n",
            "5\n",
            "Epoch: 0409 loss_train: 0.9306 acc_train: 0.7583 loss_val: 1.0858 acc_val: 0.5860 time: 0.1046s\n",
            "6\n",
            "Epoch: 0410 loss_train: 0.8875 acc_train: 0.7833 loss_val: 1.0890 acc_val: 0.5860 time: 0.1052s\n",
            "7\n",
            "Epoch: 0411 loss_train: 0.9136 acc_train: 0.7417 loss_val: 1.0917 acc_val: 0.5880 time: 0.1049s\n",
            "8\n",
            "Epoch: 0412 loss_train: 0.8734 acc_train: 0.7667 loss_val: 1.0866 acc_val: 0.5840 time: 0.1043s\n",
            "9\n",
            "Epoch: 0413 loss_train: 0.8629 acc_train: 0.8000 loss_val: 1.0859 acc_val: 0.5860 time: 0.1051s\n",
            "10\n",
            "Epoch: 0414 loss_train: 0.9273 acc_train: 0.7583 loss_val: 1.0847 acc_val: 0.5800 time: 0.1063s\n",
            "11\n",
            "Epoch: 0415 loss_train: 0.8599 acc_train: 0.8083 loss_val: 1.0854 acc_val: 0.5800 time: 0.1050s\n",
            "12\n",
            "Epoch: 0416 loss_train: 0.8888 acc_train: 0.8167 loss_val: 1.0868 acc_val: 0.5840 time: 0.1052s\n",
            "13\n",
            "Epoch: 0417 loss_train: 0.8741 acc_train: 0.8583 loss_val: 1.0921 acc_val: 0.5780 time: 0.1044s\n",
            "14\n",
            "Epoch: 0418 loss_train: 0.8932 acc_train: 0.7500 loss_val: 1.0899 acc_val: 0.5840 time: 0.1043s\n",
            "15\n",
            "Epoch: 0419 loss_train: 0.8826 acc_train: 0.8167 loss_val: 1.0846 acc_val: 0.5900 time: 0.1049s\n",
            "16\n",
            "Epoch: 0420 loss_train: 0.8777 acc_train: 0.7500 loss_val: 1.0792 acc_val: 0.5880 time: 0.1051s\n",
            "0\n",
            "Epoch: 0421 loss_train: 0.8867 acc_train: 0.8000 loss_val: 1.0743 acc_val: 0.5860 time: 0.1045s\n",
            "1\n",
            "Epoch: 0422 loss_train: 0.9253 acc_train: 0.7750 loss_val: 1.0738 acc_val: 0.5880 time: 0.1047s\n",
            "2\n",
            "Epoch: 0423 loss_train: 0.8637 acc_train: 0.8000 loss_val: 1.0787 acc_val: 0.5820 time: 0.1046s\n",
            "3\n",
            "Epoch: 0424 loss_train: 0.8744 acc_train: 0.7917 loss_val: 1.0860 acc_val: 0.5840 time: 0.1066s\n",
            "4\n",
            "Epoch: 0425 loss_train: 0.8649 acc_train: 0.8417 loss_val: 1.0907 acc_val: 0.5840 time: 0.1046s\n",
            "5\n",
            "Epoch: 0426 loss_train: 0.8576 acc_train: 0.7750 loss_val: 1.0886 acc_val: 0.5820 time: 0.1048s\n",
            "6\n",
            "Epoch: 0427 loss_train: 0.8612 acc_train: 0.8167 loss_val: 1.0844 acc_val: 0.5820 time: 0.1051s\n",
            "7\n",
            "Epoch: 0428 loss_train: 0.8720 acc_train: 0.8000 loss_val: 1.0807 acc_val: 0.5900 time: 0.1047s\n",
            "8\n",
            "Epoch: 0429 loss_train: 0.8716 acc_train: 0.7833 loss_val: 1.0765 acc_val: 0.5900 time: 0.1045s\n",
            "0\n",
            "Epoch: 0430 loss_train: 0.8838 acc_train: 0.8500 loss_val: 1.0782 acc_val: 0.5880 time: 0.1065s\n",
            "0\n",
            "Epoch: 0431 loss_train: 0.8930 acc_train: 0.7917 loss_val: 1.0832 acc_val: 0.5860 time: 0.1045s\n",
            "1\n",
            "Epoch: 0432 loss_train: 0.8609 acc_train: 0.7750 loss_val: 1.0890 acc_val: 0.5840 time: 0.1050s\n",
            "2\n",
            "Epoch: 0433 loss_train: 0.8975 acc_train: 0.7583 loss_val: 1.0905 acc_val: 0.5840 time: 0.1049s\n",
            "3\n",
            "Epoch: 0434 loss_train: 0.8684 acc_train: 0.7833 loss_val: 1.0910 acc_val: 0.5840 time: 0.1038s\n",
            "4\n",
            "Epoch: 0435 loss_train: 0.8455 acc_train: 0.7750 loss_val: 1.0904 acc_val: 0.5880 time: 0.1047s\n",
            "5\n",
            "Epoch: 0436 loss_train: 0.8523 acc_train: 0.8167 loss_val: 1.0868 acc_val: 0.5920 time: 0.1042s\n",
            "6\n",
            "Epoch: 0437 loss_train: 0.9353 acc_train: 0.7917 loss_val: 1.0845 acc_val: 0.6000 time: 0.1043s\n",
            "0\n",
            "Epoch: 0438 loss_train: 0.8551 acc_train: 0.7750 loss_val: 1.0791 acc_val: 0.5900 time: 0.1040s\n",
            "0\n",
            "Epoch: 0439 loss_train: 0.8453 acc_train: 0.7833 loss_val: 1.0750 acc_val: 0.5880 time: 0.1048s\n",
            "1\n",
            "Epoch: 0440 loss_train: 0.8597 acc_train: 0.8333 loss_val: 1.0752 acc_val: 0.5820 time: 0.1045s\n",
            "2\n",
            "Epoch: 0441 loss_train: 0.8383 acc_train: 0.8500 loss_val: 1.0773 acc_val: 0.5840 time: 0.1050s\n",
            "3\n",
            "Epoch: 0442 loss_train: 0.8643 acc_train: 0.7500 loss_val: 1.0851 acc_val: 0.5820 time: 0.1052s\n",
            "4\n",
            "Epoch: 0443 loss_train: 0.9140 acc_train: 0.7833 loss_val: 1.0881 acc_val: 0.5820 time: 0.1054s\n",
            "5\n",
            "Epoch: 0444 loss_train: 0.8805 acc_train: 0.7917 loss_val: 1.0889 acc_val: 0.5820 time: 0.1049s\n",
            "6\n",
            "Epoch: 0445 loss_train: 0.8825 acc_train: 0.8000 loss_val: 1.0889 acc_val: 0.5880 time: 0.1048s\n",
            "7\n",
            "Epoch: 0446 loss_train: 0.8641 acc_train: 0.8083 loss_val: 1.0857 acc_val: 0.5840 time: 0.1041s\n",
            "8\n",
            "Epoch: 0447 loss_train: 0.8348 acc_train: 0.8083 loss_val: 1.0864 acc_val: 0.5820 time: 0.1059s\n",
            "9\n",
            "Epoch: 0448 loss_train: 0.8365 acc_train: 0.7833 loss_val: 1.0890 acc_val: 0.5820 time: 0.1051s\n",
            "10\n",
            "Epoch: 0449 loss_train: 0.8745 acc_train: 0.8083 loss_val: 1.0918 acc_val: 0.5800 time: 0.1050s\n",
            "11\n",
            "Epoch: 0450 loss_train: 0.8389 acc_train: 0.8000 loss_val: 1.0873 acc_val: 0.5800 time: 0.1041s\n",
            "12\n",
            "Epoch: 0451 loss_train: 0.8576 acc_train: 0.8000 loss_val: 1.0813 acc_val: 0.5860 time: 0.1050s\n",
            "13\n",
            "Epoch: 0452 loss_train: 0.8752 acc_train: 0.8083 loss_val: 1.0745 acc_val: 0.5820 time: 0.1062s\n",
            "14\n",
            "Epoch: 0453 loss_train: 0.8780 acc_train: 0.8167 loss_val: 1.0715 acc_val: 0.5920 time: 0.1046s\n",
            "15\n",
            "Epoch: 0454 loss_train: 0.8770 acc_train: 0.7917 loss_val: 1.0741 acc_val: 0.5900 time: 0.1045s\n",
            "0\n",
            "Epoch: 0455 loss_train: 0.8847 acc_train: 0.7833 loss_val: 1.0778 acc_val: 0.5840 time: 0.1046s\n",
            "1\n",
            "Epoch: 0456 loss_train: 0.8832 acc_train: 0.7833 loss_val: 1.0848 acc_val: 0.5780 time: 0.1047s\n",
            "2\n",
            "Epoch: 0457 loss_train: 0.8599 acc_train: 0.8167 loss_val: 1.0908 acc_val: 0.5840 time: 0.1044s\n",
            "3\n",
            "Epoch: 0458 loss_train: 0.8508 acc_train: 0.7583 loss_val: 1.0914 acc_val: 0.5820 time: 0.1040s\n",
            "4\n",
            "Epoch: 0459 loss_train: 0.8352 acc_train: 0.8250 loss_val: 1.0871 acc_val: 0.5900 time: 0.1044s\n",
            "5\n",
            "Epoch: 0460 loss_train: 0.8515 acc_train: 0.8000 loss_val: 1.0739 acc_val: 0.5920 time: 0.1043s\n",
            "6\n",
            "Epoch: 0461 loss_train: 0.8403 acc_train: 0.7917 loss_val: 1.0720 acc_val: 0.5940 time: 0.1058s\n",
            "7\n",
            "Epoch: 0462 loss_train: 0.8429 acc_train: 0.8083 loss_val: 1.0763 acc_val: 0.5900 time: 0.1046s\n",
            "8\n",
            "Epoch: 0463 loss_train: 0.8853 acc_train: 0.8333 loss_val: 1.0862 acc_val: 0.5860 time: 0.1088s\n",
            "9\n",
            "Epoch: 0464 loss_train: 0.8650 acc_train: 0.8250 loss_val: 1.0955 acc_val: 0.5800 time: 0.1042s\n",
            "10\n",
            "Epoch: 0465 loss_train: 0.8766 acc_train: 0.7750 loss_val: 1.0896 acc_val: 0.5840 time: 0.1041s\n",
            "11\n",
            "Epoch: 0466 loss_train: 0.8875 acc_train: 0.7583 loss_val: 1.0775 acc_val: 0.5920 time: 0.1039s\n",
            "12\n",
            "Epoch: 0467 loss_train: 0.8833 acc_train: 0.7833 loss_val: 1.0695 acc_val: 0.5940 time: 0.1044s\n",
            "13\n",
            "Epoch: 0468 loss_train: 0.8581 acc_train: 0.8167 loss_val: 1.0726 acc_val: 0.5940 time: 0.1041s\n",
            "0\n",
            "Epoch: 0469 loss_train: 0.8249 acc_train: 0.8333 loss_val: 1.0774 acc_val: 0.5920 time: 0.1046s\n",
            "1\n",
            "Epoch: 0470 loss_train: 0.8423 acc_train: 0.8333 loss_val: 1.0815 acc_val: 0.5880 time: 0.1040s\n",
            "2\n",
            "Epoch: 0471 loss_train: 0.8290 acc_train: 0.8000 loss_val: 1.0904 acc_val: 0.5860 time: 0.1043s\n",
            "3\n",
            "Epoch: 0472 loss_train: 0.8588 acc_train: 0.8083 loss_val: 1.0954 acc_val: 0.5800 time: 0.1070s\n",
            "4\n",
            "Epoch: 0473 loss_train: 0.8551 acc_train: 0.7500 loss_val: 1.0895 acc_val: 0.5780 time: 0.1050s\n",
            "5\n",
            "Epoch: 0474 loss_train: 0.8867 acc_train: 0.7583 loss_val: 1.0793 acc_val: 0.5840 time: 0.1054s\n",
            "6\n",
            "Epoch: 0475 loss_train: 0.8427 acc_train: 0.8000 loss_val: 1.0653 acc_val: 0.5920 time: 0.1044s\n",
            "7\n",
            "Epoch: 0476 loss_train: 0.7954 acc_train: 0.8500 loss_val: 1.0574 acc_val: 0.5960 time: 0.1048s\n",
            "0\n",
            "Epoch: 0477 loss_train: 0.8570 acc_train: 0.8167 loss_val: 1.0590 acc_val: 0.5960 time: 0.1069s\n",
            "0\n",
            "Epoch: 0478 loss_train: 0.8604 acc_train: 0.8083 loss_val: 1.0700 acc_val: 0.5920 time: 0.1042s\n",
            "1\n",
            "Epoch: 0479 loss_train: 0.8206 acc_train: 0.8083 loss_val: 1.0863 acc_val: 0.5920 time: 0.1046s\n",
            "2\n",
            "Epoch: 0480 loss_train: 0.8930 acc_train: 0.7917 loss_val: 1.0935 acc_val: 0.5920 time: 0.1039s\n",
            "3\n",
            "Epoch: 0481 loss_train: 0.8335 acc_train: 0.8417 loss_val: 1.0893 acc_val: 0.5920 time: 0.1046s\n",
            "4\n",
            "Epoch: 0482 loss_train: 0.8643 acc_train: 0.8500 loss_val: 1.0800 acc_val: 0.5900 time: 0.1056s\n",
            "5\n",
            "Epoch: 0483 loss_train: 0.8756 acc_train: 0.7833 loss_val: 1.0672 acc_val: 0.5940 time: 0.1043s\n",
            "6\n",
            "Epoch: 0484 loss_train: 0.8262 acc_train: 0.8083 loss_val: 1.0613 acc_val: 0.5980 time: 0.1046s\n",
            "7\n",
            "Epoch: 0485 loss_train: 0.8712 acc_train: 0.8000 loss_val: 1.0629 acc_val: 0.5980 time: 0.1045s\n",
            "8\n",
            "Epoch: 0486 loss_train: 0.8508 acc_train: 0.7583 loss_val: 1.0732 acc_val: 0.5920 time: 0.1039s\n",
            "9\n",
            "Epoch: 0487 loss_train: 0.8596 acc_train: 0.8167 loss_val: 1.0892 acc_val: 0.5820 time: 0.1043s\n",
            "10\n",
            "Epoch: 0488 loss_train: 0.8543 acc_train: 0.7667 loss_val: 1.1030 acc_val: 0.5820 time: 0.1041s\n",
            "11\n",
            "Epoch: 0489 loss_train: 0.8742 acc_train: 0.7750 loss_val: 1.1055 acc_val: 0.5800 time: 0.1045s\n",
            "12\n",
            "Epoch: 0490 loss_train: 0.8347 acc_train: 0.8417 loss_val: 1.0935 acc_val: 0.5840 time: 0.1046s\n",
            "13\n",
            "Epoch: 0491 loss_train: 0.8335 acc_train: 0.8000 loss_val: 1.0782 acc_val: 0.5920 time: 0.1055s\n",
            "14\n",
            "Epoch: 0492 loss_train: 0.8132 acc_train: 0.8583 loss_val: 1.0678 acc_val: 0.5940 time: 0.1045s\n",
            "15\n",
            "Epoch: 0493 loss_train: 0.7864 acc_train: 0.8333 loss_val: 1.0620 acc_val: 0.5960 time: 0.1041s\n",
            "16\n",
            "Epoch: 0494 loss_train: 0.8024 acc_train: 0.8333 loss_val: 1.0627 acc_val: 0.5960 time: 0.1075s\n",
            "17\n",
            "Epoch: 0495 loss_train: 0.8476 acc_train: 0.8250 loss_val: 1.0695 acc_val: 0.5960 time: 0.1046s\n",
            "18\n",
            "Epoch: 0496 loss_train: 0.8455 acc_train: 0.7667 loss_val: 1.0749 acc_val: 0.5960 time: 0.1042s\n",
            "19\n",
            "Epoch: 0497 loss_train: 0.8791 acc_train: 0.8333 loss_val: 1.0829 acc_val: 0.5900 time: 0.1055s\n",
            "20\n",
            "Epoch: 0498 loss_train: 0.7947 acc_train: 0.8333 loss_val: 1.0924 acc_val: 0.5920 time: 0.1053s\n",
            "21\n",
            "Epoch: 0499 loss_train: 0.8591 acc_train: 0.8000 loss_val: 1.0949 acc_val: 0.5900 time: 0.1042s\n",
            "22\n",
            "Epoch: 0500 loss_train: 0.8546 acc_train: 0.7667 loss_val: 1.0925 acc_val: 0.5860 time: 0.1038s\n",
            "23\n",
            "Epoch: 0501 loss_train: 0.7991 acc_train: 0.8917 loss_val: 1.0859 acc_val: 0.5780 time: 0.1051s\n",
            "24\n",
            "Epoch: 0502 loss_train: 0.8597 acc_train: 0.8167 loss_val: 1.0669 acc_val: 0.5980 time: 0.1039s\n",
            "25\n",
            "Epoch: 0503 loss_train: 0.8612 acc_train: 0.8417 loss_val: 1.0529 acc_val: 0.6020 time: 0.1047s\n",
            "26\n",
            "Epoch: 0504 loss_train: 0.7777 acc_train: 0.8500 loss_val: 1.0508 acc_val: 0.6040 time: 0.1045s\n",
            "0\n",
            "Epoch: 0505 loss_train: 0.8158 acc_train: 0.8500 loss_val: 1.0596 acc_val: 0.6040 time: 0.1045s\n",
            "0\n",
            "Epoch: 0506 loss_train: 0.8068 acc_train: 0.8583 loss_val: 1.0778 acc_val: 0.5980 time: 0.1039s\n",
            "0\n",
            "Epoch: 0507 loss_train: 0.8614 acc_train: 0.8250 loss_val: 1.0920 acc_val: 0.5960 time: 0.1050s\n",
            "1\n",
            "Epoch: 0508 loss_train: 0.8234 acc_train: 0.8750 loss_val: 1.0969 acc_val: 0.5840 time: 0.1041s\n",
            "2\n",
            "Epoch: 0509 loss_train: 0.8349 acc_train: 0.8250 loss_val: 1.0930 acc_val: 0.5800 time: 0.1048s\n",
            "3\n",
            "Epoch: 0510 loss_train: 0.8689 acc_train: 0.7917 loss_val: 1.0794 acc_val: 0.5820 time: 0.1049s\n",
            "4\n",
            "Epoch: 0511 loss_train: 0.9025 acc_train: 0.7667 loss_val: 1.0690 acc_val: 0.5920 time: 0.1052s\n",
            "5\n",
            "Epoch: 0512 loss_train: 0.7958 acc_train: 0.8333 loss_val: 1.0621 acc_val: 0.6000 time: 0.1057s\n",
            "6\n",
            "Epoch: 0513 loss_train: 0.8659 acc_train: 0.8583 loss_val: 1.0650 acc_val: 0.6000 time: 0.1046s\n",
            "7\n",
            "Epoch: 0514 loss_train: 0.8181 acc_train: 0.8167 loss_val: 1.0757 acc_val: 0.5900 time: 0.1059s\n",
            "8\n",
            "Epoch: 0515 loss_train: 0.8792 acc_train: 0.7917 loss_val: 1.0786 acc_val: 0.5860 time: 0.1047s\n",
            "9\n",
            "Epoch: 0516 loss_train: 0.8224 acc_train: 0.8167 loss_val: 1.0791 acc_val: 0.5860 time: 0.1042s\n",
            "10\n",
            "Epoch: 0517 loss_train: 0.8513 acc_train: 0.8250 loss_val: 1.0799 acc_val: 0.5840 time: 0.1047s\n",
            "11\n",
            "Epoch: 0518 loss_train: 0.8158 acc_train: 0.8083 loss_val: 1.0746 acc_val: 0.5800 time: 0.1054s\n",
            "12\n",
            "Epoch: 0519 loss_train: 0.8942 acc_train: 0.7667 loss_val: 1.0684 acc_val: 0.5880 time: 0.1050s\n",
            "13\n",
            "Epoch: 0520 loss_train: 0.8044 acc_train: 0.8333 loss_val: 1.0733 acc_val: 0.5940 time: 0.1068s\n",
            "14\n",
            "Epoch: 0521 loss_train: 0.8169 acc_train: 0.8333 loss_val: 1.0875 acc_val: 0.5920 time: 0.1044s\n",
            "15\n",
            "Epoch: 0522 loss_train: 0.8837 acc_train: 0.8417 loss_val: 1.0958 acc_val: 0.5880 time: 0.1037s\n",
            "16\n",
            "Epoch: 0523 loss_train: 0.8527 acc_train: 0.7917 loss_val: 1.0963 acc_val: 0.5840 time: 0.1042s\n",
            "17\n",
            "Epoch: 0524 loss_train: 0.8553 acc_train: 0.8250 loss_val: 1.0881 acc_val: 0.5880 time: 0.1044s\n",
            "18\n",
            "Epoch: 0525 loss_train: 0.8164 acc_train: 0.8500 loss_val: 1.0732 acc_val: 0.5920 time: 0.1047s\n",
            "19\n",
            "Epoch: 0526 loss_train: 0.8183 acc_train: 0.8333 loss_val: 1.0611 acc_val: 0.5960 time: 0.1040s\n",
            "20\n",
            "Epoch: 0527 loss_train: 0.8255 acc_train: 0.8667 loss_val: 1.0582 acc_val: 0.5960 time: 0.1057s\n",
            "21\n",
            "Epoch: 0528 loss_train: 0.8331 acc_train: 0.8417 loss_val: 1.0635 acc_val: 0.5960 time: 0.1043s\n",
            "22\n",
            "Epoch: 0529 loss_train: 0.8308 acc_train: 0.8500 loss_val: 1.0715 acc_val: 0.5940 time: 0.1068s\n",
            "23\n",
            "Epoch: 0530 loss_train: 0.8451 acc_train: 0.7667 loss_val: 1.0811 acc_val: 0.5880 time: 0.1066s\n",
            "24\n",
            "Epoch: 0531 loss_train: 0.8703 acc_train: 0.8250 loss_val: 1.0802 acc_val: 0.5860 time: 0.1044s\n",
            "25\n",
            "Epoch: 0532 loss_train: 0.8531 acc_train: 0.8083 loss_val: 1.0722 acc_val: 0.5860 time: 0.1040s\n",
            "26\n",
            "Epoch: 0533 loss_train: 0.8303 acc_train: 0.7667 loss_val: 1.0696 acc_val: 0.5860 time: 0.1048s\n",
            "27\n",
            "Epoch: 0534 loss_train: 0.8277 acc_train: 0.8167 loss_val: 1.0679 acc_val: 0.5960 time: 0.1041s\n",
            "28\n",
            "Epoch: 0535 loss_train: 0.8205 acc_train: 0.8167 loss_val: 1.0654 acc_val: 0.6000 time: 0.1046s\n",
            "29\n",
            "Epoch: 0536 loss_train: 0.8272 acc_train: 0.8333 loss_val: 1.0688 acc_val: 0.5960 time: 0.1038s\n",
            "30\n",
            "Epoch: 0537 loss_train: 0.8668 acc_train: 0.7917 loss_val: 1.0760 acc_val: 0.5960 time: 0.1054s\n",
            "31\n",
            "Epoch: 0538 loss_train: 0.8374 acc_train: 0.8167 loss_val: 1.0825 acc_val: 0.5960 time: 0.1043s\n",
            "32\n",
            "Epoch: 0539 loss_train: 0.8394 acc_train: 0.7750 loss_val: 1.0847 acc_val: 0.5900 time: 0.1052s\n",
            "33\n",
            "Epoch: 0540 loss_train: 0.7936 acc_train: 0.8667 loss_val: 1.0806 acc_val: 0.5880 time: 0.1044s\n",
            "34\n",
            "Epoch: 0541 loss_train: 0.8248 acc_train: 0.8083 loss_val: 1.0676 acc_val: 0.5940 time: 0.1044s\n",
            "35\n",
            "Epoch: 0542 loss_train: 0.8165 acc_train: 0.8333 loss_val: 1.0607 acc_val: 0.6000 time: 0.1040s\n",
            "36\n",
            "Epoch: 0543 loss_train: 0.8109 acc_train: 0.8417 loss_val: 1.0626 acc_val: 0.6020 time: 0.1049s\n",
            "37\n",
            "Epoch: 0544 loss_train: 0.8070 acc_train: 0.8667 loss_val: 1.0669 acc_val: 0.6000 time: 0.1060s\n",
            "38\n",
            "Epoch: 0545 loss_train: 0.8040 acc_train: 0.8333 loss_val: 1.0764 acc_val: 0.5960 time: 0.1057s\n",
            "39\n",
            "Epoch: 0546 loss_train: 0.8072 acc_train: 0.8917 loss_val: 1.0880 acc_val: 0.5880 time: 0.1040s\n",
            "40\n",
            "Epoch: 0547 loss_train: 0.8523 acc_train: 0.8250 loss_val: 1.0908 acc_val: 0.5880 time: 0.1047s\n",
            "41\n",
            "Epoch: 0548 loss_train: 0.8725 acc_train: 0.7333 loss_val: 1.0810 acc_val: 0.5940 time: 0.1051s\n",
            "42\n",
            "Epoch: 0549 loss_train: 0.8719 acc_train: 0.7917 loss_val: 1.0713 acc_val: 0.5940 time: 0.1047s\n",
            "43\n",
            "Epoch: 0550 loss_train: 0.8424 acc_train: 0.7583 loss_val: 1.0654 acc_val: 0.5960 time: 0.1055s\n",
            "44\n",
            "Epoch: 0551 loss_train: 0.8501 acc_train: 0.8083 loss_val: 1.0615 acc_val: 0.5980 time: 0.1046s\n",
            "45\n",
            "Epoch: 0552 loss_train: 0.8094 acc_train: 0.8583 loss_val: 1.0651 acc_val: 0.5940 time: 0.1048s\n",
            "46\n",
            "Epoch: 0553 loss_train: 0.8103 acc_train: 0.8667 loss_val: 1.0762 acc_val: 0.5920 time: 0.1043s\n",
            "47\n",
            "Epoch: 0554 loss_train: 0.8146 acc_train: 0.8000 loss_val: 1.0867 acc_val: 0.5820 time: 0.1045s\n",
            "48\n",
            "Epoch: 0555 loss_train: 0.8258 acc_train: 0.7750 loss_val: 1.0920 acc_val: 0.5820 time: 0.1042s\n",
            "49\n",
            "Epoch: 0556 loss_train: 0.8380 acc_train: 0.7667 loss_val: 1.0780 acc_val: 0.5880 time: 0.1038s\n",
            "50\n",
            "Epoch: 0557 loss_train: 0.8233 acc_train: 0.7833 loss_val: 1.0629 acc_val: 0.5980 time: 0.1044s\n",
            "51\n",
            "Epoch: 0558 loss_train: 0.8108 acc_train: 0.8083 loss_val: 1.0556 acc_val: 0.5980 time: 0.1049s\n",
            "52\n",
            "Epoch: 0559 loss_train: 0.8750 acc_train: 0.7500 loss_val: 1.0545 acc_val: 0.5980 time: 0.1058s\n",
            "53\n",
            "Epoch: 0560 loss_train: 0.8602 acc_train: 0.8417 loss_val: 1.0634 acc_val: 0.5980 time: 0.1040s\n",
            "54\n",
            "Epoch: 0561 loss_train: 0.8181 acc_train: 0.8750 loss_val: 1.0792 acc_val: 0.5880 time: 0.1045s\n",
            "55\n",
            "Epoch: 0562 loss_train: 0.8346 acc_train: 0.8000 loss_val: 1.0926 acc_val: 0.5840 time: 0.1037s\n",
            "56\n",
            "Epoch: 0563 loss_train: 0.8415 acc_train: 0.8000 loss_val: 1.0915 acc_val: 0.5820 time: 0.1045s\n",
            "57\n",
            "Epoch: 0564 loss_train: 0.7865 acc_train: 0.8750 loss_val: 1.0796 acc_val: 0.5860 time: 0.1047s\n",
            "58\n",
            "Epoch: 0565 loss_train: 0.8539 acc_train: 0.7833 loss_val: 1.0666 acc_val: 0.5960 time: 0.1052s\n",
            "59\n",
            "Epoch: 0566 loss_train: 0.8189 acc_train: 0.8333 loss_val: 1.0592 acc_val: 0.5980 time: 0.1072s\n",
            "60\n",
            "Epoch: 0567 loss_train: 0.8163 acc_train: 0.8333 loss_val: 1.0538 acc_val: 0.6020 time: 0.1058s\n",
            "61\n",
            "Epoch: 0568 loss_train: 0.8545 acc_train: 0.7500 loss_val: 1.0546 acc_val: 0.6020 time: 0.1048s\n",
            "62\n",
            "Epoch: 0569 loss_train: 0.8044 acc_train: 0.8417 loss_val: 1.0627 acc_val: 0.6000 time: 0.1059s\n",
            "63\n",
            "Epoch: 0570 loss_train: 0.8458 acc_train: 0.7833 loss_val: 1.0749 acc_val: 0.5960 time: 0.1050s\n",
            "64\n",
            "Epoch: 0571 loss_train: 0.8176 acc_train: 0.8333 loss_val: 1.0830 acc_val: 0.5940 time: 0.1051s\n",
            "65\n",
            "Epoch: 0572 loss_train: 0.8459 acc_train: 0.7917 loss_val: 1.0827 acc_val: 0.5900 time: 0.1049s\n",
            "66\n",
            "Epoch: 0573 loss_train: 0.7951 acc_train: 0.8333 loss_val: 1.0819 acc_val: 0.5880 time: 0.1048s\n",
            "67\n",
            "Epoch: 0574 loss_train: 0.8396 acc_train: 0.7917 loss_val: 1.0805 acc_val: 0.5940 time: 0.1041s\n",
            "68\n",
            "Epoch: 0575 loss_train: 0.8339 acc_train: 0.8333 loss_val: 1.0761 acc_val: 0.5960 time: 0.1052s\n",
            "69\n",
            "Epoch: 0576 loss_train: 0.8082 acc_train: 0.8083 loss_val: 1.0682 acc_val: 0.6000 time: 0.1044s\n",
            "70\n",
            "Epoch: 0577 loss_train: 0.8126 acc_train: 0.8417 loss_val: 1.0644 acc_val: 0.6000 time: 0.1049s\n",
            "71\n",
            "Epoch: 0578 loss_train: 0.7753 acc_train: 0.7750 loss_val: 1.0635 acc_val: 0.5960 time: 0.1052s\n",
            "72\n",
            "Epoch: 0579 loss_train: 0.8413 acc_train: 0.7583 loss_val: 1.0659 acc_val: 0.5960 time: 0.1041s\n",
            "73\n",
            "Epoch: 0580 loss_train: 0.8115 acc_train: 0.8417 loss_val: 1.0676 acc_val: 0.5960 time: 0.1043s\n",
            "74\n",
            "Epoch: 0581 loss_train: 0.8302 acc_train: 0.7583 loss_val: 1.0704 acc_val: 0.5980 time: 0.1043s\n",
            "75\n",
            "Epoch: 0582 loss_train: 0.8607 acc_train: 0.7583 loss_val: 1.0766 acc_val: 0.5960 time: 0.1050s\n",
            "76\n",
            "Epoch: 0583 loss_train: 0.8506 acc_train: 0.8000 loss_val: 1.0801 acc_val: 0.5900 time: 0.1054s\n",
            "77\n",
            "Epoch: 0584 loss_train: 0.8459 acc_train: 0.8167 loss_val: 1.0774 acc_val: 0.5960 time: 0.1039s\n",
            "78\n",
            "Epoch: 0585 loss_train: 0.8278 acc_train: 0.7917 loss_val: 1.0720 acc_val: 0.6000 time: 0.1043s\n",
            "79\n",
            "Epoch: 0586 loss_train: 0.7762 acc_train: 0.8333 loss_val: 1.0712 acc_val: 0.6020 time: 0.1048s\n",
            "80\n",
            "Epoch: 0587 loss_train: 0.7890 acc_train: 0.8583 loss_val: 1.0685 acc_val: 0.6020 time: 0.1051s\n",
            "81\n",
            "Epoch: 0588 loss_train: 0.8376 acc_train: 0.8417 loss_val: 1.0660 acc_val: 0.6020 time: 0.1042s\n",
            "82\n",
            "Epoch: 0589 loss_train: 0.8022 acc_train: 0.8250 loss_val: 1.0677 acc_val: 0.6000 time: 0.1046s\n",
            "83\n",
            "Epoch: 0590 loss_train: 0.7846 acc_train: 0.8417 loss_val: 1.0763 acc_val: 0.5980 time: 0.1049s\n",
            "84\n",
            "Epoch: 0591 loss_train: 0.8390 acc_train: 0.8500 loss_val: 1.0819 acc_val: 0.5980 time: 0.1055s\n",
            "85\n",
            "Epoch: 0592 loss_train: 0.8248 acc_train: 0.8000 loss_val: 1.0866 acc_val: 0.5920 time: 0.1043s\n",
            "86\n",
            "Epoch: 0593 loss_train: 0.8113 acc_train: 0.8250 loss_val: 1.0858 acc_val: 0.5900 time: 0.1050s\n",
            "87\n",
            "Epoch: 0594 loss_train: 0.8212 acc_train: 0.8583 loss_val: 1.0848 acc_val: 0.5880 time: 0.1046s\n",
            "88\n",
            "Epoch: 0595 loss_train: 0.8219 acc_train: 0.8083 loss_val: 1.0739 acc_val: 0.5900 time: 0.1051s\n",
            "89\n",
            "Epoch: 0596 loss_train: 0.8506 acc_train: 0.8000 loss_val: 1.0619 acc_val: 0.5960 time: 0.1055s\n",
            "90\n",
            "Epoch: 0597 loss_train: 0.8326 acc_train: 0.8250 loss_val: 1.0538 acc_val: 0.5980 time: 0.1044s\n",
            "91\n",
            "Epoch: 0598 loss_train: 0.8292 acc_train: 0.8250 loss_val: 1.0553 acc_val: 0.6000 time: 0.1049s\n",
            "92\n",
            "Epoch: 0599 loss_train: 0.7954 acc_train: 0.8333 loss_val: 1.0714 acc_val: 0.5940 time: 0.1044s\n",
            "93\n",
            "Epoch: 0600 loss_train: 0.8274 acc_train: 0.8667 loss_val: 1.0950 acc_val: 0.5820 time: 0.1050s\n",
            "94\n",
            "Epoch: 0601 loss_train: 0.8203 acc_train: 0.7750 loss_val: 1.1056 acc_val: 0.5820 time: 0.1048s\n",
            "95\n",
            "Epoch: 0602 loss_train: 0.8182 acc_train: 0.8250 loss_val: 1.0991 acc_val: 0.5900 time: 0.1042s\n",
            "96\n",
            "Epoch: 0603 loss_train: 0.8583 acc_train: 0.8250 loss_val: 1.0837 acc_val: 0.5900 time: 0.1062s\n",
            "97\n",
            "Epoch: 0604 loss_train: 0.8196 acc_train: 0.8083 loss_val: 1.0681 acc_val: 0.5940 time: 0.1038s\n",
            "98\n",
            "Epoch: 0605 loss_train: 0.8028 acc_train: 0.8667 loss_val: 1.0640 acc_val: 0.5960 time: 0.1053s\n",
            "99\n",
            "Epoch: 0606 loss_train: 0.8244 acc_train: 0.8250 loss_val: 1.0644 acc_val: 0.5960 time: 0.1044s\n",
            "100\n",
            "Epoch: 0607 loss_train: 0.8434 acc_train: 0.8000 loss_val: 1.0702 acc_val: 0.5960 time: 0.1047s\n",
            "101\n",
            "Epoch: 0608 loss_train: 0.8072 acc_train: 0.7750 loss_val: 1.0747 acc_val: 0.6000 time: 0.1043s\n",
            "102\n",
            "Epoch: 0609 loss_train: 0.8192 acc_train: 0.8333 loss_val: 1.0840 acc_val: 0.5960 time: 0.1043s\n",
            "103\n",
            "Epoch: 0610 loss_train: 0.8206 acc_train: 0.7833 loss_val: 1.0870 acc_val: 0.5940 time: 0.1046s\n",
            "104\n",
            "Epoch: 0611 loss_train: 0.8628 acc_train: 0.8083 loss_val: 1.0789 acc_val: 0.5960 time: 0.1046s\n",
            "105\n",
            "Epoch: 0612 loss_train: 0.8340 acc_train: 0.8083 loss_val: 1.0728 acc_val: 0.5960 time: 0.1041s\n",
            "106\n",
            "Epoch: 0613 loss_train: 0.8223 acc_train: 0.8500 loss_val: 1.0644 acc_val: 0.5940 time: 0.1044s\n",
            "107\n",
            "Epoch: 0614 loss_train: 0.8242 acc_train: 0.8167 loss_val: 1.0594 acc_val: 0.5920 time: 0.1101s\n",
            "108\n",
            "Epoch: 0615 loss_train: 0.8642 acc_train: 0.7750 loss_val: 1.0605 acc_val: 0.5940 time: 0.1054s\n",
            "109\n",
            "Epoch: 0616 loss_train: 0.8641 acc_train: 0.8167 loss_val: 1.0660 acc_val: 0.5980 time: 0.1051s\n",
            "110\n",
            "Epoch: 0617 loss_train: 0.7750 acc_train: 0.8833 loss_val: 1.0795 acc_val: 0.5980 time: 0.1042s\n",
            "111\n",
            "Epoch: 0618 loss_train: 0.8225 acc_train: 0.8417 loss_val: 1.0921 acc_val: 0.5940 time: 0.1054s\n",
            "112\n",
            "Epoch: 0619 loss_train: 0.8026 acc_train: 0.7833 loss_val: 1.0966 acc_val: 0.5920 time: 0.1050s\n",
            "113\n",
            "Epoch: 0620 loss_train: 0.8118 acc_train: 0.7583 loss_val: 1.0966 acc_val: 0.5880 time: 0.1043s\n",
            "114\n",
            "Epoch: 0621 loss_train: 0.8695 acc_train: 0.7583 loss_val: 1.0853 acc_val: 0.5920 time: 0.1048s\n",
            "115\n",
            "Epoch: 0622 loss_train: 0.8701 acc_train: 0.7833 loss_val: 1.0696 acc_val: 0.5960 time: 0.1039s\n",
            "116\n",
            "Epoch: 0623 loss_train: 0.8116 acc_train: 0.8250 loss_val: 1.0596 acc_val: 0.5940 time: 0.1044s\n",
            "117\n",
            "Epoch: 0624 loss_train: 0.8405 acc_train: 0.8250 loss_val: 1.0565 acc_val: 0.5940 time: 0.1057s\n",
            "118\n",
            "Epoch: 0625 loss_train: 0.7788 acc_train: 0.8333 loss_val: 1.0640 acc_val: 0.5940 time: 0.1045s\n",
            "119\n",
            "Epoch: 0626 loss_train: 0.8114 acc_train: 0.7833 loss_val: 1.0766 acc_val: 0.5960 time: 0.1067s\n",
            "120\n",
            "Epoch: 0627 loss_train: 0.8019 acc_train: 0.8250 loss_val: 1.0905 acc_val: 0.5900 time: 0.1047s\n",
            "121\n",
            "Epoch: 0628 loss_train: 0.8321 acc_train: 0.8000 loss_val: 1.0955 acc_val: 0.5940 time: 0.1043s\n",
            "122\n",
            "Epoch: 0629 loss_train: 0.8407 acc_train: 0.8167 loss_val: 1.0884 acc_val: 0.5940 time: 0.1049s\n",
            "123\n",
            "Epoch: 0630 loss_train: 0.8193 acc_train: 0.7583 loss_val: 1.0762 acc_val: 0.5980 time: 0.1040s\n",
            "124\n",
            "Epoch: 0631 loss_train: 0.7919 acc_train: 0.8167 loss_val: 1.0671 acc_val: 0.5980 time: 0.1044s\n",
            "125\n",
            "Epoch: 0632 loss_train: 0.8834 acc_train: 0.7833 loss_val: 1.0613 acc_val: 0.5960 time: 0.1042s\n",
            "126\n",
            "Epoch: 0633 loss_train: 0.8145 acc_train: 0.7917 loss_val: 1.0578 acc_val: 0.5960 time: 0.1076s\n",
            "127\n",
            "Epoch: 0634 loss_train: 0.7964 acc_train: 0.8250 loss_val: 1.0630 acc_val: 0.5960 time: 0.1044s\n",
            "128\n",
            "Epoch: 0635 loss_train: 0.8749 acc_train: 0.8000 loss_val: 1.0734 acc_val: 0.5960 time: 0.1056s\n",
            "129\n",
            "Epoch: 0636 loss_train: 0.8248 acc_train: 0.7750 loss_val: 1.0811 acc_val: 0.5940 time: 0.1051s\n",
            "130\n",
            "Epoch: 0637 loss_train: 0.8064 acc_train: 0.8250 loss_val: 1.0862 acc_val: 0.5920 time: 0.1049s\n",
            "131\n",
            "Epoch: 0638 loss_train: 0.8239 acc_train: 0.8083 loss_val: 1.0826 acc_val: 0.5920 time: 0.1057s\n",
            "132\n",
            "Epoch: 0639 loss_train: 0.8185 acc_train: 0.8583 loss_val: 1.0777 acc_val: 0.5940 time: 0.1049s\n",
            "133\n",
            "Epoch: 0640 loss_train: 0.8204 acc_train: 0.8333 loss_val: 1.0741 acc_val: 0.5980 time: 0.1044s\n",
            "134\n",
            "Epoch: 0641 loss_train: 0.8057 acc_train: 0.8250 loss_val: 1.0756 acc_val: 0.5960 time: 0.1046s\n",
            "135\n",
            "Epoch: 0642 loss_train: 0.8232 acc_train: 0.8250 loss_val: 1.0829 acc_val: 0.5940 time: 0.1068s\n",
            "136\n",
            "Epoch: 0643 loss_train: 0.8119 acc_train: 0.7917 loss_val: 1.0899 acc_val: 0.5940 time: 0.1059s\n",
            "137\n",
            "Epoch: 0644 loss_train: 0.7845 acc_train: 0.7500 loss_val: 1.0902 acc_val: 0.5940 time: 0.1047s\n",
            "138\n",
            "Epoch: 0645 loss_train: 0.8406 acc_train: 0.8167 loss_val: 1.0827 acc_val: 0.5940 time: 0.1047s\n",
            "139\n",
            "Epoch: 0646 loss_train: 0.8288 acc_train: 0.8083 loss_val: 1.0791 acc_val: 0.5940 time: 0.1042s\n",
            "140\n",
            "Epoch: 0647 loss_train: 0.8024 acc_train: 0.8000 loss_val: 1.0777 acc_val: 0.5940 time: 0.1050s\n",
            "141\n",
            "Epoch: 0648 loss_train: 0.8333 acc_train: 0.8333 loss_val: 1.0782 acc_val: 0.5900 time: 0.1038s\n",
            "142\n",
            "Epoch: 0649 loss_train: 0.8568 acc_train: 0.8417 loss_val: 1.0735 acc_val: 0.5900 time: 0.1045s\n",
            "143\n",
            "Epoch: 0650 loss_train: 0.8440 acc_train: 0.8333 loss_val: 1.0687 acc_val: 0.6000 time: 0.1040s\n",
            "144\n",
            "Epoch: 0651 loss_train: 0.7837 acc_train: 0.8250 loss_val: 1.0706 acc_val: 0.5960 time: 0.1040s\n",
            "145\n",
            "Epoch: 0652 loss_train: 0.8169 acc_train: 0.8500 loss_val: 1.0702 acc_val: 0.5960 time: 0.1052s\n",
            "146\n",
            "Epoch: 0653 loss_train: 0.7875 acc_train: 0.8417 loss_val: 1.0720 acc_val: 0.5940 time: 0.1048s\n",
            "147\n",
            "Epoch: 0654 loss_train: 0.7786 acc_train: 0.8833 loss_val: 1.0797 acc_val: 0.5920 time: 0.1051s\n",
            "148\n",
            "Epoch: 0655 loss_train: 0.8128 acc_train: 0.8583 loss_val: 1.0872 acc_val: 0.5920 time: 0.1058s\n",
            "149\n",
            "Epoch: 0656 loss_train: 0.7965 acc_train: 0.8250 loss_val: 1.1001 acc_val: 0.5920 time: 0.1038s\n",
            "150\n",
            "Epoch: 0657 loss_train: 0.8155 acc_train: 0.8083 loss_val: 1.1022 acc_val: 0.5920 time: 0.1045s\n",
            "151\n",
            "Epoch: 0658 loss_train: 0.8307 acc_train: 0.8083 loss_val: 1.0928 acc_val: 0.5900 time: 0.1049s\n",
            "152\n",
            "Epoch: 0659 loss_train: 0.7478 acc_train: 0.8583 loss_val: 1.0809 acc_val: 0.5980 time: 0.1042s\n",
            "153\n",
            "Epoch: 0660 loss_train: 0.8325 acc_train: 0.7667 loss_val: 1.0675 acc_val: 0.6000 time: 0.1042s\n",
            "154\n",
            "Epoch: 0661 loss_train: 0.8051 acc_train: 0.8417 loss_val: 1.0605 acc_val: 0.5980 time: 0.1049s\n",
            "155\n",
            "Epoch: 0662 loss_train: 0.8222 acc_train: 0.8250 loss_val: 1.0589 acc_val: 0.6020 time: 0.1042s\n",
            "156\n",
            "Epoch: 0663 loss_train: 0.8341 acc_train: 0.8917 loss_val: 1.0672 acc_val: 0.6000 time: 0.1046s\n",
            "157\n",
            "Epoch: 0664 loss_train: 0.8022 acc_train: 0.7583 loss_val: 1.0804 acc_val: 0.5960 time: 0.1050s\n",
            "158\n",
            "Epoch: 0665 loss_train: 0.8386 acc_train: 0.8000 loss_val: 1.0859 acc_val: 0.5940 time: 0.1042s\n",
            "159\n",
            "Epoch: 0666 loss_train: 0.8310 acc_train: 0.8417 loss_val: 1.0897 acc_val: 0.5960 time: 0.1054s\n",
            "160\n",
            "Epoch: 0667 loss_train: 0.8368 acc_train: 0.8500 loss_val: 1.0878 acc_val: 0.5960 time: 0.1053s\n",
            "161\n",
            "Epoch: 0668 loss_train: 0.7828 acc_train: 0.8583 loss_val: 1.0832 acc_val: 0.5920 time: 0.1048s\n",
            "162\n",
            "Epoch: 0669 loss_train: 0.7818 acc_train: 0.8083 loss_val: 1.0718 acc_val: 0.5920 time: 0.1044s\n",
            "163\n",
            "Epoch: 0670 loss_train: 0.7954 acc_train: 0.8167 loss_val: 1.0666 acc_val: 0.5960 time: 0.1060s\n",
            "164\n",
            "Epoch: 0671 loss_train: 0.8072 acc_train: 0.8167 loss_val: 1.0733 acc_val: 0.6000 time: 0.1044s\n",
            "165\n",
            "Epoch: 0672 loss_train: 0.7960 acc_train: 0.8167 loss_val: 1.0829 acc_val: 0.5980 time: 0.1054s\n",
            "166\n",
            "Epoch: 0673 loss_train: 0.7986 acc_train: 0.8000 loss_val: 1.0939 acc_val: 0.5960 time: 0.1040s\n",
            "167\n",
            "Epoch: 0674 loss_train: 0.8018 acc_train: 0.8583 loss_val: 1.1012 acc_val: 0.5940 time: 0.1046s\n",
            "168\n",
            "Epoch: 0675 loss_train: 0.8297 acc_train: 0.8250 loss_val: 1.0969 acc_val: 0.5900 time: 0.1042s\n",
            "169\n",
            "Epoch: 0676 loss_train: 0.8438 acc_train: 0.8083 loss_val: 1.0797 acc_val: 0.5960 time: 0.1042s\n",
            "170\n",
            "Epoch: 0677 loss_train: 0.8365 acc_train: 0.8000 loss_val: 1.0588 acc_val: 0.5920 time: 0.1044s\n",
            "171\n",
            "Epoch: 0678 loss_train: 0.8061 acc_train: 0.8250 loss_val: 1.0467 acc_val: 0.5980 time: 0.1043s\n",
            "172\n",
            "Epoch: 0679 loss_train: 0.8175 acc_train: 0.8750 loss_val: 1.0480 acc_val: 0.5980 time: 0.1036s\n",
            "0\n",
            "Epoch: 0680 loss_train: 0.8290 acc_train: 0.8833 loss_val: 1.0612 acc_val: 0.5980 time: 0.1054s\n",
            "1\n",
            "Epoch: 0681 loss_train: 0.8145 acc_train: 0.8667 loss_val: 1.0823 acc_val: 0.5980 time: 0.1052s\n",
            "2\n",
            "Epoch: 0682 loss_train: 0.8140 acc_train: 0.8167 loss_val: 1.0932 acc_val: 0.5880 time: 0.1042s\n",
            "3\n",
            "Epoch: 0683 loss_train: 0.8339 acc_train: 0.8000 loss_val: 1.0880 acc_val: 0.5960 time: 0.1045s\n",
            "4\n",
            "Epoch: 0684 loss_train: 0.8431 acc_train: 0.8000 loss_val: 1.0819 acc_val: 0.5960 time: 0.1050s\n",
            "5\n",
            "Epoch: 0685 loss_train: 0.8508 acc_train: 0.8250 loss_val: 1.0797 acc_val: 0.5960 time: 0.1062s\n",
            "6\n",
            "Epoch: 0686 loss_train: 0.8031 acc_train: 0.8667 loss_val: 1.0774 acc_val: 0.5980 time: 0.1042s\n",
            "7\n",
            "Epoch: 0687 loss_train: 0.8209 acc_train: 0.8250 loss_val: 1.0784 acc_val: 0.5920 time: 0.1038s\n",
            "8\n",
            "Epoch: 0688 loss_train: 0.8013 acc_train: 0.8583 loss_val: 1.0792 acc_val: 0.5900 time: 0.1048s\n",
            "9\n",
            "Epoch: 0689 loss_train: 0.8064 acc_train: 0.7833 loss_val: 1.0768 acc_val: 0.5900 time: 0.1043s\n",
            "10\n",
            "Epoch: 0690 loss_train: 0.8064 acc_train: 0.8333 loss_val: 1.0673 acc_val: 0.5980 time: 0.1052s\n",
            "11\n",
            "Epoch: 0691 loss_train: 0.7921 acc_train: 0.8333 loss_val: 1.0647 acc_val: 0.5960 time: 0.1048s\n",
            "12\n",
            "Epoch: 0692 loss_train: 0.7990 acc_train: 0.8333 loss_val: 1.0670 acc_val: 0.6000 time: 0.1052s\n",
            "13\n",
            "Epoch: 0693 loss_train: 0.8380 acc_train: 0.8667 loss_val: 1.0723 acc_val: 0.5980 time: 0.1044s\n",
            "14\n",
            "Epoch: 0694 loss_train: 0.8084 acc_train: 0.8417 loss_val: 1.0819 acc_val: 0.5940 time: 0.1048s\n",
            "15\n",
            "Epoch: 0695 loss_train: 0.8076 acc_train: 0.8167 loss_val: 1.0923 acc_val: 0.5940 time: 0.1050s\n",
            "16\n",
            "Epoch: 0696 loss_train: 0.8351 acc_train: 0.8333 loss_val: 1.0996 acc_val: 0.5900 time: 0.1049s\n",
            "17\n",
            "Epoch: 0697 loss_train: 0.7994 acc_train: 0.8167 loss_val: 1.0993 acc_val: 0.5880 time: 0.1064s\n",
            "18\n",
            "Epoch: 0698 loss_train: 0.8497 acc_train: 0.8250 loss_val: 1.0832 acc_val: 0.5920 time: 0.1052s\n",
            "19\n",
            "Epoch: 0699 loss_train: 0.7939 acc_train: 0.8833 loss_val: 1.0681 acc_val: 0.5960 time: 0.1049s\n",
            "20\n",
            "Epoch: 0700 loss_train: 0.8096 acc_train: 0.8583 loss_val: 1.0553 acc_val: 0.5960 time: 0.1059s\n",
            "21\n",
            "Epoch: 0701 loss_train: 0.8173 acc_train: 0.8417 loss_val: 1.0511 acc_val: 0.5980 time: 0.1053s\n",
            "22\n",
            "Epoch: 0702 loss_train: 0.8341 acc_train: 0.8417 loss_val: 1.0596 acc_val: 0.5980 time: 0.1044s\n",
            "23\n",
            "Epoch: 0703 loss_train: 0.8334 acc_train: 0.8250 loss_val: 1.0790 acc_val: 0.5940 time: 0.1059s\n",
            "24\n",
            "Epoch: 0704 loss_train: 0.7805 acc_train: 0.8667 loss_val: 1.0960 acc_val: 0.5900 time: 0.1051s\n",
            "25\n",
            "Epoch: 0705 loss_train: 0.8358 acc_train: 0.8333 loss_val: 1.1059 acc_val: 0.5920 time: 0.1064s\n",
            "26\n",
            "Epoch: 0706 loss_train: 0.7921 acc_train: 0.8333 loss_val: 1.1099 acc_val: 0.5920 time: 0.1045s\n",
            "27\n",
            "Epoch: 0707 loss_train: 0.8364 acc_train: 0.7333 loss_val: 1.1040 acc_val: 0.5920 time: 0.1037s\n",
            "28\n",
            "Epoch: 0708 loss_train: 0.8012 acc_train: 0.8000 loss_val: 1.0873 acc_val: 0.5960 time: 0.1051s\n",
            "29\n",
            "Epoch: 0709 loss_train: 0.7589 acc_train: 0.8000 loss_val: 1.0694 acc_val: 0.5940 time: 0.1047s\n",
            "30\n",
            "Epoch: 0710 loss_train: 0.8125 acc_train: 0.8667 loss_val: 1.0567 acc_val: 0.6040 time: 0.1045s\n",
            "31\n",
            "Epoch: 0711 loss_train: 0.7828 acc_train: 0.8917 loss_val: 1.0581 acc_val: 0.6040 time: 0.1043s\n",
            "0\n",
            "Epoch: 0712 loss_train: 0.8065 acc_train: 0.8083 loss_val: 1.0753 acc_val: 0.6000 time: 0.1053s\n",
            "0\n",
            "Epoch: 0713 loss_train: 0.8047 acc_train: 0.7833 loss_val: 1.0964 acc_val: 0.5980 time: 0.1043s\n",
            "1\n",
            "Epoch: 0714 loss_train: 0.7936 acc_train: 0.8333 loss_val: 1.1060 acc_val: 0.5940 time: 0.1052s\n",
            "2\n",
            "Epoch: 0715 loss_train: 0.8142 acc_train: 0.8000 loss_val: 1.0986 acc_val: 0.5940 time: 0.1053s\n",
            "3\n",
            "Epoch: 0716 loss_train: 0.8279 acc_train: 0.7917 loss_val: 1.0787 acc_val: 0.5980 time: 0.1047s\n",
            "4\n",
            "Epoch: 0717 loss_train: 0.8040 acc_train: 0.8500 loss_val: 1.0664 acc_val: 0.6000 time: 0.1044s\n",
            "5\n",
            "Epoch: 0718 loss_train: 0.8535 acc_train: 0.8000 loss_val: 1.0686 acc_val: 0.5980 time: 0.1054s\n",
            "6\n",
            "Epoch: 0719 loss_train: 0.7186 acc_train: 0.8833 loss_val: 1.0778 acc_val: 0.5900 time: 0.1058s\n",
            "7\n",
            "Epoch: 0720 loss_train: 0.8119 acc_train: 0.7833 loss_val: 1.0904 acc_val: 0.5900 time: 0.1045s\n",
            "8\n",
            "Epoch: 0721 loss_train: 0.8473 acc_train: 0.7917 loss_val: 1.0926 acc_val: 0.5900 time: 0.1047s\n",
            "9\n",
            "Epoch: 0722 loss_train: 0.8264 acc_train: 0.8333 loss_val: 1.0837 acc_val: 0.6000 time: 0.1047s\n",
            "10\n",
            "Epoch: 0723 loss_train: 0.8391 acc_train: 0.7667 loss_val: 1.0696 acc_val: 0.6000 time: 0.1040s\n",
            "11\n",
            "Epoch: 0724 loss_train: 0.8011 acc_train: 0.8417 loss_val: 1.0662 acc_val: 0.6000 time: 0.1048s\n",
            "12\n",
            "Epoch: 0725 loss_train: 0.7880 acc_train: 0.8333 loss_val: 1.0732 acc_val: 0.5960 time: 0.1039s\n",
            "13\n",
            "Epoch: 0726 loss_train: 0.7793 acc_train: 0.8583 loss_val: 1.0869 acc_val: 0.5900 time: 0.1044s\n",
            "14\n",
            "Epoch: 0727 loss_train: 0.8147 acc_train: 0.8250 loss_val: 1.0903 acc_val: 0.5860 time: 0.1041s\n",
            "15\n",
            "Epoch: 0728 loss_train: 0.8202 acc_train: 0.8250 loss_val: 1.0839 acc_val: 0.5940 time: 0.1055s\n",
            "16\n",
            "Epoch: 0729 loss_train: 0.8204 acc_train: 0.7917 loss_val: 1.0758 acc_val: 0.5980 time: 0.1058s\n",
            "17\n",
            "Epoch: 0730 loss_train: 0.8159 acc_train: 0.8250 loss_val: 1.0696 acc_val: 0.6020 time: 0.1057s\n",
            "18\n",
            "Epoch: 0731 loss_train: 0.8329 acc_train: 0.8333 loss_val: 1.0698 acc_val: 0.6000 time: 0.1073s\n",
            "19\n",
            "Epoch: 0732 loss_train: 0.7616 acc_train: 0.8750 loss_val: 1.0743 acc_val: 0.5980 time: 0.1041s\n",
            "20\n",
            "Epoch: 0733 loss_train: 0.7904 acc_train: 0.8083 loss_val: 1.0806 acc_val: 0.5980 time: 0.1048s\n",
            "21\n",
            "Epoch: 0734 loss_train: 0.8636 acc_train: 0.8583 loss_val: 1.0822 acc_val: 0.5920 time: 0.1053s\n",
            "22\n",
            "Epoch: 0735 loss_train: 0.8066 acc_train: 0.8167 loss_val: 1.0799 acc_val: 0.5920 time: 0.1041s\n",
            "23\n",
            "Epoch: 0736 loss_train: 0.8391 acc_train: 0.8167 loss_val: 1.0731 acc_val: 0.5920 time: 0.1043s\n",
            "24\n",
            "Epoch: 0737 loss_train: 0.8023 acc_train: 0.8167 loss_val: 1.0717 acc_val: 0.5940 time: 0.1047s\n",
            "25\n",
            "Epoch: 0738 loss_train: 0.8662 acc_train: 0.7750 loss_val: 1.0709 acc_val: 0.5940 time: 0.1064s\n",
            "26\n",
            "Epoch: 0739 loss_train: 0.7860 acc_train: 0.8583 loss_val: 1.0705 acc_val: 0.5920 time: 0.1036s\n",
            "27\n",
            "Epoch: 0740 loss_train: 0.8539 acc_train: 0.8583 loss_val: 1.0681 acc_val: 0.5960 time: 0.1056s\n",
            "28\n",
            "Epoch: 0741 loss_train: 0.7993 acc_train: 0.8250 loss_val: 1.0644 acc_val: 0.5980 time: 0.1041s\n",
            "29\n",
            "Epoch: 0742 loss_train: 0.8331 acc_train: 0.8083 loss_val: 1.0638 acc_val: 0.5940 time: 0.1060s\n",
            "30\n",
            "Epoch: 0743 loss_train: 0.7911 acc_train: 0.8083 loss_val: 1.0714 acc_val: 0.5900 time: 0.1040s\n",
            "31\n",
            "Epoch: 0744 loss_train: 0.7712 acc_train: 0.8583 loss_val: 1.0774 acc_val: 0.5860 time: 0.1050s\n",
            "32\n",
            "Epoch: 0745 loss_train: 0.8031 acc_train: 0.8583 loss_val: 1.0780 acc_val: 0.5860 time: 0.1068s\n",
            "33\n",
            "Epoch: 0746 loss_train: 0.8136 acc_train: 0.7833 loss_val: 1.0753 acc_val: 0.5920 time: 0.1047s\n",
            "34\n",
            "Epoch: 0747 loss_train: 0.8436 acc_train: 0.7500 loss_val: 1.0679 acc_val: 0.5920 time: 0.1043s\n",
            "35\n",
            "Epoch: 0748 loss_train: 0.7856 acc_train: 0.8333 loss_val: 1.0630 acc_val: 0.6000 time: 0.1055s\n",
            "36\n",
            "Epoch: 0749 loss_train: 0.8237 acc_train: 0.8250 loss_val: 1.0660 acc_val: 0.6020 time: 0.1048s\n",
            "37\n",
            "Epoch: 0750 loss_train: 0.8145 acc_train: 0.8083 loss_val: 1.0764 acc_val: 0.6000 time: 0.1046s\n",
            "38\n",
            "Epoch: 0751 loss_train: 0.8232 acc_train: 0.8083 loss_val: 1.0837 acc_val: 0.5980 time: 0.1043s\n",
            "39\n",
            "Epoch: 0752 loss_train: 0.8222 acc_train: 0.7917 loss_val: 1.0872 acc_val: 0.5860 time: 0.1043s\n",
            "40\n",
            "Epoch: 0753 loss_train: 0.7844 acc_train: 0.8500 loss_val: 1.0856 acc_val: 0.5820 time: 0.1050s\n",
            "41\n",
            "Epoch: 0754 loss_train: 0.7888 acc_train: 0.8500 loss_val: 1.0783 acc_val: 0.5880 time: 0.1049s\n",
            "42\n",
            "Epoch: 0755 loss_train: 0.7883 acc_train: 0.8750 loss_val: 1.0666 acc_val: 0.5940 time: 0.1056s\n",
            "43\n",
            "Epoch: 0756 loss_train: 0.7755 acc_train: 0.8667 loss_val: 1.0632 acc_val: 0.5940 time: 0.1049s\n",
            "44\n",
            "Epoch: 0757 loss_train: 0.7755 acc_train: 0.8500 loss_val: 1.0632 acc_val: 0.5980 time: 0.1049s\n",
            "45\n",
            "Epoch: 0758 loss_train: 0.7697 acc_train: 0.8500 loss_val: 1.0715 acc_val: 0.5980 time: 0.1041s\n",
            "46\n",
            "Epoch: 0759 loss_train: 0.8285 acc_train: 0.7917 loss_val: 1.0777 acc_val: 0.6000 time: 0.1046s\n",
            "47\n",
            "Epoch: 0760 loss_train: 0.8099 acc_train: 0.8167 loss_val: 1.0808 acc_val: 0.6000 time: 0.1045s\n",
            "48\n",
            "Epoch: 0761 loss_train: 0.8010 acc_train: 0.8417 loss_val: 1.0798 acc_val: 0.5980 time: 0.1042s\n",
            "49\n",
            "Epoch: 0762 loss_train: 0.7745 acc_train: 0.8667 loss_val: 1.0729 acc_val: 0.6000 time: 0.1044s\n",
            "50\n",
            "Epoch: 0763 loss_train: 0.8024 acc_train: 0.8417 loss_val: 1.0685 acc_val: 0.5960 time: 0.1044s\n",
            "51\n",
            "Epoch: 0764 loss_train: 0.8091 acc_train: 0.8750 loss_val: 1.0654 acc_val: 0.5960 time: 0.1044s\n",
            "52\n",
            "Epoch: 0765 loss_train: 0.8286 acc_train: 0.8000 loss_val: 1.0700 acc_val: 0.5940 time: 0.1063s\n",
            "53\n",
            "Epoch: 0766 loss_train: 0.8170 acc_train: 0.8417 loss_val: 1.0767 acc_val: 0.5980 time: 0.1056s\n",
            "54\n",
            "Epoch: 0767 loss_train: 0.8291 acc_train: 0.8167 loss_val: 1.0840 acc_val: 0.5960 time: 0.1050s\n",
            "55\n",
            "Epoch: 0768 loss_train: 0.7737 acc_train: 0.8250 loss_val: 1.0860 acc_val: 0.5960 time: 0.1051s\n",
            "56\n",
            "Epoch: 0769 loss_train: 0.8253 acc_train: 0.8083 loss_val: 1.0821 acc_val: 0.5940 time: 0.1045s\n",
            "57\n",
            "Epoch: 0770 loss_train: 0.7945 acc_train: 0.7917 loss_val: 1.0766 acc_val: 0.5940 time: 0.1052s\n",
            "58\n",
            "Epoch: 0771 loss_train: 0.8153 acc_train: 0.8417 loss_val: 1.0688 acc_val: 0.5940 time: 0.1038s\n",
            "59\n",
            "Epoch: 0772 loss_train: 0.8403 acc_train: 0.7750 loss_val: 1.0610 acc_val: 0.5960 time: 0.1045s\n",
            "60\n",
            "Epoch: 0773 loss_train: 0.7742 acc_train: 0.8583 loss_val: 1.0676 acc_val: 0.5920 time: 0.1040s\n",
            "61\n",
            "Epoch: 0774 loss_train: 0.8116 acc_train: 0.8417 loss_val: 1.0753 acc_val: 0.5900 time: 0.1047s\n",
            "62\n",
            "Epoch: 0775 loss_train: 0.7656 acc_train: 0.8333 loss_val: 1.0824 acc_val: 0.5900 time: 0.1039s\n",
            "63\n",
            "Epoch: 0776 loss_train: 0.8040 acc_train: 0.8917 loss_val: 1.0857 acc_val: 0.5940 time: 0.1044s\n",
            "64\n",
            "Epoch: 0777 loss_train: 0.7902 acc_train: 0.8417 loss_val: 1.0912 acc_val: 0.5920 time: 0.1066s\n",
            "65\n",
            "Epoch: 0778 loss_train: 0.8076 acc_train: 0.8500 loss_val: 1.0908 acc_val: 0.5920 time: 0.1049s\n",
            "66\n",
            "Epoch: 0779 loss_train: 0.8070 acc_train: 0.8333 loss_val: 1.0842 acc_val: 0.6020 time: 0.1043s\n",
            "67\n",
            "Epoch: 0780 loss_train: 0.8472 acc_train: 0.7917 loss_val: 1.0738 acc_val: 0.6040 time: 0.1047s\n",
            "68\n",
            "Epoch: 0781 loss_train: 0.8003 acc_train: 0.8333 loss_val: 1.0692 acc_val: 0.6040 time: 0.1038s\n",
            "0\n",
            "Epoch: 0782 loss_train: 0.8572 acc_train: 0.8667 loss_val: 1.0667 acc_val: 0.5980 time: 0.1042s\n",
            "0\n",
            "Epoch: 0783 loss_train: 0.8274 acc_train: 0.8250 loss_val: 1.0691 acc_val: 0.5960 time: 0.1040s\n",
            "1\n",
            "Epoch: 0784 loss_train: 0.7947 acc_train: 0.8750 loss_val: 1.0809 acc_val: 0.5940 time: 0.1063s\n",
            "2\n",
            "Epoch: 0785 loss_train: 0.7788 acc_train: 0.7917 loss_val: 1.0901 acc_val: 0.5900 time: 0.1039s\n",
            "3\n",
            "Epoch: 0786 loss_train: 0.8048 acc_train: 0.8500 loss_val: 1.0921 acc_val: 0.5900 time: 0.1049s\n",
            "4\n",
            "Epoch: 0787 loss_train: 0.7855 acc_train: 0.8583 loss_val: 1.0884 acc_val: 0.5920 time: 0.1053s\n",
            "5\n",
            "Epoch: 0788 loss_train: 0.8387 acc_train: 0.8333 loss_val: 1.0841 acc_val: 0.5920 time: 0.1049s\n",
            "6\n",
            "Epoch: 0789 loss_train: 0.8326 acc_train: 0.7583 loss_val: 1.0754 acc_val: 0.6000 time: 0.1040s\n",
            "7\n",
            "Epoch: 0790 loss_train: 0.8003 acc_train: 0.7917 loss_val: 1.0677 acc_val: 0.6040 time: 0.1044s\n",
            "8\n",
            "Epoch: 0791 loss_train: 0.8013 acc_train: 0.8250 loss_val: 1.0653 acc_val: 0.6040 time: 0.1037s\n",
            "0\n",
            "Epoch: 0792 loss_train: 0.8252 acc_train: 0.8417 loss_val: 1.0699 acc_val: 0.6020 time: 0.1048s\n",
            "0\n",
            "Epoch: 0793 loss_train: 0.8194 acc_train: 0.8667 loss_val: 1.0742 acc_val: 0.6020 time: 0.1049s\n",
            "1\n",
            "Epoch: 0794 loss_train: 0.7676 acc_train: 0.8000 loss_val: 1.0818 acc_val: 0.6000 time: 0.1053s\n",
            "2\n",
            "Epoch: 0795 loss_train: 0.7918 acc_train: 0.8333 loss_val: 1.0871 acc_val: 0.5960 time: 0.1038s\n",
            "3\n",
            "Epoch: 0796 loss_train: 0.7803 acc_train: 0.8000 loss_val: 1.0890 acc_val: 0.6000 time: 0.1045s\n",
            "4\n",
            "Epoch: 0797 loss_train: 0.7894 acc_train: 0.8000 loss_val: 1.0828 acc_val: 0.6020 time: 0.1052s\n",
            "5\n",
            "Epoch: 0798 loss_train: 0.8024 acc_train: 0.8333 loss_val: 1.0769 acc_val: 0.6040 time: 0.1048s\n",
            "6\n",
            "Epoch: 0799 loss_train: 0.8189 acc_train: 0.7917 loss_val: 1.0721 acc_val: 0.6040 time: 0.1051s\n",
            "0\n",
            "Epoch: 0800 loss_train: 0.8786 acc_train: 0.8083 loss_val: 1.0673 acc_val: 0.6040 time: 0.1046s\n",
            "0\n",
            "Epoch: 0801 loss_train: 0.8009 acc_train: 0.7583 loss_val: 1.0653 acc_val: 0.6040 time: 0.1040s\n",
            "0\n",
            "Epoch: 0802 loss_train: 0.8235 acc_train: 0.7750 loss_val: 1.0666 acc_val: 0.6000 time: 0.1047s\n",
            "0\n",
            "Epoch: 0803 loss_train: 0.7934 acc_train: 0.8250 loss_val: 1.0739 acc_val: 0.6000 time: 0.1048s\n",
            "1\n",
            "Epoch: 0804 loss_train: 0.8140 acc_train: 0.7917 loss_val: 1.0804 acc_val: 0.5940 time: 0.1044s\n",
            "2\n",
            "Epoch: 0805 loss_train: 0.8111 acc_train: 0.8500 loss_val: 1.0813 acc_val: 0.5980 time: 0.1041s\n",
            "3\n",
            "Epoch: 0806 loss_train: 0.7668 acc_train: 0.8083 loss_val: 1.0803 acc_val: 0.5980 time: 0.1045s\n",
            "4\n",
            "Epoch: 0807 loss_train: 0.8451 acc_train: 0.8500 loss_val: 1.0796 acc_val: 0.5980 time: 0.1039s\n",
            "5\n",
            "Epoch: 0808 loss_train: 0.8271 acc_train: 0.8417 loss_val: 1.0783 acc_val: 0.6000 time: 0.1052s\n",
            "6\n",
            "Epoch: 0809 loss_train: 0.7640 acc_train: 0.8667 loss_val: 1.0768 acc_val: 0.6000 time: 0.1065s\n",
            "7\n",
            "Epoch: 0810 loss_train: 0.8317 acc_train: 0.8667 loss_val: 1.0760 acc_val: 0.5980 time: 0.1054s\n",
            "8\n",
            "Epoch: 0811 loss_train: 0.7817 acc_train: 0.7833 loss_val: 1.0734 acc_val: 0.5980 time: 0.1040s\n",
            "9\n",
            "Epoch: 0812 loss_train: 0.7711 acc_train: 0.8583 loss_val: 1.0744 acc_val: 0.5980 time: 0.1051s\n",
            "10\n",
            "Epoch: 0813 loss_train: 0.7723 acc_train: 0.8417 loss_val: 1.0769 acc_val: 0.5940 time: 0.1050s\n",
            "11\n",
            "Epoch: 0814 loss_train: 0.7937 acc_train: 0.8250 loss_val: 1.0801 acc_val: 0.5960 time: 0.1048s\n",
            "12\n",
            "Epoch: 0815 loss_train: 0.8186 acc_train: 0.7917 loss_val: 1.0777 acc_val: 0.5940 time: 0.1043s\n",
            "13\n",
            "Epoch: 0816 loss_train: 0.7699 acc_train: 0.8333 loss_val: 1.0725 acc_val: 0.5960 time: 0.1048s\n",
            "14\n",
            "Epoch: 0817 loss_train: 0.8310 acc_train: 0.8500 loss_val: 1.0686 acc_val: 0.5940 time: 0.1041s\n",
            "15\n",
            "Epoch: 0818 loss_train: 0.8336 acc_train: 0.7917 loss_val: 1.0650 acc_val: 0.5980 time: 0.1048s\n",
            "16\n",
            "Epoch: 0819 loss_train: 0.7698 acc_train: 0.8000 loss_val: 1.0657 acc_val: 0.5980 time: 0.1052s\n",
            "17\n",
            "Epoch: 0820 loss_train: 0.7964 acc_train: 0.8083 loss_val: 1.0675 acc_val: 0.5960 time: 0.1045s\n",
            "18\n",
            "Epoch: 0821 loss_train: 0.7980 acc_train: 0.8833 loss_val: 1.0727 acc_val: 0.5940 time: 0.1059s\n",
            "19\n",
            "Epoch: 0822 loss_train: 0.8110 acc_train: 0.8083 loss_val: 1.0809 acc_val: 0.5940 time: 0.1058s\n",
            "20\n",
            "Epoch: 0823 loss_train: 0.8262 acc_train: 0.8417 loss_val: 1.0918 acc_val: 0.5920 time: 0.1057s\n",
            "21\n",
            "Epoch: 0824 loss_train: 0.7942 acc_train: 0.8083 loss_val: 1.1009 acc_val: 0.5900 time: 0.1049s\n",
            "22\n",
            "Epoch: 0825 loss_train: 0.8177 acc_train: 0.8000 loss_val: 1.1037 acc_val: 0.5900 time: 0.1041s\n",
            "23\n",
            "Epoch: 0826 loss_train: 0.7839 acc_train: 0.8083 loss_val: 1.0962 acc_val: 0.5920 time: 0.1055s\n",
            "24\n",
            "Epoch: 0827 loss_train: 0.7886 acc_train: 0.8417 loss_val: 1.0840 acc_val: 0.5960 time: 0.1067s\n",
            "25\n",
            "Epoch: 0828 loss_train: 0.8225 acc_train: 0.8083 loss_val: 1.0742 acc_val: 0.5980 time: 0.1075s\n",
            "26\n",
            "Epoch: 0829 loss_train: 0.7894 acc_train: 0.8583 loss_val: 1.0674 acc_val: 0.5980 time: 0.1058s\n",
            "27\n",
            "Epoch: 0830 loss_train: 0.8008 acc_train: 0.8667 loss_val: 1.0645 acc_val: 0.5980 time: 0.1045s\n",
            "28\n",
            "Epoch: 0831 loss_train: 0.7904 acc_train: 0.8500 loss_val: 1.0651 acc_val: 0.5980 time: 0.1047s\n",
            "29\n",
            "Epoch: 0832 loss_train: 0.8033 acc_train: 0.8083 loss_val: 1.0715 acc_val: 0.5960 time: 0.1056s\n",
            "30\n",
            "Epoch: 0833 loss_train: 0.8176 acc_train: 0.8500 loss_val: 1.0790 acc_val: 0.5960 time: 0.1042s\n",
            "31\n",
            "Epoch: 0834 loss_train: 0.7912 acc_train: 0.8917 loss_val: 1.0874 acc_val: 0.5880 time: 0.1045s\n",
            "32\n",
            "Epoch: 0835 loss_train: 0.7872 acc_train: 0.7833 loss_val: 1.0887 acc_val: 0.5920 time: 0.1038s\n",
            "33\n",
            "Epoch: 0836 loss_train: 0.8059 acc_train: 0.8000 loss_val: 1.0849 acc_val: 0.5920 time: 0.1046s\n",
            "34\n",
            "Epoch: 0837 loss_train: 0.8169 acc_train: 0.8500 loss_val: 1.0734 acc_val: 0.6000 time: 0.1045s\n",
            "35\n",
            "Epoch: 0838 loss_train: 0.7858 acc_train: 0.8083 loss_val: 1.0661 acc_val: 0.6040 time: 0.1042s\n",
            "36\n",
            "Epoch: 0839 loss_train: 0.8147 acc_train: 0.8083 loss_val: 1.0589 acc_val: 0.6040 time: 0.1074s\n",
            "0\n",
            "Epoch: 0840 loss_train: 0.7716 acc_train: 0.8417 loss_val: 1.0632 acc_val: 0.6040 time: 0.1047s\n",
            "0\n",
            "Epoch: 0841 loss_train: 0.7687 acc_train: 0.8333 loss_val: 1.0786 acc_val: 0.5960 time: 0.1041s\n",
            "0\n",
            "Epoch: 0842 loss_train: 0.8146 acc_train: 0.8000 loss_val: 1.0929 acc_val: 0.5860 time: 0.1066s\n",
            "1\n",
            "Epoch: 0843 loss_train: 0.8394 acc_train: 0.8083 loss_val: 1.0958 acc_val: 0.5860 time: 0.1043s\n",
            "2\n",
            "Epoch: 0844 loss_train: 0.8107 acc_train: 0.7667 loss_val: 1.0914 acc_val: 0.5940 time: 0.1047s\n",
            "3\n",
            "Epoch: 0845 loss_train: 0.7893 acc_train: 0.8417 loss_val: 1.0837 acc_val: 0.6000 time: 0.1051s\n",
            "4\n",
            "Epoch: 0846 loss_train: 0.7665 acc_train: 0.8500 loss_val: 1.0738 acc_val: 0.6040 time: 0.1050s\n",
            "5\n",
            "Epoch: 0847 loss_train: 0.8184 acc_train: 0.8667 loss_val: 1.0655 acc_val: 0.6020 time: 0.1040s\n",
            "0\n",
            "Epoch: 0848 loss_train: 0.8155 acc_train: 0.8833 loss_val: 1.0698 acc_val: 0.6000 time: 0.1048s\n",
            "1\n",
            "Epoch: 0849 loss_train: 0.7929 acc_train: 0.8500 loss_val: 1.0751 acc_val: 0.5980 time: 0.1059s\n",
            "2\n",
            "Epoch: 0850 loss_train: 0.8028 acc_train: 0.8333 loss_val: 1.0809 acc_val: 0.5960 time: 0.1060s\n",
            "3\n",
            "Epoch: 0851 loss_train: 0.8228 acc_train: 0.8750 loss_val: 1.0891 acc_val: 0.5900 time: 0.1051s\n",
            "4\n",
            "Epoch: 0852 loss_train: 0.7984 acc_train: 0.7583 loss_val: 1.0894 acc_val: 0.5920 time: 0.1054s\n",
            "5\n",
            "Epoch: 0853 loss_train: 0.8035 acc_train: 0.8417 loss_val: 1.0783 acc_val: 0.5940 time: 0.1056s\n",
            "6\n",
            "Epoch: 0854 loss_train: 0.7460 acc_train: 0.8750 loss_val: 1.0696 acc_val: 0.5960 time: 0.1051s\n",
            "7\n",
            "Epoch: 0855 loss_train: 0.7844 acc_train: 0.8417 loss_val: 1.0622 acc_val: 0.5960 time: 0.1044s\n",
            "8\n",
            "Epoch: 0856 loss_train: 0.7972 acc_train: 0.8750 loss_val: 1.0656 acc_val: 0.5980 time: 0.1044s\n",
            "9\n",
            "Epoch: 0857 loss_train: 0.8049 acc_train: 0.8750 loss_val: 1.0747 acc_val: 0.5940 time: 0.1044s\n",
            "10\n",
            "Epoch: 0858 loss_train: 0.7865 acc_train: 0.8500 loss_val: 1.0828 acc_val: 0.5940 time: 0.1042s\n",
            "11\n",
            "Epoch: 0859 loss_train: 0.7877 acc_train: 0.8083 loss_val: 1.0864 acc_val: 0.5900 time: 0.1040s\n",
            "12\n",
            "Epoch: 0860 loss_train: 0.7903 acc_train: 0.8167 loss_val: 1.0879 acc_val: 0.5900 time: 0.1050s\n",
            "13\n",
            "Epoch: 0861 loss_train: 0.8092 acc_train: 0.8167 loss_val: 1.0821 acc_val: 0.5920 time: 0.1042s\n",
            "14\n",
            "Epoch: 0862 loss_train: 0.8012 acc_train: 0.8083 loss_val: 1.0722 acc_val: 0.5920 time: 0.1051s\n",
            "15\n",
            "Epoch: 0863 loss_train: 0.7465 acc_train: 0.8417 loss_val: 1.0710 acc_val: 0.5940 time: 0.1073s\n",
            "16\n",
            "Epoch: 0864 loss_train: 0.7473 acc_train: 0.9083 loss_val: 1.0773 acc_val: 0.5940 time: 0.1046s\n",
            "17\n",
            "Epoch: 0865 loss_train: 0.8087 acc_train: 0.8250 loss_val: 1.0836 acc_val: 0.5960 time: 0.1036s\n",
            "18\n",
            "Epoch: 0866 loss_train: 0.7969 acc_train: 0.8583 loss_val: 1.0921 acc_val: 0.5920 time: 0.1042s\n",
            "19\n",
            "Epoch: 0867 loss_train: 0.8322 acc_train: 0.8750 loss_val: 1.0929 acc_val: 0.5900 time: 0.1037s\n",
            "20\n",
            "Epoch: 0868 loss_train: 0.8188 acc_train: 0.8333 loss_val: 1.0816 acc_val: 0.5920 time: 0.1045s\n",
            "21\n",
            "Epoch: 0869 loss_train: 0.8194 acc_train: 0.7667 loss_val: 1.0701 acc_val: 0.5940 time: 0.1059s\n",
            "22\n",
            "Epoch: 0870 loss_train: 0.8157 acc_train: 0.8333 loss_val: 1.0695 acc_val: 0.5940 time: 0.1042s\n",
            "23\n",
            "Epoch: 0871 loss_train: 0.7721 acc_train: 0.8500 loss_val: 1.0721 acc_val: 0.5940 time: 0.1041s\n",
            "24\n",
            "Epoch: 0872 loss_train: 0.8161 acc_train: 0.8750 loss_val: 1.0767 acc_val: 0.5960 time: 0.1045s\n",
            "25\n",
            "Epoch: 0873 loss_train: 0.7843 acc_train: 0.8167 loss_val: 1.0806 acc_val: 0.5980 time: 0.1053s\n",
            "26\n",
            "Epoch: 0874 loss_train: 0.7992 acc_train: 0.8167 loss_val: 1.0856 acc_val: 0.6020 time: 0.1046s\n",
            "27\n",
            "Epoch: 0875 loss_train: 0.8493 acc_train: 0.8083 loss_val: 1.0862 acc_val: 0.6020 time: 0.1041s\n",
            "28\n",
            "Epoch: 0876 loss_train: 0.8272 acc_train: 0.7917 loss_val: 1.0847 acc_val: 0.5980 time: 0.1044s\n",
            "29\n",
            "Epoch: 0877 loss_train: 0.8764 acc_train: 0.8000 loss_val: 1.0840 acc_val: 0.5920 time: 0.1044s\n",
            "30\n",
            "Epoch: 0878 loss_train: 0.8228 acc_train: 0.8583 loss_val: 1.0772 acc_val: 0.5900 time: 0.1044s\n",
            "31\n",
            "Epoch: 0879 loss_train: 0.8015 acc_train: 0.8250 loss_val: 1.0727 acc_val: 0.5980 time: 0.1049s\n",
            "32\n",
            "Epoch: 0880 loss_train: 0.8445 acc_train: 0.7917 loss_val: 1.0707 acc_val: 0.5980 time: 0.1050s\n",
            "33\n",
            "Epoch: 0881 loss_train: 0.7798 acc_train: 0.8417 loss_val: 1.0731 acc_val: 0.5980 time: 0.1088s\n",
            "34\n",
            "Epoch: 0882 loss_train: 0.7636 acc_train: 0.8250 loss_val: 1.0755 acc_val: 0.6040 time: 0.1047s\n",
            "35\n",
            "Epoch: 0883 loss_train: 0.7703 acc_train: 0.8083 loss_val: 1.0800 acc_val: 0.6060 time: 0.1040s\n",
            "0\n",
            "Epoch: 0884 loss_train: 0.7637 acc_train: 0.8583 loss_val: 1.0864 acc_val: 0.6040 time: 0.1043s\n",
            "0\n",
            "Epoch: 0885 loss_train: 0.7701 acc_train: 0.8583 loss_val: 1.0915 acc_val: 0.5960 time: 0.1063s\n",
            "1\n",
            "Epoch: 0886 loss_train: 0.8031 acc_train: 0.8667 loss_val: 1.0983 acc_val: 0.5900 time: 0.1056s\n",
            "2\n",
            "Epoch: 0887 loss_train: 0.7685 acc_train: 0.8500 loss_val: 1.1029 acc_val: 0.5880 time: 0.1063s\n",
            "3\n",
            "Epoch: 0888 loss_train: 0.8118 acc_train: 0.7917 loss_val: 1.0944 acc_val: 0.5920 time: 0.1056s\n",
            "4\n",
            "Epoch: 0889 loss_train: 0.8100 acc_train: 0.8000 loss_val: 1.0790 acc_val: 0.6000 time: 0.1044s\n",
            "5\n",
            "Epoch: 0890 loss_train: 0.7919 acc_train: 0.8167 loss_val: 1.0640 acc_val: 0.6020 time: 0.1046s\n",
            "6\n",
            "Epoch: 0891 loss_train: 0.7936 acc_train: 0.8333 loss_val: 1.0536 acc_val: 0.6060 time: 0.1053s\n",
            "7\n",
            "Epoch: 0892 loss_train: 0.8192 acc_train: 0.8250 loss_val: 1.0554 acc_val: 0.6080 time: 0.1047s\n",
            "0\n",
            "Epoch: 0893 loss_train: 0.8013 acc_train: 0.8083 loss_val: 1.0617 acc_val: 0.6060 time: 0.1047s\n",
            "0\n",
            "Epoch: 0894 loss_train: 0.8164 acc_train: 0.8250 loss_val: 1.0744 acc_val: 0.6060 time: 0.1046s\n",
            "1\n",
            "Epoch: 0895 loss_train: 0.7733 acc_train: 0.8833 loss_val: 1.0884 acc_val: 0.6020 time: 0.1041s\n",
            "2\n",
            "Epoch: 0896 loss_train: 0.8403 acc_train: 0.7833 loss_val: 1.0912 acc_val: 0.5980 time: 0.1049s\n",
            "3\n",
            "Epoch: 0897 loss_train: 0.8099 acc_train: 0.8167 loss_val: 1.0858 acc_val: 0.5960 time: 0.1048s\n",
            "4\n",
            "Epoch: 0898 loss_train: 0.8294 acc_train: 0.8250 loss_val: 1.0728 acc_val: 0.6000 time: 0.1055s\n",
            "5\n",
            "Epoch: 0899 loss_train: 0.8183 acc_train: 0.8500 loss_val: 1.0658 acc_val: 0.6020 time: 0.1044s\n",
            "6\n",
            "Epoch: 0900 loss_train: 0.7821 acc_train: 0.8167 loss_val: 1.0691 acc_val: 0.6020 time: 0.1059s\n",
            "7\n",
            "Epoch: 0901 loss_train: 0.8071 acc_train: 0.8917 loss_val: 1.0762 acc_val: 0.6000 time: 0.1067s\n",
            "8\n",
            "Epoch: 0902 loss_train: 0.8113 acc_train: 0.7917 loss_val: 1.0793 acc_val: 0.5960 time: 0.1047s\n",
            "9\n",
            "Epoch: 0903 loss_train: 0.8125 acc_train: 0.8500 loss_val: 1.0747 acc_val: 0.5980 time: 0.1038s\n",
            "10\n",
            "Epoch: 0904 loss_train: 0.8017 acc_train: 0.8667 loss_val: 1.0696 acc_val: 0.6020 time: 0.1044s\n",
            "11\n",
            "Epoch: 0905 loss_train: 0.8219 acc_train: 0.8083 loss_val: 1.0651 acc_val: 0.5980 time: 0.1050s\n",
            "12\n",
            "Epoch: 0906 loss_train: 0.7990 acc_train: 0.8750 loss_val: 1.0656 acc_val: 0.5960 time: 0.1043s\n",
            "13\n",
            "Epoch: 0907 loss_train: 0.8589 acc_train: 0.7750 loss_val: 1.0635 acc_val: 0.5980 time: 0.1045s\n",
            "14\n",
            "Epoch: 0908 loss_train: 0.8126 acc_train: 0.8083 loss_val: 1.0648 acc_val: 0.5980 time: 0.1051s\n",
            "15\n",
            "Epoch: 0909 loss_train: 0.7857 acc_train: 0.8417 loss_val: 1.0736 acc_val: 0.5960 time: 0.1064s\n",
            "16\n",
            "Epoch: 0910 loss_train: 0.8084 acc_train: 0.8250 loss_val: 1.0828 acc_val: 0.5980 time: 0.1044s\n",
            "17\n",
            "Epoch: 0911 loss_train: 0.8180 acc_train: 0.8250 loss_val: 1.0805 acc_val: 0.6000 time: 0.1039s\n",
            "18\n",
            "Epoch: 0912 loss_train: 0.8032 acc_train: 0.8250 loss_val: 1.0753 acc_val: 0.5980 time: 0.1052s\n",
            "19\n",
            "Epoch: 0913 loss_train: 0.8044 acc_train: 0.8583 loss_val: 1.0752 acc_val: 0.5960 time: 0.1046s\n",
            "20\n",
            "Epoch: 0914 loss_train: 0.7906 acc_train: 0.8667 loss_val: 1.0754 acc_val: 0.5920 time: 0.1046s\n",
            "21\n",
            "Epoch: 0915 loss_train: 0.7538 acc_train: 0.8250 loss_val: 1.0764 acc_val: 0.5900 time: 0.1038s\n",
            "22\n",
            "Epoch: 0916 loss_train: 0.7967 acc_train: 0.8833 loss_val: 1.0799 acc_val: 0.5920 time: 0.1045s\n",
            "23\n",
            "Epoch: 0917 loss_train: 0.8272 acc_train: 0.8750 loss_val: 1.0784 acc_val: 0.5960 time: 0.1054s\n",
            "24\n",
            "Epoch: 0918 loss_train: 0.8053 acc_train: 0.8167 loss_val: 1.0763 acc_val: 0.6020 time: 0.1043s\n",
            "25\n",
            "Epoch: 0919 loss_train: 0.8118 acc_train: 0.8083 loss_val: 1.0713 acc_val: 0.6000 time: 0.1055s\n",
            "26\n",
            "Epoch: 0920 loss_train: 0.7739 acc_train: 0.8333 loss_val: 1.0649 acc_val: 0.6020 time: 0.1045s\n",
            "27\n",
            "Epoch: 0921 loss_train: 0.8113 acc_train: 0.8500 loss_val: 1.0653 acc_val: 0.6020 time: 0.1037s\n",
            "28\n",
            "Epoch: 0922 loss_train: 0.7900 acc_train: 0.8417 loss_val: 1.0713 acc_val: 0.5980 time: 0.1044s\n",
            "29\n",
            "Epoch: 0923 loss_train: 0.8081 acc_train: 0.8333 loss_val: 1.0815 acc_val: 0.5940 time: 0.1073s\n",
            "30\n",
            "Epoch: 0924 loss_train: 0.7336 acc_train: 0.8667 loss_val: 1.0937 acc_val: 0.5900 time: 0.1059s\n",
            "31\n",
            "Epoch: 0925 loss_train: 0.8133 acc_train: 0.8333 loss_val: 1.1017 acc_val: 0.5840 time: 0.1071s\n",
            "32\n",
            "Epoch: 0926 loss_train: 0.8304 acc_train: 0.8667 loss_val: 1.0971 acc_val: 0.5960 time: 0.1061s\n",
            "33\n",
            "Epoch: 0927 loss_train: 0.8065 acc_train: 0.8250 loss_val: 1.0796 acc_val: 0.6020 time: 0.1047s\n",
            "34\n",
            "Epoch: 0928 loss_train: 0.8243 acc_train: 0.8250 loss_val: 1.0623 acc_val: 0.6060 time: 0.1054s\n",
            "35\n",
            "Epoch: 0929 loss_train: 0.8002 acc_train: 0.8500 loss_val: 1.0579 acc_val: 0.6040 time: 0.1043s\n",
            "36\n",
            "Epoch: 0930 loss_train: 0.8306 acc_train: 0.8667 loss_val: 1.0651 acc_val: 0.6000 time: 0.1045s\n",
            "37\n",
            "Epoch: 0931 loss_train: 0.7821 acc_train: 0.8250 loss_val: 1.0799 acc_val: 0.5980 time: 0.1049s\n",
            "38\n",
            "Epoch: 0932 loss_train: 0.7787 acc_train: 0.8167 loss_val: 1.0929 acc_val: 0.5900 time: 0.1045s\n",
            "39\n",
            "Epoch: 0933 loss_train: 0.8339 acc_train: 0.8250 loss_val: 1.0891 acc_val: 0.5940 time: 0.1045s\n",
            "40\n",
            "Epoch: 0934 loss_train: 0.8129 acc_train: 0.8500 loss_val: 1.0829 acc_val: 0.5960 time: 0.1044s\n",
            "41\n",
            "Epoch: 0935 loss_train: 0.8202 acc_train: 0.7917 loss_val: 1.0724 acc_val: 0.5980 time: 0.1074s\n",
            "42\n",
            "Epoch: 0936 loss_train: 0.7911 acc_train: 0.7833 loss_val: 1.0709 acc_val: 0.5980 time: 0.1058s\n",
            "43\n",
            "Epoch: 0937 loss_train: 0.8255 acc_train: 0.8000 loss_val: 1.0739 acc_val: 0.6000 time: 0.1040s\n",
            "44\n",
            "Epoch: 0938 loss_train: 0.8252 acc_train: 0.8167 loss_val: 1.0726 acc_val: 0.6000 time: 0.1043s\n",
            "45\n",
            "Epoch: 0939 loss_train: 0.8017 acc_train: 0.7833 loss_val: 1.0737 acc_val: 0.6000 time: 0.1054s\n",
            "46\n",
            "Epoch: 0940 loss_train: 0.8273 acc_train: 0.7750 loss_val: 1.0766 acc_val: 0.6040 time: 0.1073s\n",
            "47\n",
            "Epoch: 0941 loss_train: 0.7785 acc_train: 0.8000 loss_val: 1.0759 acc_val: 0.6040 time: 0.1048s\n",
            "48\n",
            "Epoch: 0942 loss_train: 0.7653 acc_train: 0.9083 loss_val: 1.0775 acc_val: 0.6020 time: 0.1052s\n",
            "49\n",
            "Epoch: 0943 loss_train: 0.8222 acc_train: 0.8083 loss_val: 1.0775 acc_val: 0.6000 time: 0.1058s\n",
            "50\n",
            "Epoch: 0944 loss_train: 0.7944 acc_train: 0.7917 loss_val: 1.0776 acc_val: 0.5920 time: 0.1044s\n",
            "51\n",
            "Epoch: 0945 loss_train: 0.8178 acc_train: 0.8417 loss_val: 1.0741 acc_val: 0.5960 time: 0.1053s\n",
            "52\n",
            "Epoch: 0946 loss_train: 0.7969 acc_train: 0.7750 loss_val: 1.0717 acc_val: 0.5960 time: 0.1038s\n",
            "53\n",
            "Epoch: 0947 loss_train: 0.7832 acc_train: 0.7833 loss_val: 1.0698 acc_val: 0.6000 time: 0.1064s\n",
            "54\n",
            "Epoch: 0948 loss_train: 0.8117 acc_train: 0.8583 loss_val: 1.0688 acc_val: 0.6000 time: 0.1066s\n",
            "55\n",
            "Epoch: 0949 loss_train: 0.8024 acc_train: 0.7750 loss_val: 1.0654 acc_val: 0.5980 time: 0.1060s\n",
            "56\n",
            "Epoch: 0950 loss_train: 0.7660 acc_train: 0.8500 loss_val: 1.0713 acc_val: 0.6000 time: 0.1052s\n",
            "57\n",
            "Epoch: 0951 loss_train: 0.7938 acc_train: 0.8417 loss_val: 1.0798 acc_val: 0.5980 time: 0.1042s\n",
            "58\n",
            "Epoch: 0952 loss_train: 0.8319 acc_train: 0.7917 loss_val: 1.0844 acc_val: 0.5980 time: 0.1050s\n",
            "59\n",
            "Epoch: 0953 loss_train: 0.8386 acc_train: 0.8417 loss_val: 1.0827 acc_val: 0.5980 time: 0.1065s\n",
            "60\n",
            "Epoch: 0954 loss_train: 0.7953 acc_train: 0.8500 loss_val: 1.0794 acc_val: 0.6000 time: 0.1054s\n",
            "61\n",
            "Epoch: 0955 loss_train: 0.8146 acc_train: 0.7833 loss_val: 1.0716 acc_val: 0.6000 time: 0.1066s\n",
            "62\n",
            "Epoch: 0956 loss_train: 0.8116 acc_train: 0.8250 loss_val: 1.0682 acc_val: 0.5980 time: 0.1052s\n",
            "63\n",
            "Epoch: 0957 loss_train: 0.7818 acc_train: 0.8250 loss_val: 1.0733 acc_val: 0.6000 time: 0.1054s\n",
            "64\n",
            "Epoch: 0958 loss_train: 0.8203 acc_train: 0.7833 loss_val: 1.0851 acc_val: 0.5940 time: 0.1053s\n",
            "65\n",
            "Epoch: 0959 loss_train: 0.7903 acc_train: 0.8667 loss_val: 1.0963 acc_val: 0.5860 time: 0.1062s\n",
            "66\n",
            "Epoch: 0960 loss_train: 0.8065 acc_train: 0.7917 loss_val: 1.0992 acc_val: 0.5920 time: 0.1046s\n",
            "67\n",
            "Epoch: 0961 loss_train: 0.8183 acc_train: 0.8333 loss_val: 1.0918 acc_val: 0.5940 time: 0.1045s\n",
            "68\n",
            "Epoch: 0962 loss_train: 0.8145 acc_train: 0.8417 loss_val: 1.0790 acc_val: 0.6000 time: 0.1050s\n",
            "69\n",
            "Epoch: 0963 loss_train: 0.7716 acc_train: 0.8250 loss_val: 1.0730 acc_val: 0.6000 time: 0.1038s\n",
            "70\n",
            "Epoch: 0964 loss_train: 0.7978 acc_train: 0.8500 loss_val: 1.0722 acc_val: 0.6000 time: 0.1056s\n",
            "71\n",
            "Epoch: 0965 loss_train: 0.8305 acc_train: 0.8167 loss_val: 1.0723 acc_val: 0.5980 time: 0.1044s\n",
            "72\n",
            "Epoch: 0966 loss_train: 0.8081 acc_train: 0.7917 loss_val: 1.0766 acc_val: 0.5980 time: 0.1076s\n",
            "73\n",
            "Epoch: 0967 loss_train: 0.7962 acc_train: 0.8583 loss_val: 1.0844 acc_val: 0.5980 time: 0.1048s\n",
            "74\n",
            "Epoch: 0968 loss_train: 0.8361 acc_train: 0.8083 loss_val: 1.0883 acc_val: 0.5980 time: 0.1064s\n",
            "75\n",
            "Epoch: 0969 loss_train: 0.7895 acc_train: 0.8917 loss_val: 1.0904 acc_val: 0.5960 time: 0.1065s\n",
            "76\n",
            "Epoch: 0970 loss_train: 0.8051 acc_train: 0.8083 loss_val: 1.0878 acc_val: 0.5900 time: 0.1045s\n",
            "77\n",
            "Epoch: 0971 loss_train: 0.8069 acc_train: 0.7917 loss_val: 1.0838 acc_val: 0.5940 time: 0.1064s\n",
            "78\n",
            "Epoch: 0972 loss_train: 0.7834 acc_train: 0.8583 loss_val: 1.0792 acc_val: 0.5980 time: 0.1047s\n",
            "79\n",
            "Epoch: 0973 loss_train: 0.8111 acc_train: 0.8500 loss_val: 1.0769 acc_val: 0.5980 time: 0.1055s\n",
            "80\n",
            "Epoch: 0974 loss_train: 0.7752 acc_train: 0.8833 loss_val: 1.0782 acc_val: 0.5980 time: 0.1066s\n",
            "81\n",
            "Epoch: 0975 loss_train: 0.7651 acc_train: 0.8500 loss_val: 1.0783 acc_val: 0.6000 time: 0.1063s\n",
            "82\n",
            "Epoch: 0976 loss_train: 0.7867 acc_train: 0.8167 loss_val: 1.0787 acc_val: 0.5980 time: 0.1048s\n",
            "83\n",
            "Epoch: 0977 loss_train: 0.7489 acc_train: 0.8250 loss_val: 1.0849 acc_val: 0.5980 time: 0.1062s\n",
            "84\n",
            "Epoch: 0978 loss_train: 0.7693 acc_train: 0.8667 loss_val: 1.0870 acc_val: 0.5960 time: 0.1048s\n",
            "85\n",
            "Epoch: 0979 loss_train: 0.8114 acc_train: 0.8417 loss_val: 1.0806 acc_val: 0.5980 time: 0.1059s\n",
            "86\n",
            "Epoch: 0980 loss_train: 0.8029 acc_train: 0.8167 loss_val: 1.0754 acc_val: 0.5980 time: 0.1058s\n",
            "87\n",
            "Epoch: 0981 loss_train: 0.7473 acc_train: 0.8250 loss_val: 1.0747 acc_val: 0.5980 time: 0.1044s\n",
            "88\n",
            "Epoch: 0982 loss_train: 0.7719 acc_train: 0.8500 loss_val: 1.0786 acc_val: 0.6000 time: 0.1052s\n",
            "89\n",
            "Epoch: 0983 loss_train: 0.7779 acc_train: 0.8583 loss_val: 1.0781 acc_val: 0.5960 time: 0.1044s\n",
            "90\n",
            "Epoch: 0984 loss_train: 0.7310 acc_train: 0.8833 loss_val: 1.0797 acc_val: 0.5960 time: 0.1054s\n",
            "91\n",
            "Epoch: 0985 loss_train: 0.7783 acc_train: 0.8333 loss_val: 1.0816 acc_val: 0.5960 time: 0.1057s\n",
            "92\n",
            "Epoch: 0986 loss_train: 0.7955 acc_train: 0.8667 loss_val: 1.0838 acc_val: 0.5940 time: 0.1049s\n",
            "93\n",
            "Epoch: 0987 loss_train: 0.7854 acc_train: 0.8500 loss_val: 1.0846 acc_val: 0.5940 time: 0.1040s\n",
            "94\n",
            "Epoch: 0988 loss_train: 0.8001 acc_train: 0.8167 loss_val: 1.0865 acc_val: 0.6000 time: 0.1044s\n",
            "95\n",
            "Epoch: 0989 loss_train: 0.8519 acc_train: 0.8083 loss_val: 1.0868 acc_val: 0.6000 time: 0.1057s\n",
            "96\n",
            "Epoch: 0990 loss_train: 0.8315 acc_train: 0.8000 loss_val: 1.0839 acc_val: 0.5980 time: 0.1049s\n",
            "97\n",
            "Epoch: 0991 loss_train: 0.8254 acc_train: 0.8333 loss_val: 1.0791 acc_val: 0.5980 time: 0.1052s\n",
            "98\n",
            "Epoch: 0992 loss_train: 0.8293 acc_train: 0.8167 loss_val: 1.0768 acc_val: 0.5920 time: 0.1057s\n",
            "99\n",
            "Epoch: 0993 loss_train: 0.7818 acc_train: 0.8167 loss_val: 1.0784 acc_val: 0.5940 time: 0.1043s\n",
            "100\n",
            "Epoch: 0994 loss_train: 0.8404 acc_train: 0.8167 loss_val: 1.0843 acc_val: 0.5900 time: 0.1045s\n",
            "101\n",
            "Epoch: 0995 loss_train: 0.8021 acc_train: 0.8167 loss_val: 1.0856 acc_val: 0.5960 time: 0.1039s\n",
            "102\n",
            "Epoch: 0996 loss_train: 0.8328 acc_train: 0.7667 loss_val: 1.0771 acc_val: 0.5980 time: 0.1053s\n",
            "103\n",
            "Epoch: 0997 loss_train: 0.7808 acc_train: 0.8583 loss_val: 1.0710 acc_val: 0.6000 time: 0.1052s\n",
            "104\n",
            "Epoch: 0998 loss_train: 0.8075 acc_train: 0.8333 loss_val: 1.0693 acc_val: 0.6040 time: 0.1056s\n",
            "105\n",
            "Epoch: 0999 loss_train: 0.7704 acc_train: 0.8083 loss_val: 1.0686 acc_val: 0.6000 time: 0.1060s\n",
            "106\n",
            "Epoch: 1000 loss_train: 0.7771 acc_train: 0.8750 loss_val: 1.0695 acc_val: 0.5980 time: 0.1043s\n",
            "107\n",
            "Epoch: 1001 loss_train: 0.8075 acc_train: 0.8417 loss_val: 1.0738 acc_val: 0.5920 time: 0.1054s\n",
            "108\n",
            "Epoch: 1002 loss_train: 0.8026 acc_train: 0.8500 loss_val: 1.0820 acc_val: 0.5960 time: 0.1046s\n",
            "109\n",
            "Epoch: 1003 loss_train: 0.8455 acc_train: 0.7917 loss_val: 1.0863 acc_val: 0.5960 time: 0.1042s\n",
            "110\n",
            "Epoch: 1004 loss_train: 0.8636 acc_train: 0.8167 loss_val: 1.0834 acc_val: 0.5960 time: 0.1045s\n",
            "111\n",
            "Epoch: 1005 loss_train: 0.8096 acc_train: 0.8500 loss_val: 1.0749 acc_val: 0.5980 time: 0.1042s\n",
            "112\n",
            "Epoch: 1006 loss_train: 0.7948 acc_train: 0.7917 loss_val: 1.0627 acc_val: 0.6000 time: 0.1053s\n",
            "113\n",
            "Epoch: 1007 loss_train: 0.7637 acc_train: 0.8750 loss_val: 1.0634 acc_val: 0.5980 time: 0.1043s\n",
            "114\n",
            "Epoch: 1008 loss_train: 0.8311 acc_train: 0.8167 loss_val: 1.0745 acc_val: 0.5980 time: 0.1041s\n",
            "115\n",
            "Epoch: 1009 loss_train: 0.8108 acc_train: 0.7917 loss_val: 1.0817 acc_val: 0.6000 time: 0.1052s\n",
            "116\n",
            "Epoch: 1010 loss_train: 0.8246 acc_train: 0.8417 loss_val: 1.0829 acc_val: 0.6000 time: 0.1041s\n",
            "117\n",
            "Epoch: 1011 loss_train: 0.8048 acc_train: 0.8167 loss_val: 1.0807 acc_val: 0.5960 time: 0.1050s\n",
            "118\n",
            "Epoch: 1012 loss_train: 0.7957 acc_train: 0.8000 loss_val: 1.0747 acc_val: 0.5960 time: 0.1043s\n",
            "119\n",
            "Epoch: 1013 loss_train: 0.8167 acc_train: 0.8333 loss_val: 1.0645 acc_val: 0.5980 time: 0.1037s\n",
            "120\n",
            "Epoch: 1014 loss_train: 0.7994 acc_train: 0.8333 loss_val: 1.0619 acc_val: 0.5980 time: 0.1050s\n",
            "121\n",
            "Epoch: 1015 loss_train: 0.8140 acc_train: 0.8583 loss_val: 1.0640 acc_val: 0.5960 time: 0.1047s\n",
            "122\n",
            "Epoch: 1016 loss_train: 0.7864 acc_train: 0.8500 loss_val: 1.0697 acc_val: 0.5980 time: 0.1043s\n",
            "123\n",
            "Epoch: 1017 loss_train: 0.8355 acc_train: 0.8417 loss_val: 1.0730 acc_val: 0.6000 time: 0.1043s\n",
            "124\n",
            "Epoch: 1018 loss_train: 0.7978 acc_train: 0.8667 loss_val: 1.0735 acc_val: 0.6000 time: 0.1040s\n",
            "125\n",
            "Epoch: 1019 loss_train: 0.7979 acc_train: 0.7667 loss_val: 1.0691 acc_val: 0.5980 time: 0.1071s\n",
            "126\n",
            "Epoch: 1020 loss_train: 0.8266 acc_train: 0.8083 loss_val: 1.0679 acc_val: 0.5980 time: 0.1067s\n",
            "127\n",
            "Epoch: 1021 loss_train: 0.8314 acc_train: 0.8417 loss_val: 1.0686 acc_val: 0.5940 time: 0.1038s\n",
            "128\n",
            "Epoch: 1022 loss_train: 0.7921 acc_train: 0.8833 loss_val: 1.0730 acc_val: 0.5940 time: 0.1049s\n",
            "129\n",
            "Epoch: 1023 loss_train: 0.8014 acc_train: 0.7833 loss_val: 1.0775 acc_val: 0.5940 time: 0.1037s\n",
            "130\n",
            "Epoch: 1024 loss_train: 0.8342 acc_train: 0.8500 loss_val: 1.0766 acc_val: 0.5960 time: 0.1054s\n",
            "131\n",
            "Epoch: 1025 loss_train: 0.8340 acc_train: 0.8000 loss_val: 1.0745 acc_val: 0.6020 time: 0.1057s\n",
            "132\n",
            "Epoch: 1026 loss_train: 0.8259 acc_train: 0.8000 loss_val: 1.0699 acc_val: 0.6060 time: 0.1054s\n",
            "133\n",
            "Epoch: 1027 loss_train: 0.8028 acc_train: 0.8083 loss_val: 1.0646 acc_val: 0.6060 time: 0.1049s\n",
            "134\n",
            "Epoch: 1028 loss_train: 0.8478 acc_train: 0.8083 loss_val: 1.0665 acc_val: 0.6040 time: 0.1049s\n",
            "135\n",
            "Epoch: 1029 loss_train: 0.8123 acc_train: 0.8833 loss_val: 1.0754 acc_val: 0.5980 time: 0.1043s\n",
            "136\n",
            "Epoch: 1030 loss_train: 0.7860 acc_train: 0.8500 loss_val: 1.0843 acc_val: 0.5940 time: 0.1055s\n",
            "137\n",
            "Epoch: 1031 loss_train: 0.8085 acc_train: 0.7833 loss_val: 1.0850 acc_val: 0.5940 time: 0.1050s\n",
            "138\n",
            "Epoch: 1032 loss_train: 0.8242 acc_train: 0.7750 loss_val: 1.0816 acc_val: 0.5960 time: 0.1042s\n",
            "139\n",
            "Epoch: 1033 loss_train: 0.8199 acc_train: 0.8750 loss_val: 1.0730 acc_val: 0.5960 time: 0.1049s\n",
            "140\n",
            "Epoch: 1034 loss_train: 0.8070 acc_train: 0.7750 loss_val: 1.0631 acc_val: 0.6040 time: 0.1043s\n",
            "141\n",
            "Epoch: 1035 loss_train: 0.8059 acc_train: 0.8250 loss_val: 1.0595 acc_val: 0.6020 time: 0.1041s\n",
            "142\n",
            "Epoch: 1036 loss_train: 0.7995 acc_train: 0.7917 loss_val: 1.0612 acc_val: 0.6020 time: 0.1053s\n",
            "143\n",
            "Epoch: 1037 loss_train: 0.7926 acc_train: 0.8583 loss_val: 1.0687 acc_val: 0.6020 time: 0.1054s\n",
            "144\n",
            "Epoch: 1038 loss_train: 0.7959 acc_train: 0.8417 loss_val: 1.0776 acc_val: 0.6000 time: 0.1059s\n",
            "145\n",
            "Epoch: 1039 loss_train: 0.8412 acc_train: 0.8167 loss_val: 1.0840 acc_val: 0.6000 time: 0.1074s\n",
            "146\n",
            "Epoch: 1040 loss_train: 0.8095 acc_train: 0.8833 loss_val: 1.0809 acc_val: 0.6020 time: 0.1074s\n",
            "147\n",
            "Epoch: 1041 loss_train: 0.8077 acc_train: 0.8083 loss_val: 1.0753 acc_val: 0.6000 time: 0.1039s\n",
            "148\n",
            "Epoch: 1042 loss_train: 0.7858 acc_train: 0.8000 loss_val: 1.0712 acc_val: 0.6040 time: 0.1041s\n",
            "149\n",
            "Epoch: 1043 loss_train: 0.7864 acc_train: 0.8500 loss_val: 1.0722 acc_val: 0.6020 time: 0.1038s\n",
            "150\n",
            "Epoch: 1044 loss_train: 0.7775 acc_train: 0.8667 loss_val: 1.0773 acc_val: 0.5980 time: 0.1051s\n",
            "151\n",
            "Epoch: 1045 loss_train: 0.7981 acc_train: 0.8167 loss_val: 1.0833 acc_val: 0.5960 time: 0.1072s\n",
            "152\n",
            "Epoch: 1046 loss_train: 0.8263 acc_train: 0.8333 loss_val: 1.0910 acc_val: 0.5900 time: 0.1053s\n",
            "153\n",
            "Epoch: 1047 loss_train: 0.8187 acc_train: 0.8333 loss_val: 1.0896 acc_val: 0.5880 time: 0.1053s\n",
            "154\n",
            "Epoch: 1048 loss_train: 0.8139 acc_train: 0.8583 loss_val: 1.0722 acc_val: 0.5980 time: 0.1054s\n",
            "155\n",
            "Epoch: 1049 loss_train: 0.8007 acc_train: 0.7750 loss_val: 1.0587 acc_val: 0.6080 time: 0.1063s\n",
            "156\n",
            "Epoch: 1050 loss_train: 0.7959 acc_train: 0.8250 loss_val: 1.0565 acc_val: 0.6080 time: 0.1045s\n",
            "0\n",
            "Epoch: 1051 loss_train: 0.7790 acc_train: 0.8667 loss_val: 1.0619 acc_val: 0.6080 time: 0.1038s\n",
            "0\n",
            "Epoch: 1052 loss_train: 0.7733 acc_train: 0.8750 loss_val: 1.0677 acc_val: 0.6060 time: 0.1046s\n",
            "0\n",
            "Epoch: 1053 loss_train: 0.7521 acc_train: 0.8500 loss_val: 1.0820 acc_val: 0.6000 time: 0.1065s\n",
            "1\n",
            "Epoch: 1054 loss_train: 0.8149 acc_train: 0.8417 loss_val: 1.0951 acc_val: 0.6000 time: 0.1046s\n",
            "2\n",
            "Epoch: 1055 loss_train: 0.8052 acc_train: 0.7917 loss_val: 1.0951 acc_val: 0.5960 time: 0.1047s\n",
            "3\n",
            "Epoch: 1056 loss_train: 0.7627 acc_train: 0.8083 loss_val: 1.0884 acc_val: 0.5960 time: 0.1050s\n",
            "4\n",
            "Epoch: 1057 loss_train: 0.8152 acc_train: 0.8833 loss_val: 1.0734 acc_val: 0.5980 time: 0.1043s\n",
            "5\n",
            "Epoch: 1058 loss_train: 0.8358 acc_train: 0.8000 loss_val: 1.0597 acc_val: 0.6040 time: 0.1052s\n",
            "6\n",
            "Epoch: 1059 loss_train: 0.7593 acc_train: 0.8750 loss_val: 1.0554 acc_val: 0.6100 time: 0.1062s\n",
            "7\n",
            "Epoch: 1060 loss_train: 0.7901 acc_train: 0.8333 loss_val: 1.0602 acc_val: 0.6120 time: 0.1047s\n",
            "0\n",
            "Epoch: 1061 loss_train: 0.8058 acc_train: 0.8333 loss_val: 1.0698 acc_val: 0.6020 time: 0.1038s\n",
            "0\n",
            "Epoch: 1062 loss_train: 0.8293 acc_train: 0.8167 loss_val: 1.0756 acc_val: 0.5960 time: 0.1042s\n",
            "1\n",
            "Epoch: 1063 loss_train: 0.8005 acc_train: 0.8417 loss_val: 1.0835 acc_val: 0.5960 time: 0.1040s\n",
            "2\n",
            "Epoch: 1064 loss_train: 0.7843 acc_train: 0.8750 loss_val: 1.0849 acc_val: 0.5960 time: 0.1043s\n",
            "3\n",
            "Epoch: 1065 loss_train: 0.7649 acc_train: 0.8667 loss_val: 1.0772 acc_val: 0.5940 time: 0.1054s\n",
            "4\n",
            "Epoch: 1066 loss_train: 0.7803 acc_train: 0.8417 loss_val: 1.0700 acc_val: 0.6000 time: 0.1054s\n",
            "5\n",
            "Epoch: 1067 loss_train: 0.8280 acc_train: 0.8083 loss_val: 1.0655 acc_val: 0.5980 time: 0.1085s\n",
            "6\n",
            "Epoch: 1068 loss_train: 0.8409 acc_train: 0.8417 loss_val: 1.0645 acc_val: 0.6060 time: 0.1061s\n",
            "7\n",
            "Epoch: 1069 loss_train: 0.7617 acc_train: 0.8333 loss_val: 1.0700 acc_val: 0.6040 time: 0.1064s\n",
            "8\n",
            "Epoch: 1070 loss_train: 0.7868 acc_train: 0.8750 loss_val: 1.0751 acc_val: 0.6060 time: 0.1041s\n",
            "9\n",
            "Epoch: 1071 loss_train: 0.8270 acc_train: 0.8083 loss_val: 1.0828 acc_val: 0.6000 time: 0.1043s\n",
            "10\n",
            "Epoch: 1072 loss_train: 0.7880 acc_train: 0.8583 loss_val: 1.0880 acc_val: 0.5960 time: 0.1044s\n",
            "11\n",
            "Epoch: 1073 loss_train: 0.7791 acc_train: 0.8667 loss_val: 1.0881 acc_val: 0.5960 time: 0.1043s\n",
            "12\n",
            "Epoch: 1074 loss_train: 0.7855 acc_train: 0.8500 loss_val: 1.0826 acc_val: 0.5960 time: 0.1052s\n",
            "13\n",
            "Epoch: 1075 loss_train: 0.8090 acc_train: 0.8333 loss_val: 1.0760 acc_val: 0.5940 time: 0.1059s\n",
            "14\n",
            "Epoch: 1076 loss_train: 0.8150 acc_train: 0.8250 loss_val: 1.0705 acc_val: 0.5940 time: 0.1069s\n",
            "15\n",
            "Epoch: 1077 loss_train: 0.8347 acc_train: 0.8250 loss_val: 1.0683 acc_val: 0.6020 time: 0.1056s\n",
            "16\n",
            "Epoch: 1078 loss_train: 0.8136 acc_train: 0.8250 loss_val: 1.0745 acc_val: 0.6060 time: 0.1041s\n",
            "17\n",
            "Epoch: 1079 loss_train: 0.7989 acc_train: 0.8333 loss_val: 1.0755 acc_val: 0.6040 time: 0.1040s\n",
            "18\n",
            "Epoch: 1080 loss_train: 0.7461 acc_train: 0.8500 loss_val: 1.0789 acc_val: 0.6000 time: 0.1046s\n",
            "19\n",
            "Epoch: 1081 loss_train: 0.8335 acc_train: 0.8000 loss_val: 1.0851 acc_val: 0.5960 time: 0.1051s\n",
            "20\n",
            "Epoch: 1082 loss_train: 0.8017 acc_train: 0.8250 loss_val: 1.0892 acc_val: 0.5940 time: 0.1049s\n",
            "21\n",
            "Epoch: 1083 loss_train: 0.8225 acc_train: 0.8500 loss_val: 1.0793 acc_val: 0.5960 time: 0.1054s\n",
            "22\n",
            "Epoch: 1084 loss_train: 0.8163 acc_train: 0.8083 loss_val: 1.0675 acc_val: 0.5980 time: 0.1044s\n",
            "23\n",
            "Epoch: 1085 loss_train: 0.8445 acc_train: 0.8500 loss_val: 1.0642 acc_val: 0.5980 time: 0.1063s\n",
            "24\n",
            "Epoch: 1086 loss_train: 0.7566 acc_train: 0.8833 loss_val: 1.0671 acc_val: 0.6040 time: 0.1049s\n",
            "25\n",
            "Epoch: 1087 loss_train: 0.7628 acc_train: 0.7917 loss_val: 1.0765 acc_val: 0.6060 time: 0.1043s\n",
            "26\n",
            "Epoch: 1088 loss_train: 0.8061 acc_train: 0.8750 loss_val: 1.0887 acc_val: 0.6020 time: 0.1044s\n",
            "27\n",
            "Epoch: 1089 loss_train: 0.8235 acc_train: 0.8167 loss_val: 1.1032 acc_val: 0.5960 time: 0.1039s\n",
            "28\n",
            "Epoch: 1090 loss_train: 0.8265 acc_train: 0.8417 loss_val: 1.1107 acc_val: 0.5940 time: 0.1049s\n",
            "29\n",
            "Epoch: 1091 loss_train: 0.8308 acc_train: 0.8167 loss_val: 1.0988 acc_val: 0.5920 time: 0.1050s\n",
            "30\n",
            "Epoch: 1092 loss_train: 0.8349 acc_train: 0.8333 loss_val: 1.0752 acc_val: 0.5960 time: 0.1048s\n",
            "31\n",
            "Epoch: 1093 loss_train: 0.7973 acc_train: 0.8667 loss_val: 1.0558 acc_val: 0.5980 time: 0.1043s\n",
            "32\n",
            "Epoch: 1094 loss_train: 0.8042 acc_train: 0.8333 loss_val: 1.0484 acc_val: 0.6000 time: 0.1045s\n",
            "33\n",
            "Epoch: 1095 loss_train: 0.7874 acc_train: 0.8667 loss_val: 1.0567 acc_val: 0.6040 time: 0.1042s\n",
            "34\n",
            "Epoch: 1096 loss_train: 0.7708 acc_train: 0.8917 loss_val: 1.0706 acc_val: 0.6040 time: 0.1052s\n",
            "35\n",
            "Epoch: 1097 loss_train: 0.8210 acc_train: 0.8333 loss_val: 1.0900 acc_val: 0.6040 time: 0.1040s\n",
            "36\n",
            "Epoch: 1098 loss_train: 0.7823 acc_train: 0.8333 loss_val: 1.1041 acc_val: 0.5980 time: 0.1044s\n",
            "37\n",
            "Epoch: 1099 loss_train: 0.8358 acc_train: 0.7667 loss_val: 1.1031 acc_val: 0.5980 time: 0.1052s\n",
            "38\n",
            "Epoch: 1100 loss_train: 0.7924 acc_train: 0.8250 loss_val: 1.0895 acc_val: 0.6000 time: 0.1046s\n",
            "39\n",
            "Epoch: 1101 loss_train: 0.8384 acc_train: 0.8083 loss_val: 1.0669 acc_val: 0.5980 time: 0.1051s\n",
            "40\n",
            "Epoch: 1102 loss_train: 0.7755 acc_train: 0.8333 loss_val: 1.0540 acc_val: 0.6000 time: 0.1047s\n",
            "41\n",
            "Epoch: 1103 loss_train: 0.7914 acc_train: 0.8583 loss_val: 1.0508 acc_val: 0.6020 time: 0.1039s\n",
            "42\n",
            "Epoch: 1104 loss_train: 0.7764 acc_train: 0.8750 loss_val: 1.0605 acc_val: 0.6020 time: 0.1044s\n",
            "43\n",
            "Epoch: 1105 loss_train: 0.7957 acc_train: 0.8500 loss_val: 1.0774 acc_val: 0.6040 time: 0.1046s\n",
            "44\n",
            "Epoch: 1106 loss_train: 0.7948 acc_train: 0.8750 loss_val: 1.0937 acc_val: 0.5980 time: 0.1048s\n",
            "45\n",
            "Epoch: 1107 loss_train: 0.7631 acc_train: 0.8167 loss_val: 1.1038 acc_val: 0.5980 time: 0.1069s\n",
            "46\n",
            "Epoch: 1108 loss_train: 0.7970 acc_train: 0.8167 loss_val: 1.0972 acc_val: 0.5960 time: 0.1046s\n",
            "47\n",
            "Epoch: 1109 loss_train: 0.8016 acc_train: 0.8667 loss_val: 1.0815 acc_val: 0.5940 time: 0.1059s\n",
            "48\n",
            "Epoch: 1110 loss_train: 0.8117 acc_train: 0.7833 loss_val: 1.0643 acc_val: 0.6000 time: 0.1050s\n",
            "49\n",
            "Epoch: 1111 loss_train: 0.7687 acc_train: 0.8500 loss_val: 1.0526 acc_val: 0.5980 time: 0.1045s\n",
            "50\n",
            "Epoch: 1112 loss_train: 0.7977 acc_train: 0.8167 loss_val: 1.0497 acc_val: 0.5980 time: 0.1048s\n",
            "51\n",
            "Epoch: 1113 loss_train: 0.7544 acc_train: 0.8417 loss_val: 1.0571 acc_val: 0.6000 time: 0.1066s\n",
            "52\n",
            "Epoch: 1114 loss_train: 0.7775 acc_train: 0.8333 loss_val: 1.0730 acc_val: 0.6040 time: 0.1050s\n",
            "53\n",
            "Epoch: 1115 loss_train: 0.7825 acc_train: 0.8083 loss_val: 1.0843 acc_val: 0.6020 time: 0.1061s\n",
            "54\n",
            "Epoch: 1116 loss_train: 0.7542 acc_train: 0.8333 loss_val: 1.0922 acc_val: 0.5940 time: 0.1041s\n",
            "55\n",
            "Epoch: 1117 loss_train: 0.7967 acc_train: 0.8167 loss_val: 1.0919 acc_val: 0.5900 time: 0.1038s\n",
            "56\n",
            "Epoch: 1118 loss_train: 0.8141 acc_train: 0.7917 loss_val: 1.0850 acc_val: 0.5860 time: 0.1047s\n",
            "57\n",
            "Epoch: 1119 loss_train: 0.7716 acc_train: 0.7917 loss_val: 1.0756 acc_val: 0.5960 time: 0.1041s\n",
            "58\n",
            "Epoch: 1120 loss_train: 0.8472 acc_train: 0.8000 loss_val: 1.0635 acc_val: 0.6000 time: 0.1057s\n",
            "59\n",
            "Epoch: 1121 loss_train: 0.7807 acc_train: 0.8583 loss_val: 1.0606 acc_val: 0.6000 time: 0.1066s\n",
            "60\n",
            "Epoch: 1122 loss_train: 0.8259 acc_train: 0.8167 loss_val: 1.0669 acc_val: 0.6000 time: 0.1052s\n",
            "61\n",
            "Epoch: 1123 loss_train: 0.7792 acc_train: 0.8750 loss_val: 1.0762 acc_val: 0.6000 time: 0.1040s\n",
            "62\n",
            "Epoch: 1124 loss_train: 0.8059 acc_train: 0.8083 loss_val: 1.0849 acc_val: 0.5960 time: 0.1050s\n",
            "63\n",
            "Epoch: 1125 loss_train: 0.7983 acc_train: 0.7833 loss_val: 1.0881 acc_val: 0.5960 time: 0.1040s\n",
            "64\n",
            "Epoch: 1126 loss_train: 0.7967 acc_train: 0.8417 loss_val: 1.0837 acc_val: 0.6020 time: 0.1073s\n",
            "65\n",
            "Epoch: 1127 loss_train: 0.8150 acc_train: 0.8667 loss_val: 1.0782 acc_val: 0.6000 time: 0.1045s\n",
            "66\n",
            "Epoch: 1128 loss_train: 0.7598 acc_train: 0.8250 loss_val: 1.0761 acc_val: 0.6000 time: 0.1049s\n",
            "67\n",
            "Epoch: 1129 loss_train: 0.8270 acc_train: 0.7917 loss_val: 1.0748 acc_val: 0.5980 time: 0.1043s\n",
            "68\n",
            "Epoch: 1130 loss_train: 0.7774 acc_train: 0.8333 loss_val: 1.0761 acc_val: 0.5980 time: 0.1053s\n",
            "69\n",
            "Epoch: 1131 loss_train: 0.7777 acc_train: 0.8583 loss_val: 1.0833 acc_val: 0.5980 time: 0.1053s\n",
            "70\n",
            "Epoch: 1132 loss_train: 0.7895 acc_train: 0.8083 loss_val: 1.0903 acc_val: 0.5940 time: 0.1054s\n",
            "71\n",
            "Epoch: 1133 loss_train: 0.8056 acc_train: 0.8167 loss_val: 1.0882 acc_val: 0.5960 time: 0.1042s\n",
            "72\n",
            "Epoch: 1134 loss_train: 0.8625 acc_train: 0.7750 loss_val: 1.0805 acc_val: 0.6000 time: 0.1068s\n",
            "73\n",
            "Epoch: 1135 loss_train: 0.7530 acc_train: 0.8583 loss_val: 1.0719 acc_val: 0.6020 time: 0.1072s\n",
            "74\n",
            "Epoch: 1136 loss_train: 0.8195 acc_train: 0.8167 loss_val: 1.0684 acc_val: 0.6040 time: 0.1042s\n",
            "75\n",
            "Epoch: 1137 loss_train: 0.8337 acc_train: 0.8333 loss_val: 1.0716 acc_val: 0.6060 time: 0.1051s\n",
            "76\n",
            "Epoch: 1138 loss_train: 0.7668 acc_train: 0.8750 loss_val: 1.0782 acc_val: 0.6000 time: 0.1093s\n",
            "77\n",
            "Epoch: 1139 loss_train: 0.7959 acc_train: 0.7917 loss_val: 1.0845 acc_val: 0.6000 time: 0.1051s\n",
            "78\n",
            "Epoch: 1140 loss_train: 0.7597 acc_train: 0.8750 loss_val: 1.0894 acc_val: 0.5940 time: 0.1044s\n",
            "79\n",
            "Epoch: 1141 loss_train: 0.8093 acc_train: 0.7667 loss_val: 1.0922 acc_val: 0.5900 time: 0.1042s\n",
            "80\n",
            "Epoch: 1142 loss_train: 0.8522 acc_train: 0.7833 loss_val: 1.0850 acc_val: 0.5960 time: 0.1077s\n",
            "81\n",
            "Epoch: 1143 loss_train: 0.8287 acc_train: 0.8083 loss_val: 1.0721 acc_val: 0.6040 time: 0.1056s\n",
            "82\n",
            "Epoch: 1144 loss_train: 0.8023 acc_train: 0.8417 loss_val: 1.0614 acc_val: 0.6040 time: 0.1056s\n",
            "83\n",
            "Epoch: 1145 loss_train: 0.7917 acc_train: 0.8583 loss_val: 1.0543 acc_val: 0.6040 time: 0.1037s\n",
            "84\n",
            "Epoch: 1146 loss_train: 0.8278 acc_train: 0.8250 loss_val: 1.0575 acc_val: 0.6020 time: 0.1046s\n",
            "85\n",
            "Epoch: 1147 loss_train: 0.8302 acc_train: 0.8000 loss_val: 1.0657 acc_val: 0.6020 time: 0.1040s\n",
            "86\n",
            "Epoch: 1148 loss_train: 0.8037 acc_train: 0.8417 loss_val: 1.0777 acc_val: 0.6000 time: 0.1055s\n",
            "87\n",
            "Epoch: 1149 loss_train: 0.7842 acc_train: 0.8500 loss_val: 1.0914 acc_val: 0.5920 time: 0.1039s\n",
            "88\n",
            "Epoch: 1150 loss_train: 0.8389 acc_train: 0.7583 loss_val: 1.0933 acc_val: 0.5960 time: 0.1046s\n",
            "89\n",
            "Epoch: 1151 loss_train: 0.7843 acc_train: 0.7917 loss_val: 1.0846 acc_val: 0.6000 time: 0.1053s\n",
            "90\n",
            "Epoch: 1152 loss_train: 0.8278 acc_train: 0.7750 loss_val: 1.0732 acc_val: 0.6040 time: 0.1063s\n",
            "91\n",
            "Epoch: 1153 loss_train: 0.7937 acc_train: 0.7750 loss_val: 1.0669 acc_val: 0.6020 time: 0.1052s\n",
            "92\n",
            "Epoch: 1154 loss_train: 0.7477 acc_train: 0.8667 loss_val: 1.0655 acc_val: 0.6000 time: 0.1045s\n",
            "93\n",
            "Epoch: 1155 loss_train: 0.8013 acc_train: 0.8167 loss_val: 1.0646 acc_val: 0.6040 time: 0.1049s\n",
            "94\n",
            "Epoch: 1156 loss_train: 0.8389 acc_train: 0.8500 loss_val: 1.0697 acc_val: 0.6040 time: 0.1043s\n",
            "95\n",
            "Epoch: 1157 loss_train: 0.8184 acc_train: 0.8750 loss_val: 1.0761 acc_val: 0.6000 time: 0.1052s\n",
            "96\n",
            "Epoch: 1158 loss_train: 0.7966 acc_train: 0.8583 loss_val: 1.0769 acc_val: 0.5960 time: 0.1045s\n",
            "97\n",
            "Epoch: 1159 loss_train: 0.8303 acc_train: 0.8417 loss_val: 1.0731 acc_val: 0.5960 time: 0.1052s\n",
            "98\n",
            "Epoch: 1160 loss_train: 0.8007 acc_train: 0.8667 loss_val: 1.0650 acc_val: 0.5980 time: 0.1045s\n",
            "99\n",
            "Epoch: 1161 loss_train: 0.7923 acc_train: 0.8750 loss_val: 1.0647 acc_val: 0.6000 time: 0.1034s\n",
            "100\n",
            "Epoch: 1162 loss_train: 0.8293 acc_train: 0.8167 loss_val: 1.0655 acc_val: 0.5980 time: 0.1057s\n",
            "101\n",
            "Epoch: 1163 loss_train: 0.8089 acc_train: 0.8250 loss_val: 1.0746 acc_val: 0.6000 time: 0.1056s\n",
            "102\n",
            "Epoch: 1164 loss_train: 0.8193 acc_train: 0.8417 loss_val: 1.0803 acc_val: 0.6000 time: 0.1045s\n",
            "103\n",
            "Epoch: 1165 loss_train: 0.7906 acc_train: 0.8333 loss_val: 1.0821 acc_val: 0.6000 time: 0.1039s\n",
            "104\n",
            "Epoch: 1166 loss_train: 0.7905 acc_train: 0.8417 loss_val: 1.0806 acc_val: 0.6000 time: 0.1056s\n",
            "105\n",
            "Epoch: 1167 loss_train: 0.7652 acc_train: 0.8750 loss_val: 1.0769 acc_val: 0.6040 time: 0.1060s\n",
            "106\n",
            "Epoch: 1168 loss_train: 0.8114 acc_train: 0.7750 loss_val: 1.0720 acc_val: 0.6040 time: 0.1043s\n",
            "107\n",
            "Epoch: 1169 loss_train: 0.7952 acc_train: 0.8583 loss_val: 1.0675 acc_val: 0.6000 time: 0.1039s\n",
            "108\n",
            "Epoch: 1170 loss_train: 0.8087 acc_train: 0.8500 loss_val: 1.0671 acc_val: 0.5980 time: 0.1043s\n",
            "109\n",
            "Epoch: 1171 loss_train: 0.8333 acc_train: 0.8250 loss_val: 1.0687 acc_val: 0.5980 time: 0.1060s\n",
            "110\n",
            "Epoch: 1172 loss_train: 0.7932 acc_train: 0.8500 loss_val: 1.0690 acc_val: 0.6000 time: 0.1046s\n",
            "111\n",
            "Epoch: 1173 loss_train: 0.7444 acc_train: 0.9000 loss_val: 1.0726 acc_val: 0.6000 time: 0.1039s\n",
            "112\n",
            "Epoch: 1174 loss_train: 0.7784 acc_train: 0.8333 loss_val: 1.0784 acc_val: 0.6020 time: 0.1071s\n",
            "113\n",
            "Epoch: 1175 loss_train: 0.7754 acc_train: 0.8417 loss_val: 1.0823 acc_val: 0.6000 time: 0.1045s\n",
            "114\n",
            "Epoch: 1176 loss_train: 0.8001 acc_train: 0.8083 loss_val: 1.0794 acc_val: 0.6000 time: 0.1047s\n",
            "115\n",
            "Epoch: 1177 loss_train: 0.7808 acc_train: 0.8250 loss_val: 1.0753 acc_val: 0.6020 time: 0.1076s\n",
            "116\n",
            "Epoch: 1178 loss_train: 0.7988 acc_train: 0.8250 loss_val: 1.0713 acc_val: 0.6000 time: 0.1053s\n",
            "117\n",
            "Epoch: 1179 loss_train: 0.7883 acc_train: 0.8000 loss_val: 1.0685 acc_val: 0.6000 time: 0.1047s\n",
            "118\n",
            "Epoch: 1180 loss_train: 0.7647 acc_train: 0.8667 loss_val: 1.0721 acc_val: 0.5980 time: 0.1048s\n",
            "119\n",
            "Epoch: 1181 loss_train: 0.7707 acc_train: 0.8083 loss_val: 1.0740 acc_val: 0.5940 time: 0.1052s\n",
            "120\n",
            "Epoch: 1182 loss_train: 0.8048 acc_train: 0.8083 loss_val: 1.0706 acc_val: 0.6000 time: 0.1046s\n",
            "121\n",
            "Epoch: 1183 loss_train: 0.7734 acc_train: 0.8083 loss_val: 1.0726 acc_val: 0.6020 time: 0.1059s\n",
            "122\n",
            "Epoch: 1184 loss_train: 0.7740 acc_train: 0.8667 loss_val: 1.0829 acc_val: 0.6020 time: 0.1044s\n",
            "123\n",
            "Epoch: 1185 loss_train: 0.7683 acc_train: 0.8750 loss_val: 1.0885 acc_val: 0.6020 time: 0.1044s\n",
            "124\n",
            "Epoch: 1186 loss_train: 0.7899 acc_train: 0.8000 loss_val: 1.0870 acc_val: 0.6020 time: 0.1049s\n",
            "125\n",
            "Epoch: 1187 loss_train: 0.7641 acc_train: 0.8333 loss_val: 1.0822 acc_val: 0.6020 time: 0.1038s\n",
            "126\n",
            "Epoch: 1188 loss_train: 0.7917 acc_train: 0.8500 loss_val: 1.0722 acc_val: 0.5980 time: 0.1057s\n",
            "127\n",
            "Epoch: 1189 loss_train: 0.8120 acc_train: 0.8417 loss_val: 1.0678 acc_val: 0.6000 time: 0.1048s\n",
            "128\n",
            "Epoch: 1190 loss_train: 0.7849 acc_train: 0.8083 loss_val: 1.0615 acc_val: 0.6000 time: 0.1056s\n",
            "129\n",
            "Epoch: 1191 loss_train: 0.7944 acc_train: 0.7833 loss_val: 1.0627 acc_val: 0.6000 time: 0.1067s\n",
            "130\n",
            "Epoch: 1192 loss_train: 0.8533 acc_train: 0.8417 loss_val: 1.0665 acc_val: 0.6020 time: 0.1049s\n",
            "131\n",
            "Epoch: 1193 loss_train: 0.7702 acc_train: 0.8500 loss_val: 1.0735 acc_val: 0.6040 time: 0.1042s\n",
            "132\n",
            "Epoch: 1194 loss_train: 0.7965 acc_train: 0.8000 loss_val: 1.0756 acc_val: 0.6040 time: 0.1049s\n",
            "133\n",
            "Epoch: 1195 loss_train: 0.7671 acc_train: 0.8667 loss_val: 1.0738 acc_val: 0.6040 time: 0.1041s\n",
            "134\n",
            "Epoch: 1196 loss_train: 0.7983 acc_train: 0.8333 loss_val: 1.0725 acc_val: 0.6040 time: 0.1064s\n",
            "135\n",
            "Epoch: 1197 loss_train: 0.7966 acc_train: 0.8500 loss_val: 1.0712 acc_val: 0.6040 time: 0.1076s\n",
            "136\n",
            "Epoch: 1198 loss_train: 0.8144 acc_train: 0.8167 loss_val: 1.0709 acc_val: 0.6020 time: 0.1056s\n",
            "137\n",
            "Epoch: 1199 loss_train: 0.8331 acc_train: 0.7500 loss_val: 1.0657 acc_val: 0.6060 time: 0.1046s\n",
            "138\n",
            "Epoch: 1200 loss_train: 0.7999 acc_train: 0.8000 loss_val: 1.0666 acc_val: 0.6060 time: 0.1057s\n",
            "139\n",
            "Epoch: 1201 loss_train: 0.7971 acc_train: 0.8750 loss_val: 1.0659 acc_val: 0.6100 time: 0.1040s\n",
            "140\n",
            "Epoch: 1202 loss_train: 0.8021 acc_train: 0.8500 loss_val: 1.0656 acc_val: 0.6100 time: 0.1068s\n",
            "141\n",
            "Epoch: 1203 loss_train: 0.7690 acc_train: 0.8750 loss_val: 1.0714 acc_val: 0.6040 time: 0.1073s\n",
            "142\n",
            "Epoch: 1204 loss_train: 0.8092 acc_train: 0.8167 loss_val: 1.0726 acc_val: 0.6040 time: 0.1056s\n",
            "143\n",
            "Epoch: 1205 loss_train: 0.8022 acc_train: 0.8417 loss_val: 1.0778 acc_val: 0.6020 time: 0.1047s\n",
            "144\n",
            "Epoch: 1206 loss_train: 0.8058 acc_train: 0.8583 loss_val: 1.0821 acc_val: 0.6000 time: 0.1049s\n",
            "145\n",
            "Epoch: 1207 loss_train: 0.7490 acc_train: 0.8250 loss_val: 1.0874 acc_val: 0.6000 time: 0.1044s\n",
            "146\n",
            "Epoch: 1208 loss_train: 0.7278 acc_train: 0.8583 loss_val: 1.0905 acc_val: 0.6000 time: 0.1051s\n",
            "147\n",
            "Epoch: 1209 loss_train: 0.7866 acc_train: 0.8417 loss_val: 1.0862 acc_val: 0.6020 time: 0.1060s\n",
            "148\n",
            "Epoch: 1210 loss_train: 0.7898 acc_train: 0.8333 loss_val: 1.0795 acc_val: 0.6000 time: 0.1043s\n",
            "149\n",
            "Epoch: 1211 loss_train: 0.7386 acc_train: 0.8917 loss_val: 1.0693 acc_val: 0.6020 time: 0.1059s\n",
            "150\n",
            "Epoch: 1212 loss_train: 0.8054 acc_train: 0.8500 loss_val: 1.0577 acc_val: 0.6080 time: 0.1047s\n",
            "151\n",
            "Epoch: 1213 loss_train: 0.7959 acc_train: 0.8500 loss_val: 1.0548 acc_val: 0.6020 time: 0.1043s\n",
            "152\n",
            "Epoch: 1214 loss_train: 0.7863 acc_train: 0.8250 loss_val: 1.0584 acc_val: 0.6020 time: 0.1049s\n",
            "153\n",
            "Epoch: 1215 loss_train: 0.8149 acc_train: 0.8750 loss_val: 1.0699 acc_val: 0.6000 time: 0.1046s\n",
            "154\n",
            "Epoch: 1216 loss_train: 0.7913 acc_train: 0.8333 loss_val: 1.0859 acc_val: 0.5960 time: 0.1047s\n",
            "155\n",
            "Epoch: 1217 loss_train: 0.7917 acc_train: 0.8750 loss_val: 1.0956 acc_val: 0.5980 time: 0.1045s\n",
            "156\n",
            "Epoch: 1218 loss_train: 0.8595 acc_train: 0.7833 loss_val: 1.0971 acc_val: 0.6020 time: 0.1056s\n",
            "157\n",
            "Epoch: 1219 loss_train: 0.8123 acc_train: 0.8250 loss_val: 1.0894 acc_val: 0.6000 time: 0.1054s\n",
            "158\n",
            "Epoch: 1220 loss_train: 0.7838 acc_train: 0.8500 loss_val: 1.0783 acc_val: 0.6000 time: 0.1048s\n",
            "159\n",
            "Epoch: 1221 loss_train: 0.7849 acc_train: 0.8500 loss_val: 1.0664 acc_val: 0.6060 time: 0.1045s\n",
            "160\n",
            "Epoch: 1222 loss_train: 0.7713 acc_train: 0.8083 loss_val: 1.0596 acc_val: 0.6080 time: 0.1051s\n",
            "161\n",
            "Epoch: 1223 loss_train: 0.7948 acc_train: 0.8333 loss_val: 1.0607 acc_val: 0.6060 time: 0.1039s\n",
            "162\n",
            "Epoch: 1224 loss_train: 0.7668 acc_train: 0.8417 loss_val: 1.0684 acc_val: 0.6000 time: 0.1046s\n",
            "163\n",
            "Epoch: 1225 loss_train: 0.8280 acc_train: 0.7917 loss_val: 1.0786 acc_val: 0.5980 time: 0.1070s\n",
            "164\n",
            "Epoch: 1226 loss_train: 0.8421 acc_train: 0.7750 loss_val: 1.0854 acc_val: 0.6020 time: 0.1075s\n",
            "165\n",
            "Epoch: 1227 loss_train: 0.7963 acc_train: 0.7750 loss_val: 1.0813 acc_val: 0.6020 time: 0.1046s\n",
            "166\n",
            "Epoch: 1228 loss_train: 0.7766 acc_train: 0.8250 loss_val: 1.0759 acc_val: 0.6040 time: 0.1053s\n",
            "167\n",
            "Epoch: 1229 loss_train: 0.7688 acc_train: 0.8000 loss_val: 1.0721 acc_val: 0.6020 time: 0.1041s\n",
            "168\n",
            "Epoch: 1230 loss_train: 0.8413 acc_train: 0.7833 loss_val: 1.0699 acc_val: 0.6020 time: 0.1046s\n",
            "169\n",
            "Epoch: 1231 loss_train: 0.8266 acc_train: 0.8500 loss_val: 1.0723 acc_val: 0.6000 time: 0.1055s\n",
            "170\n",
            "Epoch: 1232 loss_train: 0.7805 acc_train: 0.8333 loss_val: 1.0775 acc_val: 0.6000 time: 0.1044s\n",
            "171\n",
            "Epoch: 1233 loss_train: 0.7558 acc_train: 0.8833 loss_val: 1.0821 acc_val: 0.6000 time: 0.1042s\n",
            "172\n",
            "Epoch: 1234 loss_train: 0.7965 acc_train: 0.7833 loss_val: 1.0812 acc_val: 0.6000 time: 0.1049s\n",
            "173\n",
            "Epoch: 1235 loss_train: 0.8018 acc_train: 0.8417 loss_val: 1.0791 acc_val: 0.6000 time: 0.1038s\n",
            "174\n",
            "Epoch: 1236 loss_train: 0.7977 acc_train: 0.8083 loss_val: 1.0814 acc_val: 0.5980 time: 0.1050s\n",
            "175\n",
            "Epoch: 1237 loss_train: 0.8025 acc_train: 0.8167 loss_val: 1.0818 acc_val: 0.5920 time: 0.1049s\n",
            "176\n",
            "Epoch: 1238 loss_train: 0.7992 acc_train: 0.8417 loss_val: 1.0777 acc_val: 0.5980 time: 0.1054s\n",
            "177\n",
            "Epoch: 1239 loss_train: 0.7820 acc_train: 0.8583 loss_val: 1.0733 acc_val: 0.6020 time: 0.1060s\n",
            "178\n",
            "Epoch: 1240 loss_train: 0.8290 acc_train: 0.8333 loss_val: 1.0717 acc_val: 0.6000 time: 0.1048s\n",
            "179\n",
            "Epoch: 1241 loss_train: 0.7967 acc_train: 0.8583 loss_val: 1.0698 acc_val: 0.6020 time: 0.1047s\n",
            "180\n",
            "Epoch: 1242 loss_train: 0.7866 acc_train: 0.8500 loss_val: 1.0702 acc_val: 0.6000 time: 0.1047s\n",
            "181\n",
            "Epoch: 1243 loss_train: 0.7837 acc_train: 0.8167 loss_val: 1.0762 acc_val: 0.6020 time: 0.1043s\n",
            "182\n",
            "Epoch: 1244 loss_train: 0.8084 acc_train: 0.8167 loss_val: 1.0812 acc_val: 0.6000 time: 0.1046s\n",
            "183\n",
            "Epoch: 1245 loss_train: 0.7792 acc_train: 0.8417 loss_val: 1.0871 acc_val: 0.5980 time: 0.1052s\n",
            "184\n",
            "Epoch: 1246 loss_train: 0.7506 acc_train: 0.8583 loss_val: 1.0835 acc_val: 0.6000 time: 0.1056s\n",
            "185\n",
            "Epoch: 1247 loss_train: 0.7768 acc_train: 0.9083 loss_val: 1.0815 acc_val: 0.6000 time: 0.1055s\n",
            "186\n",
            "Epoch: 1248 loss_train: 0.8058 acc_train: 0.8250 loss_val: 1.0803 acc_val: 0.6000 time: 0.1044s\n",
            "187\n",
            "Epoch: 1249 loss_train: 0.7738 acc_train: 0.8333 loss_val: 1.0827 acc_val: 0.6000 time: 0.1039s\n",
            "188\n",
            "Epoch: 1250 loss_train: 0.7997 acc_train: 0.8667 loss_val: 1.0867 acc_val: 0.6040 time: 0.1054s\n",
            "189\n",
            "Epoch: 1251 loss_train: 0.8172 acc_train: 0.7750 loss_val: 1.0888 acc_val: 0.6000 time: 0.1043s\n",
            "190\n",
            "Epoch: 1252 loss_train: 0.7503 acc_train: 0.9083 loss_val: 1.0920 acc_val: 0.5980 time: 0.1045s\n",
            "191\n",
            "Epoch: 1253 loss_train: 0.7796 acc_train: 0.8417 loss_val: 1.0929 acc_val: 0.5960 time: 0.1048s\n",
            "192\n",
            "Epoch: 1254 loss_train: 0.7726 acc_train: 0.8167 loss_val: 1.0894 acc_val: 0.6000 time: 0.1048s\n",
            "193\n",
            "Epoch: 1255 loss_train: 0.8275 acc_train: 0.8167 loss_val: 1.0808 acc_val: 0.6020 time: 0.1054s\n",
            "194\n",
            "Epoch: 1256 loss_train: 0.7970 acc_train: 0.8667 loss_val: 1.0720 acc_val: 0.6040 time: 0.1051s\n",
            "195\n",
            "Epoch: 1257 loss_train: 0.8244 acc_train: 0.8417 loss_val: 1.0707 acc_val: 0.5980 time: 0.1040s\n",
            "196\n",
            "Epoch: 1258 loss_train: 0.7874 acc_train: 0.8667 loss_val: 1.0701 acc_val: 0.5980 time: 0.1050s\n",
            "197\n",
            "Epoch: 1259 loss_train: 0.7903 acc_train: 0.8333 loss_val: 1.0742 acc_val: 0.6000 time: 0.1044s\n",
            "198\n",
            "Epoch: 1260 loss_train: 0.8091 acc_train: 0.7750 loss_val: 1.0853 acc_val: 0.5960 time: 0.1045s\n",
            "199\n",
            "Early stop! Min loss:  1.0466704368591309 , Max accuracy:  0.612\n",
            "Early stop model validation loss:  1.0466704368591309 , accuracy:  0.598\n",
            "Optimization Finished!\n",
            "Total time elapsed: 135.5024s\n",
            "Loading 677th epoch\n",
            "Test set results: loss= 1.0722 accuracy= 0.5780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5780, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDRvxWtONNm1",
        "outputId": "bcbb3d95-aa31-4add-c15f-2c480f7e604e"
      },
      "source": [
        "accs_dropout = []\n",
        "for lam in range(1,11,2):\n",
        "  Train(lam=lam/10) #cora dropout\n",
        "  accs_dropout.append(test())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 0121 loss_train: 0.6990 acc_train: 0.8500 loss_val: 1.0042 acc_val: 0.7180 time: 0.0634s\n",
            "6\n",
            "Epoch: 0122 loss_train: 0.7309 acc_train: 0.8250 loss_val: 1.0018 acc_val: 0.7220 time: 0.0662s\n",
            "7\n",
            "Epoch: 0123 loss_train: 0.7276 acc_train: 0.8167 loss_val: 0.9971 acc_val: 0.7300 time: 0.0663s\n",
            "8\n",
            "Epoch: 0124 loss_train: 0.7012 acc_train: 0.8000 loss_val: 0.9916 acc_val: 0.7300 time: 0.0644s\n",
            "9\n",
            "Epoch: 0125 loss_train: 0.7140 acc_train: 0.8167 loss_val: 0.9841 acc_val: 0.7300 time: 0.0643s\n",
            "10\n",
            "Epoch: 0126 loss_train: 0.7768 acc_train: 0.7667 loss_val: 0.9802 acc_val: 0.7360 time: 0.0641s\n",
            "11\n",
            "Epoch: 0127 loss_train: 0.7364 acc_train: 0.8000 loss_val: 0.9810 acc_val: 0.7340 time: 0.0652s\n",
            "0\n",
            "Epoch: 0128 loss_train: 0.8046 acc_train: 0.8667 loss_val: 0.9870 acc_val: 0.7260 time: 0.0654s\n",
            "1\n",
            "Epoch: 0129 loss_train: 0.7498 acc_train: 0.8083 loss_val: 0.9949 acc_val: 0.7300 time: 0.0664s\n",
            "2\n",
            "Epoch: 0130 loss_train: 0.7572 acc_train: 0.7917 loss_val: 1.0000 acc_val: 0.7260 time: 0.0664s\n",
            "3\n",
            "Epoch: 0131 loss_train: 0.6913 acc_train: 0.7750 loss_val: 1.0036 acc_val: 0.7200 time: 0.0647s\n",
            "4\n",
            "Epoch: 0132 loss_train: 0.7583 acc_train: 0.7333 loss_val: 1.0054 acc_val: 0.7200 time: 0.0664s\n",
            "5\n",
            "Epoch: 0133 loss_train: 0.6824 acc_train: 0.8083 loss_val: 1.0068 acc_val: 0.7180 time: 0.0649s\n",
            "6\n",
            "Epoch: 0134 loss_train: 0.7322 acc_train: 0.8167 loss_val: 1.0040 acc_val: 0.7180 time: 0.0641s\n",
            "7\n",
            "Epoch: 0135 loss_train: 0.7497 acc_train: 0.7750 loss_val: 1.0033 acc_val: 0.7180 time: 0.0640s\n",
            "8\n",
            "Epoch: 0136 loss_train: 0.7427 acc_train: 0.7667 loss_val: 1.0052 acc_val: 0.7160 time: 0.0652s\n",
            "9\n",
            "Epoch: 0137 loss_train: 0.7266 acc_train: 0.7833 loss_val: 1.0062 acc_val: 0.7180 time: 0.0643s\n",
            "10\n",
            "Epoch: 0138 loss_train: 0.7217 acc_train: 0.8167 loss_val: 1.0052 acc_val: 0.7180 time: 0.0660s\n",
            "11\n",
            "Epoch: 0139 loss_train: 0.6994 acc_train: 0.8417 loss_val: 1.0019 acc_val: 0.7180 time: 0.0650s\n",
            "12\n",
            "Epoch: 0140 loss_train: 0.7580 acc_train: 0.7833 loss_val: 0.9993 acc_val: 0.7180 time: 0.0643s\n",
            "13\n",
            "Epoch: 0141 loss_train: 0.7420 acc_train: 0.8250 loss_val: 0.9981 acc_val: 0.7160 time: 0.0641s\n",
            "14\n",
            "Epoch: 0142 loss_train: 0.6545 acc_train: 0.7667 loss_val: 0.9972 acc_val: 0.7200 time: 0.0644s\n",
            "15\n",
            "Epoch: 0143 loss_train: 0.7481 acc_train: 0.8500 loss_val: 0.9954 acc_val: 0.7200 time: 0.0650s\n",
            "16\n",
            "Epoch: 0144 loss_train: 0.7177 acc_train: 0.7917 loss_val: 0.9942 acc_val: 0.7240 time: 0.0638s\n",
            "17\n",
            "Epoch: 0145 loss_train: 0.7141 acc_train: 0.8750 loss_val: 0.9966 acc_val: 0.7200 time: 0.0640s\n",
            "18\n",
            "Epoch: 0146 loss_train: 0.7201 acc_train: 0.8083 loss_val: 0.9985 acc_val: 0.7200 time: 0.0658s\n",
            "19\n",
            "Epoch: 0147 loss_train: 0.6843 acc_train: 0.8333 loss_val: 1.0013 acc_val: 0.7200 time: 0.0653s\n",
            "20\n",
            "Epoch: 0148 loss_train: 0.7892 acc_train: 0.7750 loss_val: 1.0067 acc_val: 0.7180 time: 0.0636s\n",
            "21\n",
            "Epoch: 0149 loss_train: 0.6994 acc_train: 0.8167 loss_val: 1.0128 acc_val: 0.7200 time: 0.0636s\n",
            "22\n",
            "Epoch: 0150 loss_train: 0.7272 acc_train: 0.8667 loss_val: 1.0135 acc_val: 0.7180 time: 0.0668s\n",
            "23\n",
            "Epoch: 0151 loss_train: 0.6894 acc_train: 0.8500 loss_val: 1.0048 acc_val: 0.7180 time: 0.0634s\n",
            "24\n",
            "Epoch: 0152 loss_train: 0.7480 acc_train: 0.8583 loss_val: 0.9969 acc_val: 0.7220 time: 0.0635s\n",
            "25\n",
            "Epoch: 0153 loss_train: 0.7318 acc_train: 0.8083 loss_val: 0.9865 acc_val: 0.7260 time: 0.0663s\n",
            "26\n",
            "Epoch: 0154 loss_train: 0.7438 acc_train: 0.8000 loss_val: 0.9782 acc_val: 0.7280 time: 0.0644s\n",
            "27\n",
            "Epoch: 0155 loss_train: 0.7609 acc_train: 0.8167 loss_val: 0.9719 acc_val: 0.7340 time: 0.0632s\n",
            "28\n",
            "Epoch: 0156 loss_train: 0.7296 acc_train: 0.7583 loss_val: 0.9712 acc_val: 0.7320 time: 0.0631s\n",
            "0\n",
            "Epoch: 0157 loss_train: 0.6798 acc_train: 0.7833 loss_val: 0.9745 acc_val: 0.7320 time: 0.0652s\n",
            "0\n",
            "Epoch: 0158 loss_train: 0.7299 acc_train: 0.7833 loss_val: 0.9840 acc_val: 0.7260 time: 0.0649s\n",
            "1\n",
            "Epoch: 0159 loss_train: 0.6782 acc_train: 0.8083 loss_val: 0.9991 acc_val: 0.7220 time: 0.0642s\n",
            "2\n",
            "Epoch: 0160 loss_train: 0.6922 acc_train: 0.7917 loss_val: 1.0080 acc_val: 0.7240 time: 0.0641s\n",
            "3\n",
            "Epoch: 0161 loss_train: 0.7439 acc_train: 0.7750 loss_val: 1.0135 acc_val: 0.7240 time: 0.0643s\n",
            "4\n",
            "Epoch: 0162 loss_train: 0.6962 acc_train: 0.8333 loss_val: 1.0123 acc_val: 0.7240 time: 0.0634s\n",
            "5\n",
            "Epoch: 0163 loss_train: 0.7909 acc_train: 0.7917 loss_val: 1.0087 acc_val: 0.7240 time: 0.0663s\n",
            "6\n",
            "Epoch: 0164 loss_train: 0.7060 acc_train: 0.7833 loss_val: 1.0013 acc_val: 0.7260 time: 0.0654s\n",
            "7\n",
            "Epoch: 0165 loss_train: 0.7552 acc_train: 0.7500 loss_val: 0.9936 acc_val: 0.7260 time: 0.0636s\n",
            "8\n",
            "Epoch: 0166 loss_train: 0.7447 acc_train: 0.8083 loss_val: 0.9867 acc_val: 0.7300 time: 0.0632s\n",
            "9\n",
            "Epoch: 0167 loss_train: 0.7877 acc_train: 0.7667 loss_val: 0.9831 acc_val: 0.7260 time: 0.0649s\n",
            "10\n",
            "Epoch: 0168 loss_train: 0.7205 acc_train: 0.8333 loss_val: 0.9839 acc_val: 0.7240 time: 0.0670s\n",
            "11\n",
            "Epoch: 0169 loss_train: 0.6772 acc_train: 0.8333 loss_val: 0.9869 acc_val: 0.7220 time: 0.0651s\n",
            "12\n",
            "Epoch: 0170 loss_train: 0.7457 acc_train: 0.8500 loss_val: 0.9879 acc_val: 0.7220 time: 0.0631s\n",
            "13\n",
            "Epoch: 0171 loss_train: 0.7008 acc_train: 0.7917 loss_val: 0.9925 acc_val: 0.7220 time: 0.0633s\n",
            "14\n",
            "Epoch: 0172 loss_train: 0.7297 acc_train: 0.7667 loss_val: 0.9974 acc_val: 0.7220 time: 0.0644s\n",
            "15\n",
            "Epoch: 0173 loss_train: 0.6749 acc_train: 0.8083 loss_val: 0.9988 acc_val: 0.7180 time: 0.0635s\n",
            "16\n",
            "Epoch: 0174 loss_train: 0.7217 acc_train: 0.8167 loss_val: 1.0001 acc_val: 0.7160 time: 0.0637s\n",
            "17\n",
            "Epoch: 0175 loss_train: 0.7388 acc_train: 0.7417 loss_val: 0.9979 acc_val: 0.7160 time: 0.0647s\n",
            "18\n",
            "Epoch: 0176 loss_train: 0.6656 acc_train: 0.8083 loss_val: 0.9957 acc_val: 0.7180 time: 0.0637s\n",
            "19\n",
            "Epoch: 0177 loss_train: 0.6848 acc_train: 0.8417 loss_val: 0.9921 acc_val: 0.7160 time: 0.0637s\n",
            "20\n",
            "Epoch: 0178 loss_train: 0.7975 acc_train: 0.8083 loss_val: 0.9922 acc_val: 0.7200 time: 0.0634s\n",
            "21\n",
            "Epoch: 0179 loss_train: 0.7188 acc_train: 0.8000 loss_val: 0.9944 acc_val: 0.7180 time: 0.0643s\n",
            "22\n",
            "Epoch: 0180 loss_train: 0.7838 acc_train: 0.8083 loss_val: 0.9994 acc_val: 0.7220 time: 0.0632s\n",
            "23\n",
            "Epoch: 0181 loss_train: 0.7543 acc_train: 0.7917 loss_val: 1.0044 acc_val: 0.7160 time: 0.0634s\n",
            "24\n",
            "Epoch: 0182 loss_train: 0.7328 acc_train: 0.8167 loss_val: 1.0128 acc_val: 0.7200 time: 0.0633s\n",
            "25\n",
            "Epoch: 0183 loss_train: 0.7069 acc_train: 0.8500 loss_val: 1.0145 acc_val: 0.7200 time: 0.0684s\n",
            "26\n",
            "Epoch: 0184 loss_train: 0.8177 acc_train: 0.8000 loss_val: 1.0104 acc_val: 0.7200 time: 0.0631s\n",
            "27\n",
            "Epoch: 0185 loss_train: 0.7876 acc_train: 0.7917 loss_val: 0.9994 acc_val: 0.7240 time: 0.0632s\n",
            "28\n",
            "Epoch: 0186 loss_train: 0.7517 acc_train: 0.8167 loss_val: 0.9924 acc_val: 0.7300 time: 0.0638s\n",
            "29\n",
            "Epoch: 0187 loss_train: 0.7536 acc_train: 0.7750 loss_val: 0.9906 acc_val: 0.7280 time: 0.0654s\n",
            "30\n",
            "Epoch: 0188 loss_train: 0.7606 acc_train: 0.8583 loss_val: 0.9889 acc_val: 0.7260 time: 0.0643s\n",
            "31\n",
            "Epoch: 0189 loss_train: 0.7392 acc_train: 0.7833 loss_val: 0.9863 acc_val: 0.7240 time: 0.0631s\n",
            "32\n",
            "Epoch: 0190 loss_train: 0.7152 acc_train: 0.8083 loss_val: 0.9907 acc_val: 0.7200 time: 0.0648s\n",
            "33\n",
            "Epoch: 0191 loss_train: 0.7055 acc_train: 0.8417 loss_val: 0.9959 acc_val: 0.7140 time: 0.0643s\n",
            "34\n",
            "Epoch: 0192 loss_train: 0.7414 acc_train: 0.7917 loss_val: 1.0028 acc_val: 0.7100 time: 0.0632s\n",
            "35\n",
            "Epoch: 0193 loss_train: 0.6857 acc_train: 0.8750 loss_val: 1.0071 acc_val: 0.7100 time: 0.0641s\n",
            "36\n",
            "Epoch: 0194 loss_train: 0.7460 acc_train: 0.8083 loss_val: 1.0057 acc_val: 0.7200 time: 0.0647s\n",
            "37\n",
            "Epoch: 0195 loss_train: 0.7192 acc_train: 0.8583 loss_val: 1.0009 acc_val: 0.7220 time: 0.0630s\n",
            "38\n",
            "Epoch: 0196 loss_train: 0.7739 acc_train: 0.7833 loss_val: 0.9979 acc_val: 0.7220 time: 0.0632s\n",
            "39\n",
            "Epoch: 0197 loss_train: 0.7348 acc_train: 0.8250 loss_val: 0.9870 acc_val: 0.7240 time: 0.0632s\n",
            "40\n",
            "Epoch: 0198 loss_train: 0.7212 acc_train: 0.7667 loss_val: 0.9796 acc_val: 0.7240 time: 0.0655s\n",
            "41\n",
            "Epoch: 0199 loss_train: 0.7098 acc_train: 0.8000 loss_val: 0.9762 acc_val: 0.7280 time: 0.0684s\n",
            "42\n",
            "Epoch: 0200 loss_train: 0.7485 acc_train: 0.7667 loss_val: 0.9746 acc_val: 0.7280 time: 0.0634s\n",
            "43\n",
            "Epoch: 0201 loss_train: 0.7253 acc_train: 0.7583 loss_val: 0.9739 acc_val: 0.7260 time: 0.0680s\n",
            "44\n",
            "Epoch: 0202 loss_train: 0.7086 acc_train: 0.8583 loss_val: 0.9779 acc_val: 0.7280 time: 0.0636s\n",
            "45\n",
            "Epoch: 0203 loss_train: 0.7342 acc_train: 0.7500 loss_val: 0.9880 acc_val: 0.7220 time: 0.0635s\n",
            "46\n",
            "Epoch: 0204 loss_train: 0.7570 acc_train: 0.7667 loss_val: 1.0015 acc_val: 0.7140 time: 0.0633s\n",
            "47\n",
            "Epoch: 0205 loss_train: 0.7772 acc_train: 0.8250 loss_val: 1.0089 acc_val: 0.7120 time: 0.0665s\n",
            "48\n",
            "Epoch: 0206 loss_train: 0.6690 acc_train: 0.8333 loss_val: 1.0120 acc_val: 0.7100 time: 0.0634s\n",
            "49\n",
            "Epoch: 0207 loss_train: 0.7337 acc_train: 0.8333 loss_val: 1.0116 acc_val: 0.7100 time: 0.0630s\n",
            "50\n",
            "Epoch: 0208 loss_train: 0.7430 acc_train: 0.8167 loss_val: 1.0064 acc_val: 0.7120 time: 0.0636s\n",
            "51\n",
            "Epoch: 0209 loss_train: 0.7538 acc_train: 0.7250 loss_val: 0.9993 acc_val: 0.7160 time: 0.0655s\n",
            "52\n",
            "Epoch: 0210 loss_train: 0.7246 acc_train: 0.8083 loss_val: 0.9930 acc_val: 0.7180 time: 0.0650s\n",
            "53\n",
            "Epoch: 0211 loss_train: 0.7616 acc_train: 0.8583 loss_val: 0.9879 acc_val: 0.7160 time: 0.0634s\n",
            "54\n",
            "Epoch: 0212 loss_train: 0.7893 acc_train: 0.7167 loss_val: 0.9824 acc_val: 0.7200 time: 0.0632s\n",
            "55\n",
            "Epoch: 0213 loss_train: 0.7384 acc_train: 0.8167 loss_val: 0.9780 acc_val: 0.7240 time: 0.0638s\n",
            "56\n",
            "Epoch: 0214 loss_train: 0.7927 acc_train: 0.7917 loss_val: 0.9776 acc_val: 0.7300 time: 0.0656s\n",
            "57\n",
            "Epoch: 0215 loss_train: 0.7093 acc_train: 0.8333 loss_val: 0.9754 acc_val: 0.7340 time: 0.0643s\n",
            "58\n",
            "Epoch: 0216 loss_train: 0.7216 acc_train: 0.7500 loss_val: 0.9746 acc_val: 0.7280 time: 0.0659s\n",
            "59\n",
            "Epoch: 0217 loss_train: 0.7467 acc_train: 0.8083 loss_val: 0.9808 acc_val: 0.7220 time: 0.0649s\n",
            "60\n",
            "Epoch: 0218 loss_train: 0.7060 acc_train: 0.9000 loss_val: 0.9838 acc_val: 0.7200 time: 0.0637s\n",
            "61\n",
            "Epoch: 0219 loss_train: 0.6862 acc_train: 0.8083 loss_val: 0.9896 acc_val: 0.7220 time: 0.0635s\n",
            "62\n",
            "Epoch: 0220 loss_train: 0.6928 acc_train: 0.8250 loss_val: 1.0006 acc_val: 0.7160 time: 0.0664s\n",
            "63\n",
            "Epoch: 0221 loss_train: 0.7111 acc_train: 0.7917 loss_val: 1.0092 acc_val: 0.7160 time: 0.0648s\n",
            "64\n",
            "Epoch: 0222 loss_train: 0.6752 acc_train: 0.8000 loss_val: 1.0185 acc_val: 0.7080 time: 0.0636s\n",
            "65\n",
            "Epoch: 0223 loss_train: 0.7576 acc_train: 0.7750 loss_val: 1.0185 acc_val: 0.7120 time: 0.0639s\n",
            "66\n",
            "Epoch: 0224 loss_train: 0.7220 acc_train: 0.7917 loss_val: 1.0073 acc_val: 0.7180 time: 0.0641s\n",
            "67\n",
            "Epoch: 0225 loss_train: 0.7586 acc_train: 0.7667 loss_val: 0.9926 acc_val: 0.7300 time: 0.0631s\n",
            "68\n",
            "Epoch: 0226 loss_train: 0.7387 acc_train: 0.8000 loss_val: 0.9773 acc_val: 0.7300 time: 0.0634s\n",
            "69\n",
            "Epoch: 0227 loss_train: 0.7118 acc_train: 0.8333 loss_val: 0.9680 acc_val: 0.7280 time: 0.0639s\n",
            "70\n",
            "Epoch: 0228 loss_train: 0.7444 acc_train: 0.8250 loss_val: 0.9693 acc_val: 0.7340 time: 0.0629s\n",
            "0\n",
            "Epoch: 0229 loss_train: 0.7242 acc_train: 0.8583 loss_val: 0.9740 acc_val: 0.7340 time: 0.0643s\n",
            "1\n",
            "Epoch: 0230 loss_train: 0.7909 acc_train: 0.7833 loss_val: 0.9815 acc_val: 0.7300 time: 0.0631s\n",
            "2\n",
            "Epoch: 0231 loss_train: 0.7324 acc_train: 0.8250 loss_val: 0.9925 acc_val: 0.7320 time: 0.0674s\n",
            "3\n",
            "Epoch: 0232 loss_train: 0.7513 acc_train: 0.7583 loss_val: 1.0091 acc_val: 0.7180 time: 0.0650s\n",
            "4\n",
            "Epoch: 0233 loss_train: 0.7411 acc_train: 0.8083 loss_val: 1.0204 acc_val: 0.7180 time: 0.0635s\n",
            "5\n",
            "Epoch: 0234 loss_train: 0.7257 acc_train: 0.8333 loss_val: 1.0260 acc_val: 0.7140 time: 0.0639s\n",
            "6\n",
            "Epoch: 0235 loss_train: 0.6936 acc_train: 0.8417 loss_val: 1.0304 acc_val: 0.7120 time: 0.0636s\n",
            "7\n",
            "Epoch: 0236 loss_train: 0.7431 acc_train: 0.7417 loss_val: 1.0260 acc_val: 0.7160 time: 0.0634s\n",
            "8\n",
            "Epoch: 0237 loss_train: 0.7532 acc_train: 0.7417 loss_val: 1.0134 acc_val: 0.7220 time: 0.0635s\n",
            "9\n",
            "Epoch: 0238 loss_train: 0.7563 acc_train: 0.7833 loss_val: 1.0022 acc_val: 0.7240 time: 0.0638s\n",
            "10\n",
            "Epoch: 0239 loss_train: 0.7359 acc_train: 0.8000 loss_val: 0.9887 acc_val: 0.7300 time: 0.0635s\n",
            "11\n",
            "Epoch: 0240 loss_train: 0.7190 acc_train: 0.8167 loss_val: 0.9746 acc_val: 0.7280 time: 0.0631s\n",
            "12\n",
            "Epoch: 0241 loss_train: 0.7393 acc_train: 0.8000 loss_val: 0.9663 acc_val: 0.7300 time: 0.0646s\n",
            "13\n",
            "Epoch: 0242 loss_train: 0.6786 acc_train: 0.8000 loss_val: 0.9686 acc_val: 0.7320 time: 0.0651s\n",
            "0\n",
            "Epoch: 0243 loss_train: 0.7463 acc_train: 0.7167 loss_val: 0.9770 acc_val: 0.7340 time: 0.0643s\n",
            "1\n",
            "Epoch: 0244 loss_train: 0.6864 acc_train: 0.7917 loss_val: 0.9916 acc_val: 0.7260 time: 0.0648s\n",
            "2\n",
            "Epoch: 0245 loss_train: 0.6947 acc_train: 0.7917 loss_val: 1.0058 acc_val: 0.7160 time: 0.0635s\n",
            "3\n",
            "Epoch: 0246 loss_train: 0.7181 acc_train: 0.7833 loss_val: 1.0174 acc_val: 0.7100 time: 0.0637s\n",
            "4\n",
            "Epoch: 0247 loss_train: 0.7454 acc_train: 0.8333 loss_val: 1.0185 acc_val: 0.7080 time: 0.0631s\n",
            "5\n",
            "Epoch: 0248 loss_train: 0.7105 acc_train: 0.8500 loss_val: 1.0129 acc_val: 0.7120 time: 0.0638s\n",
            "6\n",
            "Epoch: 0249 loss_train: 0.7559 acc_train: 0.8000 loss_val: 1.0075 acc_val: 0.7240 time: 0.0690s\n",
            "7\n",
            "Epoch: 0250 loss_train: 0.7936 acc_train: 0.7833 loss_val: 1.0043 acc_val: 0.7240 time: 0.0634s\n",
            "8\n",
            "Epoch: 0251 loss_train: 0.6764 acc_train: 0.8250 loss_val: 0.9992 acc_val: 0.7220 time: 0.0635s\n",
            "9\n",
            "Epoch: 0252 loss_train: 0.7202 acc_train: 0.8167 loss_val: 0.9961 acc_val: 0.7220 time: 0.0630s\n",
            "10\n",
            "Epoch: 0253 loss_train: 0.7537 acc_train: 0.8000 loss_val: 0.9959 acc_val: 0.7240 time: 0.0644s\n",
            "11\n",
            "Epoch: 0254 loss_train: 0.7552 acc_train: 0.8000 loss_val: 0.9993 acc_val: 0.7160 time: 0.0634s\n",
            "12\n",
            "Epoch: 0255 loss_train: 0.7064 acc_train: 0.8000 loss_val: 1.0018 acc_val: 0.7140 time: 0.0648s\n",
            "13\n",
            "Epoch: 0256 loss_train: 0.7839 acc_train: 0.7500 loss_val: 1.0034 acc_val: 0.7200 time: 0.0632s\n",
            "14\n",
            "Epoch: 0257 loss_train: 0.7171 acc_train: 0.8167 loss_val: 1.0006 acc_val: 0.7180 time: 0.0653s\n",
            "15\n",
            "Epoch: 0258 loss_train: 0.7895 acc_train: 0.7500 loss_val: 0.9954 acc_val: 0.7220 time: 0.0640s\n",
            "16\n",
            "Epoch: 0259 loss_train: 0.7334 acc_train: 0.7583 loss_val: 0.9899 acc_val: 0.7200 time: 0.0646s\n",
            "17\n",
            "Epoch: 0260 loss_train: 0.7341 acc_train: 0.8417 loss_val: 0.9858 acc_val: 0.7180 time: 0.0632s\n",
            "18\n",
            "Epoch: 0261 loss_train: 0.7228 acc_train: 0.8417 loss_val: 0.9831 acc_val: 0.7180 time: 0.0647s\n",
            "19\n",
            "Epoch: 0262 loss_train: 0.7372 acc_train: 0.8250 loss_val: 0.9865 acc_val: 0.7180 time: 0.0631s\n",
            "20\n",
            "Epoch: 0263 loss_train: 0.7058 acc_train: 0.8083 loss_val: 0.9924 acc_val: 0.7160 time: 0.0640s\n",
            "21\n",
            "Epoch: 0264 loss_train: 0.6422 acc_train: 0.8333 loss_val: 0.9980 acc_val: 0.7200 time: 0.0655s\n",
            "22\n",
            "Epoch: 0265 loss_train: 0.7024 acc_train: 0.8833 loss_val: 1.0022 acc_val: 0.7260 time: 0.0651s\n",
            "23\n",
            "Epoch: 0266 loss_train: 0.7213 acc_train: 0.7833 loss_val: 1.0031 acc_val: 0.7220 time: 0.0639s\n",
            "24\n",
            "Epoch: 0267 loss_train: 0.7397 acc_train: 0.8083 loss_val: 0.9991 acc_val: 0.7200 time: 0.0638s\n",
            "25\n",
            "Epoch: 0268 loss_train: 0.7061 acc_train: 0.8167 loss_val: 0.9890 acc_val: 0.7260 time: 0.0638s\n",
            "26\n",
            "Epoch: 0269 loss_train: 0.6970 acc_train: 0.8000 loss_val: 0.9810 acc_val: 0.7300 time: 0.0633s\n",
            "27\n",
            "Epoch: 0270 loss_train: 0.7710 acc_train: 0.7083 loss_val: 0.9779 acc_val: 0.7300 time: 0.0653s\n",
            "28\n",
            "Epoch: 0271 loss_train: 0.7457 acc_train: 0.7750 loss_val: 0.9797 acc_val: 0.7240 time: 0.0663s\n",
            "29\n",
            "Epoch: 0272 loss_train: 0.7353 acc_train: 0.7833 loss_val: 0.9819 acc_val: 0.7220 time: 0.0634s\n",
            "30\n",
            "Epoch: 0273 loss_train: 0.7761 acc_train: 0.8250 loss_val: 0.9864 acc_val: 0.7240 time: 0.0633s\n",
            "31\n",
            "Epoch: 0274 loss_train: 0.6904 acc_train: 0.8417 loss_val: 0.9943 acc_val: 0.7220 time: 0.0631s\n",
            "32\n",
            "Epoch: 0275 loss_train: 0.7133 acc_train: 0.7917 loss_val: 0.9997 acc_val: 0.7240 time: 0.0673s\n",
            "33\n",
            "Epoch: 0276 loss_train: 0.7377 acc_train: 0.7500 loss_val: 1.0063 acc_val: 0.7260 time: 0.0651s\n",
            "34\n",
            "Epoch: 0277 loss_train: 0.7116 acc_train: 0.8417 loss_val: 1.0116 acc_val: 0.7220 time: 0.0641s\n",
            "35\n",
            "Epoch: 0278 loss_train: 0.6861 acc_train: 0.8333 loss_val: 1.0110 acc_val: 0.7240 time: 0.0656s\n",
            "36\n",
            "Epoch: 0279 loss_train: 0.7203 acc_train: 0.8167 loss_val: 1.0030 acc_val: 0.7240 time: 0.0638s\n",
            "37\n",
            "Epoch: 0280 loss_train: 0.7392 acc_train: 0.7667 loss_val: 0.9952 acc_val: 0.7240 time: 0.0638s\n",
            "38\n",
            "Epoch: 0281 loss_train: 0.6807 acc_train: 0.8167 loss_val: 0.9893 acc_val: 0.7280 time: 0.0636s\n",
            "39\n",
            "Epoch: 0282 loss_train: 0.6908 acc_train: 0.8417 loss_val: 0.9859 acc_val: 0.7280 time: 0.0670s\n",
            "40\n",
            "Epoch: 0283 loss_train: 0.7468 acc_train: 0.8083 loss_val: 0.9869 acc_val: 0.7300 time: 0.0647s\n",
            "41\n",
            "Epoch: 0284 loss_train: 0.6951 acc_train: 0.8083 loss_val: 0.9892 acc_val: 0.7280 time: 0.0637s\n",
            "42\n",
            "Epoch: 0285 loss_train: 0.7288 acc_train: 0.8333 loss_val: 0.9951 acc_val: 0.7280 time: 0.0648s\n",
            "43\n",
            "Epoch: 0286 loss_train: 0.7345 acc_train: 0.8250 loss_val: 1.0030 acc_val: 0.7280 time: 0.0665s\n",
            "44\n",
            "Epoch: 0287 loss_train: 0.7470 acc_train: 0.8000 loss_val: 1.0077 acc_val: 0.7300 time: 0.0633s\n",
            "45\n",
            "Epoch: 0288 loss_train: 0.7441 acc_train: 0.7417 loss_val: 1.0069 acc_val: 0.7260 time: 0.0633s\n",
            "46\n",
            "Epoch: 0289 loss_train: 0.7080 acc_train: 0.8250 loss_val: 1.0019 acc_val: 0.7220 time: 0.0643s\n",
            "47\n",
            "Epoch: 0290 loss_train: 0.6957 acc_train: 0.7750 loss_val: 0.9943 acc_val: 0.7180 time: 0.0656s\n",
            "48\n",
            "Epoch: 0291 loss_train: 0.6816 acc_train: 0.8167 loss_val: 0.9900 acc_val: 0.7160 time: 0.0632s\n",
            "49\n",
            "Epoch: 0292 loss_train: 0.6725 acc_train: 0.7833 loss_val: 0.9879 acc_val: 0.7220 time: 0.0632s\n",
            "50\n",
            "Epoch: 0293 loss_train: 0.7312 acc_train: 0.8250 loss_val: 0.9884 acc_val: 0.7240 time: 0.0659s\n",
            "51\n",
            "Epoch: 0294 loss_train: 0.6900 acc_train: 0.8333 loss_val: 0.9900 acc_val: 0.7240 time: 0.0631s\n",
            "52\n",
            "Epoch: 0295 loss_train: 0.7194 acc_train: 0.8583 loss_val: 0.9948 acc_val: 0.7220 time: 0.0630s\n",
            "53\n",
            "Epoch: 0296 loss_train: 0.6963 acc_train: 0.8417 loss_val: 1.0002 acc_val: 0.7180 time: 0.0654s\n",
            "54\n",
            "Epoch: 0297 loss_train: 0.7580 acc_train: 0.8083 loss_val: 0.9999 acc_val: 0.7180 time: 0.0646s\n",
            "55\n",
            "Epoch: 0298 loss_train: 0.7413 acc_train: 0.8250 loss_val: 1.0020 acc_val: 0.7160 time: 0.0630s\n",
            "56\n",
            "Epoch: 0299 loss_train: 0.7684 acc_train: 0.8167 loss_val: 1.0028 acc_val: 0.7140 time: 0.0639s\n",
            "57\n",
            "Epoch: 0300 loss_train: 0.6543 acc_train: 0.8083 loss_val: 0.9996 acc_val: 0.7140 time: 0.0659s\n",
            "58\n",
            "Epoch: 0301 loss_train: 0.7545 acc_train: 0.7833 loss_val: 0.9914 acc_val: 0.7180 time: 0.0686s\n",
            "59\n",
            "Epoch: 0302 loss_train: 0.6690 acc_train: 0.8333 loss_val: 0.9821 acc_val: 0.7220 time: 0.0631s\n",
            "60\n",
            "Epoch: 0303 loss_train: 0.7541 acc_train: 0.8083 loss_val: 0.9775 acc_val: 0.7260 time: 0.0634s\n",
            "61\n",
            "Epoch: 0304 loss_train: 0.7442 acc_train: 0.7750 loss_val: 0.9779 acc_val: 0.7260 time: 0.0645s\n",
            "62\n",
            "Epoch: 0305 loss_train: 0.7447 acc_train: 0.7583 loss_val: 0.9779 acc_val: 0.7260 time: 0.0658s\n",
            "63\n",
            "Epoch: 0306 loss_train: 0.7768 acc_train: 0.7917 loss_val: 0.9836 acc_val: 0.7260 time: 0.0630s\n",
            "64\n",
            "Epoch: 0307 loss_train: 0.7309 acc_train: 0.8500 loss_val: 0.9885 acc_val: 0.7240 time: 0.0648s\n",
            "65\n",
            "Epoch: 0308 loss_train: 0.7388 acc_train: 0.8083 loss_val: 0.9939 acc_val: 0.7220 time: 0.0633s\n",
            "66\n",
            "Epoch: 0309 loss_train: 0.6703 acc_train: 0.8250 loss_val: 0.9989 acc_val: 0.7200 time: 0.0632s\n",
            "67\n",
            "Epoch: 0310 loss_train: 0.7597 acc_train: 0.7917 loss_val: 1.0020 acc_val: 0.7180 time: 0.0631s\n",
            "68\n",
            "Epoch: 0311 loss_train: 0.7682 acc_train: 0.8167 loss_val: 1.0009 acc_val: 0.7220 time: 0.0656s\n",
            "69\n",
            "Epoch: 0312 loss_train: 0.7355 acc_train: 0.7583 loss_val: 0.9934 acc_val: 0.7240 time: 0.0656s\n",
            "70\n",
            "Epoch: 0313 loss_train: 0.6797 acc_train: 0.8000 loss_val: 0.9829 acc_val: 0.7280 time: 0.0631s\n",
            "71\n",
            "Epoch: 0314 loss_train: 0.7055 acc_train: 0.7917 loss_val: 0.9774 acc_val: 0.7260 time: 0.0634s\n",
            "72\n",
            "Epoch: 0315 loss_train: 0.7786 acc_train: 0.7333 loss_val: 0.9745 acc_val: 0.7260 time: 0.0635s\n",
            "73\n",
            "Epoch: 0316 loss_train: 0.7553 acc_train: 0.8000 loss_val: 0.9759 acc_val: 0.7220 time: 0.0630s\n",
            "74\n",
            "Epoch: 0317 loss_train: 0.7136 acc_train: 0.8000 loss_val: 0.9837 acc_val: 0.7180 time: 0.0631s\n",
            "75\n",
            "Epoch: 0318 loss_train: 0.7042 acc_train: 0.8083 loss_val: 0.9961 acc_val: 0.7220 time: 0.0641s\n",
            "76\n",
            "Epoch: 0319 loss_train: 0.7114 acc_train: 0.8167 loss_val: 1.0050 acc_val: 0.7140 time: 0.0648s\n",
            "77\n",
            "Epoch: 0320 loss_train: 0.7174 acc_train: 0.8083 loss_val: 1.0103 acc_val: 0.7120 time: 0.0656s\n",
            "78\n",
            "Epoch: 0321 loss_train: 0.6832 acc_train: 0.8333 loss_val: 1.0130 acc_val: 0.7140 time: 0.0661s\n",
            "79\n",
            "Epoch: 0322 loss_train: 0.7466 acc_train: 0.8333 loss_val: 1.0053 acc_val: 0.7180 time: 0.0652s\n",
            "80\n",
            "Epoch: 0323 loss_train: 0.7358 acc_train: 0.7667 loss_val: 1.0000 acc_val: 0.7220 time: 0.0633s\n",
            "81\n",
            "Epoch: 0324 loss_train: 0.7084 acc_train: 0.7917 loss_val: 0.9905 acc_val: 0.7240 time: 0.0637s\n",
            "82\n",
            "Epoch: 0325 loss_train: 0.7087 acc_train: 0.8167 loss_val: 0.9803 acc_val: 0.7220 time: 0.0656s\n",
            "83\n",
            "Epoch: 0326 loss_train: 0.7657 acc_train: 0.7750 loss_val: 0.9756 acc_val: 0.7280 time: 0.0649s\n",
            "84\n",
            "Epoch: 0327 loss_train: 0.6996 acc_train: 0.7667 loss_val: 0.9745 acc_val: 0.7260 time: 0.0632s\n",
            "85\n",
            "Epoch: 0328 loss_train: 0.7408 acc_train: 0.7833 loss_val: 0.9752 acc_val: 0.7260 time: 0.0641s\n",
            "86\n",
            "Epoch: 0329 loss_train: 0.7450 acc_train: 0.7917 loss_val: 0.9791 acc_val: 0.7260 time: 0.0640s\n",
            "87\n",
            "Epoch: 0330 loss_train: 0.7263 acc_train: 0.8000 loss_val: 0.9865 acc_val: 0.7260 time: 0.0636s\n",
            "88\n",
            "Epoch: 0331 loss_train: 0.7142 acc_train: 0.8000 loss_val: 0.9965 acc_val: 0.7260 time: 0.0632s\n",
            "89\n",
            "Epoch: 0332 loss_train: 0.7738 acc_train: 0.7667 loss_val: 1.0048 acc_val: 0.7220 time: 0.0655s\n",
            "90\n",
            "Epoch: 0333 loss_train: 0.6635 acc_train: 0.8000 loss_val: 1.0118 acc_val: 0.7220 time: 0.0661s\n",
            "91\n",
            "Epoch: 0334 loss_train: 0.7670 acc_train: 0.7833 loss_val: 1.0071 acc_val: 0.7200 time: 0.0635s\n",
            "92\n",
            "Epoch: 0335 loss_train: 0.7537 acc_train: 0.7833 loss_val: 0.9991 acc_val: 0.7280 time: 0.0634s\n",
            "93\n",
            "Epoch: 0336 loss_train: 0.7163 acc_train: 0.7917 loss_val: 0.9893 acc_val: 0.7260 time: 0.0664s\n",
            "94\n",
            "Epoch: 0337 loss_train: 0.7283 acc_train: 0.7750 loss_val: 0.9818 acc_val: 0.7220 time: 0.0641s\n",
            "95\n",
            "Epoch: 0338 loss_train: 0.7682 acc_train: 0.8167 loss_val: 0.9759 acc_val: 0.7280 time: 0.0632s\n",
            "96\n",
            "Epoch: 0339 loss_train: 0.7085 acc_train: 0.7667 loss_val: 0.9701 acc_val: 0.7300 time: 0.0636s\n",
            "97\n",
            "Epoch: 0340 loss_train: 0.6967 acc_train: 0.7833 loss_val: 0.9696 acc_val: 0.7280 time: 0.0650s\n",
            "98\n",
            "Epoch: 0341 loss_train: 0.7451 acc_train: 0.8583 loss_val: 0.9712 acc_val: 0.7300 time: 0.0643s\n",
            "99\n",
            "Epoch: 0342 loss_train: 0.6934 acc_train: 0.8167 loss_val: 0.9757 acc_val: 0.7220 time: 0.0658s\n",
            "100\n",
            "Epoch: 0343 loss_train: 0.6788 acc_train: 0.8083 loss_val: 0.9808 acc_val: 0.7240 time: 0.0634s\n",
            "101\n",
            "Epoch: 0344 loss_train: 0.7289 acc_train: 0.8167 loss_val: 0.9862 acc_val: 0.7260 time: 0.0644s\n",
            "102\n",
            "Epoch: 0345 loss_train: 0.6821 acc_train: 0.7917 loss_val: 0.9905 acc_val: 0.7260 time: 0.0633s\n",
            "103\n",
            "Epoch: 0346 loss_train: 0.6554 acc_train: 0.8417 loss_val: 0.9964 acc_val: 0.7240 time: 0.0639s\n",
            "104\n",
            "Epoch: 0347 loss_train: 0.7307 acc_train: 0.8083 loss_val: 0.9973 acc_val: 0.7240 time: 0.0653s\n",
            "105\n",
            "Epoch: 0348 loss_train: 0.6617 acc_train: 0.7833 loss_val: 0.9961 acc_val: 0.7260 time: 0.0654s\n",
            "106\n",
            "Epoch: 0349 loss_train: 0.7592 acc_train: 0.8500 loss_val: 0.9928 acc_val: 0.7320 time: 0.0649s\n",
            "107\n",
            "Epoch: 0350 loss_train: 0.6551 acc_train: 0.8167 loss_val: 0.9903 acc_val: 0.7280 time: 0.0632s\n",
            "108\n",
            "Epoch: 0351 loss_train: 0.7248 acc_train: 0.7250 loss_val: 0.9897 acc_val: 0.7320 time: 0.0653s\n",
            "109\n",
            "Epoch: 0352 loss_train: 0.7497 acc_train: 0.8250 loss_val: 0.9917 acc_val: 0.7300 time: 0.0631s\n",
            "110\n",
            "Epoch: 0353 loss_train: 0.7160 acc_train: 0.8167 loss_val: 0.9934 acc_val: 0.7240 time: 0.0630s\n",
            "111\n",
            "Epoch: 0354 loss_train: 0.7224 acc_train: 0.8417 loss_val: 0.9953 acc_val: 0.7180 time: 0.0676s\n",
            "112\n",
            "Epoch: 0355 loss_train: 0.7638 acc_train: 0.8167 loss_val: 0.9974 acc_val: 0.7160 time: 0.0690s\n",
            "113\n",
            "Epoch: 0356 loss_train: 0.6878 acc_train: 0.7833 loss_val: 0.9976 acc_val: 0.7220 time: 0.0639s\n",
            "114\n",
            "Epoch: 0357 loss_train: 0.6818 acc_train: 0.8250 loss_val: 0.9920 acc_val: 0.7240 time: 0.0636s\n",
            "115\n",
            "Epoch: 0358 loss_train: 0.7619 acc_train: 0.8083 loss_val: 0.9849 acc_val: 0.7300 time: 0.0644s\n",
            "116\n",
            "Epoch: 0359 loss_train: 0.6690 acc_train: 0.8500 loss_val: 0.9797 acc_val: 0.7200 time: 0.0682s\n",
            "117\n",
            "Epoch: 0360 loss_train: 0.6866 acc_train: 0.8333 loss_val: 0.9792 acc_val: 0.7180 time: 0.0677s\n",
            "118\n",
            "Epoch: 0361 loss_train: 0.7431 acc_train: 0.8333 loss_val: 0.9823 acc_val: 0.7200 time: 0.0673s\n",
            "119\n",
            "Epoch: 0362 loss_train: 0.7542 acc_train: 0.7417 loss_val: 0.9832 acc_val: 0.7200 time: 0.0643s\n",
            "120\n",
            "Epoch: 0363 loss_train: 0.7635 acc_train: 0.8333 loss_val: 0.9864 acc_val: 0.7200 time: 0.0633s\n",
            "121\n",
            "Epoch: 0364 loss_train: 0.7520 acc_train: 0.8083 loss_val: 0.9906 acc_val: 0.7220 time: 0.0629s\n",
            "122\n",
            "Epoch: 0365 loss_train: 0.7316 acc_train: 0.7917 loss_val: 0.9967 acc_val: 0.7160 time: 0.0639s\n",
            "123\n",
            "Epoch: 0366 loss_train: 0.7059 acc_train: 0.8167 loss_val: 0.9985 acc_val: 0.7160 time: 0.0661s\n",
            "124\n",
            "Epoch: 0367 loss_train: 0.7147 acc_train: 0.8000 loss_val: 0.9974 acc_val: 0.7200 time: 0.0633s\n",
            "125\n",
            "Epoch: 0368 loss_train: 0.7602 acc_train: 0.8000 loss_val: 0.9958 acc_val: 0.7220 time: 0.0631s\n",
            "126\n",
            "Epoch: 0369 loss_train: 0.7353 acc_train: 0.8250 loss_val: 0.9907 acc_val: 0.7260 time: 0.0648s\n",
            "127\n",
            "Epoch: 0370 loss_train: 0.7807 acc_train: 0.7583 loss_val: 0.9863 acc_val: 0.7280 time: 0.0630s\n",
            "128\n",
            "Epoch: 0371 loss_train: 0.7310 acc_train: 0.8333 loss_val: 0.9822 acc_val: 0.7340 time: 0.0638s\n",
            "129\n",
            "Epoch: 0372 loss_train: 0.7646 acc_train: 0.7583 loss_val: 0.9841 acc_val: 0.7260 time: 0.0653s\n",
            "130\n",
            "Epoch: 0373 loss_train: 0.7407 acc_train: 0.8500 loss_val: 0.9873 acc_val: 0.7240 time: 0.0637s\n",
            "131\n",
            "Epoch: 0374 loss_train: 0.7339 acc_train: 0.7750 loss_val: 0.9932 acc_val: 0.7240 time: 0.0634s\n",
            "132\n",
            "Epoch: 0375 loss_train: 0.7545 acc_train: 0.8500 loss_val: 1.0003 acc_val: 0.7220 time: 0.0633s\n",
            "133\n",
            "Epoch: 0376 loss_train: 0.7107 acc_train: 0.7833 loss_val: 1.0042 acc_val: 0.7200 time: 0.0640s\n",
            "134\n",
            "Epoch: 0377 loss_train: 0.7376 acc_train: 0.8083 loss_val: 1.0078 acc_val: 0.7200 time: 0.0633s\n",
            "135\n",
            "Epoch: 0378 loss_train: 0.6952 acc_train: 0.8167 loss_val: 1.0047 acc_val: 0.7200 time: 0.0631s\n",
            "136\n",
            "Epoch: 0379 loss_train: 0.7548 acc_train: 0.7750 loss_val: 0.9952 acc_val: 0.7220 time: 0.0626s\n",
            "137\n",
            "Epoch: 0380 loss_train: 0.7535 acc_train: 0.8333 loss_val: 0.9872 acc_val: 0.7260 time: 0.0655s\n",
            "138\n",
            "Epoch: 0381 loss_train: 0.7244 acc_train: 0.8417 loss_val: 0.9839 acc_val: 0.7280 time: 0.0677s\n",
            "139\n",
            "Epoch: 0382 loss_train: 0.7197 acc_train: 0.7583 loss_val: 0.9819 acc_val: 0.7300 time: 0.0642s\n",
            "140\n",
            "Epoch: 0383 loss_train: 0.7106 acc_train: 0.8250 loss_val: 0.9779 acc_val: 0.7260 time: 0.0634s\n",
            "141\n",
            "Epoch: 0384 loss_train: 0.7244 acc_train: 0.7750 loss_val: 0.9785 acc_val: 0.7320 time: 0.0652s\n",
            "142\n",
            "Epoch: 0385 loss_train: 0.7559 acc_train: 0.7333 loss_val: 0.9855 acc_val: 0.7300 time: 0.0632s\n",
            "143\n",
            "Epoch: 0386 loss_train: 0.7313 acc_train: 0.8333 loss_val: 0.9897 acc_val: 0.7300 time: 0.0634s\n",
            "144\n",
            "Epoch: 0387 loss_train: 0.7198 acc_train: 0.8250 loss_val: 0.9936 acc_val: 0.7300 time: 0.0641s\n",
            "145\n",
            "Epoch: 0388 loss_train: 0.7241 acc_train: 0.8000 loss_val: 0.9998 acc_val: 0.7300 time: 0.0631s\n",
            "146\n",
            "Epoch: 0389 loss_train: 0.6958 acc_train: 0.7917 loss_val: 1.0043 acc_val: 0.7220 time: 0.0637s\n",
            "147\n",
            "Epoch: 0390 loss_train: 0.7402 acc_train: 0.7417 loss_val: 0.9993 acc_val: 0.7260 time: 0.0637s\n",
            "148\n",
            "Epoch: 0391 loss_train: 0.7070 acc_train: 0.8667 loss_val: 0.9934 acc_val: 0.7260 time: 0.0655s\n",
            "149\n",
            "Epoch: 0392 loss_train: 0.7544 acc_train: 0.7917 loss_val: 0.9901 acc_val: 0.7300 time: 0.0656s\n",
            "150\n",
            "Epoch: 0393 loss_train: 0.6771 acc_train: 0.8167 loss_val: 0.9850 acc_val: 0.7280 time: 0.0633s\n",
            "151\n",
            "Epoch: 0394 loss_train: 0.6789 acc_train: 0.8583 loss_val: 0.9834 acc_val: 0.7340 time: 0.0646s\n",
            "152\n",
            "Epoch: 0395 loss_train: 0.7286 acc_train: 0.8000 loss_val: 0.9845 acc_val: 0.7360 time: 0.0639s\n",
            "153\n",
            "Epoch: 0396 loss_train: 0.7472 acc_train: 0.7917 loss_val: 0.9873 acc_val: 0.7340 time: 0.0633s\n",
            "0\n",
            "Epoch: 0397 loss_train: 0.7308 acc_train: 0.8250 loss_val: 0.9929 acc_val: 0.7360 time: 0.0643s\n",
            "1\n",
            "Epoch: 0398 loss_train: 0.8028 acc_train: 0.8250 loss_val: 1.0007 acc_val: 0.7280 time: 0.0658s\n",
            "0\n",
            "Epoch: 0399 loss_train: 0.6784 acc_train: 0.8583 loss_val: 1.0048 acc_val: 0.7240 time: 0.0638s\n",
            "1\n",
            "Epoch: 0400 loss_train: 0.6633 acc_train: 0.8500 loss_val: 1.0066 acc_val: 0.7240 time: 0.0633s\n",
            "2\n",
            "Epoch: 0401 loss_train: 0.7717 acc_train: 0.8083 loss_val: 1.0051 acc_val: 0.7220 time: 0.0638s\n",
            "3\n",
            "Epoch: 0402 loss_train: 0.7556 acc_train: 0.8083 loss_val: 1.0017 acc_val: 0.7260 time: 0.0657s\n",
            "4\n",
            "Epoch: 0403 loss_train: 0.7547 acc_train: 0.7917 loss_val: 0.9906 acc_val: 0.7260 time: 0.0651s\n",
            "5\n",
            "Epoch: 0404 loss_train: 0.7582 acc_train: 0.8167 loss_val: 0.9850 acc_val: 0.7280 time: 0.0637s\n",
            "6\n",
            "Epoch: 0405 loss_train: 0.6684 acc_train: 0.8083 loss_val: 0.9852 acc_val: 0.7280 time: 0.0637s\n",
            "7\n",
            "Epoch: 0406 loss_train: 0.7867 acc_train: 0.8250 loss_val: 0.9871 acc_val: 0.7280 time: 0.0638s\n",
            "8\n",
            "Epoch: 0407 loss_train: 0.7375 acc_train: 0.8417 loss_val: 0.9953 acc_val: 0.7280 time: 0.0661s\n",
            "9\n",
            "Epoch: 0408 loss_train: 0.7338 acc_train: 0.8000 loss_val: 1.0038 acc_val: 0.7240 time: 0.0631s\n",
            "10\n",
            "Epoch: 0409 loss_train: 0.7219 acc_train: 0.7500 loss_val: 1.0103 acc_val: 0.7220 time: 0.0661s\n",
            "11\n",
            "Epoch: 0410 loss_train: 0.7390 acc_train: 0.7917 loss_val: 1.0085 acc_val: 0.7220 time: 0.0662s\n",
            "12\n",
            "Epoch: 0411 loss_train: 0.6855 acc_train: 0.7833 loss_val: 1.0038 acc_val: 0.7240 time: 0.0631s\n",
            "13\n",
            "Epoch: 0412 loss_train: 0.7833 acc_train: 0.8250 loss_val: 0.9951 acc_val: 0.7220 time: 0.0666s\n",
            "14\n",
            "Epoch: 0413 loss_train: 0.7091 acc_train: 0.8083 loss_val: 0.9850 acc_val: 0.7260 time: 0.0661s\n",
            "15\n",
            "Epoch: 0414 loss_train: 0.6739 acc_train: 0.8250 loss_val: 0.9805 acc_val: 0.7280 time: 0.0650s\n",
            "16\n",
            "Epoch: 0415 loss_train: 0.7661 acc_train: 0.7833 loss_val: 0.9845 acc_val: 0.7280 time: 0.0632s\n",
            "17\n",
            "Epoch: 0416 loss_train: 0.6897 acc_train: 0.8167 loss_val: 0.9945 acc_val: 0.7220 time: 0.0658s\n",
            "18\n",
            "Epoch: 0417 loss_train: 0.7061 acc_train: 0.7917 loss_val: 1.0037 acc_val: 0.7180 time: 0.0631s\n",
            "19\n",
            "Epoch: 0418 loss_train: 0.6860 acc_train: 0.8417 loss_val: 1.0111 acc_val: 0.7160 time: 0.0656s\n",
            "20\n",
            "Epoch: 0419 loss_train: 0.7374 acc_train: 0.8083 loss_val: 1.0155 acc_val: 0.7160 time: 0.0644s\n",
            "21\n",
            "Epoch: 0420 loss_train: 0.7245 acc_train: 0.7917 loss_val: 1.0161 acc_val: 0.7180 time: 0.0663s\n",
            "22\n",
            "Epoch: 0421 loss_train: 0.7408 acc_train: 0.7917 loss_val: 1.0134 acc_val: 0.7160 time: 0.0649s\n",
            "23\n",
            "Epoch: 0422 loss_train: 0.7201 acc_train: 0.8083 loss_val: 1.0025 acc_val: 0.7260 time: 0.0637s\n",
            "24\n",
            "Epoch: 0423 loss_train: 0.7560 acc_train: 0.8167 loss_val: 0.9912 acc_val: 0.7200 time: 0.0652s\n",
            "25\n",
            "Epoch: 0424 loss_train: 0.7672 acc_train: 0.7500 loss_val: 0.9857 acc_val: 0.7240 time: 0.0635s\n",
            "26\n",
            "Epoch: 0425 loss_train: 0.7415 acc_train: 0.8167 loss_val: 0.9827 acc_val: 0.7180 time: 0.0637s\n",
            "27\n",
            "Epoch: 0426 loss_train: 0.7736 acc_train: 0.8167 loss_val: 0.9833 acc_val: 0.7180 time: 0.0633s\n",
            "28\n",
            "Epoch: 0427 loss_train: 0.7107 acc_train: 0.8167 loss_val: 0.9884 acc_val: 0.7180 time: 0.0668s\n",
            "29\n",
            "Epoch: 0428 loss_train: 0.7096 acc_train: 0.8167 loss_val: 0.9940 acc_val: 0.7200 time: 0.0650s\n",
            "30\n",
            "Epoch: 0429 loss_train: 0.7658 acc_train: 0.8167 loss_val: 1.0021 acc_val: 0.7220 time: 0.0638s\n",
            "31\n",
            "Epoch: 0430 loss_train: 0.6802 acc_train: 0.8000 loss_val: 1.0117 acc_val: 0.7180 time: 0.0634s\n",
            "32\n",
            "Epoch: 0431 loss_train: 0.7220 acc_train: 0.8833 loss_val: 1.0225 acc_val: 0.7180 time: 0.0664s\n",
            "33\n",
            "Epoch: 0432 loss_train: 0.7351 acc_train: 0.7833 loss_val: 1.0271 acc_val: 0.7160 time: 0.0644s\n",
            "34\n",
            "Epoch: 0433 loss_train: 0.7503 acc_train: 0.8167 loss_val: 1.0213 acc_val: 0.7180 time: 0.0641s\n",
            "35\n",
            "Epoch: 0434 loss_train: 0.6837 acc_train: 0.8083 loss_val: 1.0106 acc_val: 0.7180 time: 0.0636s\n",
            "36\n",
            "Epoch: 0435 loss_train: 0.7171 acc_train: 0.7583 loss_val: 0.9987 acc_val: 0.7220 time: 0.0643s\n",
            "37\n",
            "Epoch: 0436 loss_train: 0.7551 acc_train: 0.7833 loss_val: 0.9859 acc_val: 0.7240 time: 0.0634s\n",
            "38\n",
            "Epoch: 0437 loss_train: 0.6992 acc_train: 0.8417 loss_val: 0.9781 acc_val: 0.7220 time: 0.0647s\n",
            "39\n",
            "Epoch: 0438 loss_train: 0.7165 acc_train: 0.8083 loss_val: 0.9760 acc_val: 0.7260 time: 0.0664s\n",
            "40\n",
            "Epoch: 0439 loss_train: 0.7451 acc_train: 0.8083 loss_val: 0.9784 acc_val: 0.7240 time: 0.0649s\n",
            "41\n",
            "Epoch: 0440 loss_train: 0.7071 acc_train: 0.7667 loss_val: 0.9836 acc_val: 0.7220 time: 0.0634s\n",
            "42\n",
            "Epoch: 0441 loss_train: 0.7363 acc_train: 0.8250 loss_val: 0.9931 acc_val: 0.7240 time: 0.0635s\n",
            "43\n",
            "Epoch: 0442 loss_train: 0.7490 acc_train: 0.7917 loss_val: 1.0077 acc_val: 0.7220 time: 0.0659s\n",
            "44\n",
            "Epoch: 0443 loss_train: 0.7529 acc_train: 0.8083 loss_val: 1.0143 acc_val: 0.7220 time: 0.0631s\n",
            "45\n",
            "Epoch: 0444 loss_train: 0.7678 acc_train: 0.8083 loss_val: 1.0146 acc_val: 0.7200 time: 0.0652s\n",
            "46\n",
            "Epoch: 0445 loss_train: 0.7118 acc_train: 0.7917 loss_val: 1.0152 acc_val: 0.7140 time: 0.0640s\n",
            "47\n",
            "Epoch: 0446 loss_train: 0.7181 acc_train: 0.8083 loss_val: 1.0109 acc_val: 0.7240 time: 0.0636s\n",
            "48\n",
            "Epoch: 0447 loss_train: 0.6782 acc_train: 0.8583 loss_val: 1.0028 acc_val: 0.7280 time: 0.0635s\n",
            "49\n",
            "Epoch: 0448 loss_train: 0.7351 acc_train: 0.8583 loss_val: 0.9950 acc_val: 0.7200 time: 0.0633s\n",
            "50\n",
            "Epoch: 0449 loss_train: 0.6615 acc_train: 0.8500 loss_val: 0.9870 acc_val: 0.7200 time: 0.0658s\n",
            "51\n",
            "Epoch: 0450 loss_train: 0.7373 acc_train: 0.7917 loss_val: 0.9803 acc_val: 0.7240 time: 0.0643s\n",
            "52\n",
            "Epoch: 0451 loss_train: 0.7194 acc_train: 0.8500 loss_val: 0.9765 acc_val: 0.7300 time: 0.0632s\n",
            "53\n",
            "Epoch: 0452 loss_train: 0.6745 acc_train: 0.8250 loss_val: 0.9749 acc_val: 0.7320 time: 0.0646s\n",
            "54\n",
            "Epoch: 0453 loss_train: 0.7702 acc_train: 0.7833 loss_val: 0.9792 acc_val: 0.7280 time: 0.0635s\n",
            "55\n",
            "Epoch: 0454 loss_train: 0.7301 acc_train: 0.8083 loss_val: 0.9819 acc_val: 0.7260 time: 0.0631s\n",
            "56\n",
            "Epoch: 0455 loss_train: 0.7249 acc_train: 0.7750 loss_val: 0.9883 acc_val: 0.7260 time: 0.0633s\n",
            "57\n",
            "Epoch: 0456 loss_train: 0.7463 acc_train: 0.7917 loss_val: 0.9962 acc_val: 0.7180 time: 0.0640s\n",
            "58\n",
            "Epoch: 0457 loss_train: 0.7761 acc_train: 0.7917 loss_val: 0.9983 acc_val: 0.7180 time: 0.0641s\n",
            "59\n",
            "Epoch: 0458 loss_train: 0.7350 acc_train: 0.7917 loss_val: 0.9961 acc_val: 0.7160 time: 0.0651s\n",
            "60\n",
            "Epoch: 0459 loss_train: 0.7302 acc_train: 0.8333 loss_val: 0.9914 acc_val: 0.7200 time: 0.0642s\n",
            "61\n",
            "Epoch: 0460 loss_train: 0.7235 acc_train: 0.8000 loss_val: 0.9887 acc_val: 0.7240 time: 0.0663s\n",
            "62\n",
            "Epoch: 0461 loss_train: 0.7280 acc_train: 0.8417 loss_val: 0.9917 acc_val: 0.7260 time: 0.0654s\n",
            "63\n",
            "Epoch: 0462 loss_train: 0.7048 acc_train: 0.8000 loss_val: 0.9907 acc_val: 0.7280 time: 0.0633s\n",
            "64\n",
            "Epoch: 0463 loss_train: 0.7346 acc_train: 0.7917 loss_val: 0.9871 acc_val: 0.7260 time: 0.0642s\n",
            "65\n",
            "Epoch: 0464 loss_train: 0.6917 acc_train: 0.8000 loss_val: 0.9835 acc_val: 0.7220 time: 0.0632s\n",
            "66\n",
            "Epoch: 0465 loss_train: 0.7230 acc_train: 0.8083 loss_val: 0.9850 acc_val: 0.7280 time: 0.0652s\n",
            "67\n",
            "Epoch: 0466 loss_train: 0.6908 acc_train: 0.8500 loss_val: 0.9910 acc_val: 0.7280 time: 0.0648s\n",
            "68\n",
            "Epoch: 0467 loss_train: 0.7481 acc_train: 0.7500 loss_val: 0.9958 acc_val: 0.7200 time: 0.0647s\n",
            "69\n",
            "Epoch: 0468 loss_train: 0.7445 acc_train: 0.8083 loss_val: 1.0012 acc_val: 0.7180 time: 0.0636s\n",
            "70\n",
            "Epoch: 0469 loss_train: 0.7365 acc_train: 0.7833 loss_val: 1.0041 acc_val: 0.7160 time: 0.0631s\n",
            "71\n",
            "Epoch: 0470 loss_train: 0.6857 acc_train: 0.8417 loss_val: 1.0043 acc_val: 0.7160 time: 0.0654s\n",
            "72\n",
            "Epoch: 0471 loss_train: 0.7209 acc_train: 0.8167 loss_val: 1.0007 acc_val: 0.7200 time: 0.0654s\n",
            "73\n",
            "Epoch: 0472 loss_train: 0.7635 acc_train: 0.7833 loss_val: 0.9947 acc_val: 0.7180 time: 0.0635s\n",
            "74\n",
            "Epoch: 0473 loss_train: 0.7380 acc_train: 0.7750 loss_val: 0.9918 acc_val: 0.7180 time: 0.0640s\n",
            "75\n",
            "Epoch: 0474 loss_train: 0.7009 acc_train: 0.8417 loss_val: 0.9930 acc_val: 0.7240 time: 0.0658s\n",
            "76\n",
            "Epoch: 0475 loss_train: 0.7093 acc_train: 0.8083 loss_val: 0.9971 acc_val: 0.7260 time: 0.0648s\n",
            "77\n",
            "Epoch: 0476 loss_train: 0.7360 acc_train: 0.7917 loss_val: 0.9988 acc_val: 0.7240 time: 0.0635s\n",
            "78\n",
            "Epoch: 0477 loss_train: 0.6990 acc_train: 0.8250 loss_val: 0.9970 acc_val: 0.7240 time: 0.0651s\n",
            "79\n",
            "Epoch: 0478 loss_train: 0.6705 acc_train: 0.8500 loss_val: 0.9937 acc_val: 0.7240 time: 0.0647s\n",
            "80\n",
            "Epoch: 0479 loss_train: 0.7891 acc_train: 0.7750 loss_val: 0.9837 acc_val: 0.7280 time: 0.0635s\n",
            "81\n",
            "Epoch: 0480 loss_train: 0.7681 acc_train: 0.7667 loss_val: 0.9785 acc_val: 0.7340 time: 0.0634s\n",
            "82\n",
            "Epoch: 0481 loss_train: 0.7392 acc_train: 0.8583 loss_val: 0.9787 acc_val: 0.7320 time: 0.0640s\n",
            "83\n",
            "Epoch: 0482 loss_train: 0.7240 acc_train: 0.7833 loss_val: 0.9834 acc_val: 0.7340 time: 0.0627s\n",
            "84\n",
            "Epoch: 0483 loss_train: 0.7427 acc_train: 0.8250 loss_val: 0.9910 acc_val: 0.7320 time: 0.0641s\n",
            "85\n",
            "Epoch: 0484 loss_train: 0.7939 acc_train: 0.7750 loss_val: 0.9926 acc_val: 0.7280 time: 0.0644s\n",
            "86\n",
            "Epoch: 0485 loss_train: 0.7156 acc_train: 0.8333 loss_val: 0.9931 acc_val: 0.7320 time: 0.0633s\n",
            "87\n",
            "Epoch: 0486 loss_train: 0.6948 acc_train: 0.8417 loss_val: 0.9945 acc_val: 0.7300 time: 0.0630s\n",
            "88\n",
            "Epoch: 0487 loss_train: 0.7078 acc_train: 0.8167 loss_val: 0.9912 acc_val: 0.7360 time: 0.0653s\n",
            "89\n",
            "Epoch: 0488 loss_train: 0.7225 acc_train: 0.8000 loss_val: 0.9861 acc_val: 0.7320 time: 0.0662s\n",
            "0\n",
            "Epoch: 0489 loss_train: 0.7607 acc_train: 0.8167 loss_val: 0.9865 acc_val: 0.7300 time: 0.0635s\n",
            "1\n",
            "Epoch: 0490 loss_train: 0.7507 acc_train: 0.8417 loss_val: 0.9934 acc_val: 0.7280 time: 0.0634s\n",
            "2\n",
            "Epoch: 0491 loss_train: 0.7487 acc_train: 0.7750 loss_val: 0.9937 acc_val: 0.7240 time: 0.0634s\n",
            "3\n",
            "Epoch: 0492 loss_train: 0.7197 acc_train: 0.7917 loss_val: 0.9866 acc_val: 0.7280 time: 0.0652s\n",
            "4\n",
            "Epoch: 0493 loss_train: 0.7338 acc_train: 0.7750 loss_val: 0.9801 acc_val: 0.7300 time: 0.0649s\n",
            "5\n",
            "Epoch: 0494 loss_train: 0.7389 acc_train: 0.7917 loss_val: 0.9755 acc_val: 0.7300 time: 0.0645s\n",
            "6\n",
            "Epoch: 0495 loss_train: 0.7375 acc_train: 0.8250 loss_val: 0.9776 acc_val: 0.7280 time: 0.0634s\n",
            "7\n",
            "Epoch: 0496 loss_train: 0.7578 acc_train: 0.8083 loss_val: 0.9840 acc_val: 0.7260 time: 0.0661s\n",
            "8\n",
            "Epoch: 0497 loss_train: 0.7090 acc_train: 0.8167 loss_val: 0.9942 acc_val: 0.7260 time: 0.0633s\n",
            "9\n",
            "Epoch: 0498 loss_train: 0.7285 acc_train: 0.8333 loss_val: 1.0003 acc_val: 0.7180 time: 0.0635s\n",
            "10\n",
            "Epoch: 0499 loss_train: 0.7299 acc_train: 0.8083 loss_val: 1.0023 acc_val: 0.7160 time: 0.0643s\n",
            "11\n",
            "Epoch: 0500 loss_train: 0.7550 acc_train: 0.7750 loss_val: 1.0017 acc_val: 0.7180 time: 0.0632s\n",
            "12\n",
            "Epoch: 0501 loss_train: 0.7506 acc_train: 0.8167 loss_val: 1.0039 acc_val: 0.7200 time: 0.0630s\n",
            "13\n",
            "Epoch: 0502 loss_train: 0.7342 acc_train: 0.8417 loss_val: 1.0033 acc_val: 0.7160 time: 0.0634s\n",
            "14\n",
            "Epoch: 0503 loss_train: 0.7393 acc_train: 0.7833 loss_val: 0.9948 acc_val: 0.7220 time: 0.0685s\n",
            "15\n",
            "Epoch: 0504 loss_train: 0.6960 acc_train: 0.7917 loss_val: 0.9861 acc_val: 0.7300 time: 0.0668s\n",
            "16\n",
            "Epoch: 0505 loss_train: 0.7206 acc_train: 0.8250 loss_val: 0.9784 acc_val: 0.7300 time: 0.0655s\n",
            "17\n",
            "Epoch: 0506 loss_train: 0.7394 acc_train: 0.8250 loss_val: 0.9722 acc_val: 0.7340 time: 0.0660s\n",
            "18\n",
            "Epoch: 0507 loss_train: 0.7556 acc_train: 0.7833 loss_val: 0.9743 acc_val: 0.7380 time: 0.0637s\n",
            "19\n",
            "Epoch: 0508 loss_train: 0.7474 acc_train: 0.8250 loss_val: 0.9798 acc_val: 0.7340 time: 0.0639s\n",
            "0\n",
            "Epoch: 0509 loss_train: 0.7140 acc_train: 0.8167 loss_val: 0.9875 acc_val: 0.7300 time: 0.0632s\n",
            "1\n",
            "Epoch: 0510 loss_train: 0.7172 acc_train: 0.7833 loss_val: 0.9968 acc_val: 0.7300 time: 0.0653s\n",
            "2\n",
            "Epoch: 0511 loss_train: 0.6850 acc_train: 0.8167 loss_val: 1.0058 acc_val: 0.7220 time: 0.0636s\n",
            "3\n",
            "Epoch: 0512 loss_train: 0.6894 acc_train: 0.8333 loss_val: 1.0169 acc_val: 0.7140 time: 0.0633s\n",
            "4\n",
            "Epoch: 0513 loss_train: 0.6962 acc_train: 0.8667 loss_val: 1.0202 acc_val: 0.7140 time: 0.0633s\n",
            "5\n",
            "Epoch: 0514 loss_train: 0.7737 acc_train: 0.8333 loss_val: 1.0157 acc_val: 0.7240 time: 0.0639s\n",
            "6\n",
            "Epoch: 0515 loss_train: 0.8039 acc_train: 0.7917 loss_val: 1.0063 acc_val: 0.7260 time: 0.0644s\n",
            "7\n",
            "Epoch: 0516 loss_train: 0.7740 acc_train: 0.7417 loss_val: 0.9931 acc_val: 0.7320 time: 0.0648s\n",
            "8\n",
            "Epoch: 0517 loss_train: 0.6991 acc_train: 0.8500 loss_val: 0.9807 acc_val: 0.7340 time: 0.0660s\n",
            "9\n",
            "Epoch: 0518 loss_train: 0.7012 acc_train: 0.8083 loss_val: 0.9742 acc_val: 0.7360 time: 0.0647s\n",
            "10\n",
            "Epoch: 0519 loss_train: 0.7516 acc_train: 0.8000 loss_val: 0.9735 acc_val: 0.7300 time: 0.0643s\n",
            "11\n",
            "Epoch: 0520 loss_train: 0.7110 acc_train: 0.8500 loss_val: 0.9764 acc_val: 0.7300 time: 0.0661s\n",
            "12\n",
            "Epoch: 0521 loss_train: 0.7055 acc_train: 0.8417 loss_val: 0.9812 acc_val: 0.7340 time: 0.0677s\n",
            "13\n",
            "Epoch: 0522 loss_train: 0.7526 acc_train: 0.8083 loss_val: 0.9918 acc_val: 0.7320 time: 0.0647s\n",
            "14\n",
            "Epoch: 0523 loss_train: 0.7674 acc_train: 0.7583 loss_val: 1.0076 acc_val: 0.7260 time: 0.0650s\n",
            "15\n",
            "Epoch: 0524 loss_train: 0.7310 acc_train: 0.8500 loss_val: 1.0173 acc_val: 0.7140 time: 0.0658s\n",
            "16\n",
            "Epoch: 0525 loss_train: 0.7028 acc_train: 0.8750 loss_val: 1.0175 acc_val: 0.7140 time: 0.0657s\n",
            "17\n",
            "Epoch: 0526 loss_train: 0.7165 acc_train: 0.8250 loss_val: 1.0101 acc_val: 0.7200 time: 0.0633s\n",
            "18\n",
            "Epoch: 0527 loss_train: 0.7314 acc_train: 0.8000 loss_val: 0.9999 acc_val: 0.7320 time: 0.0634s\n",
            "19\n",
            "Epoch: 0528 loss_train: 0.6980 acc_train: 0.8417 loss_val: 0.9897 acc_val: 0.7320 time: 0.0710s\n",
            "20\n",
            "Epoch: 0529 loss_train: 0.6715 acc_train: 0.8083 loss_val: 0.9779 acc_val: 0.7340 time: 0.0633s\n",
            "21\n",
            "Epoch: 0530 loss_train: 0.7896 acc_train: 0.7917 loss_val: 0.9728 acc_val: 0.7400 time: 0.0640s\n",
            "22\n",
            "Epoch: 0531 loss_train: 0.7085 acc_train: 0.7917 loss_val: 0.9705 acc_val: 0.7380 time: 0.0633s\n",
            "0\n",
            "Epoch: 0532 loss_train: 0.7203 acc_train: 0.7833 loss_val: 0.9746 acc_val: 0.7400 time: 0.0646s\n",
            "1\n",
            "Epoch: 0533 loss_train: 0.7167 acc_train: 0.8250 loss_val: 0.9831 acc_val: 0.7400 time: 0.0631s\n",
            "0\n",
            "Epoch: 0534 loss_train: 0.7214 acc_train: 0.7667 loss_val: 0.9926 acc_val: 0.7360 time: 0.0638s\n",
            "0\n",
            "Epoch: 0535 loss_train: 0.6828 acc_train: 0.8167 loss_val: 1.0000 acc_val: 0.7240 time: 0.0633s\n",
            "1\n",
            "Epoch: 0536 loss_train: 0.7202 acc_train: 0.7917 loss_val: 1.0047 acc_val: 0.7200 time: 0.0642s\n",
            "2\n",
            "Epoch: 0537 loss_train: 0.6499 acc_train: 0.8250 loss_val: 1.0037 acc_val: 0.7280 time: 0.0632s\n",
            "3\n",
            "Epoch: 0538 loss_train: 0.6586 acc_train: 0.8167 loss_val: 1.0003 acc_val: 0.7280 time: 0.0658s\n",
            "4\n",
            "Epoch: 0539 loss_train: 0.6882 acc_train: 0.8583 loss_val: 0.9972 acc_val: 0.7200 time: 0.0653s\n",
            "5\n",
            "Epoch: 0540 loss_train: 0.7579 acc_train: 0.7917 loss_val: 0.9937 acc_val: 0.7240 time: 0.0647s\n",
            "6\n",
            "Epoch: 0541 loss_train: 0.7527 acc_train: 0.7833 loss_val: 0.9892 acc_val: 0.7240 time: 0.0631s\n",
            "7\n",
            "Epoch: 0542 loss_train: 0.7236 acc_train: 0.8000 loss_val: 0.9863 acc_val: 0.7240 time: 0.0633s\n",
            "8\n",
            "Epoch: 0543 loss_train: 0.7528 acc_train: 0.7917 loss_val: 0.9839 acc_val: 0.7260 time: 0.0667s\n",
            "9\n",
            "Epoch: 0544 loss_train: 0.7026 acc_train: 0.8417 loss_val: 0.9845 acc_val: 0.7300 time: 0.0634s\n",
            "10\n",
            "Epoch: 0545 loss_train: 0.7054 acc_train: 0.8250 loss_val: 0.9923 acc_val: 0.7240 time: 0.0641s\n",
            "11\n",
            "Epoch: 0546 loss_train: 0.6932 acc_train: 0.8583 loss_val: 0.9978 acc_val: 0.7220 time: 0.0634s\n",
            "12\n",
            "Epoch: 0547 loss_train: 0.6546 acc_train: 0.8500 loss_val: 1.0029 acc_val: 0.7180 time: 0.0673s\n",
            "13\n",
            "Epoch: 0548 loss_train: 0.6643 acc_train: 0.7583 loss_val: 1.0052 acc_val: 0.7180 time: 0.0637s\n",
            "14\n",
            "Epoch: 0549 loss_train: 0.7136 acc_train: 0.7833 loss_val: 1.0017 acc_val: 0.7200 time: 0.0651s\n",
            "15\n",
            "Epoch: 0550 loss_train: 0.7046 acc_train: 0.7583 loss_val: 1.0008 acc_val: 0.7240 time: 0.0637s\n",
            "16\n",
            "Epoch: 0551 loss_train: 0.6826 acc_train: 0.8250 loss_val: 0.9989 acc_val: 0.7220 time: 0.0642s\n",
            "17\n",
            "Epoch: 0552 loss_train: 0.6474 acc_train: 0.8750 loss_val: 0.9988 acc_val: 0.7200 time: 0.0633s\n",
            "18\n",
            "Epoch: 0553 loss_train: 0.7185 acc_train: 0.7917 loss_val: 0.9965 acc_val: 0.7240 time: 0.0633s\n",
            "19\n",
            "Epoch: 0554 loss_train: 0.7350 acc_train: 0.8333 loss_val: 0.9908 acc_val: 0.7240 time: 0.0682s\n",
            "20\n",
            "Epoch: 0555 loss_train: 0.7569 acc_train: 0.8250 loss_val: 0.9892 acc_val: 0.7260 time: 0.0646s\n",
            "21\n",
            "Epoch: 0556 loss_train: 0.7464 acc_train: 0.7917 loss_val: 0.9933 acc_val: 0.7220 time: 0.0632s\n",
            "22\n",
            "Epoch: 0557 loss_train: 0.7040 acc_train: 0.8833 loss_val: 0.9979 acc_val: 0.7180 time: 0.0644s\n",
            "23\n",
            "Epoch: 0558 loss_train: 0.7216 acc_train: 0.8083 loss_val: 1.0010 acc_val: 0.7200 time: 0.0652s\n",
            "24\n",
            "Epoch: 0559 loss_train: 0.7204 acc_train: 0.8250 loss_val: 1.0010 acc_val: 0.7220 time: 0.0632s\n",
            "25\n",
            "Epoch: 0560 loss_train: 0.7760 acc_train: 0.7250 loss_val: 1.0034 acc_val: 0.7220 time: 0.0633s\n",
            "26\n",
            "Epoch: 0561 loss_train: 0.7628 acc_train: 0.7917 loss_val: 1.0033 acc_val: 0.7220 time: 0.0651s\n",
            "27\n",
            "Epoch: 0562 loss_train: 0.7334 acc_train: 0.8583 loss_val: 1.0039 acc_val: 0.7160 time: 0.0634s\n",
            "28\n",
            "Epoch: 0563 loss_train: 0.7660 acc_train: 0.7917 loss_val: 1.0037 acc_val: 0.7220 time: 0.0631s\n",
            "29\n",
            "Epoch: 0564 loss_train: 0.6775 acc_train: 0.8167 loss_val: 1.0041 acc_val: 0.7200 time: 0.0664s\n",
            "30\n",
            "Epoch: 0565 loss_train: 0.7293 acc_train: 0.7750 loss_val: 0.9999 acc_val: 0.7200 time: 0.0660s\n",
            "31\n",
            "Epoch: 0566 loss_train: 0.6930 acc_train: 0.7750 loss_val: 0.9944 acc_val: 0.7220 time: 0.0644s\n",
            "32\n",
            "Epoch: 0567 loss_train: 0.7614 acc_train: 0.8250 loss_val: 0.9902 acc_val: 0.7240 time: 0.0645s\n",
            "33\n",
            "Epoch: 0568 loss_train: 0.7302 acc_train: 0.7917 loss_val: 0.9906 acc_val: 0.7280 time: 0.0655s\n",
            "34\n",
            "Epoch: 0569 loss_train: 0.7039 acc_train: 0.7583 loss_val: 0.9925 acc_val: 0.7260 time: 0.0646s\n",
            "35\n",
            "Epoch: 0570 loss_train: 0.7189 acc_train: 0.8167 loss_val: 0.9917 acc_val: 0.7260 time: 0.0633s\n",
            "36\n",
            "Epoch: 0571 loss_train: 0.7225 acc_train: 0.8167 loss_val: 0.9904 acc_val: 0.7260 time: 0.0632s\n",
            "37\n",
            "Epoch: 0572 loss_train: 0.7047 acc_train: 0.8417 loss_val: 0.9886 acc_val: 0.7260 time: 0.0647s\n",
            "38\n",
            "Epoch: 0573 loss_train: 0.8105 acc_train: 0.7833 loss_val: 0.9884 acc_val: 0.7280 time: 0.0634s\n",
            "39\n",
            "Epoch: 0574 loss_train: 0.7071 acc_train: 0.8333 loss_val: 0.9930 acc_val: 0.7220 time: 0.0647s\n",
            "40\n",
            "Epoch: 0575 loss_train: 0.7049 acc_train: 0.8250 loss_val: 0.9921 acc_val: 0.7280 time: 0.0682s\n",
            "41\n",
            "Epoch: 0576 loss_train: 0.7340 acc_train: 0.7333 loss_val: 0.9962 acc_val: 0.7280 time: 0.0664s\n",
            "42\n",
            "Epoch: 0577 loss_train: 0.7168 acc_train: 0.8083 loss_val: 1.0008 acc_val: 0.7200 time: 0.0642s\n",
            "43\n",
            "Epoch: 0578 loss_train: 0.6559 acc_train: 0.8750 loss_val: 0.9971 acc_val: 0.7220 time: 0.0633s\n",
            "44\n",
            "Epoch: 0579 loss_train: 0.7531 acc_train: 0.8167 loss_val: 0.9989 acc_val: 0.7260 time: 0.0663s\n",
            "45\n",
            "Epoch: 0580 loss_train: 0.7176 acc_train: 0.8583 loss_val: 1.0030 acc_val: 0.7220 time: 0.0643s\n",
            "46\n",
            "Epoch: 0581 loss_train: 0.7225 acc_train: 0.7583 loss_val: 1.0048 acc_val: 0.7240 time: 0.0642s\n",
            "47\n",
            "Epoch: 0582 loss_train: 0.8156 acc_train: 0.7667 loss_val: 1.0062 acc_val: 0.7200 time: 0.0637s\n",
            "48\n",
            "Epoch: 0583 loss_train: 0.7395 acc_train: 0.8417 loss_val: 1.0041 acc_val: 0.7220 time: 0.0647s\n",
            "49\n",
            "Epoch: 0584 loss_train: 0.7402 acc_train: 0.8250 loss_val: 0.9967 acc_val: 0.7240 time: 0.0647s\n",
            "50\n",
            "Epoch: 0585 loss_train: 0.7225 acc_train: 0.8083 loss_val: 0.9923 acc_val: 0.7240 time: 0.0637s\n",
            "51\n",
            "Epoch: 0586 loss_train: 0.7008 acc_train: 0.8000 loss_val: 0.9895 acc_val: 0.7260 time: 0.0653s\n",
            "52\n",
            "Epoch: 0587 loss_train: 0.7543 acc_train: 0.7083 loss_val: 0.9906 acc_val: 0.7240 time: 0.0631s\n",
            "53\n",
            "Epoch: 0588 loss_train: 0.7626 acc_train: 0.8333 loss_val: 0.9939 acc_val: 0.7220 time: 0.0634s\n",
            "54\n",
            "Epoch: 0589 loss_train: 0.6836 acc_train: 0.8167 loss_val: 0.9947 acc_val: 0.7260 time: 0.0634s\n",
            "55\n",
            "Epoch: 0590 loss_train: 0.6861 acc_train: 0.8000 loss_val: 0.9967 acc_val: 0.7260 time: 0.0653s\n",
            "56\n",
            "Epoch: 0591 loss_train: 0.7076 acc_train: 0.8083 loss_val: 0.9972 acc_val: 0.7220 time: 0.0646s\n",
            "57\n",
            "Epoch: 0592 loss_train: 0.7354 acc_train: 0.8167 loss_val: 0.9991 acc_val: 0.7240 time: 0.0646s\n",
            "58\n",
            "Epoch: 0593 loss_train: 0.7230 acc_train: 0.8167 loss_val: 1.0027 acc_val: 0.7260 time: 0.0653s\n",
            "59\n",
            "Epoch: 0594 loss_train: 0.7470 acc_train: 0.8167 loss_val: 1.0091 acc_val: 0.7240 time: 0.0684s\n",
            "60\n",
            "Epoch: 0595 loss_train: 0.7437 acc_train: 0.7750 loss_val: 1.0084 acc_val: 0.7220 time: 0.0640s\n",
            "61\n",
            "Epoch: 0596 loss_train: 0.7715 acc_train: 0.8083 loss_val: 1.0042 acc_val: 0.7220 time: 0.0634s\n",
            "62\n",
            "Epoch: 0597 loss_train: 0.7177 acc_train: 0.8000 loss_val: 0.9976 acc_val: 0.7180 time: 0.0642s\n",
            "63\n",
            "Epoch: 0598 loss_train: 0.7345 acc_train: 0.8167 loss_val: 0.9977 acc_val: 0.7160 time: 0.0642s\n",
            "64\n",
            "Epoch: 0599 loss_train: 0.7207 acc_train: 0.8250 loss_val: 1.0045 acc_val: 0.7160 time: 0.0632s\n",
            "65\n",
            "Epoch: 0600 loss_train: 0.7382 acc_train: 0.7750 loss_val: 1.0079 acc_val: 0.7220 time: 0.0640s\n",
            "66\n",
            "Epoch: 0601 loss_train: 0.7204 acc_train: 0.7917 loss_val: 1.0056 acc_val: 0.7200 time: 0.0638s\n",
            "67\n",
            "Epoch: 0602 loss_train: 0.7005 acc_train: 0.8083 loss_val: 0.9989 acc_val: 0.7240 time: 0.0633s\n",
            "68\n",
            "Epoch: 0603 loss_train: 0.7231 acc_train: 0.8333 loss_val: 0.9906 acc_val: 0.7220 time: 0.0632s\n",
            "69\n",
            "Epoch: 0604 loss_train: 0.7020 acc_train: 0.8250 loss_val: 0.9875 acc_val: 0.7320 time: 0.0641s\n",
            "70\n",
            "Epoch: 0605 loss_train: 0.7900 acc_train: 0.7500 loss_val: 0.9868 acc_val: 0.7340 time: 0.0631s\n",
            "71\n",
            "Epoch: 0606 loss_train: 0.6624 acc_train: 0.8667 loss_val: 0.9895 acc_val: 0.7320 time: 0.0632s\n",
            "72\n",
            "Epoch: 0607 loss_train: 0.8079 acc_train: 0.7583 loss_val: 0.9918 acc_val: 0.7280 time: 0.0660s\n",
            "73\n",
            "Epoch: 0608 loss_train: 0.7113 acc_train: 0.8333 loss_val: 0.9949 acc_val: 0.7260 time: 0.0677s\n",
            "74\n",
            "Epoch: 0609 loss_train: 0.6976 acc_train: 0.8333 loss_val: 0.9968 acc_val: 0.7200 time: 0.0666s\n",
            "75\n",
            "Epoch: 0610 loss_train: 0.6957 acc_train: 0.8417 loss_val: 0.9994 acc_val: 0.7160 time: 0.0667s\n",
            "76\n",
            "Epoch: 0611 loss_train: 0.7238 acc_train: 0.8250 loss_val: 0.9989 acc_val: 0.7180 time: 0.0670s\n",
            "77\n",
            "Epoch: 0612 loss_train: 0.6948 acc_train: 0.8167 loss_val: 0.9958 acc_val: 0.7220 time: 0.0642s\n",
            "78\n",
            "Epoch: 0613 loss_train: 0.6998 acc_train: 0.8083 loss_val: 0.9930 acc_val: 0.7220 time: 0.0642s\n",
            "79\n",
            "Epoch: 0614 loss_train: 0.7276 acc_train: 0.7833 loss_val: 0.9914 acc_val: 0.7260 time: 0.0635s\n",
            "80\n",
            "Epoch: 0615 loss_train: 0.7922 acc_train: 0.7833 loss_val: 0.9891 acc_val: 0.7220 time: 0.0664s\n",
            "81\n",
            "Epoch: 0616 loss_train: 0.6987 acc_train: 0.8083 loss_val: 0.9893 acc_val: 0.7240 time: 0.0653s\n",
            "82\n",
            "Epoch: 0617 loss_train: 0.7356 acc_train: 0.8000 loss_val: 0.9919 acc_val: 0.7220 time: 0.0654s\n",
            "83\n",
            "Epoch: 0618 loss_train: 0.7391 acc_train: 0.7500 loss_val: 0.9932 acc_val: 0.7200 time: 0.0644s\n",
            "84\n",
            "Epoch: 0619 loss_train: 0.6958 acc_train: 0.8333 loss_val: 0.9894 acc_val: 0.7220 time: 0.0652s\n",
            "85\n",
            "Epoch: 0620 loss_train: 0.7373 acc_train: 0.8083 loss_val: 0.9828 acc_val: 0.7220 time: 0.0646s\n",
            "86\n",
            "Epoch: 0621 loss_train: 0.6995 acc_train: 0.8417 loss_val: 0.9810 acc_val: 0.7280 time: 0.0634s\n",
            "87\n",
            "Epoch: 0622 loss_train: 0.7184 acc_train: 0.8417 loss_val: 0.9793 acc_val: 0.7280 time: 0.0650s\n",
            "88\n",
            "Epoch: 0623 loss_train: 0.7119 acc_train: 0.7833 loss_val: 0.9828 acc_val: 0.7220 time: 0.0631s\n",
            "89\n",
            "Epoch: 0624 loss_train: 0.7326 acc_train: 0.8000 loss_val: 0.9904 acc_val: 0.7180 time: 0.0636s\n",
            "90\n",
            "Epoch: 0625 loss_train: 0.7522 acc_train: 0.8250 loss_val: 0.9969 acc_val: 0.7200 time: 0.0658s\n",
            "91\n",
            "Epoch: 0626 loss_train: 0.6838 acc_train: 0.8000 loss_val: 1.0058 acc_val: 0.7160 time: 0.0635s\n",
            "92\n",
            "Epoch: 0627 loss_train: 0.7151 acc_train: 0.8250 loss_val: 1.0089 acc_val: 0.7200 time: 0.0632s\n",
            "93\n",
            "Epoch: 0628 loss_train: 0.6896 acc_train: 0.8167 loss_val: 1.0048 acc_val: 0.7200 time: 0.0632s\n",
            "94\n",
            "Epoch: 0629 loss_train: 0.7478 acc_train: 0.8000 loss_val: 0.9991 acc_val: 0.7220 time: 0.0642s\n",
            "95\n",
            "Epoch: 0630 loss_train: 0.7495 acc_train: 0.7667 loss_val: 0.9882 acc_val: 0.7240 time: 0.0660s\n",
            "96\n",
            "Epoch: 0631 loss_train: 0.7004 acc_train: 0.8500 loss_val: 0.9801 acc_val: 0.7240 time: 0.0634s\n",
            "97\n",
            "Epoch: 0632 loss_train: 0.7278 acc_train: 0.8083 loss_val: 0.9784 acc_val: 0.7260 time: 0.0631s\n",
            "98\n",
            "Epoch: 0633 loss_train: 0.7322 acc_train: 0.8250 loss_val: 0.9813 acc_val: 0.7280 time: 0.0647s\n",
            "99\n",
            "Epoch: 0634 loss_train: 0.6746 acc_train: 0.8250 loss_val: 0.9869 acc_val: 0.7220 time: 0.0631s\n",
            "100\n",
            "Epoch: 0635 loss_train: 0.6992 acc_train: 0.8000 loss_val: 0.9931 acc_val: 0.7220 time: 0.0635s\n",
            "101\n",
            "Epoch: 0636 loss_train: 0.7384 acc_train: 0.7583 loss_val: 0.9963 acc_val: 0.7220 time: 0.0651s\n",
            "102\n",
            "Epoch: 0637 loss_train: 0.8036 acc_train: 0.7583 loss_val: 1.0002 acc_val: 0.7220 time: 0.0648s\n",
            "103\n",
            "Epoch: 0638 loss_train: 0.6858 acc_train: 0.7833 loss_val: 0.9984 acc_val: 0.7240 time: 0.0639s\n",
            "104\n",
            "Epoch: 0639 loss_train: 0.7239 acc_train: 0.8583 loss_val: 0.9972 acc_val: 0.7240 time: 0.0637s\n",
            "105\n",
            "Epoch: 0640 loss_train: 0.7129 acc_train: 0.7917 loss_val: 0.9933 acc_val: 0.7220 time: 0.0651s\n",
            "106\n",
            "Epoch: 0641 loss_train: 0.6895 acc_train: 0.8000 loss_val: 0.9865 acc_val: 0.7260 time: 0.0643s\n",
            "107\n",
            "Epoch: 0642 loss_train: 0.7320 acc_train: 0.7917 loss_val: 0.9821 acc_val: 0.7200 time: 0.0644s\n",
            "108\n",
            "Epoch: 0643 loss_train: 0.7073 acc_train: 0.8083 loss_val: 0.9873 acc_val: 0.7200 time: 0.0654s\n",
            "109\n",
            "Epoch: 0644 loss_train: 0.7071 acc_train: 0.8083 loss_val: 0.9894 acc_val: 0.7240 time: 0.0642s\n",
            "110\n",
            "Epoch: 0645 loss_train: 0.7568 acc_train: 0.7917 loss_val: 0.9914 acc_val: 0.7220 time: 0.0639s\n",
            "111\n",
            "Epoch: 0646 loss_train: 0.7429 acc_train: 0.8000 loss_val: 0.9958 acc_val: 0.7180 time: 0.0632s\n",
            "112\n",
            "Epoch: 0647 loss_train: 0.7347 acc_train: 0.8333 loss_val: 1.0018 acc_val: 0.7120 time: 0.0644s\n",
            "113\n",
            "Epoch: 0648 loss_train: 0.7270 acc_train: 0.7833 loss_val: 1.0088 acc_val: 0.7040 time: 0.0631s\n",
            "114\n",
            "Epoch: 0649 loss_train: 0.7412 acc_train: 0.8000 loss_val: 1.0094 acc_val: 0.7120 time: 0.0630s\n",
            "115\n",
            "Epoch: 0650 loss_train: 0.6615 acc_train: 0.8167 loss_val: 1.0010 acc_val: 0.7140 time: 0.0651s\n",
            "116\n",
            "Epoch: 0651 loss_train: 0.7394 acc_train: 0.8500 loss_val: 0.9906 acc_val: 0.7140 time: 0.0633s\n",
            "117\n",
            "Epoch: 0652 loss_train: 0.7249 acc_train: 0.8333 loss_val: 0.9830 acc_val: 0.7220 time: 0.0632s\n",
            "118\n",
            "Epoch: 0653 loss_train: 0.7534 acc_train: 0.7417 loss_val: 0.9842 acc_val: 0.7260 time: 0.0641s\n",
            "119\n",
            "Epoch: 0654 loss_train: 0.7450 acc_train: 0.7500 loss_val: 0.9894 acc_val: 0.7200 time: 0.0655s\n",
            "120\n",
            "Epoch: 0655 loss_train: 0.7124 acc_train: 0.8250 loss_val: 0.9958 acc_val: 0.7200 time: 0.0676s\n",
            "121\n",
            "Epoch: 0656 loss_train: 0.6932 acc_train: 0.8333 loss_val: 1.0021 acc_val: 0.7160 time: 0.0659s\n",
            "122\n",
            "Epoch: 0657 loss_train: 0.6926 acc_train: 0.8167 loss_val: 1.0083 acc_val: 0.7180 time: 0.0633s\n",
            "123\n",
            "Epoch: 0658 loss_train: 0.8136 acc_train: 0.7583 loss_val: 1.0063 acc_val: 0.7180 time: 0.0640s\n",
            "124\n",
            "Epoch: 0659 loss_train: 0.7373 acc_train: 0.7667 loss_val: 0.9969 acc_val: 0.7240 time: 0.0644s\n",
            "125\n",
            "Epoch: 0660 loss_train: 0.7266 acc_train: 0.8250 loss_val: 0.9850 acc_val: 0.7300 time: 0.0634s\n",
            "126\n",
            "Epoch: 0661 loss_train: 0.7480 acc_train: 0.7583 loss_val: 0.9791 acc_val: 0.7260 time: 0.0657s\n",
            "127\n",
            "Epoch: 0662 loss_train: 0.6829 acc_train: 0.7833 loss_val: 0.9789 acc_val: 0.7200 time: 0.0650s\n",
            "128\n",
            "Epoch: 0663 loss_train: 0.6591 acc_train: 0.8667 loss_val: 0.9820 acc_val: 0.7200 time: 0.0649s\n",
            "129\n",
            "Epoch: 0664 loss_train: 0.7532 acc_train: 0.8250 loss_val: 0.9859 acc_val: 0.7160 time: 0.0654s\n",
            "130\n",
            "Epoch: 0665 loss_train: 0.7679 acc_train: 0.8000 loss_val: 0.9942 acc_val: 0.7160 time: 0.0642s\n",
            "131\n",
            "Epoch: 0666 loss_train: 0.7584 acc_train: 0.7333 loss_val: 1.0026 acc_val: 0.7140 time: 0.0654s\n",
            "132\n",
            "Epoch: 0667 loss_train: 0.6954 acc_train: 0.7917 loss_val: 1.0031 acc_val: 0.7200 time: 0.0628s\n",
            "133\n",
            "Epoch: 0668 loss_train: 0.7769 acc_train: 0.7417 loss_val: 1.0024 acc_val: 0.7160 time: 0.0638s\n",
            "134\n",
            "Epoch: 0669 loss_train: 0.7042 acc_train: 0.8250 loss_val: 0.9977 acc_val: 0.7220 time: 0.0640s\n",
            "135\n",
            "Epoch: 0670 loss_train: 0.7015 acc_train: 0.9250 loss_val: 0.9893 acc_val: 0.7280 time: 0.0701s\n",
            "136\n",
            "Epoch: 0671 loss_train: 0.7150 acc_train: 0.8333 loss_val: 0.9798 acc_val: 0.7260 time: 0.0649s\n",
            "137\n",
            "Epoch: 0672 loss_train: 0.7609 acc_train: 0.7833 loss_val: 0.9772 acc_val: 0.7200 time: 0.0636s\n",
            "138\n",
            "Epoch: 0673 loss_train: 0.7733 acc_train: 0.7833 loss_val: 0.9792 acc_val: 0.7180 time: 0.0633s\n",
            "139\n",
            "Epoch: 0674 loss_train: 0.7657 acc_train: 0.8167 loss_val: 0.9849 acc_val: 0.7160 time: 0.0634s\n",
            "140\n",
            "Epoch: 0675 loss_train: 0.6952 acc_train: 0.8083 loss_val: 0.9927 acc_val: 0.7120 time: 0.0648s\n",
            "141\n",
            "Epoch: 0676 loss_train: 0.7934 acc_train: 0.7500 loss_val: 0.9948 acc_val: 0.7120 time: 0.0650s\n",
            "142\n",
            "Epoch: 0677 loss_train: 0.7640 acc_train: 0.7750 loss_val: 0.9953 acc_val: 0.7160 time: 0.0646s\n",
            "143\n",
            "Epoch: 0678 loss_train: 0.7312 acc_train: 0.8000 loss_val: 0.9939 acc_val: 0.7180 time: 0.0634s\n",
            "144\n",
            "Epoch: 0679 loss_train: 0.6925 acc_train: 0.7833 loss_val: 0.9925 acc_val: 0.7200 time: 0.0663s\n",
            "145\n",
            "Epoch: 0680 loss_train: 0.7493 acc_train: 0.8000 loss_val: 0.9925 acc_val: 0.7180 time: 0.0678s\n",
            "146\n",
            "Epoch: 0681 loss_train: 0.6789 acc_train: 0.8083 loss_val: 0.9930 acc_val: 0.7240 time: 0.0646s\n",
            "147\n",
            "Epoch: 0682 loss_train: 0.7824 acc_train: 0.8417 loss_val: 0.9951 acc_val: 0.7180 time: 0.0642s\n",
            "148\n",
            "Epoch: 0683 loss_train: 0.7812 acc_train: 0.7750 loss_val: 0.9979 acc_val: 0.7160 time: 0.0643s\n",
            "149\n",
            "Epoch: 0684 loss_train: 0.7608 acc_train: 0.8000 loss_val: 1.0041 acc_val: 0.7180 time: 0.0633s\n",
            "150\n",
            "Epoch: 0685 loss_train: 0.7339 acc_train: 0.8667 loss_val: 1.0092 acc_val: 0.7140 time: 0.0642s\n",
            "151\n",
            "Epoch: 0686 loss_train: 0.7469 acc_train: 0.7750 loss_val: 1.0124 acc_val: 0.7160 time: 0.0657s\n",
            "152\n",
            "Epoch: 0687 loss_train: 0.6810 acc_train: 0.8167 loss_val: 1.0102 acc_val: 0.7100 time: 0.0646s\n",
            "153\n",
            "Epoch: 0688 loss_train: 0.7483 acc_train: 0.7500 loss_val: 1.0064 acc_val: 0.7060 time: 0.0655s\n",
            "154\n",
            "Epoch: 0689 loss_train: 0.7217 acc_train: 0.8333 loss_val: 1.0013 acc_val: 0.7080 time: 0.0653s\n",
            "155\n",
            "Epoch: 0690 loss_train: 0.7326 acc_train: 0.8250 loss_val: 0.9938 acc_val: 0.7240 time: 0.0634s\n",
            "156\n",
            "Epoch: 0691 loss_train: 0.7210 acc_train: 0.8167 loss_val: 0.9917 acc_val: 0.7280 time: 0.0634s\n",
            "157\n",
            "Epoch: 0692 loss_train: 0.7263 acc_train: 0.8417 loss_val: 0.9885 acc_val: 0.7220 time: 0.0635s\n",
            "158\n",
            "Epoch: 0693 loss_train: 0.7369 acc_train: 0.8417 loss_val: 0.9886 acc_val: 0.7240 time: 0.0644s\n",
            "159\n",
            "Epoch: 0694 loss_train: 0.7382 acc_train: 0.7917 loss_val: 0.9863 acc_val: 0.7260 time: 0.0633s\n",
            "160\n",
            "Epoch: 0695 loss_train: 0.7105 acc_train: 0.8333 loss_val: 0.9853 acc_val: 0.7220 time: 0.0636s\n",
            "161\n",
            "Epoch: 0696 loss_train: 0.8478 acc_train: 0.7667 loss_val: 0.9880 acc_val: 0.7200 time: 0.0644s\n",
            "162\n",
            "Epoch: 0697 loss_train: 0.7312 acc_train: 0.8083 loss_val: 1.0000 acc_val: 0.7160 time: 0.0644s\n",
            "163\n",
            "Epoch: 0698 loss_train: 0.7548 acc_train: 0.7500 loss_val: 1.0181 acc_val: 0.7080 time: 0.0636s\n",
            "164\n",
            "Epoch: 0699 loss_train: 0.7538 acc_train: 0.7917 loss_val: 1.0299 acc_val: 0.7040 time: 0.0635s\n",
            "165\n",
            "Epoch: 0700 loss_train: 0.7400 acc_train: 0.8083 loss_val: 1.0331 acc_val: 0.7040 time: 0.0646s\n",
            "166\n",
            "Epoch: 0701 loss_train: 0.7859 acc_train: 0.7667 loss_val: 1.0212 acc_val: 0.7060 time: 0.0665s\n",
            "167\n",
            "Epoch: 0702 loss_train: 0.7177 acc_train: 0.7417 loss_val: 1.0096 acc_val: 0.7180 time: 0.0633s\n",
            "168\n",
            "Epoch: 0703 loss_train: 0.7961 acc_train: 0.8000 loss_val: 0.9963 acc_val: 0.7240 time: 0.0628s\n",
            "169\n",
            "Epoch: 0704 loss_train: 0.7309 acc_train: 0.7833 loss_val: 0.9880 acc_val: 0.7220 time: 0.0698s\n",
            "170\n",
            "Epoch: 0705 loss_train: 0.7182 acc_train: 0.8333 loss_val: 0.9835 acc_val: 0.7220 time: 0.0650s\n",
            "171\n",
            "Epoch: 0706 loss_train: 0.7598 acc_train: 0.8333 loss_val: 0.9827 acc_val: 0.7240 time: 0.0636s\n",
            "172\n",
            "Epoch: 0707 loss_train: 0.7307 acc_train: 0.8250 loss_val: 0.9798 acc_val: 0.7220 time: 0.0642s\n",
            "173\n",
            "Epoch: 0708 loss_train: 0.6623 acc_train: 0.8250 loss_val: 0.9820 acc_val: 0.7260 time: 0.0632s\n",
            "174\n",
            "Epoch: 0709 loss_train: 0.7101 acc_train: 0.7833 loss_val: 0.9896 acc_val: 0.7340 time: 0.0632s\n",
            "175\n",
            "Epoch: 0710 loss_train: 0.7213 acc_train: 0.8250 loss_val: 1.0037 acc_val: 0.7300 time: 0.0635s\n",
            "176\n",
            "Epoch: 0711 loss_train: 0.7455 acc_train: 0.7833 loss_val: 1.0193 acc_val: 0.7120 time: 0.0655s\n",
            "177\n",
            "Epoch: 0712 loss_train: 0.7078 acc_train: 0.8250 loss_val: 1.0296 acc_val: 0.7040 time: 0.0646s\n",
            "178\n",
            "Epoch: 0713 loss_train: 0.7407 acc_train: 0.8000 loss_val: 1.0264 acc_val: 0.7040 time: 0.0632s\n",
            "179\n",
            "Epoch: 0714 loss_train: 0.7619 acc_train: 0.7333 loss_val: 1.0104 acc_val: 0.7160 time: 0.0634s\n",
            "180\n",
            "Epoch: 0715 loss_train: 0.7026 acc_train: 0.8750 loss_val: 0.9927 acc_val: 0.7240 time: 0.0649s\n",
            "181\n",
            "Epoch: 0716 loss_train: 0.7052 acc_train: 0.7667 loss_val: 0.9807 acc_val: 0.7240 time: 0.0650s\n",
            "182\n",
            "Epoch: 0717 loss_train: 0.6960 acc_train: 0.8167 loss_val: 0.9783 acc_val: 0.7240 time: 0.0633s\n",
            "183\n",
            "Epoch: 0718 loss_train: 0.7264 acc_train: 0.8417 loss_val: 0.9816 acc_val: 0.7220 time: 0.0634s\n",
            "184\n",
            "Epoch: 0719 loss_train: 0.7434 acc_train: 0.7917 loss_val: 0.9913 acc_val: 0.7160 time: 0.0646s\n",
            "185\n",
            "Epoch: 0720 loss_train: 0.6843 acc_train: 0.8667 loss_val: 1.0036 acc_val: 0.7180 time: 0.0632s\n",
            "186\n",
            "Epoch: 0721 loss_train: 0.7315 acc_train: 0.8167 loss_val: 1.0137 acc_val: 0.7160 time: 0.0632s\n",
            "187\n",
            "Epoch: 0722 loss_train: 0.7639 acc_train: 0.8083 loss_val: 1.0225 acc_val: 0.7100 time: 0.0659s\n",
            "188\n",
            "Epoch: 0723 loss_train: 0.7235 acc_train: 0.8333 loss_val: 1.0232 acc_val: 0.7060 time: 0.0675s\n",
            "189\n",
            "Epoch: 0724 loss_train: 0.7193 acc_train: 0.8083 loss_val: 1.0120 acc_val: 0.7140 time: 0.0637s\n",
            "190\n",
            "Epoch: 0725 loss_train: 0.7564 acc_train: 0.8250 loss_val: 0.9940 acc_val: 0.7160 time: 0.0634s\n",
            "191\n",
            "Epoch: 0726 loss_train: 0.7464 acc_train: 0.7667 loss_val: 0.9776 acc_val: 0.7240 time: 0.0650s\n",
            "192\n",
            "Epoch: 0727 loss_train: 0.7172 acc_train: 0.8500 loss_val: 0.9703 acc_val: 0.7260 time: 0.0647s\n",
            "193\n",
            "Epoch: 0728 loss_train: 0.7248 acc_train: 0.8000 loss_val: 0.9667 acc_val: 0.7280 time: 0.0644s\n",
            "194\n",
            "Epoch: 0729 loss_train: 0.6856 acc_train: 0.7833 loss_val: 0.9667 acc_val: 0.7260 time: 0.0641s\n",
            "195\n",
            "Epoch: 0730 loss_train: 0.7270 acc_train: 0.7750 loss_val: 0.9683 acc_val: 0.7260 time: 0.0645s\n",
            "196\n",
            "Epoch: 0731 loss_train: 0.7121 acc_train: 0.8583 loss_val: 0.9712 acc_val: 0.7280 time: 0.0654s\n",
            "197\n",
            "Epoch: 0732 loss_train: 0.7215 acc_train: 0.8083 loss_val: 0.9801 acc_val: 0.7260 time: 0.0643s\n",
            "198\n",
            "Epoch: 0733 loss_train: 0.7312 acc_train: 0.8750 loss_val: 0.9891 acc_val: 0.7220 time: 0.0656s\n",
            "199\n",
            "Early stop! Min loss:  0.9663064479827881 , Max accuracy:  0.74\n",
            "Early stop model validation loss:  0.9663064479827881 , accuracy:  0.73\n",
            "Optimization Finished!\n",
            "Total time elapsed: 48.8275s\n",
            "Loading 240th epoch\n",
            "Test set results: loss= 0.9387 accuracy= 0.7240\n",
            "Epoch: 0001 loss_train: 0.8024 acc_train: 0.8250 loss_val: 0.9758 acc_val: 0.7260 time: 0.0657s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8033 acc_train: 0.7833 loss_val: 0.9896 acc_val: 0.7300 time: 0.0670s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.7579 acc_train: 0.7833 loss_val: 1.0015 acc_val: 0.7240 time: 0.0644s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.8161 acc_train: 0.7833 loss_val: 1.0098 acc_val: 0.7200 time: 0.0634s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.7840 acc_train: 0.7667 loss_val: 1.0136 acc_val: 0.7160 time: 0.0644s\n",
            "2\n",
            "Epoch: 0006 loss_train: 0.7860 acc_train: 0.8333 loss_val: 1.0083 acc_val: 0.7180 time: 0.0653s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.7738 acc_train: 0.8000 loss_val: 0.9924 acc_val: 0.7300 time: 0.0632s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.7753 acc_train: 0.8500 loss_val: 0.9732 acc_val: 0.7300 time: 0.0637s\n",
            "0\n",
            "Epoch: 0009 loss_train: 0.7787 acc_train: 0.7833 loss_val: 0.9590 acc_val: 0.7300 time: 0.0656s\n",
            "0\n",
            "Epoch: 0010 loss_train: 0.8075 acc_train: 0.7917 loss_val: 0.9519 acc_val: 0.7360 time: 0.0643s\n",
            "0\n",
            "Epoch: 0011 loss_train: 0.8338 acc_train: 0.8333 loss_val: 0.9516 acc_val: 0.7380 time: 0.0636s\n",
            "0\n",
            "Epoch: 0012 loss_train: 0.7716 acc_train: 0.8333 loss_val: 0.9570 acc_val: 0.7360 time: 0.0636s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.8176 acc_train: 0.7750 loss_val: 0.9678 acc_val: 0.7320 time: 0.0673s\n",
            "1\n",
            "Epoch: 0014 loss_train: 0.8297 acc_train: 0.7917 loss_val: 0.9773 acc_val: 0.7260 time: 0.0639s\n",
            "2\n",
            "Epoch: 0015 loss_train: 0.7658 acc_train: 0.8000 loss_val: 0.9838 acc_val: 0.7240 time: 0.0655s\n",
            "3\n",
            "Epoch: 0016 loss_train: 0.8149 acc_train: 0.7667 loss_val: 0.9859 acc_val: 0.7220 time: 0.0649s\n",
            "4\n",
            "Epoch: 0017 loss_train: 0.7980 acc_train: 0.8000 loss_val: 0.9772 acc_val: 0.7220 time: 0.0643s\n",
            "5\n",
            "Epoch: 0018 loss_train: 0.7762 acc_train: 0.7750 loss_val: 0.9665 acc_val: 0.7280 time: 0.0634s\n",
            "6\n",
            "Epoch: 0019 loss_train: 0.8300 acc_train: 0.7250 loss_val: 0.9573 acc_val: 0.7340 time: 0.0637s\n",
            "7\n",
            "Epoch: 0020 loss_train: 0.7161 acc_train: 0.8167 loss_val: 0.9515 acc_val: 0.7380 time: 0.0651s\n",
            "8\n",
            "Epoch: 0021 loss_train: 0.7971 acc_train: 0.7750 loss_val: 0.9485 acc_val: 0.7360 time: 0.0634s\n",
            "0\n",
            "Epoch: 0022 loss_train: 0.7566 acc_train: 0.8000 loss_val: 0.9490 acc_val: 0.7360 time: 0.0632s\n",
            "0\n",
            "Epoch: 0023 loss_train: 0.8374 acc_train: 0.7500 loss_val: 0.9541 acc_val: 0.7220 time: 0.0636s\n",
            "1\n",
            "Epoch: 0024 loss_train: 0.7859 acc_train: 0.8583 loss_val: 0.9592 acc_val: 0.7260 time: 0.0654s\n",
            "2\n",
            "Epoch: 0025 loss_train: 0.7718 acc_train: 0.8083 loss_val: 0.9637 acc_val: 0.7240 time: 0.0653s\n",
            "3\n",
            "Epoch: 0026 loss_train: 0.7719 acc_train: 0.8167 loss_val: 0.9648 acc_val: 0.7300 time: 0.0657s\n",
            "4\n",
            "Epoch: 0027 loss_train: 0.7572 acc_train: 0.7500 loss_val: 0.9649 acc_val: 0.7260 time: 0.0645s\n",
            "5\n",
            "Epoch: 0028 loss_train: 0.7786 acc_train: 0.8417 loss_val: 0.9669 acc_val: 0.7240 time: 0.0656s\n",
            "6\n",
            "Epoch: 0029 loss_train: 0.7948 acc_train: 0.7917 loss_val: 0.9660 acc_val: 0.7240 time: 0.0634s\n",
            "7\n",
            "Epoch: 0030 loss_train: 0.7250 acc_train: 0.8500 loss_val: 0.9660 acc_val: 0.7240 time: 0.0635s\n",
            "8\n",
            "Epoch: 0031 loss_train: 0.7536 acc_train: 0.8500 loss_val: 0.9635 acc_val: 0.7240 time: 0.0642s\n",
            "9\n",
            "Epoch: 0032 loss_train: 0.7239 acc_train: 0.8333 loss_val: 0.9622 acc_val: 0.7240 time: 0.0636s\n",
            "10\n",
            "Epoch: 0033 loss_train: 0.7695 acc_train: 0.7750 loss_val: 0.9597 acc_val: 0.7240 time: 0.0635s\n",
            "11\n",
            "Epoch: 0034 loss_train: 0.7989 acc_train: 0.7667 loss_val: 0.9588 acc_val: 0.7240 time: 0.0649s\n",
            "12\n",
            "Epoch: 0035 loss_train: 0.8261 acc_train: 0.7833 loss_val: 0.9582 acc_val: 0.7260 time: 0.0658s\n",
            "13\n",
            "Epoch: 0036 loss_train: 0.8294 acc_train: 0.8250 loss_val: 0.9576 acc_val: 0.7260 time: 0.0631s\n",
            "14\n",
            "Epoch: 0037 loss_train: 0.7867 acc_train: 0.7917 loss_val: 0.9585 acc_val: 0.7260 time: 0.0635s\n",
            "15\n",
            "Epoch: 0038 loss_train: 0.7784 acc_train: 0.7833 loss_val: 0.9595 acc_val: 0.7260 time: 0.0655s\n",
            "16\n",
            "Epoch: 0039 loss_train: 0.8296 acc_train: 0.6833 loss_val: 0.9582 acc_val: 0.7280 time: 0.0647s\n",
            "17\n",
            "Epoch: 0040 loss_train: 0.7699 acc_train: 0.8250 loss_val: 0.9619 acc_val: 0.7320 time: 0.0651s\n",
            "18\n",
            "Epoch: 0041 loss_train: 0.7886 acc_train: 0.8417 loss_val: 0.9612 acc_val: 0.7340 time: 0.0650s\n",
            "19\n",
            "Epoch: 0042 loss_train: 0.7537 acc_train: 0.8500 loss_val: 0.9598 acc_val: 0.7320 time: 0.0635s\n",
            "20\n",
            "Epoch: 0043 loss_train: 0.7561 acc_train: 0.8000 loss_val: 0.9596 acc_val: 0.7280 time: 0.0651s\n",
            "21\n",
            "Epoch: 0044 loss_train: 0.7621 acc_train: 0.8000 loss_val: 0.9607 acc_val: 0.7280 time: 0.0642s\n",
            "22\n",
            "Epoch: 0045 loss_train: 0.7782 acc_train: 0.8083 loss_val: 0.9637 acc_val: 0.7280 time: 0.0642s\n",
            "23\n",
            "Epoch: 0046 loss_train: 0.7840 acc_train: 0.8250 loss_val: 0.9664 acc_val: 0.7260 time: 0.0637s\n",
            "24\n",
            "Epoch: 0047 loss_train: 0.7733 acc_train: 0.8250 loss_val: 0.9678 acc_val: 0.7260 time: 0.0635s\n",
            "25\n",
            "Epoch: 0048 loss_train: 0.7554 acc_train: 0.8333 loss_val: 0.9677 acc_val: 0.7280 time: 0.0656s\n",
            "26\n",
            "Epoch: 0049 loss_train: 0.8033 acc_train: 0.8000 loss_val: 0.9686 acc_val: 0.7240 time: 0.0652s\n",
            "27\n",
            "Epoch: 0050 loss_train: 0.7909 acc_train: 0.7500 loss_val: 0.9674 acc_val: 0.7280 time: 0.0650s\n",
            "28\n",
            "Epoch: 0051 loss_train: 0.7574 acc_train: 0.8250 loss_val: 0.9629 acc_val: 0.7300 time: 0.0642s\n",
            "29\n",
            "Epoch: 0052 loss_train: 0.7772 acc_train: 0.7917 loss_val: 0.9599 acc_val: 0.7280 time: 0.0651s\n",
            "30\n",
            "Epoch: 0053 loss_train: 0.7355 acc_train: 0.8500 loss_val: 0.9572 acc_val: 0.7300 time: 0.0672s\n",
            "31\n",
            "Epoch: 0054 loss_train: 0.7599 acc_train: 0.8750 loss_val: 0.9557 acc_val: 0.7340 time: 0.0653s\n",
            "32\n",
            "Epoch: 0055 loss_train: 0.8095 acc_train: 0.8000 loss_val: 0.9591 acc_val: 0.7320 time: 0.0639s\n",
            "33\n",
            "Epoch: 0056 loss_train: 0.7675 acc_train: 0.8250 loss_val: 0.9632 acc_val: 0.7300 time: 0.0639s\n",
            "34\n",
            "Epoch: 0057 loss_train: 0.7719 acc_train: 0.7667 loss_val: 0.9672 acc_val: 0.7260 time: 0.0633s\n",
            "35\n",
            "Epoch: 0058 loss_train: 0.7695 acc_train: 0.7667 loss_val: 0.9729 acc_val: 0.7260 time: 0.0649s\n",
            "36\n",
            "Epoch: 0059 loss_train: 0.7553 acc_train: 0.8417 loss_val: 0.9796 acc_val: 0.7240 time: 0.0640s\n",
            "37\n",
            "Epoch: 0060 loss_train: 0.7606 acc_train: 0.7833 loss_val: 0.9848 acc_val: 0.7220 time: 0.0640s\n",
            "38\n",
            "Epoch: 0061 loss_train: 0.7754 acc_train: 0.8333 loss_val: 0.9811 acc_val: 0.7200 time: 0.0633s\n",
            "39\n",
            "Epoch: 0062 loss_train: 0.7686 acc_train: 0.7750 loss_val: 0.9721 acc_val: 0.7200 time: 0.0643s\n",
            "40\n",
            "Epoch: 0063 loss_train: 0.7551 acc_train: 0.9000 loss_val: 0.9622 acc_val: 0.7240 time: 0.0641s\n",
            "41\n",
            "Epoch: 0064 loss_train: 0.7246 acc_train: 0.8083 loss_val: 0.9544 acc_val: 0.7300 time: 0.0637s\n",
            "42\n",
            "Epoch: 0065 loss_train: 0.8116 acc_train: 0.7583 loss_val: 0.9487 acc_val: 0.7380 time: 0.0632s\n",
            "43\n",
            "Epoch: 0066 loss_train: 0.7925 acc_train: 0.8417 loss_val: 0.9470 acc_val: 0.7360 time: 0.0665s\n",
            "0\n",
            "Epoch: 0067 loss_train: 0.7284 acc_train: 0.7917 loss_val: 0.9484 acc_val: 0.7400 time: 0.0642s\n",
            "0\n",
            "Epoch: 0068 loss_train: 0.7396 acc_train: 0.7750 loss_val: 0.9526 acc_val: 0.7400 time: 0.0635s\n",
            "0\n",
            "Epoch: 0069 loss_train: 0.7707 acc_train: 0.7917 loss_val: 0.9564 acc_val: 0.7360 time: 0.0641s\n",
            "0\n",
            "Epoch: 0070 loss_train: 0.7637 acc_train: 0.8917 loss_val: 0.9606 acc_val: 0.7360 time: 0.0639s\n",
            "1\n",
            "Epoch: 0071 loss_train: 0.7664 acc_train: 0.7917 loss_val: 0.9614 acc_val: 0.7360 time: 0.0637s\n",
            "2\n",
            "Epoch: 0072 loss_train: 0.8016 acc_train: 0.8667 loss_val: 0.9607 acc_val: 0.7400 time: 0.0632s\n",
            "3\n",
            "Epoch: 0073 loss_train: 0.7331 acc_train: 0.7917 loss_val: 0.9577 acc_val: 0.7380 time: 0.0684s\n",
            "0\n",
            "Epoch: 0074 loss_train: 0.7192 acc_train: 0.7667 loss_val: 0.9576 acc_val: 0.7380 time: 0.0664s\n",
            "1\n",
            "Epoch: 0075 loss_train: 0.7711 acc_train: 0.7833 loss_val: 0.9579 acc_val: 0.7360 time: 0.0646s\n",
            "2\n",
            "Epoch: 0076 loss_train: 0.8087 acc_train: 0.7500 loss_val: 0.9582 acc_val: 0.7360 time: 0.0668s\n",
            "3\n",
            "Epoch: 0077 loss_train: 0.7536 acc_train: 0.8083 loss_val: 0.9587 acc_val: 0.7380 time: 0.0656s\n",
            "4\n",
            "Epoch: 0078 loss_train: 0.7600 acc_train: 0.7583 loss_val: 0.9602 acc_val: 0.7380 time: 0.0641s\n",
            "5\n",
            "Epoch: 0079 loss_train: 0.7806 acc_train: 0.7667 loss_val: 0.9607 acc_val: 0.7380 time: 0.0633s\n",
            "6\n",
            "Epoch: 0080 loss_train: 0.7056 acc_train: 0.8250 loss_val: 0.9589 acc_val: 0.7360 time: 0.0646s\n",
            "7\n",
            "Epoch: 0081 loss_train: 0.7667 acc_train: 0.7917 loss_val: 0.9595 acc_val: 0.7340 time: 0.0643s\n",
            "8\n",
            "Epoch: 0082 loss_train: 0.7806 acc_train: 0.7917 loss_val: 0.9588 acc_val: 0.7320 time: 0.0632s\n",
            "9\n",
            "Epoch: 0083 loss_train: 0.8319 acc_train: 0.7833 loss_val: 0.9578 acc_val: 0.7320 time: 0.0635s\n",
            "10\n",
            "Epoch: 0084 loss_train: 0.7288 acc_train: 0.8083 loss_val: 0.9504 acc_val: 0.7360 time: 0.0648s\n",
            "11\n",
            "Epoch: 0085 loss_train: 0.8026 acc_train: 0.8167 loss_val: 0.9450 acc_val: 0.7380 time: 0.0642s\n",
            "12\n",
            "Epoch: 0086 loss_train: 0.8034 acc_train: 0.8333 loss_val: 0.9432 acc_val: 0.7400 time: 0.0635s\n",
            "0\n",
            "Epoch: 0087 loss_train: 0.8048 acc_train: 0.7917 loss_val: 0.9438 acc_val: 0.7400 time: 0.0633s\n",
            "0\n",
            "Epoch: 0088 loss_train: 0.6548 acc_train: 0.8333 loss_val: 0.9463 acc_val: 0.7440 time: 0.0662s\n",
            "0\n",
            "Epoch: 0089 loss_train: 0.7804 acc_train: 0.8167 loss_val: 0.9513 acc_val: 0.7420 time: 0.0642s\n",
            "0\n",
            "Epoch: 0090 loss_train: 0.7364 acc_train: 0.8417 loss_val: 0.9568 acc_val: 0.7380 time: 0.0639s\n",
            "1\n",
            "Epoch: 0091 loss_train: 0.8187 acc_train: 0.8000 loss_val: 0.9647 acc_val: 0.7340 time: 0.0644s\n",
            "2\n",
            "Epoch: 0092 loss_train: 0.7210 acc_train: 0.8583 loss_val: 0.9674 acc_val: 0.7300 time: 0.0635s\n",
            "3\n",
            "Epoch: 0093 loss_train: 0.7327 acc_train: 0.8667 loss_val: 0.9671 acc_val: 0.7280 time: 0.0637s\n",
            "4\n",
            "Epoch: 0094 loss_train: 0.7825 acc_train: 0.7917 loss_val: 0.9593 acc_val: 0.7340 time: 0.0643s\n",
            "5\n",
            "Epoch: 0095 loss_train: 0.7050 acc_train: 0.8250 loss_val: 0.9532 acc_val: 0.7360 time: 0.0657s\n",
            "6\n",
            "Epoch: 0096 loss_train: 0.7770 acc_train: 0.8500 loss_val: 0.9482 acc_val: 0.7400 time: 0.0649s\n",
            "7\n",
            "Epoch: 0097 loss_train: 0.7678 acc_train: 0.8583 loss_val: 0.9463 acc_val: 0.7400 time: 0.0647s\n",
            "8\n",
            "Epoch: 0098 loss_train: 0.7509 acc_train: 0.7333 loss_val: 0.9464 acc_val: 0.7420 time: 0.0698s\n",
            "9\n",
            "Epoch: 0099 loss_train: 0.8003 acc_train: 0.8000 loss_val: 0.9539 acc_val: 0.7360 time: 0.0662s\n",
            "10\n",
            "Epoch: 0100 loss_train: 0.7441 acc_train: 0.8167 loss_val: 0.9581 acc_val: 0.7400 time: 0.0638s\n",
            "11\n",
            "Epoch: 0101 loss_train: 0.7284 acc_train: 0.8500 loss_val: 0.9591 acc_val: 0.7380 time: 0.0646s\n",
            "12\n",
            "Epoch: 0102 loss_train: 0.7929 acc_train: 0.7917 loss_val: 0.9603 acc_val: 0.7420 time: 0.0645s\n",
            "13\n",
            "Epoch: 0103 loss_train: 0.7483 acc_train: 0.8500 loss_val: 0.9601 acc_val: 0.7340 time: 0.0640s\n",
            "14\n",
            "Epoch: 0104 loss_train: 0.7548 acc_train: 0.8000 loss_val: 0.9598 acc_val: 0.7360 time: 0.0644s\n",
            "15\n",
            "Epoch: 0105 loss_train: 0.8155 acc_train: 0.7833 loss_val: 0.9587 acc_val: 0.7380 time: 0.0640s\n",
            "16\n",
            "Epoch: 0106 loss_train: 0.7127 acc_train: 0.8250 loss_val: 0.9569 acc_val: 0.7360 time: 0.0636s\n",
            "17\n",
            "Epoch: 0107 loss_train: 0.7885 acc_train: 0.8333 loss_val: 0.9562 acc_val: 0.7340 time: 0.0634s\n",
            "18\n",
            "Epoch: 0108 loss_train: 0.7970 acc_train: 0.8167 loss_val: 0.9578 acc_val: 0.7380 time: 0.0660s\n",
            "19\n",
            "Epoch: 0109 loss_train: 0.7858 acc_train: 0.7500 loss_val: 0.9621 acc_val: 0.7340 time: 0.0653s\n",
            "20\n",
            "Epoch: 0110 loss_train: 0.7330 acc_train: 0.8417 loss_val: 0.9657 acc_val: 0.7340 time: 0.0635s\n",
            "21\n",
            "Epoch: 0111 loss_train: 0.7700 acc_train: 0.8000 loss_val: 0.9739 acc_val: 0.7340 time: 0.0637s\n",
            "22\n",
            "Epoch: 0112 loss_train: 0.7426 acc_train: 0.8417 loss_val: 0.9763 acc_val: 0.7320 time: 0.0657s\n",
            "23\n",
            "Epoch: 0113 loss_train: 0.8008 acc_train: 0.8250 loss_val: 0.9685 acc_val: 0.7300 time: 0.0632s\n",
            "24\n",
            "Epoch: 0114 loss_train: 0.7607 acc_train: 0.7417 loss_val: 0.9584 acc_val: 0.7340 time: 0.0633s\n",
            "25\n",
            "Epoch: 0115 loss_train: 0.7583 acc_train: 0.7917 loss_val: 0.9526 acc_val: 0.7360 time: 0.0633s\n",
            "26\n",
            "Epoch: 0116 loss_train: 0.7349 acc_train: 0.8583 loss_val: 0.9529 acc_val: 0.7380 time: 0.0644s\n",
            "27\n",
            "Epoch: 0117 loss_train: 0.7760 acc_train: 0.8667 loss_val: 0.9578 acc_val: 0.7280 time: 0.0632s\n",
            "28\n",
            "Epoch: 0118 loss_train: 0.7731 acc_train: 0.8667 loss_val: 0.9651 acc_val: 0.7260 time: 0.0636s\n",
            "29\n",
            "Epoch: 0119 loss_train: 0.7669 acc_train: 0.8167 loss_val: 0.9720 acc_val: 0.7260 time: 0.0650s\n",
            "30\n",
            "Epoch: 0120 loss_train: 0.7582 acc_train: 0.8333 loss_val: 0.9748 acc_val: 0.7260 time: 0.0649s\n",
            "31\n",
            "Epoch: 0121 loss_train: 0.7368 acc_train: 0.7750 loss_val: 0.9760 acc_val: 0.7280 time: 0.0637s\n",
            "32\n",
            "Epoch: 0122 loss_train: 0.7995 acc_train: 0.8000 loss_val: 0.9768 acc_val: 0.7280 time: 0.0636s\n",
            "33\n",
            "Epoch: 0123 loss_train: 0.8413 acc_train: 0.7667 loss_val: 0.9729 acc_val: 0.7260 time: 0.0632s\n",
            "34\n",
            "Epoch: 0124 loss_train: 0.7961 acc_train: 0.7833 loss_val: 0.9684 acc_val: 0.7280 time: 0.0648s\n",
            "35\n",
            "Epoch: 0125 loss_train: 0.7830 acc_train: 0.8167 loss_val: 0.9593 acc_val: 0.7320 time: 0.0635s\n",
            "36\n",
            "Epoch: 0126 loss_train: 0.7477 acc_train: 0.8167 loss_val: 0.9473 acc_val: 0.7340 time: 0.0633s\n",
            "37\n",
            "Epoch: 0127 loss_train: 0.7345 acc_train: 0.8583 loss_val: 0.9394 acc_val: 0.7360 time: 0.0634s\n",
            "38\n",
            "Epoch: 0128 loss_train: 0.7823 acc_train: 0.7417 loss_val: 0.9381 acc_val: 0.7380 time: 0.0652s\n",
            "0\n",
            "Epoch: 0129 loss_train: 0.7821 acc_train: 0.7917 loss_val: 0.9382 acc_val: 0.7380 time: 0.0645s\n",
            "0\n",
            "Epoch: 0130 loss_train: 0.7471 acc_train: 0.8167 loss_val: 0.9414 acc_val: 0.7340 time: 0.0661s\n",
            "1\n",
            "Epoch: 0131 loss_train: 0.7636 acc_train: 0.8000 loss_val: 0.9509 acc_val: 0.7300 time: 0.0658s\n",
            "2\n",
            "Epoch: 0132 loss_train: 0.7574 acc_train: 0.7583 loss_val: 0.9615 acc_val: 0.7300 time: 0.0654s\n",
            "3\n",
            "Epoch: 0133 loss_train: 0.8116 acc_train: 0.8083 loss_val: 0.9689 acc_val: 0.7300 time: 0.0635s\n",
            "4\n",
            "Epoch: 0134 loss_train: 0.7560 acc_train: 0.8000 loss_val: 0.9722 acc_val: 0.7320 time: 0.0650s\n",
            "5\n",
            "Epoch: 0135 loss_train: 0.7488 acc_train: 0.8000 loss_val: 0.9724 acc_val: 0.7340 time: 0.0643s\n",
            "6\n",
            "Epoch: 0136 loss_train: 0.7237 acc_train: 0.8250 loss_val: 0.9682 acc_val: 0.7280 time: 0.0635s\n",
            "7\n",
            "Epoch: 0137 loss_train: 0.7394 acc_train: 0.8583 loss_val: 0.9621 acc_val: 0.7320 time: 0.0634s\n",
            "8\n",
            "Epoch: 0138 loss_train: 0.7970 acc_train: 0.7500 loss_val: 0.9538 acc_val: 0.7300 time: 0.0628s\n",
            "9\n",
            "Epoch: 0139 loss_train: 0.7688 acc_train: 0.8083 loss_val: 0.9512 acc_val: 0.7340 time: 0.0646s\n",
            "10\n",
            "Epoch: 0140 loss_train: 0.7804 acc_train: 0.8083 loss_val: 0.9539 acc_val: 0.7300 time: 0.0638s\n",
            "11\n",
            "Epoch: 0141 loss_train: 0.7868 acc_train: 0.7750 loss_val: 0.9617 acc_val: 0.7260 time: 0.0632s\n",
            "12\n",
            "Epoch: 0142 loss_train: 0.7714 acc_train: 0.8083 loss_val: 0.9687 acc_val: 0.7220 time: 0.0640s\n",
            "13\n",
            "Epoch: 0143 loss_train: 0.7787 acc_train: 0.8083 loss_val: 0.9728 acc_val: 0.7140 time: 0.0661s\n",
            "14\n",
            "Epoch: 0144 loss_train: 0.8257 acc_train: 0.7917 loss_val: 0.9722 acc_val: 0.7160 time: 0.0649s\n",
            "15\n",
            "Epoch: 0145 loss_train: 0.7488 acc_train: 0.8500 loss_val: 0.9686 acc_val: 0.7180 time: 0.0642s\n",
            "16\n",
            "Epoch: 0146 loss_train: 0.7649 acc_train: 0.8000 loss_val: 0.9594 acc_val: 0.7240 time: 0.0655s\n",
            "17\n",
            "Epoch: 0147 loss_train: 0.7078 acc_train: 0.8000 loss_val: 0.9526 acc_val: 0.7280 time: 0.0656s\n",
            "18\n",
            "Epoch: 0148 loss_train: 0.8231 acc_train: 0.8250 loss_val: 0.9524 acc_val: 0.7200 time: 0.0635s\n",
            "19\n",
            "Epoch: 0149 loss_train: 0.7773 acc_train: 0.7917 loss_val: 0.9554 acc_val: 0.7280 time: 0.0657s\n",
            "20\n",
            "Epoch: 0150 loss_train: 0.7390 acc_train: 0.8000 loss_val: 0.9631 acc_val: 0.7280 time: 0.0670s\n",
            "21\n",
            "Epoch: 0151 loss_train: 0.7779 acc_train: 0.8000 loss_val: 0.9700 acc_val: 0.7200 time: 0.0635s\n",
            "22\n",
            "Epoch: 0152 loss_train: 0.8377 acc_train: 0.7583 loss_val: 0.9740 acc_val: 0.7220 time: 0.0640s\n",
            "23\n",
            "Epoch: 0153 loss_train: 0.7046 acc_train: 0.8667 loss_val: 0.9710 acc_val: 0.7240 time: 0.0657s\n",
            "24\n",
            "Epoch: 0154 loss_train: 0.7526 acc_train: 0.7833 loss_val: 0.9659 acc_val: 0.7220 time: 0.0654s\n",
            "25\n",
            "Epoch: 0155 loss_train: 0.7206 acc_train: 0.7750 loss_val: 0.9586 acc_val: 0.7180 time: 0.0633s\n",
            "26\n",
            "Epoch: 0156 loss_train: 0.7896 acc_train: 0.7500 loss_val: 0.9496 acc_val: 0.7180 time: 0.0630s\n",
            "27\n",
            "Epoch: 0157 loss_train: 0.7498 acc_train: 0.8000 loss_val: 0.9439 acc_val: 0.7200 time: 0.0655s\n",
            "28\n",
            "Epoch: 0158 loss_train: 0.7483 acc_train: 0.8333 loss_val: 0.9457 acc_val: 0.7180 time: 0.0632s\n",
            "29\n",
            "Epoch: 0159 loss_train: 0.7350 acc_train: 0.7833 loss_val: 0.9500 acc_val: 0.7140 time: 0.0640s\n",
            "30\n",
            "Epoch: 0160 loss_train: 0.7385 acc_train: 0.8167 loss_val: 0.9561 acc_val: 0.7200 time: 0.0638s\n",
            "31\n",
            "Epoch: 0161 loss_train: 0.7736 acc_train: 0.8083 loss_val: 0.9621 acc_val: 0.7180 time: 0.0671s\n",
            "32\n",
            "Epoch: 0162 loss_train: 0.7905 acc_train: 0.8000 loss_val: 0.9665 acc_val: 0.7240 time: 0.0648s\n",
            "33\n",
            "Epoch: 0163 loss_train: 0.8083 acc_train: 0.7250 loss_val: 0.9685 acc_val: 0.7220 time: 0.0652s\n",
            "34\n",
            "Epoch: 0164 loss_train: 0.7822 acc_train: 0.8333 loss_val: 0.9672 acc_val: 0.7280 time: 0.0670s\n",
            "35\n",
            "Epoch: 0165 loss_train: 0.7493 acc_train: 0.8167 loss_val: 0.9627 acc_val: 0.7280 time: 0.0664s\n",
            "36\n",
            "Epoch: 0166 loss_train: 0.7451 acc_train: 0.8500 loss_val: 0.9583 acc_val: 0.7220 time: 0.0647s\n",
            "37\n",
            "Epoch: 0167 loss_train: 0.7942 acc_train: 0.7333 loss_val: 0.9527 acc_val: 0.7260 time: 0.0634s\n",
            "38\n",
            "Epoch: 0168 loss_train: 0.7949 acc_train: 0.7583 loss_val: 0.9501 acc_val: 0.7240 time: 0.0646s\n",
            "39\n",
            "Epoch: 0169 loss_train: 0.7768 acc_train: 0.7917 loss_val: 0.9544 acc_val: 0.7260 time: 0.0632s\n",
            "40\n",
            "Epoch: 0170 loss_train: 0.7784 acc_train: 0.7833 loss_val: 0.9596 acc_val: 0.7220 time: 0.0633s\n",
            "41\n",
            "Epoch: 0171 loss_train: 0.7532 acc_train: 0.7583 loss_val: 0.9664 acc_val: 0.7280 time: 0.0637s\n",
            "42\n",
            "Epoch: 0172 loss_train: 0.7820 acc_train: 0.7167 loss_val: 0.9749 acc_val: 0.7300 time: 0.0644s\n",
            "43\n",
            "Epoch: 0173 loss_train: 0.7549 acc_train: 0.8583 loss_val: 0.9802 acc_val: 0.7280 time: 0.0633s\n",
            "44\n",
            "Epoch: 0174 loss_train: 0.7380 acc_train: 0.8250 loss_val: 0.9796 acc_val: 0.7280 time: 0.0630s\n",
            "45\n",
            "Epoch: 0175 loss_train: 0.7897 acc_train: 0.8083 loss_val: 0.9719 acc_val: 0.7320 time: 0.0634s\n",
            "46\n",
            "Epoch: 0176 loss_train: 0.7904 acc_train: 0.8000 loss_val: 0.9634 acc_val: 0.7320 time: 0.0660s\n",
            "47\n",
            "Epoch: 0177 loss_train: 0.7826 acc_train: 0.8000 loss_val: 0.9556 acc_val: 0.7300 time: 0.0651s\n",
            "48\n",
            "Epoch: 0178 loss_train: 0.7459 acc_train: 0.8333 loss_val: 0.9482 acc_val: 0.7320 time: 0.0658s\n",
            "49\n",
            "Epoch: 0179 loss_train: 0.7660 acc_train: 0.8000 loss_val: 0.9459 acc_val: 0.7280 time: 0.0642s\n",
            "50\n",
            "Epoch: 0180 loss_train: 0.7506 acc_train: 0.7917 loss_val: 0.9528 acc_val: 0.7340 time: 0.0653s\n",
            "51\n",
            "Epoch: 0181 loss_train: 0.7441 acc_train: 0.8083 loss_val: 0.9606 acc_val: 0.7280 time: 0.0648s\n",
            "52\n",
            "Epoch: 0182 loss_train: 0.7449 acc_train: 0.8000 loss_val: 0.9666 acc_val: 0.7280 time: 0.0634s\n",
            "53\n",
            "Epoch: 0183 loss_train: 0.7643 acc_train: 0.7833 loss_val: 0.9671 acc_val: 0.7240 time: 0.0652s\n",
            "54\n",
            "Epoch: 0184 loss_train: 0.7745 acc_train: 0.7833 loss_val: 0.9642 acc_val: 0.7240 time: 0.0656s\n",
            "55\n",
            "Epoch: 0185 loss_train: 0.7791 acc_train: 0.8000 loss_val: 0.9564 acc_val: 0.7260 time: 0.0647s\n",
            "56\n",
            "Epoch: 0186 loss_train: 0.7780 acc_train: 0.8000 loss_val: 0.9481 acc_val: 0.7240 time: 0.0656s\n",
            "57\n",
            "Epoch: 0187 loss_train: 0.7510 acc_train: 0.7667 loss_val: 0.9464 acc_val: 0.7300 time: 0.0647s\n",
            "58\n",
            "Epoch: 0188 loss_train: 0.7748 acc_train: 0.7583 loss_val: 0.9469 acc_val: 0.7320 time: 0.0634s\n",
            "59\n",
            "Epoch: 0189 loss_train: 0.7973 acc_train: 0.7750 loss_val: 0.9475 acc_val: 0.7260 time: 0.0634s\n",
            "60\n",
            "Epoch: 0190 loss_train: 0.7272 acc_train: 0.8333 loss_val: 0.9479 acc_val: 0.7260 time: 0.0659s\n",
            "61\n",
            "Epoch: 0191 loss_train: 0.7789 acc_train: 0.7917 loss_val: 0.9492 acc_val: 0.7260 time: 0.0652s\n",
            "62\n",
            "Epoch: 0192 loss_train: 0.7751 acc_train: 0.7833 loss_val: 0.9488 acc_val: 0.7260 time: 0.0645s\n",
            "63\n",
            "Epoch: 0193 loss_train: 0.7912 acc_train: 0.7917 loss_val: 0.9465 acc_val: 0.7300 time: 0.0639s\n",
            "64\n",
            "Epoch: 0194 loss_train: 0.7482 acc_train: 0.7667 loss_val: 0.9435 acc_val: 0.7360 time: 0.0656s\n",
            "65\n",
            "Epoch: 0195 loss_train: 0.7394 acc_train: 0.7750 loss_val: 0.9410 acc_val: 0.7360 time: 0.0663s\n",
            "66\n",
            "Epoch: 0196 loss_train: 0.7940 acc_train: 0.7667 loss_val: 0.9433 acc_val: 0.7380 time: 0.0634s\n",
            "67\n",
            "Epoch: 0197 loss_train: 0.8229 acc_train: 0.7500 loss_val: 0.9509 acc_val: 0.7340 time: 0.0639s\n",
            "68\n",
            "Epoch: 0198 loss_train: 0.7397 acc_train: 0.8500 loss_val: 0.9582 acc_val: 0.7340 time: 0.0630s\n",
            "69\n",
            "Epoch: 0199 loss_train: 0.7355 acc_train: 0.8500 loss_val: 0.9639 acc_val: 0.7300 time: 0.0628s\n",
            "70\n",
            "Epoch: 0200 loss_train: 0.7689 acc_train: 0.7833 loss_val: 0.9670 acc_val: 0.7280 time: 0.0632s\n",
            "71\n",
            "Epoch: 0201 loss_train: 0.7781 acc_train: 0.8167 loss_val: 0.9619 acc_val: 0.7320 time: 0.0651s\n",
            "72\n",
            "Epoch: 0202 loss_train: 0.7401 acc_train: 0.8167 loss_val: 0.9573 acc_val: 0.7340 time: 0.0636s\n",
            "73\n",
            "Epoch: 0203 loss_train: 0.8538 acc_train: 0.7500 loss_val: 0.9520 acc_val: 0.7340 time: 0.0657s\n",
            "74\n",
            "Epoch: 0204 loss_train: 0.7424 acc_train: 0.8000 loss_val: 0.9479 acc_val: 0.7320 time: 0.0641s\n",
            "75\n",
            "Epoch: 0205 loss_train: 0.7842 acc_train: 0.8417 loss_val: 0.9446 acc_val: 0.7320 time: 0.0641s\n",
            "76\n",
            "Epoch: 0206 loss_train: 0.8231 acc_train: 0.7667 loss_val: 0.9449 acc_val: 0.7340 time: 0.0633s\n",
            "77\n",
            "Epoch: 0207 loss_train: 0.8090 acc_train: 0.7583 loss_val: 0.9496 acc_val: 0.7420 time: 0.0646s\n",
            "78\n",
            "Epoch: 0208 loss_train: 0.7465 acc_train: 0.8250 loss_val: 0.9577 acc_val: 0.7380 time: 0.0682s\n",
            "79\n",
            "Epoch: 0209 loss_train: 0.7437 acc_train: 0.8500 loss_val: 0.9659 acc_val: 0.7360 time: 0.0655s\n",
            "80\n",
            "Epoch: 0210 loss_train: 0.7405 acc_train: 0.8333 loss_val: 0.9672 acc_val: 0.7340 time: 0.0663s\n",
            "81\n",
            "Epoch: 0211 loss_train: 0.7881 acc_train: 0.8250 loss_val: 0.9642 acc_val: 0.7300 time: 0.0651s\n",
            "82\n",
            "Epoch: 0212 loss_train: 0.7642 acc_train: 0.8083 loss_val: 0.9588 acc_val: 0.7240 time: 0.0664s\n",
            "83\n",
            "Epoch: 0213 loss_train: 0.6958 acc_train: 0.8500 loss_val: 0.9540 acc_val: 0.7240 time: 0.0659s\n",
            "84\n",
            "Epoch: 0214 loss_train: 0.7393 acc_train: 0.8333 loss_val: 0.9520 acc_val: 0.7280 time: 0.0642s\n",
            "85\n",
            "Epoch: 0215 loss_train: 0.7835 acc_train: 0.7667 loss_val: 0.9536 acc_val: 0.7280 time: 0.0645s\n",
            "86\n",
            "Epoch: 0216 loss_train: 0.7479 acc_train: 0.7417 loss_val: 0.9572 acc_val: 0.7260 time: 0.0635s\n",
            "87\n",
            "Epoch: 0217 loss_train: 0.8338 acc_train: 0.7417 loss_val: 0.9624 acc_val: 0.7200 time: 0.0630s\n",
            "88\n",
            "Epoch: 0218 loss_train: 0.7458 acc_train: 0.8083 loss_val: 0.9677 acc_val: 0.7240 time: 0.0634s\n",
            "89\n",
            "Epoch: 0219 loss_train: 0.7915 acc_train: 0.8000 loss_val: 0.9775 acc_val: 0.7240 time: 0.0648s\n",
            "90\n",
            "Epoch: 0220 loss_train: 0.7752 acc_train: 0.8333 loss_val: 0.9832 acc_val: 0.7240 time: 0.0644s\n",
            "91\n",
            "Epoch: 0221 loss_train: 0.8014 acc_train: 0.6917 loss_val: 0.9819 acc_val: 0.7240 time: 0.0636s\n",
            "92\n",
            "Epoch: 0222 loss_train: 0.8143 acc_train: 0.7667 loss_val: 0.9700 acc_val: 0.7240 time: 0.0628s\n",
            "93\n",
            "Epoch: 0223 loss_train: 0.7931 acc_train: 0.7667 loss_val: 0.9583 acc_val: 0.7280 time: 0.0653s\n",
            "94\n",
            "Epoch: 0224 loss_train: 0.7850 acc_train: 0.7917 loss_val: 0.9463 acc_val: 0.7260 time: 0.0634s\n",
            "95\n",
            "Epoch: 0225 loss_train: 0.8175 acc_train: 0.7833 loss_val: 0.9438 acc_val: 0.7280 time: 0.0666s\n",
            "96\n",
            "Epoch: 0226 loss_train: 0.7120 acc_train: 0.7833 loss_val: 0.9457 acc_val: 0.7280 time: 0.0643s\n",
            "97\n",
            "Epoch: 0227 loss_train: 0.7617 acc_train: 0.7417 loss_val: 0.9500 acc_val: 0.7300 time: 0.0661s\n",
            "98\n",
            "Epoch: 0228 loss_train: 0.8001 acc_train: 0.7667 loss_val: 0.9581 acc_val: 0.7260 time: 0.0653s\n",
            "99\n",
            "Epoch: 0229 loss_train: 0.7704 acc_train: 0.8083 loss_val: 0.9650 acc_val: 0.7200 time: 0.0646s\n",
            "100\n",
            "Epoch: 0230 loss_train: 0.7797 acc_train: 0.8167 loss_val: 0.9671 acc_val: 0.7200 time: 0.0654s\n",
            "101\n",
            "Epoch: 0231 loss_train: 0.7355 acc_train: 0.8417 loss_val: 0.9667 acc_val: 0.7260 time: 0.0647s\n",
            "102\n",
            "Epoch: 0232 loss_train: 0.7151 acc_train: 0.8917 loss_val: 0.9650 acc_val: 0.7300 time: 0.0632s\n",
            "103\n",
            "Epoch: 0233 loss_train: 0.8070 acc_train: 0.8333 loss_val: 0.9637 acc_val: 0.7280 time: 0.0632s\n",
            "104\n",
            "Epoch: 0234 loss_train: 0.7689 acc_train: 0.8250 loss_val: 0.9576 acc_val: 0.7320 time: 0.0650s\n",
            "105\n",
            "Epoch: 0235 loss_train: 0.7539 acc_train: 0.8250 loss_val: 0.9504 acc_val: 0.7360 time: 0.0634s\n",
            "106\n",
            "Epoch: 0236 loss_train: 0.7809 acc_train: 0.8083 loss_val: 0.9450 acc_val: 0.7340 time: 0.0640s\n",
            "107\n",
            "Epoch: 0237 loss_train: 0.8114 acc_train: 0.7667 loss_val: 0.9400 acc_val: 0.7360 time: 0.0632s\n",
            "108\n",
            "Epoch: 0238 loss_train: 0.7752 acc_train: 0.8250 loss_val: 0.9399 acc_val: 0.7360 time: 0.0645s\n",
            "109\n",
            "Epoch: 0239 loss_train: 0.7953 acc_train: 0.8167 loss_val: 0.9410 acc_val: 0.7300 time: 0.0641s\n",
            "110\n",
            "Epoch: 0240 loss_train: 0.7873 acc_train: 0.7750 loss_val: 0.9459 acc_val: 0.7260 time: 0.0652s\n",
            "111\n",
            "Epoch: 0241 loss_train: 0.7159 acc_train: 0.8417 loss_val: 0.9536 acc_val: 0.7240 time: 0.0654s\n",
            "112\n",
            "Epoch: 0242 loss_train: 0.7268 acc_train: 0.8500 loss_val: 0.9646 acc_val: 0.7220 time: 0.0654s\n",
            "113\n",
            "Epoch: 0243 loss_train: 0.7741 acc_train: 0.7667 loss_val: 0.9746 acc_val: 0.7220 time: 0.0645s\n",
            "114\n",
            "Epoch: 0244 loss_train: 0.7823 acc_train: 0.8083 loss_val: 0.9759 acc_val: 0.7220 time: 0.0641s\n",
            "115\n",
            "Epoch: 0245 loss_train: 0.7688 acc_train: 0.8000 loss_val: 0.9699 acc_val: 0.7260 time: 0.0652s\n",
            "116\n",
            "Epoch: 0246 loss_train: 0.7772 acc_train: 0.8167 loss_val: 0.9644 acc_val: 0.7280 time: 0.0634s\n",
            "117\n",
            "Epoch: 0247 loss_train: 0.7913 acc_train: 0.7750 loss_val: 0.9618 acc_val: 0.7260 time: 0.0638s\n",
            "118\n",
            "Epoch: 0248 loss_train: 0.7398 acc_train: 0.8000 loss_val: 0.9565 acc_val: 0.7240 time: 0.0636s\n",
            "119\n",
            "Epoch: 0249 loss_train: 0.7392 acc_train: 0.7917 loss_val: 0.9506 acc_val: 0.7300 time: 0.0649s\n",
            "120\n",
            "Epoch: 0250 loss_train: 0.7268 acc_train: 0.8417 loss_val: 0.9483 acc_val: 0.7360 time: 0.0632s\n",
            "121\n",
            "Epoch: 0251 loss_train: 0.7814 acc_train: 0.7667 loss_val: 0.9478 acc_val: 0.7340 time: 0.0634s\n",
            "122\n",
            "Epoch: 0252 loss_train: 0.7581 acc_train: 0.7750 loss_val: 0.9504 acc_val: 0.7300 time: 0.0633s\n",
            "123\n",
            "Epoch: 0253 loss_train: 0.7287 acc_train: 0.8000 loss_val: 0.9584 acc_val: 0.7320 time: 0.0646s\n",
            "124\n",
            "Epoch: 0254 loss_train: 0.7625 acc_train: 0.8417 loss_val: 0.9710 acc_val: 0.7240 time: 0.0635s\n",
            "125\n",
            "Epoch: 0255 loss_train: 0.7538 acc_train: 0.7417 loss_val: 0.9812 acc_val: 0.7200 time: 0.0633s\n",
            "126\n",
            "Epoch: 0256 loss_train: 0.7746 acc_train: 0.7833 loss_val: 0.9852 acc_val: 0.7180 time: 0.0653s\n",
            "127\n",
            "Epoch: 0257 loss_train: 0.8206 acc_train: 0.8083 loss_val: 0.9794 acc_val: 0.7200 time: 0.0662s\n",
            "128\n",
            "Epoch: 0258 loss_train: 0.7889 acc_train: 0.8333 loss_val: 0.9689 acc_val: 0.7200 time: 0.0632s\n",
            "129\n",
            "Epoch: 0259 loss_train: 0.7382 acc_train: 0.8083 loss_val: 0.9539 acc_val: 0.7240 time: 0.0629s\n",
            "130\n",
            "Epoch: 0260 loss_train: 0.7399 acc_train: 0.8250 loss_val: 0.9428 acc_val: 0.7300 time: 0.0634s\n",
            "131\n",
            "Epoch: 0261 loss_train: 0.7916 acc_train: 0.8250 loss_val: 0.9380 acc_val: 0.7300 time: 0.0665s\n",
            "132\n",
            "Epoch: 0262 loss_train: 0.8216 acc_train: 0.7750 loss_val: 0.9399 acc_val: 0.7280 time: 0.0628s\n",
            "0\n",
            "Epoch: 0263 loss_train: 0.7589 acc_train: 0.8417 loss_val: 0.9460 acc_val: 0.7260 time: 0.0634s\n",
            "1\n",
            "Epoch: 0264 loss_train: 0.7973 acc_train: 0.7833 loss_val: 0.9558 acc_val: 0.7240 time: 0.0647s\n",
            "2\n",
            "Epoch: 0265 loss_train: 0.8061 acc_train: 0.7833 loss_val: 0.9625 acc_val: 0.7240 time: 0.0652s\n",
            "3\n",
            "Epoch: 0266 loss_train: 0.8161 acc_train: 0.7833 loss_val: 0.9696 acc_val: 0.7220 time: 0.0631s\n",
            "4\n",
            "Epoch: 0267 loss_train: 0.7681 acc_train: 0.7833 loss_val: 0.9790 acc_val: 0.7180 time: 0.0632s\n",
            "5\n",
            "Epoch: 0268 loss_train: 0.7845 acc_train: 0.8250 loss_val: 0.9808 acc_val: 0.7160 time: 0.0688s\n",
            "6\n",
            "Epoch: 0269 loss_train: 0.7989 acc_train: 0.7250 loss_val: 0.9696 acc_val: 0.7140 time: 0.0653s\n",
            "7\n",
            "Epoch: 0270 loss_train: 0.7616 acc_train: 0.8167 loss_val: 0.9569 acc_val: 0.7160 time: 0.0650s\n",
            "8\n",
            "Epoch: 0271 loss_train: 0.7128 acc_train: 0.9000 loss_val: 0.9453 acc_val: 0.7140 time: 0.0661s\n",
            "9\n",
            "Epoch: 0272 loss_train: 0.7934 acc_train: 0.7583 loss_val: 0.9399 acc_val: 0.7280 time: 0.0683s\n",
            "10\n",
            "Epoch: 0273 loss_train: 0.7606 acc_train: 0.8500 loss_val: 0.9399 acc_val: 0.7300 time: 0.0648s\n",
            "11\n",
            "Epoch: 0274 loss_train: 0.7701 acc_train: 0.8000 loss_val: 0.9433 acc_val: 0.7340 time: 0.0634s\n",
            "12\n",
            "Epoch: 0275 loss_train: 0.7338 acc_train: 0.8167 loss_val: 0.9551 acc_val: 0.7260 time: 0.0644s\n",
            "13\n",
            "Epoch: 0276 loss_train: 0.7846 acc_train: 0.7667 loss_val: 0.9689 acc_val: 0.7240 time: 0.0647s\n",
            "14\n",
            "Epoch: 0277 loss_train: 0.7768 acc_train: 0.8417 loss_val: 0.9827 acc_val: 0.7240 time: 0.0631s\n",
            "15\n",
            "Epoch: 0278 loss_train: 0.7371 acc_train: 0.8250 loss_val: 0.9913 acc_val: 0.7240 time: 0.0634s\n",
            "16\n",
            "Epoch: 0279 loss_train: 0.7426 acc_train: 0.8333 loss_val: 0.9887 acc_val: 0.7160 time: 0.0681s\n",
            "17\n",
            "Epoch: 0280 loss_train: 0.7987 acc_train: 0.8250 loss_val: 0.9763 acc_val: 0.7240 time: 0.0635s\n",
            "18\n",
            "Epoch: 0281 loss_train: 0.7750 acc_train: 0.7917 loss_val: 0.9600 acc_val: 0.7220 time: 0.0636s\n",
            "19\n",
            "Epoch: 0282 loss_train: 0.7343 acc_train: 0.8250 loss_val: 0.9485 acc_val: 0.7240 time: 0.0634s\n",
            "20\n",
            "Epoch: 0283 loss_train: 0.8167 acc_train: 0.8000 loss_val: 0.9466 acc_val: 0.7280 time: 0.0649s\n",
            "21\n",
            "Epoch: 0284 loss_train: 0.7666 acc_train: 0.8083 loss_val: 0.9455 acc_val: 0.7300 time: 0.0634s\n",
            "22\n",
            "Epoch: 0285 loss_train: 0.7625 acc_train: 0.7667 loss_val: 0.9438 acc_val: 0.7280 time: 0.0632s\n",
            "23\n",
            "Epoch: 0286 loss_train: 0.7751 acc_train: 0.7583 loss_val: 0.9440 acc_val: 0.7300 time: 0.0651s\n",
            "24\n",
            "Epoch: 0287 loss_train: 0.7987 acc_train: 0.8083 loss_val: 0.9518 acc_val: 0.7320 time: 0.0643s\n",
            "25\n",
            "Epoch: 0288 loss_train: 0.8037 acc_train: 0.7833 loss_val: 0.9709 acc_val: 0.7300 time: 0.0637s\n",
            "26\n",
            "Epoch: 0289 loss_train: 0.7249 acc_train: 0.8167 loss_val: 0.9883 acc_val: 0.7240 time: 0.0634s\n",
            "27\n",
            "Epoch: 0290 loss_train: 0.7411 acc_train: 0.8833 loss_val: 1.0020 acc_val: 0.7160 time: 0.0645s\n",
            "28\n",
            "Epoch: 0291 loss_train: 0.8107 acc_train: 0.7750 loss_val: 1.0006 acc_val: 0.7180 time: 0.0631s\n",
            "29\n",
            "Epoch: 0292 loss_train: 0.7382 acc_train: 0.8583 loss_val: 0.9862 acc_val: 0.7260 time: 0.0633s\n",
            "30\n",
            "Epoch: 0293 loss_train: 0.7320 acc_train: 0.8000 loss_val: 0.9697 acc_val: 0.7240 time: 0.0634s\n",
            "31\n",
            "Epoch: 0294 loss_train: 0.7451 acc_train: 0.8250 loss_val: 0.9508 acc_val: 0.7320 time: 0.0655s\n",
            "32\n",
            "Epoch: 0295 loss_train: 0.7660 acc_train: 0.7667 loss_val: 0.9424 acc_val: 0.7320 time: 0.0655s\n",
            "33\n",
            "Epoch: 0296 loss_train: 0.7156 acc_train: 0.8083 loss_val: 0.9426 acc_val: 0.7340 time: 0.0644s\n",
            "34\n",
            "Epoch: 0297 loss_train: 0.8140 acc_train: 0.7833 loss_val: 0.9468 acc_val: 0.7340 time: 0.0653s\n",
            "35\n",
            "Epoch: 0298 loss_train: 0.7935 acc_train: 0.7583 loss_val: 0.9505 acc_val: 0.7360 time: 0.0660s\n",
            "36\n",
            "Epoch: 0299 loss_train: 0.8086 acc_train: 0.8000 loss_val: 0.9568 acc_val: 0.7340 time: 0.0635s\n",
            "37\n",
            "Epoch: 0300 loss_train: 0.7592 acc_train: 0.7333 loss_val: 0.9616 acc_val: 0.7300 time: 0.0633s\n",
            "38\n",
            "Epoch: 0301 loss_train: 0.7541 acc_train: 0.8500 loss_val: 0.9681 acc_val: 0.7320 time: 0.0674s\n",
            "39\n",
            "Epoch: 0302 loss_train: 0.7680 acc_train: 0.8000 loss_val: 0.9707 acc_val: 0.7320 time: 0.0648s\n",
            "40\n",
            "Epoch: 0303 loss_train: 0.7688 acc_train: 0.8167 loss_val: 0.9731 acc_val: 0.7320 time: 0.0634s\n",
            "41\n",
            "Epoch: 0304 loss_train: 0.8622 acc_train: 0.7500 loss_val: 0.9670 acc_val: 0.7360 time: 0.0631s\n",
            "42\n",
            "Epoch: 0305 loss_train: 0.7553 acc_train: 0.8667 loss_val: 0.9601 acc_val: 0.7340 time: 0.0660s\n",
            "43\n",
            "Epoch: 0306 loss_train: 0.8099 acc_train: 0.7750 loss_val: 0.9505 acc_val: 0.7360 time: 0.0650s\n",
            "44\n",
            "Epoch: 0307 loss_train: 0.7773 acc_train: 0.7583 loss_val: 0.9454 acc_val: 0.7360 time: 0.0635s\n",
            "45\n",
            "Epoch: 0308 loss_train: 0.7552 acc_train: 0.8417 loss_val: 0.9462 acc_val: 0.7340 time: 0.0630s\n",
            "46\n",
            "Epoch: 0309 loss_train: 0.7801 acc_train: 0.8083 loss_val: 0.9510 acc_val: 0.7300 time: 0.0636s\n",
            "47\n",
            "Epoch: 0310 loss_train: 0.7514 acc_train: 0.8333 loss_val: 0.9578 acc_val: 0.7260 time: 0.0643s\n",
            "48\n",
            "Epoch: 0311 loss_train: 0.7778 acc_train: 0.7833 loss_val: 0.9699 acc_val: 0.7200 time: 0.0630s\n",
            "49\n",
            "Epoch: 0312 loss_train: 0.8070 acc_train: 0.7750 loss_val: 0.9780 acc_val: 0.7200 time: 0.0656s\n",
            "50\n",
            "Epoch: 0313 loss_train: 0.7961 acc_train: 0.7417 loss_val: 0.9769 acc_val: 0.7220 time: 0.0648s\n",
            "51\n",
            "Epoch: 0314 loss_train: 0.7273 acc_train: 0.8333 loss_val: 0.9728 acc_val: 0.7340 time: 0.0649s\n",
            "52\n",
            "Epoch: 0315 loss_train: 0.8023 acc_train: 0.8000 loss_val: 0.9632 acc_val: 0.7340 time: 0.0646s\n",
            "53\n",
            "Epoch: 0316 loss_train: 0.7965 acc_train: 0.8250 loss_val: 0.9504 acc_val: 0.7360 time: 0.0653s\n",
            "54\n",
            "Epoch: 0317 loss_train: 0.8160 acc_train: 0.7750 loss_val: 0.9424 acc_val: 0.7360 time: 0.0655s\n",
            "55\n",
            "Epoch: 0318 loss_train: 0.7859 acc_train: 0.7833 loss_val: 0.9406 acc_val: 0.7360 time: 0.0632s\n",
            "56\n",
            "Epoch: 0319 loss_train: 0.7870 acc_train: 0.8083 loss_val: 0.9465 acc_val: 0.7300 time: 0.0645s\n",
            "57\n",
            "Epoch: 0320 loss_train: 0.7458 acc_train: 0.8000 loss_val: 0.9543 acc_val: 0.7260 time: 0.0633s\n",
            "58\n",
            "Epoch: 0321 loss_train: 0.7281 acc_train: 0.8250 loss_val: 0.9608 acc_val: 0.7300 time: 0.0652s\n",
            "59\n",
            "Epoch: 0322 loss_train: 0.7323 acc_train: 0.8083 loss_val: 0.9640 acc_val: 0.7300 time: 0.0631s\n",
            "60\n",
            "Epoch: 0323 loss_train: 0.7898 acc_train: 0.8417 loss_val: 0.9654 acc_val: 0.7280 time: 0.0639s\n",
            "61\n",
            "Epoch: 0324 loss_train: 0.7636 acc_train: 0.8333 loss_val: 0.9660 acc_val: 0.7220 time: 0.0634s\n",
            "62\n",
            "Epoch: 0325 loss_train: 0.7426 acc_train: 0.8417 loss_val: 0.9650 acc_val: 0.7240 time: 0.0635s\n",
            "63\n",
            "Epoch: 0326 loss_train: 0.7776 acc_train: 0.8333 loss_val: 0.9620 acc_val: 0.7300 time: 0.0630s\n",
            "64\n",
            "Epoch: 0327 loss_train: 0.7330 acc_train: 0.8333 loss_val: 0.9605 acc_val: 0.7280 time: 0.0649s\n",
            "65\n",
            "Epoch: 0328 loss_train: 0.7988 acc_train: 0.7833 loss_val: 0.9585 acc_val: 0.7260 time: 0.0634s\n",
            "66\n",
            "Epoch: 0329 loss_train: 0.7726 acc_train: 0.8167 loss_val: 0.9611 acc_val: 0.7360 time: 0.0653s\n",
            "67\n",
            "Epoch: 0330 loss_train: 0.8373 acc_train: 0.7833 loss_val: 0.9638 acc_val: 0.7360 time: 0.0666s\n",
            "68\n",
            "Epoch: 0331 loss_train: 0.8250 acc_train: 0.7833 loss_val: 0.9633 acc_val: 0.7340 time: 0.0666s\n",
            "69\n",
            "Epoch: 0332 loss_train: 0.7605 acc_train: 0.7667 loss_val: 0.9632 acc_val: 0.7300 time: 0.0657s\n",
            "70\n",
            "Epoch: 0333 loss_train: 0.8004 acc_train: 0.8167 loss_val: 0.9601 acc_val: 0.7280 time: 0.0647s\n",
            "71\n",
            "Epoch: 0334 loss_train: 0.7919 acc_train: 0.8250 loss_val: 0.9588 acc_val: 0.7260 time: 0.0646s\n",
            "72\n",
            "Epoch: 0335 loss_train: 0.7572 acc_train: 0.7750 loss_val: 0.9554 acc_val: 0.7280 time: 0.0632s\n",
            "73\n",
            "Epoch: 0336 loss_train: 0.7960 acc_train: 0.8000 loss_val: 0.9535 acc_val: 0.7320 time: 0.0633s\n",
            "74\n",
            "Epoch: 0337 loss_train: 0.7991 acc_train: 0.7833 loss_val: 0.9514 acc_val: 0.7300 time: 0.0635s\n",
            "75\n",
            "Epoch: 0338 loss_train: 0.7394 acc_train: 0.7667 loss_val: 0.9528 acc_val: 0.7360 time: 0.0646s\n",
            "76\n",
            "Epoch: 0339 loss_train: 0.7546 acc_train: 0.8083 loss_val: 0.9588 acc_val: 0.7320 time: 0.0635s\n",
            "77\n",
            "Epoch: 0340 loss_train: 0.7498 acc_train: 0.8000 loss_val: 0.9658 acc_val: 0.7260 time: 0.0630s\n",
            "78\n",
            "Epoch: 0341 loss_train: 0.7716 acc_train: 0.8167 loss_val: 0.9713 acc_val: 0.7240 time: 0.0631s\n",
            "79\n",
            "Epoch: 0342 loss_train: 0.7704 acc_train: 0.7250 loss_val: 0.9746 acc_val: 0.7280 time: 0.0659s\n",
            "80\n",
            "Epoch: 0343 loss_train: 0.8034 acc_train: 0.8167 loss_val: 0.9693 acc_val: 0.7300 time: 0.0650s\n",
            "81\n",
            "Epoch: 0344 loss_train: 0.7680 acc_train: 0.7750 loss_val: 0.9655 acc_val: 0.7360 time: 0.0639s\n",
            "82\n",
            "Epoch: 0345 loss_train: 0.7585 acc_train: 0.8417 loss_val: 0.9621 acc_val: 0.7300 time: 0.0632s\n",
            "83\n",
            "Epoch: 0346 loss_train: 0.7870 acc_train: 0.7750 loss_val: 0.9618 acc_val: 0.7240 time: 0.0642s\n",
            "84\n",
            "Epoch: 0347 loss_train: 0.6929 acc_train: 0.8667 loss_val: 0.9583 acc_val: 0.7260 time: 0.0658s\n",
            "85\n",
            "Epoch: 0348 loss_train: 0.7638 acc_train: 0.7333 loss_val: 0.9535 acc_val: 0.7260 time: 0.0633s\n",
            "86\n",
            "Epoch: 0349 loss_train: 0.8016 acc_train: 0.8167 loss_val: 0.9489 acc_val: 0.7280 time: 0.0646s\n",
            "87\n",
            "Epoch: 0350 loss_train: 0.8202 acc_train: 0.7917 loss_val: 0.9475 acc_val: 0.7300 time: 0.0631s\n",
            "88\n",
            "Epoch: 0351 loss_train: 0.7533 acc_train: 0.8250 loss_val: 0.9482 acc_val: 0.7280 time: 0.0643s\n",
            "89\n",
            "Epoch: 0352 loss_train: 0.7787 acc_train: 0.8417 loss_val: 0.9517 acc_val: 0.7300 time: 0.0631s\n",
            "90\n",
            "Epoch: 0353 loss_train: 0.7556 acc_train: 0.8167 loss_val: 0.9572 acc_val: 0.7300 time: 0.0653s\n",
            "91\n",
            "Epoch: 0354 loss_train: 0.7582 acc_train: 0.8333 loss_val: 0.9628 acc_val: 0.7300 time: 0.0647s\n",
            "92\n",
            "Epoch: 0355 loss_train: 0.7353 acc_train: 0.8083 loss_val: 0.9671 acc_val: 0.7300 time: 0.0631s\n",
            "93\n",
            "Epoch: 0356 loss_train: 0.8137 acc_train: 0.8167 loss_val: 0.9672 acc_val: 0.7360 time: 0.0635s\n",
            "94\n",
            "Epoch: 0357 loss_train: 0.7663 acc_train: 0.7667 loss_val: 0.9662 acc_val: 0.7360 time: 0.0663s\n",
            "95\n",
            "Epoch: 0358 loss_train: 0.7700 acc_train: 0.8000 loss_val: 0.9620 acc_val: 0.7320 time: 0.0662s\n",
            "96\n",
            "Epoch: 0359 loss_train: 0.7570 acc_train: 0.8167 loss_val: 0.9563 acc_val: 0.7320 time: 0.0663s\n",
            "97\n",
            "Epoch: 0360 loss_train: 0.7995 acc_train: 0.7250 loss_val: 0.9494 acc_val: 0.7340 time: 0.0668s\n",
            "98\n",
            "Epoch: 0361 loss_train: 0.8503 acc_train: 0.7750 loss_val: 0.9472 acc_val: 0.7320 time: 0.0649s\n",
            "99\n",
            "Epoch: 0362 loss_train: 0.7565 acc_train: 0.8250 loss_val: 0.9493 acc_val: 0.7340 time: 0.0655s\n",
            "100\n",
            "Epoch: 0363 loss_train: 0.7689 acc_train: 0.8500 loss_val: 0.9538 acc_val: 0.7320 time: 0.0645s\n",
            "101\n",
            "Epoch: 0364 loss_train: 0.8032 acc_train: 0.7667 loss_val: 0.9545 acc_val: 0.7320 time: 0.0669s\n",
            "102\n",
            "Epoch: 0365 loss_train: 0.7622 acc_train: 0.7667 loss_val: 0.9520 acc_val: 0.7300 time: 0.0640s\n",
            "103\n",
            "Epoch: 0366 loss_train: 0.7579 acc_train: 0.8167 loss_val: 0.9507 acc_val: 0.7320 time: 0.0641s\n",
            "104\n",
            "Epoch: 0367 loss_train: 0.7567 acc_train: 0.7833 loss_val: 0.9497 acc_val: 0.7320 time: 0.0651s\n",
            "105\n",
            "Epoch: 0368 loss_train: 0.8054 acc_train: 0.7917 loss_val: 0.9534 acc_val: 0.7280 time: 0.0638s\n",
            "106\n",
            "Epoch: 0369 loss_train: 0.7365 acc_train: 0.8167 loss_val: 0.9572 acc_val: 0.7300 time: 0.0636s\n",
            "107\n",
            "Epoch: 0370 loss_train: 0.8044 acc_train: 0.8250 loss_val: 0.9605 acc_val: 0.7380 time: 0.0641s\n",
            "108\n",
            "Epoch: 0371 loss_train: 0.8183 acc_train: 0.7417 loss_val: 0.9582 acc_val: 0.7300 time: 0.0641s\n",
            "109\n",
            "Epoch: 0372 loss_train: 0.7698 acc_train: 0.8083 loss_val: 0.9548 acc_val: 0.7280 time: 0.0646s\n",
            "110\n",
            "Epoch: 0373 loss_train: 0.7522 acc_train: 0.8000 loss_val: 0.9564 acc_val: 0.7300 time: 0.0648s\n",
            "111\n",
            "Epoch: 0374 loss_train: 0.7682 acc_train: 0.8167 loss_val: 0.9611 acc_val: 0.7320 time: 0.0648s\n",
            "112\n",
            "Epoch: 0375 loss_train: 0.7645 acc_train: 0.8583 loss_val: 0.9664 acc_val: 0.7300 time: 0.0639s\n",
            "113\n",
            "Epoch: 0376 loss_train: 0.8076 acc_train: 0.8167 loss_val: 0.9689 acc_val: 0.7260 time: 0.0638s\n",
            "114\n",
            "Epoch: 0377 loss_train: 0.7901 acc_train: 0.8000 loss_val: 0.9681 acc_val: 0.7240 time: 0.0673s\n",
            "115\n",
            "Epoch: 0378 loss_train: 0.7457 acc_train: 0.7667 loss_val: 0.9631 acc_val: 0.7220 time: 0.0640s\n",
            "116\n",
            "Epoch: 0379 loss_train: 0.7296 acc_train: 0.8000 loss_val: 0.9582 acc_val: 0.7180 time: 0.0642s\n",
            "117\n",
            "Epoch: 0380 loss_train: 0.7844 acc_train: 0.7417 loss_val: 0.9558 acc_val: 0.7160 time: 0.0633s\n",
            "118\n",
            "Epoch: 0381 loss_train: 0.7684 acc_train: 0.8417 loss_val: 0.9543 acc_val: 0.7160 time: 0.0652s\n",
            "119\n",
            "Epoch: 0382 loss_train: 0.7625 acc_train: 0.7833 loss_val: 0.9522 acc_val: 0.7180 time: 0.0649s\n",
            "120\n",
            "Epoch: 0383 loss_train: 0.7409 acc_train: 0.8000 loss_val: 0.9509 acc_val: 0.7280 time: 0.0650s\n",
            "121\n",
            "Epoch: 0384 loss_train: 0.7769 acc_train: 0.8250 loss_val: 0.9526 acc_val: 0.7300 time: 0.0654s\n",
            "122\n",
            "Epoch: 0385 loss_train: 0.7973 acc_train: 0.8000 loss_val: 0.9583 acc_val: 0.7240 time: 0.0658s\n",
            "123\n",
            "Epoch: 0386 loss_train: 0.8104 acc_train: 0.7417 loss_val: 0.9674 acc_val: 0.7200 time: 0.0648s\n",
            "124\n",
            "Epoch: 0387 loss_train: 0.7350 acc_train: 0.7750 loss_val: 0.9722 acc_val: 0.7240 time: 0.0658s\n",
            "125\n",
            "Epoch: 0388 loss_train: 0.7093 acc_train: 0.8333 loss_val: 0.9737 acc_val: 0.7260 time: 0.0646s\n",
            "126\n",
            "Epoch: 0389 loss_train: 0.7758 acc_train: 0.8167 loss_val: 0.9670 acc_val: 0.7300 time: 0.0633s\n",
            "127\n",
            "Epoch: 0390 loss_train: 0.8048 acc_train: 0.8000 loss_val: 0.9577 acc_val: 0.7300 time: 0.0631s\n",
            "128\n",
            "Epoch: 0391 loss_train: 0.7474 acc_train: 0.7833 loss_val: 0.9526 acc_val: 0.7260 time: 0.0634s\n",
            "129\n",
            "Epoch: 0392 loss_train: 0.7721 acc_train: 0.8333 loss_val: 0.9511 acc_val: 0.7240 time: 0.0645s\n",
            "130\n",
            "Epoch: 0393 loss_train: 0.7790 acc_train: 0.7750 loss_val: 0.9499 acc_val: 0.7240 time: 0.0652s\n",
            "131\n",
            "Epoch: 0394 loss_train: 0.7883 acc_train: 0.7833 loss_val: 0.9543 acc_val: 0.7200 time: 0.0632s\n",
            "132\n",
            "Epoch: 0395 loss_train: 0.7824 acc_train: 0.7500 loss_val: 0.9596 acc_val: 0.7200 time: 0.0632s\n",
            "133\n",
            "Epoch: 0396 loss_train: 0.7661 acc_train: 0.8083 loss_val: 0.9611 acc_val: 0.7180 time: 0.0642s\n",
            "134\n",
            "Epoch: 0397 loss_train: 0.8109 acc_train: 0.7417 loss_val: 0.9589 acc_val: 0.7280 time: 0.0660s\n",
            "135\n",
            "Epoch: 0398 loss_train: 0.7914 acc_train: 0.8167 loss_val: 0.9594 acc_val: 0.7260 time: 0.0662s\n",
            "136\n",
            "Epoch: 0399 loss_train: 0.7481 acc_train: 0.7500 loss_val: 0.9638 acc_val: 0.7260 time: 0.0653s\n",
            "137\n",
            "Epoch: 0400 loss_train: 0.7845 acc_train: 0.8167 loss_val: 0.9621 acc_val: 0.7260 time: 0.0667s\n",
            "138\n",
            "Epoch: 0401 loss_train: 0.7695 acc_train: 0.8000 loss_val: 0.9607 acc_val: 0.7300 time: 0.0645s\n",
            "139\n",
            "Epoch: 0402 loss_train: 0.7516 acc_train: 0.8083 loss_val: 0.9586 acc_val: 0.7320 time: 0.0635s\n",
            "140\n",
            "Epoch: 0403 loss_train: 0.7614 acc_train: 0.8500 loss_val: 0.9586 acc_val: 0.7320 time: 0.0653s\n",
            "141\n",
            "Epoch: 0404 loss_train: 0.7966 acc_train: 0.7917 loss_val: 0.9554 acc_val: 0.7280 time: 0.0646s\n",
            "142\n",
            "Epoch: 0405 loss_train: 0.8073 acc_train: 0.8167 loss_val: 0.9545 acc_val: 0.7300 time: 0.0653s\n",
            "143\n",
            "Epoch: 0406 loss_train: 0.7872 acc_train: 0.7500 loss_val: 0.9519 acc_val: 0.7340 time: 0.0653s\n",
            "144\n",
            "Epoch: 0407 loss_train: 0.7881 acc_train: 0.7750 loss_val: 0.9532 acc_val: 0.7300 time: 0.0652s\n",
            "145\n",
            "Epoch: 0408 loss_train: 0.8165 acc_train: 0.7917 loss_val: 0.9553 acc_val: 0.7260 time: 0.0650s\n",
            "146\n",
            "Epoch: 0409 loss_train: 0.7284 acc_train: 0.7583 loss_val: 0.9570 acc_val: 0.7240 time: 0.0632s\n",
            "147\n",
            "Epoch: 0410 loss_train: 0.8121 acc_train: 0.7500 loss_val: 0.9552 acc_val: 0.7240 time: 0.0641s\n",
            "148\n",
            "Epoch: 0411 loss_train: 0.7459 acc_train: 0.8583 loss_val: 0.9512 acc_val: 0.7280 time: 0.0632s\n",
            "149\n",
            "Epoch: 0412 loss_train: 0.7882 acc_train: 0.7833 loss_val: 0.9470 acc_val: 0.7300 time: 0.0628s\n",
            "150\n",
            "Epoch: 0413 loss_train: 0.7647 acc_train: 0.7833 loss_val: 0.9450 acc_val: 0.7320 time: 0.0626s\n",
            "151\n",
            "Epoch: 0414 loss_train: 0.7645 acc_train: 0.7833 loss_val: 0.9441 acc_val: 0.7320 time: 0.0649s\n",
            "152\n",
            "Epoch: 0415 loss_train: 0.7287 acc_train: 0.7500 loss_val: 0.9474 acc_val: 0.7320 time: 0.0633s\n",
            "153\n",
            "Epoch: 0416 loss_train: 0.7218 acc_train: 0.8250 loss_val: 0.9538 acc_val: 0.7300 time: 0.0632s\n",
            "154\n",
            "Epoch: 0417 loss_train: 0.7082 acc_train: 0.8417 loss_val: 0.9605 acc_val: 0.7320 time: 0.0640s\n",
            "155\n",
            "Epoch: 0418 loss_train: 0.8040 acc_train: 0.8333 loss_val: 0.9645 acc_val: 0.7260 time: 0.0645s\n",
            "156\n",
            "Epoch: 0419 loss_train: 0.7532 acc_train: 0.8417 loss_val: 0.9652 acc_val: 0.7220 time: 0.0631s\n",
            "157\n",
            "Epoch: 0420 loss_train: 0.7345 acc_train: 0.8333 loss_val: 0.9621 acc_val: 0.7220 time: 0.0631s\n",
            "158\n",
            "Epoch: 0421 loss_train: 0.8167 acc_train: 0.7750 loss_val: 0.9591 acc_val: 0.7240 time: 0.0631s\n",
            "159\n",
            "Epoch: 0422 loss_train: 0.7239 acc_train: 0.8000 loss_val: 0.9524 acc_val: 0.7280 time: 0.0649s\n",
            "160\n",
            "Epoch: 0423 loss_train: 0.7829 acc_train: 0.8333 loss_val: 0.9442 acc_val: 0.7300 time: 0.0646s\n",
            "161\n",
            "Epoch: 0424 loss_train: 0.8328 acc_train: 0.8083 loss_val: 0.9389 acc_val: 0.7360 time: 0.0635s\n",
            "162\n",
            "Epoch: 0425 loss_train: 0.7860 acc_train: 0.8250 loss_val: 0.9369 acc_val: 0.7380 time: 0.0634s\n",
            "163\n",
            "Epoch: 0426 loss_train: 0.8004 acc_train: 0.7167 loss_val: 0.9404 acc_val: 0.7340 time: 0.0652s\n",
            "0\n",
            "Epoch: 0427 loss_train: 0.7621 acc_train: 0.7750 loss_val: 0.9481 acc_val: 0.7300 time: 0.0688s\n",
            "1\n",
            "Epoch: 0428 loss_train: 0.7607 acc_train: 0.9000 loss_val: 0.9545 acc_val: 0.7340 time: 0.0638s\n",
            "2\n",
            "Epoch: 0429 loss_train: 0.7922 acc_train: 0.7833 loss_val: 0.9558 acc_val: 0.7320 time: 0.0666s\n",
            "3\n",
            "Epoch: 0430 loss_train: 0.7489 acc_train: 0.9083 loss_val: 0.9606 acc_val: 0.7240 time: 0.0658s\n",
            "4\n",
            "Epoch: 0431 loss_train: 0.7231 acc_train: 0.8083 loss_val: 0.9633 acc_val: 0.7260 time: 0.0651s\n",
            "5\n",
            "Epoch: 0432 loss_train: 0.7886 acc_train: 0.7333 loss_val: 0.9621 acc_val: 0.7220 time: 0.0667s\n",
            "6\n",
            "Epoch: 0433 loss_train: 0.7211 acc_train: 0.8417 loss_val: 0.9613 acc_val: 0.7240 time: 0.0660s\n",
            "7\n",
            "Epoch: 0434 loss_train: 0.7549 acc_train: 0.8333 loss_val: 0.9611 acc_val: 0.7220 time: 0.0633s\n",
            "8\n",
            "Epoch: 0435 loss_train: 0.7828 acc_train: 0.8167 loss_val: 0.9584 acc_val: 0.7200 time: 0.0628s\n",
            "9\n",
            "Epoch: 0436 loss_train: 0.7469 acc_train: 0.7667 loss_val: 0.9512 acc_val: 0.7280 time: 0.0649s\n",
            "10\n",
            "Epoch: 0437 loss_train: 0.7546 acc_train: 0.8167 loss_val: 0.9475 acc_val: 0.7300 time: 0.0657s\n",
            "11\n",
            "Epoch: 0438 loss_train: 0.8367 acc_train: 0.7583 loss_val: 0.9474 acc_val: 0.7320 time: 0.0648s\n",
            "12\n",
            "Epoch: 0439 loss_train: 0.7693 acc_train: 0.8083 loss_val: 0.9496 acc_val: 0.7320 time: 0.0634s\n",
            "13\n",
            "Epoch: 0440 loss_train: 0.7801 acc_train: 0.7917 loss_val: 0.9547 acc_val: 0.7320 time: 0.0649s\n",
            "14\n",
            "Epoch: 0441 loss_train: 0.7858 acc_train: 0.7750 loss_val: 0.9582 acc_val: 0.7320 time: 0.0646s\n",
            "15\n",
            "Epoch: 0442 loss_train: 0.7759 acc_train: 0.8083 loss_val: 0.9582 acc_val: 0.7320 time: 0.0635s\n",
            "16\n",
            "Epoch: 0443 loss_train: 0.7972 acc_train: 0.8417 loss_val: 0.9547 acc_val: 0.7300 time: 0.0642s\n",
            "17\n",
            "Epoch: 0444 loss_train: 0.7464 acc_train: 0.8500 loss_val: 0.9545 acc_val: 0.7320 time: 0.0642s\n",
            "18\n",
            "Epoch: 0445 loss_train: 0.7722 acc_train: 0.8167 loss_val: 0.9578 acc_val: 0.7340 time: 0.0631s\n",
            "19\n",
            "Epoch: 0446 loss_train: 0.7938 acc_train: 0.7667 loss_val: 0.9586 acc_val: 0.7320 time: 0.0647s\n",
            "20\n",
            "Epoch: 0447 loss_train: 0.7273 acc_train: 0.8667 loss_val: 0.9552 acc_val: 0.7360 time: 0.0663s\n",
            "21\n",
            "Epoch: 0448 loss_train: 0.7876 acc_train: 0.8167 loss_val: 0.9515 acc_val: 0.7320 time: 0.0654s\n",
            "22\n",
            "Epoch: 0449 loss_train: 0.7094 acc_train: 0.8083 loss_val: 0.9478 acc_val: 0.7300 time: 0.0649s\n",
            "23\n",
            "Epoch: 0450 loss_train: 0.7849 acc_train: 0.8000 loss_val: 0.9454 acc_val: 0.7300 time: 0.0643s\n",
            "24\n",
            "Epoch: 0451 loss_train: 0.7501 acc_train: 0.8167 loss_val: 0.9451 acc_val: 0.7300 time: 0.0644s\n",
            "25\n",
            "Epoch: 0452 loss_train: 0.7451 acc_train: 0.8167 loss_val: 0.9454 acc_val: 0.7300 time: 0.0645s\n",
            "26\n",
            "Epoch: 0453 loss_train: 0.7254 acc_train: 0.8500 loss_val: 0.9444 acc_val: 0.7300 time: 0.0653s\n",
            "27\n",
            "Epoch: 0454 loss_train: 0.7542 acc_train: 0.7750 loss_val: 0.9464 acc_val: 0.7320 time: 0.0649s\n",
            "28\n",
            "Epoch: 0455 loss_train: 0.7977 acc_train: 0.8083 loss_val: 0.9469 acc_val: 0.7340 time: 0.0633s\n",
            "29\n",
            "Epoch: 0456 loss_train: 0.7451 acc_train: 0.8500 loss_val: 0.9469 acc_val: 0.7340 time: 0.0631s\n",
            "30\n",
            "Epoch: 0457 loss_train: 0.7320 acc_train: 0.7917 loss_val: 0.9517 acc_val: 0.7280 time: 0.0633s\n",
            "31\n",
            "Epoch: 0458 loss_train: 0.7665 acc_train: 0.8417 loss_val: 0.9589 acc_val: 0.7280 time: 0.0646s\n",
            "32\n",
            "Epoch: 0459 loss_train: 0.7438 acc_train: 0.8083 loss_val: 0.9660 acc_val: 0.7260 time: 0.0653s\n",
            "33\n",
            "Epoch: 0460 loss_train: 0.7966 acc_train: 0.7333 loss_val: 0.9703 acc_val: 0.7260 time: 0.0636s\n",
            "34\n",
            "Epoch: 0461 loss_train: 0.8015 acc_train: 0.7917 loss_val: 0.9741 acc_val: 0.7240 time: 0.0632s\n",
            "35\n",
            "Epoch: 0462 loss_train: 0.7702 acc_train: 0.8250 loss_val: 0.9701 acc_val: 0.7300 time: 0.0648s\n",
            "36\n",
            "Epoch: 0463 loss_train: 0.7601 acc_train: 0.7917 loss_val: 0.9631 acc_val: 0.7260 time: 0.0652s\n",
            "37\n",
            "Epoch: 0464 loss_train: 0.7350 acc_train: 0.8667 loss_val: 0.9562 acc_val: 0.7240 time: 0.0634s\n",
            "38\n",
            "Epoch: 0465 loss_train: 0.8054 acc_train: 0.7750 loss_val: 0.9482 acc_val: 0.7260 time: 0.0652s\n",
            "39\n",
            "Epoch: 0466 loss_train: 0.7694 acc_train: 0.7750 loss_val: 0.9392 acc_val: 0.7320 time: 0.0646s\n",
            "40\n",
            "Epoch: 0467 loss_train: 0.7847 acc_train: 0.8000 loss_val: 0.9353 acc_val: 0.7320 time: 0.0677s\n",
            "41\n",
            "Epoch: 0468 loss_train: 0.7381 acc_train: 0.7833 loss_val: 0.9348 acc_val: 0.7320 time: 0.0650s\n",
            "0\n",
            "Epoch: 0469 loss_train: 0.7961 acc_train: 0.8000 loss_val: 0.9395 acc_val: 0.7300 time: 0.0647s\n",
            "0\n",
            "Epoch: 0470 loss_train: 0.8155 acc_train: 0.8083 loss_val: 0.9467 acc_val: 0.7320 time: 0.0637s\n",
            "1\n",
            "Epoch: 0471 loss_train: 0.7325 acc_train: 0.8000 loss_val: 0.9598 acc_val: 0.7300 time: 0.0630s\n",
            "2\n",
            "Epoch: 0472 loss_train: 0.7772 acc_train: 0.7917 loss_val: 0.9684 acc_val: 0.7300 time: 0.0642s\n",
            "3\n",
            "Epoch: 0473 loss_train: 0.7880 acc_train: 0.8167 loss_val: 0.9720 acc_val: 0.7220 time: 0.0634s\n",
            "4\n",
            "Epoch: 0474 loss_train: 0.7498 acc_train: 0.7833 loss_val: 0.9697 acc_val: 0.7220 time: 0.0630s\n",
            "5\n",
            "Epoch: 0475 loss_train: 0.8207 acc_train: 0.7333 loss_val: 0.9673 acc_val: 0.7220 time: 0.0631s\n",
            "6\n",
            "Epoch: 0476 loss_train: 0.8013 acc_train: 0.8083 loss_val: 0.9602 acc_val: 0.7280 time: 0.0639s\n",
            "7\n",
            "Epoch: 0477 loss_train: 0.7690 acc_train: 0.8000 loss_val: 0.9526 acc_val: 0.7320 time: 0.0637s\n",
            "8\n",
            "Epoch: 0478 loss_train: 0.7009 acc_train: 0.7917 loss_val: 0.9449 acc_val: 0.7320 time: 0.0642s\n",
            "9\n",
            "Epoch: 0479 loss_train: 0.8279 acc_train: 0.7667 loss_val: 0.9410 acc_val: 0.7320 time: 0.0633s\n",
            "10\n",
            "Epoch: 0480 loss_train: 0.7952 acc_train: 0.8167 loss_val: 0.9417 acc_val: 0.7360 time: 0.0647s\n",
            "11\n",
            "Epoch: 0481 loss_train: 0.7932 acc_train: 0.8167 loss_val: 0.9465 acc_val: 0.7300 time: 0.0632s\n",
            "12\n",
            "Epoch: 0482 loss_train: 0.7701 acc_train: 0.8167 loss_val: 0.9579 acc_val: 0.7320 time: 0.0633s\n",
            "13\n",
            "Epoch: 0483 loss_train: 0.7110 acc_train: 0.8167 loss_val: 0.9661 acc_val: 0.7240 time: 0.0631s\n",
            "14\n",
            "Epoch: 0484 loss_train: 0.7627 acc_train: 0.7750 loss_val: 0.9748 acc_val: 0.7220 time: 0.0654s\n",
            "15\n",
            "Epoch: 0485 loss_train: 0.8009 acc_train: 0.7417 loss_val: 0.9738 acc_val: 0.7180 time: 0.0633s\n",
            "16\n",
            "Epoch: 0486 loss_train: 0.7482 acc_train: 0.8250 loss_val: 0.9648 acc_val: 0.7220 time: 0.0631s\n",
            "17\n",
            "Epoch: 0487 loss_train: 0.8379 acc_train: 0.8083 loss_val: 0.9524 acc_val: 0.7200 time: 0.0636s\n",
            "18\n",
            "Epoch: 0488 loss_train: 0.7419 acc_train: 0.8250 loss_val: 0.9413 acc_val: 0.7220 time: 0.0653s\n",
            "19\n",
            "Epoch: 0489 loss_train: 0.7703 acc_train: 0.7917 loss_val: 0.9350 acc_val: 0.7220 time: 0.0646s\n",
            "20\n",
            "Epoch: 0490 loss_train: 0.7192 acc_train: 0.8250 loss_val: 0.9350 acc_val: 0.7260 time: 0.0656s\n",
            "21\n",
            "Epoch: 0491 loss_train: 0.7450 acc_train: 0.8333 loss_val: 0.9412 acc_val: 0.7280 time: 0.0662s\n",
            "22\n",
            "Epoch: 0492 loss_train: 0.7685 acc_train: 0.7667 loss_val: 0.9519 acc_val: 0.7240 time: 0.0681s\n",
            "23\n",
            "Epoch: 0493 loss_train: 0.7488 acc_train: 0.7833 loss_val: 0.9624 acc_val: 0.7200 time: 0.0651s\n",
            "24\n",
            "Epoch: 0494 loss_train: 0.7252 acc_train: 0.8000 loss_val: 0.9707 acc_val: 0.7180 time: 0.0648s\n",
            "25\n",
            "Epoch: 0495 loss_train: 0.7110 acc_train: 0.8000 loss_val: 0.9727 acc_val: 0.7200 time: 0.0645s\n",
            "26\n",
            "Epoch: 0496 loss_train: 0.7126 acc_train: 0.7833 loss_val: 0.9675 acc_val: 0.7280 time: 0.0634s\n",
            "27\n",
            "Epoch: 0497 loss_train: 0.7700 acc_train: 0.8333 loss_val: 0.9652 acc_val: 0.7240 time: 0.0676s\n",
            "28\n",
            "Epoch: 0498 loss_train: 0.7279 acc_train: 0.8583 loss_val: 0.9558 acc_val: 0.7260 time: 0.0669s\n",
            "29\n",
            "Epoch: 0499 loss_train: 0.7281 acc_train: 0.8000 loss_val: 0.9516 acc_val: 0.7240 time: 0.0657s\n",
            "30\n",
            "Epoch: 0500 loss_train: 0.7502 acc_train: 0.7667 loss_val: 0.9502 acc_val: 0.7300 time: 0.0635s\n",
            "31\n",
            "Epoch: 0501 loss_train: 0.8014 acc_train: 0.7667 loss_val: 0.9501 acc_val: 0.7320 time: 0.0632s\n",
            "32\n",
            "Epoch: 0502 loss_train: 0.7826 acc_train: 0.7917 loss_val: 0.9516 acc_val: 0.7320 time: 0.0639s\n",
            "33\n",
            "Epoch: 0503 loss_train: 0.7665 acc_train: 0.7417 loss_val: 0.9547 acc_val: 0.7300 time: 0.0631s\n",
            "34\n",
            "Epoch: 0504 loss_train: 0.7808 acc_train: 0.8500 loss_val: 0.9585 acc_val: 0.7280 time: 0.0634s\n",
            "35\n",
            "Epoch: 0505 loss_train: 0.7482 acc_train: 0.8417 loss_val: 0.9589 acc_val: 0.7260 time: 0.0644s\n",
            "36\n",
            "Epoch: 0506 loss_train: 0.7196 acc_train: 0.8000 loss_val: 0.9568 acc_val: 0.7260 time: 0.0655s\n",
            "37\n",
            "Epoch: 0507 loss_train: 0.7586 acc_train: 0.8000 loss_val: 0.9523 acc_val: 0.7260 time: 0.0647s\n",
            "38\n",
            "Epoch: 0508 loss_train: 0.8271 acc_train: 0.8000 loss_val: 0.9508 acc_val: 0.7240 time: 0.0643s\n",
            "39\n",
            "Epoch: 0509 loss_train: 0.7130 acc_train: 0.8167 loss_val: 0.9503 acc_val: 0.7240 time: 0.0642s\n",
            "40\n",
            "Epoch: 0510 loss_train: 0.7743 acc_train: 0.7750 loss_val: 0.9502 acc_val: 0.7240 time: 0.0646s\n",
            "41\n",
            "Epoch: 0511 loss_train: 0.7787 acc_train: 0.8000 loss_val: 0.9524 acc_val: 0.7260 time: 0.0631s\n",
            "42\n",
            "Epoch: 0512 loss_train: 0.7828 acc_train: 0.8167 loss_val: 0.9580 acc_val: 0.7240 time: 0.0632s\n",
            "43\n",
            "Epoch: 0513 loss_train: 0.8013 acc_train: 0.8083 loss_val: 0.9659 acc_val: 0.7200 time: 0.0671s\n",
            "44\n",
            "Epoch: 0514 loss_train: 0.7325 acc_train: 0.7667 loss_val: 0.9651 acc_val: 0.7200 time: 0.0646s\n",
            "45\n",
            "Epoch: 0515 loss_train: 0.7351 acc_train: 0.8833 loss_val: 0.9647 acc_val: 0.7200 time: 0.0632s\n",
            "46\n",
            "Epoch: 0516 loss_train: 0.7339 acc_train: 0.8333 loss_val: 0.9606 acc_val: 0.7220 time: 0.0633s\n",
            "47\n",
            "Epoch: 0517 loss_train: 0.7235 acc_train: 0.8250 loss_val: 0.9543 acc_val: 0.7220 time: 0.0646s\n",
            "48\n",
            "Epoch: 0518 loss_train: 0.8044 acc_train: 0.7000 loss_val: 0.9501 acc_val: 0.7260 time: 0.0638s\n",
            "49\n",
            "Epoch: 0519 loss_train: 0.7673 acc_train: 0.7667 loss_val: 0.9494 acc_val: 0.7280 time: 0.0665s\n",
            "50\n",
            "Epoch: 0520 loss_train: 0.7724 acc_train: 0.7667 loss_val: 0.9513 acc_val: 0.7280 time: 0.0631s\n",
            "51\n",
            "Epoch: 0521 loss_train: 0.7970 acc_train: 0.8333 loss_val: 0.9558 acc_val: 0.7300 time: 0.0661s\n",
            "52\n",
            "Epoch: 0522 loss_train: 0.7763 acc_train: 0.8250 loss_val: 0.9609 acc_val: 0.7280 time: 0.0648s\n",
            "53\n",
            "Epoch: 0523 loss_train: 0.7654 acc_train: 0.8250 loss_val: 0.9645 acc_val: 0.7220 time: 0.0650s\n",
            "54\n",
            "Epoch: 0524 loss_train: 0.7961 acc_train: 0.8000 loss_val: 0.9633 acc_val: 0.7200 time: 0.0643s\n",
            "55\n",
            "Epoch: 0525 loss_train: 0.7999 acc_train: 0.8250 loss_val: 0.9611 acc_val: 0.7220 time: 0.0631s\n",
            "56\n",
            "Epoch: 0526 loss_train: 0.7324 acc_train: 0.8000 loss_val: 0.9609 acc_val: 0.7180 time: 0.0630s\n",
            "57\n",
            "Epoch: 0527 loss_train: 0.7666 acc_train: 0.7833 loss_val: 0.9622 acc_val: 0.7180 time: 0.0637s\n",
            "58\n",
            "Epoch: 0528 loss_train: 0.7296 acc_train: 0.8083 loss_val: 0.9604 acc_val: 0.7220 time: 0.0654s\n",
            "59\n",
            "Epoch: 0529 loss_train: 0.7874 acc_train: 0.7667 loss_val: 0.9547 acc_val: 0.7260 time: 0.0682s\n",
            "60\n",
            "Epoch: 0530 loss_train: 0.7592 acc_train: 0.7917 loss_val: 0.9476 acc_val: 0.7280 time: 0.0660s\n",
            "61\n",
            "Epoch: 0531 loss_train: 0.7426 acc_train: 0.7833 loss_val: 0.9476 acc_val: 0.7320 time: 0.0651s\n",
            "62\n",
            "Epoch: 0532 loss_train: 0.7382 acc_train: 0.8167 loss_val: 0.9494 acc_val: 0.7300 time: 0.0677s\n",
            "63\n",
            "Epoch: 0533 loss_train: 0.7440 acc_train: 0.7917 loss_val: 0.9534 acc_val: 0.7280 time: 0.0639s\n",
            "64\n",
            "Epoch: 0534 loss_train: 0.8191 acc_train: 0.7750 loss_val: 0.9568 acc_val: 0.7280 time: 0.0654s\n",
            "65\n",
            "Epoch: 0535 loss_train: 0.8122 acc_train: 0.7667 loss_val: 0.9574 acc_val: 0.7300 time: 0.0652s\n",
            "66\n",
            "Epoch: 0536 loss_train: 0.8006 acc_train: 0.7417 loss_val: 0.9584 acc_val: 0.7340 time: 0.0647s\n",
            "67\n",
            "Epoch: 0537 loss_train: 0.7751 acc_train: 0.7500 loss_val: 0.9617 acc_val: 0.7340 time: 0.0662s\n",
            "68\n",
            "Epoch: 0538 loss_train: 0.7701 acc_train: 0.8500 loss_val: 0.9637 acc_val: 0.7260 time: 0.0637s\n",
            "69\n",
            "Epoch: 0539 loss_train: 0.7733 acc_train: 0.7833 loss_val: 0.9593 acc_val: 0.7200 time: 0.0666s\n",
            "70\n",
            "Epoch: 0540 loss_train: 0.7971 acc_train: 0.7667 loss_val: 0.9560 acc_val: 0.7240 time: 0.0646s\n",
            "71\n",
            "Epoch: 0541 loss_train: 0.7387 acc_train: 0.8000 loss_val: 0.9551 acc_val: 0.7280 time: 0.0648s\n",
            "72\n",
            "Epoch: 0542 loss_train: 0.7987 acc_train: 0.8167 loss_val: 0.9582 acc_val: 0.7240 time: 0.0644s\n",
            "73\n",
            "Epoch: 0543 loss_train: 0.7856 acc_train: 0.8083 loss_val: 0.9594 acc_val: 0.7260 time: 0.0635s\n",
            "74\n",
            "Epoch: 0544 loss_train: 0.7706 acc_train: 0.7917 loss_val: 0.9648 acc_val: 0.7260 time: 0.0641s\n",
            "75\n",
            "Epoch: 0545 loss_train: 0.7451 acc_train: 0.7917 loss_val: 0.9681 acc_val: 0.7260 time: 0.0637s\n",
            "76\n",
            "Epoch: 0546 loss_train: 0.7278 acc_train: 0.8333 loss_val: 0.9675 acc_val: 0.7260 time: 0.0673s\n",
            "77\n",
            "Epoch: 0547 loss_train: 0.7344 acc_train: 0.7667 loss_val: 0.9660 acc_val: 0.7260 time: 0.0636s\n",
            "78\n",
            "Epoch: 0548 loss_train: 0.8331 acc_train: 0.8250 loss_val: 0.9643 acc_val: 0.7280 time: 0.0631s\n",
            "79\n",
            "Epoch: 0549 loss_train: 0.7800 acc_train: 0.8333 loss_val: 0.9563 acc_val: 0.7280 time: 0.0631s\n",
            "80\n",
            "Epoch: 0550 loss_train: 0.8001 acc_train: 0.8250 loss_val: 0.9478 acc_val: 0.7240 time: 0.0716s\n",
            "81\n",
            "Epoch: 0551 loss_train: 0.7333 acc_train: 0.8500 loss_val: 0.9435 acc_val: 0.7300 time: 0.0646s\n",
            "82\n",
            "Epoch: 0552 loss_train: 0.7378 acc_train: 0.8250 loss_val: 0.9471 acc_val: 0.7280 time: 0.0639s\n",
            "83\n",
            "Epoch: 0553 loss_train: 0.7744 acc_train: 0.8167 loss_val: 0.9497 acc_val: 0.7360 time: 0.0637s\n",
            "84\n",
            "Epoch: 0554 loss_train: 0.7261 acc_train: 0.8083 loss_val: 0.9530 acc_val: 0.7340 time: 0.0636s\n",
            "85\n",
            "Epoch: 0555 loss_train: 0.7777 acc_train: 0.7833 loss_val: 0.9550 acc_val: 0.7320 time: 0.0628s\n",
            "86\n",
            "Epoch: 0556 loss_train: 0.7444 acc_train: 0.8250 loss_val: 0.9551 acc_val: 0.7340 time: 0.0641s\n",
            "87\n",
            "Epoch: 0557 loss_train: 0.8006 acc_train: 0.8083 loss_val: 0.9570 acc_val: 0.7320 time: 0.0646s\n",
            "88\n",
            "Epoch: 0558 loss_train: 0.7745 acc_train: 0.7917 loss_val: 0.9569 acc_val: 0.7340 time: 0.0630s\n",
            "89\n",
            "Epoch: 0559 loss_train: 0.7784 acc_train: 0.7583 loss_val: 0.9619 acc_val: 0.7320 time: 0.0642s\n",
            "90\n",
            "Epoch: 0560 loss_train: 0.8074 acc_train: 0.8417 loss_val: 0.9654 acc_val: 0.7300 time: 0.0647s\n",
            "91\n",
            "Epoch: 0561 loss_train: 0.7783 acc_train: 0.7667 loss_val: 0.9711 acc_val: 0.7240 time: 0.0651s\n",
            "92\n",
            "Epoch: 0562 loss_train: 0.7669 acc_train: 0.8083 loss_val: 0.9734 acc_val: 0.7200 time: 0.0634s\n",
            "93\n",
            "Epoch: 0563 loss_train: 0.7846 acc_train: 0.7833 loss_val: 0.9688 acc_val: 0.7260 time: 0.0632s\n",
            "94\n",
            "Epoch: 0564 loss_train: 0.7799 acc_train: 0.7917 loss_val: 0.9596 acc_val: 0.7240 time: 0.0660s\n",
            "95\n",
            "Epoch: 0565 loss_train: 0.7145 acc_train: 0.8000 loss_val: 0.9521 acc_val: 0.7280 time: 0.0655s\n",
            "96\n",
            "Epoch: 0566 loss_train: 0.8088 acc_train: 0.7833 loss_val: 0.9477 acc_val: 0.7320 time: 0.0631s\n",
            "97\n",
            "Epoch: 0567 loss_train: 0.7742 acc_train: 0.7833 loss_val: 0.9455 acc_val: 0.7340 time: 0.0636s\n",
            "98\n",
            "Epoch: 0568 loss_train: 0.7605 acc_train: 0.8083 loss_val: 0.9449 acc_val: 0.7340 time: 0.0657s\n",
            "99\n",
            "Epoch: 0569 loss_train: 0.7634 acc_train: 0.8250 loss_val: 0.9500 acc_val: 0.7360 time: 0.0646s\n",
            "100\n",
            "Epoch: 0570 loss_train: 0.7823 acc_train: 0.7667 loss_val: 0.9616 acc_val: 0.7260 time: 0.0633s\n",
            "101\n",
            "Epoch: 0571 loss_train: 0.8244 acc_train: 0.7667 loss_val: 0.9698 acc_val: 0.7240 time: 0.0640s\n",
            "102\n",
            "Epoch: 0572 loss_train: 0.8000 acc_train: 0.7667 loss_val: 0.9766 acc_val: 0.7240 time: 0.0637s\n",
            "103\n",
            "Epoch: 0573 loss_train: 0.7916 acc_train: 0.7917 loss_val: 0.9795 acc_val: 0.7200 time: 0.0631s\n",
            "104\n",
            "Epoch: 0574 loss_train: 0.7790 acc_train: 0.8917 loss_val: 0.9738 acc_val: 0.7240 time: 0.0642s\n",
            "105\n",
            "Epoch: 0575 loss_train: 0.7303 acc_train: 0.8500 loss_val: 0.9678 acc_val: 0.7280 time: 0.0669s\n",
            "106\n",
            "Epoch: 0576 loss_train: 0.7489 acc_train: 0.7833 loss_val: 0.9591 acc_val: 0.7320 time: 0.0633s\n",
            "107\n",
            "Epoch: 0577 loss_train: 0.8211 acc_train: 0.7667 loss_val: 0.9532 acc_val: 0.7340 time: 0.0635s\n",
            "108\n",
            "Epoch: 0578 loss_train: 0.7743 acc_train: 0.7583 loss_val: 0.9473 acc_val: 0.7360 time: 0.0633s\n",
            "109\n",
            "Epoch: 0579 loss_train: 0.7977 acc_train: 0.7750 loss_val: 0.9440 acc_val: 0.7360 time: 0.0651s\n",
            "110\n",
            "Epoch: 0580 loss_train: 0.7744 acc_train: 0.8083 loss_val: 0.9407 acc_val: 0.7360 time: 0.0633s\n",
            "111\n",
            "Epoch: 0581 loss_train: 0.7967 acc_train: 0.8250 loss_val: 0.9415 acc_val: 0.7320 time: 0.0639s\n",
            "112\n",
            "Epoch: 0582 loss_train: 0.7382 acc_train: 0.8083 loss_val: 0.9459 acc_val: 0.7280 time: 0.0634s\n",
            "113\n",
            "Epoch: 0583 loss_train: 0.8207 acc_train: 0.7750 loss_val: 0.9524 acc_val: 0.7260 time: 0.0677s\n",
            "114\n",
            "Epoch: 0584 loss_train: 0.7629 acc_train: 0.8250 loss_val: 0.9571 acc_val: 0.7300 time: 0.0661s\n",
            "115\n",
            "Epoch: 0585 loss_train: 0.8085 acc_train: 0.8083 loss_val: 0.9607 acc_val: 0.7300 time: 0.0659s\n",
            "116\n",
            "Epoch: 0586 loss_train: 0.7172 acc_train: 0.8250 loss_val: 0.9615 acc_val: 0.7300 time: 0.0638s\n",
            "117\n",
            "Epoch: 0587 loss_train: 0.7951 acc_train: 0.8083 loss_val: 0.9590 acc_val: 0.7320 time: 0.0647s\n",
            "118\n",
            "Epoch: 0588 loss_train: 0.7402 acc_train: 0.8417 loss_val: 0.9527 acc_val: 0.7340 time: 0.0686s\n",
            "119\n",
            "Epoch: 0589 loss_train: 0.7485 acc_train: 0.8250 loss_val: 0.9485 acc_val: 0.7360 time: 0.0648s\n",
            "120\n",
            "Epoch: 0590 loss_train: 0.7671 acc_train: 0.8500 loss_val: 0.9437 acc_val: 0.7360 time: 0.0664s\n",
            "121\n",
            "Epoch: 0591 loss_train: 0.8551 acc_train: 0.7750 loss_val: 0.9439 acc_val: 0.7320 time: 0.0649s\n",
            "122\n",
            "Epoch: 0592 loss_train: 0.7248 acc_train: 0.8833 loss_val: 0.9464 acc_val: 0.7280 time: 0.0640s\n",
            "123\n",
            "Epoch: 0593 loss_train: 0.8108 acc_train: 0.7917 loss_val: 0.9507 acc_val: 0.7280 time: 0.0636s\n",
            "124\n",
            "Epoch: 0594 loss_train: 0.8026 acc_train: 0.7917 loss_val: 0.9604 acc_val: 0.7240 time: 0.0653s\n",
            "125\n",
            "Epoch: 0595 loss_train: 0.7200 acc_train: 0.8417 loss_val: 0.9615 acc_val: 0.7220 time: 0.0651s\n",
            "126\n",
            "Epoch: 0596 loss_train: 0.7466 acc_train: 0.7750 loss_val: 0.9593 acc_val: 0.7220 time: 0.0638s\n",
            "127\n",
            "Epoch: 0597 loss_train: 0.7400 acc_train: 0.8250 loss_val: 0.9535 acc_val: 0.7260 time: 0.0646s\n",
            "128\n",
            "Epoch: 0598 loss_train: 0.7529 acc_train: 0.7833 loss_val: 0.9503 acc_val: 0.7280 time: 0.0653s\n",
            "129\n",
            "Epoch: 0599 loss_train: 0.7484 acc_train: 0.8000 loss_val: 0.9491 acc_val: 0.7320 time: 0.0671s\n",
            "130\n",
            "Epoch: 0600 loss_train: 0.7744 acc_train: 0.8000 loss_val: 0.9496 acc_val: 0.7320 time: 0.0650s\n",
            "131\n",
            "Epoch: 0601 loss_train: 0.7932 acc_train: 0.8167 loss_val: 0.9553 acc_val: 0.7300 time: 0.0676s\n",
            "132\n",
            "Epoch: 0602 loss_train: 0.8055 acc_train: 0.7583 loss_val: 0.9582 acc_val: 0.7320 time: 0.0638s\n",
            "133\n",
            "Epoch: 0603 loss_train: 0.7828 acc_train: 0.8083 loss_val: 0.9566 acc_val: 0.7340 time: 0.0635s\n",
            "134\n",
            "Epoch: 0604 loss_train: 0.7574 acc_train: 0.8500 loss_val: 0.9513 acc_val: 0.7340 time: 0.0653s\n",
            "135\n",
            "Epoch: 0605 loss_train: 0.8061 acc_train: 0.8500 loss_val: 0.9506 acc_val: 0.7340 time: 0.0647s\n",
            "136\n",
            "Epoch: 0606 loss_train: 0.7591 acc_train: 0.8167 loss_val: 0.9524 acc_val: 0.7360 time: 0.0632s\n",
            "137\n",
            "Epoch: 0607 loss_train: 0.7599 acc_train: 0.8250 loss_val: 0.9561 acc_val: 0.7360 time: 0.0632s\n",
            "138\n",
            "Epoch: 0608 loss_train: 0.7477 acc_train: 0.8083 loss_val: 0.9571 acc_val: 0.7360 time: 0.0666s\n",
            "139\n",
            "Epoch: 0609 loss_train: 0.7185 acc_train: 0.8417 loss_val: 0.9590 acc_val: 0.7360 time: 0.0660s\n",
            "140\n",
            "Epoch: 0610 loss_train: 0.7926 acc_train: 0.7833 loss_val: 0.9618 acc_val: 0.7320 time: 0.0646s\n",
            "141\n",
            "Epoch: 0611 loss_train: 0.7126 acc_train: 0.8333 loss_val: 0.9600 acc_val: 0.7260 time: 0.0634s\n",
            "142\n",
            "Epoch: 0612 loss_train: 0.7663 acc_train: 0.7500 loss_val: 0.9555 acc_val: 0.7320 time: 0.0655s\n",
            "143\n",
            "Epoch: 0613 loss_train: 0.8080 acc_train: 0.7917 loss_val: 0.9503 acc_val: 0.7340 time: 0.0655s\n",
            "144\n",
            "Epoch: 0614 loss_train: 0.8533 acc_train: 0.7917 loss_val: 0.9469 acc_val: 0.7340 time: 0.0671s\n",
            "145\n",
            "Epoch: 0615 loss_train: 0.7637 acc_train: 0.7917 loss_val: 0.9469 acc_val: 0.7360 time: 0.0666s\n",
            "146\n",
            "Epoch: 0616 loss_train: 0.7992 acc_train: 0.8000 loss_val: 0.9515 acc_val: 0.7320 time: 0.0654s\n",
            "147\n",
            "Epoch: 0617 loss_train: 0.8430 acc_train: 0.7583 loss_val: 0.9538 acc_val: 0.7340 time: 0.0641s\n",
            "148\n",
            "Epoch: 0618 loss_train: 0.7880 acc_train: 0.8167 loss_val: 0.9548 acc_val: 0.7340 time: 0.0638s\n",
            "149\n",
            "Epoch: 0619 loss_train: 0.7474 acc_train: 0.8083 loss_val: 0.9563 acc_val: 0.7320 time: 0.0666s\n",
            "150\n",
            "Epoch: 0620 loss_train: 0.8036 acc_train: 0.7917 loss_val: 0.9599 acc_val: 0.7300 time: 0.0664s\n",
            "151\n",
            "Epoch: 0621 loss_train: 0.8162 acc_train: 0.7417 loss_val: 0.9654 acc_val: 0.7260 time: 0.0653s\n",
            "152\n",
            "Epoch: 0622 loss_train: 0.7864 acc_train: 0.8000 loss_val: 0.9720 acc_val: 0.7260 time: 0.0647s\n",
            "153\n",
            "Epoch: 0623 loss_train: 0.7481 acc_train: 0.8750 loss_val: 0.9730 acc_val: 0.7220 time: 0.0661s\n",
            "154\n",
            "Epoch: 0624 loss_train: 0.8160 acc_train: 0.7917 loss_val: 0.9651 acc_val: 0.7260 time: 0.0635s\n",
            "155\n",
            "Epoch: 0625 loss_train: 0.7773 acc_train: 0.7500 loss_val: 0.9562 acc_val: 0.7260 time: 0.0636s\n",
            "156\n",
            "Epoch: 0626 loss_train: 0.7703 acc_train: 0.8417 loss_val: 0.9509 acc_val: 0.7220 time: 0.0660s\n",
            "157\n",
            "Epoch: 0627 loss_train: 0.8059 acc_train: 0.7917 loss_val: 0.9508 acc_val: 0.7280 time: 0.0646s\n",
            "158\n",
            "Epoch: 0628 loss_train: 0.7875 acc_train: 0.7583 loss_val: 0.9521 acc_val: 0.7260 time: 0.0646s\n",
            "159\n",
            "Epoch: 0629 loss_train: 0.7807 acc_train: 0.8417 loss_val: 0.9539 acc_val: 0.7240 time: 0.0642s\n",
            "160\n",
            "Epoch: 0630 loss_train: 0.7271 acc_train: 0.8333 loss_val: 0.9564 acc_val: 0.7280 time: 0.0692s\n",
            "161\n",
            "Epoch: 0631 loss_train: 0.7655 acc_train: 0.8167 loss_val: 0.9575 acc_val: 0.7260 time: 0.0648s\n",
            "162\n",
            "Epoch: 0632 loss_train: 0.8226 acc_train: 0.7750 loss_val: 0.9591 acc_val: 0.7240 time: 0.0633s\n",
            "163\n",
            "Epoch: 0633 loss_train: 0.7779 acc_train: 0.8417 loss_val: 0.9588 acc_val: 0.7280 time: 0.0655s\n",
            "164\n",
            "Epoch: 0634 loss_train: 0.7283 acc_train: 0.8167 loss_val: 0.9596 acc_val: 0.7320 time: 0.0631s\n",
            "165\n",
            "Epoch: 0635 loss_train: 0.7653 acc_train: 0.7917 loss_val: 0.9584 acc_val: 0.7320 time: 0.0671s\n",
            "166\n",
            "Epoch: 0636 loss_train: 0.8215 acc_train: 0.7417 loss_val: 0.9566 acc_val: 0.7300 time: 0.0640s\n",
            "167\n",
            "Epoch: 0637 loss_train: 0.7523 acc_train: 0.8083 loss_val: 0.9538 acc_val: 0.7280 time: 0.0656s\n",
            "168\n",
            "Epoch: 0638 loss_train: 0.8027 acc_train: 0.7583 loss_val: 0.9526 acc_val: 0.7260 time: 0.0647s\n",
            "169\n",
            "Epoch: 0639 loss_train: 0.8008 acc_train: 0.7250 loss_val: 0.9520 acc_val: 0.7280 time: 0.0654s\n",
            "170\n",
            "Epoch: 0640 loss_train: 0.7929 acc_train: 0.8000 loss_val: 0.9568 acc_val: 0.7320 time: 0.0648s\n",
            "171\n",
            "Epoch: 0641 loss_train: 0.7786 acc_train: 0.7833 loss_val: 0.9587 acc_val: 0.7300 time: 0.0632s\n",
            "172\n",
            "Epoch: 0642 loss_train: 0.7837 acc_train: 0.8500 loss_val: 0.9588 acc_val: 0.7300 time: 0.0636s\n",
            "173\n",
            "Epoch: 0643 loss_train: 0.8380 acc_train: 0.7750 loss_val: 0.9611 acc_val: 0.7300 time: 0.0639s\n",
            "174\n",
            "Epoch: 0644 loss_train: 0.7207 acc_train: 0.8167 loss_val: 0.9675 acc_val: 0.7280 time: 0.0655s\n",
            "175\n",
            "Epoch: 0645 loss_train: 0.7945 acc_train: 0.7917 loss_val: 0.9736 acc_val: 0.7220 time: 0.0647s\n",
            "176\n",
            "Epoch: 0646 loss_train: 0.7786 acc_train: 0.8083 loss_val: 0.9745 acc_val: 0.7240 time: 0.0647s\n",
            "177\n",
            "Epoch: 0647 loss_train: 0.7415 acc_train: 0.7833 loss_val: 0.9734 acc_val: 0.7240 time: 0.0647s\n",
            "178\n",
            "Epoch: 0648 loss_train: 0.7674 acc_train: 0.7750 loss_val: 0.9733 acc_val: 0.7200 time: 0.0674s\n",
            "179\n",
            "Epoch: 0649 loss_train: 0.7118 acc_train: 0.8417 loss_val: 0.9736 acc_val: 0.7240 time: 0.0640s\n",
            "180\n",
            "Epoch: 0650 loss_train: 0.7378 acc_train: 0.8083 loss_val: 0.9720 acc_val: 0.7280 time: 0.0640s\n",
            "181\n",
            "Epoch: 0651 loss_train: 0.7389 acc_train: 0.7917 loss_val: 0.9676 acc_val: 0.7280 time: 0.0650s\n",
            "182\n",
            "Epoch: 0652 loss_train: 0.7586 acc_train: 0.8333 loss_val: 0.9603 acc_val: 0.7300 time: 0.0632s\n",
            "183\n",
            "Epoch: 0653 loss_train: 0.7782 acc_train: 0.7917 loss_val: 0.9544 acc_val: 0.7280 time: 0.0634s\n",
            "184\n",
            "Epoch: 0654 loss_train: 0.7286 acc_train: 0.8083 loss_val: 0.9487 acc_val: 0.7260 time: 0.0641s\n",
            "185\n",
            "Epoch: 0655 loss_train: 0.7729 acc_train: 0.8250 loss_val: 0.9465 acc_val: 0.7280 time: 0.0678s\n",
            "186\n",
            "Epoch: 0656 loss_train: 0.7876 acc_train: 0.7917 loss_val: 0.9464 acc_val: 0.7220 time: 0.0630s\n",
            "187\n",
            "Epoch: 0657 loss_train: 0.7307 acc_train: 0.8083 loss_val: 0.9484 acc_val: 0.7300 time: 0.0663s\n",
            "188\n",
            "Epoch: 0658 loss_train: 0.8277 acc_train: 0.8083 loss_val: 0.9528 acc_val: 0.7280 time: 0.0638s\n",
            "189\n",
            "Epoch: 0659 loss_train: 0.7700 acc_train: 0.8333 loss_val: 0.9538 acc_val: 0.7260 time: 0.0639s\n",
            "190\n",
            "Epoch: 0660 loss_train: 0.7681 acc_train: 0.8000 loss_val: 0.9553 acc_val: 0.7280 time: 0.0628s\n",
            "191\n",
            "Epoch: 0661 loss_train: 0.7895 acc_train: 0.7500 loss_val: 0.9587 acc_val: 0.7260 time: 0.0631s\n",
            "192\n",
            "Epoch: 0662 loss_train: 0.7535 acc_train: 0.8500 loss_val: 0.9643 acc_val: 0.7280 time: 0.0654s\n",
            "193\n",
            "Epoch: 0663 loss_train: 0.7471 acc_train: 0.7667 loss_val: 0.9620 acc_val: 0.7260 time: 0.0643s\n",
            "194\n",
            "Epoch: 0664 loss_train: 0.7427 acc_train: 0.7500 loss_val: 0.9569 acc_val: 0.7300 time: 0.0650s\n",
            "195\n",
            "Epoch: 0665 loss_train: 0.7967 acc_train: 0.8333 loss_val: 0.9522 acc_val: 0.7320 time: 0.0632s\n",
            "196\n",
            "Epoch: 0666 loss_train: 0.7409 acc_train: 0.7917 loss_val: 0.9514 acc_val: 0.7300 time: 0.0697s\n",
            "197\n",
            "Epoch: 0667 loss_train: 0.7771 acc_train: 0.7917 loss_val: 0.9497 acc_val: 0.7340 time: 0.0652s\n",
            "198\n",
            "Epoch: 0668 loss_train: 0.7793 acc_train: 0.8167 loss_val: 0.9521 acc_val: 0.7360 time: 0.0654s\n",
            "199\n",
            "Early stop! Min loss:  0.9347784519195557 , Max accuracy:  0.744\n",
            "Early stop model validation loss:  0.9347784519195557 , accuracy:  0.732\n",
            "Optimization Finished!\n",
            "Total time elapsed: 44.5389s\n",
            "Loading 467th epoch\n",
            "Test set results: loss= 0.9076 accuracy= 0.7290\n",
            "Epoch: 0001 loss_train: 0.7805 acc_train: 0.8833 loss_val: 0.9376 acc_val: 0.7320 time: 0.0667s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8290 acc_train: 0.7917 loss_val: 0.9437 acc_val: 0.7280 time: 0.0642s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8449 acc_train: 0.7917 loss_val: 0.9515 acc_val: 0.7280 time: 0.0634s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.8416 acc_train: 0.8583 loss_val: 0.9556 acc_val: 0.7260 time: 0.0648s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.8279 acc_train: 0.7917 loss_val: 0.9598 acc_val: 0.7280 time: 0.0637s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.8403 acc_train: 0.8000 loss_val: 0.9602 acc_val: 0.7240 time: 0.0632s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.7983 acc_train: 0.7667 loss_val: 0.9552 acc_val: 0.7240 time: 0.0657s\n",
            "5\n",
            "Epoch: 0008 loss_train: 0.7892 acc_train: 0.8000 loss_val: 0.9450 acc_val: 0.7300 time: 0.0637s\n",
            "6\n",
            "Epoch: 0009 loss_train: 0.7730 acc_train: 0.8250 loss_val: 0.9377 acc_val: 0.7300 time: 0.0646s\n",
            "7\n",
            "Epoch: 0010 loss_train: 0.8465 acc_train: 0.8000 loss_val: 0.9334 acc_val: 0.7320 time: 0.0639s\n",
            "8\n",
            "Epoch: 0011 loss_train: 0.8892 acc_train: 0.7667 loss_val: 0.9300 acc_val: 0.7280 time: 0.0643s\n",
            "0\n",
            "Epoch: 0012 loss_train: 0.8493 acc_train: 0.7917 loss_val: 0.9298 acc_val: 0.7280 time: 0.0650s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.8033 acc_train: 0.8000 loss_val: 0.9345 acc_val: 0.7280 time: 0.0635s\n",
            "0\n",
            "Epoch: 0014 loss_train: 0.8202 acc_train: 0.7583 loss_val: 0.9406 acc_val: 0.7260 time: 0.0649s\n",
            "1\n",
            "Epoch: 0015 loss_train: 0.7805 acc_train: 0.8083 loss_val: 0.9472 acc_val: 0.7240 time: 0.0631s\n",
            "2\n",
            "Epoch: 0016 loss_train: 0.7912 acc_train: 0.7167 loss_val: 0.9525 acc_val: 0.7200 time: 0.0637s\n",
            "3\n",
            "Epoch: 0017 loss_train: 0.8410 acc_train: 0.8333 loss_val: 0.9511 acc_val: 0.7220 time: 0.0681s\n",
            "4\n",
            "Epoch: 0018 loss_train: 0.8418 acc_train: 0.8000 loss_val: 0.9522 acc_val: 0.7240 time: 0.0658s\n",
            "5\n",
            "Epoch: 0019 loss_train: 0.8377 acc_train: 0.8167 loss_val: 0.9512 acc_val: 0.7260 time: 0.0671s\n",
            "6\n",
            "Epoch: 0020 loss_train: 0.7986 acc_train: 0.8000 loss_val: 0.9441 acc_val: 0.7300 time: 0.0654s\n",
            "7\n",
            "Epoch: 0021 loss_train: 0.7752 acc_train: 0.8917 loss_val: 0.9354 acc_val: 0.7300 time: 0.0658s\n",
            "8\n",
            "Epoch: 0022 loss_train: 0.8648 acc_train: 0.7417 loss_val: 0.9295 acc_val: 0.7300 time: 0.0636s\n",
            "9\n",
            "Epoch: 0023 loss_train: 0.8682 acc_train: 0.7750 loss_val: 0.9296 acc_val: 0.7280 time: 0.0632s\n",
            "0\n",
            "Epoch: 0024 loss_train: 0.7728 acc_train: 0.8083 loss_val: 0.9317 acc_val: 0.7280 time: 0.0674s\n",
            "1\n",
            "Epoch: 0025 loss_train: 0.7959 acc_train: 0.8333 loss_val: 0.9381 acc_val: 0.7240 time: 0.0641s\n",
            "2\n",
            "Epoch: 0026 loss_train: 0.7988 acc_train: 0.8083 loss_val: 0.9453 acc_val: 0.7220 time: 0.0632s\n",
            "3\n",
            "Epoch: 0027 loss_train: 0.8321 acc_train: 0.8417 loss_val: 0.9496 acc_val: 0.7240 time: 0.0656s\n",
            "4\n",
            "Epoch: 0028 loss_train: 0.8604 acc_train: 0.8000 loss_val: 0.9495 acc_val: 0.7240 time: 0.0657s\n",
            "5\n",
            "Epoch: 0029 loss_train: 0.8266 acc_train: 0.8000 loss_val: 0.9488 acc_val: 0.7240 time: 0.0632s\n",
            "6\n",
            "Epoch: 0030 loss_train: 0.8624 acc_train: 0.8167 loss_val: 0.9403 acc_val: 0.7300 time: 0.0646s\n",
            "7\n",
            "Epoch: 0031 loss_train: 0.8771 acc_train: 0.7750 loss_val: 0.9332 acc_val: 0.7320 time: 0.0634s\n",
            "8\n",
            "Epoch: 0032 loss_train: 0.8149 acc_train: 0.7833 loss_val: 0.9253 acc_val: 0.7320 time: 0.0660s\n",
            "0\n",
            "Epoch: 0033 loss_train: 0.7997 acc_train: 0.7750 loss_val: 0.9173 acc_val: 0.7320 time: 0.0647s\n",
            "0\n",
            "Epoch: 0034 loss_train: 0.8458 acc_train: 0.7750 loss_val: 0.9141 acc_val: 0.7260 time: 0.0643s\n",
            "0\n",
            "Epoch: 0035 loss_train: 0.8240 acc_train: 0.7750 loss_val: 0.9157 acc_val: 0.7220 time: 0.0648s\n",
            "0\n",
            "Epoch: 0036 loss_train: 0.8055 acc_train: 0.7583 loss_val: 0.9196 acc_val: 0.7220 time: 0.0658s\n",
            "1\n",
            "Epoch: 0037 loss_train: 0.7834 acc_train: 0.7667 loss_val: 0.9268 acc_val: 0.7260 time: 0.0639s\n",
            "2\n",
            "Epoch: 0038 loss_train: 0.7828 acc_train: 0.8083 loss_val: 0.9365 acc_val: 0.7220 time: 0.0634s\n",
            "3\n",
            "Epoch: 0039 loss_train: 0.8249 acc_train: 0.7833 loss_val: 0.9485 acc_val: 0.7220 time: 0.0645s\n",
            "4\n",
            "Epoch: 0040 loss_train: 0.8220 acc_train: 0.7583 loss_val: 0.9564 acc_val: 0.7220 time: 0.0632s\n",
            "5\n",
            "Epoch: 0041 loss_train: 0.7851 acc_train: 0.8083 loss_val: 0.9594 acc_val: 0.7220 time: 0.0633s\n",
            "6\n",
            "Epoch: 0042 loss_train: 0.7988 acc_train: 0.8083 loss_val: 0.9495 acc_val: 0.7280 time: 0.0647s\n",
            "7\n",
            "Epoch: 0043 loss_train: 0.7987 acc_train: 0.8083 loss_val: 0.9343 acc_val: 0.7280 time: 0.0640s\n",
            "8\n",
            "Epoch: 0044 loss_train: 0.7768 acc_train: 0.7833 loss_val: 0.9198 acc_val: 0.7300 time: 0.0641s\n",
            "9\n",
            "Epoch: 0045 loss_train: 0.8378 acc_train: 0.8250 loss_val: 0.9097 acc_val: 0.7320 time: 0.0632s\n",
            "10\n",
            "Epoch: 0046 loss_train: 0.8464 acc_train: 0.7917 loss_val: 0.9086 acc_val: 0.7320 time: 0.0638s\n",
            "0\n",
            "Epoch: 0047 loss_train: 0.7694 acc_train: 0.8500 loss_val: 0.9149 acc_val: 0.7280 time: 0.0630s\n",
            "0\n",
            "Epoch: 0048 loss_train: 0.8105 acc_train: 0.8167 loss_val: 0.9233 acc_val: 0.7280 time: 0.0632s\n",
            "1\n",
            "Epoch: 0049 loss_train: 0.8014 acc_train: 0.7833 loss_val: 0.9314 acc_val: 0.7260 time: 0.0637s\n",
            "2\n",
            "Epoch: 0050 loss_train: 0.7740 acc_train: 0.7750 loss_val: 0.9388 acc_val: 0.7240 time: 0.0642s\n",
            "3\n",
            "Epoch: 0051 loss_train: 0.7723 acc_train: 0.7917 loss_val: 0.9440 acc_val: 0.7220 time: 0.0644s\n",
            "4\n",
            "Epoch: 0052 loss_train: 0.7994 acc_train: 0.8250 loss_val: 0.9479 acc_val: 0.7240 time: 0.0645s\n",
            "5\n",
            "Epoch: 0053 loss_train: 0.8100 acc_train: 0.7417 loss_val: 0.9493 acc_val: 0.7240 time: 0.0668s\n",
            "6\n",
            "Epoch: 0054 loss_train: 0.8161 acc_train: 0.8250 loss_val: 0.9466 acc_val: 0.7260 time: 0.0669s\n",
            "7\n",
            "Epoch: 0055 loss_train: 0.8268 acc_train: 0.8083 loss_val: 0.9345 acc_val: 0.7280 time: 0.0643s\n",
            "8\n",
            "Epoch: 0056 loss_train: 0.8460 acc_train: 0.7750 loss_val: 0.9228 acc_val: 0.7280 time: 0.0635s\n",
            "9\n",
            "Epoch: 0057 loss_train: 0.8648 acc_train: 0.8167 loss_val: 0.9154 acc_val: 0.7260 time: 0.0677s\n",
            "10\n",
            "Epoch: 0058 loss_train: 0.8379 acc_train: 0.7667 loss_val: 0.9135 acc_val: 0.7280 time: 0.0646s\n",
            "11\n",
            "Epoch: 0059 loss_train: 0.7956 acc_train: 0.8333 loss_val: 0.9167 acc_val: 0.7240 time: 0.0634s\n",
            "12\n",
            "Epoch: 0060 loss_train: 0.8388 acc_train: 0.8000 loss_val: 0.9250 acc_val: 0.7180 time: 0.0641s\n",
            "13\n",
            "Epoch: 0061 loss_train: 0.7612 acc_train: 0.7750 loss_val: 0.9345 acc_val: 0.7180 time: 0.0633s\n",
            "14\n",
            "Epoch: 0062 loss_train: 0.8472 acc_train: 0.8083 loss_val: 0.9385 acc_val: 0.7180 time: 0.0665s\n",
            "15\n",
            "Epoch: 0063 loss_train: 0.8061 acc_train: 0.8250 loss_val: 0.9439 acc_val: 0.7220 time: 0.0638s\n",
            "16\n",
            "Epoch: 0064 loss_train: 0.7779 acc_train: 0.7917 loss_val: 0.9478 acc_val: 0.7220 time: 0.0668s\n",
            "17\n",
            "Epoch: 0065 loss_train: 0.7872 acc_train: 0.8000 loss_val: 0.9474 acc_val: 0.7220 time: 0.0654s\n",
            "18\n",
            "Epoch: 0066 loss_train: 0.8069 acc_train: 0.8167 loss_val: 0.9394 acc_val: 0.7240 time: 0.0655s\n",
            "19\n",
            "Epoch: 0067 loss_train: 0.7570 acc_train: 0.8500 loss_val: 0.9300 acc_val: 0.7260 time: 0.0680s\n",
            "20\n",
            "Epoch: 0068 loss_train: 0.8721 acc_train: 0.8333 loss_val: 0.9283 acc_val: 0.7260 time: 0.0647s\n",
            "21\n",
            "Epoch: 0069 loss_train: 0.8176 acc_train: 0.7917 loss_val: 0.9308 acc_val: 0.7260 time: 0.0633s\n",
            "22\n",
            "Epoch: 0070 loss_train: 0.8323 acc_train: 0.7833 loss_val: 0.9356 acc_val: 0.7260 time: 0.0645s\n",
            "23\n",
            "Epoch: 0071 loss_train: 0.7920 acc_train: 0.8083 loss_val: 0.9364 acc_val: 0.7240 time: 0.0634s\n",
            "24\n",
            "Epoch: 0072 loss_train: 0.8359 acc_train: 0.8083 loss_val: 0.9375 acc_val: 0.7200 time: 0.0647s\n",
            "25\n",
            "Epoch: 0073 loss_train: 0.8336 acc_train: 0.8583 loss_val: 0.9429 acc_val: 0.7200 time: 0.0668s\n",
            "26\n",
            "Epoch: 0074 loss_train: 0.8149 acc_train: 0.7667 loss_val: 0.9472 acc_val: 0.7200 time: 0.0657s\n",
            "27\n",
            "Epoch: 0075 loss_train: 0.7314 acc_train: 0.8167 loss_val: 0.9529 acc_val: 0.7200 time: 0.0659s\n",
            "28\n",
            "Epoch: 0076 loss_train: 0.8087 acc_train: 0.8917 loss_val: 0.9512 acc_val: 0.7200 time: 0.0651s\n",
            "29\n",
            "Epoch: 0077 loss_train: 0.8062 acc_train: 0.8667 loss_val: 0.9443 acc_val: 0.7240 time: 0.0689s\n",
            "30\n",
            "Epoch: 0078 loss_train: 0.8523 acc_train: 0.7750 loss_val: 0.9364 acc_val: 0.7260 time: 0.0659s\n",
            "31\n",
            "Epoch: 0079 loss_train: 0.8251 acc_train: 0.8333 loss_val: 0.9285 acc_val: 0.7300 time: 0.0648s\n",
            "32\n",
            "Epoch: 0080 loss_train: 0.8084 acc_train: 0.7917 loss_val: 0.9232 acc_val: 0.7320 time: 0.0670s\n",
            "33\n",
            "Epoch: 0081 loss_train: 0.7962 acc_train: 0.8333 loss_val: 0.9224 acc_val: 0.7300 time: 0.0661s\n",
            "0\n",
            "Epoch: 0082 loss_train: 0.8198 acc_train: 0.8083 loss_val: 0.9263 acc_val: 0.7300 time: 0.0656s\n",
            "1\n",
            "Epoch: 0083 loss_train: 0.8271 acc_train: 0.7917 loss_val: 0.9339 acc_val: 0.7260 time: 0.0675s\n",
            "2\n",
            "Epoch: 0084 loss_train: 0.7970 acc_train: 0.7583 loss_val: 0.9478 acc_val: 0.7160 time: 0.0658s\n",
            "3\n",
            "Epoch: 0085 loss_train: 0.8364 acc_train: 0.8250 loss_val: 0.9578 acc_val: 0.7100 time: 0.0640s\n",
            "4\n",
            "Epoch: 0086 loss_train: 0.8188 acc_train: 0.8083 loss_val: 0.9570 acc_val: 0.7100 time: 0.0651s\n",
            "5\n",
            "Epoch: 0087 loss_train: 0.8226 acc_train: 0.8250 loss_val: 0.9493 acc_val: 0.7140 time: 0.0647s\n",
            "6\n",
            "Epoch: 0088 loss_train: 0.8478 acc_train: 0.7917 loss_val: 0.9414 acc_val: 0.7200 time: 0.0646s\n",
            "7\n",
            "Epoch: 0089 loss_train: 0.7991 acc_train: 0.8167 loss_val: 0.9341 acc_val: 0.7280 time: 0.0651s\n",
            "8\n",
            "Epoch: 0090 loss_train: 0.8146 acc_train: 0.7917 loss_val: 0.9312 acc_val: 0.7280 time: 0.0648s\n",
            "9\n",
            "Epoch: 0091 loss_train: 0.8427 acc_train: 0.7583 loss_val: 0.9309 acc_val: 0.7300 time: 0.0636s\n",
            "10\n",
            "Epoch: 0092 loss_train: 0.8543 acc_train: 0.7417 loss_val: 0.9297 acc_val: 0.7300 time: 0.0636s\n",
            "11\n",
            "Epoch: 0093 loss_train: 0.7970 acc_train: 0.8167 loss_val: 0.9266 acc_val: 0.7300 time: 0.0635s\n",
            "12\n",
            "Epoch: 0094 loss_train: 0.8040 acc_train: 0.8167 loss_val: 0.9255 acc_val: 0.7280 time: 0.0674s\n",
            "13\n",
            "Epoch: 0095 loss_train: 0.8113 acc_train: 0.7750 loss_val: 0.9268 acc_val: 0.7260 time: 0.0636s\n",
            "14\n",
            "Epoch: 0096 loss_train: 0.8105 acc_train: 0.8417 loss_val: 0.9291 acc_val: 0.7240 time: 0.0634s\n",
            "15\n",
            "Epoch: 0097 loss_train: 0.8157 acc_train: 0.7917 loss_val: 0.9368 acc_val: 0.7200 time: 0.0635s\n",
            "16\n",
            "Epoch: 0098 loss_train: 0.8312 acc_train: 0.7917 loss_val: 0.9466 acc_val: 0.7180 time: 0.0653s\n",
            "17\n",
            "Epoch: 0099 loss_train: 0.7753 acc_train: 0.7667 loss_val: 0.9504 acc_val: 0.7200 time: 0.0632s\n",
            "18\n",
            "Epoch: 0100 loss_train: 0.8707 acc_train: 0.7833 loss_val: 0.9479 acc_val: 0.7160 time: 0.0649s\n",
            "19\n",
            "Epoch: 0101 loss_train: 0.7775 acc_train: 0.8333 loss_val: 0.9419 acc_val: 0.7160 time: 0.0649s\n",
            "20\n",
            "Epoch: 0102 loss_train: 0.7575 acc_train: 0.8083 loss_val: 0.9326 acc_val: 0.7180 time: 0.0681s\n",
            "21\n",
            "Epoch: 0103 loss_train: 0.8081 acc_train: 0.8250 loss_val: 0.9243 acc_val: 0.7260 time: 0.0670s\n",
            "22\n",
            "Epoch: 0104 loss_train: 0.8110 acc_train: 0.8583 loss_val: 0.9203 acc_val: 0.7300 time: 0.0638s\n",
            "23\n",
            "Epoch: 0105 loss_train: 0.8244 acc_train: 0.7750 loss_val: 0.9196 acc_val: 0.7300 time: 0.0670s\n",
            "24\n",
            "Epoch: 0106 loss_train: 0.8371 acc_train: 0.7833 loss_val: 0.9249 acc_val: 0.7240 time: 0.0654s\n",
            "25\n",
            "Epoch: 0107 loss_train: 0.8271 acc_train: 0.8167 loss_val: 0.9326 acc_val: 0.7200 time: 0.0648s\n",
            "26\n",
            "Epoch: 0108 loss_train: 0.8175 acc_train: 0.8083 loss_val: 0.9391 acc_val: 0.7160 time: 0.0649s\n",
            "27\n",
            "Epoch: 0109 loss_train: 0.7382 acc_train: 0.7833 loss_val: 0.9416 acc_val: 0.7160 time: 0.0655s\n",
            "28\n",
            "Epoch: 0110 loss_train: 0.8006 acc_train: 0.8000 loss_val: 0.9414 acc_val: 0.7140 time: 0.0664s\n",
            "29\n",
            "Epoch: 0111 loss_train: 0.8216 acc_train: 0.7667 loss_val: 0.9392 acc_val: 0.7160 time: 0.0642s\n",
            "30\n",
            "Epoch: 0112 loss_train: 0.7903 acc_train: 0.8333 loss_val: 0.9354 acc_val: 0.7200 time: 0.0660s\n",
            "31\n",
            "Epoch: 0113 loss_train: 0.7980 acc_train: 0.8750 loss_val: 0.9334 acc_val: 0.7200 time: 0.0651s\n",
            "32\n",
            "Epoch: 0114 loss_train: 0.8361 acc_train: 0.8500 loss_val: 0.9282 acc_val: 0.7280 time: 0.0647s\n",
            "33\n",
            "Epoch: 0115 loss_train: 0.8386 acc_train: 0.7250 loss_val: 0.9249 acc_val: 0.7280 time: 0.0674s\n",
            "34\n",
            "Epoch: 0116 loss_train: 0.8036 acc_train: 0.7917 loss_val: 0.9254 acc_val: 0.7320 time: 0.0655s\n",
            "35\n",
            "Epoch: 0117 loss_train: 0.8754 acc_train: 0.8000 loss_val: 0.9278 acc_val: 0.7280 time: 0.0641s\n",
            "0\n",
            "Epoch: 0118 loss_train: 0.8457 acc_train: 0.8083 loss_val: 0.9339 acc_val: 0.7220 time: 0.0654s\n",
            "1\n",
            "Epoch: 0119 loss_train: 0.7757 acc_train: 0.7667 loss_val: 0.9395 acc_val: 0.7240 time: 0.0656s\n",
            "2\n",
            "Epoch: 0120 loss_train: 0.8116 acc_train: 0.8250 loss_val: 0.9452 acc_val: 0.7180 time: 0.0649s\n",
            "3\n",
            "Epoch: 0121 loss_train: 0.7973 acc_train: 0.8083 loss_val: 0.9463 acc_val: 0.7240 time: 0.0647s\n",
            "4\n",
            "Epoch: 0122 loss_train: 0.7797 acc_train: 0.8583 loss_val: 0.9352 acc_val: 0.7220 time: 0.0662s\n",
            "5\n",
            "Epoch: 0123 loss_train: 0.8215 acc_train: 0.7667 loss_val: 0.9279 acc_val: 0.7260 time: 0.0663s\n",
            "6\n",
            "Epoch: 0124 loss_train: 0.8286 acc_train: 0.7250 loss_val: 0.9246 acc_val: 0.7280 time: 0.0630s\n",
            "7\n",
            "Epoch: 0125 loss_train: 0.7729 acc_train: 0.8500 loss_val: 0.9239 acc_val: 0.7320 time: 0.0636s\n",
            "8\n",
            "Epoch: 0126 loss_train: 0.7679 acc_train: 0.8583 loss_val: 0.9232 acc_val: 0.7300 time: 0.0640s\n",
            "0\n",
            "Epoch: 0127 loss_train: 0.8703 acc_train: 0.7250 loss_val: 0.9234 acc_val: 0.7240 time: 0.0632s\n",
            "1\n",
            "Epoch: 0128 loss_train: 0.7839 acc_train: 0.7667 loss_val: 0.9305 acc_val: 0.7220 time: 0.0631s\n",
            "2\n",
            "Epoch: 0129 loss_train: 0.8266 acc_train: 0.8000 loss_val: 0.9372 acc_val: 0.7240 time: 0.0642s\n",
            "3\n",
            "Epoch: 0130 loss_train: 0.7604 acc_train: 0.7917 loss_val: 0.9378 acc_val: 0.7280 time: 0.0630s\n",
            "4\n",
            "Epoch: 0131 loss_train: 0.7669 acc_train: 0.8167 loss_val: 0.9376 acc_val: 0.7320 time: 0.0630s\n",
            "5\n",
            "Epoch: 0132 loss_train: 0.8438 acc_train: 0.8250 loss_val: 0.9298 acc_val: 0.7340 time: 0.0631s\n",
            "0\n",
            "Epoch: 0133 loss_train: 0.8245 acc_train: 0.8000 loss_val: 0.9221 acc_val: 0.7340 time: 0.0685s\n",
            "0\n",
            "Epoch: 0134 loss_train: 0.7458 acc_train: 0.7667 loss_val: 0.9165 acc_val: 0.7320 time: 0.0649s\n",
            "0\n",
            "Epoch: 0135 loss_train: 0.7915 acc_train: 0.8167 loss_val: 0.9157 acc_val: 0.7320 time: 0.0663s\n",
            "1\n",
            "Epoch: 0136 loss_train: 0.7736 acc_train: 0.8417 loss_val: 0.9181 acc_val: 0.7340 time: 0.0657s\n",
            "2\n",
            "Epoch: 0137 loss_train: 0.8942 acc_train: 0.7667 loss_val: 0.9235 acc_val: 0.7340 time: 0.0664s\n",
            "0\n",
            "Epoch: 0138 loss_train: 0.7738 acc_train: 0.7833 loss_val: 0.9280 acc_val: 0.7300 time: 0.0663s\n",
            "0\n",
            "Epoch: 0139 loss_train: 0.8511 acc_train: 0.8000 loss_val: 0.9348 acc_val: 0.7300 time: 0.0648s\n",
            "1\n",
            "Epoch: 0140 loss_train: 0.7897 acc_train: 0.8417 loss_val: 0.9383 acc_val: 0.7280 time: 0.0671s\n",
            "2\n",
            "Epoch: 0141 loss_train: 0.7851 acc_train: 0.7500 loss_val: 0.9384 acc_val: 0.7260 time: 0.0665s\n",
            "3\n",
            "Epoch: 0142 loss_train: 0.8625 acc_train: 0.7250 loss_val: 0.9349 acc_val: 0.7260 time: 0.0640s\n",
            "4\n",
            "Epoch: 0143 loss_train: 0.8033 acc_train: 0.8000 loss_val: 0.9293 acc_val: 0.7280 time: 0.0631s\n",
            "5\n",
            "Epoch: 0144 loss_train: 0.8270 acc_train: 0.8083 loss_val: 0.9233 acc_val: 0.7280 time: 0.0644s\n",
            "6\n",
            "Epoch: 0145 loss_train: 0.8185 acc_train: 0.8167 loss_val: 0.9179 acc_val: 0.7300 time: 0.0642s\n",
            "7\n",
            "Epoch: 0146 loss_train: 0.8236 acc_train: 0.8417 loss_val: 0.9153 acc_val: 0.7280 time: 0.0635s\n",
            "8\n",
            "Epoch: 0147 loss_train: 0.7809 acc_train: 0.8417 loss_val: 0.9176 acc_val: 0.7300 time: 0.0647s\n",
            "9\n",
            "Epoch: 0148 loss_train: 0.7863 acc_train: 0.8083 loss_val: 0.9215 acc_val: 0.7280 time: 0.0644s\n",
            "10\n",
            "Epoch: 0149 loss_train: 0.7316 acc_train: 0.8417 loss_val: 0.9250 acc_val: 0.7300 time: 0.0633s\n",
            "11\n",
            "Epoch: 0150 loss_train: 0.8168 acc_train: 0.8083 loss_val: 0.9264 acc_val: 0.7300 time: 0.0632s\n",
            "12\n",
            "Epoch: 0151 loss_train: 0.7856 acc_train: 0.8167 loss_val: 0.9219 acc_val: 0.7260 time: 0.0660s\n",
            "13\n",
            "Epoch: 0152 loss_train: 0.8663 acc_train: 0.8250 loss_val: 0.9198 acc_val: 0.7320 time: 0.0633s\n",
            "14\n",
            "Epoch: 0153 loss_train: 0.7773 acc_train: 0.8333 loss_val: 0.9201 acc_val: 0.7340 time: 0.0653s\n",
            "15\n",
            "Epoch: 0154 loss_train: 0.8267 acc_train: 0.7750 loss_val: 0.9232 acc_val: 0.7300 time: 0.0631s\n",
            "0\n",
            "Epoch: 0155 loss_train: 0.8435 acc_train: 0.7500 loss_val: 0.9291 acc_val: 0.7320 time: 0.0661s\n",
            "1\n",
            "Epoch: 0156 loss_train: 0.8499 acc_train: 0.8000 loss_val: 0.9352 acc_val: 0.7320 time: 0.0647s\n",
            "2\n",
            "Epoch: 0157 loss_train: 0.8229 acc_train: 0.8250 loss_val: 0.9410 acc_val: 0.7260 time: 0.0645s\n",
            "3\n",
            "Epoch: 0158 loss_train: 0.8368 acc_train: 0.8083 loss_val: 0.9453 acc_val: 0.7240 time: 0.0660s\n",
            "4\n",
            "Epoch: 0159 loss_train: 0.8130 acc_train: 0.8333 loss_val: 0.9490 acc_val: 0.7260 time: 0.0634s\n",
            "5\n",
            "Epoch: 0160 loss_train: 0.8267 acc_train: 0.8167 loss_val: 0.9436 acc_val: 0.7240 time: 0.0643s\n",
            "6\n",
            "Epoch: 0161 loss_train: 0.7931 acc_train: 0.8083 loss_val: 0.9343 acc_val: 0.7260 time: 0.0633s\n",
            "7\n",
            "Epoch: 0162 loss_train: 0.7805 acc_train: 0.8500 loss_val: 0.9257 acc_val: 0.7280 time: 0.0646s\n",
            "8\n",
            "Epoch: 0163 loss_train: 0.7668 acc_train: 0.8417 loss_val: 0.9161 acc_val: 0.7320 time: 0.0646s\n",
            "9\n",
            "Epoch: 0164 loss_train: 0.8300 acc_train: 0.8500 loss_val: 0.9110 acc_val: 0.7340 time: 0.0635s\n",
            "10\n",
            "Epoch: 0165 loss_train: 0.8018 acc_train: 0.8000 loss_val: 0.9087 acc_val: 0.7380 time: 0.0634s\n",
            "0\n",
            "Epoch: 0166 loss_train: 0.8214 acc_train: 0.7917 loss_val: 0.9187 acc_val: 0.7340 time: 0.0650s\n",
            "0\n",
            "Epoch: 0167 loss_train: 0.8347 acc_train: 0.7833 loss_val: 0.9299 acc_val: 0.7340 time: 0.0631s\n",
            "1\n",
            "Epoch: 0168 loss_train: 0.7804 acc_train: 0.7917 loss_val: 0.9426 acc_val: 0.7320 time: 0.0654s\n",
            "2\n",
            "Epoch: 0169 loss_train: 0.8351 acc_train: 0.7917 loss_val: 0.9483 acc_val: 0.7260 time: 0.0634s\n",
            "3\n",
            "Epoch: 0170 loss_train: 0.8070 acc_train: 0.7667 loss_val: 0.9452 acc_val: 0.7220 time: 0.0655s\n",
            "4\n",
            "Epoch: 0171 loss_train: 0.7467 acc_train: 0.8250 loss_val: 0.9344 acc_val: 0.7240 time: 0.0644s\n",
            "5\n",
            "Epoch: 0172 loss_train: 0.8474 acc_train: 0.8000 loss_val: 0.9247 acc_val: 0.7260 time: 0.0645s\n",
            "6\n",
            "Epoch: 0173 loss_train: 0.8563 acc_train: 0.7667 loss_val: 0.9194 acc_val: 0.7260 time: 0.0655s\n",
            "7\n",
            "Epoch: 0174 loss_train: 0.7983 acc_train: 0.8167 loss_val: 0.9189 acc_val: 0.7240 time: 0.0646s\n",
            "8\n",
            "Epoch: 0175 loss_train: 0.7688 acc_train: 0.8083 loss_val: 0.9180 acc_val: 0.7280 time: 0.0639s\n",
            "9\n",
            "Epoch: 0176 loss_train: 0.8645 acc_train: 0.7833 loss_val: 0.9178 acc_val: 0.7320 time: 0.0646s\n",
            "10\n",
            "Epoch: 0177 loss_train: 0.7685 acc_train: 0.8250 loss_val: 0.9175 acc_val: 0.7360 time: 0.0662s\n",
            "11\n",
            "Epoch: 0178 loss_train: 0.7983 acc_train: 0.8083 loss_val: 0.9196 acc_val: 0.7360 time: 0.0676s\n",
            "12\n",
            "Epoch: 0179 loss_train: 0.8191 acc_train: 0.8083 loss_val: 0.9282 acc_val: 0.7320 time: 0.0632s\n",
            "13\n",
            "Epoch: 0180 loss_train: 0.8385 acc_train: 0.7667 loss_val: 0.9344 acc_val: 0.7260 time: 0.0640s\n",
            "14\n",
            "Epoch: 0181 loss_train: 0.8049 acc_train: 0.7750 loss_val: 0.9347 acc_val: 0.7280 time: 0.0631s\n",
            "15\n",
            "Epoch: 0182 loss_train: 0.8404 acc_train: 0.8417 loss_val: 0.9298 acc_val: 0.7280 time: 0.0633s\n",
            "16\n",
            "Epoch: 0183 loss_train: 0.8129 acc_train: 0.8250 loss_val: 0.9236 acc_val: 0.7320 time: 0.0640s\n",
            "17\n",
            "Epoch: 0184 loss_train: 0.7736 acc_train: 0.8417 loss_val: 0.9207 acc_val: 0.7340 time: 0.0644s\n",
            "18\n",
            "Epoch: 0185 loss_train: 0.8363 acc_train: 0.8250 loss_val: 0.9218 acc_val: 0.7280 time: 0.0636s\n",
            "19\n",
            "Epoch: 0186 loss_train: 0.7942 acc_train: 0.8667 loss_val: 0.9223 acc_val: 0.7320 time: 0.0640s\n",
            "20\n",
            "Epoch: 0187 loss_train: 0.8510 acc_train: 0.8250 loss_val: 0.9241 acc_val: 0.7300 time: 0.0635s\n",
            "21\n",
            "Epoch: 0188 loss_train: 0.7810 acc_train: 0.9083 loss_val: 0.9269 acc_val: 0.7300 time: 0.0646s\n",
            "22\n",
            "Epoch: 0189 loss_train: 0.7315 acc_train: 0.8583 loss_val: 0.9300 acc_val: 0.7360 time: 0.0633s\n",
            "23\n",
            "Epoch: 0190 loss_train: 0.7998 acc_train: 0.8250 loss_val: 0.9350 acc_val: 0.7320 time: 0.0638s\n",
            "24\n",
            "Epoch: 0191 loss_train: 0.7579 acc_train: 0.8000 loss_val: 0.9399 acc_val: 0.7280 time: 0.0633s\n",
            "25\n",
            "Epoch: 0192 loss_train: 0.7955 acc_train: 0.7833 loss_val: 0.9432 acc_val: 0.7240 time: 0.0644s\n",
            "26\n",
            "Epoch: 0193 loss_train: 0.7772 acc_train: 0.8417 loss_val: 0.9415 acc_val: 0.7240 time: 0.0631s\n",
            "27\n",
            "Epoch: 0194 loss_train: 0.8184 acc_train: 0.8083 loss_val: 0.9349 acc_val: 0.7260 time: 0.0654s\n",
            "28\n",
            "Epoch: 0195 loss_train: 0.8200 acc_train: 0.8000 loss_val: 0.9254 acc_val: 0.7300 time: 0.0650s\n",
            "29\n",
            "Epoch: 0196 loss_train: 0.8008 acc_train: 0.8500 loss_val: 0.9193 acc_val: 0.7360 time: 0.0660s\n",
            "30\n",
            "Epoch: 0197 loss_train: 0.8488 acc_train: 0.8167 loss_val: 0.9175 acc_val: 0.7360 time: 0.0646s\n",
            "31\n",
            "Epoch: 0198 loss_train: 0.7924 acc_train: 0.8167 loss_val: 0.9178 acc_val: 0.7340 time: 0.0648s\n",
            "32\n",
            "Epoch: 0199 loss_train: 0.8012 acc_train: 0.8667 loss_val: 0.9240 acc_val: 0.7340 time: 0.0654s\n",
            "33\n",
            "Epoch: 0200 loss_train: 0.8204 acc_train: 0.8167 loss_val: 0.9320 acc_val: 0.7340 time: 0.0664s\n",
            "34\n",
            "Epoch: 0201 loss_train: 0.7956 acc_train: 0.7917 loss_val: 0.9409 acc_val: 0.7280 time: 0.0637s\n",
            "35\n",
            "Epoch: 0202 loss_train: 0.8276 acc_train: 0.8583 loss_val: 0.9448 acc_val: 0.7220 time: 0.0639s\n",
            "36\n",
            "Epoch: 0203 loss_train: 0.7922 acc_train: 0.8667 loss_val: 0.9425 acc_val: 0.7260 time: 0.0642s\n",
            "37\n",
            "Epoch: 0204 loss_train: 0.8074 acc_train: 0.7833 loss_val: 0.9372 acc_val: 0.7240 time: 0.0633s\n",
            "38\n",
            "Epoch: 0205 loss_train: 0.8054 acc_train: 0.8083 loss_val: 0.9332 acc_val: 0.7240 time: 0.0634s\n",
            "39\n",
            "Epoch: 0206 loss_train: 0.8620 acc_train: 0.8500 loss_val: 0.9300 acc_val: 0.7260 time: 0.0642s\n",
            "40\n",
            "Epoch: 0207 loss_train: 0.8155 acc_train: 0.8167 loss_val: 0.9265 acc_val: 0.7300 time: 0.0658s\n",
            "41\n",
            "Epoch: 0208 loss_train: 0.8026 acc_train: 0.8250 loss_val: 0.9245 acc_val: 0.7300 time: 0.0631s\n",
            "42\n",
            "Epoch: 0209 loss_train: 0.7955 acc_train: 0.8417 loss_val: 0.9221 acc_val: 0.7260 time: 0.0657s\n",
            "43\n",
            "Epoch: 0210 loss_train: 0.7998 acc_train: 0.7833 loss_val: 0.9224 acc_val: 0.7240 time: 0.0654s\n",
            "44\n",
            "Epoch: 0211 loss_train: 0.8475 acc_train: 0.8250 loss_val: 0.9266 acc_val: 0.7260 time: 0.0644s\n",
            "45\n",
            "Epoch: 0212 loss_train: 0.8105 acc_train: 0.8250 loss_val: 0.9319 acc_val: 0.7280 time: 0.0632s\n",
            "46\n",
            "Epoch: 0213 loss_train: 0.8049 acc_train: 0.8417 loss_val: 0.9354 acc_val: 0.7280 time: 0.0651s\n",
            "47\n",
            "Epoch: 0214 loss_train: 0.7907 acc_train: 0.8083 loss_val: 0.9348 acc_val: 0.7320 time: 0.0658s\n",
            "48\n",
            "Epoch: 0215 loss_train: 0.7999 acc_train: 0.7833 loss_val: 0.9306 acc_val: 0.7300 time: 0.0663s\n",
            "49\n",
            "Epoch: 0216 loss_train: 0.8026 acc_train: 0.8500 loss_val: 0.9257 acc_val: 0.7300 time: 0.0664s\n",
            "50\n",
            "Epoch: 0217 loss_train: 0.8314 acc_train: 0.8083 loss_val: 0.9217 acc_val: 0.7280 time: 0.0650s\n",
            "51\n",
            "Epoch: 0218 loss_train: 0.8035 acc_train: 0.8250 loss_val: 0.9228 acc_val: 0.7260 time: 0.0676s\n",
            "52\n",
            "Epoch: 0219 loss_train: 0.8273 acc_train: 0.7583 loss_val: 0.9299 acc_val: 0.7240 time: 0.0651s\n",
            "53\n",
            "Epoch: 0220 loss_train: 0.7655 acc_train: 0.7917 loss_val: 0.9350 acc_val: 0.7260 time: 0.0639s\n",
            "54\n",
            "Epoch: 0221 loss_train: 0.8021 acc_train: 0.8000 loss_val: 0.9412 acc_val: 0.7300 time: 0.0658s\n",
            "55\n",
            "Epoch: 0222 loss_train: 0.7996 acc_train: 0.8333 loss_val: 0.9423 acc_val: 0.7300 time: 0.0665s\n",
            "56\n",
            "Epoch: 0223 loss_train: 0.8868 acc_train: 0.7917 loss_val: 0.9456 acc_val: 0.7320 time: 0.0657s\n",
            "57\n",
            "Epoch: 0224 loss_train: 0.7943 acc_train: 0.8500 loss_val: 0.9485 acc_val: 0.7360 time: 0.0654s\n",
            "58\n",
            "Epoch: 0225 loss_train: 0.8345 acc_train: 0.8250 loss_val: 0.9498 acc_val: 0.7360 time: 0.0650s\n",
            "59\n",
            "Epoch: 0226 loss_train: 0.8075 acc_train: 0.7833 loss_val: 0.9439 acc_val: 0.7340 time: 0.0654s\n",
            "60\n",
            "Epoch: 0227 loss_train: 0.8338 acc_train: 0.8417 loss_val: 0.9403 acc_val: 0.7320 time: 0.0639s\n",
            "61\n",
            "Epoch: 0228 loss_train: 0.7319 acc_train: 0.8167 loss_val: 0.9356 acc_val: 0.7320 time: 0.0653s\n",
            "62\n",
            "Epoch: 0229 loss_train: 0.7389 acc_train: 0.8167 loss_val: 0.9332 acc_val: 0.7280 time: 0.0635s\n",
            "63\n",
            "Epoch: 0230 loss_train: 0.7892 acc_train: 0.7667 loss_val: 0.9335 acc_val: 0.7220 time: 0.0646s\n",
            "64\n",
            "Epoch: 0231 loss_train: 0.8014 acc_train: 0.8000 loss_val: 0.9294 acc_val: 0.7240 time: 0.0633s\n",
            "65\n",
            "Epoch: 0232 loss_train: 0.8168 acc_train: 0.7917 loss_val: 0.9239 acc_val: 0.7240 time: 0.0662s\n",
            "66\n",
            "Epoch: 0233 loss_train: 0.7810 acc_train: 0.8417 loss_val: 0.9224 acc_val: 0.7280 time: 0.0683s\n",
            "67\n",
            "Epoch: 0234 loss_train: 0.7672 acc_train: 0.8250 loss_val: 0.9248 acc_val: 0.7360 time: 0.0647s\n",
            "68\n",
            "Epoch: 0235 loss_train: 0.7603 acc_train: 0.8500 loss_val: 0.9297 acc_val: 0.7360 time: 0.0646s\n",
            "69\n",
            "Epoch: 0236 loss_train: 0.7814 acc_train: 0.8167 loss_val: 0.9343 acc_val: 0.7360 time: 0.0643s\n",
            "70\n",
            "Epoch: 0237 loss_train: 0.8109 acc_train: 0.8083 loss_val: 0.9361 acc_val: 0.7320 time: 0.0633s\n",
            "71\n",
            "Epoch: 0238 loss_train: 0.8301 acc_train: 0.7833 loss_val: 0.9407 acc_val: 0.7300 time: 0.0637s\n",
            "72\n",
            "Epoch: 0239 loss_train: 0.7630 acc_train: 0.8417 loss_val: 0.9482 acc_val: 0.7300 time: 0.0662s\n",
            "73\n",
            "Epoch: 0240 loss_train: 0.7820 acc_train: 0.8250 loss_val: 0.9524 acc_val: 0.7280 time: 0.0651s\n",
            "74\n",
            "Epoch: 0241 loss_train: 0.7482 acc_train: 0.8333 loss_val: 0.9495 acc_val: 0.7260 time: 0.0662s\n",
            "75\n",
            "Epoch: 0242 loss_train: 0.8412 acc_train: 0.8167 loss_val: 0.9393 acc_val: 0.7240 time: 0.0650s\n",
            "76\n",
            "Epoch: 0243 loss_train: 0.8158 acc_train: 0.8250 loss_val: 0.9295 acc_val: 0.7260 time: 0.0652s\n",
            "77\n",
            "Epoch: 0244 loss_train: 0.7735 acc_train: 0.7917 loss_val: 0.9226 acc_val: 0.7260 time: 0.0631s\n",
            "78\n",
            "Epoch: 0245 loss_train: 0.8423 acc_train: 0.7917 loss_val: 0.9179 acc_val: 0.7280 time: 0.0638s\n",
            "79\n",
            "Epoch: 0246 loss_train: 0.7565 acc_train: 0.7833 loss_val: 0.9173 acc_val: 0.7300 time: 0.0659s\n",
            "80\n",
            "Epoch: 0247 loss_train: 0.8175 acc_train: 0.8083 loss_val: 0.9208 acc_val: 0.7300 time: 0.0632s\n",
            "81\n",
            "Epoch: 0248 loss_train: 0.7933 acc_train: 0.8083 loss_val: 0.9270 acc_val: 0.7300 time: 0.0632s\n",
            "82\n",
            "Epoch: 0249 loss_train: 0.8477 acc_train: 0.7667 loss_val: 0.9312 acc_val: 0.7300 time: 0.0633s\n",
            "83\n",
            "Epoch: 0250 loss_train: 0.8315 acc_train: 0.7750 loss_val: 0.9343 acc_val: 0.7340 time: 0.0653s\n",
            "84\n",
            "Epoch: 0251 loss_train: 0.7620 acc_train: 0.8417 loss_val: 0.9398 acc_val: 0.7340 time: 0.0646s\n",
            "85\n",
            "Epoch: 0252 loss_train: 0.7928 acc_train: 0.8083 loss_val: 0.9422 acc_val: 0.7320 time: 0.0645s\n",
            "86\n",
            "Epoch: 0253 loss_train: 0.7556 acc_train: 0.8167 loss_val: 0.9404 acc_val: 0.7280 time: 0.0631s\n",
            "87\n",
            "Epoch: 0254 loss_train: 0.8452 acc_train: 0.8083 loss_val: 0.9334 acc_val: 0.7280 time: 0.0705s\n",
            "88\n",
            "Epoch: 0255 loss_train: 0.8370 acc_train: 0.7500 loss_val: 0.9318 acc_val: 0.7240 time: 0.0634s\n",
            "89\n",
            "Epoch: 0256 loss_train: 0.8305 acc_train: 0.8333 loss_val: 0.9300 acc_val: 0.7220 time: 0.0628s\n",
            "90\n",
            "Epoch: 0257 loss_train: 0.8357 acc_train: 0.7833 loss_val: 0.9329 acc_val: 0.7240 time: 0.0644s\n",
            "91\n",
            "Epoch: 0258 loss_train: 0.8240 acc_train: 0.8167 loss_val: 0.9297 acc_val: 0.7260 time: 0.0643s\n",
            "92\n",
            "Epoch: 0259 loss_train: 0.8486 acc_train: 0.7917 loss_val: 0.9260 acc_val: 0.7280 time: 0.0632s\n",
            "93\n",
            "Epoch: 0260 loss_train: 0.8265 acc_train: 0.8167 loss_val: 0.9244 acc_val: 0.7280 time: 0.0642s\n",
            "94\n",
            "Epoch: 0261 loss_train: 0.7896 acc_train: 0.8000 loss_val: 0.9253 acc_val: 0.7260 time: 0.0649s\n",
            "95\n",
            "Epoch: 0262 loss_train: 0.7593 acc_train: 0.8500 loss_val: 0.9302 acc_val: 0.7260 time: 0.0649s\n",
            "96\n",
            "Epoch: 0263 loss_train: 0.7541 acc_train: 0.8333 loss_val: 0.9366 acc_val: 0.7280 time: 0.0654s\n",
            "97\n",
            "Epoch: 0264 loss_train: 0.7618 acc_train: 0.8250 loss_val: 0.9433 acc_val: 0.7240 time: 0.0659s\n",
            "98\n",
            "Epoch: 0265 loss_train: 0.8197 acc_train: 0.8667 loss_val: 0.9472 acc_val: 0.7240 time: 0.0631s\n",
            "99\n",
            "Epoch: 0266 loss_train: 0.7885 acc_train: 0.8250 loss_val: 0.9423 acc_val: 0.7240 time: 0.0634s\n",
            "100\n",
            "Epoch: 0267 loss_train: 0.8080 acc_train: 0.7917 loss_val: 0.9364 acc_val: 0.7240 time: 0.0630s\n",
            "101\n",
            "Epoch: 0268 loss_train: 0.8134 acc_train: 0.7750 loss_val: 0.9300 acc_val: 0.7220 time: 0.0636s\n",
            "102\n",
            "Epoch: 0269 loss_train: 0.7820 acc_train: 0.8250 loss_val: 0.9255 acc_val: 0.7220 time: 0.0652s\n",
            "103\n",
            "Epoch: 0270 loss_train: 0.7568 acc_train: 0.8083 loss_val: 0.9249 acc_val: 0.7260 time: 0.0635s\n",
            "104\n",
            "Epoch: 0271 loss_train: 0.8424 acc_train: 0.8167 loss_val: 0.9240 acc_val: 0.7260 time: 0.0635s\n",
            "105\n",
            "Epoch: 0272 loss_train: 0.8265 acc_train: 0.8000 loss_val: 0.9229 acc_val: 0.7260 time: 0.0662s\n",
            "106\n",
            "Epoch: 0273 loss_train: 0.8297 acc_train: 0.8083 loss_val: 0.9230 acc_val: 0.7300 time: 0.0653s\n",
            "107\n",
            "Epoch: 0274 loss_train: 0.8250 acc_train: 0.7750 loss_val: 0.9261 acc_val: 0.7300 time: 0.0655s\n",
            "108\n",
            "Epoch: 0275 loss_train: 0.7781 acc_train: 0.8417 loss_val: 0.9292 acc_val: 0.7380 time: 0.0656s\n",
            "109\n",
            "Epoch: 0276 loss_train: 0.8068 acc_train: 0.8333 loss_val: 0.9298 acc_val: 0.7340 time: 0.0652s\n",
            "0\n",
            "Epoch: 0277 loss_train: 0.8518 acc_train: 0.8000 loss_val: 0.9313 acc_val: 0.7360 time: 0.0651s\n",
            "1\n",
            "Epoch: 0278 loss_train: 0.8020 acc_train: 0.8000 loss_val: 0.9330 acc_val: 0.7280 time: 0.0636s\n",
            "2\n",
            "Epoch: 0279 loss_train: 0.7970 acc_train: 0.8583 loss_val: 0.9310 acc_val: 0.7260 time: 0.0654s\n",
            "3\n",
            "Epoch: 0280 loss_train: 0.8351 acc_train: 0.7917 loss_val: 0.9319 acc_val: 0.7260 time: 0.0650s\n",
            "4\n",
            "Epoch: 0281 loss_train: 0.8723 acc_train: 0.7500 loss_val: 0.9322 acc_val: 0.7260 time: 0.0633s\n",
            "5\n",
            "Epoch: 0282 loss_train: 0.7730 acc_train: 0.8500 loss_val: 0.9344 acc_val: 0.7280 time: 0.0644s\n",
            "6\n",
            "Epoch: 0283 loss_train: 0.8102 acc_train: 0.8417 loss_val: 0.9371 acc_val: 0.7240 time: 0.0633s\n",
            "7\n",
            "Epoch: 0284 loss_train: 0.7869 acc_train: 0.8333 loss_val: 0.9377 acc_val: 0.7220 time: 0.0632s\n",
            "8\n",
            "Epoch: 0285 loss_train: 0.8264 acc_train: 0.7750 loss_val: 0.9374 acc_val: 0.7200 time: 0.0645s\n",
            "9\n",
            "Epoch: 0286 loss_train: 0.7863 acc_train: 0.8500 loss_val: 0.9328 acc_val: 0.7220 time: 0.0648s\n",
            "10\n",
            "Epoch: 0287 loss_train: 0.8037 acc_train: 0.8417 loss_val: 0.9330 acc_val: 0.7260 time: 0.0643s\n",
            "11\n",
            "Epoch: 0288 loss_train: 0.8041 acc_train: 0.8000 loss_val: 0.9342 acc_val: 0.7220 time: 0.0670s\n",
            "12\n",
            "Epoch: 0289 loss_train: 0.8350 acc_train: 0.7833 loss_val: 0.9327 acc_val: 0.7220 time: 0.0646s\n",
            "13\n",
            "Epoch: 0290 loss_train: 0.8546 acc_train: 0.7833 loss_val: 0.9303 acc_val: 0.7220 time: 0.0652s\n",
            "14\n",
            "Epoch: 0291 loss_train: 0.7958 acc_train: 0.8250 loss_val: 0.9277 acc_val: 0.7260 time: 0.0645s\n",
            "15\n",
            "Epoch: 0292 loss_train: 0.8487 acc_train: 0.7750 loss_val: 0.9278 acc_val: 0.7280 time: 0.0644s\n",
            "16\n",
            "Epoch: 0293 loss_train: 0.8084 acc_train: 0.7667 loss_val: 0.9327 acc_val: 0.7260 time: 0.0643s\n",
            "17\n",
            "Epoch: 0294 loss_train: 0.7910 acc_train: 0.8583 loss_val: 0.9337 acc_val: 0.7320 time: 0.0636s\n",
            "18\n",
            "Epoch: 0295 loss_train: 0.8161 acc_train: 0.8667 loss_val: 0.9314 acc_val: 0.7300 time: 0.0640s\n",
            "19\n",
            "Epoch: 0296 loss_train: 0.7877 acc_train: 0.8417 loss_val: 0.9272 acc_val: 0.7280 time: 0.0636s\n",
            "20\n",
            "Epoch: 0297 loss_train: 0.8175 acc_train: 0.8417 loss_val: 0.9240 acc_val: 0.7260 time: 0.0651s\n",
            "21\n",
            "Epoch: 0298 loss_train: 0.8007 acc_train: 0.8167 loss_val: 0.9242 acc_val: 0.7240 time: 0.0651s\n",
            "22\n",
            "Epoch: 0299 loss_train: 0.8061 acc_train: 0.8250 loss_val: 0.9229 acc_val: 0.7180 time: 0.0657s\n",
            "23\n",
            "Epoch: 0300 loss_train: 0.7976 acc_train: 0.8083 loss_val: 0.9208 acc_val: 0.7180 time: 0.0663s\n",
            "24\n",
            "Epoch: 0301 loss_train: 0.8223 acc_train: 0.8000 loss_val: 0.9212 acc_val: 0.7220 time: 0.0677s\n",
            "25\n",
            "Epoch: 0302 loss_train: 0.8557 acc_train: 0.8083 loss_val: 0.9237 acc_val: 0.7200 time: 0.0647s\n",
            "26\n",
            "Epoch: 0303 loss_train: 0.8171 acc_train: 0.7750 loss_val: 0.9279 acc_val: 0.7220 time: 0.0652s\n",
            "27\n",
            "Epoch: 0304 loss_train: 0.8332 acc_train: 0.8083 loss_val: 0.9318 acc_val: 0.7280 time: 0.0663s\n",
            "28\n",
            "Epoch: 0305 loss_train: 0.8088 acc_train: 0.8167 loss_val: 0.9364 acc_val: 0.7260 time: 0.0637s\n",
            "29\n",
            "Epoch: 0306 loss_train: 0.7797 acc_train: 0.8833 loss_val: 0.9381 acc_val: 0.7260 time: 0.0633s\n",
            "30\n",
            "Epoch: 0307 loss_train: 0.8247 acc_train: 0.8333 loss_val: 0.9398 acc_val: 0.7280 time: 0.0647s\n",
            "31\n",
            "Epoch: 0308 loss_train: 0.8004 acc_train: 0.8583 loss_val: 0.9376 acc_val: 0.7260 time: 0.0635s\n",
            "32\n",
            "Epoch: 0309 loss_train: 0.7632 acc_train: 0.8333 loss_val: 0.9352 acc_val: 0.7300 time: 0.0641s\n",
            "33\n",
            "Epoch: 0310 loss_train: 0.8140 acc_train: 0.7583 loss_val: 0.9305 acc_val: 0.7300 time: 0.0633s\n",
            "34\n",
            "Epoch: 0311 loss_train: 0.8123 acc_train: 0.8583 loss_val: 0.9275 acc_val: 0.7320 time: 0.0645s\n",
            "35\n",
            "Epoch: 0312 loss_train: 0.8155 acc_train: 0.8583 loss_val: 0.9226 acc_val: 0.7340 time: 0.0634s\n",
            "36\n",
            "Epoch: 0313 loss_train: 0.7527 acc_train: 0.8583 loss_val: 0.9189 acc_val: 0.7320 time: 0.0654s\n",
            "37\n",
            "Epoch: 0314 loss_train: 0.8493 acc_train: 0.8083 loss_val: 0.9174 acc_val: 0.7360 time: 0.0644s\n",
            "38\n",
            "Epoch: 0315 loss_train: 0.8440 acc_train: 0.8000 loss_val: 0.9198 acc_val: 0.7320 time: 0.0660s\n",
            "39\n",
            "Epoch: 0316 loss_train: 0.8255 acc_train: 0.8000 loss_val: 0.9266 acc_val: 0.7280 time: 0.0646s\n",
            "40\n",
            "Epoch: 0317 loss_train: 0.8444 acc_train: 0.7417 loss_val: 0.9329 acc_val: 0.7280 time: 0.0655s\n",
            "41\n",
            "Epoch: 0318 loss_train: 0.7970 acc_train: 0.8083 loss_val: 0.9402 acc_val: 0.7260 time: 0.0645s\n",
            "42\n",
            "Epoch: 0319 loss_train: 0.7825 acc_train: 0.8083 loss_val: 0.9409 acc_val: 0.7280 time: 0.0632s\n",
            "43\n",
            "Epoch: 0320 loss_train: 0.8553 acc_train: 0.8083 loss_val: 0.9390 acc_val: 0.7300 time: 0.0633s\n",
            "44\n",
            "Epoch: 0321 loss_train: 0.7813 acc_train: 0.8167 loss_val: 0.9338 acc_val: 0.7280 time: 0.0641s\n",
            "45\n",
            "Epoch: 0322 loss_train: 0.8406 acc_train: 0.7583 loss_val: 0.9240 acc_val: 0.7280 time: 0.0637s\n",
            "46\n",
            "Epoch: 0323 loss_train: 0.8229 acc_train: 0.8000 loss_val: 0.9187 acc_val: 0.7320 time: 0.0646s\n",
            "47\n",
            "Epoch: 0324 loss_train: 0.7833 acc_train: 0.8083 loss_val: 0.9166 acc_val: 0.7320 time: 0.0634s\n",
            "48\n",
            "Epoch: 0325 loss_train: 0.7527 acc_train: 0.8417 loss_val: 0.9190 acc_val: 0.7320 time: 0.0651s\n",
            "49\n",
            "Epoch: 0326 loss_train: 0.7897 acc_train: 0.8500 loss_val: 0.9236 acc_val: 0.7280 time: 0.0649s\n",
            "50\n",
            "Epoch: 0327 loss_train: 0.7715 acc_train: 0.8250 loss_val: 0.9289 acc_val: 0.7260 time: 0.0647s\n",
            "51\n",
            "Epoch: 0328 loss_train: 0.7550 acc_train: 0.8417 loss_val: 0.9367 acc_val: 0.7240 time: 0.0682s\n",
            "52\n",
            "Epoch: 0329 loss_train: 0.8172 acc_train: 0.8083 loss_val: 0.9395 acc_val: 0.7280 time: 0.0660s\n",
            "53\n",
            "Epoch: 0330 loss_train: 0.7798 acc_train: 0.8250 loss_val: 0.9370 acc_val: 0.7260 time: 0.0663s\n",
            "54\n",
            "Epoch: 0331 loss_train: 0.8367 acc_train: 0.8250 loss_val: 0.9309 acc_val: 0.7260 time: 0.0668s\n",
            "55\n",
            "Epoch: 0332 loss_train: 0.7868 acc_train: 0.7750 loss_val: 0.9235 acc_val: 0.7260 time: 0.0669s\n",
            "56\n",
            "Epoch: 0333 loss_train: 0.8123 acc_train: 0.8167 loss_val: 0.9197 acc_val: 0.7300 time: 0.0654s\n",
            "57\n",
            "Epoch: 0334 loss_train: 0.8214 acc_train: 0.7750 loss_val: 0.9211 acc_val: 0.7260 time: 0.0652s\n",
            "58\n",
            "Epoch: 0335 loss_train: 0.8146 acc_train: 0.8000 loss_val: 0.9223 acc_val: 0.7300 time: 0.0645s\n",
            "59\n",
            "Epoch: 0336 loss_train: 0.7980 acc_train: 0.7250 loss_val: 0.9252 acc_val: 0.7220 time: 0.0632s\n",
            "60\n",
            "Epoch: 0337 loss_train: 0.7770 acc_train: 0.7917 loss_val: 0.9316 acc_val: 0.7200 time: 0.0633s\n",
            "61\n",
            "Epoch: 0338 loss_train: 0.7995 acc_train: 0.8583 loss_val: 0.9382 acc_val: 0.7220 time: 0.0652s\n",
            "62\n",
            "Epoch: 0339 loss_train: 0.8240 acc_train: 0.7917 loss_val: 0.9413 acc_val: 0.7200 time: 0.0632s\n",
            "63\n",
            "Epoch: 0340 loss_train: 0.7720 acc_train: 0.8667 loss_val: 0.9378 acc_val: 0.7240 time: 0.0635s\n",
            "64\n",
            "Epoch: 0341 loss_train: 0.8136 acc_train: 0.7750 loss_val: 0.9334 acc_val: 0.7280 time: 0.0653s\n",
            "65\n",
            "Epoch: 0342 loss_train: 0.7671 acc_train: 0.8083 loss_val: 0.9271 acc_val: 0.7300 time: 0.0652s\n",
            "66\n",
            "Epoch: 0343 loss_train: 0.8659 acc_train: 0.7750 loss_val: 0.9237 acc_val: 0.7320 time: 0.0642s\n",
            "67\n",
            "Epoch: 0344 loss_train: 0.8442 acc_train: 0.7917 loss_val: 0.9238 acc_val: 0.7320 time: 0.0655s\n",
            "68\n",
            "Epoch: 0345 loss_train: 0.8053 acc_train: 0.8000 loss_val: 0.9235 acc_val: 0.7340 time: 0.0673s\n",
            "69\n",
            "Epoch: 0346 loss_train: 0.7622 acc_train: 0.8167 loss_val: 0.9235 acc_val: 0.7320 time: 0.0636s\n",
            "70\n",
            "Epoch: 0347 loss_train: 0.7653 acc_train: 0.8000 loss_val: 0.9230 acc_val: 0.7280 time: 0.0644s\n",
            "71\n",
            "Epoch: 0348 loss_train: 0.7848 acc_train: 0.8417 loss_val: 0.9231 acc_val: 0.7280 time: 0.0651s\n",
            "72\n",
            "Epoch: 0349 loss_train: 0.8028 acc_train: 0.8250 loss_val: 0.9224 acc_val: 0.7300 time: 0.0663s\n",
            "73\n",
            "Epoch: 0350 loss_train: 0.7920 acc_train: 0.8417 loss_val: 0.9243 acc_val: 0.7300 time: 0.0654s\n",
            "74\n",
            "Epoch: 0351 loss_train: 0.8296 acc_train: 0.7917 loss_val: 0.9276 acc_val: 0.7260 time: 0.0659s\n",
            "75\n",
            "Epoch: 0352 loss_train: 0.8683 acc_train: 0.8000 loss_val: 0.9290 acc_val: 0.7260 time: 0.0655s\n",
            "76\n",
            "Epoch: 0353 loss_train: 0.7758 acc_train: 0.8333 loss_val: 0.9291 acc_val: 0.7280 time: 0.0648s\n",
            "77\n",
            "Epoch: 0354 loss_train: 0.7691 acc_train: 0.8083 loss_val: 0.9276 acc_val: 0.7300 time: 0.0656s\n",
            "78\n",
            "Epoch: 0355 loss_train: 0.7737 acc_train: 0.8500 loss_val: 0.9249 acc_val: 0.7300 time: 0.0631s\n",
            "79\n",
            "Epoch: 0356 loss_train: 0.8229 acc_train: 0.8167 loss_val: 0.9214 acc_val: 0.7320 time: 0.0646s\n",
            "80\n",
            "Epoch: 0357 loss_train: 0.7890 acc_train: 0.8000 loss_val: 0.9203 acc_val: 0.7320 time: 0.0632s\n",
            "81\n",
            "Epoch: 0358 loss_train: 0.7769 acc_train: 0.7750 loss_val: 0.9194 acc_val: 0.7300 time: 0.0634s\n",
            "82\n",
            "Epoch: 0359 loss_train: 0.7965 acc_train: 0.8167 loss_val: 0.9201 acc_val: 0.7360 time: 0.0642s\n",
            "83\n",
            "Epoch: 0360 loss_train: 0.8146 acc_train: 0.7167 loss_val: 0.9270 acc_val: 0.7300 time: 0.0642s\n",
            "84\n",
            "Epoch: 0361 loss_train: 0.8728 acc_train: 0.7250 loss_val: 0.9327 acc_val: 0.7260 time: 0.0635s\n",
            "85\n",
            "Epoch: 0362 loss_train: 0.8337 acc_train: 0.8000 loss_val: 0.9307 acc_val: 0.7260 time: 0.0632s\n",
            "86\n",
            "Epoch: 0363 loss_train: 0.7127 acc_train: 0.8583 loss_val: 0.9271 acc_val: 0.7240 time: 0.0667s\n",
            "87\n",
            "Epoch: 0364 loss_train: 0.7777 acc_train: 0.8333 loss_val: 0.9204 acc_val: 0.7300 time: 0.0646s\n",
            "88\n",
            "Epoch: 0365 loss_train: 0.7867 acc_train: 0.8250 loss_val: 0.9153 acc_val: 0.7320 time: 0.0693s\n",
            "89\n",
            "Epoch: 0366 loss_train: 0.7483 acc_train: 0.8583 loss_val: 0.9137 acc_val: 0.7340 time: 0.0635s\n",
            "90\n",
            "Epoch: 0367 loss_train: 0.7971 acc_train: 0.8500 loss_val: 0.9132 acc_val: 0.7340 time: 0.0640s\n",
            "91\n",
            "Epoch: 0368 loss_train: 0.7684 acc_train: 0.7917 loss_val: 0.9190 acc_val: 0.7320 time: 0.0644s\n",
            "92\n",
            "Epoch: 0369 loss_train: 0.7750 acc_train: 0.8500 loss_val: 0.9253 acc_val: 0.7380 time: 0.0631s\n",
            "93\n",
            "Epoch: 0370 loss_train: 0.8344 acc_train: 0.7750 loss_val: 0.9283 acc_val: 0.7360 time: 0.0638s\n",
            "0\n",
            "Epoch: 0371 loss_train: 0.7695 acc_train: 0.8250 loss_val: 0.9290 acc_val: 0.7380 time: 0.0631s\n",
            "1\n",
            "Epoch: 0372 loss_train: 0.7856 acc_train: 0.8500 loss_val: 0.9268 acc_val: 0.7340 time: 0.0631s\n",
            "0\n",
            "Epoch: 0373 loss_train: 0.8227 acc_train: 0.8083 loss_val: 0.9249 acc_val: 0.7320 time: 0.0625s\n",
            "1\n",
            "Epoch: 0374 loss_train: 0.8211 acc_train: 0.8250 loss_val: 0.9212 acc_val: 0.7260 time: 0.0653s\n",
            "2\n",
            "Epoch: 0375 loss_train: 0.7800 acc_train: 0.8333 loss_val: 0.9193 acc_val: 0.7280 time: 0.0639s\n",
            "3\n",
            "Epoch: 0376 loss_train: 0.7893 acc_train: 0.8333 loss_val: 0.9192 acc_val: 0.7260 time: 0.0638s\n",
            "4\n",
            "Epoch: 0377 loss_train: 0.8125 acc_train: 0.8000 loss_val: 0.9187 acc_val: 0.7260 time: 0.0634s\n",
            "5\n",
            "Epoch: 0378 loss_train: 0.8364 acc_train: 0.7667 loss_val: 0.9237 acc_val: 0.7260 time: 0.0657s\n",
            "6\n",
            "Epoch: 0379 loss_train: 0.8438 acc_train: 0.8167 loss_val: 0.9265 acc_val: 0.7260 time: 0.0646s\n",
            "7\n",
            "Epoch: 0380 loss_train: 0.7588 acc_train: 0.8000 loss_val: 0.9294 acc_val: 0.7320 time: 0.0636s\n",
            "8\n",
            "Epoch: 0381 loss_train: 0.8353 acc_train: 0.8333 loss_val: 0.9311 acc_val: 0.7320 time: 0.0631s\n",
            "9\n",
            "Epoch: 0382 loss_train: 0.7823 acc_train: 0.8500 loss_val: 0.9322 acc_val: 0.7320 time: 0.0659s\n",
            "10\n",
            "Epoch: 0383 loss_train: 0.7940 acc_train: 0.7917 loss_val: 0.9335 acc_val: 0.7320 time: 0.0656s\n",
            "11\n",
            "Epoch: 0384 loss_train: 0.7819 acc_train: 0.8500 loss_val: 0.9367 acc_val: 0.7300 time: 0.0685s\n",
            "12\n",
            "Epoch: 0385 loss_train: 0.7807 acc_train: 0.8167 loss_val: 0.9418 acc_val: 0.7300 time: 0.0680s\n",
            "13\n",
            "Epoch: 0386 loss_train: 0.8532 acc_train: 0.8167 loss_val: 0.9446 acc_val: 0.7240 time: 0.0650s\n",
            "14\n",
            "Epoch: 0387 loss_train: 0.7714 acc_train: 0.8417 loss_val: 0.9447 acc_val: 0.7200 time: 0.0630s\n",
            "15\n",
            "Epoch: 0388 loss_train: 0.8136 acc_train: 0.7583 loss_val: 0.9407 acc_val: 0.7200 time: 0.0634s\n",
            "16\n",
            "Epoch: 0389 loss_train: 0.8011 acc_train: 0.7833 loss_val: 0.9370 acc_val: 0.7260 time: 0.0645s\n",
            "17\n",
            "Epoch: 0390 loss_train: 0.7728 acc_train: 0.8000 loss_val: 0.9338 acc_val: 0.7320 time: 0.0635s\n",
            "18\n",
            "Epoch: 0391 loss_train: 0.8434 acc_train: 0.7833 loss_val: 0.9344 acc_val: 0.7320 time: 0.0659s\n",
            "19\n",
            "Epoch: 0392 loss_train: 0.8395 acc_train: 0.7833 loss_val: 0.9355 acc_val: 0.7340 time: 0.0630s\n",
            "20\n",
            "Epoch: 0393 loss_train: 0.8597 acc_train: 0.7917 loss_val: 0.9346 acc_val: 0.7360 time: 0.0669s\n",
            "21\n",
            "Epoch: 0394 loss_train: 0.7843 acc_train: 0.8167 loss_val: 0.9303 acc_val: 0.7380 time: 0.0678s\n",
            "22\n",
            "Epoch: 0395 loss_train: 0.7765 acc_train: 0.8167 loss_val: 0.9231 acc_val: 0.7340 time: 0.0649s\n",
            "0\n",
            "Epoch: 0396 loss_train: 0.8056 acc_train: 0.8167 loss_val: 0.9158 acc_val: 0.7340 time: 0.0655s\n",
            "1\n",
            "Epoch: 0397 loss_train: 0.7564 acc_train: 0.9083 loss_val: 0.9151 acc_val: 0.7300 time: 0.0656s\n",
            "2\n",
            "Epoch: 0398 loss_train: 0.8024 acc_train: 0.8250 loss_val: 0.9210 acc_val: 0.7260 time: 0.0678s\n",
            "3\n",
            "Epoch: 0399 loss_train: 0.7902 acc_train: 0.8167 loss_val: 0.9279 acc_val: 0.7200 time: 0.0639s\n",
            "4\n",
            "Epoch: 0400 loss_train: 0.7875 acc_train: 0.7167 loss_val: 0.9295 acc_val: 0.7180 time: 0.0667s\n",
            "5\n",
            "Epoch: 0401 loss_train: 0.8131 acc_train: 0.8250 loss_val: 0.9274 acc_val: 0.7220 time: 0.0666s\n",
            "6\n",
            "Epoch: 0402 loss_train: 0.8169 acc_train: 0.8083 loss_val: 0.9240 acc_val: 0.7320 time: 0.0640s\n",
            "7\n",
            "Epoch: 0403 loss_train: 0.8314 acc_train: 0.8000 loss_val: 0.9209 acc_val: 0.7320 time: 0.0642s\n",
            "8\n",
            "Epoch: 0404 loss_train: 0.8229 acc_train: 0.7667 loss_val: 0.9172 acc_val: 0.7340 time: 0.0667s\n",
            "9\n",
            "Epoch: 0405 loss_train: 0.8056 acc_train: 0.8083 loss_val: 0.9162 acc_val: 0.7320 time: 0.0633s\n",
            "10\n",
            "Epoch: 0406 loss_train: 0.8419 acc_train: 0.8000 loss_val: 0.9185 acc_val: 0.7300 time: 0.0642s\n",
            "11\n",
            "Epoch: 0407 loss_train: 0.8096 acc_train: 0.7417 loss_val: 0.9199 acc_val: 0.7260 time: 0.0656s\n",
            "12\n",
            "Epoch: 0408 loss_train: 0.7826 acc_train: 0.7833 loss_val: 0.9216 acc_val: 0.7260 time: 0.0652s\n",
            "13\n",
            "Epoch: 0409 loss_train: 0.8322 acc_train: 0.8083 loss_val: 0.9301 acc_val: 0.7240 time: 0.0669s\n",
            "14\n",
            "Epoch: 0410 loss_train: 0.8329 acc_train: 0.8083 loss_val: 0.9381 acc_val: 0.7240 time: 0.0645s\n",
            "15\n",
            "Epoch: 0411 loss_train: 0.8153 acc_train: 0.7583 loss_val: 0.9436 acc_val: 0.7200 time: 0.0656s\n",
            "16\n",
            "Epoch: 0412 loss_train: 0.8228 acc_train: 0.8333 loss_val: 0.9469 acc_val: 0.7240 time: 0.0641s\n",
            "17\n",
            "Epoch: 0413 loss_train: 0.7809 acc_train: 0.8000 loss_val: 0.9461 acc_val: 0.7240 time: 0.0630s\n",
            "18\n",
            "Epoch: 0414 loss_train: 0.8201 acc_train: 0.8250 loss_val: 0.9400 acc_val: 0.7300 time: 0.0652s\n",
            "19\n",
            "Epoch: 0415 loss_train: 0.8347 acc_train: 0.8083 loss_val: 0.9327 acc_val: 0.7300 time: 0.0638s\n",
            "20\n",
            "Epoch: 0416 loss_train: 0.8456 acc_train: 0.8333 loss_val: 0.9273 acc_val: 0.7320 time: 0.0646s\n",
            "21\n",
            "Epoch: 0417 loss_train: 0.7733 acc_train: 0.7917 loss_val: 0.9232 acc_val: 0.7300 time: 0.0634s\n",
            "22\n",
            "Epoch: 0418 loss_train: 0.8045 acc_train: 0.8167 loss_val: 0.9209 acc_val: 0.7280 time: 0.0661s\n",
            "23\n",
            "Epoch: 0419 loss_train: 0.7913 acc_train: 0.7750 loss_val: 0.9219 acc_val: 0.7280 time: 0.0645s\n",
            "24\n",
            "Epoch: 0420 loss_train: 0.8021 acc_train: 0.7750 loss_val: 0.9252 acc_val: 0.7260 time: 0.0631s\n",
            "25\n",
            "Epoch: 0421 loss_train: 0.7878 acc_train: 0.8583 loss_val: 0.9328 acc_val: 0.7280 time: 0.0650s\n",
            "26\n",
            "Epoch: 0422 loss_train: 0.7550 acc_train: 0.8500 loss_val: 0.9427 acc_val: 0.7220 time: 0.0635s\n",
            "27\n",
            "Epoch: 0423 loss_train: 0.7712 acc_train: 0.8583 loss_val: 0.9463 acc_val: 0.7220 time: 0.0638s\n",
            "28\n",
            "Epoch: 0424 loss_train: 0.7889 acc_train: 0.8000 loss_val: 0.9450 acc_val: 0.7220 time: 0.0634s\n",
            "29\n",
            "Epoch: 0425 loss_train: 0.7887 acc_train: 0.8333 loss_val: 0.9436 acc_val: 0.7220 time: 0.0642s\n",
            "30\n",
            "Epoch: 0426 loss_train: 0.8172 acc_train: 0.8000 loss_val: 0.9371 acc_val: 0.7280 time: 0.0631s\n",
            "31\n",
            "Epoch: 0427 loss_train: 0.8077 acc_train: 0.8583 loss_val: 0.9231 acc_val: 0.7360 time: 0.0632s\n",
            "32\n",
            "Epoch: 0428 loss_train: 0.8354 acc_train: 0.7667 loss_val: 0.9133 acc_val: 0.7360 time: 0.0630s\n",
            "33\n",
            "Epoch: 0429 loss_train: 0.8235 acc_train: 0.7833 loss_val: 0.9110 acc_val: 0.7360 time: 0.0654s\n",
            "34\n",
            "Epoch: 0430 loss_train: 0.8143 acc_train: 0.8000 loss_val: 0.9165 acc_val: 0.7380 time: 0.0632s\n",
            "35\n",
            "Epoch: 0431 loss_train: 0.8398 acc_train: 0.7833 loss_val: 0.9259 acc_val: 0.7400 time: 0.0632s\n",
            "0\n",
            "Epoch: 0432 loss_train: 0.7765 acc_train: 0.8000 loss_val: 0.9342 acc_val: 0.7360 time: 0.0647s\n",
            "0\n",
            "Epoch: 0433 loss_train: 0.8181 acc_train: 0.8000 loss_val: 0.9377 acc_val: 0.7380 time: 0.0699s\n",
            "1\n",
            "Epoch: 0434 loss_train: 0.8633 acc_train: 0.7333 loss_val: 0.9432 acc_val: 0.7320 time: 0.0647s\n",
            "2\n",
            "Epoch: 0435 loss_train: 0.8279 acc_train: 0.8167 loss_val: 0.9455 acc_val: 0.7300 time: 0.0653s\n",
            "3\n",
            "Epoch: 0436 loss_train: 0.8163 acc_train: 0.7583 loss_val: 0.9429 acc_val: 0.7300 time: 0.0654s\n",
            "4\n",
            "Epoch: 0437 loss_train: 0.8897 acc_train: 0.7250 loss_val: 0.9373 acc_val: 0.7320 time: 0.0658s\n",
            "5\n",
            "Epoch: 0438 loss_train: 0.7752 acc_train: 0.8333 loss_val: 0.9281 acc_val: 0.7320 time: 0.0644s\n",
            "6\n",
            "Epoch: 0439 loss_train: 0.8405 acc_train: 0.8000 loss_val: 0.9234 acc_val: 0.7360 time: 0.0641s\n",
            "7\n",
            "Epoch: 0440 loss_train: 0.8013 acc_train: 0.8250 loss_val: 0.9194 acc_val: 0.7400 time: 0.0640s\n",
            "8\n",
            "Epoch: 0441 loss_train: 0.8555 acc_train: 0.7667 loss_val: 0.9178 acc_val: 0.7400 time: 0.0647s\n",
            "0\n",
            "Epoch: 0442 loss_train: 0.7566 acc_train: 0.8167 loss_val: 0.9169 acc_val: 0.7380 time: 0.0632s\n",
            "0\n",
            "Epoch: 0443 loss_train: 0.8447 acc_train: 0.8333 loss_val: 0.9190 acc_val: 0.7400 time: 0.0633s\n",
            "1\n",
            "Epoch: 0444 loss_train: 0.8257 acc_train: 0.7250 loss_val: 0.9240 acc_val: 0.7340 time: 0.0641s\n",
            "0\n",
            "Epoch: 0445 loss_train: 0.8426 acc_train: 0.7250 loss_val: 0.9350 acc_val: 0.7300 time: 0.0631s\n",
            "1\n",
            "Epoch: 0446 loss_train: 0.8063 acc_train: 0.8417 loss_val: 0.9385 acc_val: 0.7240 time: 0.0632s\n",
            "2\n",
            "Epoch: 0447 loss_train: 0.8153 acc_train: 0.8250 loss_val: 0.9385 acc_val: 0.7240 time: 0.0632s\n",
            "3\n",
            "Epoch: 0448 loss_train: 0.8500 acc_train: 0.7583 loss_val: 0.9354 acc_val: 0.7240 time: 0.0640s\n",
            "4\n",
            "Epoch: 0449 loss_train: 0.8134 acc_train: 0.7417 loss_val: 0.9307 acc_val: 0.7220 time: 0.0640s\n",
            "5\n",
            "Epoch: 0450 loss_train: 0.8295 acc_train: 0.8000 loss_val: 0.9282 acc_val: 0.7280 time: 0.0639s\n",
            "6\n",
            "Epoch: 0451 loss_train: 0.8059 acc_train: 0.8500 loss_val: 0.9277 acc_val: 0.7280 time: 0.0673s\n",
            "7\n",
            "Epoch: 0452 loss_train: 0.8451 acc_train: 0.8083 loss_val: 0.9254 acc_val: 0.7280 time: 0.0661s\n",
            "8\n",
            "Epoch: 0453 loss_train: 0.7948 acc_train: 0.8333 loss_val: 0.9243 acc_val: 0.7320 time: 0.0658s\n",
            "9\n",
            "Epoch: 0454 loss_train: 0.7718 acc_train: 0.8333 loss_val: 0.9238 acc_val: 0.7300 time: 0.0648s\n",
            "10\n",
            "Epoch: 0455 loss_train: 0.8755 acc_train: 0.7333 loss_val: 0.9268 acc_val: 0.7340 time: 0.0657s\n",
            "11\n",
            "Epoch: 0456 loss_train: 0.8128 acc_train: 0.7750 loss_val: 0.9343 acc_val: 0.7300 time: 0.0643s\n",
            "12\n",
            "Epoch: 0457 loss_train: 0.8308 acc_train: 0.7917 loss_val: 0.9382 acc_val: 0.7300 time: 0.0638s\n",
            "13\n",
            "Epoch: 0458 loss_train: 0.7708 acc_train: 0.8583 loss_val: 0.9391 acc_val: 0.7280 time: 0.0631s\n",
            "14\n",
            "Epoch: 0459 loss_train: 0.7723 acc_train: 0.8083 loss_val: 0.9307 acc_val: 0.7320 time: 0.0653s\n",
            "15\n",
            "Epoch: 0460 loss_train: 0.8226 acc_train: 0.8083 loss_val: 0.9252 acc_val: 0.7300 time: 0.0648s\n",
            "16\n",
            "Epoch: 0461 loss_train: 0.8045 acc_train: 0.7833 loss_val: 0.9243 acc_val: 0.7320 time: 0.0645s\n",
            "17\n",
            "Epoch: 0462 loss_train: 0.7922 acc_train: 0.7750 loss_val: 0.9288 acc_val: 0.7300 time: 0.0658s\n",
            "18\n",
            "Epoch: 0463 loss_train: 0.8807 acc_train: 0.7417 loss_val: 0.9351 acc_val: 0.7280 time: 0.0646s\n",
            "19\n",
            "Epoch: 0464 loss_train: 0.8222 acc_train: 0.7917 loss_val: 0.9388 acc_val: 0.7260 time: 0.0629s\n",
            "20\n",
            "Epoch: 0465 loss_train: 0.8075 acc_train: 0.8167 loss_val: 0.9385 acc_val: 0.7240 time: 0.0636s\n",
            "21\n",
            "Epoch: 0466 loss_train: 0.8779 acc_train: 0.7417 loss_val: 0.9370 acc_val: 0.7240 time: 0.0652s\n",
            "22\n",
            "Epoch: 0467 loss_train: 0.8448 acc_train: 0.7000 loss_val: 0.9348 acc_val: 0.7240 time: 0.0644s\n",
            "23\n",
            "Epoch: 0468 loss_train: 0.8199 acc_train: 0.7750 loss_val: 0.9306 acc_val: 0.7280 time: 0.0641s\n",
            "24\n",
            "Epoch: 0469 loss_train: 0.7895 acc_train: 0.8000 loss_val: 0.9254 acc_val: 0.7260 time: 0.0631s\n",
            "25\n",
            "Epoch: 0470 loss_train: 0.8086 acc_train: 0.7917 loss_val: 0.9207 acc_val: 0.7340 time: 0.0650s\n",
            "26\n",
            "Epoch: 0471 loss_train: 0.8236 acc_train: 0.7750 loss_val: 0.9218 acc_val: 0.7320 time: 0.0645s\n",
            "27\n",
            "Epoch: 0472 loss_train: 0.7987 acc_train: 0.8500 loss_val: 0.9243 acc_val: 0.7280 time: 0.0660s\n",
            "28\n",
            "Epoch: 0473 loss_train: 0.8137 acc_train: 0.7833 loss_val: 0.9272 acc_val: 0.7300 time: 0.0654s\n",
            "29\n",
            "Epoch: 0474 loss_train: 0.8594 acc_train: 0.8083 loss_val: 0.9325 acc_val: 0.7260 time: 0.0663s\n",
            "30\n",
            "Epoch: 0475 loss_train: 0.8195 acc_train: 0.7500 loss_val: 0.9396 acc_val: 0.7240 time: 0.0647s\n",
            "31\n",
            "Epoch: 0476 loss_train: 0.7700 acc_train: 0.8417 loss_val: 0.9469 acc_val: 0.7180 time: 0.0669s\n",
            "32\n",
            "Epoch: 0477 loss_train: 0.8357 acc_train: 0.8000 loss_val: 0.9489 acc_val: 0.7160 time: 0.0668s\n",
            "33\n",
            "Epoch: 0478 loss_train: 0.8195 acc_train: 0.7583 loss_val: 0.9436 acc_val: 0.7160 time: 0.0630s\n",
            "34\n",
            "Epoch: 0479 loss_train: 0.8248 acc_train: 0.8417 loss_val: 0.9367 acc_val: 0.7200 time: 0.0632s\n",
            "35\n",
            "Epoch: 0480 loss_train: 0.8562 acc_train: 0.7667 loss_val: 0.9306 acc_val: 0.7200 time: 0.0634s\n",
            "36\n",
            "Epoch: 0481 loss_train: 0.8159 acc_train: 0.7833 loss_val: 0.9259 acc_val: 0.7240 time: 0.0648s\n",
            "37\n",
            "Epoch: 0482 loss_train: 0.7874 acc_train: 0.8000 loss_val: 0.9212 acc_val: 0.7260 time: 0.0644s\n",
            "38\n",
            "Epoch: 0483 loss_train: 0.8365 acc_train: 0.7500 loss_val: 0.9217 acc_val: 0.7260 time: 0.0641s\n",
            "39\n",
            "Epoch: 0484 loss_train: 0.7861 acc_train: 0.7750 loss_val: 0.9257 acc_val: 0.7260 time: 0.0632s\n",
            "40\n",
            "Epoch: 0485 loss_train: 0.8298 acc_train: 0.8417 loss_val: 0.9350 acc_val: 0.7220 time: 0.0652s\n",
            "41\n",
            "Epoch: 0486 loss_train: 0.7739 acc_train: 0.8500 loss_val: 0.9406 acc_val: 0.7220 time: 0.0645s\n",
            "42\n",
            "Epoch: 0487 loss_train: 0.8374 acc_train: 0.8083 loss_val: 0.9428 acc_val: 0.7260 time: 0.0649s\n",
            "43\n",
            "Epoch: 0488 loss_train: 0.8432 acc_train: 0.8417 loss_val: 0.9389 acc_val: 0.7280 time: 0.0650s\n",
            "44\n",
            "Epoch: 0489 loss_train: 0.8273 acc_train: 0.7500 loss_val: 0.9294 acc_val: 0.7340 time: 0.0630s\n",
            "45\n",
            "Epoch: 0490 loss_train: 0.7963 acc_train: 0.8167 loss_val: 0.9180 acc_val: 0.7380 time: 0.0631s\n",
            "46\n",
            "Epoch: 0491 loss_train: 0.7993 acc_train: 0.8333 loss_val: 0.9112 acc_val: 0.7360 time: 0.0641s\n",
            "47\n",
            "Epoch: 0492 loss_train: 0.8365 acc_train: 0.8000 loss_val: 0.9108 acc_val: 0.7360 time: 0.0659s\n",
            "48\n",
            "Epoch: 0493 loss_train: 0.8025 acc_train: 0.7917 loss_val: 0.9165 acc_val: 0.7320 time: 0.0646s\n",
            "49\n",
            "Epoch: 0494 loss_train: 0.8819 acc_train: 0.7667 loss_val: 0.9286 acc_val: 0.7280 time: 0.0647s\n",
            "50\n",
            "Epoch: 0495 loss_train: 0.7984 acc_train: 0.8417 loss_val: 0.9446 acc_val: 0.7280 time: 0.0634s\n",
            "51\n",
            "Epoch: 0496 loss_train: 0.7851 acc_train: 0.8333 loss_val: 0.9595 acc_val: 0.7160 time: 0.0659s\n",
            "52\n",
            "Epoch: 0497 loss_train: 0.8603 acc_train: 0.8250 loss_val: 0.9597 acc_val: 0.7160 time: 0.0645s\n",
            "53\n",
            "Epoch: 0498 loss_train: 0.7937 acc_train: 0.8000 loss_val: 0.9463 acc_val: 0.7240 time: 0.0637s\n",
            "54\n",
            "Epoch: 0499 loss_train: 0.8318 acc_train: 0.7917 loss_val: 0.9312 acc_val: 0.7240 time: 0.0650s\n",
            "55\n",
            "Epoch: 0500 loss_train: 0.8212 acc_train: 0.8417 loss_val: 0.9226 acc_val: 0.7260 time: 0.0641s\n",
            "56\n",
            "Epoch: 0501 loss_train: 0.7853 acc_train: 0.8417 loss_val: 0.9180 acc_val: 0.7240 time: 0.0647s\n",
            "57\n",
            "Epoch: 0502 loss_train: 0.8113 acc_train: 0.8417 loss_val: 0.9187 acc_val: 0.7260 time: 0.0655s\n",
            "58\n",
            "Epoch: 0503 loss_train: 0.8275 acc_train: 0.8000 loss_val: 0.9239 acc_val: 0.7240 time: 0.0661s\n",
            "59\n",
            "Epoch: 0504 loss_train: 0.8316 acc_train: 0.8083 loss_val: 0.9272 acc_val: 0.7240 time: 0.0646s\n",
            "60\n",
            "Epoch: 0505 loss_train: 0.7943 acc_train: 0.8000 loss_val: 0.9358 acc_val: 0.7220 time: 0.0632s\n",
            "61\n",
            "Epoch: 0506 loss_train: 0.8202 acc_train: 0.7833 loss_val: 0.9464 acc_val: 0.7220 time: 0.0651s\n",
            "62\n",
            "Epoch: 0507 loss_train: 0.8469 acc_train: 0.8083 loss_val: 0.9494 acc_val: 0.7180 time: 0.0647s\n",
            "63\n",
            "Epoch: 0508 loss_train: 0.8090 acc_train: 0.8167 loss_val: 0.9496 acc_val: 0.7200 time: 0.0652s\n",
            "64\n",
            "Epoch: 0509 loss_train: 0.7776 acc_train: 0.8167 loss_val: 0.9459 acc_val: 0.7200 time: 0.0629s\n",
            "65\n",
            "Epoch: 0510 loss_train: 0.8344 acc_train: 0.8250 loss_val: 0.9388 acc_val: 0.7220 time: 0.0667s\n",
            "66\n",
            "Epoch: 0511 loss_train: 0.8635 acc_train: 0.7583 loss_val: 0.9311 acc_val: 0.7200 time: 0.0646s\n",
            "67\n",
            "Epoch: 0512 loss_train: 0.8091 acc_train: 0.7750 loss_val: 0.9270 acc_val: 0.7200 time: 0.0656s\n",
            "68\n",
            "Epoch: 0513 loss_train: 0.8127 acc_train: 0.8333 loss_val: 0.9247 acc_val: 0.7240 time: 0.0666s\n",
            "69\n",
            "Epoch: 0514 loss_train: 0.8586 acc_train: 0.8250 loss_val: 0.9253 acc_val: 0.7240 time: 0.0668s\n",
            "70\n",
            "Epoch: 0515 loss_train: 0.8332 acc_train: 0.7667 loss_val: 0.9281 acc_val: 0.7240 time: 0.0660s\n",
            "71\n",
            "Epoch: 0516 loss_train: 0.7529 acc_train: 0.8167 loss_val: 0.9298 acc_val: 0.7240 time: 0.0667s\n",
            "72\n",
            "Epoch: 0517 loss_train: 0.8153 acc_train: 0.8417 loss_val: 0.9348 acc_val: 0.7240 time: 0.0643s\n",
            "73\n",
            "Epoch: 0518 loss_train: 0.8307 acc_train: 0.7917 loss_val: 0.9404 acc_val: 0.7180 time: 0.0657s\n",
            "74\n",
            "Epoch: 0519 loss_train: 0.7906 acc_train: 0.8250 loss_val: 0.9441 acc_val: 0.7180 time: 0.0661s\n",
            "75\n",
            "Epoch: 0520 loss_train: 0.7997 acc_train: 0.8667 loss_val: 0.9426 acc_val: 0.7220 time: 0.0648s\n",
            "76\n",
            "Epoch: 0521 loss_train: 0.8515 acc_train: 0.7917 loss_val: 0.9361 acc_val: 0.7240 time: 0.0649s\n",
            "77\n",
            "Epoch: 0522 loss_train: 0.7726 acc_train: 0.8417 loss_val: 0.9289 acc_val: 0.7260 time: 0.0630s\n",
            "78\n",
            "Epoch: 0523 loss_train: 0.8160 acc_train: 0.8167 loss_val: 0.9231 acc_val: 0.7200 time: 0.0635s\n",
            "79\n",
            "Epoch: 0524 loss_train: 0.7839 acc_train: 0.8000 loss_val: 0.9214 acc_val: 0.7240 time: 0.0630s\n",
            "80\n",
            "Epoch: 0525 loss_train: 0.8114 acc_train: 0.7917 loss_val: 0.9248 acc_val: 0.7260 time: 0.0636s\n",
            "81\n",
            "Epoch: 0526 loss_train: 0.8117 acc_train: 0.8667 loss_val: 0.9327 acc_val: 0.7200 time: 0.0643s\n",
            "82\n",
            "Epoch: 0527 loss_train: 0.8743 acc_train: 0.8250 loss_val: 0.9396 acc_val: 0.7240 time: 0.0659s\n",
            "83\n",
            "Epoch: 0528 loss_train: 0.8441 acc_train: 0.8250 loss_val: 0.9469 acc_val: 0.7240 time: 0.0639s\n",
            "84\n",
            "Epoch: 0529 loss_train: 0.8162 acc_train: 0.8250 loss_val: 0.9474 acc_val: 0.7240 time: 0.0635s\n",
            "85\n",
            "Epoch: 0530 loss_train: 0.7895 acc_train: 0.8417 loss_val: 0.9414 acc_val: 0.7260 time: 0.0640s\n",
            "86\n",
            "Epoch: 0531 loss_train: 0.8432 acc_train: 0.7333 loss_val: 0.9309 acc_val: 0.7260 time: 0.0636s\n",
            "87\n",
            "Epoch: 0532 loss_train: 0.7804 acc_train: 0.8583 loss_val: 0.9181 acc_val: 0.7260 time: 0.0635s\n",
            "88\n",
            "Epoch: 0533 loss_train: 0.8125 acc_train: 0.7917 loss_val: 0.9091 acc_val: 0.7260 time: 0.0632s\n",
            "89\n",
            "Epoch: 0534 loss_train: 0.8468 acc_train: 0.7167 loss_val: 0.9072 acc_val: 0.7240 time: 0.0657s\n",
            "90\n",
            "Epoch: 0535 loss_train: 0.7792 acc_train: 0.8083 loss_val: 0.9089 acc_val: 0.7220 time: 0.0642s\n",
            "0\n",
            "Epoch: 0536 loss_train: 0.7965 acc_train: 0.8000 loss_val: 0.9167 acc_val: 0.7260 time: 0.0641s\n",
            "1\n",
            "Epoch: 0537 loss_train: 0.8095 acc_train: 0.7833 loss_val: 0.9274 acc_val: 0.7240 time: 0.0654s\n",
            "2\n",
            "Epoch: 0538 loss_train: 0.7760 acc_train: 0.8417 loss_val: 0.9362 acc_val: 0.7200 time: 0.0651s\n",
            "3\n",
            "Epoch: 0539 loss_train: 0.8176 acc_train: 0.8083 loss_val: 0.9400 acc_val: 0.7200 time: 0.0660s\n",
            "4\n",
            "Epoch: 0540 loss_train: 0.7880 acc_train: 0.8083 loss_val: 0.9365 acc_val: 0.7220 time: 0.0647s\n",
            "5\n",
            "Epoch: 0541 loss_train: 0.7880 acc_train: 0.8333 loss_val: 0.9261 acc_val: 0.7240 time: 0.0652s\n",
            "6\n",
            "Epoch: 0542 loss_train: 0.8707 acc_train: 0.8000 loss_val: 0.9175 acc_val: 0.7260 time: 0.0664s\n",
            "7\n",
            "Epoch: 0543 loss_train: 0.8333 acc_train: 0.7833 loss_val: 0.9106 acc_val: 0.7280 time: 0.0654s\n",
            "8\n",
            "Epoch: 0544 loss_train: 0.8211 acc_train: 0.7917 loss_val: 0.9080 acc_val: 0.7300 time: 0.0633s\n",
            "9\n",
            "Epoch: 0545 loss_train: 0.8320 acc_train: 0.8417 loss_val: 0.9121 acc_val: 0.7280 time: 0.0647s\n",
            "10\n",
            "Epoch: 0546 loss_train: 0.7871 acc_train: 0.8333 loss_val: 0.9198 acc_val: 0.7260 time: 0.0632s\n",
            "11\n",
            "Epoch: 0547 loss_train: 0.7961 acc_train: 0.8417 loss_val: 0.9330 acc_val: 0.7240 time: 0.0644s\n",
            "12\n",
            "Epoch: 0548 loss_train: 0.7783 acc_train: 0.8167 loss_val: 0.9445 acc_val: 0.7140 time: 0.0647s\n",
            "13\n",
            "Epoch: 0549 loss_train: 0.7785 acc_train: 0.7917 loss_val: 0.9529 acc_val: 0.7160 time: 0.0631s\n",
            "14\n",
            "Epoch: 0550 loss_train: 0.7307 acc_train: 0.9000 loss_val: 0.9551 acc_val: 0.7100 time: 0.0640s\n",
            "15\n",
            "Epoch: 0551 loss_train: 0.7639 acc_train: 0.8833 loss_val: 0.9460 acc_val: 0.7100 time: 0.0631s\n",
            "16\n",
            "Epoch: 0552 loss_train: 0.7817 acc_train: 0.8417 loss_val: 0.9342 acc_val: 0.7160 time: 0.0649s\n",
            "17\n",
            "Epoch: 0553 loss_train: 0.8424 acc_train: 0.7833 loss_val: 0.9231 acc_val: 0.7200 time: 0.0650s\n",
            "18\n",
            "Epoch: 0554 loss_train: 0.8028 acc_train: 0.8250 loss_val: 0.9148 acc_val: 0.7220 time: 0.0632s\n",
            "19\n",
            "Epoch: 0555 loss_train: 0.8296 acc_train: 0.7750 loss_val: 0.9130 acc_val: 0.7260 time: 0.0634s\n",
            "20\n",
            "Epoch: 0556 loss_train: 0.7914 acc_train: 0.7750 loss_val: 0.9154 acc_val: 0.7260 time: 0.0720s\n",
            "21\n",
            "Epoch: 0557 loss_train: 0.7883 acc_train: 0.8167 loss_val: 0.9212 acc_val: 0.7260 time: 0.0690s\n",
            "22\n",
            "Epoch: 0558 loss_train: 0.8475 acc_train: 0.8083 loss_val: 0.9356 acc_val: 0.7220 time: 0.0656s\n",
            "23\n",
            "Epoch: 0559 loss_train: 0.7530 acc_train: 0.8250 loss_val: 0.9537 acc_val: 0.7200 time: 0.0671s\n",
            "24\n",
            "Epoch: 0560 loss_train: 0.8002 acc_train: 0.8500 loss_val: 0.9680 acc_val: 0.7240 time: 0.0648s\n",
            "25\n",
            "Epoch: 0561 loss_train: 0.8295 acc_train: 0.7750 loss_val: 0.9716 acc_val: 0.7240 time: 0.0651s\n",
            "26\n",
            "Epoch: 0562 loss_train: 0.8225 acc_train: 0.8583 loss_val: 0.9594 acc_val: 0.7240 time: 0.0656s\n",
            "27\n",
            "Epoch: 0563 loss_train: 0.7963 acc_train: 0.8417 loss_val: 0.9437 acc_val: 0.7240 time: 0.0646s\n",
            "28\n",
            "Epoch: 0564 loss_train: 0.7965 acc_train: 0.8333 loss_val: 0.9290 acc_val: 0.7280 time: 0.0636s\n",
            "29\n",
            "Epoch: 0565 loss_train: 0.8212 acc_train: 0.8500 loss_val: 0.9176 acc_val: 0.7320 time: 0.0635s\n",
            "30\n",
            "Epoch: 0566 loss_train: 0.8241 acc_train: 0.8167 loss_val: 0.9135 acc_val: 0.7300 time: 0.0637s\n",
            "31\n",
            "Epoch: 0567 loss_train: 0.8066 acc_train: 0.8333 loss_val: 0.9152 acc_val: 0.7280 time: 0.0631s\n",
            "32\n",
            "Epoch: 0568 loss_train: 0.7860 acc_train: 0.7917 loss_val: 0.9185 acc_val: 0.7300 time: 0.0635s\n",
            "33\n",
            "Epoch: 0569 loss_train: 0.8077 acc_train: 0.7833 loss_val: 0.9233 acc_val: 0.7260 time: 0.0649s\n",
            "34\n",
            "Epoch: 0570 loss_train: 0.8586 acc_train: 0.8167 loss_val: 0.9358 acc_val: 0.7240 time: 0.0641s\n",
            "35\n",
            "Epoch: 0571 loss_train: 0.8880 acc_train: 0.7833 loss_val: 0.9466 acc_val: 0.7260 time: 0.0634s\n",
            "36\n",
            "Epoch: 0572 loss_train: 0.8387 acc_train: 0.7917 loss_val: 0.9585 acc_val: 0.7200 time: 0.0639s\n",
            "37\n",
            "Epoch: 0573 loss_train: 0.7950 acc_train: 0.7833 loss_val: 0.9625 acc_val: 0.7200 time: 0.0672s\n",
            "38\n",
            "Epoch: 0574 loss_train: 0.8575 acc_train: 0.7917 loss_val: 0.9568 acc_val: 0.7220 time: 0.0633s\n",
            "39\n",
            "Epoch: 0575 loss_train: 0.8378 acc_train: 0.8333 loss_val: 0.9470 acc_val: 0.7180 time: 0.0649s\n",
            "40\n",
            "Epoch: 0576 loss_train: 0.8697 acc_train: 0.7917 loss_val: 0.9392 acc_val: 0.7220 time: 0.0635s\n",
            "41\n",
            "Epoch: 0577 loss_train: 0.8100 acc_train: 0.8333 loss_val: 0.9317 acc_val: 0.7220 time: 0.0645s\n",
            "42\n",
            "Epoch: 0578 loss_train: 0.8248 acc_train: 0.7833 loss_val: 0.9235 acc_val: 0.7180 time: 0.0633s\n",
            "43\n",
            "Epoch: 0579 loss_train: 0.8447 acc_train: 0.7583 loss_val: 0.9218 acc_val: 0.7280 time: 0.0631s\n",
            "44\n",
            "Epoch: 0580 loss_train: 0.8497 acc_train: 0.8250 loss_val: 0.9275 acc_val: 0.7220 time: 0.0631s\n",
            "45\n",
            "Epoch: 0581 loss_train: 0.8231 acc_train: 0.8000 loss_val: 0.9369 acc_val: 0.7220 time: 0.0667s\n",
            "46\n",
            "Epoch: 0582 loss_train: 0.7482 acc_train: 0.8250 loss_val: 0.9467 acc_val: 0.7160 time: 0.0662s\n",
            "47\n",
            "Epoch: 0583 loss_train: 0.7939 acc_train: 0.8583 loss_val: 0.9549 acc_val: 0.7120 time: 0.0648s\n",
            "48\n",
            "Epoch: 0584 loss_train: 0.8018 acc_train: 0.7833 loss_val: 0.9533 acc_val: 0.7180 time: 0.0650s\n",
            "49\n",
            "Epoch: 0585 loss_train: 0.7943 acc_train: 0.8750 loss_val: 0.9475 acc_val: 0.7220 time: 0.0649s\n",
            "50\n",
            "Epoch: 0586 loss_train: 0.8184 acc_train: 0.8417 loss_val: 0.9393 acc_val: 0.7220 time: 0.0631s\n",
            "51\n",
            "Epoch: 0587 loss_train: 0.7551 acc_train: 0.8417 loss_val: 0.9288 acc_val: 0.7240 time: 0.0631s\n",
            "52\n",
            "Epoch: 0588 loss_train: 0.8140 acc_train: 0.8417 loss_val: 0.9213 acc_val: 0.7260 time: 0.0658s\n",
            "53\n",
            "Epoch: 0589 loss_train: 0.7879 acc_train: 0.8333 loss_val: 0.9182 acc_val: 0.7280 time: 0.0630s\n",
            "54\n",
            "Epoch: 0590 loss_train: 0.7990 acc_train: 0.8000 loss_val: 0.9153 acc_val: 0.7260 time: 0.0633s\n",
            "55\n",
            "Epoch: 0591 loss_train: 0.7791 acc_train: 0.8917 loss_val: 0.9155 acc_val: 0.7240 time: 0.0641s\n",
            "56\n",
            "Epoch: 0592 loss_train: 0.8475 acc_train: 0.7583 loss_val: 0.9194 acc_val: 0.7240 time: 0.0660s\n",
            "57\n",
            "Epoch: 0593 loss_train: 0.7197 acc_train: 0.8500 loss_val: 0.9273 acc_val: 0.7240 time: 0.0647s\n",
            "58\n",
            "Epoch: 0594 loss_train: 0.8569 acc_train: 0.7500 loss_val: 0.9352 acc_val: 0.7260 time: 0.0646s\n",
            "59\n",
            "Epoch: 0595 loss_train: 0.7792 acc_train: 0.7667 loss_val: 0.9427 acc_val: 0.7260 time: 0.0654s\n",
            "60\n",
            "Epoch: 0596 loss_train: 0.7859 acc_train: 0.8583 loss_val: 0.9471 acc_val: 0.7260 time: 0.0664s\n",
            "61\n",
            "Epoch: 0597 loss_train: 0.7463 acc_train: 0.8250 loss_val: 0.9474 acc_val: 0.7260 time: 0.0650s\n",
            "62\n",
            "Epoch: 0598 loss_train: 0.7955 acc_train: 0.8000 loss_val: 0.9486 acc_val: 0.7260 time: 0.0647s\n",
            "63\n",
            "Epoch: 0599 loss_train: 0.8191 acc_train: 0.8000 loss_val: 0.9443 acc_val: 0.7260 time: 0.0658s\n",
            "64\n",
            "Epoch: 0600 loss_train: 0.7825 acc_train: 0.8333 loss_val: 0.9380 acc_val: 0.7240 time: 0.0650s\n",
            "65\n",
            "Epoch: 0601 loss_train: 0.8507 acc_train: 0.7333 loss_val: 0.9347 acc_val: 0.7180 time: 0.0639s\n",
            "66\n",
            "Epoch: 0602 loss_train: 0.8514 acc_train: 0.7917 loss_val: 0.9350 acc_val: 0.7140 time: 0.0647s\n",
            "67\n",
            "Epoch: 0603 loss_train: 0.7820 acc_train: 0.8250 loss_val: 0.9375 acc_val: 0.7140 time: 0.0664s\n",
            "68\n",
            "Epoch: 0604 loss_train: 0.7821 acc_train: 0.7500 loss_val: 0.9392 acc_val: 0.7160 time: 0.0641s\n",
            "69\n",
            "Epoch: 0605 loss_train: 0.8208 acc_train: 0.8083 loss_val: 0.9386 acc_val: 0.7160 time: 0.0635s\n",
            "70\n",
            "Epoch: 0606 loss_train: 0.8310 acc_train: 0.7917 loss_val: 0.9351 acc_val: 0.7200 time: 0.0649s\n",
            "71\n",
            "Epoch: 0607 loss_train: 0.7802 acc_train: 0.8250 loss_val: 0.9315 acc_val: 0.7240 time: 0.0631s\n",
            "72\n",
            "Epoch: 0608 loss_train: 0.8284 acc_train: 0.8167 loss_val: 0.9297 acc_val: 0.7280 time: 0.0630s\n",
            "73\n",
            "Epoch: 0609 loss_train: 0.8240 acc_train: 0.7500 loss_val: 0.9271 acc_val: 0.7260 time: 0.0631s\n",
            "74\n",
            "Epoch: 0610 loss_train: 0.8075 acc_train: 0.8500 loss_val: 0.9292 acc_val: 0.7220 time: 0.0646s\n",
            "75\n",
            "Epoch: 0611 loss_train: 0.7808 acc_train: 0.8000 loss_val: 0.9308 acc_val: 0.7240 time: 0.0633s\n",
            "76\n",
            "Epoch: 0612 loss_train: 0.7935 acc_train: 0.7833 loss_val: 0.9390 acc_val: 0.7220 time: 0.0634s\n",
            "77\n",
            "Epoch: 0613 loss_train: 0.8080 acc_train: 0.8333 loss_val: 0.9443 acc_val: 0.7220 time: 0.0630s\n",
            "78\n",
            "Epoch: 0614 loss_train: 0.8656 acc_train: 0.7917 loss_val: 0.9477 acc_val: 0.7160 time: 0.0666s\n",
            "79\n",
            "Epoch: 0615 loss_train: 0.7822 acc_train: 0.8250 loss_val: 0.9437 acc_val: 0.7180 time: 0.0648s\n",
            "80\n",
            "Epoch: 0616 loss_train: 0.7635 acc_train: 0.8583 loss_val: 0.9367 acc_val: 0.7200 time: 0.0631s\n",
            "81\n",
            "Epoch: 0617 loss_train: 0.8270 acc_train: 0.8583 loss_val: 0.9314 acc_val: 0.7220 time: 0.0630s\n",
            "82\n",
            "Epoch: 0618 loss_train: 0.7807 acc_train: 0.8167 loss_val: 0.9297 acc_val: 0.7240 time: 0.0694s\n",
            "83\n",
            "Epoch: 0619 loss_train: 0.8226 acc_train: 0.8083 loss_val: 0.9318 acc_val: 0.7260 time: 0.0648s\n",
            "84\n",
            "Epoch: 0620 loss_train: 0.7816 acc_train: 0.8333 loss_val: 0.9329 acc_val: 0.7260 time: 0.0647s\n",
            "85\n",
            "Epoch: 0621 loss_train: 0.7724 acc_train: 0.8250 loss_val: 0.9347 acc_val: 0.7240 time: 0.0635s\n",
            "86\n",
            "Epoch: 0622 loss_train: 0.7718 acc_train: 0.8500 loss_val: 0.9362 acc_val: 0.7220 time: 0.0648s\n",
            "87\n",
            "Epoch: 0623 loss_train: 0.7953 acc_train: 0.8167 loss_val: 0.9358 acc_val: 0.7220 time: 0.0632s\n",
            "88\n",
            "Epoch: 0624 loss_train: 0.7948 acc_train: 0.8250 loss_val: 0.9342 acc_val: 0.7220 time: 0.0632s\n",
            "89\n",
            "Epoch: 0625 loss_train: 0.8113 acc_train: 0.7833 loss_val: 0.9306 acc_val: 0.7280 time: 0.0641s\n",
            "90\n",
            "Epoch: 0626 loss_train: 0.8171 acc_train: 0.8000 loss_val: 0.9297 acc_val: 0.7260 time: 0.0630s\n",
            "91\n",
            "Epoch: 0627 loss_train: 0.7919 acc_train: 0.8167 loss_val: 0.9286 acc_val: 0.7300 time: 0.0629s\n",
            "92\n",
            "Epoch: 0628 loss_train: 0.7953 acc_train: 0.8417 loss_val: 0.9289 acc_val: 0.7380 time: 0.0630s\n",
            "93\n",
            "Epoch: 0629 loss_train: 0.8093 acc_train: 0.8167 loss_val: 0.9322 acc_val: 0.7260 time: 0.0662s\n",
            "94\n",
            "Epoch: 0630 loss_train: 0.8368 acc_train: 0.8000 loss_val: 0.9379 acc_val: 0.7260 time: 0.0632s\n",
            "95\n",
            "Epoch: 0631 loss_train: 0.8089 acc_train: 0.8083 loss_val: 0.9422 acc_val: 0.7260 time: 0.0631s\n",
            "96\n",
            "Epoch: 0632 loss_train: 0.8373 acc_train: 0.8250 loss_val: 0.9472 acc_val: 0.7240 time: 0.0631s\n",
            "97\n",
            "Epoch: 0633 loss_train: 0.7913 acc_train: 0.8500 loss_val: 0.9485 acc_val: 0.7260 time: 0.0673s\n",
            "98\n",
            "Epoch: 0634 loss_train: 0.8169 acc_train: 0.8333 loss_val: 0.9503 acc_val: 0.7220 time: 0.0653s\n",
            "99\n",
            "Epoch: 0635 loss_train: 0.8233 acc_train: 0.8167 loss_val: 0.9429 acc_val: 0.7220 time: 0.0649s\n",
            "100\n",
            "Epoch: 0636 loss_train: 0.8142 acc_train: 0.8500 loss_val: 0.9342 acc_val: 0.7220 time: 0.0642s\n",
            "101\n",
            "Epoch: 0637 loss_train: 0.8035 acc_train: 0.8500 loss_val: 0.9212 acc_val: 0.7260 time: 0.0669s\n",
            "102\n",
            "Epoch: 0638 loss_train: 0.8376 acc_train: 0.7917 loss_val: 0.9158 acc_val: 0.7280 time: 0.0647s\n",
            "103\n",
            "Epoch: 0639 loss_train: 0.8367 acc_train: 0.7750 loss_val: 0.9176 acc_val: 0.7220 time: 0.0647s\n",
            "104\n",
            "Epoch: 0640 loss_train: 0.8534 acc_train: 0.8000 loss_val: 0.9255 acc_val: 0.7200 time: 0.0663s\n",
            "105\n",
            "Epoch: 0641 loss_train: 0.7733 acc_train: 0.8750 loss_val: 0.9357 acc_val: 0.7220 time: 0.0661s\n",
            "106\n",
            "Epoch: 0642 loss_train: 0.8409 acc_train: 0.7833 loss_val: 0.9491 acc_val: 0.7220 time: 0.0642s\n",
            "107\n",
            "Epoch: 0643 loss_train: 0.7950 acc_train: 0.8000 loss_val: 0.9605 acc_val: 0.7160 time: 0.0631s\n",
            "108\n",
            "Epoch: 0644 loss_train: 0.7534 acc_train: 0.8167 loss_val: 0.9703 acc_val: 0.7140 time: 0.0642s\n",
            "109\n",
            "Epoch: 0645 loss_train: 0.8480 acc_train: 0.7750 loss_val: 0.9711 acc_val: 0.7140 time: 0.0630s\n",
            "110\n",
            "Epoch: 0646 loss_train: 0.8251 acc_train: 0.7833 loss_val: 0.9614 acc_val: 0.7120 time: 0.0637s\n",
            "111\n",
            "Epoch: 0647 loss_train: 0.8715 acc_train: 0.7833 loss_val: 0.9481 acc_val: 0.7180 time: 0.0632s\n",
            "112\n",
            "Epoch: 0648 loss_train: 0.8109 acc_train: 0.8167 loss_val: 0.9357 acc_val: 0.7200 time: 0.0664s\n",
            "113\n",
            "Epoch: 0649 loss_train: 0.8473 acc_train: 0.7333 loss_val: 0.9241 acc_val: 0.7240 time: 0.0644s\n",
            "114\n",
            "Epoch: 0650 loss_train: 0.8669 acc_train: 0.8000 loss_val: 0.9186 acc_val: 0.7260 time: 0.0633s\n",
            "115\n",
            "Epoch: 0651 loss_train: 0.8231 acc_train: 0.8000 loss_val: 0.9176 acc_val: 0.7240 time: 0.0636s\n",
            "116\n",
            "Epoch: 0652 loss_train: 0.8143 acc_train: 0.8250 loss_val: 0.9212 acc_val: 0.7240 time: 0.0650s\n",
            "117\n",
            "Epoch: 0653 loss_train: 0.8471 acc_train: 0.8333 loss_val: 0.9272 acc_val: 0.7280 time: 0.0645s\n",
            "118\n",
            "Epoch: 0654 loss_train: 0.8215 acc_train: 0.8333 loss_val: 0.9359 acc_val: 0.7280 time: 0.0652s\n",
            "119\n",
            "Epoch: 0655 loss_train: 0.8426 acc_train: 0.8167 loss_val: 0.9464 acc_val: 0.7220 time: 0.0655s\n",
            "120\n",
            "Epoch: 0656 loss_train: 0.8091 acc_train: 0.8417 loss_val: 0.9527 acc_val: 0.7220 time: 0.0644s\n",
            "121\n",
            "Epoch: 0657 loss_train: 0.8052 acc_train: 0.7750 loss_val: 0.9513 acc_val: 0.7220 time: 0.0631s\n",
            "122\n",
            "Epoch: 0658 loss_train: 0.8074 acc_train: 0.8333 loss_val: 0.9472 acc_val: 0.7200 time: 0.0630s\n",
            "123\n",
            "Epoch: 0659 loss_train: 0.7610 acc_train: 0.8250 loss_val: 0.9391 acc_val: 0.7220 time: 0.0686s\n",
            "124\n",
            "Epoch: 0660 loss_train: 0.7255 acc_train: 0.8500 loss_val: 0.9298 acc_val: 0.7260 time: 0.0659s\n",
            "125\n",
            "Epoch: 0661 loss_train: 0.7915 acc_train: 0.8583 loss_val: 0.9196 acc_val: 0.7280 time: 0.0641s\n",
            "126\n",
            "Epoch: 0662 loss_train: 0.7909 acc_train: 0.8167 loss_val: 0.9144 acc_val: 0.7280 time: 0.0627s\n",
            "127\n",
            "Epoch: 0663 loss_train: 0.7983 acc_train: 0.7417 loss_val: 0.9112 acc_val: 0.7280 time: 0.0659s\n",
            "128\n",
            "Epoch: 0664 loss_train: 0.7471 acc_train: 0.8083 loss_val: 0.9094 acc_val: 0.7280 time: 0.0643s\n",
            "129\n",
            "Epoch: 0665 loss_train: 0.7967 acc_train: 0.8333 loss_val: 0.9120 acc_val: 0.7240 time: 0.0630s\n",
            "130\n",
            "Epoch: 0666 loss_train: 0.7596 acc_train: 0.8417 loss_val: 0.9155 acc_val: 0.7260 time: 0.0638s\n",
            "131\n",
            "Epoch: 0667 loss_train: 0.8007 acc_train: 0.8667 loss_val: 0.9227 acc_val: 0.7280 time: 0.0631s\n",
            "132\n",
            "Epoch: 0668 loss_train: 0.7533 acc_train: 0.8750 loss_val: 0.9314 acc_val: 0.7280 time: 0.0631s\n",
            "133\n",
            "Epoch: 0669 loss_train: 0.8114 acc_train: 0.7750 loss_val: 0.9415 acc_val: 0.7300 time: 0.0638s\n",
            "134\n",
            "Epoch: 0670 loss_train: 0.7508 acc_train: 0.8000 loss_val: 0.9435 acc_val: 0.7300 time: 0.0643s\n",
            "135\n",
            "Epoch: 0671 loss_train: 0.8254 acc_train: 0.8083 loss_val: 0.9425 acc_val: 0.7280 time: 0.0675s\n",
            "136\n",
            "Epoch: 0672 loss_train: 0.8692 acc_train: 0.7833 loss_val: 0.9362 acc_val: 0.7280 time: 0.0635s\n",
            "137\n",
            "Epoch: 0673 loss_train: 0.8273 acc_train: 0.8083 loss_val: 0.9296 acc_val: 0.7280 time: 0.0633s\n",
            "138\n",
            "Epoch: 0674 loss_train: 0.7345 acc_train: 0.8333 loss_val: 0.9238 acc_val: 0.7300 time: 0.0657s\n",
            "139\n",
            "Epoch: 0675 loss_train: 0.8212 acc_train: 0.7750 loss_val: 0.9204 acc_val: 0.7320 time: 0.0633s\n",
            "140\n",
            "Epoch: 0676 loss_train: 0.8429 acc_train: 0.7667 loss_val: 0.9204 acc_val: 0.7300 time: 0.0629s\n",
            "141\n",
            "Epoch: 0677 loss_train: 0.8128 acc_train: 0.8167 loss_val: 0.9211 acc_val: 0.7280 time: 0.0649s\n",
            "142\n",
            "Epoch: 0678 loss_train: 0.8259 acc_train: 0.8667 loss_val: 0.9211 acc_val: 0.7300 time: 0.0659s\n",
            "143\n",
            "Epoch: 0679 loss_train: 0.7895 acc_train: 0.7750 loss_val: 0.9234 acc_val: 0.7280 time: 0.0670s\n",
            "144\n",
            "Epoch: 0680 loss_train: 0.7968 acc_train: 0.8083 loss_val: 0.9275 acc_val: 0.7260 time: 0.0631s\n",
            "145\n",
            "Epoch: 0681 loss_train: 0.8294 acc_train: 0.7917 loss_val: 0.9297 acc_val: 0.7260 time: 0.0652s\n",
            "146\n",
            "Epoch: 0682 loss_train: 0.8496 acc_train: 0.7333 loss_val: 0.9291 acc_val: 0.7280 time: 0.0655s\n",
            "147\n",
            "Epoch: 0683 loss_train: 0.7692 acc_train: 0.8000 loss_val: 0.9265 acc_val: 0.7300 time: 0.0646s\n",
            "148\n",
            "Epoch: 0684 loss_train: 0.8227 acc_train: 0.8417 loss_val: 0.9220 acc_val: 0.7280 time: 0.0647s\n",
            "149\n",
            "Epoch: 0685 loss_train: 0.8406 acc_train: 0.8500 loss_val: 0.9201 acc_val: 0.7280 time: 0.0634s\n",
            "150\n",
            "Epoch: 0686 loss_train: 0.8294 acc_train: 0.8000 loss_val: 0.9227 acc_val: 0.7280 time: 0.0628s\n",
            "151\n",
            "Epoch: 0687 loss_train: 0.8110 acc_train: 0.8333 loss_val: 0.9274 acc_val: 0.7260 time: 0.0654s\n",
            "152\n",
            "Epoch: 0688 loss_train: 0.7726 acc_train: 0.8083 loss_val: 0.9310 acc_val: 0.7200 time: 0.0651s\n",
            "153\n",
            "Epoch: 0689 loss_train: 0.8196 acc_train: 0.7750 loss_val: 0.9357 acc_val: 0.7200 time: 0.0646s\n",
            "154\n",
            "Epoch: 0690 loss_train: 0.8029 acc_train: 0.7333 loss_val: 0.9414 acc_val: 0.7180 time: 0.0640s\n",
            "155\n",
            "Epoch: 0691 loss_train: 0.8390 acc_train: 0.7833 loss_val: 0.9468 acc_val: 0.7160 time: 0.0654s\n",
            "156\n",
            "Epoch: 0692 loss_train: 0.8537 acc_train: 0.7667 loss_val: 0.9479 acc_val: 0.7160 time: 0.0653s\n",
            "157\n",
            "Epoch: 0693 loss_train: 0.8364 acc_train: 0.8250 loss_val: 0.9432 acc_val: 0.7180 time: 0.0640s\n",
            "158\n",
            "Epoch: 0694 loss_train: 0.7959 acc_train: 0.8083 loss_val: 0.9335 acc_val: 0.7220 time: 0.0665s\n",
            "159\n",
            "Epoch: 0695 loss_train: 0.7505 acc_train: 0.8000 loss_val: 0.9233 acc_val: 0.7280 time: 0.0660s\n",
            "160\n",
            "Epoch: 0696 loss_train: 0.8383 acc_train: 0.8000 loss_val: 0.9159 acc_val: 0.7320 time: 0.0658s\n",
            "161\n",
            "Epoch: 0697 loss_train: 0.8220 acc_train: 0.8333 loss_val: 0.9137 acc_val: 0.7340 time: 0.0645s\n",
            "162\n",
            "Epoch: 0698 loss_train: 0.8021 acc_train: 0.8667 loss_val: 0.9152 acc_val: 0.7320 time: 0.0648s\n",
            "163\n",
            "Epoch: 0699 loss_train: 0.7946 acc_train: 0.7917 loss_val: 0.9188 acc_val: 0.7260 time: 0.0636s\n",
            "164\n",
            "Epoch: 0700 loss_train: 0.8254 acc_train: 0.8000 loss_val: 0.9287 acc_val: 0.7260 time: 0.0631s\n",
            "165\n",
            "Epoch: 0701 loss_train: 0.7400 acc_train: 0.7917 loss_val: 0.9435 acc_val: 0.7200 time: 0.0654s\n",
            "166\n",
            "Epoch: 0702 loss_train: 0.7530 acc_train: 0.8333 loss_val: 0.9553 acc_val: 0.7200 time: 0.0642s\n",
            "167\n",
            "Epoch: 0703 loss_train: 0.8409 acc_train: 0.8000 loss_val: 0.9653 acc_val: 0.7140 time: 0.0662s\n",
            "168\n",
            "Epoch: 0704 loss_train: 0.8125 acc_train: 0.7833 loss_val: 0.9613 acc_val: 0.7120 time: 0.0649s\n",
            "169\n",
            "Epoch: 0705 loss_train: 0.8227 acc_train: 0.8083 loss_val: 0.9537 acc_val: 0.7140 time: 0.0655s\n",
            "170\n",
            "Epoch: 0706 loss_train: 0.7948 acc_train: 0.7833 loss_val: 0.9458 acc_val: 0.7180 time: 0.0631s\n",
            "171\n",
            "Epoch: 0707 loss_train: 0.7768 acc_train: 0.8250 loss_val: 0.9363 acc_val: 0.7180 time: 0.0632s\n",
            "172\n",
            "Epoch: 0708 loss_train: 0.8720 acc_train: 0.8083 loss_val: 0.9289 acc_val: 0.7180 time: 0.0646s\n",
            "173\n",
            "Epoch: 0709 loss_train: 0.8309 acc_train: 0.7500 loss_val: 0.9255 acc_val: 0.7260 time: 0.0639s\n",
            "174\n",
            "Epoch: 0710 loss_train: 0.7944 acc_train: 0.8000 loss_val: 0.9241 acc_val: 0.7300 time: 0.0645s\n",
            "175\n",
            "Epoch: 0711 loss_train: 0.7813 acc_train: 0.8083 loss_val: 0.9240 acc_val: 0.7340 time: 0.0632s\n",
            "176\n",
            "Epoch: 0712 loss_train: 0.8005 acc_train: 0.7667 loss_val: 0.9252 acc_val: 0.7340 time: 0.0663s\n",
            "177\n",
            "Epoch: 0713 loss_train: 0.8126 acc_train: 0.8000 loss_val: 0.9280 acc_val: 0.7260 time: 0.0642s\n",
            "178\n",
            "Epoch: 0714 loss_train: 0.8390 acc_train: 0.8083 loss_val: 0.9333 acc_val: 0.7200 time: 0.0644s\n",
            "179\n",
            "Epoch: 0715 loss_train: 0.7680 acc_train: 0.7917 loss_val: 0.9401 acc_val: 0.7180 time: 0.0645s\n",
            "180\n",
            "Epoch: 0716 loss_train: 0.8079 acc_train: 0.8417 loss_val: 0.9450 acc_val: 0.7080 time: 0.0636s\n",
            "181\n",
            "Epoch: 0717 loss_train: 0.8102 acc_train: 0.8083 loss_val: 0.9453 acc_val: 0.7060 time: 0.0637s\n",
            "182\n",
            "Epoch: 0718 loss_train: 0.8160 acc_train: 0.8083 loss_val: 0.9474 acc_val: 0.7040 time: 0.0629s\n",
            "183\n",
            "Epoch: 0719 loss_train: 0.8729 acc_train: 0.7500 loss_val: 0.9440 acc_val: 0.7120 time: 0.0638s\n",
            "184\n",
            "Epoch: 0720 loss_train: 0.7548 acc_train: 0.8667 loss_val: 0.9373 acc_val: 0.7200 time: 0.0631s\n",
            "185\n",
            "Epoch: 0721 loss_train: 0.7717 acc_train: 0.8583 loss_val: 0.9311 acc_val: 0.7220 time: 0.0629s\n",
            "186\n",
            "Epoch: 0722 loss_train: 0.8089 acc_train: 0.8167 loss_val: 0.9241 acc_val: 0.7280 time: 0.0706s\n",
            "187\n",
            "Epoch: 0723 loss_train: 0.7887 acc_train: 0.8167 loss_val: 0.9244 acc_val: 0.7300 time: 0.0675s\n",
            "188\n",
            "Epoch: 0724 loss_train: 0.7672 acc_train: 0.7917 loss_val: 0.9289 acc_val: 0.7260 time: 0.0660s\n",
            "189\n",
            "Epoch: 0725 loss_train: 0.8314 acc_train: 0.8000 loss_val: 0.9326 acc_val: 0.7220 time: 0.0658s\n",
            "190\n",
            "Epoch: 0726 loss_train: 0.7573 acc_train: 0.8000 loss_val: 0.9363 acc_val: 0.7220 time: 0.0651s\n",
            "191\n",
            "Epoch: 0727 loss_train: 0.8227 acc_train: 0.7917 loss_val: 0.9371 acc_val: 0.7200 time: 0.0634s\n",
            "192\n",
            "Epoch: 0728 loss_train: 0.8085 acc_train: 0.7750 loss_val: 0.9356 acc_val: 0.7200 time: 0.0630s\n",
            "193\n",
            "Epoch: 0729 loss_train: 0.9069 acc_train: 0.7833 loss_val: 0.9381 acc_val: 0.7140 time: 0.0645s\n",
            "194\n",
            "Epoch: 0730 loss_train: 0.8075 acc_train: 0.8417 loss_val: 0.9388 acc_val: 0.7160 time: 0.0631s\n",
            "195\n",
            "Epoch: 0731 loss_train: 0.7268 acc_train: 0.8583 loss_val: 0.9390 acc_val: 0.7140 time: 0.0629s\n",
            "196\n",
            "Epoch: 0732 loss_train: 0.8009 acc_train: 0.8333 loss_val: 0.9406 acc_val: 0.7180 time: 0.0633s\n",
            "197\n",
            "Epoch: 0733 loss_train: 0.8228 acc_train: 0.8083 loss_val: 0.9437 acc_val: 0.7200 time: 0.0656s\n",
            "198\n",
            "Epoch: 0734 loss_train: 0.8498 acc_train: 0.8500 loss_val: 0.9478 acc_val: 0.7220 time: 0.0651s\n",
            "199\n",
            "Early stop! Min loss:  0.9071721434593201 , Max accuracy:  0.74\n",
            "Early stop model validation loss:  0.9071721434593201 , accuracy:  0.724\n",
            "Optimization Finished!\n",
            "Total time elapsed: 49.0265s\n",
            "Loading 533th epoch\n",
            "Test set results: loss= 0.8798 accuracy= 0.7290\n",
            "Epoch: 0001 loss_train: 0.8266 acc_train: 0.8000 loss_val: 0.9163 acc_val: 0.7280 time: 0.0634s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8328 acc_train: 0.8333 loss_val: 0.9271 acc_val: 0.7260 time: 0.0653s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8530 acc_train: 0.7750 loss_val: 0.9385 acc_val: 0.7240 time: 0.0631s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.8928 acc_train: 0.7750 loss_val: 0.9434 acc_val: 0.7220 time: 0.0645s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.8608 acc_train: 0.8250 loss_val: 0.9396 acc_val: 0.7220 time: 0.0634s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.8368 acc_train: 0.8750 loss_val: 0.9292 acc_val: 0.7220 time: 0.0664s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.8251 acc_train: 0.8250 loss_val: 0.9176 acc_val: 0.7240 time: 0.0651s\n",
            "5\n",
            "Epoch: 0008 loss_train: 0.8602 acc_train: 0.8083 loss_val: 0.9097 acc_val: 0.7220 time: 0.0668s\n",
            "6\n",
            "Epoch: 0009 loss_train: 0.8498 acc_train: 0.8167 loss_val: 0.9056 acc_val: 0.7240 time: 0.0638s\n",
            "0\n",
            "Epoch: 0010 loss_train: 0.8389 acc_train: 0.8417 loss_val: 0.9051 acc_val: 0.7240 time: 0.0631s\n",
            "0\n",
            "Epoch: 0011 loss_train: 0.8581 acc_train: 0.7833 loss_val: 0.9084 acc_val: 0.7280 time: 0.0627s\n",
            "0\n",
            "Epoch: 0012 loss_train: 0.8511 acc_train: 0.6917 loss_val: 0.9144 acc_val: 0.7260 time: 0.0638s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.8815 acc_train: 0.7833 loss_val: 0.9244 acc_val: 0.7240 time: 0.0638s\n",
            "1\n",
            "Epoch: 0014 loss_train: 0.8466 acc_train: 0.7833 loss_val: 0.9387 acc_val: 0.7220 time: 0.0629s\n",
            "2\n",
            "Epoch: 0015 loss_train: 0.8750 acc_train: 0.8000 loss_val: 0.9484 acc_val: 0.7180 time: 0.0655s\n",
            "3\n",
            "Epoch: 0016 loss_train: 0.8504 acc_train: 0.8417 loss_val: 0.9474 acc_val: 0.7160 time: 0.0641s\n",
            "4\n",
            "Epoch: 0017 loss_train: 0.8847 acc_train: 0.7500 loss_val: 0.9396 acc_val: 0.7260 time: 0.0632s\n",
            "5\n",
            "Epoch: 0018 loss_train: 0.9112 acc_train: 0.7667 loss_val: 0.9275 acc_val: 0.7260 time: 0.0634s\n",
            "6\n",
            "Epoch: 0019 loss_train: 0.8714 acc_train: 0.8583 loss_val: 0.9187 acc_val: 0.7260 time: 0.0638s\n",
            "7\n",
            "Epoch: 0020 loss_train: 0.8720 acc_train: 0.7750 loss_val: 0.9143 acc_val: 0.7280 time: 0.0658s\n",
            "8\n",
            "Epoch: 0021 loss_train: 0.8543 acc_train: 0.8333 loss_val: 0.9105 acc_val: 0.7260 time: 0.0659s\n",
            "0\n",
            "Epoch: 0022 loss_train: 0.8806 acc_train: 0.8167 loss_val: 0.9111 acc_val: 0.7200 time: 0.0654s\n",
            "1\n",
            "Epoch: 0023 loss_train: 0.8764 acc_train: 0.7833 loss_val: 0.9155 acc_val: 0.7200 time: 0.0660s\n",
            "2\n",
            "Epoch: 0024 loss_train: 0.8664 acc_train: 0.7500 loss_val: 0.9198 acc_val: 0.7200 time: 0.0683s\n",
            "3\n",
            "Epoch: 0025 loss_train: 0.8247 acc_train: 0.8167 loss_val: 0.9226 acc_val: 0.7220 time: 0.0648s\n",
            "4\n",
            "Epoch: 0026 loss_train: 0.8547 acc_train: 0.7833 loss_val: 0.9277 acc_val: 0.7220 time: 0.0681s\n",
            "5\n",
            "Epoch: 0027 loss_train: 0.8629 acc_train: 0.7917 loss_val: 0.9282 acc_val: 0.7260 time: 0.0689s\n",
            "6\n",
            "Epoch: 0028 loss_train: 0.8341 acc_train: 0.7833 loss_val: 0.9220 acc_val: 0.7260 time: 0.0645s\n",
            "7\n",
            "Epoch: 0029 loss_train: 0.8563 acc_train: 0.8000 loss_val: 0.9153 acc_val: 0.7280 time: 0.0643s\n",
            "8\n",
            "Epoch: 0030 loss_train: 0.8983 acc_train: 0.7583 loss_val: 0.9131 acc_val: 0.7320 time: 0.0643s\n",
            "0\n",
            "Epoch: 0031 loss_train: 0.8995 acc_train: 0.8167 loss_val: 0.9137 acc_val: 0.7300 time: 0.0630s\n",
            "0\n",
            "Epoch: 0032 loss_train: 0.8451 acc_train: 0.7917 loss_val: 0.9164 acc_val: 0.7240 time: 0.0632s\n",
            "1\n",
            "Epoch: 0033 loss_train: 0.8997 acc_train: 0.7417 loss_val: 0.9238 acc_val: 0.7240 time: 0.0647s\n",
            "2\n",
            "Epoch: 0034 loss_train: 0.8931 acc_train: 0.7417 loss_val: 0.9294 acc_val: 0.7220 time: 0.0653s\n",
            "3\n",
            "Epoch: 0035 loss_train: 0.8865 acc_train: 0.7833 loss_val: 0.9315 acc_val: 0.7200 time: 0.0636s\n",
            "4\n",
            "Epoch: 0036 loss_train: 0.8630 acc_train: 0.8250 loss_val: 0.9305 acc_val: 0.7220 time: 0.0641s\n",
            "5\n",
            "Epoch: 0037 loss_train: 0.8518 acc_train: 0.8583 loss_val: 0.9252 acc_val: 0.7240 time: 0.0647s\n",
            "6\n",
            "Epoch: 0038 loss_train: 0.9024 acc_train: 0.7667 loss_val: 0.9175 acc_val: 0.7240 time: 0.0633s\n",
            "7\n",
            "Epoch: 0039 loss_train: 0.8974 acc_train: 0.8083 loss_val: 0.9090 acc_val: 0.7300 time: 0.0634s\n",
            "8\n",
            "Epoch: 0040 loss_train: 0.8939 acc_train: 0.8083 loss_val: 0.9049 acc_val: 0.7260 time: 0.0631s\n",
            "9\n",
            "Epoch: 0041 loss_train: 0.8613 acc_train: 0.7667 loss_val: 0.9059 acc_val: 0.7280 time: 0.0648s\n",
            "0\n",
            "Epoch: 0042 loss_train: 0.8345 acc_train: 0.8250 loss_val: 0.9085 acc_val: 0.7220 time: 0.0657s\n",
            "1\n",
            "Epoch: 0043 loss_train: 0.8685 acc_train: 0.7917 loss_val: 0.9138 acc_val: 0.7200 time: 0.0646s\n",
            "2\n",
            "Epoch: 0044 loss_train: 0.8767 acc_train: 0.8250 loss_val: 0.9203 acc_val: 0.7180 time: 0.0665s\n",
            "3\n",
            "Epoch: 0045 loss_train: 0.8586 acc_train: 0.8167 loss_val: 0.9241 acc_val: 0.7220 time: 0.0680s\n",
            "4\n",
            "Epoch: 0046 loss_train: 0.8437 acc_train: 0.8333 loss_val: 0.9256 acc_val: 0.7220 time: 0.0647s\n",
            "5\n",
            "Epoch: 0047 loss_train: 0.8937 acc_train: 0.7917 loss_val: 0.9265 acc_val: 0.7220 time: 0.0646s\n",
            "6\n",
            "Epoch: 0048 loss_train: 0.8765 acc_train: 0.8083 loss_val: 0.9239 acc_val: 0.7240 time: 0.0661s\n",
            "7\n",
            "Epoch: 0049 loss_train: 0.8217 acc_train: 0.8083 loss_val: 0.9189 acc_val: 0.7260 time: 0.0649s\n",
            "8\n",
            "Epoch: 0050 loss_train: 0.8800 acc_train: 0.8250 loss_val: 0.9086 acc_val: 0.7280 time: 0.0662s\n",
            "9\n",
            "Epoch: 0051 loss_train: 0.8469 acc_train: 0.7583 loss_val: 0.9028 acc_val: 0.7280 time: 0.0647s\n",
            "10\n",
            "Epoch: 0052 loss_train: 0.8292 acc_train: 0.7917 loss_val: 0.9016 acc_val: 0.7260 time: 0.0647s\n",
            "0\n",
            "Epoch: 0053 loss_train: 0.8618 acc_train: 0.7583 loss_val: 0.9030 acc_val: 0.7240 time: 0.0628s\n",
            "0\n",
            "Epoch: 0054 loss_train: 0.8205 acc_train: 0.8333 loss_val: 0.9078 acc_val: 0.7240 time: 0.0630s\n",
            "1\n",
            "Epoch: 0055 loss_train: 0.8658 acc_train: 0.7833 loss_val: 0.9143 acc_val: 0.7240 time: 0.0652s\n",
            "2\n",
            "Epoch: 0056 loss_train: 0.8462 acc_train: 0.7917 loss_val: 0.9192 acc_val: 0.7220 time: 0.0655s\n",
            "3\n",
            "Epoch: 0057 loss_train: 0.8184 acc_train: 0.8000 loss_val: 0.9220 acc_val: 0.7240 time: 0.0643s\n",
            "4\n",
            "Epoch: 0058 loss_train: 0.8708 acc_train: 0.8167 loss_val: 0.9197 acc_val: 0.7240 time: 0.0633s\n",
            "5\n",
            "Epoch: 0059 loss_train: 0.7851 acc_train: 0.8250 loss_val: 0.9117 acc_val: 0.7300 time: 0.0649s\n",
            "6\n",
            "Epoch: 0060 loss_train: 0.8348 acc_train: 0.7917 loss_val: 0.9051 acc_val: 0.7360 time: 0.0647s\n",
            "7\n",
            "Epoch: 0061 loss_train: 0.8839 acc_train: 0.8583 loss_val: 0.9012 acc_val: 0.7380 time: 0.0651s\n",
            "0\n",
            "Epoch: 0062 loss_train: 0.8585 acc_train: 0.8167 loss_val: 0.8989 acc_val: 0.7380 time: 0.0650s\n",
            "0\n",
            "Epoch: 0063 loss_train: 0.8668 acc_train: 0.7750 loss_val: 0.9030 acc_val: 0.7320 time: 0.0656s\n",
            "0\n",
            "Epoch: 0064 loss_train: 0.8065 acc_train: 0.8167 loss_val: 0.9100 acc_val: 0.7300 time: 0.0644s\n",
            "1\n",
            "Epoch: 0065 loss_train: 0.8174 acc_train: 0.8250 loss_val: 0.9145 acc_val: 0.7280 time: 0.0631s\n",
            "2\n",
            "Epoch: 0066 loss_train: 0.9013 acc_train: 0.8500 loss_val: 0.9196 acc_val: 0.7280 time: 0.0658s\n",
            "3\n",
            "Epoch: 0067 loss_train: 0.7893 acc_train: 0.8500 loss_val: 0.9213 acc_val: 0.7280 time: 0.0645s\n",
            "4\n",
            "Epoch: 0068 loss_train: 0.8081 acc_train: 0.8250 loss_val: 0.9208 acc_val: 0.7280 time: 0.0632s\n",
            "5\n",
            "Epoch: 0069 loss_train: 0.8398 acc_train: 0.7583 loss_val: 0.9168 acc_val: 0.7280 time: 0.0645s\n",
            "6\n",
            "Epoch: 0070 loss_train: 0.8615 acc_train: 0.8333 loss_val: 0.9138 acc_val: 0.7300 time: 0.0631s\n",
            "7\n",
            "Epoch: 0071 loss_train: 0.8711 acc_train: 0.8083 loss_val: 0.9113 acc_val: 0.7300 time: 0.0630s\n",
            "8\n",
            "Epoch: 0072 loss_train: 0.8697 acc_train: 0.8083 loss_val: 0.9050 acc_val: 0.7320 time: 0.0631s\n",
            "9\n",
            "Epoch: 0073 loss_train: 0.8607 acc_train: 0.8417 loss_val: 0.9018 acc_val: 0.7360 time: 0.0672s\n",
            "10\n",
            "Epoch: 0074 loss_train: 0.8740 acc_train: 0.8000 loss_val: 0.9029 acc_val: 0.7300 time: 0.0637s\n",
            "11\n",
            "Epoch: 0075 loss_train: 0.8121 acc_train: 0.8000 loss_val: 0.9071 acc_val: 0.7280 time: 0.0671s\n",
            "12\n",
            "Epoch: 0076 loss_train: 0.8513 acc_train: 0.7667 loss_val: 0.9137 acc_val: 0.7200 time: 0.0649s\n",
            "13\n",
            "Epoch: 0077 loss_train: 0.8193 acc_train: 0.8250 loss_val: 0.9203 acc_val: 0.7180 time: 0.0676s\n",
            "14\n",
            "Epoch: 0078 loss_train: 0.8425 acc_train: 0.8250 loss_val: 0.9228 acc_val: 0.7220 time: 0.0670s\n",
            "15\n",
            "Epoch: 0079 loss_train: 0.8446 acc_train: 0.8083 loss_val: 0.9258 acc_val: 0.7220 time: 0.0665s\n",
            "16\n",
            "Epoch: 0080 loss_train: 0.8484 acc_train: 0.7917 loss_val: 0.9233 acc_val: 0.7200 time: 0.0675s\n",
            "17\n",
            "Epoch: 0081 loss_train: 0.7894 acc_train: 0.8750 loss_val: 0.9176 acc_val: 0.7280 time: 0.0660s\n",
            "18\n",
            "Epoch: 0082 loss_train: 0.9139 acc_train: 0.8167 loss_val: 0.9107 acc_val: 0.7300 time: 0.0667s\n",
            "19\n",
            "Epoch: 0083 loss_train: 0.8761 acc_train: 0.8250 loss_val: 0.9069 acc_val: 0.7280 time: 0.0687s\n",
            "20\n",
            "Epoch: 0084 loss_train: 0.8438 acc_train: 0.7917 loss_val: 0.9028 acc_val: 0.7320 time: 0.0652s\n",
            "21\n",
            "Epoch: 0085 loss_train: 0.8358 acc_train: 0.8083 loss_val: 0.9000 acc_val: 0.7340 time: 0.0658s\n",
            "22\n",
            "Epoch: 0086 loss_train: 0.9218 acc_train: 0.8167 loss_val: 0.9004 acc_val: 0.7340 time: 0.0650s\n",
            "23\n",
            "Epoch: 0087 loss_train: 0.9130 acc_train: 0.7583 loss_val: 0.9030 acc_val: 0.7340 time: 0.0637s\n",
            "24\n",
            "Epoch: 0088 loss_train: 0.8039 acc_train: 0.9000 loss_val: 0.9079 acc_val: 0.7340 time: 0.0644s\n",
            "25\n",
            "Epoch: 0089 loss_train: 0.8330 acc_train: 0.8667 loss_val: 0.9107 acc_val: 0.7340 time: 0.0656s\n",
            "26\n",
            "Epoch: 0090 loss_train: 0.8731 acc_train: 0.7917 loss_val: 0.9128 acc_val: 0.7300 time: 0.0638s\n",
            "27\n",
            "Epoch: 0091 loss_train: 0.8323 acc_train: 0.7750 loss_val: 0.9129 acc_val: 0.7260 time: 0.0647s\n",
            "28\n",
            "Epoch: 0092 loss_train: 0.8454 acc_train: 0.8417 loss_val: 0.9108 acc_val: 0.7240 time: 0.0638s\n",
            "29\n",
            "Epoch: 0093 loss_train: 0.8245 acc_train: 0.8167 loss_val: 0.9099 acc_val: 0.7240 time: 0.0678s\n",
            "30\n",
            "Epoch: 0094 loss_train: 0.8343 acc_train: 0.7583 loss_val: 0.9122 acc_val: 0.7200 time: 0.0658s\n",
            "31\n",
            "Epoch: 0095 loss_train: 0.8372 acc_train: 0.8083 loss_val: 0.9146 acc_val: 0.7220 time: 0.0652s\n",
            "32\n",
            "Epoch: 0096 loss_train: 0.8102 acc_train: 0.8417 loss_val: 0.9128 acc_val: 0.7220 time: 0.0679s\n",
            "33\n",
            "Epoch: 0097 loss_train: 0.8767 acc_train: 0.8083 loss_val: 0.9132 acc_val: 0.7240 time: 0.0660s\n",
            "34\n",
            "Epoch: 0098 loss_train: 0.8731 acc_train: 0.7500 loss_val: 0.9139 acc_val: 0.7300 time: 0.0685s\n",
            "35\n",
            "Epoch: 0099 loss_train: 0.8853 acc_train: 0.7417 loss_val: 0.9161 acc_val: 0.7280 time: 0.0678s\n",
            "36\n",
            "Epoch: 0100 loss_train: 0.8254 acc_train: 0.8250 loss_val: 0.9195 acc_val: 0.7280 time: 0.0641s\n",
            "37\n",
            "Epoch: 0101 loss_train: 0.9117 acc_train: 0.7750 loss_val: 0.9267 acc_val: 0.7240 time: 0.0632s\n",
            "38\n",
            "Epoch: 0102 loss_train: 0.8151 acc_train: 0.8000 loss_val: 0.9317 acc_val: 0.7220 time: 0.0635s\n",
            "39\n",
            "Epoch: 0103 loss_train: 0.8523 acc_train: 0.8500 loss_val: 0.9313 acc_val: 0.7200 time: 0.0656s\n",
            "40\n",
            "Epoch: 0104 loss_train: 0.8761 acc_train: 0.8250 loss_val: 0.9291 acc_val: 0.7180 time: 0.0639s\n",
            "41\n",
            "Epoch: 0105 loss_train: 0.8410 acc_train: 0.8583 loss_val: 0.9217 acc_val: 0.7220 time: 0.0639s\n",
            "42\n",
            "Epoch: 0106 loss_train: 0.8547 acc_train: 0.8000 loss_val: 0.9143 acc_val: 0.7260 time: 0.0632s\n",
            "43\n",
            "Epoch: 0107 loss_train: 0.9045 acc_train: 0.7667 loss_val: 0.9073 acc_val: 0.7320 time: 0.0660s\n",
            "44\n",
            "Epoch: 0108 loss_train: 0.8892 acc_train: 0.8417 loss_val: 0.9014 acc_val: 0.7360 time: 0.0647s\n",
            "45\n",
            "Epoch: 0109 loss_train: 0.8826 acc_train: 0.7917 loss_val: 0.9012 acc_val: 0.7280 time: 0.0647s\n",
            "46\n",
            "Epoch: 0110 loss_train: 0.8399 acc_train: 0.7667 loss_val: 0.9079 acc_val: 0.7260 time: 0.0649s\n",
            "47\n",
            "Epoch: 0111 loss_train: 0.8884 acc_train: 0.8250 loss_val: 0.9220 acc_val: 0.7220 time: 0.0672s\n",
            "48\n",
            "Epoch: 0112 loss_train: 0.8798 acc_train: 0.8083 loss_val: 0.9317 acc_val: 0.7260 time: 0.0647s\n",
            "49\n",
            "Epoch: 0113 loss_train: 0.8513 acc_train: 0.8083 loss_val: 0.9349 acc_val: 0.7240 time: 0.0631s\n",
            "50\n",
            "Epoch: 0114 loss_train: 0.8472 acc_train: 0.8417 loss_val: 0.9272 acc_val: 0.7280 time: 0.0642s\n",
            "51\n",
            "Epoch: 0115 loss_train: 0.8226 acc_train: 0.8167 loss_val: 0.9186 acc_val: 0.7240 time: 0.0635s\n",
            "52\n",
            "Epoch: 0116 loss_train: 0.8484 acc_train: 0.8500 loss_val: 0.9079 acc_val: 0.7340 time: 0.0628s\n",
            "53\n",
            "Epoch: 0117 loss_train: 0.8568 acc_train: 0.8083 loss_val: 0.9006 acc_val: 0.7340 time: 0.0629s\n",
            "54\n",
            "Epoch: 0118 loss_train: 0.8298 acc_train: 0.8000 loss_val: 0.8968 acc_val: 0.7380 time: 0.0640s\n",
            "55\n",
            "Epoch: 0119 loss_train: 0.8343 acc_train: 0.8333 loss_val: 0.8973 acc_val: 0.7380 time: 0.0639s\n",
            "0\n",
            "Epoch: 0120 loss_train: 0.8225 acc_train: 0.8167 loss_val: 0.9012 acc_val: 0.7260 time: 0.0634s\n",
            "0\n",
            "Epoch: 0121 loss_train: 0.8575 acc_train: 0.7917 loss_val: 0.9096 acc_val: 0.7220 time: 0.0631s\n",
            "1\n",
            "Epoch: 0122 loss_train: 0.8950 acc_train: 0.8000 loss_val: 0.9215 acc_val: 0.7200 time: 0.0641s\n",
            "2\n",
            "Epoch: 0123 loss_train: 0.8772 acc_train: 0.7417 loss_val: 0.9320 acc_val: 0.7140 time: 0.0642s\n",
            "3\n",
            "Epoch: 0124 loss_train: 0.8272 acc_train: 0.8083 loss_val: 0.9296 acc_val: 0.7220 time: 0.0649s\n",
            "4\n",
            "Epoch: 0125 loss_train: 0.8483 acc_train: 0.8167 loss_val: 0.9178 acc_val: 0.7260 time: 0.0677s\n",
            "5\n",
            "Epoch: 0126 loss_train: 0.8316 acc_train: 0.7667 loss_val: 0.9071 acc_val: 0.7320 time: 0.0697s\n",
            "6\n",
            "Epoch: 0127 loss_train: 0.8092 acc_train: 0.8167 loss_val: 0.8983 acc_val: 0.7320 time: 0.0654s\n",
            "7\n",
            "Epoch: 0128 loss_train: 0.8264 acc_train: 0.7750 loss_val: 0.8957 acc_val: 0.7320 time: 0.0664s\n",
            "8\n",
            "Epoch: 0129 loss_train: 0.8394 acc_train: 0.8500 loss_val: 0.8979 acc_val: 0.7320 time: 0.0664s\n",
            "0\n",
            "Epoch: 0130 loss_train: 0.8706 acc_train: 0.7583 loss_val: 0.9005 acc_val: 0.7300 time: 0.0640s\n",
            "1\n",
            "Epoch: 0131 loss_train: 0.8341 acc_train: 0.8417 loss_val: 0.9028 acc_val: 0.7300 time: 0.0644s\n",
            "2\n",
            "Epoch: 0132 loss_train: 0.8585 acc_train: 0.8083 loss_val: 0.9077 acc_val: 0.7240 time: 0.0637s\n",
            "3\n",
            "Epoch: 0133 loss_train: 0.8972 acc_train: 0.8167 loss_val: 0.9179 acc_val: 0.7240 time: 0.0637s\n",
            "4\n",
            "Epoch: 0134 loss_train: 0.8345 acc_train: 0.8083 loss_val: 0.9334 acc_val: 0.7180 time: 0.0632s\n",
            "5\n",
            "Epoch: 0135 loss_train: 0.8769 acc_train: 0.8167 loss_val: 0.9470 acc_val: 0.7080 time: 0.0651s\n",
            "6\n",
            "Epoch: 0136 loss_train: 0.8303 acc_train: 0.7833 loss_val: 0.9481 acc_val: 0.7100 time: 0.0651s\n",
            "7\n",
            "Epoch: 0137 loss_train: 0.8726 acc_train: 0.7833 loss_val: 0.9326 acc_val: 0.7140 time: 0.0654s\n",
            "8\n",
            "Epoch: 0138 loss_train: 0.8627 acc_train: 0.8167 loss_val: 0.9153 acc_val: 0.7200 time: 0.0651s\n",
            "9\n",
            "Epoch: 0139 loss_train: 0.8604 acc_train: 0.8250 loss_val: 0.9048 acc_val: 0.7280 time: 0.0662s\n",
            "10\n",
            "Epoch: 0140 loss_train: 0.8813 acc_train: 0.8000 loss_val: 0.9018 acc_val: 0.7260 time: 0.0632s\n",
            "11\n",
            "Epoch: 0141 loss_train: 0.9187 acc_train: 0.7583 loss_val: 0.9050 acc_val: 0.7320 time: 0.0665s\n",
            "12\n",
            "Epoch: 0142 loss_train: 0.8435 acc_train: 0.8167 loss_val: 0.9109 acc_val: 0.7280 time: 0.0643s\n",
            "13\n",
            "Epoch: 0143 loss_train: 0.8114 acc_train: 0.8167 loss_val: 0.9181 acc_val: 0.7280 time: 0.0630s\n",
            "14\n",
            "Epoch: 0144 loss_train: 0.8020 acc_train: 0.8583 loss_val: 0.9259 acc_val: 0.7240 time: 0.0639s\n",
            "15\n",
            "Epoch: 0145 loss_train: 0.8880 acc_train: 0.8500 loss_val: 0.9277 acc_val: 0.7260 time: 0.0630s\n",
            "16\n",
            "Epoch: 0146 loss_train: 0.8538 acc_train: 0.7833 loss_val: 0.9292 acc_val: 0.7220 time: 0.0748s\n",
            "17\n",
            "Epoch: 0147 loss_train: 0.8124 acc_train: 0.8333 loss_val: 0.9317 acc_val: 0.7200 time: 0.0679s\n",
            "18\n",
            "Epoch: 0148 loss_train: 0.8124 acc_train: 0.8083 loss_val: 0.9337 acc_val: 0.7120 time: 0.0645s\n",
            "19\n",
            "Epoch: 0149 loss_train: 0.8246 acc_train: 0.8167 loss_val: 0.9331 acc_val: 0.7120 time: 0.0634s\n",
            "20\n",
            "Epoch: 0150 loss_train: 0.8557 acc_train: 0.7917 loss_val: 0.9305 acc_val: 0.7160 time: 0.0666s\n",
            "21\n",
            "Epoch: 0151 loss_train: 0.8746 acc_train: 0.8083 loss_val: 0.9266 acc_val: 0.7120 time: 0.0645s\n",
            "22\n",
            "Epoch: 0152 loss_train: 0.8071 acc_train: 0.7917 loss_val: 0.9280 acc_val: 0.7180 time: 0.0645s\n",
            "23\n",
            "Epoch: 0153 loss_train: 0.8699 acc_train: 0.8250 loss_val: 0.9274 acc_val: 0.7220 time: 0.0661s\n",
            "24\n",
            "Epoch: 0154 loss_train: 0.7937 acc_train: 0.8667 loss_val: 0.9284 acc_val: 0.7220 time: 0.0645s\n",
            "25\n",
            "Epoch: 0155 loss_train: 0.8662 acc_train: 0.7000 loss_val: 0.9260 acc_val: 0.7260 time: 0.0644s\n",
            "26\n",
            "Epoch: 0156 loss_train: 0.8734 acc_train: 0.7750 loss_val: 0.9165 acc_val: 0.7260 time: 0.0663s\n",
            "27\n",
            "Epoch: 0157 loss_train: 0.8557 acc_train: 0.8000 loss_val: 0.9066 acc_val: 0.7300 time: 0.0643s\n",
            "28\n",
            "Epoch: 0158 loss_train: 0.8097 acc_train: 0.8583 loss_val: 0.9020 acc_val: 0.7260 time: 0.0637s\n",
            "29\n",
            "Epoch: 0159 loss_train: 0.8707 acc_train: 0.7667 loss_val: 0.9035 acc_val: 0.7280 time: 0.0633s\n",
            "30\n",
            "Epoch: 0160 loss_train: 0.8470 acc_train: 0.8250 loss_val: 0.9115 acc_val: 0.7220 time: 0.0644s\n",
            "31\n",
            "Epoch: 0161 loss_train: 0.8503 acc_train: 0.8500 loss_val: 0.9205 acc_val: 0.7220 time: 0.0633s\n",
            "32\n",
            "Epoch: 0162 loss_train: 0.8429 acc_train: 0.7500 loss_val: 0.9260 acc_val: 0.7180 time: 0.0630s\n",
            "33\n",
            "Epoch: 0163 loss_train: 0.9079 acc_train: 0.7583 loss_val: 0.9300 acc_val: 0.7160 time: 0.0632s\n",
            "34\n",
            "Epoch: 0164 loss_train: 0.8106 acc_train: 0.8083 loss_val: 0.9291 acc_val: 0.7180 time: 0.0648s\n",
            "35\n",
            "Epoch: 0165 loss_train: 0.8389 acc_train: 0.8167 loss_val: 0.9239 acc_val: 0.7180 time: 0.0638s\n",
            "36\n",
            "Epoch: 0166 loss_train: 0.8418 acc_train: 0.8167 loss_val: 0.9173 acc_val: 0.7220 time: 0.0631s\n",
            "37\n",
            "Epoch: 0167 loss_train: 0.8945 acc_train: 0.7833 loss_val: 0.9115 acc_val: 0.7280 time: 0.0633s\n",
            "38\n",
            "Epoch: 0168 loss_train: 0.8113 acc_train: 0.8000 loss_val: 0.9074 acc_val: 0.7320 time: 0.0648s\n",
            "39\n",
            "Epoch: 0169 loss_train: 0.8369 acc_train: 0.8333 loss_val: 0.9008 acc_val: 0.7300 time: 0.0642s\n",
            "40\n",
            "Epoch: 0170 loss_train: 0.8097 acc_train: 0.8667 loss_val: 0.8980 acc_val: 0.7340 time: 0.0641s\n",
            "41\n",
            "Epoch: 0171 loss_train: 0.8269 acc_train: 0.8167 loss_val: 0.8989 acc_val: 0.7340 time: 0.0654s\n",
            "42\n",
            "Epoch: 0172 loss_train: 0.8219 acc_train: 0.7917 loss_val: 0.9029 acc_val: 0.7300 time: 0.0665s\n",
            "43\n",
            "Epoch: 0173 loss_train: 0.8874 acc_train: 0.8167 loss_val: 0.9108 acc_val: 0.7260 time: 0.0647s\n",
            "44\n",
            "Epoch: 0174 loss_train: 0.8232 acc_train: 0.7667 loss_val: 0.9168 acc_val: 0.7220 time: 0.0649s\n",
            "45\n",
            "Epoch: 0175 loss_train: 0.8589 acc_train: 0.8333 loss_val: 0.9176 acc_val: 0.7220 time: 0.0653s\n",
            "46\n",
            "Epoch: 0176 loss_train: 0.8676 acc_train: 0.8083 loss_val: 0.9191 acc_val: 0.7200 time: 0.0656s\n",
            "47\n",
            "Epoch: 0177 loss_train: 0.8930 acc_train: 0.8167 loss_val: 0.9185 acc_val: 0.7200 time: 0.0638s\n",
            "48\n",
            "Epoch: 0178 loss_train: 0.8622 acc_train: 0.8333 loss_val: 0.9187 acc_val: 0.7240 time: 0.0660s\n",
            "49\n",
            "Epoch: 0179 loss_train: 0.8599 acc_train: 0.7833 loss_val: 0.9178 acc_val: 0.7260 time: 0.0633s\n",
            "50\n",
            "Epoch: 0180 loss_train: 0.9117 acc_train: 0.7833 loss_val: 0.9187 acc_val: 0.7280 time: 0.0628s\n",
            "51\n",
            "Epoch: 0181 loss_train: 0.8865 acc_train: 0.8000 loss_val: 0.9151 acc_val: 0.7260 time: 0.0632s\n",
            "52\n",
            "Epoch: 0182 loss_train: 0.8607 acc_train: 0.7833 loss_val: 0.9115 acc_val: 0.7300 time: 0.0653s\n",
            "53\n",
            "Epoch: 0183 loss_train: 0.8336 acc_train: 0.7750 loss_val: 0.9141 acc_val: 0.7320 time: 0.0636s\n",
            "54\n",
            "Epoch: 0184 loss_train: 0.8300 acc_train: 0.7750 loss_val: 0.9170 acc_val: 0.7280 time: 0.0632s\n",
            "55\n",
            "Epoch: 0185 loss_train: 0.8488 acc_train: 0.8083 loss_val: 0.9202 acc_val: 0.7260 time: 0.0634s\n",
            "56\n",
            "Epoch: 0186 loss_train: 0.8625 acc_train: 0.7833 loss_val: 0.9232 acc_val: 0.7300 time: 0.0678s\n",
            "57\n",
            "Epoch: 0187 loss_train: 0.8953 acc_train: 0.8250 loss_val: 0.9225 acc_val: 0.7340 time: 0.0662s\n",
            "58\n",
            "Epoch: 0188 loss_train: 0.8627 acc_train: 0.8167 loss_val: 0.9174 acc_val: 0.7300 time: 0.0647s\n",
            "59\n",
            "Epoch: 0189 loss_train: 0.8315 acc_train: 0.8167 loss_val: 0.9133 acc_val: 0.7240 time: 0.0639s\n",
            "60\n",
            "Epoch: 0190 loss_train: 0.8512 acc_train: 0.8417 loss_val: 0.9115 acc_val: 0.7240 time: 0.0656s\n",
            "61\n",
            "Epoch: 0191 loss_train: 0.8567 acc_train: 0.8000 loss_val: 0.9175 acc_val: 0.7260 time: 0.0660s\n",
            "62\n",
            "Epoch: 0192 loss_train: 0.8696 acc_train: 0.8083 loss_val: 0.9270 acc_val: 0.7240 time: 0.0657s\n",
            "63\n",
            "Epoch: 0193 loss_train: 0.8512 acc_train: 0.7750 loss_val: 0.9333 acc_val: 0.7240 time: 0.0642s\n",
            "64\n",
            "Epoch: 0194 loss_train: 0.8778 acc_train: 0.7583 loss_val: 0.9366 acc_val: 0.7260 time: 0.0633s\n",
            "65\n",
            "Epoch: 0195 loss_train: 0.8596 acc_train: 0.8250 loss_val: 0.9349 acc_val: 0.7280 time: 0.0630s\n",
            "66\n",
            "Epoch: 0196 loss_train: 0.8285 acc_train: 0.8167 loss_val: 0.9293 acc_val: 0.7280 time: 0.0631s\n",
            "67\n",
            "Epoch: 0197 loss_train: 0.8763 acc_train: 0.7917 loss_val: 0.9229 acc_val: 0.7260 time: 0.0657s\n",
            "68\n",
            "Epoch: 0198 loss_train: 0.8945 acc_train: 0.7750 loss_val: 0.9163 acc_val: 0.7300 time: 0.0647s\n",
            "69\n",
            "Epoch: 0199 loss_train: 0.8220 acc_train: 0.8000 loss_val: 0.9176 acc_val: 0.7280 time: 0.0651s\n",
            "70\n",
            "Epoch: 0200 loss_train: 0.8200 acc_train: 0.8500 loss_val: 0.9222 acc_val: 0.7260 time: 0.0647s\n",
            "71\n",
            "Epoch: 0201 loss_train: 0.8448 acc_train: 0.7833 loss_val: 0.9260 acc_val: 0.7260 time: 0.0689s\n",
            "72\n",
            "Epoch: 0202 loss_train: 0.8311 acc_train: 0.8083 loss_val: 0.9299 acc_val: 0.7300 time: 0.0656s\n",
            "73\n",
            "Epoch: 0203 loss_train: 0.8394 acc_train: 0.8333 loss_val: 0.9297 acc_val: 0.7300 time: 0.0646s\n",
            "74\n",
            "Epoch: 0204 loss_train: 0.8448 acc_train: 0.8333 loss_val: 0.9250 acc_val: 0.7300 time: 0.0658s\n",
            "75\n",
            "Epoch: 0205 loss_train: 0.8659 acc_train: 0.8250 loss_val: 0.9186 acc_val: 0.7300 time: 0.0631s\n",
            "76\n",
            "Epoch: 0206 loss_train: 0.8151 acc_train: 0.8167 loss_val: 0.9115 acc_val: 0.7280 time: 0.0631s\n",
            "77\n",
            "Epoch: 0207 loss_train: 0.8708 acc_train: 0.7833 loss_val: 0.9072 acc_val: 0.7280 time: 0.0631s\n",
            "78\n",
            "Epoch: 0208 loss_train: 0.8498 acc_train: 0.8333 loss_val: 0.9022 acc_val: 0.7300 time: 0.0651s\n",
            "79\n",
            "Epoch: 0209 loss_train: 0.8524 acc_train: 0.8000 loss_val: 0.9000 acc_val: 0.7300 time: 0.0631s\n",
            "80\n",
            "Epoch: 0210 loss_train: 0.9222 acc_train: 0.8167 loss_val: 0.9030 acc_val: 0.7300 time: 0.0635s\n",
            "81\n",
            "Epoch: 0211 loss_train: 0.8807 acc_train: 0.8417 loss_val: 0.9093 acc_val: 0.7260 time: 0.0631s\n",
            "82\n",
            "Epoch: 0212 loss_train: 0.8593 acc_train: 0.8000 loss_val: 0.9132 acc_val: 0.7280 time: 0.0642s\n",
            "83\n",
            "Epoch: 0213 loss_train: 0.8312 acc_train: 0.8167 loss_val: 0.9143 acc_val: 0.7260 time: 0.0650s\n",
            "84\n",
            "Epoch: 0214 loss_train: 0.8896 acc_train: 0.7917 loss_val: 0.9182 acc_val: 0.7220 time: 0.0631s\n",
            "85\n",
            "Epoch: 0215 loss_train: 0.8144 acc_train: 0.8417 loss_val: 0.9188 acc_val: 0.7220 time: 0.0632s\n",
            "86\n",
            "Epoch: 0216 loss_train: 0.8820 acc_train: 0.8333 loss_val: 0.9162 acc_val: 0.7260 time: 0.0641s\n",
            "87\n",
            "Epoch: 0217 loss_train: 0.8136 acc_train: 0.8417 loss_val: 0.9078 acc_val: 0.7300 time: 0.0644s\n",
            "88\n",
            "Epoch: 0218 loss_train: 0.7964 acc_train: 0.8583 loss_val: 0.9019 acc_val: 0.7320 time: 0.0632s\n",
            "89\n",
            "Epoch: 0219 loss_train: 0.8336 acc_train: 0.8583 loss_val: 0.8971 acc_val: 0.7360 time: 0.0654s\n",
            "90\n",
            "Epoch: 0220 loss_train: 0.8403 acc_train: 0.8750 loss_val: 0.8980 acc_val: 0.7340 time: 0.0647s\n",
            "91\n",
            "Epoch: 0221 loss_train: 0.8551 acc_train: 0.8250 loss_val: 0.9033 acc_val: 0.7280 time: 0.0649s\n",
            "92\n",
            "Epoch: 0222 loss_train: 0.8288 acc_train: 0.8333 loss_val: 0.9108 acc_val: 0.7280 time: 0.0631s\n",
            "93\n",
            "Epoch: 0223 loss_train: 0.7981 acc_train: 0.8500 loss_val: 0.9195 acc_val: 0.7240 time: 0.0662s\n",
            "94\n",
            "Epoch: 0224 loss_train: 0.8230 acc_train: 0.8250 loss_val: 0.9260 acc_val: 0.7240 time: 0.0643s\n",
            "95\n",
            "Epoch: 0225 loss_train: 0.9218 acc_train: 0.7833 loss_val: 0.9256 acc_val: 0.7220 time: 0.0635s\n",
            "96\n",
            "Epoch: 0226 loss_train: 0.8031 acc_train: 0.8750 loss_val: 0.9239 acc_val: 0.7220 time: 0.0656s\n",
            "97\n",
            "Epoch: 0227 loss_train: 0.8645 acc_train: 0.7750 loss_val: 0.9169 acc_val: 0.7280 time: 0.0638s\n",
            "98\n",
            "Epoch: 0228 loss_train: 0.8136 acc_train: 0.8000 loss_val: 0.9094 acc_val: 0.7280 time: 0.0654s\n",
            "99\n",
            "Epoch: 0229 loss_train: 0.8334 acc_train: 0.8083 loss_val: 0.9021 acc_val: 0.7320 time: 0.0637s\n",
            "100\n",
            "Epoch: 0230 loss_train: 0.8417 acc_train: 0.8250 loss_val: 0.8954 acc_val: 0.7340 time: 0.0651s\n",
            "101\n",
            "Epoch: 0231 loss_train: 0.8530 acc_train: 0.8417 loss_val: 0.8929 acc_val: 0.7360 time: 0.0646s\n",
            "0\n",
            "Epoch: 0232 loss_train: 0.8894 acc_train: 0.8500 loss_val: 0.8981 acc_val: 0.7360 time: 0.0669s\n",
            "0\n",
            "Epoch: 0233 loss_train: 0.8756 acc_train: 0.7917 loss_val: 0.9076 acc_val: 0.7320 time: 0.0656s\n",
            "1\n",
            "Epoch: 0234 loss_train: 0.8751 acc_train: 0.8500 loss_val: 0.9140 acc_val: 0.7280 time: 0.0637s\n",
            "2\n",
            "Epoch: 0235 loss_train: 0.8091 acc_train: 0.8333 loss_val: 0.9182 acc_val: 0.7280 time: 0.0633s\n",
            "3\n",
            "Epoch: 0236 loss_train: 0.8343 acc_train: 0.8667 loss_val: 0.9203 acc_val: 0.7280 time: 0.0632s\n",
            "4\n",
            "Epoch: 0237 loss_train: 0.8682 acc_train: 0.8083 loss_val: 0.9164 acc_val: 0.7300 time: 0.0668s\n",
            "5\n",
            "Epoch: 0238 loss_train: 0.8581 acc_train: 0.8250 loss_val: 0.9070 acc_val: 0.7300 time: 0.0694s\n",
            "6\n",
            "Epoch: 0239 loss_train: 0.8527 acc_train: 0.8083 loss_val: 0.9008 acc_val: 0.7320 time: 0.0678s\n",
            "7\n",
            "Epoch: 0240 loss_train: 0.8749 acc_train: 0.8083 loss_val: 0.8997 acc_val: 0.7300 time: 0.0675s\n",
            "8\n",
            "Epoch: 0241 loss_train: 0.9293 acc_train: 0.8083 loss_val: 0.9029 acc_val: 0.7260 time: 0.0657s\n",
            "9\n",
            "Epoch: 0242 loss_train: 0.8279 acc_train: 0.9000 loss_val: 0.9087 acc_val: 0.7200 time: 0.0668s\n",
            "10\n",
            "Epoch: 0243 loss_train: 0.8272 acc_train: 0.8000 loss_val: 0.9106 acc_val: 0.7200 time: 0.0652s\n",
            "11\n",
            "Epoch: 0244 loss_train: 0.8296 acc_train: 0.8500 loss_val: 0.9115 acc_val: 0.7180 time: 0.0659s\n",
            "12\n",
            "Epoch: 0245 loss_train: 0.8141 acc_train: 0.7667 loss_val: 0.9134 acc_val: 0.7240 time: 0.0641s\n",
            "13\n",
            "Epoch: 0246 loss_train: 0.8189 acc_train: 0.8333 loss_val: 0.9170 acc_val: 0.7240 time: 0.0644s\n",
            "14\n",
            "Epoch: 0247 loss_train: 0.8339 acc_train: 0.8417 loss_val: 0.9198 acc_val: 0.7280 time: 0.0689s\n",
            "15\n",
            "Epoch: 0248 loss_train: 0.8320 acc_train: 0.8750 loss_val: 0.9167 acc_val: 0.7300 time: 0.0644s\n",
            "16\n",
            "Epoch: 0249 loss_train: 0.8780 acc_train: 0.7583 loss_val: 0.9093 acc_val: 0.7300 time: 0.0639s\n",
            "17\n",
            "Epoch: 0250 loss_train: 0.8509 acc_train: 0.7917 loss_val: 0.9009 acc_val: 0.7300 time: 0.0640s\n",
            "18\n",
            "Epoch: 0251 loss_train: 0.7990 acc_train: 0.8083 loss_val: 0.8954 acc_val: 0.7320 time: 0.0645s\n",
            "19\n",
            "Epoch: 0252 loss_train: 0.8909 acc_train: 0.7833 loss_val: 0.8947 acc_val: 0.7320 time: 0.0636s\n",
            "20\n",
            "Epoch: 0253 loss_train: 0.8875 acc_train: 0.8083 loss_val: 0.8972 acc_val: 0.7340 time: 0.0641s\n",
            "21\n",
            "Epoch: 0254 loss_train: 0.8868 acc_train: 0.8417 loss_val: 0.9034 acc_val: 0.7360 time: 0.0682s\n",
            "22\n",
            "Epoch: 0255 loss_train: 0.8629 acc_train: 0.7417 loss_val: 0.9088 acc_val: 0.7360 time: 0.0658s\n",
            "23\n",
            "Epoch: 0256 loss_train: 0.8457 acc_train: 0.8167 loss_val: 0.9145 acc_val: 0.7340 time: 0.0654s\n",
            "24\n",
            "Epoch: 0257 loss_train: 0.9370 acc_train: 0.8083 loss_val: 0.9200 acc_val: 0.7240 time: 0.0673s\n",
            "25\n",
            "Epoch: 0258 loss_train: 0.8536 acc_train: 0.7750 loss_val: 0.9177 acc_val: 0.7220 time: 0.0726s\n",
            "26\n",
            "Epoch: 0259 loss_train: 0.8109 acc_train: 0.8750 loss_val: 0.9134 acc_val: 0.7200 time: 0.0672s\n",
            "27\n",
            "Epoch: 0260 loss_train: 0.8382 acc_train: 0.7833 loss_val: 0.9110 acc_val: 0.7260 time: 0.0655s\n",
            "28\n",
            "Epoch: 0261 loss_train: 0.8916 acc_train: 0.7417 loss_val: 0.9094 acc_val: 0.7240 time: 0.0675s\n",
            "29\n",
            "Epoch: 0262 loss_train: 0.8565 acc_train: 0.8167 loss_val: 0.9060 acc_val: 0.7260 time: 0.0667s\n",
            "30\n",
            "Epoch: 0263 loss_train: 0.8632 acc_train: 0.8083 loss_val: 0.9021 acc_val: 0.7260 time: 0.0657s\n",
            "31\n",
            "Epoch: 0264 loss_train: 0.8109 acc_train: 0.8583 loss_val: 0.9013 acc_val: 0.7260 time: 0.0644s\n",
            "32\n",
            "Epoch: 0265 loss_train: 0.8037 acc_train: 0.7833 loss_val: 0.9023 acc_val: 0.7220 time: 0.0632s\n",
            "33\n",
            "Epoch: 0266 loss_train: 0.7910 acc_train: 0.8500 loss_val: 0.9057 acc_val: 0.7240 time: 0.0631s\n",
            "34\n",
            "Epoch: 0267 loss_train: 0.8361 acc_train: 0.7417 loss_val: 0.9089 acc_val: 0.7240 time: 0.0633s\n",
            "35\n",
            "Epoch: 0268 loss_train: 0.8094 acc_train: 0.7917 loss_val: 0.9094 acc_val: 0.7220 time: 0.0646s\n",
            "36\n",
            "Epoch: 0269 loss_train: 0.8981 acc_train: 0.7917 loss_val: 0.9114 acc_val: 0.7260 time: 0.0629s\n",
            "37\n",
            "Epoch: 0270 loss_train: 0.7895 acc_train: 0.8333 loss_val: 0.9122 acc_val: 0.7300 time: 0.0641s\n",
            "38\n",
            "Epoch: 0271 loss_train: 0.8455 acc_train: 0.7583 loss_val: 0.9119 acc_val: 0.7300 time: 0.0631s\n",
            "39\n",
            "Epoch: 0272 loss_train: 0.8447 acc_train: 0.8167 loss_val: 0.9091 acc_val: 0.7300 time: 0.0643s\n",
            "40\n",
            "Epoch: 0273 loss_train: 0.8560 acc_train: 0.8083 loss_val: 0.9042 acc_val: 0.7400 time: 0.0635s\n",
            "41\n",
            "Epoch: 0274 loss_train: 0.9029 acc_train: 0.7667 loss_val: 0.9052 acc_val: 0.7320 time: 0.0631s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.8571 acc_train: 0.7917 loss_val: 0.9107 acc_val: 0.7280 time: 0.0634s\n",
            "1\n",
            "Epoch: 0276 loss_train: 0.8212 acc_train: 0.8583 loss_val: 0.9179 acc_val: 0.7260 time: 0.0656s\n",
            "2\n",
            "Epoch: 0277 loss_train: 0.8359 acc_train: 0.8167 loss_val: 0.9227 acc_val: 0.7240 time: 0.0680s\n",
            "3\n",
            "Epoch: 0278 loss_train: 0.8732 acc_train: 0.8250 loss_val: 0.9222 acc_val: 0.7280 time: 0.0646s\n",
            "4\n",
            "Epoch: 0279 loss_train: 0.8695 acc_train: 0.7833 loss_val: 0.9187 acc_val: 0.7280 time: 0.0635s\n",
            "5\n",
            "Epoch: 0280 loss_train: 0.8823 acc_train: 0.8417 loss_val: 0.9144 acc_val: 0.7320 time: 0.0657s\n",
            "6\n",
            "Epoch: 0281 loss_train: 0.8412 acc_train: 0.7583 loss_val: 0.9118 acc_val: 0.7300 time: 0.0633s\n",
            "7\n",
            "Epoch: 0282 loss_train: 0.8303 acc_train: 0.8417 loss_val: 0.9107 acc_val: 0.7360 time: 0.0632s\n",
            "8\n",
            "Epoch: 0283 loss_train: 0.8210 acc_train: 0.7917 loss_val: 0.9095 acc_val: 0.7380 time: 0.0639s\n",
            "9\n",
            "Epoch: 0284 loss_train: 0.8543 acc_train: 0.8250 loss_val: 0.9099 acc_val: 0.7360 time: 0.0644s\n",
            "10\n",
            "Epoch: 0285 loss_train: 0.8408 acc_train: 0.8083 loss_val: 0.9118 acc_val: 0.7360 time: 0.0630s\n",
            "11\n",
            "Epoch: 0286 loss_train: 0.8365 acc_train: 0.8167 loss_val: 0.9132 acc_val: 0.7320 time: 0.0632s\n",
            "12\n",
            "Epoch: 0287 loss_train: 0.8220 acc_train: 0.7833 loss_val: 0.9141 acc_val: 0.7320 time: 0.0662s\n",
            "13\n",
            "Epoch: 0288 loss_train: 0.8726 acc_train: 0.7833 loss_val: 0.9132 acc_val: 0.7260 time: 0.0656s\n",
            "14\n",
            "Epoch: 0289 loss_train: 0.8522 acc_train: 0.7750 loss_val: 0.9110 acc_val: 0.7260 time: 0.0647s\n",
            "15\n",
            "Epoch: 0290 loss_train: 0.8528 acc_train: 0.8000 loss_val: 0.9100 acc_val: 0.7280 time: 0.0647s\n",
            "16\n",
            "Epoch: 0291 loss_train: 0.9019 acc_train: 0.8333 loss_val: 0.9068 acc_val: 0.7300 time: 0.0681s\n",
            "17\n",
            "Epoch: 0292 loss_train: 0.8604 acc_train: 0.8083 loss_val: 0.9057 acc_val: 0.7280 time: 0.0660s\n",
            "18\n",
            "Epoch: 0293 loss_train: 0.8421 acc_train: 0.8250 loss_val: 0.9042 acc_val: 0.7320 time: 0.0664s\n",
            "19\n",
            "Epoch: 0294 loss_train: 0.8531 acc_train: 0.7917 loss_val: 0.9026 acc_val: 0.7320 time: 0.0657s\n",
            "20\n",
            "Epoch: 0295 loss_train: 0.8399 acc_train: 0.7833 loss_val: 0.9048 acc_val: 0.7300 time: 0.0658s\n",
            "21\n",
            "Epoch: 0296 loss_train: 0.8529 acc_train: 0.8083 loss_val: 0.9109 acc_val: 0.7320 time: 0.0645s\n",
            "22\n",
            "Epoch: 0297 loss_train: 0.8523 acc_train: 0.8000 loss_val: 0.9167 acc_val: 0.7320 time: 0.0640s\n",
            "23\n",
            "Epoch: 0298 loss_train: 0.8239 acc_train: 0.8167 loss_val: 0.9184 acc_val: 0.7340 time: 0.0646s\n",
            "24\n",
            "Epoch: 0299 loss_train: 0.8039 acc_train: 0.7583 loss_val: 0.9174 acc_val: 0.7340 time: 0.0635s\n",
            "25\n",
            "Epoch: 0300 loss_train: 0.8414 acc_train: 0.8417 loss_val: 0.9135 acc_val: 0.7340 time: 0.0633s\n",
            "26\n",
            "Epoch: 0301 loss_train: 0.8841 acc_train: 0.8500 loss_val: 0.9112 acc_val: 0.7320 time: 0.0645s\n",
            "27\n",
            "Epoch: 0302 loss_train: 0.8903 acc_train: 0.7500 loss_val: 0.9149 acc_val: 0.7300 time: 0.0636s\n",
            "28\n",
            "Epoch: 0303 loss_train: 0.8336 acc_train: 0.8417 loss_val: 0.9217 acc_val: 0.7260 time: 0.0641s\n",
            "29\n",
            "Epoch: 0304 loss_train: 0.8181 acc_train: 0.8250 loss_val: 0.9269 acc_val: 0.7260 time: 0.0680s\n",
            "30\n",
            "Epoch: 0305 loss_train: 0.9078 acc_train: 0.8000 loss_val: 0.9270 acc_val: 0.7280 time: 0.0632s\n",
            "31\n",
            "Epoch: 0306 loss_train: 0.8562 acc_train: 0.7917 loss_val: 0.9202 acc_val: 0.7280 time: 0.0634s\n",
            "32\n",
            "Epoch: 0307 loss_train: 0.8896 acc_train: 0.7583 loss_val: 0.9108 acc_val: 0.7340 time: 0.0632s\n",
            "33\n",
            "Epoch: 0308 loss_train: 0.8986 acc_train: 0.8083 loss_val: 0.9021 acc_val: 0.7340 time: 0.0684s\n",
            "34\n",
            "Epoch: 0309 loss_train: 0.8646 acc_train: 0.8000 loss_val: 0.8967 acc_val: 0.7340 time: 0.0654s\n",
            "35\n",
            "Epoch: 0310 loss_train: 0.8852 acc_train: 0.7750 loss_val: 0.9007 acc_val: 0.7340 time: 0.0635s\n",
            "36\n",
            "Epoch: 0311 loss_train: 0.8704 acc_train: 0.7417 loss_val: 0.9106 acc_val: 0.7260 time: 0.0633s\n",
            "37\n",
            "Epoch: 0312 loss_train: 0.8845 acc_train: 0.8167 loss_val: 0.9237 acc_val: 0.7320 time: 0.0654s\n",
            "38\n",
            "Epoch: 0313 loss_train: 0.8852 acc_train: 0.7250 loss_val: 0.9344 acc_val: 0.7280 time: 0.0647s\n",
            "39\n",
            "Epoch: 0314 loss_train: 0.8240 acc_train: 0.8000 loss_val: 0.9379 acc_val: 0.7260 time: 0.0634s\n",
            "40\n",
            "Epoch: 0315 loss_train: 0.8665 acc_train: 0.7750 loss_val: 0.9317 acc_val: 0.7220 time: 0.0665s\n",
            "41\n",
            "Epoch: 0316 loss_train: 0.8377 acc_train: 0.7667 loss_val: 0.9229 acc_val: 0.7260 time: 0.0656s\n",
            "42\n",
            "Epoch: 0317 loss_train: 0.8414 acc_train: 0.8083 loss_val: 0.9153 acc_val: 0.7260 time: 0.0657s\n",
            "43\n",
            "Epoch: 0318 loss_train: 0.8039 acc_train: 0.8167 loss_val: 0.9131 acc_val: 0.7220 time: 0.0644s\n",
            "44\n",
            "Epoch: 0319 loss_train: 0.8420 acc_train: 0.8167 loss_val: 0.9098 acc_val: 0.7240 time: 0.0652s\n",
            "45\n",
            "Epoch: 0320 loss_train: 0.9120 acc_train: 0.7750 loss_val: 0.9074 acc_val: 0.7280 time: 0.0634s\n",
            "46\n",
            "Epoch: 0321 loss_train: 0.8893 acc_train: 0.7750 loss_val: 0.9085 acc_val: 0.7280 time: 0.0643s\n",
            "47\n",
            "Epoch: 0322 loss_train: 0.8962 acc_train: 0.8250 loss_val: 0.9156 acc_val: 0.7280 time: 0.0643s\n",
            "48\n",
            "Epoch: 0323 loss_train: 0.8280 acc_train: 0.7833 loss_val: 0.9235 acc_val: 0.7320 time: 0.0645s\n",
            "49\n",
            "Epoch: 0324 loss_train: 0.8235 acc_train: 0.8583 loss_val: 0.9252 acc_val: 0.7320 time: 0.0633s\n",
            "50\n",
            "Epoch: 0325 loss_train: 0.8050 acc_train: 0.8667 loss_val: 0.9256 acc_val: 0.7320 time: 0.0631s\n",
            "51\n",
            "Epoch: 0326 loss_train: 0.8566 acc_train: 0.8167 loss_val: 0.9251 acc_val: 0.7300 time: 0.0646s\n",
            "52\n",
            "Epoch: 0327 loss_train: 0.8239 acc_train: 0.8167 loss_val: 0.9223 acc_val: 0.7280 time: 0.0644s\n",
            "53\n",
            "Epoch: 0328 loss_train: 0.8878 acc_train: 0.7500 loss_val: 0.9180 acc_val: 0.7260 time: 0.0630s\n",
            "54\n",
            "Epoch: 0329 loss_train: 0.8653 acc_train: 0.8083 loss_val: 0.9140 acc_val: 0.7260 time: 0.0631s\n",
            "55\n",
            "Epoch: 0330 loss_train: 0.8638 acc_train: 0.7917 loss_val: 0.9096 acc_val: 0.7240 time: 0.0645s\n",
            "56\n",
            "Epoch: 0331 loss_train: 0.8744 acc_train: 0.7667 loss_val: 0.9059 acc_val: 0.7200 time: 0.0644s\n",
            "57\n",
            "Epoch: 0332 loss_train: 0.7782 acc_train: 0.8000 loss_val: 0.9045 acc_val: 0.7300 time: 0.0635s\n",
            "58\n",
            "Epoch: 0333 loss_train: 0.8971 acc_train: 0.7750 loss_val: 0.9048 acc_val: 0.7300 time: 0.0647s\n",
            "59\n",
            "Epoch: 0334 loss_train: 0.8333 acc_train: 0.7667 loss_val: 0.9065 acc_val: 0.7300 time: 0.0651s\n",
            "60\n",
            "Epoch: 0335 loss_train: 0.8166 acc_train: 0.8417 loss_val: 0.9145 acc_val: 0.7280 time: 0.0644s\n",
            "61\n",
            "Epoch: 0336 loss_train: 0.8875 acc_train: 0.7917 loss_val: 0.9241 acc_val: 0.7280 time: 0.0642s\n",
            "62\n",
            "Epoch: 0337 loss_train: 0.8149 acc_train: 0.8083 loss_val: 0.9327 acc_val: 0.7280 time: 0.0645s\n",
            "63\n",
            "Epoch: 0338 loss_train: 0.8281 acc_train: 0.7333 loss_val: 0.9339 acc_val: 0.7300 time: 0.0675s\n",
            "64\n",
            "Epoch: 0339 loss_train: 0.8222 acc_train: 0.8417 loss_val: 0.9285 acc_val: 0.7300 time: 0.0635s\n",
            "65\n",
            "Epoch: 0340 loss_train: 0.8499 acc_train: 0.8333 loss_val: 0.9199 acc_val: 0.7280 time: 0.0632s\n",
            "66\n",
            "Epoch: 0341 loss_train: 0.9152 acc_train: 0.7833 loss_val: 0.9113 acc_val: 0.7280 time: 0.0653s\n",
            "67\n",
            "Epoch: 0342 loss_train: 0.8509 acc_train: 0.7917 loss_val: 0.9065 acc_val: 0.7260 time: 0.0659s\n",
            "68\n",
            "Epoch: 0343 loss_train: 0.8873 acc_train: 0.8250 loss_val: 0.9084 acc_val: 0.7280 time: 0.0658s\n",
            "69\n",
            "Epoch: 0344 loss_train: 0.7986 acc_train: 0.8000 loss_val: 0.9143 acc_val: 0.7280 time: 0.0667s\n",
            "70\n",
            "Epoch: 0345 loss_train: 0.8077 acc_train: 0.8333 loss_val: 0.9217 acc_val: 0.7300 time: 0.0647s\n",
            "71\n",
            "Epoch: 0346 loss_train: 0.8525 acc_train: 0.8250 loss_val: 0.9230 acc_val: 0.7280 time: 0.0647s\n",
            "72\n",
            "Epoch: 0347 loss_train: 0.8255 acc_train: 0.7917 loss_val: 0.9165 acc_val: 0.7260 time: 0.0637s\n",
            "73\n",
            "Epoch: 0348 loss_train: 0.8362 acc_train: 0.8333 loss_val: 0.9117 acc_val: 0.7280 time: 0.0690s\n",
            "74\n",
            "Epoch: 0349 loss_train: 0.8476 acc_train: 0.8833 loss_val: 0.9112 acc_val: 0.7280 time: 0.0634s\n",
            "75\n",
            "Epoch: 0350 loss_train: 0.8547 acc_train: 0.7583 loss_val: 0.9154 acc_val: 0.7260 time: 0.0631s\n",
            "76\n",
            "Epoch: 0351 loss_train: 0.8181 acc_train: 0.8167 loss_val: 0.9221 acc_val: 0.7280 time: 0.0647s\n",
            "77\n",
            "Epoch: 0352 loss_train: 0.8488 acc_train: 0.7917 loss_val: 0.9245 acc_val: 0.7260 time: 0.0640s\n",
            "78\n",
            "Epoch: 0353 loss_train: 0.8859 acc_train: 0.7000 loss_val: 0.9234 acc_val: 0.7300 time: 0.0643s\n",
            "79\n",
            "Epoch: 0354 loss_train: 0.8378 acc_train: 0.7667 loss_val: 0.9240 acc_val: 0.7300 time: 0.0652s\n",
            "80\n",
            "Epoch: 0355 loss_train: 0.8282 acc_train: 0.8083 loss_val: 0.9254 acc_val: 0.7260 time: 0.0662s\n",
            "81\n",
            "Epoch: 0356 loss_train: 0.8314 acc_train: 0.7917 loss_val: 0.9273 acc_val: 0.7220 time: 0.0646s\n",
            "82\n",
            "Epoch: 0357 loss_train: 0.8278 acc_train: 0.8083 loss_val: 0.9270 acc_val: 0.7240 time: 0.0660s\n",
            "83\n",
            "Epoch: 0358 loss_train: 0.9060 acc_train: 0.7333 loss_val: 0.9178 acc_val: 0.7240 time: 0.0654s\n",
            "84\n",
            "Epoch: 0359 loss_train: 0.8113 acc_train: 0.8500 loss_val: 0.9063 acc_val: 0.7280 time: 0.0674s\n",
            "85\n",
            "Epoch: 0360 loss_train: 0.8013 acc_train: 0.9083 loss_val: 0.8987 acc_val: 0.7320 time: 0.0655s\n",
            "86\n",
            "Epoch: 0361 loss_train: 0.8554 acc_train: 0.7500 loss_val: 0.8957 acc_val: 0.7280 time: 0.0646s\n",
            "87\n",
            "Epoch: 0362 loss_train: 0.8671 acc_train: 0.7417 loss_val: 0.8994 acc_val: 0.7260 time: 0.0647s\n",
            "88\n",
            "Epoch: 0363 loss_train: 0.8468 acc_train: 0.8500 loss_val: 0.9041 acc_val: 0.7280 time: 0.0633s\n",
            "89\n",
            "Epoch: 0364 loss_train: 0.8618 acc_train: 0.8583 loss_val: 0.9114 acc_val: 0.7300 time: 0.0632s\n",
            "90\n",
            "Epoch: 0365 loss_train: 0.8362 acc_train: 0.8333 loss_val: 0.9181 acc_val: 0.7300 time: 0.0638s\n",
            "91\n",
            "Epoch: 0366 loss_train: 0.7870 acc_train: 0.8750 loss_val: 0.9222 acc_val: 0.7260 time: 0.0646s\n",
            "92\n",
            "Epoch: 0367 loss_train: 0.7635 acc_train: 0.8333 loss_val: 0.9237 acc_val: 0.7260 time: 0.0632s\n",
            "93\n",
            "Epoch: 0368 loss_train: 0.8687 acc_train: 0.7583 loss_val: 0.9197 acc_val: 0.7300 time: 0.0631s\n",
            "94\n",
            "Epoch: 0369 loss_train: 0.8109 acc_train: 0.8500 loss_val: 0.9116 acc_val: 0.7320 time: 0.0640s\n",
            "95\n",
            "Epoch: 0370 loss_train: 0.9013 acc_train: 0.7917 loss_val: 0.9026 acc_val: 0.7340 time: 0.0643s\n",
            "96\n",
            "Epoch: 0371 loss_train: 0.8693 acc_train: 0.7917 loss_val: 0.9016 acc_val: 0.7360 time: 0.0631s\n",
            "97\n",
            "Epoch: 0372 loss_train: 0.7990 acc_train: 0.8000 loss_val: 0.9063 acc_val: 0.7340 time: 0.0633s\n",
            "98\n",
            "Epoch: 0373 loss_train: 0.8171 acc_train: 0.8333 loss_val: 0.9100 acc_val: 0.7320 time: 0.0630s\n",
            "99\n",
            "Epoch: 0374 loss_train: 0.9150 acc_train: 0.7833 loss_val: 0.9177 acc_val: 0.7280 time: 0.0670s\n",
            "100\n",
            "Epoch: 0375 loss_train: 0.8494 acc_train: 0.8333 loss_val: 0.9261 acc_val: 0.7240 time: 0.0646s\n",
            "101\n",
            "Epoch: 0376 loss_train: 0.8695 acc_train: 0.8500 loss_val: 0.9299 acc_val: 0.7260 time: 0.0645s\n",
            "102\n",
            "Epoch: 0377 loss_train: 0.8263 acc_train: 0.8000 loss_val: 0.9281 acc_val: 0.7260 time: 0.0654s\n",
            "103\n",
            "Epoch: 0378 loss_train: 0.8833 acc_train: 0.7250 loss_val: 0.9184 acc_val: 0.7280 time: 0.0659s\n",
            "104\n",
            "Epoch: 0379 loss_train: 0.8534 acc_train: 0.8333 loss_val: 0.9098 acc_val: 0.7340 time: 0.0647s\n",
            "105\n",
            "Epoch: 0380 loss_train: 0.8014 acc_train: 0.8083 loss_val: 0.9036 acc_val: 0.7320 time: 0.0632s\n",
            "106\n",
            "Epoch: 0381 loss_train: 0.8601 acc_train: 0.8083 loss_val: 0.9027 acc_val: 0.7320 time: 0.0657s\n",
            "107\n",
            "Epoch: 0382 loss_train: 0.8800 acc_train: 0.7750 loss_val: 0.9038 acc_val: 0.7320 time: 0.0642s\n",
            "108\n",
            "Epoch: 0383 loss_train: 0.8096 acc_train: 0.8417 loss_val: 0.9078 acc_val: 0.7320 time: 0.0634s\n",
            "109\n",
            "Epoch: 0384 loss_train: 0.8384 acc_train: 0.7667 loss_val: 0.9124 acc_val: 0.7300 time: 0.0643s\n",
            "110\n",
            "Epoch: 0385 loss_train: 0.8662 acc_train: 0.8667 loss_val: 0.9153 acc_val: 0.7280 time: 0.0698s\n",
            "111\n",
            "Epoch: 0386 loss_train: 0.8243 acc_train: 0.8167 loss_val: 0.9202 acc_val: 0.7280 time: 0.0632s\n",
            "112\n",
            "Epoch: 0387 loss_train: 0.8799 acc_train: 0.8417 loss_val: 0.9237 acc_val: 0.7280 time: 0.0631s\n",
            "113\n",
            "Epoch: 0388 loss_train: 0.8354 acc_train: 0.8167 loss_val: 0.9232 acc_val: 0.7280 time: 0.0641s\n",
            "114\n",
            "Epoch: 0389 loss_train: 0.7946 acc_train: 0.8083 loss_val: 0.9169 acc_val: 0.7300 time: 0.0631s\n",
            "115\n",
            "Epoch: 0390 loss_train: 0.7943 acc_train: 0.8333 loss_val: 0.9097 acc_val: 0.7320 time: 0.0630s\n",
            "116\n",
            "Epoch: 0391 loss_train: 0.8463 acc_train: 0.8250 loss_val: 0.9067 acc_val: 0.7340 time: 0.0636s\n",
            "117\n",
            "Epoch: 0392 loss_train: 0.9126 acc_train: 0.8333 loss_val: 0.9100 acc_val: 0.7340 time: 0.0663s\n",
            "118\n",
            "Epoch: 0393 loss_train: 0.8934 acc_train: 0.7583 loss_val: 0.9162 acc_val: 0.7360 time: 0.0669s\n",
            "119\n",
            "Epoch: 0394 loss_train: 0.8221 acc_train: 0.8250 loss_val: 0.9226 acc_val: 0.7300 time: 0.0644s\n",
            "120\n",
            "Epoch: 0395 loss_train: 0.8350 acc_train: 0.7833 loss_val: 0.9260 acc_val: 0.7300 time: 0.0643s\n",
            "121\n",
            "Epoch: 0396 loss_train: 0.8364 acc_train: 0.8250 loss_val: 0.9308 acc_val: 0.7280 time: 0.0652s\n",
            "122\n",
            "Epoch: 0397 loss_train: 0.8419 acc_train: 0.8583 loss_val: 0.9311 acc_val: 0.7260 time: 0.0646s\n",
            "123\n",
            "Epoch: 0398 loss_train: 0.8616 acc_train: 0.7833 loss_val: 0.9246 acc_val: 0.7260 time: 0.0647s\n",
            "124\n",
            "Epoch: 0399 loss_train: 0.8348 acc_train: 0.7833 loss_val: 0.9173 acc_val: 0.7300 time: 0.0678s\n",
            "125\n",
            "Epoch: 0400 loss_train: 0.9014 acc_train: 0.8083 loss_val: 0.9137 acc_val: 0.7280 time: 0.0650s\n",
            "126\n",
            "Epoch: 0401 loss_train: 0.8876 acc_train: 0.8083 loss_val: 0.9127 acc_val: 0.7260 time: 0.0654s\n",
            "127\n",
            "Epoch: 0402 loss_train: 0.8185 acc_train: 0.8417 loss_val: 0.9128 acc_val: 0.7260 time: 0.0646s\n",
            "128\n",
            "Epoch: 0403 loss_train: 0.8967 acc_train: 0.7667 loss_val: 0.9139 acc_val: 0.7260 time: 0.0659s\n",
            "129\n",
            "Epoch: 0404 loss_train: 0.8052 acc_train: 0.8250 loss_val: 0.9173 acc_val: 0.7240 time: 0.0646s\n",
            "130\n",
            "Epoch: 0405 loss_train: 0.8537 acc_train: 0.8333 loss_val: 0.9254 acc_val: 0.7260 time: 0.0630s\n",
            "131\n",
            "Epoch: 0406 loss_train: 0.8172 acc_train: 0.8417 loss_val: 0.9308 acc_val: 0.7220 time: 0.0641s\n",
            "132\n",
            "Epoch: 0407 loss_train: 0.8559 acc_train: 0.8167 loss_val: 0.9287 acc_val: 0.7220 time: 0.0636s\n",
            "133\n",
            "Epoch: 0408 loss_train: 0.9116 acc_train: 0.7667 loss_val: 0.9209 acc_val: 0.7260 time: 0.0644s\n",
            "134\n",
            "Epoch: 0409 loss_train: 0.8386 acc_train: 0.8250 loss_val: 0.9150 acc_val: 0.7260 time: 0.0653s\n",
            "135\n",
            "Epoch: 0410 loss_train: 0.8168 acc_train: 0.8333 loss_val: 0.9086 acc_val: 0.7280 time: 0.0660s\n",
            "136\n",
            "Epoch: 0411 loss_train: 0.8730 acc_train: 0.7833 loss_val: 0.9037 acc_val: 0.7260 time: 0.0647s\n",
            "137\n",
            "Epoch: 0412 loss_train: 0.8765 acc_train: 0.8083 loss_val: 0.9036 acc_val: 0.7280 time: 0.0634s\n",
            "138\n",
            "Epoch: 0413 loss_train: 0.8306 acc_train: 0.7500 loss_val: 0.9066 acc_val: 0.7280 time: 0.0664s\n",
            "139\n",
            "Epoch: 0414 loss_train: 0.9010 acc_train: 0.7667 loss_val: 0.9133 acc_val: 0.7240 time: 0.0660s\n",
            "140\n",
            "Epoch: 0415 loss_train: 0.7860 acc_train: 0.8833 loss_val: 0.9229 acc_val: 0.7240 time: 0.0651s\n",
            "141\n",
            "Epoch: 0416 loss_train: 0.7705 acc_train: 0.8167 loss_val: 0.9272 acc_val: 0.7200 time: 0.0642s\n",
            "142\n",
            "Epoch: 0417 loss_train: 0.8052 acc_train: 0.8917 loss_val: 0.9273 acc_val: 0.7220 time: 0.0668s\n",
            "143\n",
            "Epoch: 0418 loss_train: 0.8573 acc_train: 0.8000 loss_val: 0.9257 acc_val: 0.7220 time: 0.0663s\n",
            "144\n",
            "Epoch: 0419 loss_train: 0.8370 acc_train: 0.8417 loss_val: 0.9212 acc_val: 0.7220 time: 0.0650s\n",
            "145\n",
            "Epoch: 0420 loss_train: 0.7908 acc_train: 0.8000 loss_val: 0.9158 acc_val: 0.7280 time: 0.0642s\n",
            "146\n",
            "Epoch: 0421 loss_train: 0.8280 acc_train: 0.8583 loss_val: 0.9076 acc_val: 0.7280 time: 0.0632s\n",
            "147\n",
            "Epoch: 0422 loss_train: 0.8573 acc_train: 0.8417 loss_val: 0.9023 acc_val: 0.7300 time: 0.0646s\n",
            "148\n",
            "Epoch: 0423 loss_train: 0.8591 acc_train: 0.8083 loss_val: 0.9031 acc_val: 0.7300 time: 0.0671s\n",
            "149\n",
            "Epoch: 0424 loss_train: 0.8558 acc_train: 0.8000 loss_val: 0.9076 acc_val: 0.7280 time: 0.0657s\n",
            "150\n",
            "Epoch: 0425 loss_train: 0.8570 acc_train: 0.8000 loss_val: 0.9137 acc_val: 0.7280 time: 0.0655s\n",
            "151\n",
            "Epoch: 0426 loss_train: 0.8794 acc_train: 0.8000 loss_val: 0.9244 acc_val: 0.7280 time: 0.0645s\n",
            "152\n",
            "Epoch: 0427 loss_train: 0.8396 acc_train: 0.8250 loss_val: 0.9332 acc_val: 0.7260 time: 0.0653s\n",
            "153\n",
            "Epoch: 0428 loss_train: 0.8039 acc_train: 0.8083 loss_val: 0.9348 acc_val: 0.7220 time: 0.0645s\n",
            "154\n",
            "Epoch: 0429 loss_train: 0.8487 acc_train: 0.8167 loss_val: 0.9354 acc_val: 0.7220 time: 0.0657s\n",
            "155\n",
            "Epoch: 0430 loss_train: 0.8602 acc_train: 0.8000 loss_val: 0.9309 acc_val: 0.7240 time: 0.0651s\n",
            "156\n",
            "Epoch: 0431 loss_train: 0.8104 acc_train: 0.8417 loss_val: 0.9237 acc_val: 0.7260 time: 0.0658s\n",
            "157\n",
            "Epoch: 0432 loss_train: 0.8218 acc_train: 0.8167 loss_val: 0.9147 acc_val: 0.7280 time: 0.0667s\n",
            "158\n",
            "Epoch: 0433 loss_train: 0.8899 acc_train: 0.7750 loss_val: 0.9068 acc_val: 0.7280 time: 0.0641s\n",
            "159\n",
            "Epoch: 0434 loss_train: 0.8649 acc_train: 0.7583 loss_val: 0.9040 acc_val: 0.7280 time: 0.0654s\n",
            "160\n",
            "Epoch: 0435 loss_train: 0.8698 acc_train: 0.7667 loss_val: 0.9037 acc_val: 0.7300 time: 0.0644s\n",
            "161\n",
            "Epoch: 0436 loss_train: 0.8428 acc_train: 0.7833 loss_val: 0.9067 acc_val: 0.7300 time: 0.0637s\n",
            "162\n",
            "Epoch: 0437 loss_train: 0.8240 acc_train: 0.8750 loss_val: 0.9127 acc_val: 0.7280 time: 0.0644s\n",
            "163\n",
            "Epoch: 0438 loss_train: 0.8597 acc_train: 0.8167 loss_val: 0.9254 acc_val: 0.7280 time: 0.0665s\n",
            "164\n",
            "Epoch: 0439 loss_train: 0.8221 acc_train: 0.8583 loss_val: 0.9335 acc_val: 0.7200 time: 0.0639s\n",
            "165\n",
            "Epoch: 0440 loss_train: 0.8546 acc_train: 0.8500 loss_val: 0.9349 acc_val: 0.7220 time: 0.0636s\n",
            "166\n",
            "Epoch: 0441 loss_train: 0.9007 acc_train: 0.8417 loss_val: 0.9335 acc_val: 0.7240 time: 0.0646s\n",
            "167\n",
            "Epoch: 0442 loss_train: 0.8703 acc_train: 0.7833 loss_val: 0.9249 acc_val: 0.7240 time: 0.0631s\n",
            "168\n",
            "Epoch: 0443 loss_train: 0.8513 acc_train: 0.7833 loss_val: 0.9130 acc_val: 0.7240 time: 0.0643s\n",
            "169\n",
            "Epoch: 0444 loss_train: 0.8160 acc_train: 0.8667 loss_val: 0.9027 acc_val: 0.7300 time: 0.0662s\n",
            "170\n",
            "Epoch: 0445 loss_train: 0.8358 acc_train: 0.8333 loss_val: 0.8991 acc_val: 0.7320 time: 0.0653s\n",
            "171\n",
            "Epoch: 0446 loss_train: 0.8225 acc_train: 0.7917 loss_val: 0.8988 acc_val: 0.7280 time: 0.0645s\n",
            "172\n",
            "Epoch: 0447 loss_train: 0.8613 acc_train: 0.7750 loss_val: 0.9052 acc_val: 0.7300 time: 0.0632s\n",
            "173\n",
            "Epoch: 0448 loss_train: 0.8463 acc_train: 0.8167 loss_val: 0.9153 acc_val: 0.7280 time: 0.0650s\n",
            "174\n",
            "Epoch: 0449 loss_train: 0.8558 acc_train: 0.8000 loss_val: 0.9245 acc_val: 0.7220 time: 0.0631s\n",
            "175\n",
            "Epoch: 0450 loss_train: 0.8664 acc_train: 0.8167 loss_val: 0.9304 acc_val: 0.7180 time: 0.0630s\n",
            "176\n",
            "Epoch: 0451 loss_train: 0.8606 acc_train: 0.8417 loss_val: 0.9299 acc_val: 0.7200 time: 0.0639s\n",
            "177\n",
            "Epoch: 0452 loss_train: 0.8144 acc_train: 0.8500 loss_val: 0.9230 acc_val: 0.7220 time: 0.0677s\n",
            "178\n",
            "Epoch: 0453 loss_train: 0.8335 acc_train: 0.8500 loss_val: 0.9138 acc_val: 0.7280 time: 0.0648s\n",
            "179\n",
            "Epoch: 0454 loss_train: 0.8552 acc_train: 0.8250 loss_val: 0.9043 acc_val: 0.7240 time: 0.0647s\n",
            "180\n",
            "Epoch: 0455 loss_train: 0.8237 acc_train: 0.8167 loss_val: 0.9007 acc_val: 0.7240 time: 0.0635s\n",
            "181\n",
            "Epoch: 0456 loss_train: 0.8501 acc_train: 0.8333 loss_val: 0.9013 acc_val: 0.7260 time: 0.0681s\n",
            "182\n",
            "Epoch: 0457 loss_train: 0.7761 acc_train: 0.8583 loss_val: 0.9057 acc_val: 0.7260 time: 0.0645s\n",
            "183\n",
            "Epoch: 0458 loss_train: 0.8721 acc_train: 0.7167 loss_val: 0.9120 acc_val: 0.7240 time: 0.0640s\n",
            "184\n",
            "Epoch: 0459 loss_train: 0.8279 acc_train: 0.7917 loss_val: 0.9178 acc_val: 0.7260 time: 0.0649s\n",
            "185\n",
            "Epoch: 0460 loss_train: 0.8918 acc_train: 0.8083 loss_val: 0.9208 acc_val: 0.7260 time: 0.0654s\n",
            "186\n",
            "Epoch: 0461 loss_train: 0.8343 acc_train: 0.7667 loss_val: 0.9211 acc_val: 0.7240 time: 0.0631s\n",
            "187\n",
            "Epoch: 0462 loss_train: 0.9024 acc_train: 0.8000 loss_val: 0.9186 acc_val: 0.7240 time: 0.0632s\n",
            "188\n",
            "Epoch: 0463 loss_train: 0.8549 acc_train: 0.8583 loss_val: 0.9175 acc_val: 0.7240 time: 0.0644s\n",
            "189\n",
            "Epoch: 0464 loss_train: 0.8731 acc_train: 0.7833 loss_val: 0.9187 acc_val: 0.7240 time: 0.0668s\n",
            "190\n",
            "Epoch: 0465 loss_train: 0.8649 acc_train: 0.9000 loss_val: 0.9194 acc_val: 0.7280 time: 0.0654s\n",
            "191\n",
            "Epoch: 0466 loss_train: 0.8153 acc_train: 0.8250 loss_val: 0.9208 acc_val: 0.7260 time: 0.0639s\n",
            "192\n",
            "Epoch: 0467 loss_train: 0.8685 acc_train: 0.8083 loss_val: 0.9174 acc_val: 0.7260 time: 0.0651s\n",
            "193\n",
            "Epoch: 0468 loss_train: 0.8670 acc_train: 0.7500 loss_val: 0.9175 acc_val: 0.7260 time: 0.0639s\n",
            "194\n",
            "Epoch: 0469 loss_train: 0.8125 acc_train: 0.8667 loss_val: 0.9194 acc_val: 0.7240 time: 0.0632s\n",
            "195\n",
            "Epoch: 0470 loss_train: 0.8640 acc_train: 0.8000 loss_val: 0.9170 acc_val: 0.7220 time: 0.0631s\n",
            "196\n",
            "Epoch: 0471 loss_train: 0.8392 acc_train: 0.8333 loss_val: 0.9136 acc_val: 0.7260 time: 0.0680s\n",
            "197\n",
            "Epoch: 0472 loss_train: 0.8501 acc_train: 0.8417 loss_val: 0.9123 acc_val: 0.7260 time: 0.0657s\n",
            "198\n",
            "Epoch: 0473 loss_train: 0.8296 acc_train: 0.8000 loss_val: 0.9146 acc_val: 0.7260 time: 0.0644s\n",
            "199\n",
            "Early stop! Min loss:  0.8928804397583008 , Max accuracy:  0.74\n",
            "Early stop model validation loss:  0.8928804397583008 , accuracy:  0.736\n",
            "Optimization Finished!\n",
            "Total time elapsed: 31.6529s\n",
            "Loading 230th epoch\n",
            "Test set results: loss= 0.8658 accuracy= 0.7280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwDnzZCmU7sn",
        "outputId": "1b0302ee-ea3a-4d45-ce27-4e5342b14ee5"
      },
      "source": [
        "accs_dropedge = []\n",
        "for lam in range(1,11,2):\n",
        "  Train(lam=lam/10) #cora dropedge \n",
        "  accs_dropedge.append(test())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 0074 loss_train: 1.0303 acc_train: 0.8833 loss_val: 1.4744 acc_val: 0.6780 time: 0.0958s\n",
            "0\n",
            "Epoch: 0075 loss_train: 1.0277 acc_train: 0.8250 loss_val: 1.4633 acc_val: 0.6760 time: 0.0984s\n",
            "0\n",
            "Epoch: 0076 loss_train: 1.0023 acc_train: 0.8917 loss_val: 1.4530 acc_val: 0.6760 time: 0.0960s\n",
            "0\n",
            "Epoch: 0077 loss_train: 0.9658 acc_train: 0.8333 loss_val: 1.4424 acc_val: 0.6720 time: 0.0980s\n",
            "0\n",
            "Epoch: 0078 loss_train: 0.9462 acc_train: 0.8917 loss_val: 1.4329 acc_val: 0.6800 time: 0.0949s\n",
            "0\n",
            "Epoch: 0079 loss_train: 0.9490 acc_train: 0.8667 loss_val: 1.4255 acc_val: 0.6800 time: 0.0981s\n",
            "0\n",
            "Epoch: 0080 loss_train: 0.9439 acc_train: 0.8500 loss_val: 1.4189 acc_val: 0.6880 time: 0.1074s\n",
            "0\n",
            "Epoch: 0081 loss_train: 0.8959 acc_train: 0.8417 loss_val: 1.4103 acc_val: 0.6960 time: 0.1025s\n",
            "0\n",
            "Epoch: 0082 loss_train: 0.8880 acc_train: 0.8667 loss_val: 1.3994 acc_val: 0.6960 time: 0.0992s\n",
            "0\n",
            "Epoch: 0083 loss_train: 0.8802 acc_train: 0.8917 loss_val: 1.3883 acc_val: 0.6980 time: 0.1020s\n",
            "0\n",
            "Epoch: 0084 loss_train: 0.8336 acc_train: 0.8833 loss_val: 1.3765 acc_val: 0.7000 time: 0.0990s\n",
            "0\n",
            "Epoch: 0085 loss_train: 0.8284 acc_train: 0.8750 loss_val: 1.3635 acc_val: 0.6980 time: 0.0984s\n",
            "0\n",
            "Epoch: 0086 loss_train: 0.8580 acc_train: 0.7833 loss_val: 1.3504 acc_val: 0.7000 time: 0.0977s\n",
            "0\n",
            "Epoch: 0087 loss_train: 0.8057 acc_train: 0.8500 loss_val: 1.3384 acc_val: 0.7020 time: 0.0980s\n",
            "0\n",
            "Epoch: 0088 loss_train: 0.7944 acc_train: 0.9250 loss_val: 1.3293 acc_val: 0.7040 time: 0.1020s\n",
            "0\n",
            "Epoch: 0089 loss_train: 0.8205 acc_train: 0.8833 loss_val: 1.3236 acc_val: 0.7040 time: 0.1045s\n",
            "0\n",
            "Epoch: 0090 loss_train: 0.7638 acc_train: 0.8750 loss_val: 1.3194 acc_val: 0.7000 time: 0.1002s\n",
            "0\n",
            "Epoch: 0091 loss_train: 0.7661 acc_train: 0.8917 loss_val: 1.3152 acc_val: 0.7000 time: 0.0981s\n",
            "0\n",
            "Epoch: 0092 loss_train: 0.7225 acc_train: 0.8833 loss_val: 1.3099 acc_val: 0.7060 time: 0.1001s\n",
            "0\n",
            "Epoch: 0093 loss_train: 0.7405 acc_train: 0.8917 loss_val: 1.3020 acc_val: 0.7080 time: 0.0974s\n",
            "0\n",
            "Epoch: 0094 loss_train: 0.7391 acc_train: 0.8833 loss_val: 1.2943 acc_val: 0.7040 time: 0.0976s\n",
            "0\n",
            "Epoch: 0095 loss_train: 0.7109 acc_train: 0.9417 loss_val: 1.2835 acc_val: 0.7020 time: 0.0960s\n",
            "0\n",
            "Epoch: 0096 loss_train: 0.6992 acc_train: 0.9250 loss_val: 1.2744 acc_val: 0.7060 time: 0.0958s\n",
            "0\n",
            "Epoch: 0097 loss_train: 0.6780 acc_train: 0.9167 loss_val: 1.2658 acc_val: 0.7100 time: 0.0960s\n",
            "0\n",
            "Epoch: 0098 loss_train: 0.6765 acc_train: 0.9167 loss_val: 1.2569 acc_val: 0.7100 time: 0.0980s\n",
            "0\n",
            "Epoch: 0099 loss_train: 0.6441 acc_train: 0.9000 loss_val: 1.2490 acc_val: 0.7100 time: 0.1004s\n",
            "0\n",
            "Epoch: 0100 loss_train: 0.6594 acc_train: 0.9250 loss_val: 1.2428 acc_val: 0.7080 time: 0.0979s\n",
            "0\n",
            "Epoch: 0101 loss_train: 0.6376 acc_train: 0.9333 loss_val: 1.2385 acc_val: 0.7040 time: 0.0954s\n",
            "0\n",
            "Epoch: 0102 loss_train: 0.6446 acc_train: 0.8917 loss_val: 1.2333 acc_val: 0.7100 time: 0.0985s\n",
            "0\n",
            "Epoch: 0103 loss_train: 0.6498 acc_train: 0.9500 loss_val: 1.2244 acc_val: 0.7140 time: 0.0983s\n",
            "0\n",
            "Epoch: 0104 loss_train: 0.6254 acc_train: 0.9333 loss_val: 1.2152 acc_val: 0.7180 time: 0.0978s\n",
            "0\n",
            "Epoch: 0105 loss_train: 0.6263 acc_train: 0.9167 loss_val: 1.2061 acc_val: 0.7220 time: 0.0954s\n",
            "0\n",
            "Epoch: 0106 loss_train: 0.5976 acc_train: 0.9167 loss_val: 1.2002 acc_val: 0.7240 time: 0.0994s\n",
            "0\n",
            "Epoch: 0107 loss_train: 0.6150 acc_train: 0.9167 loss_val: 1.1956 acc_val: 0.7200 time: 0.0953s\n",
            "0\n",
            "Epoch: 0108 loss_train: 0.5583 acc_train: 0.9583 loss_val: 1.1928 acc_val: 0.7160 time: 0.0959s\n",
            "0\n",
            "Epoch: 0109 loss_train: 0.5881 acc_train: 0.9250 loss_val: 1.1900 acc_val: 0.7140 time: 0.1035s\n",
            "0\n",
            "Epoch: 0110 loss_train: 0.5926 acc_train: 0.9167 loss_val: 1.1873 acc_val: 0.7180 time: 0.0950s\n",
            "0\n",
            "Epoch: 0111 loss_train: 0.5889 acc_train: 0.9333 loss_val: 1.1810 acc_val: 0.7180 time: 0.0956s\n",
            "0\n",
            "Epoch: 0112 loss_train: 0.5646 acc_train: 0.9250 loss_val: 1.1742 acc_val: 0.7200 time: 0.0993s\n",
            "0\n",
            "Epoch: 0113 loss_train: 0.5828 acc_train: 0.9250 loss_val: 1.1674 acc_val: 0.7180 time: 0.0950s\n",
            "0\n",
            "Epoch: 0114 loss_train: 0.5406 acc_train: 0.8917 loss_val: 1.1614 acc_val: 0.7240 time: 0.0981s\n",
            "0\n",
            "Epoch: 0115 loss_train: 0.5351 acc_train: 0.9333 loss_val: 1.1553 acc_val: 0.7220 time: 0.0952s\n",
            "0\n",
            "Epoch: 0116 loss_train: 0.5234 acc_train: 0.9000 loss_val: 1.1502 acc_val: 0.7180 time: 0.1035s\n",
            "0\n",
            "Epoch: 0117 loss_train: 0.5228 acc_train: 0.9333 loss_val: 1.1456 acc_val: 0.7140 time: 0.0989s\n",
            "0\n",
            "Epoch: 0118 loss_train: 0.5317 acc_train: 0.9333 loss_val: 1.1402 acc_val: 0.7160 time: 0.1001s\n",
            "0\n",
            "Epoch: 0119 loss_train: 0.5489 acc_train: 0.9083 loss_val: 1.1342 acc_val: 0.7200 time: 0.1062s\n",
            "0\n",
            "Epoch: 0120 loss_train: 0.5234 acc_train: 0.9333 loss_val: 1.1304 acc_val: 0.7200 time: 0.0973s\n",
            "0\n",
            "Epoch: 0121 loss_train: 0.5255 acc_train: 0.9333 loss_val: 1.1283 acc_val: 0.7140 time: 0.1022s\n",
            "0\n",
            "Epoch: 0122 loss_train: 0.5122 acc_train: 0.9250 loss_val: 1.1246 acc_val: 0.7140 time: 0.0960s\n",
            "0\n",
            "Epoch: 0123 loss_train: 0.5019 acc_train: 0.9333 loss_val: 1.1233 acc_val: 0.7160 time: 0.0956s\n",
            "0\n",
            "Epoch: 0124 loss_train: 0.5042 acc_train: 0.9333 loss_val: 1.1213 acc_val: 0.7180 time: 0.0950s\n",
            "0\n",
            "Epoch: 0125 loss_train: 0.4857 acc_train: 0.9417 loss_val: 1.1170 acc_val: 0.7160 time: 0.0951s\n",
            "0\n",
            "Epoch: 0126 loss_train: 0.4898 acc_train: 0.9167 loss_val: 1.1093 acc_val: 0.7260 time: 0.0987s\n",
            "0\n",
            "Epoch: 0127 loss_train: 0.5031 acc_train: 0.9417 loss_val: 1.1027 acc_val: 0.7240 time: 0.0962s\n",
            "0\n",
            "Epoch: 0128 loss_train: 0.4725 acc_train: 0.9417 loss_val: 1.0979 acc_val: 0.7220 time: 0.0985s\n",
            "0\n",
            "Epoch: 0129 loss_train: 0.4935 acc_train: 0.9167 loss_val: 1.0963 acc_val: 0.7240 time: 0.0964s\n",
            "0\n",
            "Epoch: 0130 loss_train: 0.4568 acc_train: 0.9333 loss_val: 1.0962 acc_val: 0.7260 time: 0.0961s\n",
            "0\n",
            "Epoch: 0131 loss_train: 0.4602 acc_train: 0.8917 loss_val: 1.0963 acc_val: 0.7240 time: 0.0955s\n",
            "0\n",
            "Epoch: 0132 loss_train: 0.4853 acc_train: 0.9083 loss_val: 1.0920 acc_val: 0.7180 time: 0.1025s\n",
            "1\n",
            "Epoch: 0133 loss_train: 0.4541 acc_train: 0.9167 loss_val: 1.0876 acc_val: 0.7200 time: 0.0976s\n",
            "0\n",
            "Epoch: 0134 loss_train: 0.4435 acc_train: 0.9250 loss_val: 1.0830 acc_val: 0.7200 time: 0.0989s\n",
            "0\n",
            "Epoch: 0135 loss_train: 0.4643 acc_train: 0.9500 loss_val: 1.0811 acc_val: 0.7160 time: 0.0962s\n",
            "0\n",
            "Epoch: 0136 loss_train: 0.4710 acc_train: 0.9333 loss_val: 1.0788 acc_val: 0.7220 time: 0.0981s\n",
            "0\n",
            "Epoch: 0137 loss_train: 0.4432 acc_train: 0.9500 loss_val: 1.0768 acc_val: 0.7240 time: 0.0961s\n",
            "0\n",
            "Epoch: 0138 loss_train: 0.4710 acc_train: 0.9167 loss_val: 1.0752 acc_val: 0.7180 time: 0.0986s\n",
            "0\n",
            "Epoch: 0139 loss_train: 0.4541 acc_train: 0.9750 loss_val: 1.0702 acc_val: 0.7200 time: 0.0962s\n",
            "0\n",
            "Epoch: 0140 loss_train: 0.4410 acc_train: 0.9500 loss_val: 1.0657 acc_val: 0.7200 time: 0.0959s\n",
            "0\n",
            "Epoch: 0141 loss_train: 0.4574 acc_train: 0.9250 loss_val: 1.0637 acc_val: 0.7180 time: 0.0959s\n",
            "0\n",
            "Epoch: 0142 loss_train: 0.4273 acc_train: 0.9500 loss_val: 1.0625 acc_val: 0.7240 time: 0.0951s\n",
            "0\n",
            "Epoch: 0143 loss_train: 0.4117 acc_train: 0.9333 loss_val: 1.0625 acc_val: 0.7220 time: 0.0976s\n",
            "0\n",
            "Epoch: 0144 loss_train: 0.4176 acc_train: 0.9250 loss_val: 1.0638 acc_val: 0.7240 time: 0.0959s\n",
            "0\n",
            "Epoch: 0145 loss_train: 0.4145 acc_train: 0.9500 loss_val: 1.0625 acc_val: 0.7260 time: 0.0980s\n",
            "1\n",
            "Epoch: 0146 loss_train: 0.4199 acc_train: 0.9083 loss_val: 1.0566 acc_val: 0.7220 time: 0.0967s\n",
            "0\n",
            "Epoch: 0147 loss_train: 0.4127 acc_train: 0.9333 loss_val: 1.0515 acc_val: 0.7260 time: 0.0962s\n",
            "0\n",
            "Epoch: 0148 loss_train: 0.4134 acc_train: 0.9333 loss_val: 1.0454 acc_val: 0.7200 time: 0.1034s\n",
            "0\n",
            "Epoch: 0149 loss_train: 0.4075 acc_train: 0.9583 loss_val: 1.0434 acc_val: 0.7160 time: 0.0952s\n",
            "0\n",
            "Epoch: 0150 loss_train: 0.3881 acc_train: 0.9667 loss_val: 1.0415 acc_val: 0.7180 time: 0.0992s\n",
            "0\n",
            "Epoch: 0151 loss_train: 0.4284 acc_train: 0.9250 loss_val: 1.0400 acc_val: 0.7220 time: 0.0980s\n",
            "0\n",
            "Epoch: 0152 loss_train: 0.3871 acc_train: 0.9500 loss_val: 1.0390 acc_val: 0.7240 time: 0.0985s\n",
            "0\n",
            "Epoch: 0153 loss_train: 0.3930 acc_train: 0.9417 loss_val: 1.0387 acc_val: 0.7280 time: 0.0966s\n",
            "0\n",
            "Epoch: 0154 loss_train: 0.3961 acc_train: 0.9250 loss_val: 1.0385 acc_val: 0.7320 time: 0.0955s\n",
            "0\n",
            "Epoch: 0155 loss_train: 0.4079 acc_train: 0.9417 loss_val: 1.0358 acc_val: 0.7280 time: 0.1005s\n",
            "0\n",
            "Epoch: 0156 loss_train: 0.4010 acc_train: 0.9333 loss_val: 1.0348 acc_val: 0.7220 time: 0.0954s\n",
            "0\n",
            "Epoch: 0157 loss_train: 0.3765 acc_train: 0.9583 loss_val: 1.0354 acc_val: 0.7200 time: 0.0984s\n",
            "0\n",
            "Epoch: 0158 loss_train: 0.4102 acc_train: 0.9417 loss_val: 1.0371 acc_val: 0.7220 time: 0.1008s\n",
            "1\n",
            "Epoch: 0159 loss_train: 0.3747 acc_train: 0.9583 loss_val: 1.0355 acc_val: 0.7220 time: 0.0955s\n",
            "2\n",
            "Epoch: 0160 loss_train: 0.4025 acc_train: 0.9500 loss_val: 1.0289 acc_val: 0.7220 time: 0.1001s\n",
            "3\n",
            "Epoch: 0161 loss_train: 0.3745 acc_train: 0.9667 loss_val: 1.0230 acc_val: 0.7280 time: 0.0960s\n",
            "0\n",
            "Epoch: 0162 loss_train: 0.3661 acc_train: 0.9500 loss_val: 1.0202 acc_val: 0.7360 time: 0.0979s\n",
            "0\n",
            "Epoch: 0163 loss_train: 0.3852 acc_train: 0.9500 loss_val: 1.0180 acc_val: 0.7320 time: 0.0955s\n",
            "0\n",
            "Epoch: 0164 loss_train: 0.3755 acc_train: 0.9417 loss_val: 1.0182 acc_val: 0.7300 time: 0.0981s\n",
            "0\n",
            "Epoch: 0165 loss_train: 0.3801 acc_train: 0.9583 loss_val: 1.0206 acc_val: 0.7280 time: 0.0984s\n",
            "1\n",
            "Epoch: 0166 loss_train: 0.3869 acc_train: 0.9583 loss_val: 1.0223 acc_val: 0.7220 time: 0.0958s\n",
            "2\n",
            "Epoch: 0167 loss_train: 0.3877 acc_train: 0.9333 loss_val: 1.0236 acc_val: 0.7240 time: 0.0972s\n",
            "3\n",
            "Epoch: 0168 loss_train: 0.3775 acc_train: 0.9583 loss_val: 1.0217 acc_val: 0.7180 time: 0.1008s\n",
            "4\n",
            "Epoch: 0169 loss_train: 0.3875 acc_train: 0.9333 loss_val: 1.0191 acc_val: 0.7180 time: 0.0953s\n",
            "5\n",
            "Epoch: 0170 loss_train: 0.3636 acc_train: 0.9833 loss_val: 1.0143 acc_val: 0.7200 time: 0.0996s\n",
            "6\n",
            "Epoch: 0171 loss_train: 0.3658 acc_train: 0.8917 loss_val: 1.0122 acc_val: 0.7220 time: 0.0999s\n",
            "0\n",
            "Epoch: 0172 loss_train: 0.3655 acc_train: 0.9333 loss_val: 1.0074 acc_val: 0.7280 time: 0.0975s\n",
            "0\n",
            "Epoch: 0173 loss_train: 0.3471 acc_train: 0.9417 loss_val: 1.0027 acc_val: 0.7260 time: 0.0955s\n",
            "0\n",
            "Epoch: 0174 loss_train: 0.3505 acc_train: 0.9583 loss_val: 1.0025 acc_val: 0.7240 time: 0.0988s\n",
            "0\n",
            "Epoch: 0175 loss_train: 0.3438 acc_train: 0.9583 loss_val: 1.0058 acc_val: 0.7280 time: 0.0953s\n",
            "0\n",
            "Epoch: 0176 loss_train: 0.3556 acc_train: 0.9417 loss_val: 1.0096 acc_val: 0.7240 time: 0.0958s\n",
            "1\n",
            "Epoch: 0177 loss_train: 0.3587 acc_train: 0.9500 loss_val: 1.0110 acc_val: 0.7220 time: 0.0987s\n",
            "2\n",
            "Epoch: 0178 loss_train: 0.3635 acc_train: 0.9500 loss_val: 1.0103 acc_val: 0.7200 time: 0.1040s\n",
            "3\n",
            "Epoch: 0179 loss_train: 0.3690 acc_train: 0.9667 loss_val: 1.0083 acc_val: 0.7240 time: 0.0969s\n",
            "4\n",
            "Epoch: 0180 loss_train: 0.3577 acc_train: 0.9583 loss_val: 1.0033 acc_val: 0.7260 time: 0.0987s\n",
            "5\n",
            "Epoch: 0181 loss_train: 0.3605 acc_train: 0.9417 loss_val: 0.9984 acc_val: 0.7260 time: 0.0968s\n",
            "6\n",
            "Epoch: 0182 loss_train: 0.3312 acc_train: 0.9583 loss_val: 0.9947 acc_val: 0.7280 time: 0.0989s\n",
            "0\n",
            "Epoch: 0183 loss_train: 0.3541 acc_train: 0.9333 loss_val: 0.9906 acc_val: 0.7300 time: 0.0952s\n",
            "0\n",
            "Epoch: 0184 loss_train: 0.3633 acc_train: 0.9500 loss_val: 0.9906 acc_val: 0.7300 time: 0.0946s\n",
            "0\n",
            "Epoch: 0185 loss_train: 0.3489 acc_train: 0.9583 loss_val: 0.9944 acc_val: 0.7300 time: 0.1012s\n",
            "0\n",
            "Epoch: 0186 loss_train: 0.3224 acc_train: 0.9583 loss_val: 1.0007 acc_val: 0.7300 time: 0.0958s\n",
            "1\n",
            "Epoch: 0187 loss_train: 0.3351 acc_train: 0.9500 loss_val: 1.0048 acc_val: 0.7260 time: 0.0984s\n",
            "2\n",
            "Epoch: 0188 loss_train: 0.3336 acc_train: 0.9500 loss_val: 1.0052 acc_val: 0.7260 time: 0.1019s\n",
            "3\n",
            "Epoch: 0189 loss_train: 0.3405 acc_train: 0.9667 loss_val: 1.0003 acc_val: 0.7240 time: 0.0953s\n",
            "4\n",
            "Epoch: 0190 loss_train: 0.3337 acc_train: 0.9667 loss_val: 0.9925 acc_val: 0.7240 time: 0.1000s\n",
            "5\n",
            "Epoch: 0191 loss_train: 0.3236 acc_train: 0.9750 loss_val: 0.9838 acc_val: 0.7220 time: 0.0958s\n",
            "6\n",
            "Epoch: 0192 loss_train: 0.3742 acc_train: 0.9250 loss_val: 0.9782 acc_val: 0.7260 time: 0.1023s\n",
            "0\n",
            "Epoch: 0193 loss_train: 0.3377 acc_train: 0.9500 loss_val: 0.9763 acc_val: 0.7260 time: 0.0958s\n",
            "0\n",
            "Epoch: 0194 loss_train: 0.3390 acc_train: 0.9583 loss_val: 0.9807 acc_val: 0.7340 time: 0.0962s\n",
            "0\n",
            "Epoch: 0195 loss_train: 0.3277 acc_train: 0.9417 loss_val: 0.9857 acc_val: 0.7260 time: 0.0990s\n",
            "1\n",
            "Epoch: 0196 loss_train: 0.3242 acc_train: 0.9500 loss_val: 0.9916 acc_val: 0.7240 time: 0.0951s\n",
            "2\n",
            "Epoch: 0197 loss_train: 0.3453 acc_train: 0.9500 loss_val: 0.9964 acc_val: 0.7240 time: 0.0974s\n",
            "3\n",
            "Epoch: 0198 loss_train: 0.3354 acc_train: 0.9250 loss_val: 0.9972 acc_val: 0.7200 time: 0.1042s\n",
            "4\n",
            "Epoch: 0199 loss_train: 0.3400 acc_train: 0.9583 loss_val: 0.9935 acc_val: 0.7260 time: 0.0960s\n",
            "5\n",
            "Epoch: 0200 loss_train: 0.3312 acc_train: 0.9583 loss_val: 0.9880 acc_val: 0.7220 time: 0.0992s\n",
            "6\n",
            "Epoch: 0201 loss_train: 0.3378 acc_train: 0.9250 loss_val: 0.9839 acc_val: 0.7260 time: 0.0957s\n",
            "7\n",
            "Epoch: 0202 loss_train: 0.3359 acc_train: 0.9583 loss_val: 0.9806 acc_val: 0.7240 time: 0.0981s\n",
            "8\n",
            "Epoch: 0203 loss_train: 0.3248 acc_train: 0.9167 loss_val: 0.9791 acc_val: 0.7260 time: 0.0990s\n",
            "9\n",
            "Epoch: 0204 loss_train: 0.3464 acc_train: 0.9500 loss_val: 0.9781 acc_val: 0.7280 time: 0.0947s\n",
            "10\n",
            "Epoch: 0205 loss_train: 0.3183 acc_train: 0.9750 loss_val: 0.9788 acc_val: 0.7260 time: 0.0989s\n",
            "11\n",
            "Epoch: 0206 loss_train: 0.3198 acc_train: 0.9417 loss_val: 0.9800 acc_val: 0.7160 time: 0.0954s\n",
            "12\n",
            "Epoch: 0207 loss_train: 0.3091 acc_train: 0.9667 loss_val: 0.9816 acc_val: 0.7180 time: 0.0953s\n",
            "13\n",
            "Epoch: 0208 loss_train: 0.3218 acc_train: 0.9500 loss_val: 0.9803 acc_val: 0.7180 time: 0.1058s\n",
            "14\n",
            "Epoch: 0209 loss_train: 0.3199 acc_train: 0.9417 loss_val: 0.9797 acc_val: 0.7260 time: 0.0960s\n",
            "15\n",
            "Epoch: 0210 loss_train: 0.3321 acc_train: 0.9500 loss_val: 0.9802 acc_val: 0.7340 time: 0.0979s\n",
            "16\n",
            "Epoch: 0211 loss_train: 0.3335 acc_train: 0.9333 loss_val: 0.9803 acc_val: 0.7360 time: 0.1008s\n",
            "17\n",
            "Epoch: 0212 loss_train: 0.3111 acc_train: 0.9583 loss_val: 0.9809 acc_val: 0.7300 time: 0.0967s\n",
            "0\n",
            "Epoch: 0213 loss_train: 0.3229 acc_train: 0.9500 loss_val: 0.9811 acc_val: 0.7260 time: 0.0986s\n",
            "1\n",
            "Epoch: 0214 loss_train: 0.3067 acc_train: 0.9417 loss_val: 0.9823 acc_val: 0.7240 time: 0.0953s\n",
            "2\n",
            "Epoch: 0215 loss_train: 0.3250 acc_train: 0.9667 loss_val: 0.9793 acc_val: 0.7340 time: 0.0955s\n",
            "3\n",
            "Epoch: 0216 loss_train: 0.2949 acc_train: 0.9500 loss_val: 0.9748 acc_val: 0.7300 time: 0.1025s\n",
            "4\n",
            "Epoch: 0217 loss_train: 0.3184 acc_train: 0.9333 loss_val: 0.9710 acc_val: 0.7300 time: 0.0969s\n",
            "0\n",
            "Epoch: 0218 loss_train: 0.3020 acc_train: 0.9417 loss_val: 0.9707 acc_val: 0.7280 time: 0.1026s\n",
            "0\n",
            "Epoch: 0219 loss_train: 0.3290 acc_train: 0.9667 loss_val: 0.9734 acc_val: 0.7300 time: 0.0958s\n",
            "0\n",
            "Epoch: 0220 loss_train: 0.2949 acc_train: 0.9500 loss_val: 0.9754 acc_val: 0.7280 time: 0.0964s\n",
            "1\n",
            "Epoch: 0221 loss_train: 0.3079 acc_train: 0.9750 loss_val: 0.9755 acc_val: 0.7260 time: 0.0996s\n",
            "2\n",
            "Epoch: 0222 loss_train: 0.3107 acc_train: 0.9833 loss_val: 0.9757 acc_val: 0.7280 time: 0.0952s\n",
            "3\n",
            "Epoch: 0223 loss_train: 0.2935 acc_train: 0.9750 loss_val: 0.9714 acc_val: 0.7300 time: 0.0976s\n",
            "4\n",
            "Epoch: 0224 loss_train: 0.3165 acc_train: 0.9417 loss_val: 0.9642 acc_val: 0.7260 time: 0.1057s\n",
            "5\n",
            "Epoch: 0225 loss_train: 0.2876 acc_train: 0.9750 loss_val: 0.9602 acc_val: 0.7380 time: 0.0971s\n",
            "0\n",
            "Epoch: 0226 loss_train: 0.2994 acc_train: 0.9500 loss_val: 0.9570 acc_val: 0.7380 time: 0.0975s\n",
            "0\n",
            "Epoch: 0227 loss_train: 0.3132 acc_train: 0.9500 loss_val: 0.9571 acc_val: 0.7320 time: 0.0973s\n",
            "0\n",
            "Epoch: 0228 loss_train: 0.2890 acc_train: 0.9417 loss_val: 0.9593 acc_val: 0.7320 time: 0.0997s\n",
            "1\n",
            "Epoch: 0229 loss_train: 0.3034 acc_train: 0.9583 loss_val: 0.9647 acc_val: 0.7280 time: 0.0952s\n",
            "2\n",
            "Epoch: 0230 loss_train: 0.2934 acc_train: 0.9417 loss_val: 0.9712 acc_val: 0.7220 time: 0.0988s\n",
            "3\n",
            "Epoch: 0231 loss_train: 0.2977 acc_train: 0.9667 loss_val: 0.9736 acc_val: 0.7220 time: 0.0952s\n",
            "4\n",
            "Epoch: 0232 loss_train: 0.2981 acc_train: 0.9750 loss_val: 0.9692 acc_val: 0.7260 time: 0.0958s\n",
            "5\n",
            "Epoch: 0233 loss_train: 0.2946 acc_train: 0.9500 loss_val: 0.9632 acc_val: 0.7200 time: 0.0988s\n",
            "6\n",
            "Epoch: 0234 loss_train: 0.2984 acc_train: 0.9750 loss_val: 0.9546 acc_val: 0.7280 time: 0.0950s\n",
            "7\n",
            "Epoch: 0235 loss_train: 0.3089 acc_train: 0.9583 loss_val: 0.9514 acc_val: 0.7300 time: 0.0945s\n",
            "0\n",
            "Epoch: 0236 loss_train: 0.2981 acc_train: 0.9583 loss_val: 0.9536 acc_val: 0.7280 time: 0.0975s\n",
            "0\n",
            "Epoch: 0237 loss_train: 0.3122 acc_train: 0.9750 loss_val: 0.9582 acc_val: 0.7320 time: 0.0970s\n",
            "1\n",
            "Epoch: 0238 loss_train: 0.3184 acc_train: 0.9417 loss_val: 0.9652 acc_val: 0.7380 time: 0.0996s\n",
            "2\n",
            "Epoch: 0239 loss_train: 0.2897 acc_train: 0.9583 loss_val: 0.9689 acc_val: 0.7300 time: 0.0978s\n",
            "0\n",
            "Epoch: 0240 loss_train: 0.2919 acc_train: 0.9750 loss_val: 0.9702 acc_val: 0.7220 time: 0.1014s\n",
            "1\n",
            "Epoch: 0241 loss_train: 0.2866 acc_train: 0.9750 loss_val: 0.9680 acc_val: 0.7240 time: 0.0995s\n",
            "2\n",
            "Epoch: 0242 loss_train: 0.2896 acc_train: 0.9583 loss_val: 0.9623 acc_val: 0.7300 time: 0.0955s\n",
            "3\n",
            "Epoch: 0243 loss_train: 0.2893 acc_train: 0.9833 loss_val: 0.9537 acc_val: 0.7360 time: 0.0995s\n",
            "4\n",
            "Epoch: 0244 loss_train: 0.3016 acc_train: 0.9833 loss_val: 0.9475 acc_val: 0.7340 time: 0.0953s\n",
            "5\n",
            "Epoch: 0245 loss_train: 0.3085 acc_train: 0.9417 loss_val: 0.9480 acc_val: 0.7300 time: 0.0960s\n",
            "0\n",
            "Epoch: 0246 loss_train: 0.2892 acc_train: 0.9750 loss_val: 0.9516 acc_val: 0.7280 time: 0.0982s\n",
            "1\n",
            "Epoch: 0247 loss_train: 0.2948 acc_train: 0.9667 loss_val: 0.9547 acc_val: 0.7240 time: 0.0958s\n",
            "2\n",
            "Epoch: 0248 loss_train: 0.2660 acc_train: 0.9667 loss_val: 0.9578 acc_val: 0.7220 time: 0.1032s\n",
            "3\n",
            "Epoch: 0249 loss_train: 0.3088 acc_train: 0.9583 loss_val: 0.9592 acc_val: 0.7220 time: 0.0966s\n",
            "4\n",
            "Epoch: 0250 loss_train: 0.2972 acc_train: 0.9750 loss_val: 0.9579 acc_val: 0.7220 time: 0.0964s\n",
            "5\n",
            "Epoch: 0251 loss_train: 0.2728 acc_train: 0.9833 loss_val: 0.9576 acc_val: 0.7220 time: 0.0990s\n",
            "6\n",
            "Epoch: 0252 loss_train: 0.2751 acc_train: 0.9667 loss_val: 0.9549 acc_val: 0.7260 time: 0.0950s\n",
            "7\n",
            "Epoch: 0253 loss_train: 0.2807 acc_train: 0.9750 loss_val: 0.9516 acc_val: 0.7260 time: 0.0952s\n",
            "8\n",
            "Epoch: 0254 loss_train: 0.3057 acc_train: 0.9667 loss_val: 0.9486 acc_val: 0.7280 time: 0.1002s\n",
            "9\n",
            "Epoch: 0255 loss_train: 0.3111 acc_train: 0.9417 loss_val: 0.9468 acc_val: 0.7220 time: 0.0954s\n",
            "10\n",
            "Epoch: 0256 loss_train: 0.2854 acc_train: 0.9833 loss_val: 0.9472 acc_val: 0.7280 time: 0.0961s\n",
            "0\n",
            "Epoch: 0257 loss_train: 0.2830 acc_train: 0.9750 loss_val: 0.9506 acc_val: 0.7260 time: 0.1087s\n",
            "1\n",
            "Epoch: 0258 loss_train: 0.2847 acc_train: 0.9833 loss_val: 0.9527 acc_val: 0.7220 time: 0.1003s\n",
            "2\n",
            "Epoch: 0259 loss_train: 0.2874 acc_train: 0.9417 loss_val: 0.9542 acc_val: 0.7300 time: 0.0990s\n",
            "3\n",
            "Epoch: 0260 loss_train: 0.2768 acc_train: 0.9583 loss_val: 0.9533 acc_val: 0.7320 time: 0.0963s\n",
            "4\n",
            "Epoch: 0261 loss_train: 0.2758 acc_train: 0.9917 loss_val: 0.9515 acc_val: 0.7240 time: 0.0993s\n",
            "5\n",
            "Epoch: 0262 loss_train: 0.2894 acc_train: 0.9333 loss_val: 0.9573 acc_val: 0.7320 time: 0.0951s\n",
            "6\n",
            "Epoch: 0263 loss_train: 0.2896 acc_train: 0.9667 loss_val: 0.9610 acc_val: 0.7260 time: 0.0964s\n",
            "7\n",
            "Epoch: 0264 loss_train: 0.2771 acc_train: 0.9417 loss_val: 0.9608 acc_val: 0.7220 time: 0.0980s\n",
            "8\n",
            "Epoch: 0265 loss_train: 0.2944 acc_train: 0.9667 loss_val: 0.9561 acc_val: 0.7260 time: 0.0953s\n",
            "9\n",
            "Epoch: 0266 loss_train: 0.2865 acc_train: 0.9500 loss_val: 0.9495 acc_val: 0.7260 time: 0.0979s\n",
            "10\n",
            "Epoch: 0267 loss_train: 0.3032 acc_train: 0.9583 loss_val: 0.9478 acc_val: 0.7300 time: 0.1012s\n",
            "11\n",
            "Epoch: 0268 loss_train: 0.2920 acc_train: 0.9417 loss_val: 0.9496 acc_val: 0.7380 time: 0.0958s\n",
            "12\n",
            "Epoch: 0269 loss_train: 0.2672 acc_train: 0.9667 loss_val: 0.9511 acc_val: 0.7300 time: 0.0999s\n",
            "0\n",
            "Epoch: 0270 loss_train: 0.2660 acc_train: 0.9833 loss_val: 0.9503 acc_val: 0.7300 time: 0.1011s\n",
            "1\n",
            "Epoch: 0271 loss_train: 0.2732 acc_train: 0.9750 loss_val: 0.9472 acc_val: 0.7280 time: 0.0978s\n",
            "2\n",
            "Epoch: 0272 loss_train: 0.2823 acc_train: 0.9500 loss_val: 0.9468 acc_val: 0.7260 time: 0.0998s\n",
            "3\n",
            "Epoch: 0273 loss_train: 0.2701 acc_train: 0.9500 loss_val: 0.9463 acc_val: 0.7220 time: 0.0954s\n",
            "4\n",
            "Epoch: 0274 loss_train: 0.2838 acc_train: 0.9833 loss_val: 0.9492 acc_val: 0.7240 time: 0.0953s\n",
            "0\n",
            "Epoch: 0275 loss_train: 0.2794 acc_train: 0.9833 loss_val: 0.9516 acc_val: 0.7240 time: 0.0986s\n",
            "1\n",
            "Epoch: 0276 loss_train: 0.2813 acc_train: 0.9250 loss_val: 0.9499 acc_val: 0.7260 time: 0.0953s\n",
            "2\n",
            "Epoch: 0277 loss_train: 0.2875 acc_train: 0.9333 loss_val: 0.9486 acc_val: 0.7260 time: 0.0976s\n",
            "3\n",
            "Epoch: 0278 loss_train: 0.2605 acc_train: 0.9750 loss_val: 0.9508 acc_val: 0.7280 time: 0.0982s\n",
            "4\n",
            "Epoch: 0279 loss_train: 0.2808 acc_train: 0.9750 loss_val: 0.9574 acc_val: 0.7300 time: 0.1017s\n",
            "5\n",
            "Epoch: 0280 loss_train: 0.2545 acc_train: 0.9667 loss_val: 0.9585 acc_val: 0.7280 time: 0.0973s\n",
            "6\n",
            "Epoch: 0281 loss_train: 0.2733 acc_train: 0.9833 loss_val: 0.9571 acc_val: 0.7260 time: 0.1005s\n",
            "7\n",
            "Epoch: 0282 loss_train: 0.2803 acc_train: 0.9750 loss_val: 0.9518 acc_val: 0.7220 time: 0.0965s\n",
            "8\n",
            "Epoch: 0283 loss_train: 0.2706 acc_train: 0.9500 loss_val: 0.9445 acc_val: 0.7320 time: 0.1000s\n",
            "9\n",
            "Epoch: 0284 loss_train: 0.2688 acc_train: 0.9333 loss_val: 0.9376 acc_val: 0.7300 time: 0.0956s\n",
            "0\n",
            "Epoch: 0285 loss_train: 0.2742 acc_train: 0.9667 loss_val: 0.9336 acc_val: 0.7260 time: 0.0960s\n",
            "0\n",
            "Epoch: 0286 loss_train: 0.2881 acc_train: 0.9500 loss_val: 0.9336 acc_val: 0.7340 time: 0.0955s\n",
            "0\n",
            "Epoch: 0287 loss_train: 0.2809 acc_train: 0.9583 loss_val: 0.9396 acc_val: 0.7300 time: 0.0968s\n",
            "1\n",
            "Epoch: 0288 loss_train: 0.2654 acc_train: 0.9750 loss_val: 0.9490 acc_val: 0.7340 time: 0.0996s\n",
            "2\n",
            "Epoch: 0289 loss_train: 0.2495 acc_train: 0.9750 loss_val: 0.9554 acc_val: 0.7320 time: 0.1004s\n",
            "3\n",
            "Epoch: 0290 loss_train: 0.2582 acc_train: 0.9750 loss_val: 0.9533 acc_val: 0.7340 time: 0.0972s\n",
            "4\n",
            "Epoch: 0291 loss_train: 0.2804 acc_train: 0.9500 loss_val: 0.9462 acc_val: 0.7340 time: 0.0997s\n",
            "5\n",
            "Epoch: 0292 loss_train: 0.2571 acc_train: 0.9417 loss_val: 0.9364 acc_val: 0.7340 time: 0.0953s\n",
            "6\n",
            "Epoch: 0293 loss_train: 0.2725 acc_train: 0.9583 loss_val: 0.9303 acc_val: 0.7340 time: 0.1025s\n",
            "7\n",
            "Epoch: 0294 loss_train: 0.2717 acc_train: 0.9583 loss_val: 0.9245 acc_val: 0.7320 time: 0.0953s\n",
            "0\n",
            "Epoch: 0295 loss_train: 0.2513 acc_train: 0.9583 loss_val: 0.9257 acc_val: 0.7260 time: 0.0947s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.2556 acc_train: 0.9583 loss_val: 0.9321 acc_val: 0.7280 time: 0.0985s\n",
            "1\n",
            "Epoch: 0297 loss_train: 0.2731 acc_train: 0.9417 loss_val: 0.9388 acc_val: 0.7300 time: 0.0957s\n",
            "2\n",
            "Epoch: 0298 loss_train: 0.2579 acc_train: 0.9667 loss_val: 0.9446 acc_val: 0.7240 time: 0.0986s\n",
            "3\n",
            "Epoch: 0299 loss_train: 0.2787 acc_train: 0.9417 loss_val: 0.9464 acc_val: 0.7300 time: 0.0970s\n",
            "4\n",
            "Epoch: 0300 loss_train: 0.2533 acc_train: 0.9833 loss_val: 0.9419 acc_val: 0.7320 time: 0.0971s\n",
            "5\n",
            "Epoch: 0301 loss_train: 0.2716 acc_train: 0.9667 loss_val: 0.9369 acc_val: 0.7300 time: 0.0978s\n",
            "6\n",
            "Epoch: 0302 loss_train: 0.2739 acc_train: 0.9667 loss_val: 0.9352 acc_val: 0.7280 time: 0.0953s\n",
            "7\n",
            "Epoch: 0303 loss_train: 0.2470 acc_train: 0.9750 loss_val: 0.9356 acc_val: 0.7240 time: 0.0956s\n",
            "8\n",
            "Epoch: 0304 loss_train: 0.2652 acc_train: 0.9667 loss_val: 0.9378 acc_val: 0.7280 time: 0.0957s\n",
            "9\n",
            "Epoch: 0305 loss_train: 0.2664 acc_train: 0.9667 loss_val: 0.9411 acc_val: 0.7180 time: 0.1024s\n",
            "10\n",
            "Epoch: 0306 loss_train: 0.2604 acc_train: 0.9750 loss_val: 0.9429 acc_val: 0.7180 time: 0.1008s\n",
            "11\n",
            "Epoch: 0307 loss_train: 0.2397 acc_train: 0.9583 loss_val: 0.9417 acc_val: 0.7240 time: 0.0955s\n",
            "12\n",
            "Epoch: 0308 loss_train: 0.2628 acc_train: 0.9750 loss_val: 0.9419 acc_val: 0.7220 time: 0.0981s\n",
            "13\n",
            "Epoch: 0309 loss_train: 0.2596 acc_train: 0.9667 loss_val: 0.9428 acc_val: 0.7200 time: 0.1007s\n",
            "14\n",
            "Epoch: 0310 loss_train: 0.2833 acc_train: 0.9417 loss_val: 0.9440 acc_val: 0.7260 time: 0.0961s\n",
            "15\n",
            "Epoch: 0311 loss_train: 0.2662 acc_train: 0.9583 loss_val: 0.9392 acc_val: 0.7300 time: 0.1005s\n",
            "16\n",
            "Epoch: 0312 loss_train: 0.2584 acc_train: 0.9417 loss_val: 0.9380 acc_val: 0.7260 time: 0.0968s\n",
            "17\n",
            "Epoch: 0313 loss_train: 0.2616 acc_train: 0.9500 loss_val: 0.9376 acc_val: 0.7220 time: 0.0990s\n",
            "18\n",
            "Epoch: 0314 loss_train: 0.2914 acc_train: 0.9417 loss_val: 0.9400 acc_val: 0.7200 time: 0.0981s\n",
            "19\n",
            "Epoch: 0315 loss_train: 0.2595 acc_train: 0.9750 loss_val: 0.9416 acc_val: 0.7220 time: 0.0952s\n",
            "20\n",
            "Epoch: 0316 loss_train: 0.2722 acc_train: 0.9500 loss_val: 0.9449 acc_val: 0.7200 time: 0.1002s\n",
            "21\n",
            "Epoch: 0317 loss_train: 0.2589 acc_train: 0.9583 loss_val: 0.9428 acc_val: 0.7220 time: 0.1081s\n",
            "22\n",
            "Epoch: 0318 loss_train: 0.2620 acc_train: 0.9417 loss_val: 0.9368 acc_val: 0.7260 time: 0.0999s\n",
            "23\n",
            "Epoch: 0319 loss_train: 0.2738 acc_train: 0.9667 loss_val: 0.9348 acc_val: 0.7300 time: 0.1034s\n",
            "24\n",
            "Epoch: 0320 loss_train: 0.2555 acc_train: 0.9417 loss_val: 0.9339 acc_val: 0.7300 time: 0.1083s\n",
            "25\n",
            "Epoch: 0321 loss_train: 0.2597 acc_train: 0.9417 loss_val: 0.9359 acc_val: 0.7300 time: 0.1046s\n",
            "26\n",
            "Epoch: 0322 loss_train: 0.2566 acc_train: 0.9750 loss_val: 0.9349 acc_val: 0.7200 time: 0.1006s\n",
            "27\n",
            "Epoch: 0323 loss_train: 0.2651 acc_train: 0.9750 loss_val: 0.9333 acc_val: 0.7220 time: 0.0962s\n",
            "28\n",
            "Epoch: 0324 loss_train: 0.2481 acc_train: 0.9833 loss_val: 0.9333 acc_val: 0.7220 time: 0.0988s\n",
            "29\n",
            "Epoch: 0325 loss_train: 0.2620 acc_train: 0.9750 loss_val: 0.9311 acc_val: 0.7220 time: 0.1026s\n",
            "30\n",
            "Epoch: 0326 loss_train: 0.2571 acc_train: 0.9500 loss_val: 0.9328 acc_val: 0.7200 time: 0.0975s\n",
            "31\n",
            "Epoch: 0327 loss_train: 0.2718 acc_train: 0.9583 loss_val: 0.9317 acc_val: 0.7260 time: 0.1039s\n",
            "32\n",
            "Epoch: 0328 loss_train: 0.2519 acc_train: 0.9833 loss_val: 0.9308 acc_val: 0.7300 time: 0.0959s\n",
            "33\n",
            "Epoch: 0329 loss_train: 0.2562 acc_train: 0.9583 loss_val: 0.9290 acc_val: 0.7340 time: 0.1122s\n",
            "34\n",
            "Epoch: 0330 loss_train: 0.2493 acc_train: 0.9667 loss_val: 0.9286 acc_val: 0.7300 time: 0.0971s\n",
            "35\n",
            "Epoch: 0331 loss_train: 0.2565 acc_train: 0.9667 loss_val: 0.9310 acc_val: 0.7300 time: 0.1017s\n",
            "36\n",
            "Epoch: 0332 loss_train: 0.2424 acc_train: 0.9750 loss_val: 0.9333 acc_val: 0.7320 time: 0.0993s\n",
            "37\n",
            "Epoch: 0333 loss_train: 0.2625 acc_train: 0.9750 loss_val: 0.9353 acc_val: 0.7200 time: 0.0953s\n",
            "38\n",
            "Epoch: 0334 loss_train: 0.2725 acc_train: 0.9583 loss_val: 0.9367 acc_val: 0.7220 time: 0.0999s\n",
            "39\n",
            "Epoch: 0335 loss_train: 0.2562 acc_train: 0.9417 loss_val: 0.9325 acc_val: 0.7220 time: 0.0953s\n",
            "40\n",
            "Epoch: 0336 loss_train: 0.2546 acc_train: 0.9750 loss_val: 0.9285 acc_val: 0.7280 time: 0.0948s\n",
            "41\n",
            "Epoch: 0337 loss_train: 0.2514 acc_train: 0.9333 loss_val: 0.9263 acc_val: 0.7280 time: 0.0990s\n",
            "42\n",
            "Epoch: 0338 loss_train: 0.2679 acc_train: 0.9583 loss_val: 0.9256 acc_val: 0.7260 time: 0.1036s\n",
            "43\n",
            "Epoch: 0339 loss_train: 0.2739 acc_train: 0.9750 loss_val: 0.9282 acc_val: 0.7280 time: 0.1000s\n",
            "44\n",
            "Epoch: 0340 loss_train: 0.2735 acc_train: 0.9417 loss_val: 0.9306 acc_val: 0.7220 time: 0.1007s\n",
            "45\n",
            "Epoch: 0341 loss_train: 0.2568 acc_train: 0.9500 loss_val: 0.9322 acc_val: 0.7240 time: 0.0962s\n",
            "46\n",
            "Epoch: 0342 loss_train: 0.2516 acc_train: 0.9667 loss_val: 0.9339 acc_val: 0.7200 time: 0.1002s\n",
            "47\n",
            "Epoch: 0343 loss_train: 0.2671 acc_train: 0.9583 loss_val: 0.9329 acc_val: 0.7240 time: 0.1002s\n",
            "48\n",
            "Epoch: 0344 loss_train: 0.2653 acc_train: 0.9583 loss_val: 0.9332 acc_val: 0.7260 time: 0.1002s\n",
            "49\n",
            "Epoch: 0345 loss_train: 0.2567 acc_train: 0.9833 loss_val: 0.9330 acc_val: 0.7260 time: 0.0977s\n",
            "50\n",
            "Epoch: 0346 loss_train: 0.2448 acc_train: 0.9833 loss_val: 0.9341 acc_val: 0.7280 time: 0.0958s\n",
            "51\n",
            "Epoch: 0347 loss_train: 0.2810 acc_train: 0.9500 loss_val: 0.9303 acc_val: 0.7340 time: 0.1001s\n",
            "52\n",
            "Epoch: 0348 loss_train: 0.2461 acc_train: 0.9667 loss_val: 0.9274 acc_val: 0.7340 time: 0.0964s\n",
            "53\n",
            "Epoch: 0349 loss_train: 0.2453 acc_train: 0.9667 loss_val: 0.9267 acc_val: 0.7360 time: 0.1031s\n",
            "54\n",
            "Epoch: 0350 loss_train: 0.2423 acc_train: 0.9750 loss_val: 0.9251 acc_val: 0.7260 time: 0.0994s\n",
            "55\n",
            "Epoch: 0351 loss_train: 0.2425 acc_train: 0.9667 loss_val: 0.9281 acc_val: 0.7260 time: 0.0955s\n",
            "56\n",
            "Epoch: 0352 loss_train: 0.2532 acc_train: 0.9750 loss_val: 0.9287 acc_val: 0.7260 time: 0.1001s\n",
            "57\n",
            "Epoch: 0353 loss_train: 0.2415 acc_train: 0.9750 loss_val: 0.9290 acc_val: 0.7220 time: 0.0956s\n",
            "58\n",
            "Epoch: 0354 loss_train: 0.2546 acc_train: 0.9333 loss_val: 0.9273 acc_val: 0.7260 time: 0.0952s\n",
            "59\n",
            "Epoch: 0355 loss_train: 0.2383 acc_train: 0.9750 loss_val: 0.9269 acc_val: 0.7260 time: 0.0987s\n",
            "60\n",
            "Epoch: 0356 loss_train: 0.2488 acc_train: 0.9750 loss_val: 0.9274 acc_val: 0.7260 time: 0.0959s\n",
            "61\n",
            "Epoch: 0357 loss_train: 0.2480 acc_train: 0.9833 loss_val: 0.9280 acc_val: 0.7280 time: 0.0972s\n",
            "62\n",
            "Epoch: 0358 loss_train: 0.2606 acc_train: 0.9583 loss_val: 0.9261 acc_val: 0.7220 time: 0.1035s\n",
            "63\n",
            "Epoch: 0359 loss_train: 0.2551 acc_train: 0.9750 loss_val: 0.9247 acc_val: 0.7180 time: 0.0985s\n",
            "64\n",
            "Epoch: 0360 loss_train: 0.2568 acc_train: 0.9500 loss_val: 0.9262 acc_val: 0.7240 time: 0.0978s\n",
            "65\n",
            "Epoch: 0361 loss_train: 0.2492 acc_train: 0.9750 loss_val: 0.9277 acc_val: 0.7280 time: 0.1036s\n",
            "66\n",
            "Epoch: 0362 loss_train: 0.2568 acc_train: 0.9667 loss_val: 0.9299 acc_val: 0.7200 time: 0.1047s\n",
            "67\n",
            "Epoch: 0363 loss_train: 0.2525 acc_train: 0.9583 loss_val: 0.9324 acc_val: 0.7180 time: 0.1046s\n",
            "68\n",
            "Epoch: 0364 loss_train: 0.2538 acc_train: 0.9833 loss_val: 0.9313 acc_val: 0.7220 time: 0.1056s\n",
            "69\n",
            "Epoch: 0365 loss_train: 0.2505 acc_train: 0.9500 loss_val: 0.9295 acc_val: 0.7240 time: 0.1027s\n",
            "70\n",
            "Epoch: 0366 loss_train: 0.2391 acc_train: 0.9750 loss_val: 0.9244 acc_val: 0.7240 time: 0.0982s\n",
            "71\n",
            "Epoch: 0367 loss_train: 0.2313 acc_train: 0.9750 loss_val: 0.9195 acc_val: 0.7240 time: 0.0953s\n",
            "0\n",
            "Epoch: 0368 loss_train: 0.2473 acc_train: 0.9583 loss_val: 0.9191 acc_val: 0.7280 time: 0.0960s\n",
            "0\n",
            "Epoch: 0369 loss_train: 0.2467 acc_train: 0.9750 loss_val: 0.9216 acc_val: 0.7220 time: 0.1024s\n",
            "0\n",
            "Epoch: 0370 loss_train: 0.2575 acc_train: 0.9750 loss_val: 0.9257 acc_val: 0.7200 time: 0.0956s\n",
            "1\n",
            "Epoch: 0371 loss_train: 0.2471 acc_train: 0.9583 loss_val: 0.9309 acc_val: 0.7240 time: 0.0954s\n",
            "2\n",
            "Epoch: 0372 loss_train: 0.2360 acc_train: 0.9833 loss_val: 0.9291 acc_val: 0.7280 time: 0.0978s\n",
            "3\n",
            "Epoch: 0373 loss_train: 0.2395 acc_train: 0.9750 loss_val: 0.9253 acc_val: 0.7240 time: 0.0962s\n",
            "4\n",
            "Epoch: 0374 loss_train: 0.2370 acc_train: 0.9500 loss_val: 0.9224 acc_val: 0.7180 time: 0.0951s\n",
            "5\n",
            "Epoch: 0375 loss_train: 0.2462 acc_train: 0.9583 loss_val: 0.9185 acc_val: 0.7200 time: 0.0981s\n",
            "6\n",
            "Epoch: 0376 loss_train: 0.2625 acc_train: 0.9667 loss_val: 0.9185 acc_val: 0.7200 time: 0.0962s\n",
            "0\n",
            "Epoch: 0377 loss_train: 0.2512 acc_train: 0.9583 loss_val: 0.9211 acc_val: 0.7200 time: 0.0982s\n",
            "1\n",
            "Epoch: 0378 loss_train: 0.2269 acc_train: 0.9917 loss_val: 0.9211 acc_val: 0.7200 time: 0.0995s\n",
            "2\n",
            "Epoch: 0379 loss_train: 0.2526 acc_train: 0.9583 loss_val: 0.9243 acc_val: 0.7300 time: 0.1075s\n",
            "3\n",
            "Epoch: 0380 loss_train: 0.2510 acc_train: 0.9583 loss_val: 0.9318 acc_val: 0.7260 time: 0.1057s\n",
            "4\n",
            "Epoch: 0381 loss_train: 0.2435 acc_train: 0.9583 loss_val: 0.9400 acc_val: 0.7240 time: 0.1037s\n",
            "5\n",
            "Epoch: 0382 loss_train: 0.2441 acc_train: 0.9583 loss_val: 0.9397 acc_val: 0.7240 time: 0.1046s\n",
            "6\n",
            "Epoch: 0383 loss_train: 0.2304 acc_train: 0.9750 loss_val: 0.9290 acc_val: 0.7200 time: 0.1017s\n",
            "7\n",
            "Epoch: 0384 loss_train: 0.2308 acc_train: 0.9750 loss_val: 0.9187 acc_val: 0.7240 time: 0.1079s\n",
            "8\n",
            "Epoch: 0385 loss_train: 0.2473 acc_train: 0.9417 loss_val: 0.9154 acc_val: 0.7280 time: 0.1000s\n",
            "9\n",
            "Epoch: 0386 loss_train: 0.2481 acc_train: 0.9667 loss_val: 0.9172 acc_val: 0.7240 time: 0.1010s\n",
            "0\n",
            "Epoch: 0387 loss_train: 0.2312 acc_train: 0.9750 loss_val: 0.9223 acc_val: 0.7240 time: 0.0994s\n",
            "1\n",
            "Epoch: 0388 loss_train: 0.2477 acc_train: 0.9667 loss_val: 0.9293 acc_val: 0.7300 time: 0.1058s\n",
            "2\n",
            "Epoch: 0389 loss_train: 0.2452 acc_train: 0.9417 loss_val: 0.9380 acc_val: 0.7280 time: 0.1063s\n",
            "3\n",
            "Epoch: 0390 loss_train: 0.2548 acc_train: 0.9667 loss_val: 0.9378 acc_val: 0.7260 time: 0.0984s\n",
            "4\n",
            "Epoch: 0391 loss_train: 0.2661 acc_train: 0.9500 loss_val: 0.9329 acc_val: 0.7160 time: 0.0988s\n",
            "5\n",
            "Epoch: 0392 loss_train: 0.2479 acc_train: 0.9500 loss_val: 0.9266 acc_val: 0.7220 time: 0.1019s\n",
            "6\n",
            "Epoch: 0393 loss_train: 0.2343 acc_train: 0.9750 loss_val: 0.9216 acc_val: 0.7260 time: 0.0978s\n",
            "7\n",
            "Epoch: 0394 loss_train: 0.2566 acc_train: 0.9500 loss_val: 0.9212 acc_val: 0.7260 time: 0.1041s\n",
            "8\n",
            "Epoch: 0395 loss_train: 0.2461 acc_train: 0.9750 loss_val: 0.9263 acc_val: 0.7220 time: 0.0982s\n",
            "9\n",
            "Epoch: 0396 loss_train: 0.2630 acc_train: 0.9583 loss_val: 0.9299 acc_val: 0.7280 time: 0.0988s\n",
            "10\n",
            "Epoch: 0397 loss_train: 0.2426 acc_train: 0.9833 loss_val: 0.9358 acc_val: 0.7300 time: 0.1018s\n",
            "11\n",
            "Epoch: 0398 loss_train: 0.2620 acc_train: 0.9417 loss_val: 0.9384 acc_val: 0.7300 time: 0.1035s\n",
            "12\n",
            "Epoch: 0399 loss_train: 0.2349 acc_train: 0.9667 loss_val: 0.9356 acc_val: 0.7220 time: 0.1030s\n",
            "13\n",
            "Epoch: 0400 loss_train: 0.2303 acc_train: 0.9500 loss_val: 0.9314 acc_val: 0.7260 time: 0.0956s\n",
            "14\n",
            "Epoch: 0401 loss_train: 0.2424 acc_train: 0.9667 loss_val: 0.9277 acc_val: 0.7240 time: 0.0984s\n",
            "15\n",
            "Epoch: 0402 loss_train: 0.2466 acc_train: 0.9583 loss_val: 0.9239 acc_val: 0.7240 time: 0.0977s\n",
            "16\n",
            "Epoch: 0403 loss_train: 0.2335 acc_train: 0.9833 loss_val: 0.9192 acc_val: 0.7280 time: 0.0961s\n",
            "17\n",
            "Epoch: 0404 loss_train: 0.2367 acc_train: 0.9583 loss_val: 0.9127 acc_val: 0.7280 time: 0.0988s\n",
            "18\n",
            "Epoch: 0405 loss_train: 0.2290 acc_train: 0.9667 loss_val: 0.9123 acc_val: 0.7240 time: 0.0982s\n",
            "0\n",
            "Epoch: 0406 loss_train: 0.2193 acc_train: 0.9750 loss_val: 0.9152 acc_val: 0.7160 time: 0.0957s\n",
            "0\n",
            "Epoch: 0407 loss_train: 0.2345 acc_train: 0.9667 loss_val: 0.9211 acc_val: 0.7160 time: 0.0992s\n",
            "1\n",
            "Epoch: 0408 loss_train: 0.2460 acc_train: 0.9583 loss_val: 0.9270 acc_val: 0.7140 time: 0.0990s\n",
            "2\n",
            "Epoch: 0409 loss_train: 0.2447 acc_train: 0.9583 loss_val: 0.9317 acc_val: 0.7160 time: 0.1024s\n",
            "3\n",
            "Epoch: 0410 loss_train: 0.2316 acc_train: 0.9667 loss_val: 0.9313 acc_val: 0.7160 time: 0.0997s\n",
            "4\n",
            "Epoch: 0411 loss_train: 0.2282 acc_train: 0.9750 loss_val: 0.9270 acc_val: 0.7140 time: 0.0975s\n",
            "5\n",
            "Epoch: 0412 loss_train: 0.2376 acc_train: 0.9917 loss_val: 0.9207 acc_val: 0.7200 time: 0.1007s\n",
            "6\n",
            "Epoch: 0413 loss_train: 0.2361 acc_train: 0.9750 loss_val: 0.9177 acc_val: 0.7180 time: 0.0954s\n",
            "7\n",
            "Epoch: 0414 loss_train: 0.2526 acc_train: 0.9583 loss_val: 0.9149 acc_val: 0.7220 time: 0.0976s\n",
            "8\n",
            "Epoch: 0415 loss_train: 0.2434 acc_train: 0.9500 loss_val: 0.9135 acc_val: 0.7220 time: 0.0983s\n",
            "9\n",
            "Epoch: 0416 loss_train: 0.2344 acc_train: 0.9917 loss_val: 0.9167 acc_val: 0.7200 time: 0.0956s\n",
            "10\n",
            "Epoch: 0417 loss_train: 0.2515 acc_train: 0.9667 loss_val: 0.9183 acc_val: 0.7180 time: 0.0988s\n",
            "11\n",
            "Epoch: 0418 loss_train: 0.2590 acc_train: 0.9667 loss_val: 0.9207 acc_val: 0.7180 time: 0.1012s\n",
            "12\n",
            "Epoch: 0419 loss_train: 0.2371 acc_train: 0.9417 loss_val: 0.9237 acc_val: 0.7200 time: 0.0990s\n",
            "13\n",
            "Epoch: 0420 loss_train: 0.2260 acc_train: 0.9750 loss_val: 0.9222 acc_val: 0.7240 time: 0.0972s\n",
            "14\n",
            "Epoch: 0421 loss_train: 0.2373 acc_train: 0.9500 loss_val: 0.9138 acc_val: 0.7280 time: 0.0982s\n",
            "15\n",
            "Epoch: 0422 loss_train: 0.2579 acc_train: 0.9500 loss_val: 0.9107 acc_val: 0.7340 time: 0.0991s\n",
            "16\n",
            "Epoch: 0423 loss_train: 0.2434 acc_train: 0.9583 loss_val: 0.9096 acc_val: 0.7320 time: 0.0986s\n",
            "0\n",
            "Epoch: 0424 loss_train: 0.2511 acc_train: 0.9667 loss_val: 0.9093 acc_val: 0.7280 time: 0.1033s\n",
            "0\n",
            "Epoch: 0425 loss_train: 0.2496 acc_train: 0.9583 loss_val: 0.9178 acc_val: 0.7260 time: 0.0960s\n",
            "0\n",
            "Epoch: 0426 loss_train: 0.2302 acc_train: 0.9583 loss_val: 0.9283 acc_val: 0.7180 time: 0.0961s\n",
            "1\n",
            "Epoch: 0427 loss_train: 0.2260 acc_train: 0.9833 loss_val: 0.9347 acc_val: 0.7200 time: 0.0991s\n",
            "2\n",
            "Epoch: 0428 loss_train: 0.2450 acc_train: 0.9500 loss_val: 0.9328 acc_val: 0.7180 time: 0.1005s\n",
            "3\n",
            "Epoch: 0429 loss_train: 0.2522 acc_train: 0.9583 loss_val: 0.9248 acc_val: 0.7220 time: 0.0989s\n",
            "4\n",
            "Epoch: 0430 loss_train: 0.2454 acc_train: 0.9500 loss_val: 0.9173 acc_val: 0.7300 time: 0.0953s\n",
            "5\n",
            "Epoch: 0431 loss_train: 0.2248 acc_train: 0.9833 loss_val: 0.9146 acc_val: 0.7340 time: 0.0950s\n",
            "6\n",
            "Epoch: 0432 loss_train: 0.2226 acc_train: 0.9917 loss_val: 0.9121 acc_val: 0.7300 time: 0.0988s\n",
            "7\n",
            "Epoch: 0433 loss_train: 0.2498 acc_train: 0.9667 loss_val: 0.9158 acc_val: 0.7220 time: 0.1024s\n",
            "8\n",
            "Epoch: 0434 loss_train: 0.2363 acc_train: 0.9750 loss_val: 0.9247 acc_val: 0.7200 time: 0.0968s\n",
            "9\n",
            "Epoch: 0435 loss_train: 0.2347 acc_train: 0.9583 loss_val: 0.9314 acc_val: 0.7140 time: 0.1065s\n",
            "10\n",
            "Epoch: 0436 loss_train: 0.2309 acc_train: 0.9417 loss_val: 0.9374 acc_val: 0.7120 time: 0.0986s\n",
            "11\n",
            "Epoch: 0437 loss_train: 0.2347 acc_train: 0.9750 loss_val: 0.9333 acc_val: 0.7240 time: 0.0994s\n",
            "12\n",
            "Epoch: 0438 loss_train: 0.2323 acc_train: 0.9667 loss_val: 0.9217 acc_val: 0.7280 time: 0.0978s\n",
            "13\n",
            "Epoch: 0439 loss_train: 0.2225 acc_train: 0.9500 loss_val: 0.9122 acc_val: 0.7280 time: 0.0957s\n",
            "14\n",
            "Epoch: 0440 loss_train: 0.2345 acc_train: 0.9750 loss_val: 0.9121 acc_val: 0.7280 time: 0.0983s\n",
            "15\n",
            "Epoch: 0441 loss_train: 0.2393 acc_train: 0.9667 loss_val: 0.9175 acc_val: 0.7360 time: 0.1064s\n",
            "16\n",
            "Epoch: 0442 loss_train: 0.2362 acc_train: 0.9667 loss_val: 0.9297 acc_val: 0.7240 time: 0.1027s\n",
            "17\n",
            "Epoch: 0443 loss_train: 0.2386 acc_train: 0.9667 loss_val: 0.9370 acc_val: 0.7160 time: 0.0959s\n",
            "18\n",
            "Epoch: 0444 loss_train: 0.2477 acc_train: 0.9750 loss_val: 0.9373 acc_val: 0.7100 time: 0.0998s\n",
            "19\n",
            "Epoch: 0445 loss_train: 0.2263 acc_train: 0.9833 loss_val: 0.9326 acc_val: 0.7140 time: 0.0966s\n",
            "20\n",
            "Epoch: 0446 loss_train: 0.2425 acc_train: 0.9500 loss_val: 0.9248 acc_val: 0.7220 time: 0.0960s\n",
            "21\n",
            "Epoch: 0447 loss_train: 0.2245 acc_train: 0.9500 loss_val: 0.9206 acc_val: 0.7260 time: 0.1007s\n",
            "22\n",
            "Epoch: 0448 loss_train: 0.2278 acc_train: 0.9667 loss_val: 0.9162 acc_val: 0.7200 time: 0.1004s\n",
            "23\n",
            "Epoch: 0449 loss_train: 0.2373 acc_train: 0.9583 loss_val: 0.9143 acc_val: 0.7220 time: 0.0963s\n",
            "24\n",
            "Epoch: 0450 loss_train: 0.2261 acc_train: 0.9833 loss_val: 0.9208 acc_val: 0.7320 time: 0.1014s\n",
            "25\n",
            "Epoch: 0451 loss_train: 0.2440 acc_train: 0.9667 loss_val: 0.9309 acc_val: 0.7240 time: 0.0951s\n",
            "26\n",
            "Epoch: 0452 loss_train: 0.2314 acc_train: 0.9833 loss_val: 0.9363 acc_val: 0.7200 time: 0.0981s\n",
            "27\n",
            "Epoch: 0453 loss_train: 0.2312 acc_train: 0.9750 loss_val: 0.9332 acc_val: 0.7180 time: 0.0983s\n",
            "28\n",
            "Epoch: 0454 loss_train: 0.2483 acc_train: 0.9667 loss_val: 0.9274 acc_val: 0.7140 time: 0.0963s\n",
            "29\n",
            "Epoch: 0455 loss_train: 0.2335 acc_train: 0.9667 loss_val: 0.9207 acc_val: 0.7240 time: 0.0999s\n",
            "30\n",
            "Epoch: 0456 loss_train: 0.2468 acc_train: 0.9500 loss_val: 0.9180 acc_val: 0.7240 time: 0.0962s\n",
            "31\n",
            "Epoch: 0457 loss_train: 0.2318 acc_train: 0.9833 loss_val: 0.9162 acc_val: 0.7200 time: 0.0990s\n",
            "32\n",
            "Epoch: 0458 loss_train: 0.2281 acc_train: 0.9667 loss_val: 0.9173 acc_val: 0.7340 time: 0.1011s\n",
            "33\n",
            "Epoch: 0459 loss_train: 0.2271 acc_train: 0.9667 loss_val: 0.9207 acc_val: 0.7280 time: 0.0981s\n",
            "34\n",
            "Epoch: 0460 loss_train: 0.2496 acc_train: 0.9583 loss_val: 0.9251 acc_val: 0.7260 time: 0.1007s\n",
            "35\n",
            "Epoch: 0461 loss_train: 0.2371 acc_train: 0.9750 loss_val: 0.9256 acc_val: 0.7240 time: 0.0952s\n",
            "36\n",
            "Epoch: 0462 loss_train: 0.2219 acc_train: 0.9750 loss_val: 0.9247 acc_val: 0.7140 time: 0.1027s\n",
            "37\n",
            "Epoch: 0463 loss_train: 0.2483 acc_train: 0.9667 loss_val: 0.9261 acc_val: 0.7160 time: 0.0963s\n",
            "38\n",
            "Epoch: 0464 loss_train: 0.2311 acc_train: 0.9583 loss_val: 0.9237 acc_val: 0.7200 time: 0.0968s\n",
            "39\n",
            "Epoch: 0465 loss_train: 0.2331 acc_train: 0.9583 loss_val: 0.9219 acc_val: 0.7180 time: 0.1022s\n",
            "40\n",
            "Epoch: 0466 loss_train: 0.2285 acc_train: 0.9917 loss_val: 0.9198 acc_val: 0.7320 time: 0.0958s\n",
            "41\n",
            "Epoch: 0467 loss_train: 0.2405 acc_train: 0.9833 loss_val: 0.9165 acc_val: 0.7340 time: 0.0960s\n",
            "42\n",
            "Epoch: 0468 loss_train: 0.2275 acc_train: 0.9583 loss_val: 0.9140 acc_val: 0.7320 time: 0.1035s\n",
            "43\n",
            "Epoch: 0469 loss_train: 0.2372 acc_train: 0.9667 loss_val: 0.9141 acc_val: 0.7300 time: 0.0971s\n",
            "44\n",
            "Epoch: 0470 loss_train: 0.2321 acc_train: 0.9667 loss_val: 0.9166 acc_val: 0.7180 time: 0.0968s\n",
            "45\n",
            "Epoch: 0471 loss_train: 0.2297 acc_train: 0.9667 loss_val: 0.9259 acc_val: 0.7180 time: 0.1055s\n",
            "46\n",
            "Epoch: 0472 loss_train: 0.2075 acc_train: 0.9833 loss_val: 0.9338 acc_val: 0.7240 time: 0.0966s\n",
            "47\n",
            "Epoch: 0473 loss_train: 0.2305 acc_train: 0.9417 loss_val: 0.9340 acc_val: 0.7280 time: 0.0990s\n",
            "48\n",
            "Epoch: 0474 loss_train: 0.2291 acc_train: 0.9583 loss_val: 0.9287 acc_val: 0.7300 time: 0.0973s\n",
            "49\n",
            "Epoch: 0475 loss_train: 0.2189 acc_train: 0.9750 loss_val: 0.9211 acc_val: 0.7300 time: 0.0968s\n",
            "50\n",
            "Epoch: 0476 loss_train: 0.2416 acc_train: 0.9750 loss_val: 0.9163 acc_val: 0.7260 time: 0.0985s\n",
            "51\n",
            "Epoch: 0477 loss_train: 0.2325 acc_train: 0.9583 loss_val: 0.9126 acc_val: 0.7260 time: 0.0997s\n",
            "52\n",
            "Epoch: 0478 loss_train: 0.2123 acc_train: 0.9750 loss_val: 0.9134 acc_val: 0.7320 time: 0.1072s\n",
            "53\n",
            "Epoch: 0479 loss_train: 0.2365 acc_train: 0.9500 loss_val: 0.9204 acc_val: 0.7260 time: 0.0961s\n",
            "54\n",
            "Epoch: 0480 loss_train: 0.2384 acc_train: 0.9667 loss_val: 0.9299 acc_val: 0.7240 time: 0.0965s\n",
            "55\n",
            "Epoch: 0481 loss_train: 0.2302 acc_train: 0.9583 loss_val: 0.9332 acc_val: 0.7240 time: 0.0995s\n",
            "56\n",
            "Epoch: 0482 loss_train: 0.2211 acc_train: 0.9750 loss_val: 0.9301 acc_val: 0.7320 time: 0.0953s\n",
            "57\n",
            "Epoch: 0483 loss_train: 0.2325 acc_train: 0.9750 loss_val: 0.9216 acc_val: 0.7260 time: 0.0953s\n",
            "58\n",
            "Epoch: 0484 loss_train: 0.2303 acc_train: 0.9500 loss_val: 0.9133 acc_val: 0.7200 time: 0.0997s\n",
            "59\n",
            "Epoch: 0485 loss_train: 0.2305 acc_train: 0.9417 loss_val: 0.9083 acc_val: 0.7240 time: 0.0967s\n",
            "60\n",
            "Epoch: 0486 loss_train: 0.2379 acc_train: 0.9667 loss_val: 0.9089 acc_val: 0.7260 time: 0.0962s\n",
            "0\n",
            "Epoch: 0487 loss_train: 0.2137 acc_train: 0.9917 loss_val: 0.9116 acc_val: 0.7200 time: 0.1036s\n",
            "1\n",
            "Epoch: 0488 loss_train: 0.2137 acc_train: 0.9750 loss_val: 0.9199 acc_val: 0.7240 time: 0.1008s\n",
            "2\n",
            "Epoch: 0489 loss_train: 0.2367 acc_train: 0.9417 loss_val: 0.9269 acc_val: 0.7300 time: 0.1012s\n",
            "3\n",
            "Epoch: 0490 loss_train: 0.2528 acc_train: 0.9667 loss_val: 0.9277 acc_val: 0.7320 time: 0.0968s\n",
            "4\n",
            "Epoch: 0491 loss_train: 0.2307 acc_train: 0.9833 loss_val: 0.9246 acc_val: 0.7280 time: 0.1011s\n",
            "5\n",
            "Epoch: 0492 loss_train: 0.2261 acc_train: 0.9917 loss_val: 0.9182 acc_val: 0.7220 time: 0.0977s\n",
            "6\n",
            "Epoch: 0493 loss_train: 0.2313 acc_train: 0.9667 loss_val: 0.9135 acc_val: 0.7300 time: 0.0965s\n",
            "7\n",
            "Epoch: 0494 loss_train: 0.2360 acc_train: 0.9667 loss_val: 0.9089 acc_val: 0.7300 time: 0.0998s\n",
            "8\n",
            "Epoch: 0495 loss_train: 0.2212 acc_train: 0.9583 loss_val: 0.9085 acc_val: 0.7300 time: 0.0986s\n",
            "9\n",
            "Epoch: 0496 loss_train: 0.2111 acc_train: 0.9833 loss_val: 0.9148 acc_val: 0.7200 time: 0.0987s\n",
            "10\n",
            "Epoch: 0497 loss_train: 0.2227 acc_train: 0.9833 loss_val: 0.9229 acc_val: 0.7220 time: 0.0983s\n",
            "11\n",
            "Epoch: 0498 loss_train: 0.2286 acc_train: 0.9500 loss_val: 0.9280 acc_val: 0.7240 time: 0.0984s\n",
            "12\n",
            "Epoch: 0499 loss_train: 0.2335 acc_train: 0.9667 loss_val: 0.9277 acc_val: 0.7240 time: 0.0997s\n",
            "13\n",
            "Epoch: 0500 loss_train: 0.2479 acc_train: 0.9667 loss_val: 0.9244 acc_val: 0.7240 time: 0.0953s\n",
            "14\n",
            "Epoch: 0501 loss_train: 0.2241 acc_train: 0.9667 loss_val: 0.9154 acc_val: 0.7240 time: 0.1019s\n",
            "15\n",
            "Epoch: 0502 loss_train: 0.2273 acc_train: 0.9583 loss_val: 0.9107 acc_val: 0.7220 time: 0.0957s\n",
            "16\n",
            "Epoch: 0503 loss_train: 0.2315 acc_train: 0.9917 loss_val: 0.9121 acc_val: 0.7220 time: 0.0981s\n",
            "17\n",
            "Epoch: 0504 loss_train: 0.2302 acc_train: 0.9667 loss_val: 0.9201 acc_val: 0.7180 time: 0.1001s\n",
            "18\n",
            "Epoch: 0505 loss_train: 0.2275 acc_train: 0.9667 loss_val: 0.9306 acc_val: 0.7140 time: 0.0957s\n",
            "19\n",
            "Epoch: 0506 loss_train: 0.2379 acc_train: 0.9667 loss_val: 0.9343 acc_val: 0.7180 time: 0.0983s\n",
            "20\n",
            "Epoch: 0507 loss_train: 0.2381 acc_train: 0.9917 loss_val: 0.9307 acc_val: 0.7200 time: 0.0960s\n",
            "21\n",
            "Epoch: 0508 loss_train: 0.2307 acc_train: 0.9750 loss_val: 0.9209 acc_val: 0.7200 time: 0.0990s\n",
            "22\n",
            "Epoch: 0509 loss_train: 0.2393 acc_train: 0.9667 loss_val: 0.9107 acc_val: 0.7240 time: 0.0998s\n",
            "23\n",
            "Epoch: 0510 loss_train: 0.2154 acc_train: 0.9750 loss_val: 0.9116 acc_val: 0.7240 time: 0.0969s\n",
            "24\n",
            "Epoch: 0511 loss_train: 0.2231 acc_train: 0.9750 loss_val: 0.9149 acc_val: 0.7160 time: 0.1018s\n",
            "25\n",
            "Epoch: 0512 loss_train: 0.2439 acc_train: 0.9750 loss_val: 0.9216 acc_val: 0.7120 time: 0.0953s\n",
            "26\n",
            "Epoch: 0513 loss_train: 0.2193 acc_train: 0.9667 loss_val: 0.9326 acc_val: 0.7240 time: 0.0982s\n",
            "27\n",
            "Epoch: 0514 loss_train: 0.2375 acc_train: 0.9500 loss_val: 0.9373 acc_val: 0.7200 time: 0.1047s\n",
            "28\n",
            "Epoch: 0515 loss_train: 0.2322 acc_train: 0.9750 loss_val: 0.9296 acc_val: 0.7260 time: 0.0961s\n",
            "29\n",
            "Epoch: 0516 loss_train: 0.2118 acc_train: 0.9750 loss_val: 0.9137 acc_val: 0.7240 time: 0.1009s\n",
            "30\n",
            "Epoch: 0517 loss_train: 0.2260 acc_train: 0.9667 loss_val: 0.9039 acc_val: 0.7220 time: 0.0970s\n",
            "31\n",
            "Epoch: 0518 loss_train: 0.2403 acc_train: 0.9500 loss_val: 0.8997 acc_val: 0.7260 time: 0.0996s\n",
            "0\n",
            "Epoch: 0519 loss_train: 0.2202 acc_train: 0.9583 loss_val: 0.9024 acc_val: 0.7240 time: 0.0958s\n",
            "0\n",
            "Epoch: 0520 loss_train: 0.2230 acc_train: 0.9750 loss_val: 0.9083 acc_val: 0.7200 time: 0.0958s\n",
            "1\n",
            "Epoch: 0521 loss_train: 0.2360 acc_train: 0.9833 loss_val: 0.9176 acc_val: 0.7240 time: 0.0991s\n",
            "2\n",
            "Epoch: 0522 loss_train: 0.2244 acc_train: 0.9750 loss_val: 0.9236 acc_val: 0.7200 time: 0.0981s\n",
            "3\n",
            "Epoch: 0523 loss_train: 0.2283 acc_train: 0.9833 loss_val: 0.9255 acc_val: 0.7220 time: 0.1011s\n",
            "4\n",
            "Epoch: 0524 loss_train: 0.2231 acc_train: 0.9750 loss_val: 0.9242 acc_val: 0.7240 time: 0.1013s\n",
            "5\n",
            "Epoch: 0525 loss_train: 0.2179 acc_train: 0.9667 loss_val: 0.9194 acc_val: 0.7240 time: 0.0967s\n",
            "6\n",
            "Epoch: 0526 loss_train: 0.2193 acc_train: 0.9750 loss_val: 0.9141 acc_val: 0.7200 time: 0.0988s\n",
            "7\n",
            "Epoch: 0527 loss_train: 0.2274 acc_train: 0.9667 loss_val: 0.9132 acc_val: 0.7200 time: 0.0956s\n",
            "8\n",
            "Epoch: 0528 loss_train: 0.2347 acc_train: 0.9750 loss_val: 0.9097 acc_val: 0.7220 time: 0.0970s\n",
            "9\n",
            "Epoch: 0529 loss_train: 0.2301 acc_train: 0.9667 loss_val: 0.9115 acc_val: 0.7260 time: 0.0990s\n",
            "10\n",
            "Epoch: 0530 loss_train: 0.2267 acc_train: 0.9667 loss_val: 0.9154 acc_val: 0.7300 time: 0.0950s\n",
            "11\n",
            "Epoch: 0531 loss_train: 0.2239 acc_train: 0.9750 loss_val: 0.9201 acc_val: 0.7260 time: 0.0963s\n",
            "12\n",
            "Epoch: 0532 loss_train: 0.2367 acc_train: 0.9417 loss_val: 0.9242 acc_val: 0.7200 time: 0.1028s\n",
            "13\n",
            "Epoch: 0533 loss_train: 0.2303 acc_train: 0.9750 loss_val: 0.9273 acc_val: 0.7160 time: 0.0959s\n",
            "14\n",
            "Epoch: 0534 loss_train: 0.2340 acc_train: 0.9417 loss_val: 0.9304 acc_val: 0.7160 time: 0.0963s\n",
            "15\n",
            "Epoch: 0535 loss_train: 0.2320 acc_train: 0.9500 loss_val: 0.9294 acc_val: 0.7180 time: 0.0997s\n",
            "16\n",
            "Epoch: 0536 loss_train: 0.2293 acc_train: 0.9583 loss_val: 0.9248 acc_val: 0.7120 time: 0.0952s\n",
            "17\n",
            "Epoch: 0537 loss_train: 0.2212 acc_train: 0.9667 loss_val: 0.9199 acc_val: 0.7280 time: 0.1004s\n",
            "18\n",
            "Epoch: 0538 loss_train: 0.2278 acc_train: 0.9833 loss_val: 0.9129 acc_val: 0.7360 time: 0.1004s\n",
            "19\n",
            "Epoch: 0539 loss_train: 0.2355 acc_train: 0.9750 loss_val: 0.9062 acc_val: 0.7260 time: 0.1016s\n",
            "20\n",
            "Epoch: 0540 loss_train: 0.2262 acc_train: 0.9833 loss_val: 0.9050 acc_val: 0.7260 time: 0.1011s\n",
            "21\n",
            "Epoch: 0541 loss_train: 0.2303 acc_train: 0.9833 loss_val: 0.9088 acc_val: 0.7220 time: 0.0952s\n",
            "22\n",
            "Epoch: 0542 loss_train: 0.2221 acc_train: 0.9667 loss_val: 0.9177 acc_val: 0.7180 time: 0.0956s\n",
            "23\n",
            "Epoch: 0543 loss_train: 0.2175 acc_train: 0.9583 loss_val: 0.9251 acc_val: 0.7200 time: 0.0984s\n",
            "24\n",
            "Epoch: 0544 loss_train: 0.2356 acc_train: 0.9583 loss_val: 0.9242 acc_val: 0.7200 time: 0.0962s\n",
            "25\n",
            "Epoch: 0545 loss_train: 0.2384 acc_train: 0.9583 loss_val: 0.9248 acc_val: 0.7200 time: 0.1006s\n",
            "26\n",
            "Epoch: 0546 loss_train: 0.2264 acc_train: 0.9833 loss_val: 0.9212 acc_val: 0.7220 time: 0.1007s\n",
            "27\n",
            "Epoch: 0547 loss_train: 0.2175 acc_train: 0.9917 loss_val: 0.9166 acc_val: 0.7260 time: 0.0959s\n",
            "28\n",
            "Epoch: 0548 loss_train: 0.2243 acc_train: 0.9833 loss_val: 0.9137 acc_val: 0.7280 time: 0.0997s\n",
            "29\n",
            "Epoch: 0549 loss_train: 0.2262 acc_train: 0.9750 loss_val: 0.9154 acc_val: 0.7280 time: 0.0987s\n",
            "30\n",
            "Epoch: 0550 loss_train: 0.2224 acc_train: 0.9583 loss_val: 0.9148 acc_val: 0.7220 time: 0.0965s\n",
            "31\n",
            "Epoch: 0551 loss_train: 0.2187 acc_train: 0.9667 loss_val: 0.9137 acc_val: 0.7220 time: 0.1026s\n",
            "32\n",
            "Epoch: 0552 loss_train: 0.2309 acc_train: 0.9750 loss_val: 0.9151 acc_val: 0.7160 time: 0.0958s\n",
            "33\n",
            "Epoch: 0553 loss_train: 0.2391 acc_train: 0.9667 loss_val: 0.9174 acc_val: 0.7160 time: 0.0985s\n",
            "34\n",
            "Epoch: 0554 loss_train: 0.2155 acc_train: 0.9833 loss_val: 0.9187 acc_val: 0.7180 time: 0.0966s\n",
            "35\n",
            "Epoch: 0555 loss_train: 0.2212 acc_train: 0.9667 loss_val: 0.9161 acc_val: 0.7200 time: 0.0960s\n",
            "36\n",
            "Epoch: 0556 loss_train: 0.2031 acc_train: 0.9583 loss_val: 0.9126 acc_val: 0.7200 time: 0.1045s\n",
            "37\n",
            "Epoch: 0557 loss_train: 0.2434 acc_train: 0.9667 loss_val: 0.9114 acc_val: 0.7340 time: 0.0989s\n",
            "38\n",
            "Epoch: 0558 loss_train: 0.2203 acc_train: 0.9667 loss_val: 0.9139 acc_val: 0.7320 time: 0.1006s\n",
            "39\n",
            "Epoch: 0559 loss_train: 0.2339 acc_train: 0.9500 loss_val: 0.9161 acc_val: 0.7220 time: 0.1012s\n",
            "40\n",
            "Epoch: 0560 loss_train: 0.2211 acc_train: 0.9583 loss_val: 0.9177 acc_val: 0.7260 time: 0.0958s\n",
            "41\n",
            "Epoch: 0561 loss_train: 0.2229 acc_train: 0.9667 loss_val: 0.9184 acc_val: 0.7240 time: 0.1024s\n",
            "42\n",
            "Epoch: 0562 loss_train: 0.2126 acc_train: 0.9917 loss_val: 0.9178 acc_val: 0.7220 time: 0.0958s\n",
            "43\n",
            "Epoch: 0563 loss_train: 0.2331 acc_train: 0.9583 loss_val: 0.9151 acc_val: 0.7180 time: 0.1085s\n",
            "44\n",
            "Epoch: 0564 loss_train: 0.2124 acc_train: 0.9917 loss_val: 0.9183 acc_val: 0.7200 time: 0.0976s\n",
            "45\n",
            "Epoch: 0565 loss_train: 0.2316 acc_train: 0.9667 loss_val: 0.9231 acc_val: 0.7160 time: 0.0959s\n",
            "46\n",
            "Epoch: 0566 loss_train: 0.2272 acc_train: 0.9417 loss_val: 0.9237 acc_val: 0.7160 time: 0.0988s\n",
            "47\n",
            "Epoch: 0567 loss_train: 0.2120 acc_train: 0.9833 loss_val: 0.9185 acc_val: 0.7200 time: 0.0968s\n",
            "48\n",
            "Epoch: 0568 loss_train: 0.2197 acc_train: 0.9750 loss_val: 0.9108 acc_val: 0.7280 time: 0.1020s\n",
            "49\n",
            "Epoch: 0569 loss_train: 0.2180 acc_train: 0.9750 loss_val: 0.9050 acc_val: 0.7340 time: 0.1016s\n",
            "50\n",
            "Epoch: 0570 loss_train: 0.2420 acc_train: 0.9583 loss_val: 0.9051 acc_val: 0.7220 time: 0.0959s\n",
            "51\n",
            "Epoch: 0571 loss_train: 0.2416 acc_train: 0.9917 loss_val: 0.9110 acc_val: 0.7200 time: 0.0998s\n",
            "52\n",
            "Epoch: 0572 loss_train: 0.2458 acc_train: 0.9667 loss_val: 0.9255 acc_val: 0.7140 time: 0.0963s\n",
            "53\n",
            "Epoch: 0573 loss_train: 0.2200 acc_train: 0.9833 loss_val: 0.9380 acc_val: 0.7180 time: 0.1046s\n",
            "54\n",
            "Epoch: 0574 loss_train: 0.2212 acc_train: 0.9833 loss_val: 0.9392 acc_val: 0.7200 time: 0.0967s\n",
            "55\n",
            "Epoch: 0575 loss_train: 0.2292 acc_train: 0.9500 loss_val: 0.9270 acc_val: 0.7240 time: 0.0994s\n",
            "56\n",
            "Epoch: 0576 loss_train: 0.2393 acc_train: 0.9667 loss_val: 0.9102 acc_val: 0.7260 time: 0.1027s\n",
            "57\n",
            "Epoch: 0577 loss_train: 0.2246 acc_train: 0.9917 loss_val: 0.8985 acc_val: 0.7260 time: 0.0965s\n",
            "58\n",
            "Epoch: 0578 loss_train: 0.2373 acc_train: 0.9500 loss_val: 0.8968 acc_val: 0.7300 time: 0.0986s\n",
            "0\n",
            "Epoch: 0579 loss_train: 0.2088 acc_train: 0.9917 loss_val: 0.9014 acc_val: 0.7300 time: 0.1005s\n",
            "0\n",
            "Epoch: 0580 loss_train: 0.2162 acc_train: 0.9833 loss_val: 0.9123 acc_val: 0.7280 time: 0.0955s\n",
            "1\n",
            "Epoch: 0581 loss_train: 0.2161 acc_train: 0.9667 loss_val: 0.9237 acc_val: 0.7200 time: 0.0999s\n",
            "2\n",
            "Epoch: 0582 loss_train: 0.2126 acc_train: 1.0000 loss_val: 0.9321 acc_val: 0.7200 time: 0.0971s\n",
            "3\n",
            "Epoch: 0583 loss_train: 0.2093 acc_train: 0.9750 loss_val: 0.9321 acc_val: 0.7140 time: 0.0995s\n",
            "4\n",
            "Epoch: 0584 loss_train: 0.2260 acc_train: 0.9500 loss_val: 0.9252 acc_val: 0.7180 time: 0.0973s\n",
            "5\n",
            "Epoch: 0585 loss_train: 0.2078 acc_train: 0.9750 loss_val: 0.9167 acc_val: 0.7220 time: 0.0957s\n",
            "6\n",
            "Epoch: 0586 loss_train: 0.2173 acc_train: 0.9667 loss_val: 0.9075 acc_val: 0.7260 time: 0.0984s\n",
            "7\n",
            "Epoch: 0587 loss_train: 0.2102 acc_train: 0.9667 loss_val: 0.9042 acc_val: 0.7280 time: 0.0958s\n",
            "8\n",
            "Epoch: 0588 loss_train: 0.2203 acc_train: 0.9917 loss_val: 0.9039 acc_val: 0.7320 time: 0.1013s\n",
            "9\n",
            "Epoch: 0589 loss_train: 0.2287 acc_train: 0.9917 loss_val: 0.9033 acc_val: 0.7280 time: 0.1059s\n",
            "10\n",
            "Epoch: 0590 loss_train: 0.2360 acc_train: 0.9500 loss_val: 0.9080 acc_val: 0.7240 time: 0.0961s\n",
            "11\n",
            "Epoch: 0591 loss_train: 0.2175 acc_train: 0.9750 loss_val: 0.9202 acc_val: 0.7160 time: 0.0998s\n",
            "12\n",
            "Epoch: 0592 loss_train: 0.2102 acc_train: 0.9750 loss_val: 0.9323 acc_val: 0.7120 time: 0.0951s\n",
            "13\n",
            "Epoch: 0593 loss_train: 0.2232 acc_train: 0.9500 loss_val: 0.9293 acc_val: 0.7100 time: 0.0953s\n",
            "14\n",
            "Epoch: 0594 loss_train: 0.2120 acc_train: 0.9583 loss_val: 0.9182 acc_val: 0.7220 time: 0.1042s\n",
            "15\n",
            "Epoch: 0595 loss_train: 0.2260 acc_train: 0.9833 loss_val: 0.9058 acc_val: 0.7300 time: 0.0953s\n",
            "16\n",
            "Epoch: 0596 loss_train: 0.2369 acc_train: 0.9667 loss_val: 0.8978 acc_val: 0.7320 time: 0.0962s\n",
            "17\n",
            "Epoch: 0597 loss_train: 0.2204 acc_train: 0.9417 loss_val: 0.8972 acc_val: 0.7320 time: 0.1018s\n",
            "18\n",
            "Epoch: 0598 loss_train: 0.2419 acc_train: 0.9500 loss_val: 0.9024 acc_val: 0.7320 time: 0.0968s\n",
            "19\n",
            "Epoch: 0599 loss_train: 0.2249 acc_train: 0.9833 loss_val: 0.9162 acc_val: 0.7280 time: 0.1004s\n",
            "20\n",
            "Epoch: 0600 loss_train: 0.2363 acc_train: 0.9500 loss_val: 0.9351 acc_val: 0.7200 time: 0.1020s\n",
            "21\n",
            "Epoch: 0601 loss_train: 0.2144 acc_train: 0.9750 loss_val: 0.9372 acc_val: 0.7220 time: 0.0958s\n",
            "22\n",
            "Epoch: 0602 loss_train: 0.2164 acc_train: 0.9750 loss_val: 0.9290 acc_val: 0.7220 time: 0.1006s\n",
            "23\n",
            "Epoch: 0603 loss_train: 0.2306 acc_train: 0.9667 loss_val: 0.9184 acc_val: 0.7280 time: 0.0965s\n",
            "24\n",
            "Epoch: 0604 loss_train: 0.2166 acc_train: 0.9583 loss_val: 0.9103 acc_val: 0.7260 time: 0.0959s\n",
            "25\n",
            "Epoch: 0605 loss_train: 0.2126 acc_train: 0.9583 loss_val: 0.9079 acc_val: 0.7280 time: 0.1006s\n",
            "26\n",
            "Epoch: 0606 loss_train: 0.2177 acc_train: 0.9667 loss_val: 0.9090 acc_val: 0.7340 time: 0.1635s\n",
            "27\n",
            "Epoch: 0607 loss_train: 0.2202 acc_train: 0.9667 loss_val: 0.9122 acc_val: 0.7300 time: 0.1003s\n",
            "28\n",
            "Epoch: 0608 loss_train: 0.2268 acc_train: 0.9667 loss_val: 0.9213 acc_val: 0.7260 time: 0.0994s\n",
            "29\n",
            "Epoch: 0609 loss_train: 0.2261 acc_train: 0.9750 loss_val: 0.9301 acc_val: 0.7240 time: 0.0982s\n",
            "30\n",
            "Epoch: 0610 loss_train: 0.2211 acc_train: 0.9583 loss_val: 0.9275 acc_val: 0.7240 time: 0.1020s\n",
            "31\n",
            "Epoch: 0611 loss_train: 0.2243 acc_train: 0.9917 loss_val: 0.9172 acc_val: 0.7260 time: 0.0983s\n",
            "32\n",
            "Epoch: 0612 loss_train: 0.2132 acc_train: 0.9833 loss_val: 0.9066 acc_val: 0.7220 time: 0.1015s\n",
            "33\n",
            "Epoch: 0613 loss_train: 0.2201 acc_train: 0.9667 loss_val: 0.9025 acc_val: 0.7260 time: 0.0957s\n",
            "34\n",
            "Epoch: 0614 loss_train: 0.2272 acc_train: 0.9667 loss_val: 0.9034 acc_val: 0.7220 time: 0.0957s\n",
            "35\n",
            "Epoch: 0615 loss_train: 0.2062 acc_train: 0.9750 loss_val: 0.9102 acc_val: 0.7340 time: 0.0991s\n",
            "36\n",
            "Epoch: 0616 loss_train: 0.2458 acc_train: 0.9500 loss_val: 0.9187 acc_val: 0.7300 time: 0.0956s\n",
            "37\n",
            "Epoch: 0617 loss_train: 0.2268 acc_train: 0.9667 loss_val: 0.9266 acc_val: 0.7300 time: 0.0968s\n",
            "38\n",
            "Epoch: 0618 loss_train: 0.2205 acc_train: 0.9750 loss_val: 0.9289 acc_val: 0.7200 time: 0.1037s\n",
            "39\n",
            "Epoch: 0619 loss_train: 0.2307 acc_train: 0.9750 loss_val: 0.9211 acc_val: 0.7240 time: 0.0952s\n",
            "40\n",
            "Epoch: 0620 loss_train: 0.2177 acc_train: 0.9667 loss_val: 0.9124 acc_val: 0.7200 time: 0.0980s\n",
            "41\n",
            "Epoch: 0621 loss_train: 0.2206 acc_train: 0.9667 loss_val: 0.9042 acc_val: 0.7200 time: 0.1021s\n",
            "42\n",
            "Epoch: 0622 loss_train: 0.2302 acc_train: 0.9667 loss_val: 0.8998 acc_val: 0.7240 time: 0.0960s\n",
            "43\n",
            "Epoch: 0623 loss_train: 0.2186 acc_train: 0.9667 loss_val: 0.9005 acc_val: 0.7240 time: 0.0970s\n",
            "44\n",
            "Epoch: 0624 loss_train: 0.2221 acc_train: 0.9500 loss_val: 0.9106 acc_val: 0.7340 time: 0.0989s\n",
            "45\n",
            "Epoch: 0625 loss_train: 0.2224 acc_train: 0.9667 loss_val: 0.9242 acc_val: 0.7320 time: 0.0959s\n",
            "46\n",
            "Epoch: 0626 loss_train: 0.2241 acc_train: 0.9667 loss_val: 0.9329 acc_val: 0.7220 time: 0.0963s\n",
            "47\n",
            "Epoch: 0627 loss_train: 0.2353 acc_train: 0.9833 loss_val: 0.9287 acc_val: 0.7200 time: 0.1043s\n",
            "48\n",
            "Epoch: 0628 loss_train: 0.2204 acc_train: 0.9750 loss_val: 0.9187 acc_val: 0.7300 time: 0.1023s\n",
            "49\n",
            "Epoch: 0629 loss_train: 0.2315 acc_train: 0.9583 loss_val: 0.9092 acc_val: 0.7260 time: 0.0958s\n",
            "50\n",
            "Epoch: 0630 loss_train: 0.2229 acc_train: 0.9833 loss_val: 0.9001 acc_val: 0.7280 time: 0.0990s\n",
            "51\n",
            "Epoch: 0631 loss_train: 0.2290 acc_train: 0.9750 loss_val: 0.8983 acc_val: 0.7280 time: 0.0955s\n",
            "52\n",
            "Epoch: 0632 loss_train: 0.2150 acc_train: 0.9667 loss_val: 0.9065 acc_val: 0.7220 time: 0.0984s\n",
            "53\n",
            "Epoch: 0633 loss_train: 0.2002 acc_train: 0.9750 loss_val: 0.9192 acc_val: 0.7340 time: 0.0969s\n",
            "54\n",
            "Epoch: 0634 loss_train: 0.2194 acc_train: 0.9667 loss_val: 0.9335 acc_val: 0.7320 time: 0.0957s\n",
            "55\n",
            "Epoch: 0635 loss_train: 0.2096 acc_train: 0.9833 loss_val: 0.9424 acc_val: 0.7260 time: 0.0994s\n",
            "56\n",
            "Epoch: 0636 loss_train: 0.2351 acc_train: 0.9667 loss_val: 0.9380 acc_val: 0.7220 time: 0.0968s\n",
            "57\n",
            "Epoch: 0637 loss_train: 0.2371 acc_train: 0.9500 loss_val: 0.9231 acc_val: 0.7180 time: 0.0965s\n",
            "58\n",
            "Epoch: 0638 loss_train: 0.2097 acc_train: 0.9750 loss_val: 0.9104 acc_val: 0.7200 time: 0.1026s\n",
            "59\n",
            "Epoch: 0639 loss_train: 0.2363 acc_train: 0.9250 loss_val: 0.9059 acc_val: 0.7220 time: 0.0962s\n",
            "60\n",
            "Epoch: 0640 loss_train: 0.2237 acc_train: 0.9583 loss_val: 0.9085 acc_val: 0.7200 time: 0.0975s\n",
            "61\n",
            "Epoch: 0641 loss_train: 0.2192 acc_train: 0.9667 loss_val: 0.9154 acc_val: 0.7240 time: 0.1061s\n",
            "62\n",
            "Epoch: 0642 loss_train: 0.2174 acc_train: 0.9583 loss_val: 0.9225 acc_val: 0.7220 time: 0.0955s\n",
            "63\n",
            "Epoch: 0643 loss_train: 0.2147 acc_train: 0.9750 loss_val: 0.9301 acc_val: 0.7300 time: 0.1015s\n",
            "64\n",
            "Epoch: 0644 loss_train: 0.2218 acc_train: 0.9667 loss_val: 0.9274 acc_val: 0.7300 time: 0.0987s\n",
            "65\n",
            "Epoch: 0645 loss_train: 0.2179 acc_train: 0.9917 loss_val: 0.9221 acc_val: 0.7200 time: 0.1059s\n",
            "66\n",
            "Epoch: 0646 loss_train: 0.2137 acc_train: 0.9833 loss_val: 0.9165 acc_val: 0.7220 time: 0.0961s\n",
            "67\n",
            "Epoch: 0647 loss_train: 0.2268 acc_train: 0.9667 loss_val: 0.9117 acc_val: 0.7220 time: 0.0951s\n",
            "68\n",
            "Epoch: 0648 loss_train: 0.2150 acc_train: 0.9833 loss_val: 0.9092 acc_val: 0.7260 time: 0.1035s\n",
            "69\n",
            "Epoch: 0649 loss_train: 0.2140 acc_train: 1.0000 loss_val: 0.9111 acc_val: 0.7240 time: 0.0958s\n",
            "70\n",
            "Epoch: 0650 loss_train: 0.2323 acc_train: 1.0000 loss_val: 0.9151 acc_val: 0.7280 time: 0.0964s\n",
            "71\n",
            "Epoch: 0651 loss_train: 0.2264 acc_train: 0.9667 loss_val: 0.9206 acc_val: 0.7220 time: 0.0993s\n",
            "72\n",
            "Epoch: 0652 loss_train: 0.2150 acc_train: 0.9833 loss_val: 0.9200 acc_val: 0.7240 time: 0.0949s\n",
            "73\n",
            "Epoch: 0653 loss_train: 0.2082 acc_train: 0.9583 loss_val: 0.9194 acc_val: 0.7220 time: 0.0952s\n",
            "74\n",
            "Epoch: 0654 loss_train: 0.2168 acc_train: 0.9667 loss_val: 0.9163 acc_val: 0.7200 time: 0.1001s\n",
            "75\n",
            "Epoch: 0655 loss_train: 0.2169 acc_train: 0.9750 loss_val: 0.9155 acc_val: 0.7220 time: 0.0961s\n",
            "76\n",
            "Epoch: 0656 loss_train: 0.2166 acc_train: 0.9833 loss_val: 0.9122 acc_val: 0.7180 time: 0.0960s\n",
            "77\n",
            "Epoch: 0657 loss_train: 0.2348 acc_train: 0.9583 loss_val: 0.9143 acc_val: 0.7220 time: 0.1010s\n",
            "78\n",
            "Epoch: 0658 loss_train: 0.2203 acc_train: 0.9917 loss_val: 0.9174 acc_val: 0.7220 time: 0.0961s\n",
            "79\n",
            "Epoch: 0659 loss_train: 0.2359 acc_train: 0.9750 loss_val: 0.9234 acc_val: 0.7260 time: 0.0987s\n",
            "80\n",
            "Epoch: 0660 loss_train: 0.2177 acc_train: 0.9750 loss_val: 0.9257 acc_val: 0.7240 time: 0.0978s\n",
            "81\n",
            "Epoch: 0661 loss_train: 0.2331 acc_train: 0.9583 loss_val: 0.9230 acc_val: 0.7160 time: 0.0969s\n",
            "82\n",
            "Epoch: 0662 loss_train: 0.2345 acc_train: 0.9417 loss_val: 0.9180 acc_val: 0.7140 time: 0.1012s\n",
            "83\n",
            "Epoch: 0663 loss_train: 0.2261 acc_train: 0.9833 loss_val: 0.9139 acc_val: 0.7160 time: 0.0997s\n",
            "84\n",
            "Epoch: 0664 loss_train: 0.2226 acc_train: 0.9500 loss_val: 0.9123 acc_val: 0.7180 time: 0.0951s\n",
            "85\n",
            "Epoch: 0665 loss_train: 0.2355 acc_train: 0.9583 loss_val: 0.9130 acc_val: 0.7200 time: 0.0971s\n",
            "86\n",
            "Epoch: 0666 loss_train: 0.2240 acc_train: 0.9750 loss_val: 0.9173 acc_val: 0.7140 time: 0.0957s\n",
            "87\n",
            "Epoch: 0667 loss_train: 0.2205 acc_train: 0.9583 loss_val: 0.9196 acc_val: 0.7220 time: 0.0985s\n",
            "88\n",
            "Epoch: 0668 loss_train: 0.2079 acc_train: 0.9750 loss_val: 0.9214 acc_val: 0.7280 time: 0.0965s\n",
            "89\n",
            "Epoch: 0669 loss_train: 0.2224 acc_train: 0.9667 loss_val: 0.9219 acc_val: 0.7280 time: 0.1030s\n",
            "90\n",
            "Epoch: 0670 loss_train: 0.2268 acc_train: 0.9667 loss_val: 0.9189 acc_val: 0.7300 time: 0.1026s\n",
            "91\n",
            "Epoch: 0671 loss_train: 0.2374 acc_train: 0.9667 loss_val: 0.9196 acc_val: 0.7200 time: 0.0986s\n",
            "92\n",
            "Epoch: 0672 loss_train: 0.2201 acc_train: 0.9667 loss_val: 0.9213 acc_val: 0.7180 time: 0.0991s\n",
            "93\n",
            "Epoch: 0673 loss_train: 0.2198 acc_train: 0.9667 loss_val: 0.9195 acc_val: 0.7140 time: 0.1047s\n",
            "94\n",
            "Epoch: 0674 loss_train: 0.2309 acc_train: 0.9417 loss_val: 0.9136 acc_val: 0.7200 time: 0.1096s\n",
            "95\n",
            "Epoch: 0675 loss_train: 0.2263 acc_train: 0.9667 loss_val: 0.9127 acc_val: 0.7220 time: 0.1033s\n",
            "96\n",
            "Epoch: 0676 loss_train: 0.2352 acc_train: 0.9583 loss_val: 0.9133 acc_val: 0.7240 time: 0.1056s\n",
            "97\n",
            "Epoch: 0677 loss_train: 0.2182 acc_train: 0.9833 loss_val: 0.9161 acc_val: 0.7240 time: 0.0989s\n",
            "98\n",
            "Epoch: 0678 loss_train: 0.2182 acc_train: 0.9667 loss_val: 0.9202 acc_val: 0.7240 time: 0.1086s\n",
            "99\n",
            "Epoch: 0679 loss_train: 0.2297 acc_train: 0.9583 loss_val: 0.9229 acc_val: 0.7240 time: 0.1033s\n",
            "100\n",
            "Epoch: 0680 loss_train: 0.2313 acc_train: 0.9833 loss_val: 0.9242 acc_val: 0.7220 time: 0.1012s\n",
            "101\n",
            "Epoch: 0681 loss_train: 0.2201 acc_train: 0.9750 loss_val: 0.9200 acc_val: 0.7180 time: 0.1092s\n",
            "102\n",
            "Epoch: 0682 loss_train: 0.2423 acc_train: 0.9583 loss_val: 0.9127 acc_val: 0.7220 time: 0.1027s\n",
            "103\n",
            "Epoch: 0683 loss_train: 0.2253 acc_train: 0.9500 loss_val: 0.9087 acc_val: 0.7220 time: 0.0995s\n",
            "104\n",
            "Epoch: 0684 loss_train: 0.2450 acc_train: 0.9667 loss_val: 0.9095 acc_val: 0.7220 time: 0.0992s\n",
            "105\n",
            "Epoch: 0685 loss_train: 0.2324 acc_train: 0.9750 loss_val: 0.9134 acc_val: 0.7260 time: 0.1011s\n",
            "106\n",
            "Epoch: 0686 loss_train: 0.2172 acc_train: 0.9750 loss_val: 0.9182 acc_val: 0.7260 time: 0.0961s\n",
            "107\n",
            "Epoch: 0687 loss_train: 0.2323 acc_train: 0.9500 loss_val: 0.9227 acc_val: 0.7240 time: 0.0988s\n",
            "108\n",
            "Epoch: 0688 loss_train: 0.2283 acc_train: 0.9833 loss_val: 0.9202 acc_val: 0.7200 time: 0.0998s\n",
            "109\n",
            "Epoch: 0689 loss_train: 0.2500 acc_train: 0.9833 loss_val: 0.9177 acc_val: 0.7160 time: 0.0953s\n",
            "110\n",
            "Epoch: 0690 loss_train: 0.2131 acc_train: 0.9833 loss_val: 0.9108 acc_val: 0.7240 time: 0.0991s\n",
            "111\n",
            "Epoch: 0691 loss_train: 0.2168 acc_train: 0.9667 loss_val: 0.9055 acc_val: 0.7240 time: 0.0957s\n",
            "112\n",
            "Epoch: 0692 loss_train: 0.2252 acc_train: 0.9417 loss_val: 0.9085 acc_val: 0.7220 time: 0.0980s\n",
            "113\n",
            "Epoch: 0693 loss_train: 0.2171 acc_train: 0.9667 loss_val: 0.9137 acc_val: 0.7180 time: 0.0968s\n",
            "114\n",
            "Epoch: 0694 loss_train: 0.2254 acc_train: 0.9500 loss_val: 0.9184 acc_val: 0.7260 time: 0.0952s\n",
            "115\n",
            "Epoch: 0695 loss_train: 0.2154 acc_train: 0.9583 loss_val: 0.9200 acc_val: 0.7240 time: 0.1018s\n",
            "116\n",
            "Epoch: 0696 loss_train: 0.2183 acc_train: 0.9667 loss_val: 0.9215 acc_val: 0.7200 time: 0.0957s\n",
            "117\n",
            "Epoch: 0697 loss_train: 0.1953 acc_train: 0.9750 loss_val: 0.9204 acc_val: 0.7240 time: 0.0960s\n",
            "118\n",
            "Epoch: 0698 loss_train: 0.2260 acc_train: 0.9583 loss_val: 0.9167 acc_val: 0.7260 time: 0.1039s\n",
            "119\n",
            "Epoch: 0699 loss_train: 0.2316 acc_train: 0.9667 loss_val: 0.9125 acc_val: 0.7240 time: 0.0956s\n",
            "120\n",
            "Epoch: 0700 loss_train: 0.2281 acc_train: 0.9833 loss_val: 0.9109 acc_val: 0.7220 time: 0.0951s\n",
            "121\n",
            "Epoch: 0701 loss_train: 0.2344 acc_train: 0.9667 loss_val: 0.9119 acc_val: 0.7200 time: 0.0989s\n",
            "122\n",
            "Epoch: 0702 loss_train: 0.2269 acc_train: 0.9417 loss_val: 0.9160 acc_val: 0.7180 time: 0.0990s\n",
            "123\n",
            "Epoch: 0703 loss_train: 0.2170 acc_train: 0.9750 loss_val: 0.9180 acc_val: 0.7200 time: 0.0957s\n",
            "124\n",
            "Epoch: 0704 loss_train: 0.2232 acc_train: 0.9750 loss_val: 0.9172 acc_val: 0.7200 time: 0.0984s\n",
            "125\n",
            "Epoch: 0705 loss_train: 0.2225 acc_train: 0.9583 loss_val: 0.9151 acc_val: 0.7240 time: 0.0964s\n",
            "126\n",
            "Epoch: 0706 loss_train: 0.2253 acc_train: 0.9667 loss_val: 0.9129 acc_val: 0.7220 time: 0.0998s\n",
            "127\n",
            "Epoch: 0707 loss_train: 0.2360 acc_train: 0.9583 loss_val: 0.9131 acc_val: 0.7240 time: 0.0950s\n",
            "128\n",
            "Epoch: 0708 loss_train: 0.2311 acc_train: 0.9667 loss_val: 0.9141 acc_val: 0.7240 time: 0.1012s\n",
            "129\n",
            "Epoch: 0709 loss_train: 0.2285 acc_train: 0.9500 loss_val: 0.9148 acc_val: 0.7220 time: 0.1026s\n",
            "130\n",
            "Epoch: 0710 loss_train: 0.2140 acc_train: 0.9667 loss_val: 0.9207 acc_val: 0.7300 time: 0.0959s\n",
            "131\n",
            "Epoch: 0711 loss_train: 0.2072 acc_train: 0.9583 loss_val: 0.9271 acc_val: 0.7300 time: 0.0987s\n",
            "132\n",
            "Epoch: 0712 loss_train: 0.2348 acc_train: 0.9500 loss_val: 0.9248 acc_val: 0.7320 time: 0.0956s\n",
            "133\n",
            "Epoch: 0713 loss_train: 0.2439 acc_train: 0.9750 loss_val: 0.9180 acc_val: 0.7220 time: 0.0986s\n",
            "134\n",
            "Epoch: 0714 loss_train: 0.2133 acc_train: 0.9917 loss_val: 0.9115 acc_val: 0.7280 time: 0.1073s\n",
            "135\n",
            "Epoch: 0715 loss_train: 0.2251 acc_train: 0.9750 loss_val: 0.9078 acc_val: 0.7280 time: 0.0980s\n",
            "136\n",
            "Epoch: 0716 loss_train: 0.2190 acc_train: 0.9750 loss_val: 0.9065 acc_val: 0.7340 time: 0.1011s\n",
            "137\n",
            "Epoch: 0717 loss_train: 0.2302 acc_train: 0.9750 loss_val: 0.9087 acc_val: 0.7320 time: 0.1060s\n",
            "138\n",
            "Epoch: 0718 loss_train: 0.2229 acc_train: 0.9833 loss_val: 0.9148 acc_val: 0.7220 time: 0.1090s\n",
            "139\n",
            "Epoch: 0719 loss_train: 0.2156 acc_train: 0.9583 loss_val: 0.9207 acc_val: 0.7280 time: 0.1000s\n",
            "140\n",
            "Epoch: 0720 loss_train: 0.2109 acc_train: 0.9667 loss_val: 0.9228 acc_val: 0.7240 time: 0.0993s\n",
            "141\n",
            "Epoch: 0721 loss_train: 0.2436 acc_train: 0.9417 loss_val: 0.9174 acc_val: 0.7320 time: 0.1023s\n",
            "142\n",
            "Epoch: 0722 loss_train: 0.2054 acc_train: 0.9833 loss_val: 0.9064 acc_val: 0.7300 time: 0.1014s\n",
            "143\n",
            "Epoch: 0723 loss_train: 0.2287 acc_train: 0.9667 loss_val: 0.9008 acc_val: 0.7260 time: 0.1022s\n",
            "144\n",
            "Epoch: 0724 loss_train: 0.2158 acc_train: 0.9583 loss_val: 0.9010 acc_val: 0.7300 time: 0.0974s\n",
            "145\n",
            "Epoch: 0725 loss_train: 0.2208 acc_train: 0.9583 loss_val: 0.9056 acc_val: 0.7300 time: 0.1037s\n",
            "146\n",
            "Epoch: 0726 loss_train: 0.2220 acc_train: 0.9667 loss_val: 0.9133 acc_val: 0.7240 time: 0.1016s\n",
            "147\n",
            "Epoch: 0727 loss_train: 0.2315 acc_train: 0.9750 loss_val: 0.9208 acc_val: 0.7220 time: 0.0994s\n",
            "148\n",
            "Epoch: 0728 loss_train: 0.2364 acc_train: 0.9750 loss_val: 0.9225 acc_val: 0.7180 time: 0.1047s\n",
            "149\n",
            "Epoch: 0729 loss_train: 0.2191 acc_train: 0.9500 loss_val: 0.9224 acc_val: 0.7220 time: 0.0955s\n",
            "150\n",
            "Epoch: 0730 loss_train: 0.2277 acc_train: 0.9833 loss_val: 0.9200 acc_val: 0.7220 time: 0.0986s\n",
            "151\n",
            "Epoch: 0731 loss_train: 0.2249 acc_train: 0.9833 loss_val: 0.9125 acc_val: 0.7300 time: 0.0968s\n",
            "152\n",
            "Epoch: 0732 loss_train: 0.2261 acc_train: 0.9750 loss_val: 0.9092 acc_val: 0.7260 time: 0.1012s\n",
            "153\n",
            "Epoch: 0733 loss_train: 0.2103 acc_train: 0.9750 loss_val: 0.9115 acc_val: 0.7300 time: 0.0958s\n",
            "154\n",
            "Epoch: 0734 loss_train: 0.2480 acc_train: 0.9583 loss_val: 0.9160 acc_val: 0.7260 time: 0.0959s\n",
            "155\n",
            "Epoch: 0735 loss_train: 0.2027 acc_train: 0.9667 loss_val: 0.9203 acc_val: 0.7240 time: 0.0996s\n",
            "156\n",
            "Epoch: 0736 loss_train: 0.2314 acc_train: 0.9583 loss_val: 0.9214 acc_val: 0.7240 time: 0.0954s\n",
            "157\n",
            "Epoch: 0737 loss_train: 0.2434 acc_train: 0.9750 loss_val: 0.9162 acc_val: 0.7260 time: 0.0978s\n",
            "158\n",
            "Epoch: 0738 loss_train: 0.2060 acc_train: 0.9917 loss_val: 0.9115 acc_val: 0.7240 time: 0.1002s\n",
            "159\n",
            "Epoch: 0739 loss_train: 0.2261 acc_train: 0.9833 loss_val: 0.9105 acc_val: 0.7300 time: 0.0977s\n",
            "160\n",
            "Epoch: 0740 loss_train: 0.2076 acc_train: 0.9833 loss_val: 0.9131 acc_val: 0.7300 time: 0.0955s\n",
            "161\n",
            "Epoch: 0741 loss_train: 0.2105 acc_train: 0.9833 loss_val: 0.9153 acc_val: 0.7260 time: 0.0994s\n",
            "162\n",
            "Epoch: 0742 loss_train: 0.2177 acc_train: 0.9833 loss_val: 0.9210 acc_val: 0.7260 time: 0.0957s\n",
            "163\n",
            "Epoch: 0743 loss_train: 0.2171 acc_train: 0.9917 loss_val: 0.9248 acc_val: 0.7220 time: 0.0950s\n",
            "164\n",
            "Epoch: 0744 loss_train: 0.2360 acc_train: 0.9583 loss_val: 0.9230 acc_val: 0.7220 time: 0.1051s\n",
            "165\n",
            "Epoch: 0745 loss_train: 0.2228 acc_train: 0.9750 loss_val: 0.9151 acc_val: 0.7260 time: 0.0968s\n",
            "166\n",
            "Epoch: 0746 loss_train: 0.2219 acc_train: 0.9667 loss_val: 0.9084 acc_val: 0.7300 time: 0.0958s\n",
            "167\n",
            "Epoch: 0747 loss_train: 0.2196 acc_train: 0.9750 loss_val: 0.9052 acc_val: 0.7320 time: 0.1087s\n",
            "168\n",
            "Epoch: 0748 loss_train: 0.2206 acc_train: 0.9500 loss_val: 0.9079 acc_val: 0.7300 time: 0.1010s\n",
            "169\n",
            "Epoch: 0749 loss_train: 0.2042 acc_train: 0.9833 loss_val: 0.9107 acc_val: 0.7300 time: 0.0975s\n",
            "170\n",
            "Epoch: 0750 loss_train: 0.2117 acc_train: 0.9667 loss_val: 0.9154 acc_val: 0.7200 time: 0.1001s\n",
            "171\n",
            "Epoch: 0751 loss_train: 0.2283 acc_train: 0.9667 loss_val: 0.9199 acc_val: 0.7220 time: 0.0977s\n",
            "172\n",
            "Epoch: 0752 loss_train: 0.2233 acc_train: 0.9750 loss_val: 0.9259 acc_val: 0.7180 time: 0.0996s\n",
            "173\n",
            "Epoch: 0753 loss_train: 0.2245 acc_train: 0.9667 loss_val: 0.9257 acc_val: 0.7180 time: 0.0952s\n",
            "174\n",
            "Epoch: 0754 loss_train: 0.2293 acc_train: 0.9667 loss_val: 0.9190 acc_val: 0.7160 time: 0.0967s\n",
            "175\n",
            "Epoch: 0755 loss_train: 0.2276 acc_train: 0.9750 loss_val: 0.9160 acc_val: 0.7200 time: 0.0992s\n",
            "176\n",
            "Epoch: 0756 loss_train: 0.2110 acc_train: 0.9583 loss_val: 0.9165 acc_val: 0.7160 time: 0.0956s\n",
            "177\n",
            "Epoch: 0757 loss_train: 0.2059 acc_train: 0.9917 loss_val: 0.9154 acc_val: 0.7200 time: 0.0988s\n",
            "178\n",
            "Epoch: 0758 loss_train: 0.2423 acc_train: 0.9750 loss_val: 0.9117 acc_val: 0.7280 time: 0.1073s\n",
            "179\n",
            "Epoch: 0759 loss_train: 0.2157 acc_train: 0.9750 loss_val: 0.9085 acc_val: 0.7240 time: 0.0961s\n",
            "180\n",
            "Epoch: 0760 loss_train: 0.2139 acc_train: 0.9667 loss_val: 0.9109 acc_val: 0.7240 time: 0.0983s\n",
            "181\n",
            "Epoch: 0761 loss_train: 0.2224 acc_train: 0.9750 loss_val: 0.9166 acc_val: 0.7200 time: 0.0955s\n",
            "182\n",
            "Epoch: 0762 loss_train: 0.2155 acc_train: 0.9917 loss_val: 0.9213 acc_val: 0.7200 time: 0.0975s\n",
            "183\n",
            "Epoch: 0763 loss_train: 0.2422 acc_train: 0.9667 loss_val: 0.9227 acc_val: 0.7240 time: 0.0966s\n",
            "184\n",
            "Epoch: 0764 loss_train: 0.2378 acc_train: 0.9583 loss_val: 0.9212 acc_val: 0.7200 time: 0.0963s\n",
            "185\n",
            "Epoch: 0765 loss_train: 0.2386 acc_train: 0.9750 loss_val: 0.9209 acc_val: 0.7180 time: 0.0995s\n",
            "186\n",
            "Epoch: 0766 loss_train: 0.2310 acc_train: 0.9583 loss_val: 0.9175 acc_val: 0.7200 time: 0.0963s\n",
            "187\n",
            "Epoch: 0767 loss_train: 0.2207 acc_train: 0.9833 loss_val: 0.9113 acc_val: 0.7240 time: 0.0968s\n",
            "188\n",
            "Epoch: 0768 loss_train: 0.2523 acc_train: 0.9417 loss_val: 0.9074 acc_val: 0.7280 time: 0.1024s\n",
            "189\n",
            "Epoch: 0769 loss_train: 0.2293 acc_train: 0.9500 loss_val: 0.9079 acc_val: 0.7260 time: 0.0981s\n",
            "190\n",
            "Epoch: 0770 loss_train: 0.2252 acc_train: 0.9833 loss_val: 0.9149 acc_val: 0.7220 time: 0.0989s\n",
            "191\n",
            "Epoch: 0771 loss_train: 0.2281 acc_train: 0.9667 loss_val: 0.9234 acc_val: 0.7220 time: 0.0960s\n",
            "192\n",
            "Epoch: 0772 loss_train: 0.2357 acc_train: 0.9583 loss_val: 0.9258 acc_val: 0.7240 time: 0.0955s\n",
            "193\n",
            "Epoch: 0773 loss_train: 0.2391 acc_train: 0.9750 loss_val: 0.9226 acc_val: 0.7220 time: 0.1026s\n",
            "194\n",
            "Epoch: 0774 loss_train: 0.2254 acc_train: 0.9917 loss_val: 0.9209 acc_val: 0.7240 time: 0.0981s\n",
            "195\n",
            "Epoch: 0775 loss_train: 0.2166 acc_train: 0.9750 loss_val: 0.9186 acc_val: 0.7320 time: 0.0968s\n",
            "196\n",
            "Epoch: 0776 loss_train: 0.2159 acc_train: 0.9667 loss_val: 0.9149 acc_val: 0.7280 time: 0.0993s\n",
            "197\n",
            "Epoch: 0777 loss_train: 0.2173 acc_train: 0.9750 loss_val: 0.9144 acc_val: 0.7320 time: 0.0951s\n",
            "198\n",
            "Epoch: 0778 loss_train: 0.2251 acc_train: 0.9833 loss_val: 0.9162 acc_val: 0.7360 time: 0.1015s\n",
            "199\n",
            "Early stop! Min loss:  0.8968355059623718 , Max accuracy:  0.738\n",
            "Early stop model validation loss:  0.8968355059623718 , accuracy:  0.73\n",
            "Optimization Finished!\n",
            "Total time elapsed: 78.9926s\n",
            "Loading 577th epoch\n",
            "Test set results: loss= 0.8787 accuracy= 0.7180\n",
            "Epoch: 0001 loss_train: 0.2609 acc_train: 0.9667 loss_val: 0.9011 acc_val: 0.7220 time: 0.0960s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.2531 acc_train: 0.9833 loss_val: 0.9090 acc_val: 0.7180 time: 0.0964s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.2466 acc_train: 0.9667 loss_val: 0.9114 acc_val: 0.7200 time: 0.1005s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.2654 acc_train: 0.9500 loss_val: 0.9120 acc_val: 0.7220 time: 0.0960s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.2610 acc_train: 0.9583 loss_val: 0.9062 acc_val: 0.7260 time: 0.1004s\n",
            "0\n",
            "Epoch: 0006 loss_train: 0.2591 acc_train: 0.9750 loss_val: 0.8990 acc_val: 0.7280 time: 0.0958s\n",
            "0\n",
            "Epoch: 0007 loss_train: 0.2576 acc_train: 0.9583 loss_val: 0.8880 acc_val: 0.7260 time: 0.1026s\n",
            "0\n",
            "Epoch: 0008 loss_train: 0.2440 acc_train: 0.9583 loss_val: 0.8779 acc_val: 0.7280 time: 0.0996s\n",
            "0\n",
            "Epoch: 0009 loss_train: 0.2580 acc_train: 0.9750 loss_val: 0.8785 acc_val: 0.7280 time: 0.0960s\n",
            "0\n",
            "Epoch: 0010 loss_train: 0.2483 acc_train: 0.9667 loss_val: 0.8853 acc_val: 0.7240 time: 0.1010s\n",
            "0\n",
            "Epoch: 0011 loss_train: 0.2639 acc_train: 0.9833 loss_val: 0.8927 acc_val: 0.7200 time: 0.0953s\n",
            "1\n",
            "Epoch: 0012 loss_train: 0.2470 acc_train: 0.9750 loss_val: 0.8943 acc_val: 0.7120 time: 0.0981s\n",
            "2\n",
            "Epoch: 0013 loss_train: 0.2380 acc_train: 0.9833 loss_val: 0.8908 acc_val: 0.7260 time: 0.0966s\n",
            "3\n",
            "Epoch: 0014 loss_train: 0.2450 acc_train: 0.9583 loss_val: 0.8861 acc_val: 0.7280 time: 0.0955s\n",
            "4\n",
            "Epoch: 0015 loss_train: 0.2444 acc_train: 0.9750 loss_val: 0.8814 acc_val: 0.7280 time: 0.0989s\n",
            "0\n",
            "Epoch: 0016 loss_train: 0.2527 acc_train: 0.9750 loss_val: 0.8771 acc_val: 0.7260 time: 0.0957s\n",
            "0\n",
            "Epoch: 0017 loss_train: 0.2440 acc_train: 0.9500 loss_val: 0.8761 acc_val: 0.7340 time: 0.0957s\n",
            "0\n",
            "Epoch: 0018 loss_train: 0.2462 acc_train: 0.9417 loss_val: 0.8759 acc_val: 0.7360 time: 0.0980s\n",
            "0\n",
            "Epoch: 0019 loss_train: 0.2525 acc_train: 0.9750 loss_val: 0.8732 acc_val: 0.7320 time: 0.0947s\n",
            "0\n",
            "Epoch: 0020 loss_train: 0.2512 acc_train: 0.9667 loss_val: 0.8710 acc_val: 0.7360 time: 0.1069s\n",
            "0\n",
            "Epoch: 0021 loss_train: 0.2459 acc_train: 0.9417 loss_val: 0.8706 acc_val: 0.7320 time: 0.0963s\n",
            "0\n",
            "Epoch: 0022 loss_train: 0.2561 acc_train: 0.9667 loss_val: 0.8729 acc_val: 0.7280 time: 0.0958s\n",
            "0\n",
            "Epoch: 0023 loss_train: 0.2194 acc_train: 0.9750 loss_val: 0.8767 acc_val: 0.7340 time: 0.1014s\n",
            "1\n",
            "Epoch: 0024 loss_train: 0.2451 acc_train: 0.9750 loss_val: 0.8777 acc_val: 0.7320 time: 0.0982s\n",
            "2\n",
            "Epoch: 0025 loss_train: 0.2426 acc_train: 0.9667 loss_val: 0.8795 acc_val: 0.7320 time: 0.0994s\n",
            "3\n",
            "Epoch: 0026 loss_train: 0.2434 acc_train: 0.9667 loss_val: 0.8770 acc_val: 0.7300 time: 0.0959s\n",
            "4\n",
            "Epoch: 0027 loss_train: 0.2407 acc_train: 0.9667 loss_val: 0.8689 acc_val: 0.7300 time: 0.0968s\n",
            "5\n",
            "Epoch: 0028 loss_train: 0.2547 acc_train: 0.9750 loss_val: 0.8613 acc_val: 0.7300 time: 0.0975s\n",
            "0\n",
            "Epoch: 0029 loss_train: 0.2568 acc_train: 0.9667 loss_val: 0.8567 acc_val: 0.7300 time: 0.0973s\n",
            "0\n",
            "Epoch: 0030 loss_train: 0.2354 acc_train: 0.9750 loss_val: 0.8604 acc_val: 0.7320 time: 0.1004s\n",
            "0\n",
            "Epoch: 0031 loss_train: 0.2359 acc_train: 0.9833 loss_val: 0.8684 acc_val: 0.7300 time: 0.0977s\n",
            "1\n",
            "Epoch: 0032 loss_train: 0.2307 acc_train: 0.9833 loss_val: 0.8734 acc_val: 0.7340 time: 0.0953s\n",
            "2\n",
            "Epoch: 0033 loss_train: 0.2499 acc_train: 0.9583 loss_val: 0.8766 acc_val: 0.7320 time: 0.1035s\n",
            "3\n",
            "Epoch: 0034 loss_train: 0.2507 acc_train: 0.9583 loss_val: 0.8746 acc_val: 0.7280 time: 0.0991s\n",
            "4\n",
            "Epoch: 0035 loss_train: 0.2461 acc_train: 0.9500 loss_val: 0.8700 acc_val: 0.7340 time: 0.0974s\n",
            "5\n",
            "Epoch: 0036 loss_train: 0.2369 acc_train: 0.9750 loss_val: 0.8635 acc_val: 0.7340 time: 0.1023s\n",
            "6\n",
            "Epoch: 0037 loss_train: 0.2633 acc_train: 0.9417 loss_val: 0.8596 acc_val: 0.7340 time: 0.0955s\n",
            "7\n",
            "Epoch: 0038 loss_train: 0.2562 acc_train: 0.9750 loss_val: 0.8592 acc_val: 0.7340 time: 0.0993s\n",
            "8\n",
            "Epoch: 0039 loss_train: 0.2395 acc_train: 0.9583 loss_val: 0.8636 acc_val: 0.7300 time: 0.1003s\n",
            "9\n",
            "Epoch: 0040 loss_train: 0.2354 acc_train: 0.9833 loss_val: 0.8712 acc_val: 0.7300 time: 0.1005s\n",
            "10\n",
            "Epoch: 0041 loss_train: 0.2382 acc_train: 0.9667 loss_val: 0.8794 acc_val: 0.7300 time: 0.0985s\n",
            "11\n",
            "Epoch: 0042 loss_train: 0.2531 acc_train: 0.9750 loss_val: 0.8817 acc_val: 0.7300 time: 0.0977s\n",
            "12\n",
            "Epoch: 0043 loss_train: 0.2378 acc_train: 0.9667 loss_val: 0.8809 acc_val: 0.7300 time: 0.0981s\n",
            "13\n",
            "Epoch: 0044 loss_train: 0.2563 acc_train: 0.9750 loss_val: 0.8754 acc_val: 0.7300 time: 0.0956s\n",
            "14\n",
            "Epoch: 0045 loss_train: 0.2378 acc_train: 0.9750 loss_val: 0.8693 acc_val: 0.7300 time: 0.0973s\n",
            "15\n",
            "Epoch: 0046 loss_train: 0.2304 acc_train: 0.9750 loss_val: 0.8662 acc_val: 0.7300 time: 0.0985s\n",
            "16\n",
            "Epoch: 0047 loss_train: 0.2465 acc_train: 0.9833 loss_val: 0.8682 acc_val: 0.7300 time: 0.0976s\n",
            "17\n",
            "Epoch: 0048 loss_train: 0.2478 acc_train: 0.9583 loss_val: 0.8726 acc_val: 0.7340 time: 0.0948s\n",
            "18\n",
            "Epoch: 0049 loss_train: 0.2542 acc_train: 0.9333 loss_val: 0.8811 acc_val: 0.7340 time: 0.1039s\n",
            "19\n",
            "Epoch: 0050 loss_train: 0.2352 acc_train: 0.9583 loss_val: 0.8868 acc_val: 0.7240 time: 0.1002s\n",
            "20\n",
            "Epoch: 0051 loss_train: 0.2540 acc_train: 0.9667 loss_val: 0.8871 acc_val: 0.7260 time: 0.0970s\n",
            "21\n",
            "Epoch: 0052 loss_train: 0.2291 acc_train: 0.9500 loss_val: 0.8791 acc_val: 0.7320 time: 0.0999s\n",
            "22\n",
            "Epoch: 0053 loss_train: 0.2319 acc_train: 0.9583 loss_val: 0.8719 acc_val: 0.7340 time: 0.0950s\n",
            "23\n",
            "Epoch: 0054 loss_train: 0.2445 acc_train: 0.9833 loss_val: 0.8680 acc_val: 0.7420 time: 0.1008s\n",
            "24\n",
            "Epoch: 0055 loss_train: 0.2398 acc_train: 0.9750 loss_val: 0.8673 acc_val: 0.7400 time: 0.0962s\n",
            "0\n",
            "Epoch: 0056 loss_train: 0.2515 acc_train: 0.9833 loss_val: 0.8701 acc_val: 0.7400 time: 0.0959s\n",
            "1\n",
            "Epoch: 0057 loss_train: 0.2406 acc_train: 0.9500 loss_val: 0.8758 acc_val: 0.7360 time: 0.0996s\n",
            "2\n",
            "Epoch: 0058 loss_train: 0.2258 acc_train: 0.9750 loss_val: 0.8814 acc_val: 0.7260 time: 0.0952s\n",
            "3\n",
            "Epoch: 0059 loss_train: 0.2389 acc_train: 0.9750 loss_val: 0.8828 acc_val: 0.7240 time: 0.0985s\n",
            "4\n",
            "Epoch: 0060 loss_train: 0.2488 acc_train: 0.9750 loss_val: 0.8822 acc_val: 0.7300 time: 0.1030s\n",
            "5\n",
            "Epoch: 0061 loss_train: 0.2502 acc_train: 0.9417 loss_val: 0.8792 acc_val: 0.7300 time: 0.0958s\n",
            "6\n",
            "Epoch: 0062 loss_train: 0.2484 acc_train: 0.9500 loss_val: 0.8745 acc_val: 0.7320 time: 0.1041s\n",
            "7\n",
            "Epoch: 0063 loss_train: 0.2556 acc_train: 0.9667 loss_val: 0.8737 acc_val: 0.7340 time: 0.0956s\n",
            "8\n",
            "Epoch: 0064 loss_train: 0.2455 acc_train: 0.9917 loss_val: 0.8744 acc_val: 0.7360 time: 0.0959s\n",
            "9\n",
            "Epoch: 0065 loss_train: 0.2289 acc_train: 0.9750 loss_val: 0.8744 acc_val: 0.7380 time: 0.0988s\n",
            "10\n",
            "Epoch: 0066 loss_train: 0.2354 acc_train: 0.9417 loss_val: 0.8716 acc_val: 0.7340 time: 0.0950s\n",
            "11\n",
            "Epoch: 0067 loss_train: 0.2317 acc_train: 0.9750 loss_val: 0.8718 acc_val: 0.7320 time: 0.0955s\n",
            "12\n",
            "Epoch: 0068 loss_train: 0.2481 acc_train: 0.9917 loss_val: 0.8735 acc_val: 0.7320 time: 0.1005s\n",
            "13\n",
            "Epoch: 0069 loss_train: 0.2487 acc_train: 0.9917 loss_val: 0.8748 acc_val: 0.7320 time: 0.0955s\n",
            "14\n",
            "Epoch: 0070 loss_train: 0.2316 acc_train: 0.9833 loss_val: 0.8737 acc_val: 0.7320 time: 0.0951s\n",
            "15\n",
            "Epoch: 0071 loss_train: 0.2355 acc_train: 0.9500 loss_val: 0.8745 acc_val: 0.7360 time: 0.1042s\n",
            "16\n",
            "Epoch: 0072 loss_train: 0.2436 acc_train: 0.9917 loss_val: 0.8762 acc_val: 0.7380 time: 0.0954s\n",
            "17\n",
            "Epoch: 0073 loss_train: 0.2346 acc_train: 0.9917 loss_val: 0.8765 acc_val: 0.7300 time: 0.0953s\n",
            "18\n",
            "Epoch: 0074 loss_train: 0.2521 acc_train: 0.9833 loss_val: 0.8716 acc_val: 0.7320 time: 0.1081s\n",
            "19\n",
            "Epoch: 0075 loss_train: 0.2616 acc_train: 0.9667 loss_val: 0.8721 acc_val: 0.7280 time: 0.1011s\n",
            "20\n",
            "Epoch: 0076 loss_train: 0.2478 acc_train: 0.9667 loss_val: 0.8785 acc_val: 0.7300 time: 0.1073s\n",
            "21\n",
            "Epoch: 0077 loss_train: 0.2430 acc_train: 0.9500 loss_val: 0.8791 acc_val: 0.7280 time: 0.0995s\n",
            "22\n",
            "Epoch: 0078 loss_train: 0.2462 acc_train: 0.9583 loss_val: 0.8777 acc_val: 0.7260 time: 0.0950s\n",
            "23\n",
            "Epoch: 0079 loss_train: 0.2371 acc_train: 0.9333 loss_val: 0.8722 acc_val: 0.7320 time: 0.0988s\n",
            "24\n",
            "Epoch: 0080 loss_train: 0.2565 acc_train: 0.9583 loss_val: 0.8672 acc_val: 0.7380 time: 0.0963s\n",
            "25\n",
            "Epoch: 0081 loss_train: 0.2187 acc_train: 1.0000 loss_val: 0.8635 acc_val: 0.7400 time: 0.1002s\n",
            "26\n",
            "Epoch: 0082 loss_train: 0.2554 acc_train: 0.9500 loss_val: 0.8666 acc_val: 0.7360 time: 0.1004s\n",
            "27\n",
            "Epoch: 0083 loss_train: 0.2484 acc_train: 0.9833 loss_val: 0.8748 acc_val: 0.7320 time: 0.0951s\n",
            "28\n",
            "Epoch: 0084 loss_train: 0.2420 acc_train: 0.9833 loss_val: 0.8800 acc_val: 0.7260 time: 0.0979s\n",
            "29\n",
            "Epoch: 0085 loss_train: 0.2480 acc_train: 0.9583 loss_val: 0.8805 acc_val: 0.7300 time: 0.0955s\n",
            "30\n",
            "Epoch: 0086 loss_train: 0.2312 acc_train: 0.9833 loss_val: 0.8740 acc_val: 0.7280 time: 0.0983s\n",
            "31\n",
            "Epoch: 0087 loss_train: 0.2273 acc_train: 0.9750 loss_val: 0.8690 acc_val: 0.7300 time: 0.1035s\n",
            "32\n",
            "Epoch: 0088 loss_train: 0.2382 acc_train: 0.9833 loss_val: 0.8667 acc_val: 0.7340 time: 0.0973s\n",
            "33\n",
            "Epoch: 0089 loss_train: 0.2485 acc_train: 0.9750 loss_val: 0.8691 acc_val: 0.7260 time: 0.0952s\n",
            "34\n",
            "Epoch: 0090 loss_train: 0.2447 acc_train: 0.9667 loss_val: 0.8755 acc_val: 0.7300 time: 0.1009s\n",
            "35\n",
            "Epoch: 0091 loss_train: 0.2428 acc_train: 0.9917 loss_val: 0.8828 acc_val: 0.7280 time: 0.1008s\n",
            "36\n",
            "Epoch: 0092 loss_train: 0.2398 acc_train: 0.9667 loss_val: 0.8818 acc_val: 0.7260 time: 0.0997s\n",
            "37\n",
            "Epoch: 0093 loss_train: 0.2422 acc_train: 0.9750 loss_val: 0.8758 acc_val: 0.7320 time: 0.0989s\n",
            "38\n",
            "Epoch: 0094 loss_train: 0.2287 acc_train: 0.9583 loss_val: 0.8695 acc_val: 0.7340 time: 0.0953s\n",
            "39\n",
            "Epoch: 0095 loss_train: 0.2478 acc_train: 0.9500 loss_val: 0.8676 acc_val: 0.7360 time: 0.0983s\n",
            "40\n",
            "Epoch: 0096 loss_train: 0.2627 acc_train: 0.9500 loss_val: 0.8685 acc_val: 0.7360 time: 0.0962s\n",
            "41\n",
            "Epoch: 0097 loss_train: 0.2461 acc_train: 0.9583 loss_val: 0.8683 acc_val: 0.7320 time: 0.0957s\n",
            "42\n",
            "Epoch: 0098 loss_train: 0.2389 acc_train: 0.9500 loss_val: 0.8721 acc_val: 0.7300 time: 0.1017s\n",
            "43\n",
            "Epoch: 0099 loss_train: 0.2338 acc_train: 0.9750 loss_val: 0.8770 acc_val: 0.7280 time: 0.1013s\n",
            "44\n",
            "Epoch: 0100 loss_train: 0.2515 acc_train: 0.9750 loss_val: 0.8801 acc_val: 0.7280 time: 0.0949s\n",
            "45\n",
            "Epoch: 0101 loss_train: 0.2350 acc_train: 0.9667 loss_val: 0.8778 acc_val: 0.7320 time: 0.1017s\n",
            "46\n",
            "Epoch: 0102 loss_train: 0.2366 acc_train: 0.9500 loss_val: 0.8751 acc_val: 0.7320 time: 0.0977s\n",
            "47\n",
            "Epoch: 0103 loss_train: 0.2438 acc_train: 0.9750 loss_val: 0.8745 acc_val: 0.7340 time: 0.0953s\n",
            "48\n",
            "Epoch: 0104 loss_train: 0.2527 acc_train: 0.9667 loss_val: 0.8770 acc_val: 0.7300 time: 0.1043s\n",
            "49\n",
            "Epoch: 0105 loss_train: 0.2622 acc_train: 0.9500 loss_val: 0.8808 acc_val: 0.7280 time: 0.0974s\n",
            "50\n",
            "Epoch: 0106 loss_train: 0.2360 acc_train: 0.9583 loss_val: 0.8821 acc_val: 0.7260 time: 0.0958s\n",
            "51\n",
            "Epoch: 0107 loss_train: 0.2540 acc_train: 0.9583 loss_val: 0.8806 acc_val: 0.7260 time: 0.0991s\n",
            "52\n",
            "Epoch: 0108 loss_train: 0.2434 acc_train: 0.9667 loss_val: 0.8738 acc_val: 0.7320 time: 0.0953s\n",
            "53\n",
            "Epoch: 0109 loss_train: 0.2398 acc_train: 0.9833 loss_val: 0.8667 acc_val: 0.7320 time: 0.0946s\n",
            "54\n",
            "Epoch: 0110 loss_train: 0.2378 acc_train: 0.9750 loss_val: 0.8646 acc_val: 0.7360 time: 0.1048s\n",
            "55\n",
            "Epoch: 0111 loss_train: 0.2491 acc_train: 0.9583 loss_val: 0.8664 acc_val: 0.7320 time: 0.0988s\n",
            "56\n",
            "Epoch: 0112 loss_train: 0.2527 acc_train: 0.9583 loss_val: 0.8723 acc_val: 0.7320 time: 0.0970s\n",
            "57\n",
            "Epoch: 0113 loss_train: 0.2509 acc_train: 0.9750 loss_val: 0.8776 acc_val: 0.7280 time: 0.1013s\n",
            "58\n",
            "Epoch: 0114 loss_train: 0.2464 acc_train: 0.9500 loss_val: 0.8811 acc_val: 0.7280 time: 0.0951s\n",
            "59\n",
            "Epoch: 0115 loss_train: 0.2220 acc_train: 0.9667 loss_val: 0.8760 acc_val: 0.7260 time: 0.0988s\n",
            "60\n",
            "Epoch: 0116 loss_train: 0.2379 acc_train: 0.9833 loss_val: 0.8690 acc_val: 0.7280 time: 0.0958s\n",
            "61\n",
            "Epoch: 0117 loss_train: 0.2347 acc_train: 0.9917 loss_val: 0.8668 acc_val: 0.7320 time: 0.0984s\n",
            "62\n",
            "Epoch: 0118 loss_train: 0.2390 acc_train: 0.9583 loss_val: 0.8697 acc_val: 0.7320 time: 0.0984s\n",
            "63\n",
            "Epoch: 0119 loss_train: 0.2461 acc_train: 0.9583 loss_val: 0.8737 acc_val: 0.7300 time: 0.0952s\n",
            "64\n",
            "Epoch: 0120 loss_train: 0.2423 acc_train: 0.9500 loss_val: 0.8758 acc_val: 0.7280 time: 0.0973s\n",
            "65\n",
            "Epoch: 0121 loss_train: 0.2252 acc_train: 0.9833 loss_val: 0.8774 acc_val: 0.7260 time: 0.1002s\n",
            "66\n",
            "Epoch: 0122 loss_train: 0.2291 acc_train: 0.9583 loss_val: 0.8779 acc_val: 0.7260 time: 0.0984s\n",
            "67\n",
            "Epoch: 0123 loss_train: 0.2636 acc_train: 0.9333 loss_val: 0.8742 acc_val: 0.7300 time: 0.0951s\n",
            "68\n",
            "Epoch: 0124 loss_train: 0.2261 acc_train: 0.9667 loss_val: 0.8709 acc_val: 0.7320 time: 0.1032s\n",
            "69\n",
            "Epoch: 0125 loss_train: 0.2341 acc_train: 0.9583 loss_val: 0.8690 acc_val: 0.7300 time: 0.0957s\n",
            "70\n",
            "Epoch: 0126 loss_train: 0.2450 acc_train: 0.9833 loss_val: 0.8682 acc_val: 0.7300 time: 0.0951s\n",
            "71\n",
            "Epoch: 0127 loss_train: 0.2418 acc_train: 0.9917 loss_val: 0.8696 acc_val: 0.7320 time: 0.0997s\n",
            "72\n",
            "Epoch: 0128 loss_train: 0.2434 acc_train: 0.9833 loss_val: 0.8677 acc_val: 0.7300 time: 0.0949s\n",
            "73\n",
            "Epoch: 0129 loss_train: 0.2459 acc_train: 0.9583 loss_val: 0.8684 acc_val: 0.7300 time: 0.0950s\n",
            "74\n",
            "Epoch: 0130 loss_train: 0.2358 acc_train: 0.9667 loss_val: 0.8697 acc_val: 0.7360 time: 0.0981s\n",
            "75\n",
            "Epoch: 0131 loss_train: 0.2148 acc_train: 0.9833 loss_val: 0.8739 acc_val: 0.7340 time: 0.0993s\n",
            "76\n",
            "Epoch: 0132 loss_train: 0.2573 acc_train: 0.9500 loss_val: 0.8745 acc_val: 0.7340 time: 0.0965s\n",
            "77\n",
            "Epoch: 0133 loss_train: 0.2600 acc_train: 0.9583 loss_val: 0.8751 acc_val: 0.7340 time: 0.0997s\n",
            "78\n",
            "Epoch: 0134 loss_train: 0.2508 acc_train: 0.9750 loss_val: 0.8731 acc_val: 0.7260 time: 0.0949s\n",
            "79\n",
            "Epoch: 0135 loss_train: 0.2335 acc_train: 0.9833 loss_val: 0.8741 acc_val: 0.7260 time: 0.0978s\n",
            "80\n",
            "Epoch: 0136 loss_train: 0.2457 acc_train: 0.9667 loss_val: 0.8741 acc_val: 0.7280 time: 0.0952s\n",
            "81\n",
            "Epoch: 0137 loss_train: 0.2365 acc_train: 0.9667 loss_val: 0.8731 acc_val: 0.7320 time: 0.0960s\n",
            "82\n",
            "Epoch: 0138 loss_train: 0.2380 acc_train: 0.9750 loss_val: 0.8700 acc_val: 0.7300 time: 0.1025s\n",
            "83\n",
            "Epoch: 0139 loss_train: 0.2480 acc_train: 0.9667 loss_val: 0.8685 acc_val: 0.7340 time: 0.0972s\n",
            "84\n",
            "Epoch: 0140 loss_train: 0.2429 acc_train: 0.9833 loss_val: 0.8663 acc_val: 0.7340 time: 0.1021s\n",
            "85\n",
            "Epoch: 0141 loss_train: 0.2455 acc_train: 0.9833 loss_val: 0.8661 acc_val: 0.7340 time: 0.1037s\n",
            "86\n",
            "Epoch: 0142 loss_train: 0.2418 acc_train: 0.9500 loss_val: 0.8696 acc_val: 0.7320 time: 0.0973s\n",
            "87\n",
            "Epoch: 0143 loss_train: 0.2358 acc_train: 0.9500 loss_val: 0.8772 acc_val: 0.7280 time: 0.0991s\n",
            "88\n",
            "Epoch: 0144 loss_train: 0.2329 acc_train: 0.9750 loss_val: 0.8880 acc_val: 0.7240 time: 0.0949s\n",
            "89\n",
            "Epoch: 0145 loss_train: 0.2398 acc_train: 0.9750 loss_val: 0.8901 acc_val: 0.7260 time: 0.0968s\n",
            "90\n",
            "Epoch: 0146 loss_train: 0.2468 acc_train: 0.9750 loss_val: 0.8800 acc_val: 0.7240 time: 0.1025s\n",
            "91\n",
            "Epoch: 0147 loss_train: 0.2371 acc_train: 0.9667 loss_val: 0.8698 acc_val: 0.7300 time: 0.0972s\n",
            "92\n",
            "Epoch: 0148 loss_train: 0.2438 acc_train: 0.9667 loss_val: 0.8655 acc_val: 0.7380 time: 0.0970s\n",
            "93\n",
            "Epoch: 0149 loss_train: 0.2394 acc_train: 0.9833 loss_val: 0.8663 acc_val: 0.7400 time: 0.1068s\n",
            "94\n",
            "Epoch: 0150 loss_train: 0.2270 acc_train: 0.9667 loss_val: 0.8691 acc_val: 0.7360 time: 0.0965s\n",
            "95\n",
            "Epoch: 0151 loss_train: 0.2499 acc_train: 0.9667 loss_val: 0.8724 acc_val: 0.7300 time: 0.1035s\n",
            "96\n",
            "Epoch: 0152 loss_train: 0.2562 acc_train: 0.9583 loss_val: 0.8729 acc_val: 0.7260 time: 0.0974s\n",
            "97\n",
            "Epoch: 0153 loss_train: 0.2437 acc_train: 0.9500 loss_val: 0.8731 acc_val: 0.7260 time: 0.0971s\n",
            "98\n",
            "Epoch: 0154 loss_train: 0.2479 acc_train: 0.9333 loss_val: 0.8711 acc_val: 0.7280 time: 0.0996s\n",
            "99\n",
            "Epoch: 0155 loss_train: 0.2447 acc_train: 0.9833 loss_val: 0.8645 acc_val: 0.7340 time: 0.0964s\n",
            "100\n",
            "Epoch: 0156 loss_train: 0.2364 acc_train: 0.9583 loss_val: 0.8617 acc_val: 0.7320 time: 0.1012s\n",
            "101\n",
            "Epoch: 0157 loss_train: 0.2443 acc_train: 0.9583 loss_val: 0.8590 acc_val: 0.7340 time: 0.0974s\n",
            "102\n",
            "Epoch: 0158 loss_train: 0.2506 acc_train: 0.9833 loss_val: 0.8594 acc_val: 0.7340 time: 0.0979s\n",
            "103\n",
            "Epoch: 0159 loss_train: 0.2381 acc_train: 0.9750 loss_val: 0.8660 acc_val: 0.7340 time: 0.1006s\n",
            "104\n",
            "Epoch: 0160 loss_train: 0.2318 acc_train: 0.9833 loss_val: 0.8751 acc_val: 0.7280 time: 0.0960s\n",
            "105\n",
            "Epoch: 0161 loss_train: 0.2390 acc_train: 0.9667 loss_val: 0.8775 acc_val: 0.7260 time: 0.1006s\n",
            "106\n",
            "Epoch: 0162 loss_train: 0.2482 acc_train: 0.9500 loss_val: 0.8750 acc_val: 0.7280 time: 0.1015s\n",
            "107\n",
            "Epoch: 0163 loss_train: 0.2379 acc_train: 0.9667 loss_val: 0.8723 acc_val: 0.7280 time: 0.0950s\n",
            "108\n",
            "Epoch: 0164 loss_train: 0.2350 acc_train: 0.9833 loss_val: 0.8721 acc_val: 0.7320 time: 0.0983s\n",
            "109\n",
            "Epoch: 0165 loss_train: 0.2420 acc_train: 0.9667 loss_val: 0.8739 acc_val: 0.7340 time: 0.0970s\n",
            "110\n",
            "Epoch: 0166 loss_train: 0.2265 acc_train: 0.9583 loss_val: 0.8745 acc_val: 0.7340 time: 0.0955s\n",
            "111\n",
            "Epoch: 0167 loss_train: 0.2400 acc_train: 0.9583 loss_val: 0.8780 acc_val: 0.7260 time: 0.1003s\n",
            "112\n",
            "Epoch: 0168 loss_train: 0.2320 acc_train: 0.9833 loss_val: 0.8775 acc_val: 0.7300 time: 0.0976s\n",
            "113\n",
            "Epoch: 0169 loss_train: 0.2597 acc_train: 0.9333 loss_val: 0.8739 acc_val: 0.7280 time: 0.0947s\n",
            "114\n",
            "Epoch: 0170 loss_train: 0.2358 acc_train: 0.9500 loss_val: 0.8696 acc_val: 0.7280 time: 0.0996s\n",
            "115\n",
            "Epoch: 0171 loss_train: 0.2468 acc_train: 0.9583 loss_val: 0.8674 acc_val: 0.7340 time: 0.1000s\n",
            "116\n",
            "Epoch: 0172 loss_train: 0.2465 acc_train: 0.9750 loss_val: 0.8684 acc_val: 0.7360 time: 0.0992s\n",
            "117\n",
            "Epoch: 0173 loss_train: 0.2460 acc_train: 0.9500 loss_val: 0.8734 acc_val: 0.7360 time: 0.1000s\n",
            "118\n",
            "Epoch: 0174 loss_train: 0.2339 acc_train: 0.9667 loss_val: 0.8760 acc_val: 0.7420 time: 0.0951s\n",
            "119\n",
            "Epoch: 0175 loss_train: 0.2286 acc_train: 0.9583 loss_val: 0.8774 acc_val: 0.7340 time: 0.0998s\n",
            "0\n",
            "Epoch: 0176 loss_train: 0.2310 acc_train: 0.9750 loss_val: 0.8787 acc_val: 0.7340 time: 0.0958s\n",
            "1\n",
            "Epoch: 0177 loss_train: 0.2377 acc_train: 0.9833 loss_val: 0.8780 acc_val: 0.7280 time: 0.0953s\n",
            "2\n",
            "Epoch: 0178 loss_train: 0.2383 acc_train: 0.9750 loss_val: 0.8731 acc_val: 0.7300 time: 0.0990s\n",
            "3\n",
            "Epoch: 0179 loss_train: 0.2458 acc_train: 0.9500 loss_val: 0.8706 acc_val: 0.7280 time: 0.1022s\n",
            "4\n",
            "Epoch: 0180 loss_train: 0.2376 acc_train: 0.9667 loss_val: 0.8670 acc_val: 0.7320 time: 0.0973s\n",
            "5\n",
            "Epoch: 0181 loss_train: 0.2366 acc_train: 0.9667 loss_val: 0.8694 acc_val: 0.7340 time: 0.1112s\n",
            "6\n",
            "Epoch: 0182 loss_train: 0.2420 acc_train: 0.9583 loss_val: 0.8728 acc_val: 0.7340 time: 0.1042s\n",
            "7\n",
            "Epoch: 0183 loss_train: 0.2365 acc_train: 0.9667 loss_val: 0.8782 acc_val: 0.7300 time: 0.0962s\n",
            "8\n",
            "Epoch: 0184 loss_train: 0.2290 acc_train: 0.9750 loss_val: 0.8790 acc_val: 0.7320 time: 0.0955s\n",
            "9\n",
            "Epoch: 0185 loss_train: 0.2360 acc_train: 0.9583 loss_val: 0.8780 acc_val: 0.7240 time: 0.1005s\n",
            "10\n",
            "Epoch: 0186 loss_train: 0.2364 acc_train: 0.9583 loss_val: 0.8746 acc_val: 0.7220 time: 0.0960s\n",
            "11\n",
            "Epoch: 0187 loss_train: 0.2432 acc_train: 0.9917 loss_val: 0.8720 acc_val: 0.7220 time: 0.0974s\n",
            "12\n",
            "Epoch: 0188 loss_train: 0.2500 acc_train: 0.9333 loss_val: 0.8696 acc_val: 0.7200 time: 0.1020s\n",
            "13\n",
            "Epoch: 0189 loss_train: 0.2278 acc_train: 0.9583 loss_val: 0.8673 acc_val: 0.7240 time: 0.0952s\n",
            "14\n",
            "Epoch: 0190 loss_train: 0.2418 acc_train: 0.9833 loss_val: 0.8660 acc_val: 0.7340 time: 0.0948s\n",
            "15\n",
            "Epoch: 0191 loss_train: 0.2385 acc_train: 0.9750 loss_val: 0.8699 acc_val: 0.7380 time: 0.1015s\n",
            "16\n",
            "Epoch: 0192 loss_train: 0.2428 acc_train: 0.9833 loss_val: 0.8777 acc_val: 0.7320 time: 0.0982s\n",
            "17\n",
            "Epoch: 0193 loss_train: 0.2317 acc_train: 0.9667 loss_val: 0.8838 acc_val: 0.7280 time: 0.0951s\n",
            "18\n",
            "Epoch: 0194 loss_train: 0.2500 acc_train: 0.9750 loss_val: 0.8831 acc_val: 0.7240 time: 0.1026s\n",
            "19\n",
            "Epoch: 0195 loss_train: 0.2344 acc_train: 0.9917 loss_val: 0.8793 acc_val: 0.7220 time: 0.1000s\n",
            "20\n",
            "Epoch: 0196 loss_train: 0.2221 acc_train: 0.9750 loss_val: 0.8739 acc_val: 0.7240 time: 0.0958s\n",
            "21\n",
            "Epoch: 0197 loss_train: 0.2388 acc_train: 0.9750 loss_val: 0.8678 acc_val: 0.7260 time: 0.1004s\n",
            "22\n",
            "Epoch: 0198 loss_train: 0.2514 acc_train: 0.9750 loss_val: 0.8653 acc_val: 0.7280 time: 0.0954s\n",
            "23\n",
            "Epoch: 0199 loss_train: 0.2336 acc_train: 0.9667 loss_val: 0.8682 acc_val: 0.7300 time: 0.0955s\n",
            "24\n",
            "Epoch: 0200 loss_train: 0.2513 acc_train: 0.9750 loss_val: 0.8737 acc_val: 0.7280 time: 0.1005s\n",
            "25\n",
            "Epoch: 0201 loss_train: 0.2353 acc_train: 0.9417 loss_val: 0.8788 acc_val: 0.7260 time: 0.0954s\n",
            "26\n",
            "Epoch: 0202 loss_train: 0.2244 acc_train: 0.9583 loss_val: 0.8817 acc_val: 0.7260 time: 0.1024s\n",
            "27\n",
            "Epoch: 0203 loss_train: 0.2404 acc_train: 0.9417 loss_val: 0.8824 acc_val: 0.7300 time: 0.1048s\n",
            "28\n",
            "Epoch: 0204 loss_train: 0.2299 acc_train: 0.9750 loss_val: 0.8786 acc_val: 0.7280 time: 0.0986s\n",
            "29\n",
            "Epoch: 0205 loss_train: 0.2330 acc_train: 0.9833 loss_val: 0.8725 acc_val: 0.7280 time: 0.0995s\n",
            "30\n",
            "Epoch: 0206 loss_train: 0.2349 acc_train: 0.9833 loss_val: 0.8680 acc_val: 0.7320 time: 0.0959s\n",
            "31\n",
            "Epoch: 0207 loss_train: 0.2505 acc_train: 0.9667 loss_val: 0.8688 acc_val: 0.7300 time: 0.0974s\n",
            "32\n",
            "Epoch: 0208 loss_train: 0.2535 acc_train: 0.9750 loss_val: 0.8685 acc_val: 0.7300 time: 0.0951s\n",
            "33\n",
            "Epoch: 0209 loss_train: 0.2500 acc_train: 0.9750 loss_val: 0.8693 acc_val: 0.7320 time: 0.0959s\n",
            "34\n",
            "Epoch: 0210 loss_train: 0.2559 acc_train: 0.9417 loss_val: 0.8701 acc_val: 0.7280 time: 0.1004s\n",
            "35\n",
            "Epoch: 0211 loss_train: 0.2278 acc_train: 0.9833 loss_val: 0.8697 acc_val: 0.7280 time: 0.0955s\n",
            "36\n",
            "Epoch: 0212 loss_train: 0.2372 acc_train: 0.9750 loss_val: 0.8681 acc_val: 0.7340 time: 0.1020s\n",
            "37\n",
            "Epoch: 0213 loss_train: 0.2335 acc_train: 0.9667 loss_val: 0.8694 acc_val: 0.7320 time: 0.1019s\n",
            "38\n",
            "Epoch: 0214 loss_train: 0.2437 acc_train: 0.9833 loss_val: 0.8700 acc_val: 0.7300 time: 0.0961s\n",
            "39\n",
            "Epoch: 0215 loss_train: 0.2441 acc_train: 0.9583 loss_val: 0.8688 acc_val: 0.7300 time: 0.1050s\n",
            "40\n",
            "Epoch: 0216 loss_train: 0.2243 acc_train: 0.9833 loss_val: 0.8675 acc_val: 0.7300 time: 0.0958s\n",
            "41\n",
            "Epoch: 0217 loss_train: 0.2365 acc_train: 0.9750 loss_val: 0.8671 acc_val: 0.7300 time: 0.0960s\n",
            "42\n",
            "Epoch: 0218 loss_train: 0.2377 acc_train: 0.9667 loss_val: 0.8676 acc_val: 0.7300 time: 0.1023s\n",
            "43\n",
            "Epoch: 0219 loss_train: 0.2405 acc_train: 0.9500 loss_val: 0.8695 acc_val: 0.7300 time: 0.0952s\n",
            "44\n",
            "Epoch: 0220 loss_train: 0.2427 acc_train: 0.9750 loss_val: 0.8730 acc_val: 0.7300 time: 0.0966s\n",
            "45\n",
            "Epoch: 0221 loss_train: 0.2320 acc_train: 0.9833 loss_val: 0.8749 acc_val: 0.7320 time: 0.0994s\n",
            "46\n",
            "Epoch: 0222 loss_train: 0.2411 acc_train: 0.9833 loss_val: 0.8738 acc_val: 0.7300 time: 0.0999s\n",
            "47\n",
            "Epoch: 0223 loss_train: 0.2497 acc_train: 0.9417 loss_val: 0.8716 acc_val: 0.7300 time: 0.0952s\n",
            "48\n",
            "Epoch: 0224 loss_train: 0.2474 acc_train: 0.9833 loss_val: 0.8690 acc_val: 0.7280 time: 0.1023s\n",
            "49\n",
            "Epoch: 0225 loss_train: 0.2390 acc_train: 0.9500 loss_val: 0.8695 acc_val: 0.7260 time: 0.0984s\n",
            "50\n",
            "Epoch: 0226 loss_train: 0.2395 acc_train: 0.9750 loss_val: 0.8701 acc_val: 0.7280 time: 0.0999s\n",
            "51\n",
            "Epoch: 0227 loss_train: 0.2351 acc_train: 0.9750 loss_val: 0.8705 acc_val: 0.7260 time: 0.0979s\n",
            "52\n",
            "Epoch: 0228 loss_train: 0.2424 acc_train: 0.9667 loss_val: 0.8731 acc_val: 0.7260 time: 0.0951s\n",
            "53\n",
            "Epoch: 0229 loss_train: 0.2424 acc_train: 0.9750 loss_val: 0.8771 acc_val: 0.7280 time: 0.0988s\n",
            "54\n",
            "Epoch: 0230 loss_train: 0.2505 acc_train: 0.9583 loss_val: 0.8766 acc_val: 0.7320 time: 0.0955s\n",
            "55\n",
            "Epoch: 0231 loss_train: 0.2371 acc_train: 0.9667 loss_val: 0.8742 acc_val: 0.7320 time: 0.1011s\n",
            "56\n",
            "Epoch: 0232 loss_train: 0.2445 acc_train: 0.9750 loss_val: 0.8685 acc_val: 0.7300 time: 0.1039s\n",
            "57\n",
            "Epoch: 0233 loss_train: 0.2278 acc_train: 0.9583 loss_val: 0.8655 acc_val: 0.7300 time: 0.0958s\n",
            "58\n",
            "Epoch: 0234 loss_train: 0.2370 acc_train: 0.9833 loss_val: 0.8671 acc_val: 0.7260 time: 0.1025s\n",
            "59\n",
            "Epoch: 0235 loss_train: 0.2332 acc_train: 0.9583 loss_val: 0.8711 acc_val: 0.7240 time: 0.0962s\n",
            "60\n",
            "Epoch: 0236 loss_train: 0.2422 acc_train: 0.9750 loss_val: 0.8755 acc_val: 0.7260 time: 0.0969s\n",
            "61\n",
            "Epoch: 0237 loss_train: 0.2486 acc_train: 0.9917 loss_val: 0.8736 acc_val: 0.7240 time: 0.1021s\n",
            "62\n",
            "Epoch: 0238 loss_train: 0.2425 acc_train: 0.9833 loss_val: 0.8729 acc_val: 0.7280 time: 0.0951s\n",
            "63\n",
            "Epoch: 0239 loss_train: 0.2448 acc_train: 0.9583 loss_val: 0.8712 acc_val: 0.7320 time: 0.0980s\n",
            "64\n",
            "Epoch: 0240 loss_train: 0.2495 acc_train: 0.9750 loss_val: 0.8674 acc_val: 0.7300 time: 0.1010s\n",
            "65\n",
            "Epoch: 0241 loss_train: 0.2419 acc_train: 0.9833 loss_val: 0.8639 acc_val: 0.7340 time: 0.0956s\n",
            "66\n",
            "Epoch: 0242 loss_train: 0.2329 acc_train: 0.9917 loss_val: 0.8628 acc_val: 0.7320 time: 0.1014s\n",
            "67\n",
            "Epoch: 0243 loss_train: 0.2404 acc_train: 0.9667 loss_val: 0.8664 acc_val: 0.7260 time: 0.1003s\n",
            "68\n",
            "Epoch: 0244 loss_train: 0.2481 acc_train: 0.9750 loss_val: 0.8736 acc_val: 0.7300 time: 0.0968s\n",
            "69\n",
            "Epoch: 0245 loss_train: 0.2345 acc_train: 0.9917 loss_val: 0.8824 acc_val: 0.7200 time: 0.1033s\n",
            "70\n",
            "Epoch: 0246 loss_train: 0.2394 acc_train: 0.9750 loss_val: 0.8841 acc_val: 0.7260 time: 0.0955s\n",
            "71\n",
            "Epoch: 0247 loss_train: 0.2551 acc_train: 0.9417 loss_val: 0.8785 acc_val: 0.7280 time: 0.0955s\n",
            "72\n",
            "Epoch: 0248 loss_train: 0.2500 acc_train: 0.9500 loss_val: 0.8703 acc_val: 0.7300 time: 0.1012s\n",
            "73\n",
            "Epoch: 0249 loss_train: 0.2325 acc_train: 0.9667 loss_val: 0.8652 acc_val: 0.7340 time: 0.0952s\n",
            "74\n",
            "Epoch: 0250 loss_train: 0.2468 acc_train: 0.9833 loss_val: 0.8648 acc_val: 0.7340 time: 0.0952s\n",
            "75\n",
            "Epoch: 0251 loss_train: 0.2525 acc_train: 0.9667 loss_val: 0.8680 acc_val: 0.7360 time: 0.1014s\n",
            "76\n",
            "Epoch: 0252 loss_train: 0.2345 acc_train: 0.9833 loss_val: 0.8704 acc_val: 0.7300 time: 0.1026s\n",
            "77\n",
            "Epoch: 0253 loss_train: 0.2403 acc_train: 0.9917 loss_val: 0.8727 acc_val: 0.7280 time: 0.0968s\n",
            "78\n",
            "Epoch: 0254 loss_train: 0.2371 acc_train: 0.9667 loss_val: 0.8723 acc_val: 0.7320 time: 0.1001s\n",
            "79\n",
            "Epoch: 0255 loss_train: 0.2403 acc_train: 0.9833 loss_val: 0.8717 acc_val: 0.7320 time: 0.0952s\n",
            "80\n",
            "Epoch: 0256 loss_train: 0.2438 acc_train: 0.9833 loss_val: 0.8683 acc_val: 0.7300 time: 0.1027s\n",
            "81\n",
            "Epoch: 0257 loss_train: 0.2287 acc_train: 0.9667 loss_val: 0.8675 acc_val: 0.7340 time: 0.0983s\n",
            "82\n",
            "Epoch: 0258 loss_train: 0.2400 acc_train: 0.9667 loss_val: 0.8685 acc_val: 0.7340 time: 0.0953s\n",
            "83\n",
            "Epoch: 0259 loss_train: 0.2430 acc_train: 0.9500 loss_val: 0.8713 acc_val: 0.7340 time: 0.1008s\n",
            "84\n",
            "Epoch: 0260 loss_train: 0.2281 acc_train: 0.9667 loss_val: 0.8719 acc_val: 0.7300 time: 0.0953s\n",
            "85\n",
            "Epoch: 0261 loss_train: 0.2481 acc_train: 0.9500 loss_val: 0.8710 acc_val: 0.7300 time: 0.1005s\n",
            "86\n",
            "Epoch: 0262 loss_train: 0.2492 acc_train: 0.9583 loss_val: 0.8732 acc_val: 0.7280 time: 0.1069s\n",
            "87\n",
            "Epoch: 0263 loss_train: 0.2546 acc_train: 0.9583 loss_val: 0.8741 acc_val: 0.7300 time: 0.0958s\n",
            "88\n",
            "Epoch: 0264 loss_train: 0.2407 acc_train: 0.9667 loss_val: 0.8702 acc_val: 0.7320 time: 0.0994s\n",
            "89\n",
            "Epoch: 0265 loss_train: 0.2543 acc_train: 0.9500 loss_val: 0.8663 acc_val: 0.7340 time: 0.0948s\n",
            "90\n",
            "Epoch: 0266 loss_train: 0.2470 acc_train: 0.9750 loss_val: 0.8668 acc_val: 0.7340 time: 0.0984s\n",
            "91\n",
            "Epoch: 0267 loss_train: 0.2486 acc_train: 0.9667 loss_val: 0.8716 acc_val: 0.7360 time: 0.1028s\n",
            "92\n",
            "Epoch: 0268 loss_train: 0.2475 acc_train: 0.9333 loss_val: 0.8755 acc_val: 0.7340 time: 0.0952s\n",
            "93\n",
            "Epoch: 0269 loss_train: 0.2539 acc_train: 0.9667 loss_val: 0.8796 acc_val: 0.7280 time: 0.0975s\n",
            "94\n",
            "Epoch: 0270 loss_train: 0.2543 acc_train: 0.9500 loss_val: 0.8786 acc_val: 0.7320 time: 0.0987s\n",
            "95\n",
            "Epoch: 0271 loss_train: 0.2411 acc_train: 0.9917 loss_val: 0.8782 acc_val: 0.7260 time: 0.0970s\n",
            "96\n",
            "Epoch: 0272 loss_train: 0.2405 acc_train: 0.9583 loss_val: 0.8770 acc_val: 0.7300 time: 0.0975s\n",
            "97\n",
            "Epoch: 0273 loss_train: 0.2433 acc_train: 0.9583 loss_val: 0.8778 acc_val: 0.7380 time: 0.0995s\n",
            "98\n",
            "Epoch: 0274 loss_train: 0.2404 acc_train: 0.9667 loss_val: 0.8776 acc_val: 0.7380 time: 0.0968s\n",
            "99\n",
            "Epoch: 0275 loss_train: 0.2269 acc_train: 0.9750 loss_val: 0.8754 acc_val: 0.7360 time: 0.1021s\n",
            "100\n",
            "Epoch: 0276 loss_train: 0.2474 acc_train: 0.9417 loss_val: 0.8700 acc_val: 0.7360 time: 0.0976s\n",
            "101\n",
            "Epoch: 0277 loss_train: 0.2398 acc_train: 0.9583 loss_val: 0.8650 acc_val: 0.7340 time: 0.0954s\n",
            "102\n",
            "Epoch: 0278 loss_train: 0.2453 acc_train: 0.9750 loss_val: 0.8653 acc_val: 0.7320 time: 0.1021s\n",
            "103\n",
            "Epoch: 0279 loss_train: 0.2554 acc_train: 0.9500 loss_val: 0.8711 acc_val: 0.7300 time: 0.0955s\n",
            "104\n",
            "Epoch: 0280 loss_train: 0.2301 acc_train: 0.9583 loss_val: 0.8762 acc_val: 0.7280 time: 0.0966s\n",
            "105\n",
            "Epoch: 0281 loss_train: 0.2289 acc_train: 0.9833 loss_val: 0.8762 acc_val: 0.7280 time: 0.1034s\n",
            "106\n",
            "Epoch: 0282 loss_train: 0.2609 acc_train: 0.9667 loss_val: 0.8710 acc_val: 0.7300 time: 0.0999s\n",
            "107\n",
            "Epoch: 0283 loss_train: 0.2453 acc_train: 0.9583 loss_val: 0.8678 acc_val: 0.7320 time: 0.0953s\n",
            "108\n",
            "Epoch: 0284 loss_train: 0.2392 acc_train: 0.9583 loss_val: 0.8640 acc_val: 0.7340 time: 0.1009s\n",
            "109\n",
            "Epoch: 0285 loss_train: 0.2380 acc_train: 0.9583 loss_val: 0.8622 acc_val: 0.7300 time: 0.0987s\n",
            "110\n",
            "Epoch: 0286 loss_train: 0.2361 acc_train: 0.9667 loss_val: 0.8611 acc_val: 0.7320 time: 0.1054s\n",
            "111\n",
            "Epoch: 0287 loss_train: 0.2450 acc_train: 0.9750 loss_val: 0.8647 acc_val: 0.7300 time: 0.0966s\n",
            "112\n",
            "Epoch: 0288 loss_train: 0.2450 acc_train: 0.9500 loss_val: 0.8723 acc_val: 0.7240 time: 0.0955s\n",
            "113\n",
            "Epoch: 0289 loss_train: 0.2361 acc_train: 0.9667 loss_val: 0.8759 acc_val: 0.7240 time: 0.1016s\n",
            "114\n",
            "Epoch: 0290 loss_train: 0.2465 acc_train: 0.9750 loss_val: 0.8764 acc_val: 0.7280 time: 0.0957s\n",
            "115\n",
            "Epoch: 0291 loss_train: 0.2429 acc_train: 0.9500 loss_val: 0.8721 acc_val: 0.7280 time: 0.0977s\n",
            "116\n",
            "Epoch: 0292 loss_train: 0.2281 acc_train: 0.9750 loss_val: 0.8701 acc_val: 0.7320 time: 0.1016s\n",
            "117\n",
            "Epoch: 0293 loss_train: 0.2564 acc_train: 0.9583 loss_val: 0.8690 acc_val: 0.7280 time: 0.0958s\n",
            "118\n",
            "Epoch: 0294 loss_train: 0.2340 acc_train: 0.9750 loss_val: 0.8686 acc_val: 0.7320 time: 0.0957s\n",
            "119\n",
            "Epoch: 0295 loss_train: 0.2397 acc_train: 0.9417 loss_val: 0.8667 acc_val: 0.7320 time: 0.1066s\n",
            "120\n",
            "Epoch: 0296 loss_train: 0.2306 acc_train: 0.9750 loss_val: 0.8670 acc_val: 0.7300 time: 0.0974s\n",
            "121\n",
            "Epoch: 0297 loss_train: 0.2398 acc_train: 0.9667 loss_val: 0.8708 acc_val: 0.7300 time: 0.0952s\n",
            "122\n",
            "Epoch: 0298 loss_train: 0.2360 acc_train: 0.9500 loss_val: 0.8736 acc_val: 0.7280 time: 0.0987s\n",
            "123\n",
            "Epoch: 0299 loss_train: 0.2315 acc_train: 0.9750 loss_val: 0.8753 acc_val: 0.7280 time: 0.0961s\n",
            "124\n",
            "Epoch: 0300 loss_train: 0.2432 acc_train: 0.9583 loss_val: 0.8742 acc_val: 0.7320 time: 0.0950s\n",
            "125\n",
            "Epoch: 0301 loss_train: 0.2512 acc_train: 0.9500 loss_val: 0.8738 acc_val: 0.7340 time: 0.0992s\n",
            "126\n",
            "Epoch: 0302 loss_train: 0.2324 acc_train: 0.9583 loss_val: 0.8717 acc_val: 0.7300 time: 0.1014s\n",
            "127\n",
            "Epoch: 0303 loss_train: 0.2291 acc_train: 0.9750 loss_val: 0.8682 acc_val: 0.7300 time: 0.0954s\n",
            "128\n",
            "Epoch: 0304 loss_train: 0.2425 acc_train: 0.9667 loss_val: 0.8707 acc_val: 0.7300 time: 0.1010s\n",
            "129\n",
            "Epoch: 0305 loss_train: 0.2644 acc_train: 0.9667 loss_val: 0.8749 acc_val: 0.7300 time: 0.0953s\n",
            "130\n",
            "Epoch: 0306 loss_train: 0.2399 acc_train: 0.9583 loss_val: 0.8777 acc_val: 0.7380 time: 0.1023s\n",
            "131\n",
            "Epoch: 0307 loss_train: 0.2329 acc_train: 0.9750 loss_val: 0.8764 acc_val: 0.7340 time: 0.0962s\n",
            "132\n",
            "Epoch: 0308 loss_train: 0.2500 acc_train: 0.9750 loss_val: 0.8706 acc_val: 0.7400 time: 0.0956s\n",
            "133\n",
            "Epoch: 0309 loss_train: 0.2302 acc_train: 0.9750 loss_val: 0.8671 acc_val: 0.7320 time: 0.1015s\n",
            "134\n",
            "Epoch: 0310 loss_train: 0.2379 acc_train: 0.9750 loss_val: 0.8645 acc_val: 0.7300 time: 0.1037s\n",
            "135\n",
            "Epoch: 0311 loss_train: 0.2477 acc_train: 0.9667 loss_val: 0.8675 acc_val: 0.7300 time: 0.1063s\n",
            "136\n",
            "Epoch: 0312 loss_train: 0.2464 acc_train: 0.9750 loss_val: 0.8717 acc_val: 0.7280 time: 0.1056s\n",
            "137\n",
            "Epoch: 0313 loss_train: 0.2450 acc_train: 0.9833 loss_val: 0.8720 acc_val: 0.7320 time: 0.1005s\n",
            "138\n",
            "Epoch: 0314 loss_train: 0.2384 acc_train: 0.9667 loss_val: 0.8734 acc_val: 0.7280 time: 0.1116s\n",
            "139\n",
            "Epoch: 0315 loss_train: 0.2487 acc_train: 0.9750 loss_val: 0.8720 acc_val: 0.7360 time: 0.0970s\n",
            "140\n",
            "Epoch: 0316 loss_train: 0.2229 acc_train: 0.9917 loss_val: 0.8664 acc_val: 0.7360 time: 0.0982s\n",
            "141\n",
            "Epoch: 0317 loss_train: 0.2335 acc_train: 0.9750 loss_val: 0.8633 acc_val: 0.7320 time: 0.0974s\n",
            "142\n",
            "Epoch: 0318 loss_train: 0.2305 acc_train: 0.9750 loss_val: 0.8628 acc_val: 0.7340 time: 0.0994s\n",
            "143\n",
            "Epoch: 0319 loss_train: 0.2431 acc_train: 0.9833 loss_val: 0.8682 acc_val: 0.7280 time: 0.0947s\n",
            "144\n",
            "Epoch: 0320 loss_train: 0.2482 acc_train: 0.9333 loss_val: 0.8745 acc_val: 0.7280 time: 0.0954s\n",
            "145\n",
            "Epoch: 0321 loss_train: 0.2234 acc_train: 0.9667 loss_val: 0.8762 acc_val: 0.7240 time: 0.1009s\n",
            "146\n",
            "Epoch: 0322 loss_train: 0.2279 acc_train: 0.9667 loss_val: 0.8748 acc_val: 0.7240 time: 0.0978s\n",
            "147\n",
            "Epoch: 0323 loss_train: 0.2348 acc_train: 0.9667 loss_val: 0.8722 acc_val: 0.7260 time: 0.0955s\n",
            "148\n",
            "Epoch: 0324 loss_train: 0.2349 acc_train: 0.9667 loss_val: 0.8699 acc_val: 0.7320 time: 0.1006s\n",
            "149\n",
            "Epoch: 0325 loss_train: 0.2307 acc_train: 0.9750 loss_val: 0.8740 acc_val: 0.7320 time: 0.0960s\n",
            "150\n",
            "Epoch: 0326 loss_train: 0.2337 acc_train: 0.9583 loss_val: 0.8751 acc_val: 0.7360 time: 0.0959s\n",
            "151\n",
            "Epoch: 0327 loss_train: 0.2381 acc_train: 0.9667 loss_val: 0.8796 acc_val: 0.7280 time: 0.1018s\n",
            "152\n",
            "Epoch: 0328 loss_train: 0.2412 acc_train: 0.9667 loss_val: 0.8793 acc_val: 0.7280 time: 0.0963s\n",
            "153\n",
            "Epoch: 0329 loss_train: 0.2458 acc_train: 0.9583 loss_val: 0.8791 acc_val: 0.7280 time: 0.0993s\n",
            "154\n",
            "Epoch: 0330 loss_train: 0.2277 acc_train: 0.9500 loss_val: 0.8744 acc_val: 0.7300 time: 0.1002s\n",
            "155\n",
            "Epoch: 0331 loss_train: 0.2406 acc_train: 0.9750 loss_val: 0.8684 acc_val: 0.7320 time: 0.0960s\n",
            "156\n",
            "Epoch: 0332 loss_train: 0.2351 acc_train: 0.9750 loss_val: 0.8635 acc_val: 0.7340 time: 0.1004s\n",
            "157\n",
            "Epoch: 0333 loss_train: 0.2442 acc_train: 0.9667 loss_val: 0.8620 acc_val: 0.7320 time: 0.1006s\n",
            "158\n",
            "Epoch: 0334 loss_train: 0.2304 acc_train: 0.9833 loss_val: 0.8655 acc_val: 0.7340 time: 0.0970s\n",
            "159\n",
            "Epoch: 0335 loss_train: 0.2267 acc_train: 0.9750 loss_val: 0.8710 acc_val: 0.7360 time: 0.1008s\n",
            "160\n",
            "Epoch: 0336 loss_train: 0.2376 acc_train: 0.9500 loss_val: 0.8766 acc_val: 0.7280 time: 0.0958s\n",
            "161\n",
            "Epoch: 0337 loss_train: 0.2235 acc_train: 0.9833 loss_val: 0.8804 acc_val: 0.7260 time: 0.0952s\n",
            "162\n",
            "Epoch: 0338 loss_train: 0.2430 acc_train: 0.9583 loss_val: 0.8761 acc_val: 0.7300 time: 0.1043s\n",
            "163\n",
            "Epoch: 0339 loss_train: 0.2506 acc_train: 0.9500 loss_val: 0.8685 acc_val: 0.7320 time: 0.0959s\n",
            "164\n",
            "Epoch: 0340 loss_train: 0.2429 acc_train: 0.9750 loss_val: 0.8636 acc_val: 0.7320 time: 0.1046s\n",
            "165\n",
            "Epoch: 0341 loss_train: 0.2449 acc_train: 0.9583 loss_val: 0.8609 acc_val: 0.7320 time: 0.1022s\n",
            "166\n",
            "Epoch: 0342 loss_train: 0.2496 acc_train: 0.9667 loss_val: 0.8618 acc_val: 0.7320 time: 0.1035s\n",
            "167\n",
            "Epoch: 0343 loss_train: 0.2315 acc_train: 0.9667 loss_val: 0.8660 acc_val: 0.7300 time: 0.1034s\n",
            "168\n",
            "Epoch: 0344 loss_train: 0.2331 acc_train: 0.9750 loss_val: 0.8766 acc_val: 0.7240 time: 0.0996s\n",
            "169\n",
            "Epoch: 0345 loss_train: 0.2460 acc_train: 0.9667 loss_val: 0.8859 acc_val: 0.7260 time: 0.1055s\n",
            "170\n",
            "Epoch: 0346 loss_train: 0.2370 acc_train: 0.9667 loss_val: 0.8855 acc_val: 0.7180 time: 0.0998s\n",
            "171\n",
            "Epoch: 0347 loss_train: 0.2464 acc_train: 0.9500 loss_val: 0.8769 acc_val: 0.7260 time: 0.1036s\n",
            "172\n",
            "Epoch: 0348 loss_train: 0.2454 acc_train: 0.9750 loss_val: 0.8701 acc_val: 0.7320 time: 0.1001s\n",
            "173\n",
            "Epoch: 0349 loss_train: 0.2290 acc_train: 0.9667 loss_val: 0.8652 acc_val: 0.7320 time: 0.0963s\n",
            "174\n",
            "Epoch: 0350 loss_train: 0.2508 acc_train: 0.9583 loss_val: 0.8619 acc_val: 0.7320 time: 0.1011s\n",
            "175\n",
            "Epoch: 0351 loss_train: 0.2290 acc_train: 0.9500 loss_val: 0.8640 acc_val: 0.7400 time: 0.0956s\n",
            "176\n",
            "Epoch: 0352 loss_train: 0.2490 acc_train: 0.9667 loss_val: 0.8754 acc_val: 0.7300 time: 0.1072s\n",
            "177\n",
            "Epoch: 0353 loss_train: 0.2350 acc_train: 0.9917 loss_val: 0.8881 acc_val: 0.7200 time: 0.0968s\n",
            "178\n",
            "Epoch: 0354 loss_train: 0.2341 acc_train: 0.9833 loss_val: 0.8888 acc_val: 0.7220 time: 0.0961s\n",
            "179\n",
            "Epoch: 0355 loss_train: 0.2399 acc_train: 0.9750 loss_val: 0.8824 acc_val: 0.7220 time: 0.1001s\n",
            "180\n",
            "Epoch: 0356 loss_train: 0.2388 acc_train: 0.9917 loss_val: 0.8724 acc_val: 0.7240 time: 0.0951s\n",
            "181\n",
            "Epoch: 0357 loss_train: 0.2437 acc_train: 0.9583 loss_val: 0.8628 acc_val: 0.7340 time: 0.0951s\n",
            "182\n",
            "Epoch: 0358 loss_train: 0.2376 acc_train: 0.9500 loss_val: 0.8595 acc_val: 0.7340 time: 0.1003s\n",
            "183\n",
            "Epoch: 0359 loss_train: 0.2379 acc_train: 0.9750 loss_val: 0.8650 acc_val: 0.7380 time: 0.0968s\n",
            "184\n",
            "Epoch: 0360 loss_train: 0.2413 acc_train: 0.9667 loss_val: 0.8758 acc_val: 0.7280 time: 0.0966s\n",
            "185\n",
            "Epoch: 0361 loss_train: 0.2370 acc_train: 0.9750 loss_val: 0.8828 acc_val: 0.7260 time: 0.0990s\n",
            "186\n",
            "Epoch: 0362 loss_train: 0.2418 acc_train: 0.9500 loss_val: 0.8918 acc_val: 0.7140 time: 0.0973s\n",
            "187\n",
            "Epoch: 0363 loss_train: 0.2456 acc_train: 0.9417 loss_val: 0.8892 acc_val: 0.7180 time: 0.0955s\n",
            "188\n",
            "Epoch: 0364 loss_train: 0.2621 acc_train: 0.9667 loss_val: 0.8738 acc_val: 0.7260 time: 0.1035s\n",
            "189\n",
            "Epoch: 0365 loss_train: 0.2288 acc_train: 0.9667 loss_val: 0.8643 acc_val: 0.7340 time: 0.0968s\n",
            "190\n",
            "Epoch: 0366 loss_train: 0.2419 acc_train: 0.9750 loss_val: 0.8609 acc_val: 0.7300 time: 0.0955s\n",
            "191\n",
            "Epoch: 0367 loss_train: 0.2352 acc_train: 0.9667 loss_val: 0.8633 acc_val: 0.7300 time: 0.1035s\n",
            "192\n",
            "Epoch: 0368 loss_train: 0.2386 acc_train: 0.9667 loss_val: 0.8682 acc_val: 0.7300 time: 0.0970s\n",
            "193\n",
            "Epoch: 0369 loss_train: 0.2395 acc_train: 0.9750 loss_val: 0.8754 acc_val: 0.7280 time: 0.1008s\n",
            "194\n",
            "Epoch: 0370 loss_train: 0.2273 acc_train: 0.9750 loss_val: 0.8825 acc_val: 0.7260 time: 0.1068s\n",
            "195\n",
            "Epoch: 0371 loss_train: 0.2374 acc_train: 0.9750 loss_val: 0.8847 acc_val: 0.7160 time: 0.1009s\n",
            "196\n",
            "Epoch: 0372 loss_train: 0.2273 acc_train: 0.9750 loss_val: 0.8799 acc_val: 0.7200 time: 0.1102s\n",
            "197\n",
            "Epoch: 0373 loss_train: 0.2523 acc_train: 0.9583 loss_val: 0.8721 acc_val: 0.7220 time: 0.1010s\n",
            "198\n",
            "Epoch: 0374 loss_train: 0.2183 acc_train: 0.9667 loss_val: 0.8654 acc_val: 0.7260 time: 0.1042s\n",
            "199\n",
            "Early stop! Min loss:  0.8567425012588501 , Max accuracy:  0.742\n",
            "Early stop model validation loss:  0.8567425012588501 , accuracy:  0.73\n",
            "Optimization Finished!\n",
            "Total time elapsed: 37.6998s\n",
            "Loading 28th epoch\n",
            "Test set results: loss= 0.8424 accuracy= 0.7180\n",
            "Epoch: 0001 loss_train: 0.2882 acc_train: 0.9667 loss_val: 0.8571 acc_val: 0.7340 time: 0.1091s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.2820 acc_train: 0.9417 loss_val: 0.8601 acc_val: 0.7340 time: 0.1040s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.2688 acc_train: 0.9833 loss_val: 0.8643 acc_val: 0.7300 time: 0.0996s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.2805 acc_train: 0.9750 loss_val: 0.8666 acc_val: 0.7340 time: 0.0982s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.2719 acc_train: 0.9750 loss_val: 0.8658 acc_val: 0.7360 time: 0.1054s\n",
            "0\n",
            "Epoch: 0006 loss_train: 0.2641 acc_train: 0.9917 loss_val: 0.8628 acc_val: 0.7340 time: 0.1037s\n",
            "0\n",
            "Epoch: 0007 loss_train: 0.2705 acc_train: 0.9667 loss_val: 0.8604 acc_val: 0.7300 time: 0.1034s\n",
            "1\n",
            "Epoch: 0008 loss_train: 0.2658 acc_train: 0.9500 loss_val: 0.8612 acc_val: 0.7300 time: 0.0995s\n",
            "2\n",
            "Epoch: 0009 loss_train: 0.2707 acc_train: 0.9750 loss_val: 0.8628 acc_val: 0.7300 time: 0.0949s\n",
            "3\n",
            "Epoch: 0010 loss_train: 0.2790 acc_train: 0.9583 loss_val: 0.8603 acc_val: 0.7280 time: 0.1010s\n",
            "4\n",
            "Epoch: 0011 loss_train: 0.2515 acc_train: 0.9583 loss_val: 0.8581 acc_val: 0.7300 time: 0.0958s\n",
            "5\n",
            "Epoch: 0012 loss_train: 0.2565 acc_train: 0.9750 loss_val: 0.8546 acc_val: 0.7280 time: 0.0947s\n",
            "6\n",
            "Epoch: 0013 loss_train: 0.2667 acc_train: 0.9833 loss_val: 0.8518 acc_val: 0.7300 time: 0.0991s\n",
            "0\n",
            "Epoch: 0014 loss_train: 0.2619 acc_train: 0.9833 loss_val: 0.8483 acc_val: 0.7340 time: 0.0950s\n",
            "0\n",
            "Epoch: 0015 loss_train: 0.2780 acc_train: 0.9667 loss_val: 0.8481 acc_val: 0.7320 time: 0.0951s\n",
            "0\n",
            "Epoch: 0016 loss_train: 0.2537 acc_train: 0.9833 loss_val: 0.8518 acc_val: 0.7320 time: 0.1026s\n",
            "0\n",
            "Epoch: 0017 loss_train: 0.2503 acc_train: 0.9500 loss_val: 0.8556 acc_val: 0.7320 time: 0.1062s\n",
            "1\n",
            "Epoch: 0018 loss_train: 0.2549 acc_train: 0.9833 loss_val: 0.8584 acc_val: 0.7300 time: 0.1127s\n",
            "2\n",
            "Epoch: 0019 loss_train: 0.2705 acc_train: 0.9667 loss_val: 0.8619 acc_val: 0.7300 time: 0.1167s\n",
            "3\n",
            "Epoch: 0020 loss_train: 0.2630 acc_train: 0.9667 loss_val: 0.8590 acc_val: 0.7320 time: 0.0966s\n",
            "4\n",
            "Epoch: 0021 loss_train: 0.2320 acc_train: 0.9667 loss_val: 0.8539 acc_val: 0.7340 time: 0.0962s\n",
            "5\n",
            "Epoch: 0022 loss_train: 0.2676 acc_train: 0.9833 loss_val: 0.8524 acc_val: 0.7340 time: 0.1059s\n",
            "6\n",
            "Epoch: 0023 loss_train: 0.2427 acc_train: 0.9667 loss_val: 0.8532 acc_val: 0.7340 time: 0.0979s\n",
            "7\n",
            "Epoch: 0024 loss_train: 0.2636 acc_train: 0.9583 loss_val: 0.8566 acc_val: 0.7360 time: 0.0988s\n",
            "8\n",
            "Epoch: 0025 loss_train: 0.2819 acc_train: 0.9417 loss_val: 0.8617 acc_val: 0.7340 time: 0.1029s\n",
            "0\n",
            "Epoch: 0026 loss_train: 0.2548 acc_train: 0.9583 loss_val: 0.8649 acc_val: 0.7300 time: 0.0964s\n",
            "1\n",
            "Epoch: 0027 loss_train: 0.2729 acc_train: 0.9667 loss_val: 0.8648 acc_val: 0.7280 time: 0.1049s\n",
            "2\n",
            "Epoch: 0028 loss_train: 0.2696 acc_train: 0.9750 loss_val: 0.8602 acc_val: 0.7320 time: 0.0953s\n",
            "3\n",
            "Epoch: 0029 loss_train: 0.2569 acc_train: 0.9417 loss_val: 0.8561 acc_val: 0.7340 time: 0.0971s\n",
            "4\n",
            "Epoch: 0030 loss_train: 0.2806 acc_train: 0.9500 loss_val: 0.8507 acc_val: 0.7340 time: 0.1032s\n",
            "5\n",
            "Epoch: 0031 loss_train: 0.2629 acc_train: 0.9833 loss_val: 0.8499 acc_val: 0.7340 time: 0.0982s\n",
            "6\n",
            "Epoch: 0032 loss_train: 0.2521 acc_train: 0.9667 loss_val: 0.8523 acc_val: 0.7340 time: 0.0959s\n",
            "7\n",
            "Epoch: 0033 loss_train: 0.2663 acc_train: 0.9667 loss_val: 0.8586 acc_val: 0.7320 time: 0.0993s\n",
            "8\n",
            "Epoch: 0034 loss_train: 0.2640 acc_train: 0.9750 loss_val: 0.8654 acc_val: 0.7320 time: 0.0966s\n",
            "9\n",
            "Epoch: 0035 loss_train: 0.2672 acc_train: 0.9667 loss_val: 0.8668 acc_val: 0.7300 time: 0.0985s\n",
            "10\n",
            "Epoch: 0036 loss_train: 0.2598 acc_train: 0.9583 loss_val: 0.8618 acc_val: 0.7320 time: 0.0986s\n",
            "11\n",
            "Epoch: 0037 loss_train: 0.2574 acc_train: 0.9750 loss_val: 0.8519 acc_val: 0.7380 time: 0.0984s\n",
            "12\n",
            "Epoch: 0038 loss_train: 0.2599 acc_train: 0.9833 loss_val: 0.8440 acc_val: 0.7320 time: 0.1005s\n",
            "0\n",
            "Epoch: 0039 loss_train: 0.2446 acc_train: 0.9833 loss_val: 0.8423 acc_val: 0.7340 time: 0.0962s\n",
            "0\n",
            "Epoch: 0040 loss_train: 0.2453 acc_train: 0.9667 loss_val: 0.8452 acc_val: 0.7340 time: 0.1054s\n",
            "0\n",
            "Epoch: 0041 loss_train: 0.2470 acc_train: 0.9917 loss_val: 0.8538 acc_val: 0.7360 time: 0.0975s\n",
            "1\n",
            "Epoch: 0042 loss_train: 0.2569 acc_train: 0.9667 loss_val: 0.8610 acc_val: 0.7320 time: 0.0956s\n",
            "2\n",
            "Epoch: 0043 loss_train: 0.2515 acc_train: 0.9667 loss_val: 0.8642 acc_val: 0.7340 time: 0.0993s\n",
            "3\n",
            "Epoch: 0044 loss_train: 0.2508 acc_train: 0.9667 loss_val: 0.8610 acc_val: 0.7360 time: 0.0955s\n",
            "4\n",
            "Epoch: 0045 loss_train: 0.2607 acc_train: 0.9667 loss_val: 0.8556 acc_val: 0.7380 time: 0.0988s\n",
            "5\n",
            "Epoch: 0046 loss_train: 0.2725 acc_train: 0.9750 loss_val: 0.8503 acc_val: 0.7420 time: 0.1002s\n",
            "0\n",
            "Epoch: 0047 loss_train: 0.2585 acc_train: 0.9667 loss_val: 0.8459 acc_val: 0.7340 time: 0.1012s\n",
            "0\n",
            "Epoch: 0048 loss_train: 0.2724 acc_train: 0.9750 loss_val: 0.8473 acc_val: 0.7360 time: 0.0957s\n",
            "1\n",
            "Epoch: 0049 loss_train: 0.2552 acc_train: 0.9667 loss_val: 0.8493 acc_val: 0.7360 time: 0.1006s\n",
            "2\n",
            "Epoch: 0050 loss_train: 0.2650 acc_train: 0.9667 loss_val: 0.8544 acc_val: 0.7320 time: 0.0957s\n",
            "3\n",
            "Epoch: 0051 loss_train: 0.2645 acc_train: 0.9667 loss_val: 0.8575 acc_val: 0.7300 time: 0.0953s\n",
            "4\n",
            "Epoch: 0052 loss_train: 0.2602 acc_train: 0.9667 loss_val: 0.8594 acc_val: 0.7320 time: 0.1058s\n",
            "5\n",
            "Epoch: 0053 loss_train: 0.2540 acc_train: 0.9750 loss_val: 0.8581 acc_val: 0.7360 time: 0.0994s\n",
            "6\n",
            "Epoch: 0054 loss_train: 0.2488 acc_train: 0.9750 loss_val: 0.8533 acc_val: 0.7380 time: 0.0954s\n",
            "7\n",
            "Epoch: 0055 loss_train: 0.2491 acc_train: 0.9583 loss_val: 0.8480 acc_val: 0.7440 time: 0.0992s\n",
            "8\n",
            "Epoch: 0056 loss_train: 0.2484 acc_train: 0.9917 loss_val: 0.8462 acc_val: 0.7380 time: 0.0956s\n",
            "0\n",
            "Epoch: 0057 loss_train: 0.2455 acc_train: 0.9750 loss_val: 0.8467 acc_val: 0.7380 time: 0.1009s\n",
            "1\n",
            "Epoch: 0058 loss_train: 0.2554 acc_train: 0.9667 loss_val: 0.8474 acc_val: 0.7400 time: 0.0983s\n",
            "2\n",
            "Epoch: 0059 loss_train: 0.2363 acc_train: 0.9750 loss_val: 0.8474 acc_val: 0.7400 time: 0.0989s\n",
            "3\n",
            "Epoch: 0060 loss_train: 0.2520 acc_train: 0.9750 loss_val: 0.8478 acc_val: 0.7380 time: 0.1047s\n",
            "4\n",
            "Epoch: 0061 loss_train: 0.2570 acc_train: 0.9917 loss_val: 0.8502 acc_val: 0.7360 time: 0.0966s\n",
            "5\n",
            "Epoch: 0062 loss_train: 0.2560 acc_train: 0.9667 loss_val: 0.8514 acc_val: 0.7400 time: 0.1012s\n",
            "6\n",
            "Epoch: 0063 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.8529 acc_val: 0.7400 time: 0.0978s\n",
            "7\n",
            "Epoch: 0064 loss_train: 0.2564 acc_train: 0.9750 loss_val: 0.8537 acc_val: 0.7380 time: 0.0968s\n",
            "8\n",
            "Epoch: 0065 loss_train: 0.2592 acc_train: 0.9750 loss_val: 0.8520 acc_val: 0.7320 time: 0.0972s\n",
            "9\n",
            "Epoch: 0066 loss_train: 0.2736 acc_train: 0.9583 loss_val: 0.8511 acc_val: 0.7300 time: 0.0953s\n",
            "10\n",
            "Epoch: 0067 loss_train: 0.2548 acc_train: 0.9667 loss_val: 0.8503 acc_val: 0.7320 time: 0.1041s\n",
            "11\n",
            "Epoch: 0068 loss_train: 0.2621 acc_train: 0.9583 loss_val: 0.8503 acc_val: 0.7340 time: 0.0973s\n",
            "12\n",
            "Epoch: 0069 loss_train: 0.2505 acc_train: 0.9750 loss_val: 0.8516 acc_val: 0.7400 time: 0.0962s\n",
            "13\n",
            "Epoch: 0070 loss_train: 0.2589 acc_train: 0.9500 loss_val: 0.8547 acc_val: 0.7360 time: 0.0990s\n",
            "14\n",
            "Epoch: 0071 loss_train: 0.2562 acc_train: 0.9667 loss_val: 0.8564 acc_val: 0.7300 time: 0.0956s\n",
            "15\n",
            "Epoch: 0072 loss_train: 0.2635 acc_train: 0.9833 loss_val: 0.8510 acc_val: 0.7380 time: 0.0990s\n",
            "16\n",
            "Epoch: 0073 loss_train: 0.2631 acc_train: 0.9583 loss_val: 0.8477 acc_val: 0.7340 time: 0.1001s\n",
            "17\n",
            "Epoch: 0074 loss_train: 0.2528 acc_train: 0.9667 loss_val: 0.8451 acc_val: 0.7380 time: 0.0975s\n",
            "18\n",
            "Epoch: 0075 loss_train: 0.2572 acc_train: 0.9583 loss_val: 0.8457 acc_val: 0.7380 time: 0.1010s\n",
            "19\n",
            "Epoch: 0076 loss_train: 0.2511 acc_train: 0.9583 loss_val: 0.8493 acc_val: 0.7340 time: 0.0969s\n",
            "20\n",
            "Epoch: 0077 loss_train: 0.2706 acc_train: 0.9750 loss_val: 0.8527 acc_val: 0.7340 time: 0.1062s\n",
            "21\n",
            "Epoch: 0078 loss_train: 0.2677 acc_train: 0.9583 loss_val: 0.8512 acc_val: 0.7380 time: 0.0962s\n",
            "22\n",
            "Epoch: 0079 loss_train: 0.2390 acc_train: 0.9583 loss_val: 0.8497 acc_val: 0.7340 time: 0.0971s\n",
            "23\n",
            "Epoch: 0080 loss_train: 0.2550 acc_train: 0.9750 loss_val: 0.8501 acc_val: 0.7380 time: 0.1006s\n",
            "24\n",
            "Epoch: 0081 loss_train: 0.2597 acc_train: 0.9750 loss_val: 0.8536 acc_val: 0.7320 time: 0.0954s\n",
            "25\n",
            "Epoch: 0082 loss_train: 0.2692 acc_train: 0.9500 loss_val: 0.8553 acc_val: 0.7320 time: 0.0965s\n",
            "26\n",
            "Epoch: 0083 loss_train: 0.2589 acc_train: 0.9667 loss_val: 0.8552 acc_val: 0.7380 time: 0.1003s\n",
            "27\n",
            "Epoch: 0084 loss_train: 0.2638 acc_train: 0.9667 loss_val: 0.8554 acc_val: 0.7400 time: 0.0992s\n",
            "28\n",
            "Epoch: 0085 loss_train: 0.2656 acc_train: 0.9667 loss_val: 0.8516 acc_val: 0.7340 time: 0.0953s\n",
            "29\n",
            "Epoch: 0086 loss_train: 0.2674 acc_train: 0.9583 loss_val: 0.8488 acc_val: 0.7320 time: 0.1004s\n",
            "30\n",
            "Epoch: 0087 loss_train: 0.2517 acc_train: 0.9583 loss_val: 0.8493 acc_val: 0.7360 time: 0.1020s\n",
            "31\n",
            "Epoch: 0088 loss_train: 0.2819 acc_train: 0.9583 loss_val: 0.8485 acc_val: 0.7360 time: 0.1022s\n",
            "32\n",
            "Epoch: 0089 loss_train: 0.2497 acc_train: 0.9750 loss_val: 0.8483 acc_val: 0.7380 time: 0.0972s\n",
            "33\n",
            "Epoch: 0090 loss_train: 0.2434 acc_train: 0.9833 loss_val: 0.8511 acc_val: 0.7360 time: 0.0965s\n",
            "34\n",
            "Epoch: 0091 loss_train: 0.2452 acc_train: 0.9667 loss_val: 0.8511 acc_val: 0.7360 time: 0.1020s\n",
            "35\n",
            "Epoch: 0092 loss_train: 0.2574 acc_train: 0.9583 loss_val: 0.8514 acc_val: 0.7360 time: 0.0959s\n",
            "36\n",
            "Epoch: 0093 loss_train: 0.2605 acc_train: 0.9833 loss_val: 0.8495 acc_val: 0.7360 time: 0.1059s\n",
            "37\n",
            "Epoch: 0094 loss_train: 0.2641 acc_train: 0.9750 loss_val: 0.8484 acc_val: 0.7320 time: 0.0997s\n",
            "38\n",
            "Epoch: 0095 loss_train: 0.2837 acc_train: 0.9583 loss_val: 0.8517 acc_val: 0.7340 time: 0.0955s\n",
            "39\n",
            "Epoch: 0096 loss_train: 0.2544 acc_train: 0.9750 loss_val: 0.8542 acc_val: 0.7340 time: 0.1003s\n",
            "40\n",
            "Epoch: 0097 loss_train: 0.2585 acc_train: 0.9333 loss_val: 0.8570 acc_val: 0.7320 time: 0.1016s\n",
            "41\n",
            "Epoch: 0098 loss_train: 0.2563 acc_train: 0.9417 loss_val: 0.8552 acc_val: 0.7320 time: 0.1019s\n",
            "42\n",
            "Epoch: 0099 loss_train: 0.2581 acc_train: 0.9500 loss_val: 0.8502 acc_val: 0.7340 time: 0.0993s\n",
            "43\n",
            "Epoch: 0100 loss_train: 0.2540 acc_train: 0.9667 loss_val: 0.8462 acc_val: 0.7360 time: 0.0992s\n",
            "44\n",
            "Epoch: 0101 loss_train: 0.2631 acc_train: 0.9833 loss_val: 0.8460 acc_val: 0.7400 time: 0.1061s\n",
            "45\n",
            "Epoch: 0102 loss_train: 0.2597 acc_train: 0.9667 loss_val: 0.8493 acc_val: 0.7340 time: 0.0981s\n",
            "46\n",
            "Epoch: 0103 loss_train: 0.2478 acc_train: 0.9583 loss_val: 0.8557 acc_val: 0.7300 time: 0.1040s\n",
            "47\n",
            "Epoch: 0104 loss_train: 0.2511 acc_train: 0.9917 loss_val: 0.8588 acc_val: 0.7300 time: 0.0996s\n",
            "48\n",
            "Epoch: 0105 loss_train: 0.2482 acc_train: 0.9750 loss_val: 0.8557 acc_val: 0.7320 time: 0.1004s\n",
            "49\n",
            "Epoch: 0106 loss_train: 0.2602 acc_train: 0.9667 loss_val: 0.8524 acc_val: 0.7360 time: 0.0961s\n",
            "50\n",
            "Epoch: 0107 loss_train: 0.2511 acc_train: 0.9583 loss_val: 0.8498 acc_val: 0.7340 time: 0.1025s\n",
            "51\n",
            "Epoch: 0108 loss_train: 0.2650 acc_train: 0.9667 loss_val: 0.8473 acc_val: 0.7400 time: 0.1008s\n",
            "52\n",
            "Epoch: 0109 loss_train: 0.2772 acc_train: 0.9667 loss_val: 0.8462 acc_val: 0.7380 time: 0.0966s\n",
            "53\n",
            "Epoch: 0110 loss_train: 0.2477 acc_train: 0.9833 loss_val: 0.8523 acc_val: 0.7320 time: 0.1014s\n",
            "54\n",
            "Epoch: 0111 loss_train: 0.2520 acc_train: 0.9917 loss_val: 0.8615 acc_val: 0.7260 time: 0.0960s\n",
            "55\n",
            "Epoch: 0112 loss_train: 0.2485 acc_train: 0.9833 loss_val: 0.8656 acc_val: 0.7260 time: 0.0960s\n",
            "56\n",
            "Epoch: 0113 loss_train: 0.2432 acc_train: 0.9833 loss_val: 0.8626 acc_val: 0.7280 time: 0.1004s\n",
            "57\n",
            "Epoch: 0114 loss_train: 0.2552 acc_train: 0.9833 loss_val: 0.8564 acc_val: 0.7360 time: 0.0967s\n",
            "58\n",
            "Epoch: 0115 loss_train: 0.2641 acc_train: 0.9583 loss_val: 0.8518 acc_val: 0.7400 time: 0.1109s\n",
            "59\n",
            "Epoch: 0116 loss_train: 0.2597 acc_train: 0.9333 loss_val: 0.8484 acc_val: 0.7400 time: 0.0967s\n",
            "60\n",
            "Epoch: 0117 loss_train: 0.2582 acc_train: 0.9667 loss_val: 0.8450 acc_val: 0.7380 time: 0.1036s\n",
            "61\n",
            "Epoch: 0118 loss_train: 0.2572 acc_train: 0.9500 loss_val: 0.8491 acc_val: 0.7380 time: 0.1055s\n",
            "62\n",
            "Epoch: 0119 loss_train: 0.2622 acc_train: 0.9583 loss_val: 0.8548 acc_val: 0.7360 time: 0.0966s\n",
            "63\n",
            "Epoch: 0120 loss_train: 0.2721 acc_train: 0.9500 loss_val: 0.8571 acc_val: 0.7340 time: 0.1033s\n",
            "64\n",
            "Epoch: 0121 loss_train: 0.2488 acc_train: 0.9583 loss_val: 0.8567 acc_val: 0.7360 time: 0.0954s\n",
            "65\n",
            "Epoch: 0122 loss_train: 0.2399 acc_train: 0.9750 loss_val: 0.8535 acc_val: 0.7320 time: 0.0969s\n",
            "66\n",
            "Epoch: 0123 loss_train: 0.2679 acc_train: 0.9500 loss_val: 0.8507 acc_val: 0.7320 time: 0.1002s\n",
            "67\n",
            "Epoch: 0124 loss_train: 0.2453 acc_train: 0.9833 loss_val: 0.8513 acc_val: 0.7340 time: 0.0954s\n",
            "68\n",
            "Epoch: 0125 loss_train: 0.2677 acc_train: 0.9750 loss_val: 0.8539 acc_val: 0.7360 time: 0.1076s\n",
            "69\n",
            "Epoch: 0126 loss_train: 0.2533 acc_train: 0.9750 loss_val: 0.8588 acc_val: 0.7320 time: 0.1032s\n",
            "70\n",
            "Epoch: 0127 loss_train: 0.2626 acc_train: 0.9583 loss_val: 0.8638 acc_val: 0.7320 time: 0.1011s\n",
            "71\n",
            "Epoch: 0128 loss_train: 0.2485 acc_train: 0.9667 loss_val: 0.8648 acc_val: 0.7300 time: 0.1038s\n",
            "72\n",
            "Epoch: 0129 loss_train: 0.2414 acc_train: 0.9500 loss_val: 0.8597 acc_val: 0.7320 time: 0.0964s\n",
            "73\n",
            "Epoch: 0130 loss_train: 0.2549 acc_train: 0.9833 loss_val: 0.8554 acc_val: 0.7320 time: 0.0992s\n",
            "74\n",
            "Epoch: 0131 loss_train: 0.2554 acc_train: 0.9750 loss_val: 0.8501 acc_val: 0.7340 time: 0.0951s\n",
            "75\n",
            "Epoch: 0132 loss_train: 0.2664 acc_train: 0.9583 loss_val: 0.8471 acc_val: 0.7320 time: 0.0967s\n",
            "76\n",
            "Epoch: 0133 loss_train: 0.2559 acc_train: 0.9583 loss_val: 0.8454 acc_val: 0.7360 time: 0.1041s\n",
            "77\n",
            "Epoch: 0134 loss_train: 0.2548 acc_train: 0.9750 loss_val: 0.8463 acc_val: 0.7380 time: 0.0969s\n",
            "78\n",
            "Epoch: 0135 loss_train: 0.2621 acc_train: 0.9917 loss_val: 0.8503 acc_val: 0.7360 time: 0.0954s\n",
            "79\n",
            "Epoch: 0136 loss_train: 0.2496 acc_train: 0.9667 loss_val: 0.8513 acc_val: 0.7340 time: 0.0998s\n",
            "80\n",
            "Epoch: 0137 loss_train: 0.2559 acc_train: 0.9667 loss_val: 0.8475 acc_val: 0.7340 time: 0.0971s\n",
            "81\n",
            "Epoch: 0138 loss_train: 0.2511 acc_train: 0.9667 loss_val: 0.8450 acc_val: 0.7380 time: 0.0961s\n",
            "82\n",
            "Epoch: 0139 loss_train: 0.2607 acc_train: 0.9750 loss_val: 0.8417 acc_val: 0.7400 time: 0.1034s\n",
            "83\n",
            "Epoch: 0140 loss_train: 0.2430 acc_train: 0.9833 loss_val: 0.8390 acc_val: 0.7420 time: 0.0967s\n",
            "0\n",
            "Epoch: 0141 loss_train: 0.2697 acc_train: 0.9750 loss_val: 0.8411 acc_val: 0.7420 time: 0.0987s\n",
            "0\n",
            "Epoch: 0142 loss_train: 0.2532 acc_train: 0.9750 loss_val: 0.8458 acc_val: 0.7380 time: 0.1038s\n",
            "1\n",
            "Epoch: 0143 loss_train: 0.2776 acc_train: 0.9667 loss_val: 0.8530 acc_val: 0.7340 time: 0.0967s\n",
            "2\n",
            "Epoch: 0144 loss_train: 0.2671 acc_train: 0.9667 loss_val: 0.8608 acc_val: 0.7300 time: 0.1006s\n",
            "3\n",
            "Epoch: 0145 loss_train: 0.2488 acc_train: 0.9917 loss_val: 0.8605 acc_val: 0.7300 time: 0.0958s\n",
            "4\n",
            "Epoch: 0146 loss_train: 0.2519 acc_train: 0.9833 loss_val: 0.8555 acc_val: 0.7340 time: 0.0969s\n",
            "5\n",
            "Epoch: 0147 loss_train: 0.2468 acc_train: 0.9667 loss_val: 0.8476 acc_val: 0.7400 time: 0.1050s\n",
            "6\n",
            "Epoch: 0148 loss_train: 0.2681 acc_train: 0.9667 loss_val: 0.8448 acc_val: 0.7380 time: 0.0967s\n",
            "7\n",
            "Epoch: 0149 loss_train: 0.2424 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7340 time: 0.0956s\n",
            "8\n",
            "Epoch: 0150 loss_train: 0.2528 acc_train: 0.9750 loss_val: 0.8488 acc_val: 0.7360 time: 0.1038s\n",
            "9\n",
            "Epoch: 0151 loss_train: 0.2432 acc_train: 0.9583 loss_val: 0.8507 acc_val: 0.7380 time: 0.0956s\n",
            "10\n",
            "Epoch: 0152 loss_train: 0.2514 acc_train: 0.9917 loss_val: 0.8486 acc_val: 0.7400 time: 0.0958s\n",
            "11\n",
            "Epoch: 0153 loss_train: 0.2410 acc_train: 1.0000 loss_val: 0.8474 acc_val: 0.7340 time: 0.1010s\n",
            "12\n",
            "Epoch: 0154 loss_train: 0.2591 acc_train: 0.9750 loss_val: 0.8520 acc_val: 0.7300 time: 0.0957s\n",
            "13\n",
            "Epoch: 0155 loss_train: 0.2396 acc_train: 0.9667 loss_val: 0.8580 acc_val: 0.7280 time: 0.1022s\n",
            "14\n",
            "Epoch: 0156 loss_train: 0.2489 acc_train: 0.9417 loss_val: 0.8599 acc_val: 0.7300 time: 0.1071s\n",
            "15\n",
            "Epoch: 0157 loss_train: 0.2490 acc_train: 0.9667 loss_val: 0.8602 acc_val: 0.7300 time: 0.1027s\n",
            "16\n",
            "Epoch: 0158 loss_train: 0.2576 acc_train: 0.9583 loss_val: 0.8581 acc_val: 0.7320 time: 0.1015s\n",
            "17\n",
            "Epoch: 0159 loss_train: 0.2590 acc_train: 0.9917 loss_val: 0.8542 acc_val: 0.7340 time: 0.0982s\n",
            "18\n",
            "Epoch: 0160 loss_train: 0.2573 acc_train: 0.9750 loss_val: 0.8512 acc_val: 0.7380 time: 0.1031s\n",
            "19\n",
            "Epoch: 0161 loss_train: 0.2656 acc_train: 0.9417 loss_val: 0.8513 acc_val: 0.7440 time: 0.0962s\n",
            "20\n",
            "Epoch: 0162 loss_train: 0.2599 acc_train: 0.9833 loss_val: 0.8550 acc_val: 0.7360 time: 0.0952s\n",
            "0\n",
            "Epoch: 0163 loss_train: 0.2566 acc_train: 0.9750 loss_val: 0.8565 acc_val: 0.7320 time: 0.1047s\n",
            "1\n",
            "Epoch: 0164 loss_train: 0.2454 acc_train: 0.9750 loss_val: 0.8577 acc_val: 0.7300 time: 0.0972s\n",
            "2\n",
            "Epoch: 0165 loss_train: 0.2447 acc_train: 0.9833 loss_val: 0.8576 acc_val: 0.7320 time: 0.0964s\n",
            "3\n",
            "Epoch: 0166 loss_train: 0.2718 acc_train: 0.9750 loss_val: 0.8535 acc_val: 0.7340 time: 0.0994s\n",
            "4\n",
            "Epoch: 0167 loss_train: 0.2385 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7400 time: 0.1015s\n",
            "5\n",
            "Epoch: 0168 loss_train: 0.2599 acc_train: 0.9583 loss_val: 0.8483 acc_val: 0.7400 time: 0.1034s\n",
            "6\n",
            "Epoch: 0169 loss_train: 0.2463 acc_train: 0.9667 loss_val: 0.8484 acc_val: 0.7420 time: 0.0963s\n",
            "7\n",
            "Epoch: 0170 loss_train: 0.2546 acc_train: 0.9750 loss_val: 0.8502 acc_val: 0.7400 time: 0.0965s\n",
            "8\n",
            "Epoch: 0171 loss_train: 0.2569 acc_train: 0.9667 loss_val: 0.8565 acc_val: 0.7360 time: 0.1087s\n",
            "9\n",
            "Epoch: 0172 loss_train: 0.2472 acc_train: 0.9917 loss_val: 0.8575 acc_val: 0.7300 time: 0.0953s\n",
            "10\n",
            "Epoch: 0173 loss_train: 0.2600 acc_train: 0.9667 loss_val: 0.8540 acc_val: 0.7380 time: 0.0969s\n",
            "11\n",
            "Epoch: 0174 loss_train: 0.2436 acc_train: 0.9583 loss_val: 0.8512 acc_val: 0.7360 time: 0.1001s\n",
            "12\n",
            "Epoch: 0175 loss_train: 0.2475 acc_train: 0.9750 loss_val: 0.8479 acc_val: 0.7420 time: 0.0972s\n",
            "13\n",
            "Epoch: 0176 loss_train: 0.2750 acc_train: 0.9667 loss_val: 0.8493 acc_val: 0.7420 time: 0.0962s\n",
            "14\n",
            "Epoch: 0177 loss_train: 0.2576 acc_train: 0.9833 loss_val: 0.8505 acc_val: 0.7400 time: 0.1054s\n",
            "15\n",
            "Epoch: 0178 loss_train: 0.2619 acc_train: 0.9667 loss_val: 0.8520 acc_val: 0.7340 time: 0.0951s\n",
            "16\n",
            "Epoch: 0179 loss_train: 0.2479 acc_train: 0.9917 loss_val: 0.8511 acc_val: 0.7320 time: 0.0954s\n",
            "17\n",
            "Epoch: 0180 loss_train: 0.2650 acc_train: 0.9583 loss_val: 0.8494 acc_val: 0.7340 time: 0.1017s\n",
            "18\n",
            "Epoch: 0181 loss_train: 0.2532 acc_train: 0.9750 loss_val: 0.8488 acc_val: 0.7380 time: 0.0992s\n",
            "19\n",
            "Epoch: 0182 loss_train: 0.2634 acc_train: 0.9667 loss_val: 0.8497 acc_val: 0.7380 time: 0.0950s\n",
            "20\n",
            "Epoch: 0183 loss_train: 0.2596 acc_train: 0.9750 loss_val: 0.8498 acc_val: 0.7380 time: 0.1035s\n",
            "21\n",
            "Epoch: 0184 loss_train: 0.2408 acc_train: 0.9750 loss_val: 0.8514 acc_val: 0.7340 time: 0.0958s\n",
            "22\n",
            "Epoch: 0185 loss_train: 0.2567 acc_train: 0.9583 loss_val: 0.8530 acc_val: 0.7340 time: 0.0956s\n",
            "23\n",
            "Epoch: 0186 loss_train: 0.2602 acc_train: 0.9667 loss_val: 0.8507 acc_val: 0.7360 time: 0.1006s\n",
            "24\n",
            "Epoch: 0187 loss_train: 0.2591 acc_train: 0.9417 loss_val: 0.8487 acc_val: 0.7380 time: 0.0977s\n",
            "25\n",
            "Epoch: 0188 loss_train: 0.2585 acc_train: 0.9500 loss_val: 0.8464 acc_val: 0.7380 time: 0.0985s\n",
            "26\n",
            "Epoch: 0189 loss_train: 0.2629 acc_train: 0.9500 loss_val: 0.8487 acc_val: 0.7360 time: 0.1084s\n",
            "27\n",
            "Epoch: 0190 loss_train: 0.2603 acc_train: 0.9750 loss_val: 0.8515 acc_val: 0.7360 time: 0.0952s\n",
            "28\n",
            "Epoch: 0191 loss_train: 0.2531 acc_train: 0.9500 loss_val: 0.8543 acc_val: 0.7280 time: 0.0989s\n",
            "29\n",
            "Epoch: 0192 loss_train: 0.2418 acc_train: 0.9833 loss_val: 0.8555 acc_val: 0.7320 time: 0.0960s\n",
            "30\n",
            "Epoch: 0193 loss_train: 0.2602 acc_train: 0.9500 loss_val: 0.8542 acc_val: 0.7320 time: 0.0948s\n",
            "31\n",
            "Epoch: 0194 loss_train: 0.2678 acc_train: 0.9667 loss_val: 0.8488 acc_val: 0.7380 time: 0.1015s\n",
            "32\n",
            "Epoch: 0195 loss_train: 0.2587 acc_train: 0.9917 loss_val: 0.8446 acc_val: 0.7420 time: 0.0968s\n",
            "33\n",
            "Epoch: 0196 loss_train: 0.2507 acc_train: 0.9667 loss_val: 0.8447 acc_val: 0.7380 time: 0.0955s\n",
            "34\n",
            "Epoch: 0197 loss_train: 0.2630 acc_train: 0.9583 loss_val: 0.8510 acc_val: 0.7360 time: 0.1048s\n",
            "35\n",
            "Epoch: 0198 loss_train: 0.2626 acc_train: 0.9750 loss_val: 0.8590 acc_val: 0.7340 time: 0.0988s\n",
            "36\n",
            "Epoch: 0199 loss_train: 0.2584 acc_train: 0.9750 loss_val: 0.8644 acc_val: 0.7300 time: 0.1003s\n",
            "37\n",
            "Epoch: 0200 loss_train: 0.2504 acc_train: 0.9750 loss_val: 0.8651 acc_val: 0.7240 time: 0.1006s\n",
            "38\n",
            "Epoch: 0201 loss_train: 0.2468 acc_train: 0.9583 loss_val: 0.8588 acc_val: 0.7320 time: 0.0959s\n",
            "39\n",
            "Epoch: 0202 loss_train: 0.2616 acc_train: 0.9667 loss_val: 0.8532 acc_val: 0.7320 time: 0.1055s\n",
            "40\n",
            "Epoch: 0203 loss_train: 0.2382 acc_train: 0.9917 loss_val: 0.8501 acc_val: 0.7300 time: 0.1056s\n",
            "41\n",
            "Epoch: 0204 loss_train: 0.2461 acc_train: 0.9833 loss_val: 0.8503 acc_val: 0.7340 time: 0.1019s\n",
            "42\n",
            "Epoch: 0205 loss_train: 0.2506 acc_train: 0.9583 loss_val: 0.8519 acc_val: 0.7380 time: 0.0988s\n",
            "43\n",
            "Epoch: 0206 loss_train: 0.2683 acc_train: 0.9750 loss_val: 0.8534 acc_val: 0.7360 time: 0.0968s\n",
            "44\n",
            "Epoch: 0207 loss_train: 0.2562 acc_train: 0.9333 loss_val: 0.8560 acc_val: 0.7320 time: 0.1072s\n",
            "45\n",
            "Epoch: 0208 loss_train: 0.2557 acc_train: 0.9750 loss_val: 0.8551 acc_val: 0.7320 time: 0.0973s\n",
            "46\n",
            "Epoch: 0209 loss_train: 0.2521 acc_train: 0.9583 loss_val: 0.8504 acc_val: 0.7320 time: 0.0974s\n",
            "47\n",
            "Epoch: 0210 loss_train: 0.2721 acc_train: 0.9417 loss_val: 0.8459 acc_val: 0.7380 time: 0.1063s\n",
            "48\n",
            "Epoch: 0211 loss_train: 0.2642 acc_train: 0.9750 loss_val: 0.8463 acc_val: 0.7380 time: 0.1002s\n",
            "49\n",
            "Epoch: 0212 loss_train: 0.2604 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7340 time: 0.0991s\n",
            "50\n",
            "Epoch: 0213 loss_train: 0.2497 acc_train: 0.9833 loss_val: 0.8557 acc_val: 0.7360 time: 0.1024s\n",
            "51\n",
            "Epoch: 0214 loss_train: 0.2723 acc_train: 0.9667 loss_val: 0.8664 acc_val: 0.7300 time: 0.0983s\n",
            "52\n",
            "Epoch: 0215 loss_train: 0.2693 acc_train: 0.9750 loss_val: 0.8699 acc_val: 0.7240 time: 0.1025s\n",
            "53\n",
            "Epoch: 0216 loss_train: 0.2556 acc_train: 0.9583 loss_val: 0.8614 acc_val: 0.7320 time: 0.0983s\n",
            "54\n",
            "Epoch: 0217 loss_train: 0.2430 acc_train: 0.9750 loss_val: 0.8508 acc_val: 0.7360 time: 0.0981s\n",
            "55\n",
            "Epoch: 0218 loss_train: 0.2636 acc_train: 0.9583 loss_val: 0.8429 acc_val: 0.7420 time: 0.1054s\n",
            "56\n",
            "Epoch: 0219 loss_train: 0.2636 acc_train: 0.9667 loss_val: 0.8414 acc_val: 0.7420 time: 0.0968s\n",
            "57\n",
            "Epoch: 0220 loss_train: 0.2655 acc_train: 0.9667 loss_val: 0.8434 acc_val: 0.7440 time: 0.0997s\n",
            "58\n",
            "Epoch: 0221 loss_train: 0.2581 acc_train: 0.9583 loss_val: 0.8498 acc_val: 0.7360 time: 0.0962s\n",
            "0\n",
            "Epoch: 0222 loss_train: 0.2299 acc_train: 0.9833 loss_val: 0.8582 acc_val: 0.7360 time: 0.0962s\n",
            "1\n",
            "Epoch: 0223 loss_train: 0.2732 acc_train: 0.9333 loss_val: 0.8625 acc_val: 0.7380 time: 0.1009s\n",
            "2\n",
            "Epoch: 0224 loss_train: 0.2533 acc_train: 0.9667 loss_val: 0.8592 acc_val: 0.7360 time: 0.0963s\n",
            "3\n",
            "Epoch: 0225 loss_train: 0.2650 acc_train: 0.9833 loss_val: 0.8541 acc_val: 0.7320 time: 0.0955s\n",
            "4\n",
            "Epoch: 0226 loss_train: 0.2370 acc_train: 0.9750 loss_val: 0.8480 acc_val: 0.7380 time: 0.1040s\n",
            "5\n",
            "Epoch: 0227 loss_train: 0.2486 acc_train: 0.9750 loss_val: 0.8430 acc_val: 0.7400 time: 0.0993s\n",
            "6\n",
            "Epoch: 0228 loss_train: 0.2564 acc_train: 0.9583 loss_val: 0.8438 acc_val: 0.7400 time: 0.0975s\n",
            "7\n",
            "Epoch: 0229 loss_train: 0.2593 acc_train: 0.9750 loss_val: 0.8480 acc_val: 0.7380 time: 0.0988s\n",
            "8\n",
            "Epoch: 0230 loss_train: 0.2632 acc_train: 0.9583 loss_val: 0.8557 acc_val: 0.7360 time: 0.1036s\n",
            "9\n",
            "Epoch: 0231 loss_train: 0.2569 acc_train: 0.9417 loss_val: 0.8630 acc_val: 0.7300 time: 0.0954s\n",
            "10\n",
            "Epoch: 0232 loss_train: 0.2596 acc_train: 0.9417 loss_val: 0.8629 acc_val: 0.7300 time: 0.1083s\n",
            "11\n",
            "Epoch: 0233 loss_train: 0.2599 acc_train: 0.9667 loss_val: 0.8546 acc_val: 0.7360 time: 0.0984s\n",
            "12\n",
            "Epoch: 0234 loss_train: 0.2390 acc_train: 0.9583 loss_val: 0.8493 acc_val: 0.7400 time: 0.1009s\n",
            "13\n",
            "Epoch: 0235 loss_train: 0.2609 acc_train: 0.9750 loss_val: 0.8428 acc_val: 0.7380 time: 0.0955s\n",
            "14\n",
            "Epoch: 0236 loss_train: 0.2545 acc_train: 0.9583 loss_val: 0.8438 acc_val: 0.7420 time: 0.0989s\n",
            "15\n",
            "Epoch: 0237 loss_train: 0.2445 acc_train: 0.9833 loss_val: 0.8500 acc_val: 0.7380 time: 0.0998s\n",
            "16\n",
            "Epoch: 0238 loss_train: 0.2613 acc_train: 0.9583 loss_val: 0.8548 acc_val: 0.7360 time: 0.0949s\n",
            "17\n",
            "Epoch: 0239 loss_train: 0.2489 acc_train: 0.9667 loss_val: 0.8596 acc_val: 0.7340 time: 0.0998s\n",
            "18\n",
            "Epoch: 0240 loss_train: 0.2582 acc_train: 0.9750 loss_val: 0.8606 acc_val: 0.7340 time: 0.0954s\n",
            "19\n",
            "Epoch: 0241 loss_train: 0.2571 acc_train: 0.9833 loss_val: 0.8569 acc_val: 0.7380 time: 0.0948s\n",
            "20\n",
            "Epoch: 0242 loss_train: 0.2666 acc_train: 0.9667 loss_val: 0.8510 acc_val: 0.7380 time: 0.1016s\n",
            "21\n",
            "Epoch: 0243 loss_train: 0.2612 acc_train: 0.9833 loss_val: 0.8454 acc_val: 0.7460 time: 0.0947s\n",
            "22\n",
            "Epoch: 0244 loss_train: 0.2459 acc_train: 0.9750 loss_val: 0.8428 acc_val: 0.7400 time: 0.0954s\n",
            "0\n",
            "Epoch: 0245 loss_train: 0.2487 acc_train: 0.9667 loss_val: 0.8462 acc_val: 0.7380 time: 0.1005s\n",
            "1\n",
            "Epoch: 0246 loss_train: 0.2612 acc_train: 0.9917 loss_val: 0.8517 acc_val: 0.7340 time: 0.0945s\n",
            "2\n",
            "Epoch: 0247 loss_train: 0.2450 acc_train: 0.9833 loss_val: 0.8564 acc_val: 0.7300 time: 0.0986s\n",
            "3\n",
            "Epoch: 0248 loss_train: 0.2669 acc_train: 0.9833 loss_val: 0.8592 acc_val: 0.7280 time: 0.1022s\n",
            "4\n",
            "Epoch: 0249 loss_train: 0.2577 acc_train: 0.9833 loss_val: 0.8610 acc_val: 0.7280 time: 0.0952s\n",
            "5\n",
            "Epoch: 0250 loss_train: 0.2523 acc_train: 1.0000 loss_val: 0.8587 acc_val: 0.7300 time: 0.0962s\n",
            "6\n",
            "Epoch: 0251 loss_train: 0.2386 acc_train: 0.9667 loss_val: 0.8540 acc_val: 0.7340 time: 0.0992s\n",
            "7\n",
            "Epoch: 0252 loss_train: 0.2571 acc_train: 0.9833 loss_val: 0.8532 acc_val: 0.7340 time: 0.0972s\n",
            "8\n",
            "Epoch: 0253 loss_train: 0.2553 acc_train: 0.9417 loss_val: 0.8547 acc_val: 0.7360 time: 0.0972s\n",
            "9\n",
            "Epoch: 0254 loss_train: 0.2433 acc_train: 0.9750 loss_val: 0.8552 acc_val: 0.7340 time: 0.0993s\n",
            "10\n",
            "Epoch: 0255 loss_train: 0.2490 acc_train: 0.9750 loss_val: 0.8557 acc_val: 0.7320 time: 0.0950s\n",
            "11\n",
            "Epoch: 0256 loss_train: 0.2447 acc_train: 0.9833 loss_val: 0.8527 acc_val: 0.7360 time: 0.0961s\n",
            "12\n",
            "Epoch: 0257 loss_train: 0.2498 acc_train: 0.9417 loss_val: 0.8504 acc_val: 0.7360 time: 0.0994s\n",
            "13\n",
            "Epoch: 0258 loss_train: 0.2465 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7340 time: 0.0961s\n",
            "14\n",
            "Epoch: 0259 loss_train: 0.2565 acc_train: 0.9667 loss_val: 0.8513 acc_val: 0.7360 time: 0.1030s\n",
            "15\n",
            "Epoch: 0260 loss_train: 0.2547 acc_train: 0.9667 loss_val: 0.8552 acc_val: 0.7340 time: 0.0954s\n",
            "16\n",
            "Epoch: 0261 loss_train: 0.2519 acc_train: 0.9667 loss_val: 0.8581 acc_val: 0.7300 time: 0.0985s\n",
            "17\n",
            "Epoch: 0262 loss_train: 0.2528 acc_train: 0.9583 loss_val: 0.8581 acc_val: 0.7300 time: 0.0977s\n",
            "18\n",
            "Epoch: 0263 loss_train: 0.2843 acc_train: 0.9750 loss_val: 0.8549 acc_val: 0.7320 time: 0.0955s\n",
            "19\n",
            "Epoch: 0264 loss_train: 0.2464 acc_train: 0.9667 loss_val: 0.8521 acc_val: 0.7360 time: 0.1023s\n",
            "20\n",
            "Epoch: 0265 loss_train: 0.2491 acc_train: 0.9750 loss_val: 0.8517 acc_val: 0.7360 time: 0.0950s\n",
            "21\n",
            "Epoch: 0266 loss_train: 0.2654 acc_train: 0.9750 loss_val: 0.8505 acc_val: 0.7340 time: 0.0959s\n",
            "22\n",
            "Epoch: 0267 loss_train: 0.2586 acc_train: 0.9667 loss_val: 0.8553 acc_val: 0.7300 time: 0.1018s\n",
            "23\n",
            "Epoch: 0268 loss_train: 0.2296 acc_train: 0.9917 loss_val: 0.8576 acc_val: 0.7300 time: 0.0949s\n",
            "24\n",
            "Epoch: 0269 loss_train: 0.2596 acc_train: 0.9667 loss_val: 0.8577 acc_val: 0.7300 time: 0.0972s\n",
            "25\n",
            "Epoch: 0270 loss_train: 0.2477 acc_train: 0.9750 loss_val: 0.8544 acc_val: 0.7380 time: 0.1013s\n",
            "26\n",
            "Epoch: 0271 loss_train: 0.2512 acc_train: 0.9500 loss_val: 0.8521 acc_val: 0.7380 time: 0.0948s\n",
            "27\n",
            "Epoch: 0272 loss_train: 0.2503 acc_train: 0.9833 loss_val: 0.8521 acc_val: 0.7440 time: 0.0974s\n",
            "28\n",
            "Epoch: 0273 loss_train: 0.2525 acc_train: 0.9833 loss_val: 0.8530 acc_val: 0.7360 time: 0.1025s\n",
            "29\n",
            "Epoch: 0274 loss_train: 0.2385 acc_train: 0.9750 loss_val: 0.8561 acc_val: 0.7300 time: 0.0976s\n",
            "30\n",
            "Epoch: 0275 loss_train: 0.2441 acc_train: 0.9917 loss_val: 0.8560 acc_val: 0.7300 time: 0.0973s\n",
            "31\n",
            "Epoch: 0276 loss_train: 0.2434 acc_train: 0.9583 loss_val: 0.8540 acc_val: 0.7320 time: 0.1028s\n",
            "32\n",
            "Epoch: 0277 loss_train: 0.2540 acc_train: 0.9750 loss_val: 0.8482 acc_val: 0.7340 time: 0.0997s\n",
            "33\n",
            "Epoch: 0278 loss_train: 0.2709 acc_train: 0.9417 loss_val: 0.8454 acc_val: 0.7420 time: 0.1041s\n",
            "34\n",
            "Epoch: 0279 loss_train: 0.2554 acc_train: 0.9750 loss_val: 0.8472 acc_val: 0.7400 time: 0.0955s\n",
            "35\n",
            "Epoch: 0280 loss_train: 0.2554 acc_train: 0.9833 loss_val: 0.8533 acc_val: 0.7360 time: 0.0951s\n",
            "36\n",
            "Epoch: 0281 loss_train: 0.2601 acc_train: 0.9667 loss_val: 0.8583 acc_val: 0.7300 time: 0.1036s\n",
            "37\n",
            "Epoch: 0282 loss_train: 0.2528 acc_train: 0.9833 loss_val: 0.8571 acc_val: 0.7360 time: 0.0971s\n",
            "38\n",
            "Epoch: 0283 loss_train: 0.2435 acc_train: 0.9583 loss_val: 0.8542 acc_val: 0.7400 time: 0.0956s\n",
            "39\n",
            "Epoch: 0284 loss_train: 0.2504 acc_train: 0.9583 loss_val: 0.8538 acc_val: 0.7400 time: 0.1021s\n",
            "40\n",
            "Epoch: 0285 loss_train: 0.2800 acc_train: 0.9500 loss_val: 0.8550 acc_val: 0.7340 time: 0.0972s\n",
            "41\n",
            "Epoch: 0286 loss_train: 0.2384 acc_train: 0.9750 loss_val: 0.8547 acc_val: 0.7360 time: 0.0959s\n",
            "42\n",
            "Epoch: 0287 loss_train: 0.2558 acc_train: 0.9500 loss_val: 0.8578 acc_val: 0.7380 time: 0.1056s\n",
            "43\n",
            "Epoch: 0288 loss_train: 0.2583 acc_train: 0.9833 loss_val: 0.8604 acc_val: 0.7320 time: 0.0958s\n",
            "44\n",
            "Epoch: 0289 loss_train: 0.2497 acc_train: 0.9667 loss_val: 0.8616 acc_val: 0.7280 time: 0.0951s\n",
            "45\n",
            "Epoch: 0290 loss_train: 0.2683 acc_train: 0.9667 loss_val: 0.8593 acc_val: 0.7320 time: 0.0986s\n",
            "46\n",
            "Epoch: 0291 loss_train: 0.2588 acc_train: 0.9750 loss_val: 0.8559 acc_val: 0.7400 time: 0.0946s\n",
            "47\n",
            "Epoch: 0292 loss_train: 0.2521 acc_train: 0.9833 loss_val: 0.8521 acc_val: 0.7400 time: 0.0969s\n",
            "48\n",
            "Epoch: 0293 loss_train: 0.2504 acc_train: 0.9833 loss_val: 0.8476 acc_val: 0.7380 time: 0.1039s\n",
            "49\n",
            "Epoch: 0294 loss_train: 0.2593 acc_train: 0.9750 loss_val: 0.8439 acc_val: 0.7440 time: 0.0989s\n",
            "50\n",
            "Epoch: 0295 loss_train: 0.2445 acc_train: 0.9833 loss_val: 0.8448 acc_val: 0.7400 time: 0.0967s\n",
            "51\n",
            "Epoch: 0296 loss_train: 0.2404 acc_train: 0.9750 loss_val: 0.8510 acc_val: 0.7380 time: 0.1022s\n",
            "52\n",
            "Epoch: 0297 loss_train: 0.2674 acc_train: 0.9583 loss_val: 0.8595 acc_val: 0.7340 time: 0.1037s\n",
            "53\n",
            "Epoch: 0298 loss_train: 0.2681 acc_train: 0.9667 loss_val: 0.8669 acc_val: 0.7240 time: 0.1033s\n",
            "54\n",
            "Epoch: 0299 loss_train: 0.2545 acc_train: 0.9750 loss_val: 0.8682 acc_val: 0.7220 time: 0.1047s\n",
            "55\n",
            "Epoch: 0300 loss_train: 0.2514 acc_train: 0.9917 loss_val: 0.8632 acc_val: 0.7260 time: 0.0969s\n",
            "56\n",
            "Epoch: 0301 loss_train: 0.2455 acc_train: 0.9667 loss_val: 0.8526 acc_val: 0.7360 time: 0.1021s\n",
            "57\n",
            "Epoch: 0302 loss_train: 0.2466 acc_train: 0.9917 loss_val: 0.8419 acc_val: 0.7380 time: 0.0952s\n",
            "58\n",
            "Epoch: 0303 loss_train: 0.2579 acc_train: 0.9750 loss_val: 0.8379 acc_val: 0.7420 time: 0.0954s\n",
            "59\n",
            "Epoch: 0304 loss_train: 0.2559 acc_train: 0.9667 loss_val: 0.8394 acc_val: 0.7420 time: 0.1012s\n",
            "0\n",
            "Epoch: 0305 loss_train: 0.2722 acc_train: 0.9667 loss_val: 0.8475 acc_val: 0.7340 time: 0.0954s\n",
            "1\n",
            "Epoch: 0306 loss_train: 0.2401 acc_train: 0.9583 loss_val: 0.8611 acc_val: 0.7260 time: 0.0980s\n",
            "2\n",
            "Epoch: 0307 loss_train: 0.2609 acc_train: 0.9750 loss_val: 0.8718 acc_val: 0.7240 time: 0.1063s\n",
            "3\n",
            "Epoch: 0308 loss_train: 0.2455 acc_train: 0.9833 loss_val: 0.8699 acc_val: 0.7260 time: 0.0995s\n",
            "4\n",
            "Epoch: 0309 loss_train: 0.2552 acc_train: 0.9667 loss_val: 0.8595 acc_val: 0.7300 time: 0.0958s\n",
            "5\n",
            "Epoch: 0310 loss_train: 0.2503 acc_train: 0.9833 loss_val: 0.8497 acc_val: 0.7340 time: 0.1001s\n",
            "6\n",
            "Epoch: 0311 loss_train: 0.2516 acc_train: 0.9750 loss_val: 0.8448 acc_val: 0.7420 time: 0.0999s\n",
            "7\n",
            "Epoch: 0312 loss_train: 0.2587 acc_train: 0.9750 loss_val: 0.8460 acc_val: 0.7420 time: 0.1010s\n",
            "8\n",
            "Epoch: 0313 loss_train: 0.2570 acc_train: 0.9917 loss_val: 0.8511 acc_val: 0.7360 time: 0.0968s\n",
            "9\n",
            "Epoch: 0314 loss_train: 0.2625 acc_train: 0.9833 loss_val: 0.8571 acc_val: 0.7320 time: 0.0960s\n",
            "10\n",
            "Epoch: 0315 loss_train: 0.2586 acc_train: 0.9667 loss_val: 0.8617 acc_val: 0.7280 time: 0.1011s\n",
            "11\n",
            "Epoch: 0316 loss_train: 0.2389 acc_train: 0.9833 loss_val: 0.8603 acc_val: 0.7320 time: 0.0959s\n",
            "12\n",
            "Epoch: 0317 loss_train: 0.2637 acc_train: 0.9583 loss_val: 0.8561 acc_val: 0.7340 time: 0.1052s\n",
            "13\n",
            "Epoch: 0318 loss_train: 0.2628 acc_train: 0.9667 loss_val: 0.8522 acc_val: 0.7360 time: 0.0993s\n",
            "14\n",
            "Epoch: 0319 loss_train: 0.2457 acc_train: 0.9917 loss_val: 0.8504 acc_val: 0.7360 time: 0.0950s\n",
            "15\n",
            "Epoch: 0320 loss_train: 0.2546 acc_train: 0.9583 loss_val: 0.8502 acc_val: 0.7400 time: 0.0974s\n",
            "16\n",
            "Epoch: 0321 loss_train: 0.2484 acc_train: 0.9500 loss_val: 0.8525 acc_val: 0.7420 time: 0.0966s\n",
            "17\n",
            "Epoch: 0322 loss_train: 0.2430 acc_train: 0.9750 loss_val: 0.8554 acc_val: 0.7380 time: 0.0953s\n",
            "18\n",
            "Epoch: 0323 loss_train: 0.2410 acc_train: 0.9750 loss_val: 0.8573 acc_val: 0.7360 time: 0.1028s\n",
            "19\n",
            "Epoch: 0324 loss_train: 0.2524 acc_train: 0.9583 loss_val: 0.8606 acc_val: 0.7360 time: 0.0991s\n",
            "20\n",
            "Epoch: 0325 loss_train: 0.2767 acc_train: 0.9417 loss_val: 0.8616 acc_val: 0.7340 time: 0.0948s\n",
            "21\n",
            "Epoch: 0326 loss_train: 0.2490 acc_train: 0.9750 loss_val: 0.8562 acc_val: 0.7360 time: 0.0997s\n",
            "22\n",
            "Epoch: 0327 loss_train: 0.2579 acc_train: 0.9500 loss_val: 0.8518 acc_val: 0.7380 time: 0.0970s\n",
            "23\n",
            "Epoch: 0328 loss_train: 0.2654 acc_train: 0.9750 loss_val: 0.8496 acc_val: 0.7360 time: 0.0981s\n",
            "24\n",
            "Epoch: 0329 loss_train: 0.2691 acc_train: 0.9417 loss_val: 0.8514 acc_val: 0.7400 time: 0.0966s\n",
            "25\n",
            "Epoch: 0330 loss_train: 0.2444 acc_train: 0.9750 loss_val: 0.8545 acc_val: 0.7380 time: 0.0963s\n",
            "26\n",
            "Epoch: 0331 loss_train: 0.2669 acc_train: 0.9750 loss_val: 0.8584 acc_val: 0.7340 time: 0.1036s\n",
            "27\n",
            "Epoch: 0332 loss_train: 0.2476 acc_train: 0.9750 loss_val: 0.8626 acc_val: 0.7320 time: 0.0971s\n",
            "28\n",
            "Epoch: 0333 loss_train: 0.2353 acc_train: 0.9833 loss_val: 0.8627 acc_val: 0.7320 time: 0.0947s\n",
            "29\n",
            "Epoch: 0334 loss_train: 0.2530 acc_train: 0.9833 loss_val: 0.8602 acc_val: 0.7360 time: 0.1053s\n",
            "30\n",
            "Epoch: 0335 loss_train: 0.2443 acc_train: 0.9833 loss_val: 0.8562 acc_val: 0.7360 time: 0.0953s\n",
            "31\n",
            "Epoch: 0336 loss_train: 0.2537 acc_train: 0.9583 loss_val: 0.8530 acc_val: 0.7340 time: 0.0960s\n",
            "32\n",
            "Epoch: 0337 loss_train: 0.2458 acc_train: 0.9417 loss_val: 0.8500 acc_val: 0.7340 time: 0.1038s\n",
            "33\n",
            "Epoch: 0338 loss_train: 0.2375 acc_train: 0.9750 loss_val: 0.8496 acc_val: 0.7360 time: 0.1001s\n",
            "34\n",
            "Epoch: 0339 loss_train: 0.2392 acc_train: 0.9750 loss_val: 0.8512 acc_val: 0.7380 time: 0.0952s\n",
            "35\n",
            "Epoch: 0340 loss_train: 0.2453 acc_train: 0.9583 loss_val: 0.8540 acc_val: 0.7340 time: 0.1011s\n",
            "36\n",
            "Epoch: 0341 loss_train: 0.2578 acc_train: 0.9500 loss_val: 0.8553 acc_val: 0.7360 time: 0.0954s\n",
            "37\n",
            "Epoch: 0342 loss_train: 0.2480 acc_train: 0.9833 loss_val: 0.8546 acc_val: 0.7380 time: 0.0963s\n",
            "38\n",
            "Epoch: 0343 loss_train: 0.2454 acc_train: 0.9583 loss_val: 0.8515 acc_val: 0.7380 time: 0.1008s\n",
            "39\n",
            "Epoch: 0344 loss_train: 0.2675 acc_train: 0.9667 loss_val: 0.8477 acc_val: 0.7360 time: 0.0969s\n",
            "40\n",
            "Epoch: 0345 loss_train: 0.2515 acc_train: 0.9750 loss_val: 0.8453 acc_val: 0.7340 time: 0.1024s\n",
            "41\n",
            "Epoch: 0346 loss_train: 0.2651 acc_train: 0.9583 loss_val: 0.8450 acc_val: 0.7360 time: 0.0974s\n",
            "42\n",
            "Epoch: 0347 loss_train: 0.2421 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7380 time: 0.1070s\n",
            "43\n",
            "Epoch: 0348 loss_train: 0.2636 acc_train: 0.9667 loss_val: 0.8493 acc_val: 0.7360 time: 0.0980s\n",
            "44\n",
            "Epoch: 0349 loss_train: 0.2518 acc_train: 0.9750 loss_val: 0.8494 acc_val: 0.7340 time: 0.0956s\n",
            "45\n",
            "Epoch: 0350 loss_train: 0.2364 acc_train: 0.9667 loss_val: 0.8508 acc_val: 0.7340 time: 0.1017s\n",
            "46\n",
            "Epoch: 0351 loss_train: 0.2464 acc_train: 0.9583 loss_val: 0.8534 acc_val: 0.7300 time: 0.0972s\n",
            "47\n",
            "Epoch: 0352 loss_train: 0.2523 acc_train: 0.9583 loss_val: 0.8522 acc_val: 0.7320 time: 0.0958s\n",
            "48\n",
            "Epoch: 0353 loss_train: 0.2620 acc_train: 0.9750 loss_val: 0.8483 acc_val: 0.7380 time: 0.1040s\n",
            "49\n",
            "Epoch: 0354 loss_train: 0.2479 acc_train: 0.9667 loss_val: 0.8474 acc_val: 0.7340 time: 0.0974s\n",
            "50\n",
            "Epoch: 0355 loss_train: 0.2493 acc_train: 0.9500 loss_val: 0.8477 acc_val: 0.7380 time: 0.0961s\n",
            "51\n",
            "Epoch: 0356 loss_train: 0.2468 acc_train: 0.9583 loss_val: 0.8469 acc_val: 0.7380 time: 0.1029s\n",
            "52\n",
            "Epoch: 0357 loss_train: 0.2493 acc_train: 0.9667 loss_val: 0.8509 acc_val: 0.7340 time: 0.0984s\n",
            "53\n",
            "Epoch: 0358 loss_train: 0.2564 acc_train: 0.9500 loss_val: 0.8540 acc_val: 0.7340 time: 0.0973s\n",
            "54\n",
            "Epoch: 0359 loss_train: 0.2606 acc_train: 0.9750 loss_val: 0.8569 acc_val: 0.7340 time: 0.1056s\n",
            "55\n",
            "Epoch: 0360 loss_train: 0.2596 acc_train: 0.9667 loss_val: 0.8580 acc_val: 0.7320 time: 0.0946s\n",
            "56\n",
            "Epoch: 0361 loss_train: 0.2588 acc_train: 0.9667 loss_val: 0.8533 acc_val: 0.7360 time: 0.1034s\n",
            "57\n",
            "Epoch: 0362 loss_train: 0.2608 acc_train: 0.9667 loss_val: 0.8454 acc_val: 0.7360 time: 0.0974s\n",
            "58\n",
            "Epoch: 0363 loss_train: 0.2589 acc_train: 0.9833 loss_val: 0.8434 acc_val: 0.7340 time: 0.0956s\n",
            "59\n",
            "Epoch: 0364 loss_train: 0.2509 acc_train: 0.9250 loss_val: 0.8443 acc_val: 0.7380 time: 0.1020s\n",
            "60\n",
            "Epoch: 0365 loss_train: 0.2602 acc_train: 0.9750 loss_val: 0.8503 acc_val: 0.7360 time: 0.0959s\n",
            "61\n",
            "Epoch: 0366 loss_train: 0.2488 acc_train: 0.9583 loss_val: 0.8561 acc_val: 0.7320 time: 0.0994s\n",
            "62\n",
            "Epoch: 0367 loss_train: 0.2705 acc_train: 0.9750 loss_val: 0.8611 acc_val: 0.7280 time: 0.1056s\n",
            "63\n",
            "Epoch: 0368 loss_train: 0.2604 acc_train: 0.9583 loss_val: 0.8595 acc_val: 0.7280 time: 0.1019s\n",
            "64\n",
            "Epoch: 0369 loss_train: 0.2396 acc_train: 0.9833 loss_val: 0.8547 acc_val: 0.7340 time: 0.0973s\n",
            "65\n",
            "Epoch: 0370 loss_train: 0.2607 acc_train: 0.9833 loss_val: 0.8527 acc_val: 0.7360 time: 0.1043s\n",
            "66\n",
            "Epoch: 0371 loss_train: 0.2662 acc_train: 0.9500 loss_val: 0.8485 acc_val: 0.7380 time: 0.0960s\n",
            "67\n",
            "Epoch: 0372 loss_train: 0.2592 acc_train: 0.9833 loss_val: 0.8471 acc_val: 0.7380 time: 0.1014s\n",
            "68\n",
            "Epoch: 0373 loss_train: 0.2472 acc_train: 0.9417 loss_val: 0.8514 acc_val: 0.7360 time: 0.0958s\n",
            "69\n",
            "Epoch: 0374 loss_train: 0.2510 acc_train: 0.9583 loss_val: 0.8565 acc_val: 0.7320 time: 0.0953s\n",
            "70\n",
            "Epoch: 0375 loss_train: 0.2509 acc_train: 0.9750 loss_val: 0.8588 acc_val: 0.7320 time: 0.1044s\n",
            "71\n",
            "Epoch: 0376 loss_train: 0.2471 acc_train: 0.9750 loss_val: 0.8608 acc_val: 0.7320 time: 0.0979s\n",
            "72\n",
            "Epoch: 0377 loss_train: 0.2457 acc_train: 0.9833 loss_val: 0.8569 acc_val: 0.7380 time: 0.1030s\n",
            "73\n",
            "Epoch: 0378 loss_train: 0.2485 acc_train: 0.9750 loss_val: 0.8541 acc_val: 0.7380 time: 0.1005s\n",
            "74\n",
            "Epoch: 0379 loss_train: 0.2702 acc_train: 0.9583 loss_val: 0.8492 acc_val: 0.7360 time: 0.0952s\n",
            "75\n",
            "Epoch: 0380 loss_train: 0.2428 acc_train: 0.9583 loss_val: 0.8463 acc_val: 0.7360 time: 0.0986s\n",
            "76\n",
            "Epoch: 0381 loss_train: 0.2748 acc_train: 0.9667 loss_val: 0.8477 acc_val: 0.7360 time: 0.0969s\n",
            "77\n",
            "Epoch: 0382 loss_train: 0.2457 acc_train: 0.9750 loss_val: 0.8505 acc_val: 0.7360 time: 0.0953s\n",
            "78\n",
            "Epoch: 0383 loss_train: 0.2428 acc_train: 0.9750 loss_val: 0.8523 acc_val: 0.7320 time: 0.1017s\n",
            "79\n",
            "Epoch: 0384 loss_train: 0.2557 acc_train: 0.9583 loss_val: 0.8547 acc_val: 0.7300 time: 0.0981s\n",
            "80\n",
            "Epoch: 0385 loss_train: 0.2461 acc_train: 0.9750 loss_val: 0.8549 acc_val: 0.7320 time: 0.0984s\n",
            "81\n",
            "Epoch: 0386 loss_train: 0.2518 acc_train: 0.9667 loss_val: 0.8572 acc_val: 0.7300 time: 0.0981s\n",
            "82\n",
            "Epoch: 0387 loss_train: 0.2295 acc_train: 0.9917 loss_val: 0.8578 acc_val: 0.7340 time: 0.0976s\n",
            "83\n",
            "Epoch: 0388 loss_train: 0.2555 acc_train: 0.9583 loss_val: 0.8581 acc_val: 0.7340 time: 0.1018s\n",
            "84\n",
            "Epoch: 0389 loss_train: 0.2641 acc_train: 0.9667 loss_val: 0.8559 acc_val: 0.7380 time: 0.0954s\n",
            "85\n",
            "Epoch: 0390 loss_train: 0.2500 acc_train: 0.9750 loss_val: 0.8509 acc_val: 0.7360 time: 0.0955s\n",
            "86\n",
            "Epoch: 0391 loss_train: 0.2485 acc_train: 0.9667 loss_val: 0.8497 acc_val: 0.7380 time: 0.1014s\n",
            "87\n",
            "Epoch: 0392 loss_train: 0.2524 acc_train: 0.9667 loss_val: 0.8472 acc_val: 0.7380 time: 0.0947s\n",
            "88\n",
            "Epoch: 0393 loss_train: 0.2618 acc_train: 0.9583 loss_val: 0.8467 acc_val: 0.7420 time: 0.0970s\n",
            "89\n",
            "Epoch: 0394 loss_train: 0.2607 acc_train: 0.9417 loss_val: 0.8505 acc_val: 0.7380 time: 0.1004s\n",
            "90\n",
            "Epoch: 0395 loss_train: 0.2581 acc_train: 0.9667 loss_val: 0.8532 acc_val: 0.7360 time: 0.0951s\n",
            "91\n",
            "Epoch: 0396 loss_train: 0.2505 acc_train: 0.9583 loss_val: 0.8534 acc_val: 0.7360 time: 0.0959s\n",
            "92\n",
            "Epoch: 0397 loss_train: 0.2521 acc_train: 0.9750 loss_val: 0.8526 acc_val: 0.7360 time: 0.1071s\n",
            "93\n",
            "Epoch: 0398 loss_train: 0.2495 acc_train: 0.9833 loss_val: 0.8547 acc_val: 0.7360 time: 0.1004s\n",
            "94\n",
            "Epoch: 0399 loss_train: 0.2554 acc_train: 0.9917 loss_val: 0.8522 acc_val: 0.7320 time: 0.0986s\n",
            "95\n",
            "Epoch: 0400 loss_train: 0.2687 acc_train: 0.9750 loss_val: 0.8503 acc_val: 0.7380 time: 0.1062s\n",
            "96\n",
            "Epoch: 0401 loss_train: 0.2592 acc_train: 0.9583 loss_val: 0.8495 acc_val: 0.7400 time: 0.0945s\n",
            "97\n",
            "Epoch: 0402 loss_train: 0.2483 acc_train: 0.9833 loss_val: 0.8483 acc_val: 0.7420 time: 0.1004s\n",
            "98\n",
            "Epoch: 0403 loss_train: 0.2578 acc_train: 0.9417 loss_val: 0.8506 acc_val: 0.7420 time: 0.0951s\n",
            "99\n",
            "Epoch: 0404 loss_train: 0.2512 acc_train: 0.9750 loss_val: 0.8565 acc_val: 0.7320 time: 0.0944s\n",
            "100\n",
            "Epoch: 0405 loss_train: 0.2621 acc_train: 0.9500 loss_val: 0.8596 acc_val: 0.7320 time: 0.0983s\n",
            "101\n",
            "Epoch: 0406 loss_train: 0.2713 acc_train: 0.9500 loss_val: 0.8588 acc_val: 0.7300 time: 0.0953s\n",
            "102\n",
            "Epoch: 0407 loss_train: 0.2592 acc_train: 0.9750 loss_val: 0.8531 acc_val: 0.7340 time: 0.1043s\n",
            "103\n",
            "Epoch: 0408 loss_train: 0.2597 acc_train: 0.9750 loss_val: 0.8491 acc_val: 0.7380 time: 0.0994s\n",
            "104\n",
            "Epoch: 0409 loss_train: 0.2508 acc_train: 0.9750 loss_val: 0.8466 acc_val: 0.7400 time: 0.0979s\n",
            "105\n",
            "Epoch: 0410 loss_train: 0.2387 acc_train: 0.9750 loss_val: 0.8484 acc_val: 0.7360 time: 0.1001s\n",
            "106\n",
            "Epoch: 0411 loss_train: 0.2511 acc_train: 0.9667 loss_val: 0.8494 acc_val: 0.7360 time: 0.0952s\n",
            "107\n",
            "Epoch: 0412 loss_train: 0.2675 acc_train: 0.9833 loss_val: 0.8523 acc_val: 0.7380 time: 0.0951s\n",
            "108\n",
            "Epoch: 0413 loss_train: 0.2595 acc_train: 0.9583 loss_val: 0.8538 acc_val: 0.7400 time: 0.1087s\n",
            "109\n",
            "Epoch: 0414 loss_train: 0.2339 acc_train: 0.9917 loss_val: 0.8513 acc_val: 0.7380 time: 0.0978s\n",
            "110\n",
            "Epoch: 0415 loss_train: 0.2418 acc_train: 0.9917 loss_val: 0.8471 acc_val: 0.7400 time: 0.0976s\n",
            "111\n",
            "Epoch: 0416 loss_train: 0.2613 acc_train: 0.9583 loss_val: 0.8429 acc_val: 0.7360 time: 0.1034s\n",
            "112\n",
            "Epoch: 0417 loss_train: 0.2543 acc_train: 0.9583 loss_val: 0.8409 acc_val: 0.7380 time: 0.1008s\n",
            "113\n",
            "Epoch: 0418 loss_train: 0.2496 acc_train: 0.9583 loss_val: 0.8443 acc_val: 0.7380 time: 0.0955s\n",
            "114\n",
            "Epoch: 0419 loss_train: 0.2546 acc_train: 0.9583 loss_val: 0.8507 acc_val: 0.7340 time: 0.0989s\n",
            "115\n",
            "Epoch: 0420 loss_train: 0.2639 acc_train: 0.9833 loss_val: 0.8566 acc_val: 0.7380 time: 0.0949s\n",
            "116\n",
            "Epoch: 0421 loss_train: 0.2546 acc_train: 0.9583 loss_val: 0.8583 acc_val: 0.7400 time: 0.0970s\n",
            "117\n",
            "Epoch: 0422 loss_train: 0.2539 acc_train: 0.9917 loss_val: 0.8568 acc_val: 0.7340 time: 0.0957s\n",
            "118\n",
            "Epoch: 0423 loss_train: 0.2545 acc_train: 0.9833 loss_val: 0.8507 acc_val: 0.7400 time: 0.0966s\n",
            "119\n",
            "Epoch: 0424 loss_train: 0.2447 acc_train: 0.9833 loss_val: 0.8447 acc_val: 0.7360 time: 0.1033s\n",
            "120\n",
            "Epoch: 0425 loss_train: 0.2465 acc_train: 0.9667 loss_val: 0.8428 acc_val: 0.7380 time: 0.0963s\n",
            "121\n",
            "Epoch: 0426 loss_train: 0.2564 acc_train: 0.9583 loss_val: 0.8470 acc_val: 0.7320 time: 0.0956s\n",
            "122\n",
            "Epoch: 0427 loss_train: 0.2460 acc_train: 0.9750 loss_val: 0.8517 acc_val: 0.7300 time: 0.1055s\n",
            "123\n",
            "Epoch: 0428 loss_train: 0.2531 acc_train: 0.9750 loss_val: 0.8588 acc_val: 0.7320 time: 0.1006s\n",
            "124\n",
            "Epoch: 0429 loss_train: 0.2488 acc_train: 0.9417 loss_val: 0.8632 acc_val: 0.7320 time: 0.0985s\n",
            "125\n",
            "Epoch: 0430 loss_train: 0.2566 acc_train: 0.9583 loss_val: 0.8597 acc_val: 0.7320 time: 0.1025s\n",
            "126\n",
            "Epoch: 0431 loss_train: 0.2600 acc_train: 0.9500 loss_val: 0.8554 acc_val: 0.7360 time: 0.0956s\n",
            "127\n",
            "Epoch: 0432 loss_train: 0.2386 acc_train: 0.9500 loss_val: 0.8513 acc_val: 0.7380 time: 0.1013s\n",
            "128\n",
            "Epoch: 0433 loss_train: 0.2475 acc_train: 0.9500 loss_val: 0.8458 acc_val: 0.7420 time: 0.0958s\n",
            "129\n",
            "Epoch: 0434 loss_train: 0.2658 acc_train: 0.9583 loss_val: 0.8421 acc_val: 0.7400 time: 0.0971s\n",
            "130\n",
            "Epoch: 0435 loss_train: 0.2447 acc_train: 0.9417 loss_val: 0.8461 acc_val: 0.7360 time: 0.0998s\n",
            "131\n",
            "Epoch: 0436 loss_train: 0.2466 acc_train: 0.9583 loss_val: 0.8565 acc_val: 0.7300 time: 0.0961s\n",
            "132\n",
            "Epoch: 0437 loss_train: 0.2591 acc_train: 0.9750 loss_val: 0.8637 acc_val: 0.7300 time: 0.1029s\n",
            "133\n",
            "Epoch: 0438 loss_train: 0.2579 acc_train: 0.9750 loss_val: 0.8649 acc_val: 0.7320 time: 0.1024s\n",
            "134\n",
            "Epoch: 0439 loss_train: 0.2591 acc_train: 0.9667 loss_val: 0.8603 acc_val: 0.7340 time: 0.1030s\n",
            "135\n",
            "Epoch: 0440 loss_train: 0.2558 acc_train: 0.9750 loss_val: 0.8515 acc_val: 0.7340 time: 0.1058s\n",
            "136\n",
            "Epoch: 0441 loss_train: 0.2548 acc_train: 0.9750 loss_val: 0.8457 acc_val: 0.7340 time: 0.1001s\n",
            "137\n",
            "Epoch: 0442 loss_train: 0.2480 acc_train: 0.9750 loss_val: 0.8430 acc_val: 0.7320 time: 0.1009s\n",
            "138\n",
            "Epoch: 0443 loss_train: 0.2556 acc_train: 0.9750 loss_val: 0.8464 acc_val: 0.7320 time: 0.0958s\n",
            "139\n",
            "Epoch: 0444 loss_train: 0.2525 acc_train: 0.9583 loss_val: 0.8526 acc_val: 0.7300 time: 0.1006s\n",
            "140\n",
            "Epoch: 0445 loss_train: 0.2532 acc_train: 0.9750 loss_val: 0.8587 acc_val: 0.7300 time: 0.0963s\n",
            "141\n",
            "Epoch: 0446 loss_train: 0.2440 acc_train: 0.9750 loss_val: 0.8595 acc_val: 0.7280 time: 0.1046s\n",
            "142\n",
            "Epoch: 0447 loss_train: 0.2463 acc_train: 0.9750 loss_val: 0.8546 acc_val: 0.7320 time: 0.1015s\n",
            "143\n",
            "Epoch: 0448 loss_train: 0.2601 acc_train: 0.9667 loss_val: 0.8492 acc_val: 0.7380 time: 0.0959s\n",
            "144\n",
            "Epoch: 0449 loss_train: 0.2432 acc_train: 0.9917 loss_val: 0.8446 acc_val: 0.7400 time: 0.1003s\n",
            "145\n",
            "Epoch: 0450 loss_train: 0.2441 acc_train: 0.9667 loss_val: 0.8461 acc_val: 0.7400 time: 0.0959s\n",
            "146\n",
            "Epoch: 0451 loss_train: 0.2515 acc_train: 0.9833 loss_val: 0.8494 acc_val: 0.7380 time: 0.0983s\n",
            "147\n",
            "Epoch: 0452 loss_train: 0.2550 acc_train: 0.9500 loss_val: 0.8543 acc_val: 0.7340 time: 0.0961s\n",
            "148\n",
            "Epoch: 0453 loss_train: 0.2565 acc_train: 0.9750 loss_val: 0.8585 acc_val: 0.7300 time: 0.0983s\n",
            "149\n",
            "Epoch: 0454 loss_train: 0.2611 acc_train: 0.9417 loss_val: 0.8587 acc_val: 0.7300 time: 0.1043s\n",
            "150\n",
            "Epoch: 0455 loss_train: 0.2755 acc_train: 0.9750 loss_val: 0.8546 acc_val: 0.7300 time: 0.0991s\n",
            "151\n",
            "Epoch: 0456 loss_train: 0.2606 acc_train: 0.9750 loss_val: 0.8495 acc_val: 0.7400 time: 0.1035s\n",
            "152\n",
            "Epoch: 0457 loss_train: 0.2479 acc_train: 0.9583 loss_val: 0.8476 acc_val: 0.7380 time: 0.1034s\n",
            "153\n",
            "Epoch: 0458 loss_train: 0.2523 acc_train: 0.9667 loss_val: 0.8473 acc_val: 0.7380 time: 0.1058s\n",
            "154\n",
            "Epoch: 0459 loss_train: 0.2473 acc_train: 0.9833 loss_val: 0.8513 acc_val: 0.7340 time: 0.0949s\n",
            "155\n",
            "Epoch: 0460 loss_train: 0.2661 acc_train: 0.9500 loss_val: 0.8584 acc_val: 0.7260 time: 0.1007s\n",
            "156\n",
            "Epoch: 0461 loss_train: 0.2554 acc_train: 0.9583 loss_val: 0.8647 acc_val: 0.7260 time: 0.0950s\n",
            "157\n",
            "Epoch: 0462 loss_train: 0.2559 acc_train: 0.9750 loss_val: 0.8639 acc_val: 0.7240 time: 0.0951s\n",
            "158\n",
            "Epoch: 0463 loss_train: 0.2502 acc_train: 0.9583 loss_val: 0.8587 acc_val: 0.7280 time: 0.1002s\n",
            "159\n",
            "Epoch: 0464 loss_train: 0.2559 acc_train: 0.9667 loss_val: 0.8556 acc_val: 0.7300 time: 0.0952s\n",
            "160\n",
            "Epoch: 0465 loss_train: 0.2410 acc_train: 0.9833 loss_val: 0.8519 acc_val: 0.7340 time: 0.0963s\n",
            "161\n",
            "Epoch: 0466 loss_train: 0.2404 acc_train: 0.9750 loss_val: 0.8513 acc_val: 0.7380 time: 0.1009s\n",
            "162\n",
            "Epoch: 0467 loss_train: 0.2691 acc_train: 0.9750 loss_val: 0.8531 acc_val: 0.7400 time: 0.1011s\n",
            "163\n",
            "Epoch: 0468 loss_train: 0.2579 acc_train: 0.9667 loss_val: 0.8554 acc_val: 0.7320 time: 0.0954s\n",
            "164\n",
            "Epoch: 0469 loss_train: 0.2359 acc_train: 0.9750 loss_val: 0.8557 acc_val: 0.7340 time: 0.1045s\n",
            "165\n",
            "Epoch: 0470 loss_train: 0.2516 acc_train: 0.9667 loss_val: 0.8548 acc_val: 0.7320 time: 0.1021s\n",
            "166\n",
            "Epoch: 0471 loss_train: 0.2526 acc_train: 0.9583 loss_val: 0.8572 acc_val: 0.7280 time: 0.1036s\n",
            "167\n",
            "Epoch: 0472 loss_train: 0.2406 acc_train: 0.9500 loss_val: 0.8557 acc_val: 0.7300 time: 0.0977s\n",
            "168\n",
            "Epoch: 0473 loss_train: 0.2577 acc_train: 0.9833 loss_val: 0.8513 acc_val: 0.7320 time: 0.1039s\n",
            "169\n",
            "Epoch: 0474 loss_train: 0.2709 acc_train: 0.9667 loss_val: 0.8483 acc_val: 0.7320 time: 0.0953s\n",
            "170\n",
            "Epoch: 0475 loss_train: 0.2580 acc_train: 0.9833 loss_val: 0.8483 acc_val: 0.7380 time: 0.0983s\n",
            "171\n",
            "Epoch: 0476 loss_train: 0.2545 acc_train: 0.9750 loss_val: 0.8537 acc_val: 0.7320 time: 0.0985s\n",
            "172\n",
            "Epoch: 0477 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.8576 acc_val: 0.7300 time: 0.0989s\n",
            "173\n",
            "Epoch: 0478 loss_train: 0.2560 acc_train: 0.9583 loss_val: 0.8576 acc_val: 0.7300 time: 0.1015s\n",
            "174\n",
            "Epoch: 0479 loss_train: 0.2399 acc_train: 0.9667 loss_val: 0.8533 acc_val: 0.7340 time: 0.0988s\n",
            "175\n",
            "Epoch: 0480 loss_train: 0.2665 acc_train: 0.9667 loss_val: 0.8459 acc_val: 0.7340 time: 0.0974s\n",
            "176\n",
            "Epoch: 0481 loss_train: 0.2523 acc_train: 0.9750 loss_val: 0.8434 acc_val: 0.7340 time: 0.1006s\n",
            "177\n",
            "Epoch: 0482 loss_train: 0.2421 acc_train: 0.9583 loss_val: 0.8453 acc_val: 0.7360 time: 0.0955s\n",
            "178\n",
            "Epoch: 0483 loss_train: 0.2519 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7400 time: 0.1002s\n",
            "179\n",
            "Epoch: 0484 loss_train: 0.2368 acc_train: 0.9833 loss_val: 0.8527 acc_val: 0.7380 time: 0.0953s\n",
            "180\n",
            "Epoch: 0485 loss_train: 0.2513 acc_train: 0.9917 loss_val: 0.8565 acc_val: 0.7340 time: 0.0961s\n",
            "181\n",
            "Epoch: 0486 loss_train: 0.2511 acc_train: 0.9833 loss_val: 0.8565 acc_val: 0.7300 time: 0.0986s\n",
            "182\n",
            "Epoch: 0487 loss_train: 0.2482 acc_train: 0.9583 loss_val: 0.8519 acc_val: 0.7300 time: 0.0997s\n",
            "183\n",
            "Epoch: 0488 loss_train: 0.2700 acc_train: 0.9500 loss_val: 0.8498 acc_val: 0.7360 time: 0.0968s\n",
            "184\n",
            "Epoch: 0489 loss_train: 0.2360 acc_train: 0.9833 loss_val: 0.8467 acc_val: 0.7360 time: 0.1004s\n",
            "185\n",
            "Epoch: 0490 loss_train: 0.2564 acc_train: 0.9750 loss_val: 0.8459 acc_val: 0.7400 time: 0.0984s\n",
            "186\n",
            "Epoch: 0491 loss_train: 0.2619 acc_train: 0.9583 loss_val: 0.8476 acc_val: 0.7400 time: 0.0990s\n",
            "187\n",
            "Epoch: 0492 loss_train: 0.2392 acc_train: 0.9750 loss_val: 0.8507 acc_val: 0.7400 time: 0.0966s\n",
            "188\n",
            "Epoch: 0493 loss_train: 0.2569 acc_train: 0.9750 loss_val: 0.8510 acc_val: 0.7360 time: 0.0991s\n",
            "189\n",
            "Epoch: 0494 loss_train: 0.2657 acc_train: 0.9333 loss_val: 0.8517 acc_val: 0.7340 time: 0.1043s\n",
            "190\n",
            "Epoch: 0495 loss_train: 0.2489 acc_train: 0.9833 loss_val: 0.8549 acc_val: 0.7320 time: 0.0989s\n",
            "191\n",
            "Epoch: 0496 loss_train: 0.2571 acc_train: 0.9917 loss_val: 0.8588 acc_val: 0.7300 time: 0.1012s\n",
            "192\n",
            "Epoch: 0497 loss_train: 0.2587 acc_train: 0.9583 loss_val: 0.8606 acc_val: 0.7300 time: 0.0998s\n",
            "193\n",
            "Epoch: 0498 loss_train: 0.2635 acc_train: 0.9750 loss_val: 0.8571 acc_val: 0.7300 time: 0.0967s\n",
            "194\n",
            "Epoch: 0499 loss_train: 0.2419 acc_train: 0.9833 loss_val: 0.8513 acc_val: 0.7340 time: 0.1011s\n",
            "195\n",
            "Epoch: 0500 loss_train: 0.2614 acc_train: 0.9583 loss_val: 0.8483 acc_val: 0.7360 time: 0.0946s\n",
            "196\n",
            "Epoch: 0501 loss_train: 0.2587 acc_train: 0.9667 loss_val: 0.8490 acc_val: 0.7340 time: 0.0988s\n",
            "197\n",
            "Epoch: 0502 loss_train: 0.2561 acc_train: 0.9667 loss_val: 0.8536 acc_val: 0.7360 time: 0.0959s\n",
            "198\n",
            "Epoch: 0503 loss_train: 0.2552 acc_train: 0.9750 loss_val: 0.8577 acc_val: 0.7320 time: 0.0953s\n",
            "199\n",
            "Early stop! Min loss:  0.8378822803497314 , Max accuracy:  0.746\n",
            "Early stop model validation loss:  0.8378822803497314 , accuracy:  0.742\n",
            "Optimization Finished!\n",
            "Total time elapsed: 50.9346s\n",
            "Loading 302th epoch\n",
            "Test set results: loss= 0.8203 accuracy= 0.7250\n",
            "Epoch: 0001 loss_train: 0.2708 acc_train: 0.9750 loss_val: 0.8455 acc_val: 0.7400 time: 0.1029s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.2762 acc_train: 0.9917 loss_val: 0.8594 acc_val: 0.7300 time: 0.1012s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.2763 acc_train: 0.9667 loss_val: 0.8676 acc_val: 0.7220 time: 0.1018s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.2853 acc_train: 0.9667 loss_val: 0.8657 acc_val: 0.7280 time: 0.1044s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.2913 acc_train: 0.9667 loss_val: 0.8524 acc_val: 0.7360 time: 0.0997s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.2684 acc_train: 0.9833 loss_val: 0.8404 acc_val: 0.7460 time: 0.0992s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.2667 acc_train: 0.9667 loss_val: 0.8341 acc_val: 0.7440 time: 0.1019s\n",
            "0\n",
            "Epoch: 0008 loss_train: 0.2839 acc_train: 0.9583 loss_val: 0.8354 acc_val: 0.7460 time: 0.0979s\n",
            "0\n",
            "Epoch: 0009 loss_train: 0.2547 acc_train: 0.9833 loss_val: 0.8402 acc_val: 0.7440 time: 0.1013s\n",
            "0\n",
            "Epoch: 0010 loss_train: 0.2876 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7420 time: 0.0956s\n",
            "1\n",
            "Epoch: 0011 loss_train: 0.2907 acc_train: 0.9500 loss_val: 0.8509 acc_val: 0.7320 time: 0.1012s\n",
            "2\n",
            "Epoch: 0012 loss_train: 0.2801 acc_train: 0.9583 loss_val: 0.8525 acc_val: 0.7360 time: 0.0972s\n",
            "3\n",
            "Epoch: 0013 loss_train: 0.2630 acc_train: 0.9833 loss_val: 0.8496 acc_val: 0.7340 time: 0.0949s\n",
            "4\n",
            "Epoch: 0014 loss_train: 0.2735 acc_train: 0.9833 loss_val: 0.8437 acc_val: 0.7400 time: 0.1041s\n",
            "5\n",
            "Epoch: 0015 loss_train: 0.2616 acc_train: 0.9750 loss_val: 0.8395 acc_val: 0.7380 time: 0.0959s\n",
            "6\n",
            "Epoch: 0016 loss_train: 0.2827 acc_train: 0.9667 loss_val: 0.8413 acc_val: 0.7400 time: 0.0963s\n",
            "7\n",
            "Epoch: 0017 loss_train: 0.2806 acc_train: 0.9750 loss_val: 0.8450 acc_val: 0.7380 time: 0.0994s\n",
            "8\n",
            "Epoch: 0018 loss_train: 0.2615 acc_train: 0.9583 loss_val: 0.8475 acc_val: 0.7400 time: 0.0977s\n",
            "9\n",
            "Epoch: 0019 loss_train: 0.2662 acc_train: 0.9583 loss_val: 0.8487 acc_val: 0.7400 time: 0.0954s\n",
            "10\n",
            "Epoch: 0020 loss_train: 0.2856 acc_train: 0.9750 loss_val: 0.8483 acc_val: 0.7360 time: 0.1044s\n",
            "11\n",
            "Epoch: 0021 loss_train: 0.2752 acc_train: 0.9667 loss_val: 0.8482 acc_val: 0.7320 time: 0.0991s\n",
            "12\n",
            "Epoch: 0022 loss_train: 0.2822 acc_train: 0.9667 loss_val: 0.8492 acc_val: 0.7280 time: 0.0954s\n",
            "13\n",
            "Epoch: 0023 loss_train: 0.2715 acc_train: 0.9667 loss_val: 0.8474 acc_val: 0.7320 time: 0.1048s\n",
            "14\n",
            "Epoch: 0024 loss_train: 0.2730 acc_train: 1.0000 loss_val: 0.8452 acc_val: 0.7340 time: 0.0988s\n",
            "15\n",
            "Epoch: 0025 loss_train: 0.2743 acc_train: 0.9667 loss_val: 0.8439 acc_val: 0.7380 time: 0.0999s\n",
            "16\n",
            "Epoch: 0026 loss_train: 0.2823 acc_train: 0.9500 loss_val: 0.8437 acc_val: 0.7400 time: 0.0971s\n",
            "17\n",
            "Epoch: 0027 loss_train: 0.2936 acc_train: 0.9750 loss_val: 0.8442 acc_val: 0.7380 time: 0.0955s\n",
            "18\n",
            "Epoch: 0028 loss_train: 0.2581 acc_train: 0.9667 loss_val: 0.8468 acc_val: 0.7400 time: 0.1009s\n",
            "19\n",
            "Epoch: 0029 loss_train: 0.2469 acc_train: 0.9917 loss_val: 0.8515 acc_val: 0.7340 time: 0.0972s\n",
            "20\n",
            "Epoch: 0030 loss_train: 0.2772 acc_train: 0.9500 loss_val: 0.8542 acc_val: 0.7320 time: 0.0954s\n",
            "21\n",
            "Epoch: 0031 loss_train: 0.2695 acc_train: 0.9583 loss_val: 0.8539 acc_val: 0.7300 time: 0.1022s\n",
            "22\n",
            "Epoch: 0032 loss_train: 0.2732 acc_train: 0.9667 loss_val: 0.8512 acc_val: 0.7320 time: 0.0952s\n",
            "23\n",
            "Epoch: 0033 loss_train: 0.2777 acc_train: 0.9333 loss_val: 0.8502 acc_val: 0.7340 time: 0.0952s\n",
            "24\n",
            "Epoch: 0034 loss_train: 0.2691 acc_train: 0.9500 loss_val: 0.8486 acc_val: 0.7400 time: 0.1065s\n",
            "25\n",
            "Epoch: 0035 loss_train: 0.2805 acc_train: 0.9833 loss_val: 0.8451 acc_val: 0.7400 time: 0.1036s\n",
            "26\n",
            "Epoch: 0036 loss_train: 0.2816 acc_train: 0.9750 loss_val: 0.8437 acc_val: 0.7460 time: 0.1015s\n",
            "27\n",
            "Epoch: 0037 loss_train: 0.2626 acc_train: 0.9833 loss_val: 0.8423 acc_val: 0.7460 time: 0.1012s\n",
            "0\n",
            "Epoch: 0038 loss_train: 0.2665 acc_train: 0.9667 loss_val: 0.8441 acc_val: 0.7460 time: 0.1000s\n",
            "0\n",
            "Epoch: 0039 loss_train: 0.2688 acc_train: 0.9667 loss_val: 0.8449 acc_val: 0.7440 time: 0.1053s\n",
            "0\n",
            "Epoch: 0040 loss_train: 0.2624 acc_train: 0.9750 loss_val: 0.8494 acc_val: 0.7380 time: 0.1036s\n",
            "1\n",
            "Epoch: 0041 loss_train: 0.2738 acc_train: 0.9583 loss_val: 0.8510 acc_val: 0.7360 time: 0.0977s\n",
            "2\n",
            "Epoch: 0042 loss_train: 0.2662 acc_train: 0.9750 loss_val: 0.8496 acc_val: 0.7400 time: 0.1068s\n",
            "3\n",
            "Epoch: 0043 loss_train: 0.2660 acc_train: 0.9583 loss_val: 0.8462 acc_val: 0.7420 time: 0.0972s\n",
            "4\n",
            "Epoch: 0044 loss_train: 0.2779 acc_train: 0.9667 loss_val: 0.8418 acc_val: 0.7440 time: 0.1034s\n",
            "5\n",
            "Epoch: 0045 loss_train: 0.2692 acc_train: 0.9583 loss_val: 0.8380 acc_val: 0.7440 time: 0.1000s\n",
            "6\n",
            "Epoch: 0046 loss_train: 0.2714 acc_train: 0.9833 loss_val: 0.8383 acc_val: 0.7440 time: 0.0986s\n",
            "7\n",
            "Epoch: 0047 loss_train: 0.2831 acc_train: 0.9583 loss_val: 0.8429 acc_val: 0.7440 time: 0.0984s\n",
            "8\n",
            "Epoch: 0048 loss_train: 0.2804 acc_train: 0.9750 loss_val: 0.8503 acc_val: 0.7420 time: 0.1078s\n",
            "9\n",
            "Epoch: 0049 loss_train: 0.2829 acc_train: 0.9500 loss_val: 0.8540 acc_val: 0.7400 time: 0.0962s\n",
            "10\n",
            "Epoch: 0050 loss_train: 0.2739 acc_train: 0.9583 loss_val: 0.8483 acc_val: 0.7380 time: 0.1044s\n",
            "11\n",
            "Epoch: 0051 loss_train: 0.2702 acc_train: 0.9750 loss_val: 0.8404 acc_val: 0.7440 time: 0.0967s\n",
            "12\n",
            "Epoch: 0052 loss_train: 0.2609 acc_train: 0.9833 loss_val: 0.8348 acc_val: 0.7460 time: 0.0978s\n",
            "13\n",
            "Epoch: 0053 loss_train: 0.2600 acc_train: 0.9833 loss_val: 0.8326 acc_val: 0.7460 time: 0.0997s\n",
            "0\n",
            "Epoch: 0054 loss_train: 0.2703 acc_train: 0.9750 loss_val: 0.8348 acc_val: 0.7460 time: 0.1000s\n",
            "0\n",
            "Epoch: 0055 loss_train: 0.2726 acc_train: 0.9917 loss_val: 0.8438 acc_val: 0.7460 time: 0.1051s\n",
            "0\n",
            "Epoch: 0056 loss_train: 0.2644 acc_train: 0.9750 loss_val: 0.8510 acc_val: 0.7420 time: 0.0974s\n",
            "0\n",
            "Epoch: 0057 loss_train: 0.2636 acc_train: 0.9750 loss_val: 0.8581 acc_val: 0.7400 time: 0.0967s\n",
            "1\n",
            "Epoch: 0058 loss_train: 0.2663 acc_train: 0.9583 loss_val: 0.8564 acc_val: 0.7400 time: 0.1011s\n",
            "2\n",
            "Epoch: 0059 loss_train: 0.2695 acc_train: 0.9583 loss_val: 0.8496 acc_val: 0.7420 time: 0.0957s\n",
            "3\n",
            "Epoch: 0060 loss_train: 0.2592 acc_train: 0.9750 loss_val: 0.8430 acc_val: 0.7440 time: 0.0989s\n",
            "4\n",
            "Epoch: 0061 loss_train: 0.2661 acc_train: 0.9583 loss_val: 0.8389 acc_val: 0.7460 time: 0.0956s\n",
            "5\n",
            "Epoch: 0062 loss_train: 0.2694 acc_train: 0.9750 loss_val: 0.8392 acc_val: 0.7440 time: 0.0952s\n",
            "0\n",
            "Epoch: 0063 loss_train: 0.2535 acc_train: 0.9750 loss_val: 0.8428 acc_val: 0.7400 time: 0.0992s\n",
            "1\n",
            "Epoch: 0064 loss_train: 0.2524 acc_train: 0.9583 loss_val: 0.8453 acc_val: 0.7400 time: 0.1036s\n",
            "2\n",
            "Epoch: 0065 loss_train: 0.2647 acc_train: 0.9833 loss_val: 0.8430 acc_val: 0.7440 time: 0.0982s\n",
            "3\n",
            "Epoch: 0066 loss_train: 0.2650 acc_train: 0.9667 loss_val: 0.8426 acc_val: 0.7440 time: 0.0992s\n",
            "4\n",
            "Epoch: 0067 loss_train: 0.2697 acc_train: 0.9833 loss_val: 0.8436 acc_val: 0.7440 time: 0.0956s\n",
            "5\n",
            "Epoch: 0068 loss_train: 0.2747 acc_train: 0.9667 loss_val: 0.8444 acc_val: 0.7440 time: 0.1024s\n",
            "6\n",
            "Epoch: 0069 loss_train: 0.2783 acc_train: 0.9917 loss_val: 0.8426 acc_val: 0.7440 time: 0.0979s\n",
            "7\n",
            "Epoch: 0070 loss_train: 0.2668 acc_train: 0.9917 loss_val: 0.8427 acc_val: 0.7420 time: 0.0994s\n",
            "8\n",
            "Epoch: 0071 loss_train: 0.2719 acc_train: 0.9917 loss_val: 0.8405 acc_val: 0.7400 time: 0.1027s\n",
            "9\n",
            "Epoch: 0072 loss_train: 0.2698 acc_train: 0.9750 loss_val: 0.8405 acc_val: 0.7380 time: 0.0952s\n",
            "10\n",
            "Epoch: 0073 loss_train: 0.2594 acc_train: 0.9583 loss_val: 0.8392 acc_val: 0.7420 time: 0.1028s\n",
            "11\n",
            "Epoch: 0074 loss_train: 0.2459 acc_train: 0.9667 loss_val: 0.8413 acc_val: 0.7360 time: 0.1026s\n",
            "12\n",
            "Epoch: 0075 loss_train: 0.2590 acc_train: 0.9750 loss_val: 0.8459 acc_val: 0.7360 time: 0.1008s\n",
            "13\n",
            "Epoch: 0076 loss_train: 0.2621 acc_train: 0.9333 loss_val: 0.8492 acc_val: 0.7360 time: 0.0982s\n",
            "14\n",
            "Epoch: 0077 loss_train: 0.2717 acc_train: 0.9833 loss_val: 0.8497 acc_val: 0.7400 time: 0.1004s\n",
            "15\n",
            "Epoch: 0078 loss_train: 0.2616 acc_train: 0.9667 loss_val: 0.8475 acc_val: 0.7440 time: 0.0996s\n",
            "16\n",
            "Epoch: 0079 loss_train: 0.2650 acc_train: 0.9750 loss_val: 0.8440 acc_val: 0.7420 time: 0.0960s\n",
            "17\n",
            "Epoch: 0080 loss_train: 0.2762 acc_train: 0.9667 loss_val: 0.8401 acc_val: 0.7400 time: 0.0965s\n",
            "18\n",
            "Epoch: 0081 loss_train: 0.2564 acc_train: 0.9750 loss_val: 0.8378 acc_val: 0.7420 time: 0.0992s\n",
            "19\n",
            "Epoch: 0082 loss_train: 0.2607 acc_train: 1.0000 loss_val: 0.8419 acc_val: 0.7400 time: 0.1002s\n",
            "20\n",
            "Epoch: 0083 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.8485 acc_val: 0.7360 time: 0.0977s\n",
            "21\n",
            "Epoch: 0084 loss_train: 0.2797 acc_train: 0.9500 loss_val: 0.8541 acc_val: 0.7320 time: 0.1082s\n",
            "22\n",
            "Epoch: 0085 loss_train: 0.2632 acc_train: 0.9833 loss_val: 0.8532 acc_val: 0.7340 time: 0.1012s\n",
            "23\n",
            "Epoch: 0086 loss_train: 0.2736 acc_train: 0.9750 loss_val: 0.8514 acc_val: 0.7360 time: 0.1047s\n",
            "24\n",
            "Epoch: 0087 loss_train: 0.2726 acc_train: 0.9500 loss_val: 0.8434 acc_val: 0.7360 time: 0.0958s\n",
            "25\n",
            "Epoch: 0088 loss_train: 0.2735 acc_train: 0.9833 loss_val: 0.8383 acc_val: 0.7380 time: 0.0962s\n",
            "26\n",
            "Epoch: 0089 loss_train: 0.2596 acc_train: 0.9750 loss_val: 0.8387 acc_val: 0.7380 time: 0.1018s\n",
            "27\n",
            "Epoch: 0090 loss_train: 0.2661 acc_train: 0.9833 loss_val: 0.8440 acc_val: 0.7360 time: 0.0963s\n",
            "28\n",
            "Epoch: 0091 loss_train: 0.2676 acc_train: 0.9500 loss_val: 0.8513 acc_val: 0.7340 time: 0.0983s\n",
            "29\n",
            "Epoch: 0092 loss_train: 0.2917 acc_train: 0.9500 loss_val: 0.8577 acc_val: 0.7340 time: 0.1033s\n",
            "30\n",
            "Epoch: 0093 loss_train: 0.2596 acc_train: 0.9833 loss_val: 0.8555 acc_val: 0.7320 time: 0.0987s\n",
            "31\n",
            "Epoch: 0094 loss_train: 0.2724 acc_train: 0.9667 loss_val: 0.8500 acc_val: 0.7340 time: 0.1062s\n",
            "32\n",
            "Epoch: 0095 loss_train: 0.2667 acc_train: 0.9750 loss_val: 0.8446 acc_val: 0.7380 time: 0.0960s\n",
            "33\n",
            "Epoch: 0096 loss_train: 0.2726 acc_train: 0.9750 loss_val: 0.8391 acc_val: 0.7420 time: 0.0961s\n",
            "34\n",
            "Epoch: 0097 loss_train: 0.2720 acc_train: 0.9667 loss_val: 0.8394 acc_val: 0.7420 time: 0.1009s\n",
            "35\n",
            "Epoch: 0098 loss_train: 0.2611 acc_train: 0.9583 loss_val: 0.8436 acc_val: 0.7380 time: 0.0949s\n",
            "36\n",
            "Epoch: 0099 loss_train: 0.2618 acc_train: 0.9583 loss_val: 0.8489 acc_val: 0.7400 time: 0.1012s\n",
            "37\n",
            "Epoch: 0100 loss_train: 0.2750 acc_train: 0.9667 loss_val: 0.8523 acc_val: 0.7420 time: 0.1068s\n",
            "38\n",
            "Epoch: 0101 loss_train: 0.2697 acc_train: 0.9583 loss_val: 0.8509 acc_val: 0.7380 time: 0.1035s\n",
            "39\n",
            "Epoch: 0102 loss_train: 0.2475 acc_train: 0.9833 loss_val: 0.8486 acc_val: 0.7420 time: 0.0957s\n",
            "40\n",
            "Epoch: 0103 loss_train: 0.2696 acc_train: 0.9750 loss_val: 0.8446 acc_val: 0.7380 time: 0.0983s\n",
            "41\n",
            "Epoch: 0104 loss_train: 0.2562 acc_train: 0.9917 loss_val: 0.8411 acc_val: 0.7440 time: 0.1097s\n",
            "42\n",
            "Epoch: 0105 loss_train: 0.2561 acc_train: 0.9750 loss_val: 0.8387 acc_val: 0.7400 time: 0.1007s\n",
            "43\n",
            "Epoch: 0106 loss_train: 0.2573 acc_train: 0.9583 loss_val: 0.8404 acc_val: 0.7380 time: 0.1013s\n",
            "44\n",
            "Epoch: 0107 loss_train: 0.2637 acc_train: 0.9583 loss_val: 0.8450 acc_val: 0.7420 time: 0.1086s\n",
            "45\n",
            "Epoch: 0108 loss_train: 0.2722 acc_train: 0.9750 loss_val: 0.8486 acc_val: 0.7400 time: 0.0962s\n",
            "46\n",
            "Epoch: 0109 loss_train: 0.2849 acc_train: 0.9500 loss_val: 0.8490 acc_val: 0.7420 time: 0.1009s\n",
            "47\n",
            "Epoch: 0110 loss_train: 0.2728 acc_train: 0.9667 loss_val: 0.8520 acc_val: 0.7400 time: 0.0953s\n",
            "48\n",
            "Epoch: 0111 loss_train: 0.2667 acc_train: 0.9583 loss_val: 0.8537 acc_val: 0.7340 time: 0.0996s\n",
            "49\n",
            "Epoch: 0112 loss_train: 0.2652 acc_train: 0.9750 loss_val: 0.8495 acc_val: 0.7400 time: 0.1565s\n",
            "50\n",
            "Epoch: 0113 loss_train: 0.2773 acc_train: 0.9583 loss_val: 0.8429 acc_val: 0.7440 time: 0.1065s\n",
            "51\n",
            "Epoch: 0114 loss_train: 0.2773 acc_train: 0.9583 loss_val: 0.8379 acc_val: 0.7440 time: 0.0984s\n",
            "52\n",
            "Epoch: 0115 loss_train: 0.2739 acc_train: 0.9583 loss_val: 0.8364 acc_val: 0.7420 time: 0.0964s\n",
            "53\n",
            "Epoch: 0116 loss_train: 0.2545 acc_train: 0.9583 loss_val: 0.8394 acc_val: 0.7440 time: 0.1023s\n",
            "54\n",
            "Epoch: 0117 loss_train: 0.2760 acc_train: 0.9500 loss_val: 0.8439 acc_val: 0.7460 time: 0.0957s\n",
            "55\n",
            "Epoch: 0118 loss_train: 0.2661 acc_train: 0.9750 loss_val: 0.8488 acc_val: 0.7400 time: 0.1051s\n",
            "0\n",
            "Epoch: 0119 loss_train: 0.2752 acc_train: 0.9583 loss_val: 0.8512 acc_val: 0.7400 time: 0.0962s\n",
            "1\n",
            "Epoch: 0120 loss_train: 0.2841 acc_train: 0.9417 loss_val: 0.8493 acc_val: 0.7400 time: 0.0996s\n",
            "2\n",
            "Epoch: 0121 loss_train: 0.2612 acc_train: 0.9750 loss_val: 0.8440 acc_val: 0.7460 time: 0.1004s\n",
            "3\n",
            "Epoch: 0122 loss_train: 0.2583 acc_train: 0.9583 loss_val: 0.8416 acc_val: 0.7460 time: 0.0955s\n",
            "0\n",
            "Epoch: 0123 loss_train: 0.2876 acc_train: 0.9500 loss_val: 0.8408 acc_val: 0.7420 time: 0.1037s\n",
            "0\n",
            "Epoch: 0124 loss_train: 0.2694 acc_train: 0.9500 loss_val: 0.8439 acc_val: 0.7460 time: 0.0954s\n",
            "1\n",
            "Epoch: 0125 loss_train: 0.2700 acc_train: 0.9667 loss_val: 0.8507 acc_val: 0.7480 time: 0.0957s\n",
            "0\n",
            "Epoch: 0126 loss_train: 0.2727 acc_train: 0.9583 loss_val: 0.8560 acc_val: 0.7440 time: 0.1019s\n",
            "0\n",
            "Epoch: 0127 loss_train: 0.2774 acc_train: 0.9500 loss_val: 0.8569 acc_val: 0.7400 time: 0.0987s\n",
            "1\n",
            "Epoch: 0128 loss_train: 0.2548 acc_train: 0.9917 loss_val: 0.8498 acc_val: 0.7380 time: 0.0984s\n",
            "2\n",
            "Epoch: 0129 loss_train: 0.2686 acc_train: 0.9667 loss_val: 0.8424 acc_val: 0.7400 time: 0.1098s\n",
            "3\n",
            "Epoch: 0130 loss_train: 0.2761 acc_train: 0.9667 loss_val: 0.8380 acc_val: 0.7420 time: 0.0992s\n",
            "4\n",
            "Epoch: 0131 loss_train: 0.2667 acc_train: 0.9667 loss_val: 0.8363 acc_val: 0.7420 time: 0.1042s\n",
            "5\n",
            "Epoch: 0132 loss_train: 0.2600 acc_train: 0.9917 loss_val: 0.8425 acc_val: 0.7400 time: 0.0969s\n",
            "6\n",
            "Epoch: 0133 loss_train: 0.2684 acc_train: 0.9833 loss_val: 0.8496 acc_val: 0.7360 time: 0.1028s\n",
            "7\n",
            "Epoch: 0134 loss_train: 0.2753 acc_train: 0.9667 loss_val: 0.8550 acc_val: 0.7380 time: 0.0958s\n",
            "8\n",
            "Epoch: 0135 loss_train: 0.2536 acc_train: 0.9583 loss_val: 0.8575 acc_val: 0.7360 time: 0.0960s\n",
            "9\n",
            "Epoch: 0136 loss_train: 0.2688 acc_train: 0.9750 loss_val: 0.8533 acc_val: 0.7340 time: 0.1007s\n",
            "10\n",
            "Epoch: 0137 loss_train: 0.2759 acc_train: 0.9583 loss_val: 0.8440 acc_val: 0.7360 time: 0.0950s\n",
            "11\n",
            "Epoch: 0138 loss_train: 0.2780 acc_train: 0.9583 loss_val: 0.8354 acc_val: 0.7440 time: 0.0973s\n",
            "12\n",
            "Epoch: 0139 loss_train: 0.2599 acc_train: 0.9917 loss_val: 0.8330 acc_val: 0.7460 time: 0.1045s\n",
            "13\n",
            "Epoch: 0140 loss_train: 0.2772 acc_train: 0.9500 loss_val: 0.8368 acc_val: 0.7420 time: 0.1014s\n",
            "14\n",
            "Epoch: 0141 loss_train: 0.2808 acc_train: 0.9500 loss_val: 0.8459 acc_val: 0.7360 time: 0.1039s\n",
            "15\n",
            "Epoch: 0142 loss_train: 0.2676 acc_train: 0.9583 loss_val: 0.8517 acc_val: 0.7380 time: 0.1140s\n",
            "16\n",
            "Epoch: 0143 loss_train: 0.2738 acc_train: 0.9917 loss_val: 0.8539 acc_val: 0.7380 time: 0.1139s\n",
            "17\n",
            "Epoch: 0144 loss_train: 0.2712 acc_train: 0.9417 loss_val: 0.8507 acc_val: 0.7400 time: 0.1030s\n",
            "18\n",
            "Epoch: 0145 loss_train: 0.2595 acc_train: 0.9750 loss_val: 0.8424 acc_val: 0.7400 time: 0.1103s\n",
            "19\n",
            "Epoch: 0146 loss_train: 0.2533 acc_train: 0.9833 loss_val: 0.8365 acc_val: 0.7440 time: 0.0961s\n",
            "20\n",
            "Epoch: 0147 loss_train: 0.2590 acc_train: 0.9917 loss_val: 0.8369 acc_val: 0.7460 time: 0.0953s\n",
            "21\n",
            "Epoch: 0148 loss_train: 0.2687 acc_train: 0.9500 loss_val: 0.8393 acc_val: 0.7400 time: 0.1051s\n",
            "22\n",
            "Epoch: 0149 loss_train: 0.2619 acc_train: 0.9750 loss_val: 0.8443 acc_val: 0.7400 time: 0.1000s\n",
            "23\n",
            "Epoch: 0150 loss_train: 0.2670 acc_train: 0.9500 loss_val: 0.8516 acc_val: 0.7380 time: 0.0976s\n",
            "24\n",
            "Epoch: 0151 loss_train: 0.2643 acc_train: 0.9583 loss_val: 0.8572 acc_val: 0.7360 time: 0.1080s\n",
            "25\n",
            "Epoch: 0152 loss_train: 0.2463 acc_train: 0.9917 loss_val: 0.8560 acc_val: 0.7380 time: 0.1034s\n",
            "26\n",
            "Epoch: 0153 loss_train: 0.2610 acc_train: 0.9667 loss_val: 0.8486 acc_val: 0.7380 time: 0.1070s\n",
            "27\n",
            "Epoch: 0154 loss_train: 0.2782 acc_train: 0.9750 loss_val: 0.8398 acc_val: 0.7420 time: 0.0998s\n",
            "28\n",
            "Epoch: 0155 loss_train: 0.2592 acc_train: 0.9667 loss_val: 0.8357 acc_val: 0.7440 time: 0.1065s\n",
            "29\n",
            "Epoch: 0156 loss_train: 0.2711 acc_train: 0.9750 loss_val: 0.8394 acc_val: 0.7460 time: 0.0959s\n",
            "30\n",
            "Epoch: 0157 loss_train: 0.2656 acc_train: 0.9667 loss_val: 0.8482 acc_val: 0.7400 time: 0.1011s\n",
            "31\n",
            "Epoch: 0158 loss_train: 0.2552 acc_train: 0.9750 loss_val: 0.8579 acc_val: 0.7340 time: 0.0981s\n",
            "32\n",
            "Epoch: 0159 loss_train: 0.2626 acc_train: 0.9583 loss_val: 0.8615 acc_val: 0.7280 time: 0.0993s\n",
            "33\n",
            "Epoch: 0160 loss_train: 0.2672 acc_train: 0.9500 loss_val: 0.8547 acc_val: 0.7340 time: 0.1018s\n",
            "34\n",
            "Epoch: 0161 loss_train: 0.2743 acc_train: 0.9750 loss_val: 0.8442 acc_val: 0.7400 time: 0.0966s\n",
            "35\n",
            "Epoch: 0162 loss_train: 0.2714 acc_train: 0.9333 loss_val: 0.8371 acc_val: 0.7420 time: 0.1051s\n",
            "36\n",
            "Epoch: 0163 loss_train: 0.2831 acc_train: 0.9500 loss_val: 0.8363 acc_val: 0.7440 time: 0.0956s\n",
            "37\n",
            "Epoch: 0164 loss_train: 0.2722 acc_train: 0.9583 loss_val: 0.8427 acc_val: 0.7380 time: 0.0970s\n",
            "38\n",
            "Epoch: 0165 loss_train: 0.2664 acc_train: 0.9500 loss_val: 0.8514 acc_val: 0.7360 time: 0.1035s\n",
            "39\n",
            "Epoch: 0166 loss_train: 0.2664 acc_train: 0.9417 loss_val: 0.8575 acc_val: 0.7300 time: 0.0995s\n",
            "40\n",
            "Epoch: 0167 loss_train: 0.2722 acc_train: 0.9833 loss_val: 0.8574 acc_val: 0.7300 time: 0.0978s\n",
            "41\n",
            "Epoch: 0168 loss_train: 0.2810 acc_train: 0.9583 loss_val: 0.8489 acc_val: 0.7340 time: 0.1059s\n",
            "42\n",
            "Epoch: 0169 loss_train: 0.2745 acc_train: 0.9583 loss_val: 0.8420 acc_val: 0.7400 time: 0.0979s\n",
            "43\n",
            "Epoch: 0170 loss_train: 0.2669 acc_train: 0.9750 loss_val: 0.8401 acc_val: 0.7380 time: 0.1038s\n",
            "44\n",
            "Epoch: 0171 loss_train: 0.2820 acc_train: 0.9750 loss_val: 0.8442 acc_val: 0.7360 time: 0.0948s\n",
            "45\n",
            "Epoch: 0172 loss_train: 0.2587 acc_train: 0.9833 loss_val: 0.8482 acc_val: 0.7360 time: 0.1027s\n",
            "46\n",
            "Epoch: 0173 loss_train: 0.2683 acc_train: 0.9833 loss_val: 0.8516 acc_val: 0.7380 time: 0.1002s\n",
            "47\n",
            "Epoch: 0174 loss_train: 0.2657 acc_train: 0.9750 loss_val: 0.8518 acc_val: 0.7340 time: 0.0970s\n",
            "48\n",
            "Epoch: 0175 loss_train: 0.2755 acc_train: 0.9583 loss_val: 0.8458 acc_val: 0.7400 time: 0.1014s\n",
            "49\n",
            "Epoch: 0176 loss_train: 0.2628 acc_train: 0.9667 loss_val: 0.8382 acc_val: 0.7420 time: 0.0956s\n",
            "50\n",
            "Epoch: 0177 loss_train: 0.2517 acc_train: 0.9750 loss_val: 0.8355 acc_val: 0.7400 time: 0.1024s\n",
            "51\n",
            "Epoch: 0178 loss_train: 0.2694 acc_train: 0.9667 loss_val: 0.8375 acc_val: 0.7400 time: 0.0994s\n",
            "52\n",
            "Epoch: 0179 loss_train: 0.2601 acc_train: 0.9583 loss_val: 0.8421 acc_val: 0.7360 time: 0.0984s\n",
            "53\n",
            "Epoch: 0180 loss_train: 0.2604 acc_train: 0.9833 loss_val: 0.8452 acc_val: 0.7380 time: 0.1055s\n",
            "54\n",
            "Epoch: 0181 loss_train: 0.2513 acc_train: 0.9833 loss_val: 0.8465 acc_val: 0.7360 time: 0.0976s\n",
            "55\n",
            "Epoch: 0182 loss_train: 0.2603 acc_train: 0.9500 loss_val: 0.8447 acc_val: 0.7360 time: 0.1051s\n",
            "56\n",
            "Epoch: 0183 loss_train: 0.2742 acc_train: 0.9667 loss_val: 0.8406 acc_val: 0.7360 time: 0.0955s\n",
            "57\n",
            "Epoch: 0184 loss_train: 0.2492 acc_train: 0.9667 loss_val: 0.8384 acc_val: 0.7380 time: 0.0960s\n",
            "58\n",
            "Epoch: 0185 loss_train: 0.2675 acc_train: 0.9500 loss_val: 0.8379 acc_val: 0.7400 time: 0.1034s\n",
            "59\n",
            "Epoch: 0186 loss_train: 0.2746 acc_train: 0.9583 loss_val: 0.8403 acc_val: 0.7380 time: 0.0959s\n",
            "60\n",
            "Epoch: 0187 loss_train: 0.2825 acc_train: 0.9500 loss_val: 0.8450 acc_val: 0.7400 time: 0.0995s\n",
            "61\n",
            "Epoch: 0188 loss_train: 0.2734 acc_train: 0.9750 loss_val: 0.8503 acc_val: 0.7340 time: 0.1021s\n",
            "62\n",
            "Epoch: 0189 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.8514 acc_val: 0.7360 time: 0.0963s\n",
            "63\n",
            "Epoch: 0190 loss_train: 0.2720 acc_train: 0.9583 loss_val: 0.8491 acc_val: 0.7380 time: 0.1064s\n",
            "64\n",
            "Epoch: 0191 loss_train: 0.2598 acc_train: 0.9833 loss_val: 0.8459 acc_val: 0.7380 time: 0.0996s\n",
            "65\n",
            "Epoch: 0192 loss_train: 0.2775 acc_train: 0.9667 loss_val: 0.8398 acc_val: 0.7360 time: 0.1033s\n",
            "66\n",
            "Epoch: 0193 loss_train: 0.2816 acc_train: 0.9500 loss_val: 0.8388 acc_val: 0.7420 time: 0.1041s\n",
            "67\n",
            "Epoch: 0194 loss_train: 0.2699 acc_train: 0.9500 loss_val: 0.8420 acc_val: 0.7400 time: 0.0967s\n",
            "68\n",
            "Epoch: 0195 loss_train: 0.2536 acc_train: 0.9667 loss_val: 0.8484 acc_val: 0.7360 time: 0.1027s\n",
            "69\n",
            "Epoch: 0196 loss_train: 0.2759 acc_train: 0.9667 loss_val: 0.8555 acc_val: 0.7340 time: 0.0967s\n",
            "70\n",
            "Epoch: 0197 loss_train: 0.2589 acc_train: 0.9667 loss_val: 0.8578 acc_val: 0.7340 time: 0.0973s\n",
            "71\n",
            "Epoch: 0198 loss_train: 0.2813 acc_train: 0.9667 loss_val: 0.8577 acc_val: 0.7340 time: 0.1024s\n",
            "72\n",
            "Epoch: 0199 loss_train: 0.2850 acc_train: 0.9333 loss_val: 0.8519 acc_val: 0.7360 time: 0.0984s\n",
            "73\n",
            "Epoch: 0200 loss_train: 0.2676 acc_train: 0.9833 loss_val: 0.8425 acc_val: 0.7380 time: 0.1021s\n",
            "74\n",
            "Epoch: 0201 loss_train: 0.2723 acc_train: 0.9750 loss_val: 0.8360 acc_val: 0.7420 time: 0.0964s\n",
            "75\n",
            "Epoch: 0202 loss_train: 0.2680 acc_train: 0.9667 loss_val: 0.8353 acc_val: 0.7420 time: 0.1022s\n",
            "76\n",
            "Epoch: 0203 loss_train: 0.2763 acc_train: 0.9500 loss_val: 0.8401 acc_val: 0.7380 time: 0.1290s\n",
            "77\n",
            "Epoch: 0204 loss_train: 0.2743 acc_train: 0.9750 loss_val: 0.8457 acc_val: 0.7400 time: 0.1077s\n",
            "78\n",
            "Epoch: 0205 loss_train: 0.2774 acc_train: 0.9833 loss_val: 0.8493 acc_val: 0.7420 time: 0.1049s\n",
            "79\n",
            "Epoch: 0206 loss_train: 0.2739 acc_train: 0.9667 loss_val: 0.8512 acc_val: 0.7420 time: 0.1074s\n",
            "80\n",
            "Epoch: 0207 loss_train: 0.2665 acc_train: 0.9667 loss_val: 0.8500 acc_val: 0.7380 time: 0.1064s\n",
            "81\n",
            "Epoch: 0208 loss_train: 0.2637 acc_train: 0.9667 loss_val: 0.8460 acc_val: 0.7400 time: 0.1008s\n",
            "82\n",
            "Epoch: 0209 loss_train: 0.2571 acc_train: 0.9500 loss_val: 0.8427 acc_val: 0.7400 time: 0.1018s\n",
            "83\n",
            "Epoch: 0210 loss_train: 0.2721 acc_train: 0.9750 loss_val: 0.8416 acc_val: 0.7400 time: 0.0991s\n",
            "84\n",
            "Epoch: 0211 loss_train: 0.2567 acc_train: 0.9667 loss_val: 0.8439 acc_val: 0.7380 time: 0.1071s\n",
            "85\n",
            "Epoch: 0212 loss_train: 0.2687 acc_train: 0.9833 loss_val: 0.8482 acc_val: 0.7380 time: 0.1010s\n",
            "86\n",
            "Epoch: 0213 loss_train: 0.2757 acc_train: 0.9667 loss_val: 0.8503 acc_val: 0.7380 time: 0.1071s\n",
            "87\n",
            "Epoch: 0214 loss_train: 0.2602 acc_train: 0.9833 loss_val: 0.8495 acc_val: 0.7380 time: 0.0993s\n",
            "88\n",
            "Epoch: 0215 loss_train: 0.2673 acc_train: 0.9500 loss_val: 0.8476 acc_val: 0.7440 time: 0.1055s\n",
            "89\n",
            "Epoch: 0216 loss_train: 0.2837 acc_train: 0.9667 loss_val: 0.8468 acc_val: 0.7440 time: 0.0993s\n",
            "90\n",
            "Epoch: 0217 loss_train: 0.2561 acc_train: 0.9583 loss_val: 0.8468 acc_val: 0.7440 time: 0.1033s\n",
            "91\n",
            "Epoch: 0218 loss_train: 0.2527 acc_train: 0.9667 loss_val: 0.8461 acc_val: 0.7420 time: 0.0982s\n",
            "92\n",
            "Epoch: 0219 loss_train: 0.2474 acc_train: 0.9750 loss_val: 0.8453 acc_val: 0.7380 time: 0.1037s\n",
            "93\n",
            "Epoch: 0220 loss_train: 0.2819 acc_train: 0.9417 loss_val: 0.8441 acc_val: 0.7380 time: 0.0972s\n",
            "94\n",
            "Epoch: 0221 loss_train: 0.2860 acc_train: 0.9417 loss_val: 0.8438 acc_val: 0.7400 time: 0.1000s\n",
            "95\n",
            "Epoch: 0222 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.8455 acc_val: 0.7400 time: 0.1070s\n",
            "96\n",
            "Epoch: 0223 loss_train: 0.2660 acc_train: 0.9750 loss_val: 0.8472 acc_val: 0.7420 time: 0.0980s\n",
            "97\n",
            "Epoch: 0224 loss_train: 0.2663 acc_train: 0.9750 loss_val: 0.8473 acc_val: 0.7400 time: 0.1035s\n",
            "98\n",
            "Epoch: 0225 loss_train: 0.2671 acc_train: 0.9667 loss_val: 0.8465 acc_val: 0.7420 time: 0.1013s\n",
            "99\n",
            "Epoch: 0226 loss_train: 0.2741 acc_train: 0.9750 loss_val: 0.8435 acc_val: 0.7400 time: 0.1017s\n",
            "100\n",
            "Epoch: 0227 loss_train: 0.2731 acc_train: 0.9750 loss_val: 0.8434 acc_val: 0.7380 time: 0.0957s\n",
            "101\n",
            "Epoch: 0228 loss_train: 0.2569 acc_train: 0.9500 loss_val: 0.8437 acc_val: 0.7400 time: 0.0959s\n",
            "102\n",
            "Epoch: 0229 loss_train: 0.2713 acc_train: 0.9667 loss_val: 0.8452 acc_val: 0.7400 time: 0.1003s\n",
            "103\n",
            "Epoch: 0230 loss_train: 0.2805 acc_train: 0.9583 loss_val: 0.8464 acc_val: 0.7380 time: 0.0974s\n",
            "104\n",
            "Epoch: 0231 loss_train: 0.2705 acc_train: 0.9833 loss_val: 0.8461 acc_val: 0.7380 time: 0.0985s\n",
            "105\n",
            "Epoch: 0232 loss_train: 0.2641 acc_train: 0.9917 loss_val: 0.8450 acc_val: 0.7400 time: 0.1032s\n",
            "106\n",
            "Epoch: 0233 loss_train: 0.2564 acc_train: 0.9750 loss_val: 0.8448 acc_val: 0.7380 time: 0.0977s\n",
            "107\n",
            "Epoch: 0234 loss_train: 0.2710 acc_train: 0.9833 loss_val: 0.8422 acc_val: 0.7420 time: 0.0996s\n",
            "108\n",
            "Epoch: 0235 loss_train: 0.2932 acc_train: 0.9500 loss_val: 0.8431 acc_val: 0.7400 time: 0.0960s\n",
            "109\n",
            "Epoch: 0236 loss_train: 0.2682 acc_train: 0.9583 loss_val: 0.8475 acc_val: 0.7380 time: 0.0972s\n",
            "110\n",
            "Epoch: 0237 loss_train: 0.2723 acc_train: 0.9667 loss_val: 0.8530 acc_val: 0.7360 time: 0.1018s\n",
            "111\n",
            "Epoch: 0238 loss_train: 0.2666 acc_train: 0.9667 loss_val: 0.8575 acc_val: 0.7300 time: 0.0959s\n",
            "112\n",
            "Epoch: 0239 loss_train: 0.2547 acc_train: 1.0000 loss_val: 0.8583 acc_val: 0.7320 time: 0.0987s\n",
            "113\n",
            "Epoch: 0240 loss_train: 0.2764 acc_train: 0.9583 loss_val: 0.8518 acc_val: 0.7360 time: 0.1122s\n",
            "114\n",
            "Epoch: 0241 loss_train: 0.2697 acc_train: 0.9833 loss_val: 0.8446 acc_val: 0.7440 time: 0.1065s\n",
            "115\n",
            "Epoch: 0242 loss_train: 0.2526 acc_train: 0.9917 loss_val: 0.8387 acc_val: 0.7400 time: 0.1072s\n",
            "116\n",
            "Epoch: 0243 loss_train: 0.2807 acc_train: 0.9500 loss_val: 0.8361 acc_val: 0.7380 time: 0.0975s\n",
            "117\n",
            "Epoch: 0244 loss_train: 0.2547 acc_train: 0.9583 loss_val: 0.8386 acc_val: 0.7420 time: 0.1062s\n",
            "118\n",
            "Epoch: 0245 loss_train: 0.2674 acc_train: 0.9667 loss_val: 0.8483 acc_val: 0.7360 time: 0.0994s\n",
            "119\n",
            "Epoch: 0246 loss_train: 0.2707 acc_train: 0.9333 loss_val: 0.8528 acc_val: 0.7360 time: 0.1041s\n",
            "120\n",
            "Epoch: 0247 loss_train: 0.2430 acc_train: 0.9833 loss_val: 0.8530 acc_val: 0.7340 time: 0.0972s\n",
            "121\n",
            "Epoch: 0248 loss_train: 0.2717 acc_train: 0.9750 loss_val: 0.8491 acc_val: 0.7360 time: 0.1108s\n",
            "122\n",
            "Epoch: 0249 loss_train: 0.2484 acc_train: 0.9583 loss_val: 0.8417 acc_val: 0.7400 time: 0.1046s\n",
            "123\n",
            "Epoch: 0250 loss_train: 0.2715 acc_train: 0.9750 loss_val: 0.8391 acc_val: 0.7440 time: 0.1094s\n",
            "124\n",
            "Epoch: 0251 loss_train: 0.2966 acc_train: 0.9583 loss_val: 0.8436 acc_val: 0.7440 time: 0.0962s\n",
            "125\n",
            "Epoch: 0252 loss_train: 0.2879 acc_train: 0.9833 loss_val: 0.8485 acc_val: 0.7400 time: 0.0960s\n",
            "126\n",
            "Epoch: 0253 loss_train: 0.2731 acc_train: 0.9750 loss_val: 0.8516 acc_val: 0.7400 time: 0.1037s\n",
            "127\n",
            "Epoch: 0254 loss_train: 0.2890 acc_train: 0.9833 loss_val: 0.8513 acc_val: 0.7360 time: 0.1047s\n",
            "128\n",
            "Epoch: 0255 loss_train: 0.2571 acc_train: 0.9667 loss_val: 0.8451 acc_val: 0.7340 time: 0.0998s\n",
            "129\n",
            "Epoch: 0256 loss_train: 0.2620 acc_train: 0.9500 loss_val: 0.8394 acc_val: 0.7380 time: 0.0993s\n",
            "130\n",
            "Epoch: 0257 loss_train: 0.2723 acc_train: 0.9750 loss_val: 0.8383 acc_val: 0.7420 time: 0.0964s\n",
            "131\n",
            "Epoch: 0258 loss_train: 0.2672 acc_train: 0.9750 loss_val: 0.8434 acc_val: 0.7420 time: 0.1103s\n",
            "132\n",
            "Epoch: 0259 loss_train: 0.2859 acc_train: 0.9750 loss_val: 0.8499 acc_val: 0.7420 time: 0.0970s\n",
            "133\n",
            "Epoch: 0260 loss_train: 0.2633 acc_train: 0.9667 loss_val: 0.8514 acc_val: 0.7400 time: 0.1078s\n",
            "134\n",
            "Epoch: 0261 loss_train: 0.2704 acc_train: 0.9750 loss_val: 0.8506 acc_val: 0.7380 time: 0.1047s\n",
            "135\n",
            "Epoch: 0262 loss_train: 0.2570 acc_train: 0.9583 loss_val: 0.8469 acc_val: 0.7360 time: 0.0965s\n",
            "136\n",
            "Epoch: 0263 loss_train: 0.2640 acc_train: 0.9500 loss_val: 0.8440 acc_val: 0.7380 time: 0.1031s\n",
            "137\n",
            "Epoch: 0264 loss_train: 0.2722 acc_train: 0.9500 loss_val: 0.8417 acc_val: 0.7380 time: 0.1024s\n",
            "138\n",
            "Epoch: 0265 loss_train: 0.2647 acc_train: 0.9750 loss_val: 0.8410 acc_val: 0.7360 time: 0.0963s\n",
            "139\n",
            "Epoch: 0266 loss_train: 0.2645 acc_train: 0.9667 loss_val: 0.8427 acc_val: 0.7400 time: 0.1043s\n",
            "140\n",
            "Epoch: 0267 loss_train: 0.2526 acc_train: 0.9667 loss_val: 0.8459 acc_val: 0.7360 time: 0.0976s\n",
            "141\n",
            "Epoch: 0268 loss_train: 0.2620 acc_train: 0.9750 loss_val: 0.8467 acc_val: 0.7440 time: 0.1050s\n",
            "142\n",
            "Epoch: 0269 loss_train: 0.2599 acc_train: 0.9833 loss_val: 0.8457 acc_val: 0.7420 time: 0.0962s\n",
            "143\n",
            "Epoch: 0270 loss_train: 0.2636 acc_train: 0.9750 loss_val: 0.8417 acc_val: 0.7400 time: 0.0989s\n",
            "144\n",
            "Epoch: 0271 loss_train: 0.2622 acc_train: 0.9833 loss_val: 0.8411 acc_val: 0.7400 time: 0.1062s\n",
            "145\n",
            "Epoch: 0272 loss_train: 0.2765 acc_train: 0.9750 loss_val: 0.8467 acc_val: 0.7380 time: 0.1001s\n",
            "146\n",
            "Epoch: 0273 loss_train: 0.2729 acc_train: 0.9667 loss_val: 0.8483 acc_val: 0.7380 time: 0.1002s\n",
            "147\n",
            "Epoch: 0274 loss_train: 0.2544 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7380 time: 0.0966s\n",
            "148\n",
            "Epoch: 0275 loss_train: 0.2601 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7360 time: 0.1015s\n",
            "149\n",
            "Epoch: 0276 loss_train: 0.2622 acc_train: 0.9750 loss_val: 0.8418 acc_val: 0.7380 time: 0.1050s\n",
            "150\n",
            "Epoch: 0277 loss_train: 0.2696 acc_train: 0.9750 loss_val: 0.8446 acc_val: 0.7380 time: 0.0954s\n",
            "151\n",
            "Epoch: 0278 loss_train: 0.2829 acc_train: 0.9583 loss_val: 0.8480 acc_val: 0.7400 time: 0.1024s\n",
            "152\n",
            "Epoch: 0279 loss_train: 0.2584 acc_train: 0.9667 loss_val: 0.8501 acc_val: 0.7400 time: 0.0958s\n",
            "153\n",
            "Epoch: 0280 loss_train: 0.2702 acc_train: 0.9833 loss_val: 0.8486 acc_val: 0.7400 time: 0.1074s\n",
            "154\n",
            "Epoch: 0281 loss_train: 0.2605 acc_train: 0.9750 loss_val: 0.8436 acc_val: 0.7380 time: 0.1050s\n",
            "155\n",
            "Epoch: 0282 loss_train: 0.2639 acc_train: 0.9833 loss_val: 0.8407 acc_val: 0.7420 time: 0.1004s\n",
            "156\n",
            "Epoch: 0283 loss_train: 0.2563 acc_train: 0.9750 loss_val: 0.8403 acc_val: 0.7360 time: 0.1050s\n",
            "157\n",
            "Epoch: 0284 loss_train: 0.2623 acc_train: 0.9750 loss_val: 0.8434 acc_val: 0.7380 time: 0.0998s\n",
            "158\n",
            "Epoch: 0285 loss_train: 0.2607 acc_train: 0.9917 loss_val: 0.8494 acc_val: 0.7360 time: 0.1013s\n",
            "159\n",
            "Epoch: 0286 loss_train: 0.2630 acc_train: 0.9833 loss_val: 0.8536 acc_val: 0.7340 time: 0.0957s\n",
            "160\n",
            "Epoch: 0287 loss_train: 0.2730 acc_train: 0.9667 loss_val: 0.8521 acc_val: 0.7320 time: 0.1001s\n",
            "161\n",
            "Epoch: 0288 loss_train: 0.2607 acc_train: 0.9583 loss_val: 0.8482 acc_val: 0.7380 time: 0.0961s\n",
            "162\n",
            "Epoch: 0289 loss_train: 0.2563 acc_train: 0.9833 loss_val: 0.8441 acc_val: 0.7400 time: 0.0956s\n",
            "163\n",
            "Epoch: 0290 loss_train: 0.2804 acc_train: 0.9833 loss_val: 0.8430 acc_val: 0.7400 time: 0.1011s\n",
            "164\n",
            "Epoch: 0291 loss_train: 0.2561 acc_train: 0.9750 loss_val: 0.8440 acc_val: 0.7360 time: 0.0954s\n",
            "165\n",
            "Epoch: 0292 loss_train: 0.2703 acc_train: 0.9833 loss_val: 0.8481 acc_val: 0.7380 time: 0.0962s\n",
            "166\n",
            "Epoch: 0293 loss_train: 0.2618 acc_train: 0.9833 loss_val: 0.8463 acc_val: 0.7380 time: 0.1032s\n",
            "167\n",
            "Epoch: 0294 loss_train: 0.2651 acc_train: 0.9500 loss_val: 0.8439 acc_val: 0.7400 time: 0.0957s\n",
            "168\n",
            "Epoch: 0295 loss_train: 0.2610 acc_train: 0.9500 loss_val: 0.8406 acc_val: 0.7420 time: 0.0963s\n",
            "169\n",
            "Epoch: 0296 loss_train: 0.2486 acc_train: 0.9667 loss_val: 0.8373 acc_val: 0.7400 time: 0.1011s\n",
            "170\n",
            "Epoch: 0297 loss_train: 0.2615 acc_train: 0.9750 loss_val: 0.8391 acc_val: 0.7400 time: 0.0955s\n",
            "171\n",
            "Epoch: 0298 loss_train: 0.2839 acc_train: 0.9583 loss_val: 0.8416 acc_val: 0.7420 time: 0.0973s\n",
            "172\n",
            "Epoch: 0299 loss_train: 0.2493 acc_train: 0.9833 loss_val: 0.8429 acc_val: 0.7400 time: 0.1036s\n",
            "173\n",
            "Epoch: 0300 loss_train: 0.2716 acc_train: 0.9750 loss_val: 0.8455 acc_val: 0.7360 time: 0.1004s\n",
            "174\n",
            "Epoch: 0301 loss_train: 0.2785 acc_train: 0.9750 loss_val: 0.8470 acc_val: 0.7380 time: 0.0974s\n",
            "175\n",
            "Epoch: 0302 loss_train: 0.2647 acc_train: 0.9583 loss_val: 0.8464 acc_val: 0.7380 time: 0.1015s\n",
            "176\n",
            "Epoch: 0303 loss_train: 0.2752 acc_train: 0.9917 loss_val: 0.8421 acc_val: 0.7380 time: 0.0956s\n",
            "177\n",
            "Epoch: 0304 loss_train: 0.2617 acc_train: 0.9833 loss_val: 0.8406 acc_val: 0.7420 time: 0.1013s\n",
            "178\n",
            "Epoch: 0305 loss_train: 0.2691 acc_train: 0.9750 loss_val: 0.8405 acc_val: 0.7380 time: 0.0955s\n",
            "179\n",
            "Epoch: 0306 loss_train: 0.2638 acc_train: 0.9750 loss_val: 0.8387 acc_val: 0.7400 time: 0.0960s\n",
            "180\n",
            "Epoch: 0307 loss_train: 0.2752 acc_train: 0.9833 loss_val: 0.8387 acc_val: 0.7400 time: 0.1025s\n",
            "181\n",
            "Epoch: 0308 loss_train: 0.2712 acc_train: 0.9750 loss_val: 0.8403 acc_val: 0.7380 time: 0.0973s\n",
            "182\n",
            "Epoch: 0309 loss_train: 0.2694 acc_train: 0.9417 loss_val: 0.8411 acc_val: 0.7360 time: 0.0976s\n",
            "183\n",
            "Epoch: 0310 loss_train: 0.2715 acc_train: 0.9750 loss_val: 0.8446 acc_val: 0.7360 time: 0.1073s\n",
            "184\n",
            "Epoch: 0311 loss_train: 0.2620 acc_train: 0.9750 loss_val: 0.8435 acc_val: 0.7340 time: 0.0965s\n",
            "185\n",
            "Epoch: 0312 loss_train: 0.2675 acc_train: 0.9750 loss_val: 0.8431 acc_val: 0.7380 time: 0.1016s\n",
            "186\n",
            "Epoch: 0313 loss_train: 0.2559 acc_train: 0.9500 loss_val: 0.8467 acc_val: 0.7380 time: 0.0984s\n",
            "187\n",
            "Epoch: 0314 loss_train: 0.2445 acc_train: 0.9917 loss_val: 0.8463 acc_val: 0.7340 time: 0.1007s\n",
            "188\n",
            "Epoch: 0315 loss_train: 0.2842 acc_train: 0.9667 loss_val: 0.8434 acc_val: 0.7380 time: 0.1007s\n",
            "189\n",
            "Epoch: 0316 loss_train: 0.2667 acc_train: 0.9500 loss_val: 0.8422 acc_val: 0.7440 time: 0.0972s\n",
            "190\n",
            "Epoch: 0317 loss_train: 0.2574 acc_train: 0.9833 loss_val: 0.8429 acc_val: 0.7420 time: 0.1026s\n",
            "191\n",
            "Epoch: 0318 loss_train: 0.2624 acc_train: 0.9667 loss_val: 0.8444 acc_val: 0.7400 time: 0.0976s\n",
            "192\n",
            "Epoch: 0319 loss_train: 0.2855 acc_train: 0.9917 loss_val: 0.8482 acc_val: 0.7400 time: 0.0961s\n",
            "193\n",
            "Epoch: 0320 loss_train: 0.2690 acc_train: 0.9583 loss_val: 0.8495 acc_val: 0.7360 time: 0.1046s\n",
            "194\n",
            "Epoch: 0321 loss_train: 0.2651 acc_train: 0.9667 loss_val: 0.8484 acc_val: 0.7380 time: 0.0982s\n",
            "195\n",
            "Epoch: 0322 loss_train: 0.2757 acc_train: 0.9667 loss_val: 0.8467 acc_val: 0.7380 time: 0.1010s\n",
            "196\n",
            "Epoch: 0323 loss_train: 0.2487 acc_train: 0.9917 loss_val: 0.8435 acc_val: 0.7400 time: 0.0963s\n",
            "197\n",
            "Epoch: 0324 loss_train: 0.2678 acc_train: 0.9750 loss_val: 0.8453 acc_val: 0.7380 time: 0.0958s\n",
            "198\n",
            "Epoch: 0325 loss_train: 0.2576 acc_train: 0.9667 loss_val: 0.8427 acc_val: 0.7400 time: 0.1116s\n",
            "199\n",
            "Early stop! Min loss:  0.8325702548027039 , Max accuracy:  0.748\n",
            "Early stop model validation loss:  0.8325702548027039 , accuracy:  0.746\n",
            "Optimization Finished!\n",
            "Total time elapsed: 33.3733s\n",
            "Loading 52th epoch\n",
            "Test set results: loss= 0.8165 accuracy= 0.7280\n",
            "Epoch: 0001 loss_train: 0.2758 acc_train: 0.9917 loss_val: 0.8363 acc_val: 0.7480 time: 0.0981s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.3011 acc_train: 0.9667 loss_val: 0.8434 acc_val: 0.7440 time: 0.0997s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.2837 acc_train: 1.0000 loss_val: 0.8494 acc_val: 0.7440 time: 0.0965s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.2797 acc_train: 0.9750 loss_val: 0.8512 acc_val: 0.7380 time: 0.0973s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.2885 acc_train: 0.9667 loss_val: 0.8465 acc_val: 0.7380 time: 0.1019s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.2787 acc_train: 0.9667 loss_val: 0.8421 acc_val: 0.7420 time: 0.0995s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.2848 acc_train: 0.9750 loss_val: 0.8391 acc_val: 0.7400 time: 0.0988s\n",
            "5\n",
            "Epoch: 0008 loss_train: 0.2826 acc_train: 0.9333 loss_val: 0.8378 acc_val: 0.7440 time: 0.0992s\n",
            "6\n",
            "Epoch: 0009 loss_train: 0.2916 acc_train: 0.9667 loss_val: 0.8373 acc_val: 0.7440 time: 0.0986s\n",
            "7\n",
            "Epoch: 0010 loss_train: 0.2899 acc_train: 0.9833 loss_val: 0.8398 acc_val: 0.7420 time: 0.1035s\n",
            "8\n",
            "Epoch: 0011 loss_train: 0.3038 acc_train: 0.9667 loss_val: 0.8433 acc_val: 0.7420 time: 0.0949s\n",
            "9\n",
            "Epoch: 0012 loss_train: 0.3064 acc_train: 0.9583 loss_val: 0.8446 acc_val: 0.7440 time: 0.1066s\n",
            "10\n",
            "Epoch: 0013 loss_train: 0.2928 acc_train: 0.9583 loss_val: 0.8451 acc_val: 0.7400 time: 0.0955s\n",
            "11\n",
            "Epoch: 0014 loss_train: 0.2831 acc_train: 0.9750 loss_val: 0.8420 acc_val: 0.7440 time: 0.1002s\n",
            "12\n",
            "Epoch: 0015 loss_train: 0.2801 acc_train: 0.9583 loss_val: 0.8417 acc_val: 0.7440 time: 0.1037s\n",
            "13\n",
            "Epoch: 0016 loss_train: 0.2866 acc_train: 0.9750 loss_val: 0.8400 acc_val: 0.7460 time: 0.0960s\n",
            "14\n",
            "Epoch: 0017 loss_train: 0.2887 acc_train: 0.9500 loss_val: 0.8375 acc_val: 0.7460 time: 0.1003s\n",
            "15\n",
            "Epoch: 0018 loss_train: 0.2829 acc_train: 0.9667 loss_val: 0.8341 acc_val: 0.7480 time: 0.0993s\n",
            "16\n",
            "Epoch: 0019 loss_train: 0.2769 acc_train: 0.9750 loss_val: 0.8342 acc_val: 0.7440 time: 0.0956s\n",
            "0\n",
            "Epoch: 0020 loss_train: 0.2880 acc_train: 0.9667 loss_val: 0.8367 acc_val: 0.7460 time: 0.1011s\n",
            "1\n",
            "Epoch: 0021 loss_train: 0.2995 acc_train: 0.9583 loss_val: 0.8422 acc_val: 0.7440 time: 0.0967s\n",
            "2\n",
            "Epoch: 0022 loss_train: 0.2693 acc_train: 0.9583 loss_val: 0.8453 acc_val: 0.7440 time: 0.1020s\n",
            "3\n",
            "Epoch: 0023 loss_train: 0.2844 acc_train: 0.9667 loss_val: 0.8446 acc_val: 0.7420 time: 0.0961s\n",
            "4\n",
            "Epoch: 0024 loss_train: 0.2815 acc_train: 0.9667 loss_val: 0.8415 acc_val: 0.7420 time: 0.1021s\n",
            "5\n",
            "Epoch: 0025 loss_train: 0.2868 acc_train: 0.9750 loss_val: 0.8407 acc_val: 0.7380 time: 0.1006s\n",
            "6\n",
            "Epoch: 0026 loss_train: 0.2783 acc_train: 0.9583 loss_val: 0.8378 acc_val: 0.7420 time: 0.0994s\n",
            "7\n",
            "Epoch: 0027 loss_train: 0.2950 acc_train: 0.9833 loss_val: 0.8369 acc_val: 0.7480 time: 0.1239s\n",
            "8\n",
            "Epoch: 0028 loss_train: 0.2808 acc_train: 0.9417 loss_val: 0.8380 acc_val: 0.7400 time: 0.1114s\n",
            "0\n",
            "Epoch: 0029 loss_train: 0.2802 acc_train: 0.9833 loss_val: 0.8403 acc_val: 0.7380 time: 0.1015s\n",
            "1\n",
            "Epoch: 0030 loss_train: 0.2836 acc_train: 0.9750 loss_val: 0.8425 acc_val: 0.7420 time: 0.1045s\n",
            "2\n",
            "Epoch: 0031 loss_train: 0.2882 acc_train: 0.9750 loss_val: 0.8416 acc_val: 0.7460 time: 0.1005s\n",
            "3\n",
            "Epoch: 0032 loss_train: 0.2648 acc_train: 0.9667 loss_val: 0.8424 acc_val: 0.7380 time: 0.0971s\n",
            "4\n",
            "Epoch: 0033 loss_train: 0.2880 acc_train: 0.9583 loss_val: 0.8437 acc_val: 0.7380 time: 0.1035s\n",
            "5\n",
            "Epoch: 0034 loss_train: 0.2771 acc_train: 0.9583 loss_val: 0.8396 acc_val: 0.7360 time: 0.1024s\n",
            "6\n",
            "Epoch: 0035 loss_train: 0.2790 acc_train: 0.9750 loss_val: 0.8366 acc_val: 0.7440 time: 0.0997s\n",
            "7\n",
            "Epoch: 0036 loss_train: 0.2970 acc_train: 0.9833 loss_val: 0.8360 acc_val: 0.7420 time: 0.1010s\n",
            "8\n",
            "Epoch: 0037 loss_train: 0.2899 acc_train: 0.9667 loss_val: 0.8364 acc_val: 0.7360 time: 0.0994s\n",
            "9\n",
            "Epoch: 0038 loss_train: 0.2741 acc_train: 0.9833 loss_val: 0.8387 acc_val: 0.7400 time: 0.1120s\n",
            "10\n",
            "Epoch: 0039 loss_train: 0.2850 acc_train: 0.9667 loss_val: 0.8428 acc_val: 0.7420 time: 0.0994s\n",
            "11\n",
            "Epoch: 0040 loss_train: 0.2826 acc_train: 0.9833 loss_val: 0.8499 acc_val: 0.7440 time: 0.1022s\n",
            "12\n",
            "Epoch: 0041 loss_train: 0.2716 acc_train: 0.9833 loss_val: 0.8486 acc_val: 0.7440 time: 0.1013s\n",
            "13\n",
            "Epoch: 0042 loss_train: 0.2975 acc_train: 0.9333 loss_val: 0.8415 acc_val: 0.7420 time: 0.0967s\n",
            "14\n",
            "Epoch: 0043 loss_train: 0.2751 acc_train: 0.9750 loss_val: 0.8355 acc_val: 0.7480 time: 0.1023s\n",
            "15\n",
            "Epoch: 0044 loss_train: 0.3017 acc_train: 0.9500 loss_val: 0.8351 acc_val: 0.7460 time: 0.1002s\n",
            "0\n",
            "Epoch: 0045 loss_train: 0.2790 acc_train: 0.9500 loss_val: 0.8382 acc_val: 0.7400 time: 0.0981s\n",
            "1\n",
            "Epoch: 0046 loss_train: 0.2820 acc_train: 0.9750 loss_val: 0.8425 acc_val: 0.7400 time: 0.1052s\n",
            "2\n",
            "Epoch: 0047 loss_train: 0.3034 acc_train: 0.9750 loss_val: 0.8478 acc_val: 0.7400 time: 0.1007s\n",
            "3\n",
            "Epoch: 0048 loss_train: 0.2947 acc_train: 0.9583 loss_val: 0.8487 acc_val: 0.7400 time: 0.1084s\n",
            "4\n",
            "Epoch: 0049 loss_train: 0.2710 acc_train: 0.9667 loss_val: 0.8431 acc_val: 0.7440 time: 0.0971s\n",
            "5\n",
            "Epoch: 0050 loss_train: 0.2685 acc_train: 0.9833 loss_val: 0.8380 acc_val: 0.7420 time: 0.1014s\n",
            "6\n",
            "Epoch: 0051 loss_train: 0.2891 acc_train: 0.9833 loss_val: 0.8355 acc_val: 0.7440 time: 0.0976s\n",
            "7\n",
            "Epoch: 0052 loss_train: 0.2836 acc_train: 0.9500 loss_val: 0.8382 acc_val: 0.7420 time: 0.1012s\n",
            "8\n",
            "Epoch: 0053 loss_train: 0.2689 acc_train: 0.9833 loss_val: 0.8430 acc_val: 0.7380 time: 0.1079s\n",
            "9\n",
            "Epoch: 0054 loss_train: 0.2772 acc_train: 0.9500 loss_val: 0.8454 acc_val: 0.7380 time: 0.1011s\n",
            "10\n",
            "Epoch: 0055 loss_train: 0.2762 acc_train: 0.9750 loss_val: 0.8429 acc_val: 0.7440 time: 0.1024s\n",
            "11\n",
            "Epoch: 0056 loss_train: 0.2597 acc_train: 0.9833 loss_val: 0.8380 acc_val: 0.7440 time: 0.0972s\n",
            "12\n",
            "Epoch: 0057 loss_train: 0.2892 acc_train: 0.9500 loss_val: 0.8369 acc_val: 0.7420 time: 0.1010s\n",
            "13\n",
            "Epoch: 0058 loss_train: 0.2679 acc_train: 0.9750 loss_val: 0.8382 acc_val: 0.7420 time: 0.0968s\n",
            "14\n",
            "Epoch: 0059 loss_train: 0.2982 acc_train: 0.9333 loss_val: 0.8425 acc_val: 0.7440 time: 0.0965s\n",
            "15\n",
            "Epoch: 0060 loss_train: 0.2869 acc_train: 0.9250 loss_val: 0.8415 acc_val: 0.7400 time: 0.1010s\n",
            "16\n",
            "Epoch: 0061 loss_train: 0.2865 acc_train: 0.9583 loss_val: 0.8386 acc_val: 0.7400 time: 0.0978s\n",
            "17\n",
            "Epoch: 0062 loss_train: 0.2769 acc_train: 0.9583 loss_val: 0.8393 acc_val: 0.7400 time: 0.1001s\n",
            "18\n",
            "Epoch: 0063 loss_train: 0.2793 acc_train: 0.9833 loss_val: 0.8420 acc_val: 0.7420 time: 0.0999s\n",
            "19\n",
            "Epoch: 0064 loss_train: 0.2762 acc_train: 0.9917 loss_val: 0.8390 acc_val: 0.7400 time: 0.0965s\n",
            "20\n",
            "Epoch: 0065 loss_train: 0.2867 acc_train: 0.9500 loss_val: 0.8351 acc_val: 0.7400 time: 0.1045s\n",
            "21\n",
            "Epoch: 0066 loss_train: 0.2720 acc_train: 0.9500 loss_val: 0.8342 acc_val: 0.7400 time: 0.0966s\n",
            "22\n",
            "Epoch: 0067 loss_train: 0.2767 acc_train: 0.9917 loss_val: 0.8354 acc_val: 0.7420 time: 0.1022s\n",
            "23\n",
            "Epoch: 0068 loss_train: 0.2943 acc_train: 0.9750 loss_val: 0.8387 acc_val: 0.7400 time: 0.0968s\n",
            "24\n",
            "Epoch: 0069 loss_train: 0.2849 acc_train: 0.9833 loss_val: 0.8420 acc_val: 0.7380 time: 0.0964s\n",
            "25\n",
            "Epoch: 0070 loss_train: 0.2778 acc_train: 0.9833 loss_val: 0.8422 acc_val: 0.7380 time: 0.1039s\n",
            "26\n",
            "Epoch: 0071 loss_train: 0.2864 acc_train: 0.9833 loss_val: 0.8449 acc_val: 0.7380 time: 0.0951s\n",
            "27\n",
            "Epoch: 0072 loss_train: 0.2712 acc_train: 0.9500 loss_val: 0.8441 acc_val: 0.7420 time: 0.0955s\n",
            "28\n",
            "Epoch: 0073 loss_train: 0.2814 acc_train: 0.9917 loss_val: 0.8402 acc_val: 0.7400 time: 0.1060s\n",
            "29\n",
            "Epoch: 0074 loss_train: 0.2837 acc_train: 0.9667 loss_val: 0.8369 acc_val: 0.7400 time: 0.1009s\n",
            "30\n",
            "Epoch: 0075 loss_train: 0.2820 acc_train: 0.9667 loss_val: 0.8337 acc_val: 0.7400 time: 0.0956s\n",
            "31\n",
            "Epoch: 0076 loss_train: 0.2677 acc_train: 0.9833 loss_val: 0.8342 acc_val: 0.7400 time: 0.1007s\n",
            "0\n",
            "Epoch: 0077 loss_train: 0.2827 acc_train: 0.9750 loss_val: 0.8373 acc_val: 0.7400 time: 0.0996s\n",
            "1\n",
            "Epoch: 0078 loss_train: 0.2666 acc_train: 0.9750 loss_val: 0.8407 acc_val: 0.7380 time: 0.0971s\n",
            "2\n",
            "Epoch: 0079 loss_train: 0.2869 acc_train: 0.9750 loss_val: 0.8416 acc_val: 0.7380 time: 0.1016s\n",
            "3\n",
            "Epoch: 0080 loss_train: 0.2711 acc_train: 0.9417 loss_val: 0.8381 acc_val: 0.7380 time: 0.0965s\n",
            "4\n",
            "Epoch: 0081 loss_train: 0.2794 acc_train: 0.9500 loss_val: 0.8357 acc_val: 0.7400 time: 0.0999s\n",
            "5\n",
            "Epoch: 0082 loss_train: 0.2968 acc_train: 0.9417 loss_val: 0.8379 acc_val: 0.7440 time: 0.0964s\n",
            "6\n",
            "Epoch: 0083 loss_train: 0.2704 acc_train: 0.9667 loss_val: 0.8380 acc_val: 0.7420 time: 0.1034s\n",
            "7\n",
            "Epoch: 0084 loss_train: 0.2821 acc_train: 0.9583 loss_val: 0.8390 acc_val: 0.7420 time: 0.1035s\n",
            "8\n",
            "Epoch: 0085 loss_train: 0.2907 acc_train: 0.9750 loss_val: 0.8385 acc_val: 0.7400 time: 0.0981s\n",
            "9\n",
            "Epoch: 0086 loss_train: 0.2786 acc_train: 0.9500 loss_val: 0.8353 acc_val: 0.7420 time: 0.1050s\n",
            "10\n",
            "Epoch: 0087 loss_train: 0.2788 acc_train: 0.9583 loss_val: 0.8365 acc_val: 0.7400 time: 0.0995s\n",
            "11\n",
            "Epoch: 0088 loss_train: 0.2754 acc_train: 0.9750 loss_val: 0.8405 acc_val: 0.7380 time: 0.0992s\n",
            "12\n",
            "Epoch: 0089 loss_train: 0.2726 acc_train: 0.9750 loss_val: 0.8433 acc_val: 0.7380 time: 0.1053s\n",
            "13\n",
            "Epoch: 0090 loss_train: 0.2792 acc_train: 0.9500 loss_val: 0.8448 acc_val: 0.7400 time: 0.0965s\n",
            "14\n",
            "Epoch: 0091 loss_train: 0.2633 acc_train: 0.9667 loss_val: 0.8430 acc_val: 0.7400 time: 0.0992s\n",
            "15\n",
            "Epoch: 0092 loss_train: 0.2759 acc_train: 0.9667 loss_val: 0.8375 acc_val: 0.7420 time: 0.0955s\n",
            "16\n",
            "Epoch: 0093 loss_train: 0.2763 acc_train: 0.9750 loss_val: 0.8359 acc_val: 0.7400 time: 0.1066s\n",
            "17\n",
            "Epoch: 0094 loss_train: 0.2749 acc_train: 0.9750 loss_val: 0.8386 acc_val: 0.7380 time: 0.0970s\n",
            "18\n",
            "Epoch: 0095 loss_train: 0.2916 acc_train: 0.9750 loss_val: 0.8411 acc_val: 0.7380 time: 0.1019s\n",
            "19\n",
            "Epoch: 0096 loss_train: 0.2680 acc_train: 1.0000 loss_val: 0.8421 acc_val: 0.7380 time: 0.0969s\n",
            "20\n",
            "Epoch: 0097 loss_train: 0.2720 acc_train: 0.9833 loss_val: 0.8446 acc_val: 0.7400 time: 0.1004s\n",
            "21\n",
            "Epoch: 0098 loss_train: 0.2926 acc_train: 0.9667 loss_val: 0.8407 acc_val: 0.7420 time: 0.1057s\n",
            "22\n",
            "Epoch: 0099 loss_train: 0.2829 acc_train: 0.9583 loss_val: 0.8385 acc_val: 0.7380 time: 0.0984s\n",
            "23\n",
            "Epoch: 0100 loss_train: 0.2753 acc_train: 0.9750 loss_val: 0.8345 acc_val: 0.7420 time: 0.1049s\n",
            "24\n",
            "Epoch: 0101 loss_train: 0.2743 acc_train: 0.9750 loss_val: 0.8328 acc_val: 0.7400 time: 0.0957s\n",
            "25\n",
            "Epoch: 0102 loss_train: 0.2799 acc_train: 0.9583 loss_val: 0.8369 acc_val: 0.7400 time: 0.0957s\n",
            "0\n",
            "Epoch: 0103 loss_train: 0.2880 acc_train: 0.9667 loss_val: 0.8450 acc_val: 0.7400 time: 0.1093s\n",
            "1\n",
            "Epoch: 0104 loss_train: 0.2751 acc_train: 0.9917 loss_val: 0.8464 acc_val: 0.7380 time: 0.0972s\n",
            "2\n",
            "Epoch: 0105 loss_train: 0.2767 acc_train: 0.9750 loss_val: 0.8419 acc_val: 0.7360 time: 0.1000s\n",
            "3\n",
            "Epoch: 0106 loss_train: 0.2834 acc_train: 0.9500 loss_val: 0.8395 acc_val: 0.7400 time: 0.0987s\n",
            "4\n",
            "Epoch: 0107 loss_train: 0.2851 acc_train: 0.9333 loss_val: 0.8353 acc_val: 0.7460 time: 0.0997s\n",
            "5\n",
            "Epoch: 0108 loss_train: 0.2675 acc_train: 0.9583 loss_val: 0.8328 acc_val: 0.7420 time: 0.0952s\n",
            "6\n",
            "Epoch: 0109 loss_train: 0.2833 acc_train: 0.9417 loss_val: 0.8385 acc_val: 0.7400 time: 0.0959s\n",
            "7\n",
            "Epoch: 0110 loss_train: 0.2671 acc_train: 0.9833 loss_val: 0.8492 acc_val: 0.7400 time: 0.1046s\n",
            "8\n",
            "Epoch: 0111 loss_train: 0.2634 acc_train: 0.9500 loss_val: 0.8524 acc_val: 0.7400 time: 0.0989s\n",
            "9\n",
            "Epoch: 0112 loss_train: 0.2691 acc_train: 0.9833 loss_val: 0.8429 acc_val: 0.7400 time: 0.0988s\n",
            "10\n",
            "Epoch: 0113 loss_train: 0.2713 acc_train: 0.9917 loss_val: 0.8318 acc_val: 0.7420 time: 0.1075s\n",
            "11\n",
            "Epoch: 0114 loss_train: 0.2803 acc_train: 0.9750 loss_val: 0.8273 acc_val: 0.7440 time: 0.0980s\n",
            "0\n",
            "Epoch: 0115 loss_train: 0.2852 acc_train: 0.9667 loss_val: 0.8315 acc_val: 0.7480 time: 0.0997s\n",
            "0\n",
            "Epoch: 0116 loss_train: 0.3003 acc_train: 0.9833 loss_val: 0.8388 acc_val: 0.7420 time: 0.0976s\n",
            "0\n",
            "Epoch: 0117 loss_train: 0.2957 acc_train: 0.9417 loss_val: 0.8492 acc_val: 0.7400 time: 0.1034s\n",
            "1\n",
            "Epoch: 0118 loss_train: 0.2669 acc_train: 0.9833 loss_val: 0.8524 acc_val: 0.7400 time: 0.0955s\n",
            "2\n",
            "Epoch: 0119 loss_train: 0.2894 acc_train: 0.9667 loss_val: 0.8442 acc_val: 0.7400 time: 0.0968s\n",
            "3\n",
            "Epoch: 0120 loss_train: 0.2759 acc_train: 0.9833 loss_val: 0.8318 acc_val: 0.7400 time: 0.0995s\n",
            "4\n",
            "Epoch: 0121 loss_train: 0.2865 acc_train: 0.9583 loss_val: 0.8270 acc_val: 0.7440 time: 0.0968s\n",
            "5\n",
            "Epoch: 0122 loss_train: 0.3030 acc_train: 0.9333 loss_val: 0.8295 acc_val: 0.7420 time: 0.0960s\n",
            "0\n",
            "Epoch: 0123 loss_train: 0.2933 acc_train: 0.9667 loss_val: 0.8407 acc_val: 0.7400 time: 0.1074s\n",
            "1\n",
            "Epoch: 0124 loss_train: 0.2891 acc_train: 0.9333 loss_val: 0.8548 acc_val: 0.7420 time: 0.0998s\n",
            "2\n",
            "Epoch: 0125 loss_train: 0.2768 acc_train: 0.9583 loss_val: 0.8603 acc_val: 0.7400 time: 0.1042s\n",
            "3\n",
            "Epoch: 0126 loss_train: 0.2577 acc_train: 0.9833 loss_val: 0.8524 acc_val: 0.7400 time: 0.1009s\n",
            "4\n",
            "Epoch: 0127 loss_train: 0.2817 acc_train: 0.9667 loss_val: 0.8409 acc_val: 0.7420 time: 0.1036s\n",
            "5\n",
            "Epoch: 0128 loss_train: 0.2583 acc_train: 0.9833 loss_val: 0.8291 acc_val: 0.7420 time: 0.0960s\n",
            "6\n",
            "Epoch: 0129 loss_train: 0.2736 acc_train: 0.9500 loss_val: 0.8259 acc_val: 0.7460 time: 0.0984s\n",
            "7\n",
            "Epoch: 0130 loss_train: 0.2957 acc_train: 0.9583 loss_val: 0.8327 acc_val: 0.7440 time: 0.0986s\n",
            "0\n",
            "Epoch: 0131 loss_train: 0.2885 acc_train: 0.9917 loss_val: 0.8436 acc_val: 0.7400 time: 0.1001s\n",
            "1\n",
            "Epoch: 0132 loss_train: 0.2908 acc_train: 0.9667 loss_val: 0.8546 acc_val: 0.7400 time: 0.1056s\n",
            "2\n",
            "Epoch: 0133 loss_train: 0.2887 acc_train: 0.9500 loss_val: 0.8546 acc_val: 0.7420 time: 0.1104s\n",
            "3\n",
            "Epoch: 0134 loss_train: 0.2838 acc_train: 0.9750 loss_val: 0.8473 acc_val: 0.7380 time: 0.0981s\n",
            "4\n",
            "Epoch: 0135 loss_train: 0.2722 acc_train: 0.9417 loss_val: 0.8394 acc_val: 0.7420 time: 0.1030s\n",
            "5\n",
            "Epoch: 0136 loss_train: 0.2829 acc_train: 0.9500 loss_val: 0.8332 acc_val: 0.7420 time: 0.1022s\n",
            "6\n",
            "Epoch: 0137 loss_train: 0.2753 acc_train: 0.9583 loss_val: 0.8349 acc_val: 0.7440 time: 0.0952s\n",
            "7\n",
            "Epoch: 0138 loss_train: 0.2777 acc_train: 0.9833 loss_val: 0.8400 acc_val: 0.7440 time: 0.1018s\n",
            "8\n",
            "Epoch: 0139 loss_train: 0.2741 acc_train: 0.9667 loss_val: 0.8483 acc_val: 0.7400 time: 0.0995s\n",
            "9\n",
            "Epoch: 0140 loss_train: 0.2682 acc_train: 0.9667 loss_val: 0.8558 acc_val: 0.7380 time: 0.0952s\n",
            "10\n",
            "Epoch: 0141 loss_train: 0.2600 acc_train: 0.9833 loss_val: 0.8559 acc_val: 0.7360 time: 0.1020s\n",
            "11\n",
            "Epoch: 0142 loss_train: 0.2730 acc_train: 0.9583 loss_val: 0.8489 acc_val: 0.7380 time: 0.0959s\n",
            "12\n",
            "Epoch: 0143 loss_train: 0.2762 acc_train: 0.9500 loss_val: 0.8376 acc_val: 0.7400 time: 0.1042s\n",
            "13\n",
            "Epoch: 0144 loss_train: 0.2787 acc_train: 0.9750 loss_val: 0.8302 acc_val: 0.7440 time: 0.1006s\n",
            "14\n",
            "Epoch: 0145 loss_train: 0.2773 acc_train: 0.9667 loss_val: 0.8325 acc_val: 0.7440 time: 0.0967s\n",
            "15\n",
            "Epoch: 0146 loss_train: 0.2820 acc_train: 0.9500 loss_val: 0.8433 acc_val: 0.7400 time: 0.1016s\n",
            "16\n",
            "Epoch: 0147 loss_train: 0.2637 acc_train: 0.9833 loss_val: 0.8515 acc_val: 0.7380 time: 0.0957s\n",
            "17\n",
            "Epoch: 0148 loss_train: 0.2642 acc_train: 0.9667 loss_val: 0.8503 acc_val: 0.7380 time: 0.1040s\n",
            "18\n",
            "Epoch: 0149 loss_train: 0.2814 acc_train: 0.9417 loss_val: 0.8446 acc_val: 0.7380 time: 0.0990s\n",
            "19\n",
            "Epoch: 0150 loss_train: 0.2776 acc_train: 0.9917 loss_val: 0.8404 acc_val: 0.7400 time: 0.1016s\n",
            "20\n",
            "Epoch: 0151 loss_train: 0.2753 acc_train: 0.9500 loss_val: 0.8376 acc_val: 0.7400 time: 0.1014s\n",
            "21\n",
            "Epoch: 0152 loss_train: 0.2791 acc_train: 0.9417 loss_val: 0.8358 acc_val: 0.7400 time: 0.0963s\n",
            "22\n",
            "Epoch: 0153 loss_train: 0.2968 acc_train: 0.9750 loss_val: 0.8427 acc_val: 0.7420 time: 0.1033s\n",
            "23\n",
            "Epoch: 0154 loss_train: 0.2756 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7420 time: 0.0959s\n",
            "24\n",
            "Epoch: 0155 loss_train: 0.2851 acc_train: 0.9583 loss_val: 0.8486 acc_val: 0.7380 time: 0.0961s\n",
            "25\n",
            "Epoch: 0156 loss_train: 0.3083 acc_train: 0.9417 loss_val: 0.8444 acc_val: 0.7400 time: 0.1002s\n",
            "26\n",
            "Epoch: 0157 loss_train: 0.2851 acc_train: 0.9583 loss_val: 0.8391 acc_val: 0.7420 time: 0.0979s\n",
            "27\n",
            "Epoch: 0158 loss_train: 0.2789 acc_train: 0.9583 loss_val: 0.8377 acc_val: 0.7420 time: 0.0980s\n",
            "28\n",
            "Epoch: 0159 loss_train: 0.2730 acc_train: 0.9917 loss_val: 0.8372 acc_val: 0.7420 time: 0.1017s\n",
            "29\n",
            "Epoch: 0160 loss_train: 0.2810 acc_train: 0.9750 loss_val: 0.8396 acc_val: 0.7440 time: 0.1001s\n",
            "30\n",
            "Epoch: 0161 loss_train: 0.2719 acc_train: 0.9667 loss_val: 0.8420 acc_val: 0.7420 time: 0.1045s\n",
            "31\n",
            "Epoch: 0162 loss_train: 0.2751 acc_train: 0.9583 loss_val: 0.8452 acc_val: 0.7380 time: 0.1031s\n",
            "32\n",
            "Epoch: 0163 loss_train: 0.2694 acc_train: 0.9500 loss_val: 0.8473 acc_val: 0.7380 time: 0.0967s\n",
            "33\n",
            "Epoch: 0164 loss_train: 0.2745 acc_train: 0.9917 loss_val: 0.8459 acc_val: 0.7400 time: 0.1043s\n",
            "34\n",
            "Epoch: 0165 loss_train: 0.2752 acc_train: 0.9667 loss_val: 0.8428 acc_val: 0.7400 time: 0.0979s\n",
            "35\n",
            "Epoch: 0166 loss_train: 0.2695 acc_train: 0.9917 loss_val: 0.8381 acc_val: 0.7400 time: 0.1002s\n",
            "36\n",
            "Epoch: 0167 loss_train: 0.2722 acc_train: 0.9750 loss_val: 0.8381 acc_val: 0.7440 time: 0.0955s\n",
            "37\n",
            "Epoch: 0168 loss_train: 0.2807 acc_train: 0.9500 loss_val: 0.8405 acc_val: 0.7440 time: 0.0978s\n",
            "38\n",
            "Epoch: 0169 loss_train: 0.2620 acc_train: 0.9667 loss_val: 0.8426 acc_val: 0.7420 time: 0.1030s\n",
            "39\n",
            "Epoch: 0170 loss_train: 0.2906 acc_train: 0.9417 loss_val: 0.8417 acc_val: 0.7400 time: 0.0952s\n",
            "40\n",
            "Epoch: 0171 loss_train: 0.2751 acc_train: 0.9833 loss_val: 0.8418 acc_val: 0.7400 time: 0.1005s\n",
            "41\n",
            "Epoch: 0172 loss_train: 0.2725 acc_train: 0.9833 loss_val: 0.8422 acc_val: 0.7400 time: 0.1026s\n",
            "42\n",
            "Epoch: 0173 loss_train: 0.2830 acc_train: 0.9750 loss_val: 0.8431 acc_val: 0.7420 time: 0.0999s\n",
            "43\n",
            "Epoch: 0174 loss_train: 0.2715 acc_train: 0.9583 loss_val: 0.8413 acc_val: 0.7420 time: 0.1041s\n",
            "44\n",
            "Epoch: 0175 loss_train: 0.2752 acc_train: 0.9500 loss_val: 0.8393 acc_val: 0.7400 time: 0.0945s\n",
            "45\n",
            "Epoch: 0176 loss_train: 0.2705 acc_train: 0.9750 loss_val: 0.8374 acc_val: 0.7400 time: 0.0997s\n",
            "46\n",
            "Epoch: 0177 loss_train: 0.2765 acc_train: 0.9667 loss_val: 0.8371 acc_val: 0.7400 time: 0.0949s\n",
            "47\n",
            "Epoch: 0178 loss_train: 0.2886 acc_train: 0.9250 loss_val: 0.8404 acc_val: 0.7380 time: 0.0969s\n",
            "48\n",
            "Epoch: 0179 loss_train: 0.2695 acc_train: 0.9500 loss_val: 0.8430 acc_val: 0.7400 time: 0.0999s\n",
            "49\n",
            "Epoch: 0180 loss_train: 0.2660 acc_train: 0.9667 loss_val: 0.8439 acc_val: 0.7440 time: 0.0950s\n",
            "50\n",
            "Epoch: 0181 loss_train: 0.2795 acc_train: 0.9750 loss_val: 0.8465 acc_val: 0.7400 time: 0.0950s\n",
            "51\n",
            "Epoch: 0182 loss_train: 0.2752 acc_train: 0.9750 loss_val: 0.8431 acc_val: 0.7420 time: 0.1002s\n",
            "52\n",
            "Epoch: 0183 loss_train: 0.2782 acc_train: 0.9667 loss_val: 0.8394 acc_val: 0.7420 time: 0.0987s\n",
            "53\n",
            "Epoch: 0184 loss_train: 0.2838 acc_train: 0.9500 loss_val: 0.8364 acc_val: 0.7380 time: 0.0956s\n",
            "54\n",
            "Epoch: 0185 loss_train: 0.2869 acc_train: 0.9667 loss_val: 0.8372 acc_val: 0.7380 time: 0.1022s\n",
            "55\n",
            "Epoch: 0186 loss_train: 0.2815 acc_train: 0.9500 loss_val: 0.8398 acc_val: 0.7400 time: 0.1015s\n",
            "56\n",
            "Epoch: 0187 loss_train: 0.2718 acc_train: 0.9667 loss_val: 0.8457 acc_val: 0.7420 time: 0.0988s\n",
            "57\n",
            "Epoch: 0188 loss_train: 0.2818 acc_train: 0.9500 loss_val: 0.8502 acc_val: 0.7400 time: 0.1031s\n",
            "58\n",
            "Epoch: 0189 loss_train: 0.2692 acc_train: 0.9667 loss_val: 0.8466 acc_val: 0.7400 time: 0.0958s\n",
            "59\n",
            "Epoch: 0190 loss_train: 0.2646 acc_train: 1.0000 loss_val: 0.8376 acc_val: 0.7440 time: 0.1033s\n",
            "60\n",
            "Epoch: 0191 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.8327 acc_val: 0.7440 time: 0.0968s\n",
            "61\n",
            "Epoch: 0192 loss_train: 0.2697 acc_train: 0.9750 loss_val: 0.8310 acc_val: 0.7420 time: 0.0966s\n",
            "62\n",
            "Epoch: 0193 loss_train: 0.3035 acc_train: 0.9833 loss_val: 0.8346 acc_val: 0.7400 time: 0.1026s\n",
            "63\n",
            "Epoch: 0194 loss_train: 0.2772 acc_train: 0.9667 loss_val: 0.8406 acc_val: 0.7440 time: 0.0958s\n",
            "64\n",
            "Epoch: 0195 loss_train: 0.2680 acc_train: 0.9833 loss_val: 0.8428 acc_val: 0.7400 time: 0.0984s\n",
            "65\n",
            "Epoch: 0196 loss_train: 0.2672 acc_train: 0.9667 loss_val: 0.8388 acc_val: 0.7420 time: 0.1032s\n",
            "66\n",
            "Epoch: 0197 loss_train: 0.2671 acc_train: 0.9833 loss_val: 0.8341 acc_val: 0.7420 time: 0.1013s\n",
            "67\n",
            "Epoch: 0198 loss_train: 0.2890 acc_train: 0.9750 loss_val: 0.8342 acc_val: 0.7460 time: 0.1038s\n",
            "68\n",
            "Epoch: 0199 loss_train: 0.2674 acc_train: 0.9833 loss_val: 0.8360 acc_val: 0.7400 time: 0.0982s\n",
            "69\n",
            "Epoch: 0200 loss_train: 0.2752 acc_train: 0.9750 loss_val: 0.8397 acc_val: 0.7400 time: 0.0956s\n",
            "70\n",
            "Epoch: 0201 loss_train: 0.2804 acc_train: 0.9750 loss_val: 0.8465 acc_val: 0.7420 time: 0.1004s\n",
            "71\n",
            "Epoch: 0202 loss_train: 0.2630 acc_train: 0.9750 loss_val: 0.8462 acc_val: 0.7400 time: 0.0978s\n",
            "72\n",
            "Epoch: 0203 loss_train: 0.2754 acc_train: 0.9833 loss_val: 0.8418 acc_val: 0.7400 time: 0.0993s\n",
            "73\n",
            "Epoch: 0204 loss_train: 0.2984 acc_train: 0.9583 loss_val: 0.8384 acc_val: 0.7420 time: 0.0958s\n",
            "74\n",
            "Epoch: 0205 loss_train: 0.2604 acc_train: 0.9667 loss_val: 0.8387 acc_val: 0.7400 time: 0.0956s\n",
            "75\n",
            "Epoch: 0206 loss_train: 0.2808 acc_train: 0.9583 loss_val: 0.8395 acc_val: 0.7420 time: 0.1009s\n",
            "76\n",
            "Epoch: 0207 loss_train: 0.2739 acc_train: 0.9500 loss_val: 0.8420 acc_val: 0.7420 time: 0.0955s\n",
            "77\n",
            "Epoch: 0208 loss_train: 0.2806 acc_train: 0.9750 loss_val: 0.8441 acc_val: 0.7440 time: 0.0993s\n",
            "78\n",
            "Epoch: 0209 loss_train: 0.2762 acc_train: 0.9833 loss_val: 0.8422 acc_val: 0.7420 time: 0.1015s\n",
            "79\n",
            "Epoch: 0210 loss_train: 0.2735 acc_train: 0.9833 loss_val: 0.8394 acc_val: 0.7400 time: 0.0961s\n",
            "80\n",
            "Epoch: 0211 loss_train: 0.2789 acc_train: 0.9667 loss_val: 0.8375 acc_val: 0.7420 time: 0.1001s\n",
            "81\n",
            "Epoch: 0212 loss_train: 0.2614 acc_train: 0.9583 loss_val: 0.8384 acc_val: 0.7420 time: 0.1025s\n",
            "82\n",
            "Epoch: 0213 loss_train: 0.2713 acc_train: 0.9750 loss_val: 0.8389 acc_val: 0.7400 time: 0.1001s\n",
            "83\n",
            "Epoch: 0214 loss_train: 0.2744 acc_train: 0.9750 loss_val: 0.8373 acc_val: 0.7420 time: 0.1012s\n",
            "84\n",
            "Epoch: 0215 loss_train: 0.2754 acc_train: 0.9750 loss_val: 0.8371 acc_val: 0.7400 time: 0.0962s\n",
            "85\n",
            "Epoch: 0216 loss_train: 0.2747 acc_train: 0.9667 loss_val: 0.8369 acc_val: 0.7400 time: 0.1003s\n",
            "86\n",
            "Epoch: 0217 loss_train: 0.2833 acc_train: 0.9750 loss_val: 0.8319 acc_val: 0.7440 time: 0.0949s\n",
            "87\n",
            "Epoch: 0218 loss_train: 0.2736 acc_train: 0.9583 loss_val: 0.8320 acc_val: 0.7420 time: 0.0980s\n",
            "88\n",
            "Epoch: 0219 loss_train: 0.2748 acc_train: 0.9750 loss_val: 0.8374 acc_val: 0.7380 time: 0.0994s\n",
            "89\n",
            "Epoch: 0220 loss_train: 0.2604 acc_train: 0.9833 loss_val: 0.8421 acc_val: 0.7400 time: 0.0952s\n",
            "90\n",
            "Epoch: 0221 loss_train: 0.2652 acc_train: 0.9667 loss_val: 0.8437 acc_val: 0.7380 time: 0.0960s\n",
            "91\n",
            "Epoch: 0222 loss_train: 0.2703 acc_train: 0.9833 loss_val: 0.8393 acc_val: 0.7420 time: 0.1035s\n",
            "92\n",
            "Epoch: 0223 loss_train: 0.2739 acc_train: 0.9667 loss_val: 0.8380 acc_val: 0.7440 time: 0.1018s\n",
            "93\n",
            "Epoch: 0224 loss_train: 0.2712 acc_train: 0.9500 loss_val: 0.8403 acc_val: 0.7460 time: 0.0968s\n",
            "94\n",
            "Epoch: 0225 loss_train: 0.2859 acc_train: 0.9500 loss_val: 0.8451 acc_val: 0.7400 time: 0.1059s\n",
            "95\n",
            "Epoch: 0226 loss_train: 0.2735 acc_train: 0.9833 loss_val: 0.8496 acc_val: 0.7340 time: 0.1001s\n",
            "96\n",
            "Epoch: 0227 loss_train: 0.2778 acc_train: 0.9667 loss_val: 0.8508 acc_val: 0.7340 time: 0.0975s\n",
            "97\n",
            "Epoch: 0228 loss_train: 0.2719 acc_train: 0.9750 loss_val: 0.8458 acc_val: 0.7340 time: 0.1013s\n",
            "98\n",
            "Epoch: 0229 loss_train: 0.2728 acc_train: 0.9667 loss_val: 0.8401 acc_val: 0.7380 time: 0.0952s\n",
            "99\n",
            "Epoch: 0230 loss_train: 0.2800 acc_train: 0.9750 loss_val: 0.8396 acc_val: 0.7400 time: 0.1002s\n",
            "100\n",
            "Epoch: 0231 loss_train: 0.2693 acc_train: 0.9583 loss_val: 0.8422 acc_val: 0.7420 time: 0.0954s\n",
            "101\n",
            "Epoch: 0232 loss_train: 0.2783 acc_train: 0.9583 loss_val: 0.8453 acc_val: 0.7400 time: 0.0954s\n",
            "102\n",
            "Epoch: 0233 loss_train: 0.2662 acc_train: 0.9750 loss_val: 0.8478 acc_val: 0.7360 time: 0.1044s\n",
            "103\n",
            "Epoch: 0234 loss_train: 0.2875 acc_train: 0.9750 loss_val: 0.8495 acc_val: 0.7380 time: 0.0954s\n",
            "104\n",
            "Epoch: 0235 loss_train: 0.2685 acc_train: 0.9583 loss_val: 0.8454 acc_val: 0.7380 time: 0.0948s\n",
            "105\n",
            "Epoch: 0236 loss_train: 0.2813 acc_train: 0.9500 loss_val: 0.8410 acc_val: 0.7400 time: 0.0995s\n",
            "106\n",
            "Epoch: 0237 loss_train: 0.2748 acc_train: 0.9917 loss_val: 0.8357 acc_val: 0.7420 time: 0.0974s\n",
            "107\n",
            "Epoch: 0238 loss_train: 0.2749 acc_train: 0.9750 loss_val: 0.8343 acc_val: 0.7420 time: 0.0972s\n",
            "108\n",
            "Epoch: 0239 loss_train: 0.2786 acc_train: 0.9667 loss_val: 0.8410 acc_val: 0.7420 time: 0.1086s\n",
            "109\n",
            "Epoch: 0240 loss_train: 0.2786 acc_train: 0.9583 loss_val: 0.8450 acc_val: 0.7420 time: 0.0963s\n",
            "110\n",
            "Epoch: 0241 loss_train: 0.2720 acc_train: 0.9333 loss_val: 0.8447 acc_val: 0.7420 time: 0.0964s\n",
            "111\n",
            "Epoch: 0242 loss_train: 0.2730 acc_train: 0.9750 loss_val: 0.8412 acc_val: 0.7420 time: 0.1013s\n",
            "112\n",
            "Epoch: 0243 loss_train: 0.2608 acc_train: 0.9833 loss_val: 0.8362 acc_val: 0.7440 time: 0.1025s\n",
            "113\n",
            "Epoch: 0244 loss_train: 0.2707 acc_train: 0.9750 loss_val: 0.8372 acc_val: 0.7460 time: 0.1014s\n",
            "114\n",
            "Epoch: 0245 loss_train: 0.2676 acc_train: 0.9667 loss_val: 0.8391 acc_val: 0.7420 time: 0.1040s\n",
            "115\n",
            "Epoch: 0246 loss_train: 0.2824 acc_train: 0.9667 loss_val: 0.8404 acc_val: 0.7400 time: 0.1039s\n",
            "116\n",
            "Epoch: 0247 loss_train: 0.2942 acc_train: 0.9667 loss_val: 0.8394 acc_val: 0.7400 time: 0.1080s\n",
            "117\n",
            "Epoch: 0248 loss_train: 0.2793 acc_train: 0.9917 loss_val: 0.8404 acc_val: 0.7400 time: 0.0985s\n",
            "118\n",
            "Epoch: 0249 loss_train: 0.2775 acc_train: 0.9667 loss_val: 0.8421 acc_val: 0.7400 time: 0.0994s\n",
            "119\n",
            "Epoch: 0250 loss_train: 0.2877 acc_train: 0.9500 loss_val: 0.8446 acc_val: 0.7420 time: 0.0952s\n",
            "120\n",
            "Epoch: 0251 loss_train: 0.2659 acc_train: 0.9667 loss_val: 0.8467 acc_val: 0.7420 time: 0.1026s\n",
            "121\n",
            "Epoch: 0252 loss_train: 0.2658 acc_train: 0.9833 loss_val: 0.8442 acc_val: 0.7380 time: 0.0967s\n",
            "122\n",
            "Epoch: 0253 loss_train: 0.2893 acc_train: 0.9500 loss_val: 0.8412 acc_val: 0.7380 time: 0.1004s\n",
            "123\n",
            "Epoch: 0254 loss_train: 0.2786 acc_train: 0.9750 loss_val: 0.8384 acc_val: 0.7400 time: 0.0964s\n",
            "124\n",
            "Epoch: 0255 loss_train: 0.2963 acc_train: 0.9500 loss_val: 0.8387 acc_val: 0.7360 time: 0.0959s\n",
            "125\n",
            "Epoch: 0256 loss_train: 0.2719 acc_train: 0.9750 loss_val: 0.8401 acc_val: 0.7360 time: 0.1015s\n",
            "126\n",
            "Epoch: 0257 loss_train: 0.2540 acc_train: 0.9667 loss_val: 0.8423 acc_val: 0.7360 time: 0.0957s\n",
            "127\n",
            "Epoch: 0258 loss_train: 0.2744 acc_train: 0.9917 loss_val: 0.8414 acc_val: 0.7400 time: 0.0953s\n",
            "128\n",
            "Epoch: 0259 loss_train: 0.2682 acc_train: 0.9667 loss_val: 0.8393 acc_val: 0.7420 time: 0.1044s\n",
            "129\n",
            "Epoch: 0260 loss_train: 0.2705 acc_train: 0.9667 loss_val: 0.8374 acc_val: 0.7420 time: 0.0989s\n",
            "130\n",
            "Epoch: 0261 loss_train: 0.2715 acc_train: 0.9583 loss_val: 0.8372 acc_val: 0.7420 time: 0.0999s\n",
            "131\n",
            "Epoch: 0262 loss_train: 0.2805 acc_train: 0.9667 loss_val: 0.8375 acc_val: 0.7420 time: 0.0985s\n",
            "132\n",
            "Epoch: 0263 loss_train: 0.2652 acc_train: 0.9750 loss_val: 0.8366 acc_val: 0.7400 time: 0.0988s\n",
            "133\n",
            "Epoch: 0264 loss_train: 0.2734 acc_train: 0.9750 loss_val: 0.8379 acc_val: 0.7440 time: 0.1009s\n",
            "134\n",
            "Epoch: 0265 loss_train: 0.2799 acc_train: 0.9667 loss_val: 0.8377 acc_val: 0.7440 time: 0.0952s\n",
            "135\n",
            "Epoch: 0266 loss_train: 0.2945 acc_train: 0.9583 loss_val: 0.8427 acc_val: 0.7380 time: 0.1011s\n",
            "136\n",
            "Epoch: 0267 loss_train: 0.2694 acc_train: 0.9750 loss_val: 0.8469 acc_val: 0.7400 time: 0.1002s\n",
            "137\n",
            "Epoch: 0268 loss_train: 0.2701 acc_train: 0.9583 loss_val: 0.8482 acc_val: 0.7400 time: 0.0980s\n",
            "138\n",
            "Epoch: 0269 loss_train: 0.2643 acc_train: 0.9583 loss_val: 0.8455 acc_val: 0.7420 time: 0.1047s\n",
            "139\n",
            "Epoch: 0270 loss_train: 0.2778 acc_train: 0.9667 loss_val: 0.8404 acc_val: 0.7440 time: 0.0972s\n",
            "140\n",
            "Epoch: 0271 loss_train: 0.2719 acc_train: 0.9500 loss_val: 0.8334 acc_val: 0.7460 time: 0.0994s\n",
            "141\n",
            "Epoch: 0272 loss_train: 0.2772 acc_train: 1.0000 loss_val: 0.8318 acc_val: 0.7460 time: 0.0960s\n",
            "142\n",
            "Epoch: 0273 loss_train: 0.2684 acc_train: 0.9833 loss_val: 0.8363 acc_val: 0.7400 time: 0.0987s\n",
            "143\n",
            "Epoch: 0274 loss_train: 0.2672 acc_train: 0.9833 loss_val: 0.8465 acc_val: 0.7400 time: 0.1003s\n",
            "144\n",
            "Epoch: 0275 loss_train: 0.2645 acc_train: 0.9500 loss_val: 0.8540 acc_val: 0.7420 time: 0.0962s\n",
            "145\n",
            "Epoch: 0276 loss_train: 0.2664 acc_train: 0.9833 loss_val: 0.8511 acc_val: 0.7420 time: 0.1030s\n",
            "146\n",
            "Epoch: 0277 loss_train: 0.2678 acc_train: 0.9917 loss_val: 0.8411 acc_val: 0.7460 time: 0.0976s\n",
            "147\n",
            "Epoch: 0278 loss_train: 0.2701 acc_train: 0.9917 loss_val: 0.8347 acc_val: 0.7480 time: 0.0954s\n",
            "148\n",
            "Epoch: 0279 loss_train: 0.2574 acc_train: 0.9833 loss_val: 0.8336 acc_val: 0.7480 time: 0.1046s\n",
            "0\n",
            "Epoch: 0280 loss_train: 0.2980 acc_train: 0.9583 loss_val: 0.8382 acc_val: 0.7400 time: 0.1042s\n",
            "0\n",
            "Epoch: 0281 loss_train: 0.2756 acc_train: 0.9667 loss_val: 0.8451 acc_val: 0.7380 time: 0.0988s\n",
            "1\n",
            "Epoch: 0282 loss_train: 0.2730 acc_train: 0.9667 loss_val: 0.8547 acc_val: 0.7360 time: 0.0987s\n",
            "2\n",
            "Epoch: 0283 loss_train: 0.2800 acc_train: 0.9833 loss_val: 0.8535 acc_val: 0.7380 time: 0.0962s\n",
            "3\n",
            "Epoch: 0284 loss_train: 0.2759 acc_train: 0.9583 loss_val: 0.8406 acc_val: 0.7380 time: 0.1023s\n",
            "4\n",
            "Epoch: 0285 loss_train: 0.2628 acc_train: 0.9750 loss_val: 0.8319 acc_val: 0.7460 time: 0.0977s\n",
            "5\n",
            "Epoch: 0286 loss_train: 0.2567 acc_train: 0.9917 loss_val: 0.8304 acc_val: 0.7460 time: 0.1035s\n",
            "6\n",
            "Epoch: 0287 loss_train: 0.2645 acc_train: 0.9750 loss_val: 0.8354 acc_val: 0.7480 time: 0.0985s\n",
            "7\n",
            "Epoch: 0288 loss_train: 0.2820 acc_train: 0.9583 loss_val: 0.8461 acc_val: 0.7400 time: 0.1004s\n",
            "0\n",
            "Epoch: 0289 loss_train: 0.2804 acc_train: 0.9667 loss_val: 0.8575 acc_val: 0.7360 time: 0.0957s\n",
            "1\n",
            "Epoch: 0290 loss_train: 0.2817 acc_train: 0.9500 loss_val: 0.8592 acc_val: 0.7380 time: 0.1032s\n",
            "2\n",
            "Epoch: 0291 loss_train: 0.2927 acc_train: 0.9500 loss_val: 0.8486 acc_val: 0.7380 time: 0.0952s\n",
            "3\n",
            "Epoch: 0292 loss_train: 0.2632 acc_train: 0.9667 loss_val: 0.8380 acc_val: 0.7420 time: 0.0979s\n",
            "4\n",
            "Epoch: 0293 loss_train: 0.2784 acc_train: 0.9500 loss_val: 0.8336 acc_val: 0.7440 time: 0.1032s\n",
            "5\n",
            "Epoch: 0294 loss_train: 0.2764 acc_train: 0.9500 loss_val: 0.8334 acc_val: 0.7480 time: 0.0951s\n",
            "6\n",
            "Epoch: 0295 loss_train: 0.2837 acc_train: 0.9333 loss_val: 0.8402 acc_val: 0.7460 time: 0.0949s\n",
            "0\n",
            "Epoch: 0296 loss_train: 0.2852 acc_train: 0.9667 loss_val: 0.8498 acc_val: 0.7420 time: 0.1057s\n",
            "1\n",
            "Epoch: 0297 loss_train: 0.2580 acc_train: 0.9667 loss_val: 0.8536 acc_val: 0.7420 time: 0.0955s\n",
            "2\n",
            "Epoch: 0298 loss_train: 0.2754 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7440 time: 0.0955s\n",
            "3\n",
            "Epoch: 0299 loss_train: 0.2874 acc_train: 0.9583 loss_val: 0.8391 acc_val: 0.7400 time: 0.1003s\n",
            "4\n",
            "Epoch: 0300 loss_train: 0.2700 acc_train: 0.9667 loss_val: 0.8343 acc_val: 0.7420 time: 0.0957s\n",
            "5\n",
            "Epoch: 0301 loss_train: 0.2959 acc_train: 0.9750 loss_val: 0.8356 acc_val: 0.7420 time: 0.0956s\n",
            "6\n",
            "Epoch: 0302 loss_train: 0.2676 acc_train: 0.9750 loss_val: 0.8392 acc_val: 0.7460 time: 0.1089s\n",
            "7\n",
            "Epoch: 0303 loss_train: 0.2717 acc_train: 0.9500 loss_val: 0.8396 acc_val: 0.7460 time: 0.0989s\n",
            "8\n",
            "Epoch: 0304 loss_train: 0.2764 acc_train: 0.9750 loss_val: 0.8418 acc_val: 0.7440 time: 0.0956s\n",
            "9\n",
            "Epoch: 0305 loss_train: 0.2824 acc_train: 0.9833 loss_val: 0.8395 acc_val: 0.7440 time: 0.1021s\n",
            "10\n",
            "Epoch: 0306 loss_train: 0.2762 acc_train: 0.9583 loss_val: 0.8404 acc_val: 0.7440 time: 0.0965s\n",
            "11\n",
            "Epoch: 0307 loss_train: 0.2948 acc_train: 0.9667 loss_val: 0.8449 acc_val: 0.7400 time: 0.1014s\n",
            "12\n",
            "Epoch: 0308 loss_train: 0.2694 acc_train: 0.9750 loss_val: 0.8485 acc_val: 0.7420 time: 0.0989s\n",
            "13\n",
            "Epoch: 0309 loss_train: 0.2740 acc_train: 0.9583 loss_val: 0.8479 acc_val: 0.7420 time: 0.0958s\n",
            "14\n",
            "Epoch: 0310 loss_train: 0.2723 acc_train: 0.9750 loss_val: 0.8479 acc_val: 0.7440 time: 0.1048s\n",
            "15\n",
            "Epoch: 0311 loss_train: 0.2785 acc_train: 0.9667 loss_val: 0.8480 acc_val: 0.7420 time: 0.0983s\n",
            "16\n",
            "Epoch: 0312 loss_train: 0.2731 acc_train: 0.9583 loss_val: 0.8433 acc_val: 0.7460 time: 0.1022s\n",
            "17\n",
            "Epoch: 0313 loss_train: 0.2765 acc_train: 0.9750 loss_val: 0.8395 acc_val: 0.7440 time: 0.1000s\n",
            "18\n",
            "Epoch: 0314 loss_train: 0.2757 acc_train: 0.9583 loss_val: 0.8416 acc_val: 0.7400 time: 0.0966s\n",
            "19\n",
            "Epoch: 0315 loss_train: 0.2576 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7420 time: 0.1056s\n",
            "20\n",
            "Epoch: 0316 loss_train: 0.2599 acc_train: 0.9583 loss_val: 0.8476 acc_val: 0.7420 time: 0.0979s\n",
            "21\n",
            "Epoch: 0317 loss_train: 0.2840 acc_train: 0.9583 loss_val: 0.8440 acc_val: 0.7420 time: 0.1045s\n",
            "22\n",
            "Epoch: 0318 loss_train: 0.2694 acc_train: 0.9667 loss_val: 0.8406 acc_val: 0.7420 time: 0.0969s\n",
            "23\n",
            "Epoch: 0319 loss_train: 0.2797 acc_train: 0.9583 loss_val: 0.8383 acc_val: 0.7440 time: 0.1024s\n",
            "24\n",
            "Epoch: 0320 loss_train: 0.2675 acc_train: 0.9917 loss_val: 0.8372 acc_val: 0.7460 time: 0.1010s\n",
            "25\n",
            "Epoch: 0321 loss_train: 0.2749 acc_train: 0.9583 loss_val: 0.8369 acc_val: 0.7460 time: 0.0985s\n",
            "26\n",
            "Epoch: 0322 loss_train: 0.2778 acc_train: 0.9583 loss_val: 0.8401 acc_val: 0.7400 time: 0.1076s\n",
            "27\n",
            "Epoch: 0323 loss_train: 0.2768 acc_train: 0.9667 loss_val: 0.8459 acc_val: 0.7400 time: 0.0953s\n",
            "28\n",
            "Epoch: 0324 loss_train: 0.2684 acc_train: 0.9583 loss_val: 0.8503 acc_val: 0.7400 time: 0.0960s\n",
            "29\n",
            "Epoch: 0325 loss_train: 0.2840 acc_train: 0.9667 loss_val: 0.8475 acc_val: 0.7400 time: 0.1006s\n",
            "30\n",
            "Epoch: 0326 loss_train: 0.2724 acc_train: 0.9750 loss_val: 0.8396 acc_val: 0.7420 time: 0.0976s\n",
            "31\n",
            "Epoch: 0327 loss_train: 0.2955 acc_train: 0.9583 loss_val: 0.8319 acc_val: 0.7460 time: 0.0954s\n",
            "32\n",
            "Epoch: 0328 loss_train: 0.2714 acc_train: 0.9667 loss_val: 0.8318 acc_val: 0.7480 time: 0.1006s\n",
            "33\n",
            "Epoch: 0329 loss_train: 0.2863 acc_train: 0.9583 loss_val: 0.8389 acc_val: 0.7480 time: 0.0974s\n",
            "0\n",
            "Epoch: 0330 loss_train: 0.2795 acc_train: 0.9583 loss_val: 0.8473 acc_val: 0.7460 time: 0.0950s\n",
            "0\n",
            "Epoch: 0331 loss_train: 0.2720 acc_train: 0.9750 loss_val: 0.8523 acc_val: 0.7420 time: 0.1068s\n",
            "1\n",
            "Epoch: 0332 loss_train: 0.2774 acc_train: 0.9667 loss_val: 0.8472 acc_val: 0.7400 time: 0.1044s\n",
            "2\n",
            "Epoch: 0333 loss_train: 0.2694 acc_train: 0.9333 loss_val: 0.8418 acc_val: 0.7420 time: 0.0955s\n",
            "3\n",
            "Epoch: 0334 loss_train: 0.2651 acc_train: 0.9833 loss_val: 0.8392 acc_val: 0.7420 time: 0.1084s\n",
            "4\n",
            "Epoch: 0335 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.8371 acc_val: 0.7440 time: 0.0960s\n",
            "5\n",
            "Epoch: 0336 loss_train: 0.2669 acc_train: 0.9667 loss_val: 0.8402 acc_val: 0.7460 time: 0.1032s\n",
            "6\n",
            "Epoch: 0337 loss_train: 0.2670 acc_train: 0.9917 loss_val: 0.8445 acc_val: 0.7460 time: 0.0959s\n",
            "7\n",
            "Epoch: 0338 loss_train: 0.2633 acc_train: 0.9500 loss_val: 0.8495 acc_val: 0.7400 time: 0.0997s\n",
            "8\n",
            "Epoch: 0339 loss_train: 0.2836 acc_train: 0.9500 loss_val: 0.8540 acc_val: 0.7400 time: 0.0955s\n",
            "9\n",
            "Epoch: 0340 loss_train: 0.2722 acc_train: 0.9583 loss_val: 0.8521 acc_val: 0.7380 time: 0.0958s\n",
            "10\n",
            "Epoch: 0341 loss_train: 0.2573 acc_train: 0.9833 loss_val: 0.8449 acc_val: 0.7440 time: 0.1010s\n",
            "11\n",
            "Epoch: 0342 loss_train: 0.2570 acc_train: 0.9750 loss_val: 0.8390 acc_val: 0.7400 time: 0.1002s\n",
            "12\n",
            "Epoch: 0343 loss_train: 0.2684 acc_train: 0.9667 loss_val: 0.8372 acc_val: 0.7440 time: 0.0953s\n",
            "13\n",
            "Epoch: 0344 loss_train: 0.2863 acc_train: 0.9583 loss_val: 0.8399 acc_val: 0.7440 time: 0.1089s\n",
            "14\n",
            "Epoch: 0345 loss_train: 0.2864 acc_train: 0.9833 loss_val: 0.8470 acc_val: 0.7460 time: 0.0982s\n",
            "15\n",
            "Epoch: 0346 loss_train: 0.2767 acc_train: 0.9917 loss_val: 0.8531 acc_val: 0.7380 time: 0.1000s\n",
            "16\n",
            "Epoch: 0347 loss_train: 0.2826 acc_train: 0.9750 loss_val: 0.8471 acc_val: 0.7400 time: 0.1032s\n",
            "17\n",
            "Epoch: 0348 loss_train: 0.2907 acc_train: 0.9500 loss_val: 0.8410 acc_val: 0.7420 time: 0.0971s\n",
            "18\n",
            "Epoch: 0349 loss_train: 0.2678 acc_train: 0.9750 loss_val: 0.8378 acc_val: 0.7440 time: 0.0995s\n",
            "19\n",
            "Epoch: 0350 loss_train: 0.2820 acc_train: 0.9500 loss_val: 0.8381 acc_val: 0.7400 time: 0.0966s\n",
            "20\n",
            "Epoch: 0351 loss_train: 0.2679 acc_train: 0.9750 loss_val: 0.8407 acc_val: 0.7420 time: 0.0973s\n",
            "21\n",
            "Epoch: 0352 loss_train: 0.2866 acc_train: 0.9583 loss_val: 0.8462 acc_val: 0.7440 time: 0.1059s\n",
            "22\n",
            "Epoch: 0353 loss_train: 0.2871 acc_train: 0.9583 loss_val: 0.8487 acc_val: 0.7420 time: 0.0988s\n",
            "23\n",
            "Epoch: 0354 loss_train: 0.2678 acc_train: 0.9667 loss_val: 0.8485 acc_val: 0.7420 time: 0.1000s\n",
            "24\n",
            "Epoch: 0355 loss_train: 0.2759 acc_train: 0.9583 loss_val: 0.8417 acc_val: 0.7440 time: 0.0952s\n",
            "25\n",
            "Epoch: 0356 loss_train: 0.2739 acc_train: 0.9750 loss_val: 0.8354 acc_val: 0.7440 time: 0.0967s\n",
            "26\n",
            "Epoch: 0357 loss_train: 0.2659 acc_train: 0.9833 loss_val: 0.8332 acc_val: 0.7440 time: 0.1036s\n",
            "27\n",
            "Epoch: 0358 loss_train: 0.2890 acc_train: 0.9583 loss_val: 0.8375 acc_val: 0.7420 time: 0.1037s\n",
            "28\n",
            "Epoch: 0359 loss_train: 0.2675 acc_train: 0.9583 loss_val: 0.8413 acc_val: 0.7420 time: 0.0954s\n",
            "29\n",
            "Epoch: 0360 loss_train: 0.2875 acc_train: 0.9583 loss_val: 0.8481 acc_val: 0.7380 time: 0.1066s\n",
            "30\n",
            "Epoch: 0361 loss_train: 0.2682 acc_train: 0.9500 loss_val: 0.8510 acc_val: 0.7360 time: 0.1055s\n",
            "31\n",
            "Epoch: 0362 loss_train: 0.2901 acc_train: 0.9667 loss_val: 0.8488 acc_val: 0.7420 time: 0.1038s\n",
            "32\n",
            "Epoch: 0363 loss_train: 0.2681 acc_train: 0.9500 loss_val: 0.8429 acc_val: 0.7480 time: 0.1047s\n",
            "33\n",
            "Epoch: 0364 loss_train: 0.2701 acc_train: 0.9750 loss_val: 0.8401 acc_val: 0.7460 time: 0.1037s\n",
            "0\n",
            "Epoch: 0365 loss_train: 0.2760 acc_train: 1.0000 loss_val: 0.8417 acc_val: 0.7400 time: 0.1027s\n",
            "1\n",
            "Epoch: 0366 loss_train: 0.2702 acc_train: 0.9750 loss_val: 0.8451 acc_val: 0.7380 time: 0.1179s\n",
            "2\n",
            "Epoch: 0367 loss_train: 0.2645 acc_train: 0.9917 loss_val: 0.8467 acc_val: 0.7420 time: 0.1069s\n",
            "3\n",
            "Epoch: 0368 loss_train: 0.2765 acc_train: 0.9667 loss_val: 0.8458 acc_val: 0.7380 time: 0.1034s\n",
            "4\n",
            "Epoch: 0369 loss_train: 0.2880 acc_train: 0.9417 loss_val: 0.8455 acc_val: 0.7380 time: 0.0991s\n",
            "5\n",
            "Epoch: 0370 loss_train: 0.2910 acc_train: 0.9417 loss_val: 0.8458 acc_val: 0.7420 time: 0.1031s\n",
            "6\n",
            "Epoch: 0371 loss_train: 0.2645 acc_train: 0.9833 loss_val: 0.8456 acc_val: 0.7460 time: 0.0969s\n",
            "7\n",
            "Epoch: 0372 loss_train: 0.2647 acc_train: 0.9750 loss_val: 0.8432 acc_val: 0.7440 time: 0.1014s\n",
            "8\n",
            "Epoch: 0373 loss_train: 0.2707 acc_train: 0.9667 loss_val: 0.8412 acc_val: 0.7420 time: 0.0974s\n",
            "9\n",
            "Epoch: 0374 loss_train: 0.2827 acc_train: 0.9750 loss_val: 0.8416 acc_val: 0.7420 time: 0.0980s\n",
            "10\n",
            "Epoch: 0375 loss_train: 0.2767 acc_train: 0.9500 loss_val: 0.8421 acc_val: 0.7420 time: 0.1060s\n",
            "11\n",
            "Epoch: 0376 loss_train: 0.2755 acc_train: 0.9750 loss_val: 0.8412 acc_val: 0.7400 time: 0.0986s\n",
            "12\n",
            "Epoch: 0377 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.8402 acc_val: 0.7400 time: 0.1030s\n",
            "13\n",
            "Epoch: 0378 loss_train: 0.2765 acc_train: 0.9500 loss_val: 0.8370 acc_val: 0.7480 time: 0.0971s\n",
            "14\n",
            "Epoch: 0379 loss_train: 0.2606 acc_train: 0.9667 loss_val: 0.8327 acc_val: 0.7460 time: 0.0950s\n",
            "0\n",
            "Epoch: 0380 loss_train: 0.2722 acc_train: 0.9750 loss_val: 0.8343 acc_val: 0.7420 time: 0.0998s\n",
            "1\n",
            "Epoch: 0381 loss_train: 0.2658 acc_train: 0.9750 loss_val: 0.8390 acc_val: 0.7440 time: 0.1041s\n",
            "2\n",
            "Epoch: 0382 loss_train: 0.2737 acc_train: 0.9667 loss_val: 0.8428 acc_val: 0.7400 time: 0.0980s\n",
            "3\n",
            "Epoch: 0383 loss_train: 0.2837 acc_train: 0.9500 loss_val: 0.8430 acc_val: 0.7380 time: 0.0986s\n",
            "4\n",
            "Epoch: 0384 loss_train: 0.2800 acc_train: 0.9583 loss_val: 0.8411 acc_val: 0.7380 time: 0.0990s\n",
            "5\n",
            "Epoch: 0385 loss_train: 0.2608 acc_train: 0.9917 loss_val: 0.8395 acc_val: 0.7400 time: 0.1050s\n",
            "6\n",
            "Epoch: 0386 loss_train: 0.2744 acc_train: 0.9750 loss_val: 0.8391 acc_val: 0.7400 time: 0.0971s\n",
            "7\n",
            "Epoch: 0387 loss_train: 0.2847 acc_train: 0.9417 loss_val: 0.8417 acc_val: 0.7420 time: 0.1054s\n",
            "8\n",
            "Epoch: 0388 loss_train: 0.2762 acc_train: 0.9583 loss_val: 0.8468 acc_val: 0.7380 time: 0.0965s\n",
            "9\n",
            "Epoch: 0389 loss_train: 0.2704 acc_train: 0.9833 loss_val: 0.8496 acc_val: 0.7360 time: 0.0967s\n",
            "10\n",
            "Epoch: 0390 loss_train: 0.2772 acc_train: 0.9583 loss_val: 0.8505 acc_val: 0.7340 time: 0.1007s\n",
            "11\n",
            "Epoch: 0391 loss_train: 0.2632 acc_train: 0.9833 loss_val: 0.8453 acc_val: 0.7380 time: 0.0999s\n",
            "12\n",
            "Epoch: 0392 loss_train: 0.2913 acc_train: 0.9583 loss_val: 0.8395 acc_val: 0.7380 time: 0.0971s\n",
            "13\n",
            "Epoch: 0393 loss_train: 0.2712 acc_train: 0.9667 loss_val: 0.8365 acc_val: 0.7380 time: 0.1031s\n",
            "14\n",
            "Epoch: 0394 loss_train: 0.2856 acc_train: 0.9750 loss_val: 0.8380 acc_val: 0.7400 time: 0.0957s\n",
            "15\n",
            "Epoch: 0395 loss_train: 0.2720 acc_train: 0.9667 loss_val: 0.8417 acc_val: 0.7400 time: 0.0967s\n",
            "16\n",
            "Epoch: 0396 loss_train: 0.2686 acc_train: 0.9583 loss_val: 0.8425 acc_val: 0.7400 time: 0.0954s\n",
            "17\n",
            "Epoch: 0397 loss_train: 0.2712 acc_train: 0.9750 loss_val: 0.8427 acc_val: 0.7400 time: 0.0951s\n",
            "18\n",
            "Epoch: 0398 loss_train: 0.2878 acc_train: 0.9583 loss_val: 0.8413 acc_val: 0.7380 time: 0.1026s\n",
            "19\n",
            "Epoch: 0399 loss_train: 0.2683 acc_train: 0.9833 loss_val: 0.8378 acc_val: 0.7380 time: 0.0994s\n",
            "20\n",
            "Epoch: 0400 loss_train: 0.2563 acc_train: 0.9750 loss_val: 0.8349 acc_val: 0.7360 time: 0.0984s\n",
            "21\n",
            "Epoch: 0401 loss_train: 0.2716 acc_train: 0.9750 loss_val: 0.8355 acc_val: 0.7360 time: 0.1078s\n",
            "22\n",
            "Epoch: 0402 loss_train: 0.2769 acc_train: 0.9583 loss_val: 0.8388 acc_val: 0.7380 time: 0.1014s\n",
            "23\n",
            "Epoch: 0403 loss_train: 0.2741 acc_train: 0.9417 loss_val: 0.8403 acc_val: 0.7400 time: 0.1006s\n",
            "24\n",
            "Epoch: 0404 loss_train: 0.2665 acc_train: 0.9667 loss_val: 0.8393 acc_val: 0.7380 time: 0.0977s\n",
            "25\n",
            "Epoch: 0405 loss_train: 0.2750 acc_train: 0.9667 loss_val: 0.8347 acc_val: 0.7400 time: 0.0979s\n",
            "26\n",
            "Epoch: 0406 loss_train: 0.2606 acc_train: 1.0000 loss_val: 0.8321 acc_val: 0.7400 time: 0.0949s\n",
            "27\n",
            "Epoch: 0407 loss_train: 0.2642 acc_train: 0.9750 loss_val: 0.8346 acc_val: 0.7380 time: 0.0985s\n",
            "28\n",
            "Epoch: 0408 loss_train: 0.2747 acc_train: 0.9917 loss_val: 0.8388 acc_val: 0.7400 time: 0.1034s\n",
            "29\n",
            "Epoch: 0409 loss_train: 0.2641 acc_train: 0.9917 loss_val: 0.8450 acc_val: 0.7420 time: 0.0957s\n",
            "30\n",
            "Epoch: 0410 loss_train: 0.2816 acc_train: 0.9667 loss_val: 0.8458 acc_val: 0.7360 time: 0.0956s\n",
            "31\n",
            "Epoch: 0411 loss_train: 0.2705 acc_train: 0.9833 loss_val: 0.8401 acc_val: 0.7400 time: 0.1090s\n",
            "32\n",
            "Epoch: 0412 loss_train: 0.2591 acc_train: 0.9833 loss_val: 0.8325 acc_val: 0.7420 time: 0.1035s\n",
            "33\n",
            "Epoch: 0413 loss_train: 0.2851 acc_train: 0.9667 loss_val: 0.8313 acc_val: 0.7420 time: 0.0990s\n",
            "34\n",
            "Epoch: 0414 loss_train: 0.2785 acc_train: 0.9583 loss_val: 0.8306 acc_val: 0.7400 time: 0.1060s\n",
            "35\n",
            "Epoch: 0415 loss_train: 0.2905 acc_train: 0.9667 loss_val: 0.8361 acc_val: 0.7380 time: 0.0982s\n",
            "36\n",
            "Epoch: 0416 loss_train: 0.2858 acc_train: 0.9500 loss_val: 0.8434 acc_val: 0.7380 time: 0.1037s\n",
            "37\n",
            "Epoch: 0417 loss_train: 0.2711 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7360 time: 0.0969s\n",
            "38\n",
            "Epoch: 0418 loss_train: 0.2723 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7360 time: 0.0990s\n",
            "39\n",
            "Epoch: 0419 loss_train: 0.2761 acc_train: 0.9667 loss_val: 0.8391 acc_val: 0.7380 time: 0.0953s\n",
            "40\n",
            "Epoch: 0420 loss_train: 0.2822 acc_train: 0.9500 loss_val: 0.8366 acc_val: 0.7420 time: 0.0999s\n",
            "41\n",
            "Epoch: 0421 loss_train: 0.2741 acc_train: 0.9750 loss_val: 0.8372 acc_val: 0.7420 time: 0.1063s\n",
            "42\n",
            "Epoch: 0422 loss_train: 0.2842 acc_train: 0.9750 loss_val: 0.8395 acc_val: 0.7400 time: 0.0962s\n",
            "43\n",
            "Epoch: 0423 loss_train: 0.2743 acc_train: 0.9833 loss_val: 0.8434 acc_val: 0.7380 time: 0.1013s\n",
            "44\n",
            "Epoch: 0424 loss_train: 0.2615 acc_train: 0.9750 loss_val: 0.8451 acc_val: 0.7400 time: 0.0981s\n",
            "45\n",
            "Epoch: 0425 loss_train: 0.2790 acc_train: 0.9500 loss_val: 0.8432 acc_val: 0.7380 time: 0.0993s\n",
            "46\n",
            "Epoch: 0426 loss_train: 0.2813 acc_train: 0.9667 loss_val: 0.8413 acc_val: 0.7380 time: 0.1023s\n",
            "47\n",
            "Epoch: 0427 loss_train: 0.2695 acc_train: 0.9917 loss_val: 0.8395 acc_val: 0.7380 time: 0.0959s\n",
            "48\n",
            "Epoch: 0428 loss_train: 0.2838 acc_train: 0.9583 loss_val: 0.8384 acc_val: 0.7420 time: 0.1018s\n",
            "49\n",
            "Epoch: 0429 loss_train: 0.2784 acc_train: 0.9667 loss_val: 0.8412 acc_val: 0.7420 time: 0.0963s\n",
            "50\n",
            "Epoch: 0430 loss_train: 0.2808 acc_train: 0.9583 loss_val: 0.8465 acc_val: 0.7380 time: 0.0985s\n",
            "51\n",
            "Epoch: 0431 loss_train: 0.2838 acc_train: 0.9833 loss_val: 0.8484 acc_val: 0.7380 time: 0.1203s\n",
            "52\n",
            "Epoch: 0432 loss_train: 0.2630 acc_train: 0.9750 loss_val: 0.8455 acc_val: 0.7360 time: 0.1091s\n",
            "53\n",
            "Epoch: 0433 loss_train: 0.2680 acc_train: 0.9750 loss_val: 0.8399 acc_val: 0.7380 time: 0.1028s\n",
            "54\n",
            "Epoch: 0434 loss_train: 0.2776 acc_train: 0.9500 loss_val: 0.8367 acc_val: 0.7380 time: 0.0961s\n",
            "55\n",
            "Epoch: 0435 loss_train: 0.2585 acc_train: 0.9750 loss_val: 0.8345 acc_val: 0.7400 time: 0.1038s\n",
            "56\n",
            "Epoch: 0436 loss_train: 0.2800 acc_train: 0.9750 loss_val: 0.8377 acc_val: 0.7400 time: 0.0965s\n",
            "57\n",
            "Epoch: 0437 loss_train: 0.2913 acc_train: 0.9667 loss_val: 0.8430 acc_val: 0.7380 time: 0.1040s\n",
            "58\n",
            "Epoch: 0438 loss_train: 0.2733 acc_train: 0.9500 loss_val: 0.8502 acc_val: 0.7400 time: 0.0968s\n",
            "59\n",
            "Epoch: 0439 loss_train: 0.2590 acc_train: 0.9750 loss_val: 0.8489 acc_val: 0.7420 time: 0.0995s\n",
            "60\n",
            "Epoch: 0440 loss_train: 0.3073 acc_train: 0.9500 loss_val: 0.8416 acc_val: 0.7380 time: 0.1055s\n",
            "61\n",
            "Epoch: 0441 loss_train: 0.2709 acc_train: 0.9667 loss_val: 0.8358 acc_val: 0.7400 time: 0.1007s\n",
            "62\n",
            "Epoch: 0442 loss_train: 0.2857 acc_train: 0.9417 loss_val: 0.8346 acc_val: 0.7420 time: 0.0996s\n",
            "63\n",
            "Epoch: 0443 loss_train: 0.2938 acc_train: 0.9583 loss_val: 0.8388 acc_val: 0.7420 time: 0.0973s\n",
            "64\n",
            "Epoch: 0444 loss_train: 0.2798 acc_train: 0.9500 loss_val: 0.8448 acc_val: 0.7360 time: 0.0976s\n",
            "65\n",
            "Epoch: 0445 loss_train: 0.2844 acc_train: 0.9750 loss_val: 0.8506 acc_val: 0.7380 time: 0.1028s\n",
            "66\n",
            "Epoch: 0446 loss_train: 0.2869 acc_train: 0.9583 loss_val: 0.8509 acc_val: 0.7380 time: 0.0965s\n",
            "67\n",
            "Epoch: 0447 loss_train: 0.2787 acc_train: 0.9417 loss_val: 0.8483 acc_val: 0.7340 time: 0.1010s\n",
            "68\n",
            "Epoch: 0448 loss_train: 0.2693 acc_train: 0.9750 loss_val: 0.8447 acc_val: 0.7380 time: 0.1081s\n",
            "69\n",
            "Epoch: 0449 loss_train: 0.2720 acc_train: 0.9750 loss_val: 0.8439 acc_val: 0.7380 time: 0.1043s\n",
            "70\n",
            "Epoch: 0450 loss_train: 0.2669 acc_train: 0.9750 loss_val: 0.8437 acc_val: 0.7380 time: 0.0963s\n",
            "71\n",
            "Epoch: 0451 loss_train: 0.2702 acc_train: 0.9917 loss_val: 0.8445 acc_val: 0.7380 time: 0.0987s\n",
            "72\n",
            "Epoch: 0452 loss_train: 0.2703 acc_train: 0.9583 loss_val: 0.8470 acc_val: 0.7340 time: 0.1054s\n",
            "73\n",
            "Epoch: 0453 loss_train: 0.2840 acc_train: 0.9667 loss_val: 0.8468 acc_val: 0.7360 time: 0.0959s\n",
            "74\n",
            "Epoch: 0454 loss_train: 0.2764 acc_train: 0.9750 loss_val: 0.8458 acc_val: 0.7360 time: 0.1027s\n",
            "75\n",
            "Epoch: 0455 loss_train: 0.2655 acc_train: 0.9750 loss_val: 0.8431 acc_val: 0.7380 time: 0.0987s\n",
            "76\n",
            "Epoch: 0456 loss_train: 0.2693 acc_train: 0.9667 loss_val: 0.8433 acc_val: 0.7380 time: 0.0965s\n",
            "77\n",
            "Epoch: 0457 loss_train: 0.2687 acc_train: 0.9917 loss_val: 0.8422 acc_val: 0.7440 time: 0.1024s\n",
            "78\n",
            "Epoch: 0458 loss_train: 0.2769 acc_train: 0.9583 loss_val: 0.8417 acc_val: 0.7420 time: 0.0956s\n",
            "79\n",
            "Epoch: 0459 loss_train: 0.2696 acc_train: 0.9750 loss_val: 0.8401 acc_val: 0.7400 time: 0.0990s\n",
            "80\n",
            "Epoch: 0460 loss_train: 0.2704 acc_train: 0.9833 loss_val: 0.8431 acc_val: 0.7400 time: 0.0967s\n",
            "81\n",
            "Epoch: 0461 loss_train: 0.2717 acc_train: 0.9500 loss_val: 0.8478 acc_val: 0.7380 time: 0.0996s\n",
            "82\n",
            "Epoch: 0462 loss_train: 0.2793 acc_train: 0.9583 loss_val: 0.8513 acc_val: 0.7380 time: 0.1052s\n",
            "83\n",
            "Epoch: 0463 loss_train: 0.2825 acc_train: 0.9667 loss_val: 0.8504 acc_val: 0.7360 time: 0.1000s\n",
            "84\n",
            "Epoch: 0464 loss_train: 0.2829 acc_train: 0.9750 loss_val: 0.8455 acc_val: 0.7400 time: 0.0986s\n",
            "85\n",
            "Epoch: 0465 loss_train: 0.2682 acc_train: 0.9583 loss_val: 0.8403 acc_val: 0.7420 time: 0.1034s\n",
            "86\n",
            "Epoch: 0466 loss_train: 0.2689 acc_train: 0.9750 loss_val: 0.8388 acc_val: 0.7420 time: 0.1200s\n",
            "87\n",
            "Epoch: 0467 loss_train: 0.2743 acc_train: 0.9667 loss_val: 0.8403 acc_val: 0.7400 time: 0.1103s\n",
            "88\n",
            "Epoch: 0468 loss_train: 0.2810 acc_train: 0.9667 loss_val: 0.8418 acc_val: 0.7400 time: 0.1036s\n",
            "89\n",
            "Epoch: 0469 loss_train: 0.2848 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7420 time: 0.1003s\n",
            "90\n",
            "Epoch: 0470 loss_train: 0.2653 acc_train: 0.9667 loss_val: 0.8459 acc_val: 0.7380 time: 0.1112s\n",
            "91\n",
            "Epoch: 0471 loss_train: 0.2750 acc_train: 0.9500 loss_val: 0.8470 acc_val: 0.7380 time: 0.0994s\n",
            "92\n",
            "Epoch: 0472 loss_train: 0.2716 acc_train: 0.9750 loss_val: 0.8449 acc_val: 0.7360 time: 0.1106s\n",
            "93\n",
            "Epoch: 0473 loss_train: 0.2753 acc_train: 0.9500 loss_val: 0.8399 acc_val: 0.7380 time: 0.0988s\n",
            "94\n",
            "Epoch: 0474 loss_train: 0.2713 acc_train: 0.9667 loss_val: 0.8378 acc_val: 0.7420 time: 0.1088s\n",
            "95\n",
            "Epoch: 0475 loss_train: 0.2719 acc_train: 0.9833 loss_val: 0.8371 acc_val: 0.7420 time: 0.1034s\n",
            "96\n",
            "Epoch: 0476 loss_train: 0.2612 acc_train: 0.9750 loss_val: 0.8399 acc_val: 0.7420 time: 0.1037s\n",
            "97\n",
            "Epoch: 0477 loss_train: 0.2672 acc_train: 0.9750 loss_val: 0.8463 acc_val: 0.7420 time: 0.0974s\n",
            "98\n",
            "Epoch: 0478 loss_train: 0.2846 acc_train: 0.9750 loss_val: 0.8467 acc_val: 0.7400 time: 0.1089s\n",
            "99\n",
            "Epoch: 0479 loss_train: 0.2578 acc_train: 0.9750 loss_val: 0.8439 acc_val: 0.7360 time: 0.1025s\n",
            "100\n",
            "Epoch: 0480 loss_train: 0.2750 acc_train: 0.9667 loss_val: 0.8407 acc_val: 0.7380 time: 0.1119s\n",
            "101\n",
            "Epoch: 0481 loss_train: 0.2797 acc_train: 0.9667 loss_val: 0.8390 acc_val: 0.7380 time: 0.1006s\n",
            "102\n",
            "Epoch: 0482 loss_train: 0.2812 acc_train: 0.9833 loss_val: 0.8416 acc_val: 0.7400 time: 0.0999s\n",
            "103\n",
            "Epoch: 0483 loss_train: 0.2677 acc_train: 0.9750 loss_val: 0.8469 acc_val: 0.7400 time: 0.1054s\n",
            "104\n",
            "Epoch: 0484 loss_train: 0.2800 acc_train: 0.9833 loss_val: 0.8486 acc_val: 0.7400 time: 0.1019s\n",
            "105\n",
            "Epoch: 0485 loss_train: 0.2862 acc_train: 0.9667 loss_val: 0.8473 acc_val: 0.7420 time: 0.1091s\n",
            "106\n",
            "Epoch: 0486 loss_train: 0.2791 acc_train: 0.9583 loss_val: 0.8433 acc_val: 0.7420 time: 0.0980s\n",
            "107\n",
            "Epoch: 0487 loss_train: 0.2674 acc_train: 0.9583 loss_val: 0.8410 acc_val: 0.7380 time: 0.1036s\n",
            "108\n",
            "Epoch: 0488 loss_train: 0.2929 acc_train: 0.9750 loss_val: 0.8408 acc_val: 0.7420 time: 0.0997s\n",
            "109\n",
            "Epoch: 0489 loss_train: 0.2898 acc_train: 0.9667 loss_val: 0.8450 acc_val: 0.7380 time: 0.1032s\n",
            "110\n",
            "Epoch: 0490 loss_train: 0.2570 acc_train: 0.9833 loss_val: 0.8472 acc_val: 0.7380 time: 0.1058s\n",
            "111\n",
            "Epoch: 0491 loss_train: 0.2772 acc_train: 0.9750 loss_val: 0.8448 acc_val: 0.7380 time: 0.1008s\n",
            "112\n",
            "Epoch: 0492 loss_train: 0.2679 acc_train: 0.9667 loss_val: 0.8433 acc_val: 0.7380 time: 0.1019s\n",
            "113\n",
            "Epoch: 0493 loss_train: 0.2752 acc_train: 0.9750 loss_val: 0.8435 acc_val: 0.7380 time: 0.0960s\n",
            "114\n",
            "Epoch: 0494 loss_train: 0.2889 acc_train: 0.9750 loss_val: 0.8439 acc_val: 0.7380 time: 0.0966s\n",
            "115\n",
            "Epoch: 0495 loss_train: 0.2775 acc_train: 0.9667 loss_val: 0.8439 acc_val: 0.7380 time: 0.1026s\n",
            "116\n",
            "Epoch: 0496 loss_train: 0.2856 acc_train: 0.9583 loss_val: 0.8440 acc_val: 0.7380 time: 0.0983s\n",
            "117\n",
            "Epoch: 0497 loss_train: 0.2609 acc_train: 0.9917 loss_val: 0.8448 acc_val: 0.7380 time: 0.0970s\n",
            "118\n",
            "Epoch: 0498 loss_train: 0.2631 acc_train: 0.9750 loss_val: 0.8433 acc_val: 0.7360 time: 0.1066s\n",
            "119\n",
            "Epoch: 0499 loss_train: 0.2721 acc_train: 0.9833 loss_val: 0.8398 acc_val: 0.7400 time: 0.1037s\n",
            "120\n",
            "Epoch: 0500 loss_train: 0.2884 acc_train: 0.9750 loss_val: 0.8411 acc_val: 0.7400 time: 0.0980s\n",
            "121\n",
            "Epoch: 0501 loss_train: 0.2694 acc_train: 0.9833 loss_val: 0.8432 acc_val: 0.7380 time: 0.1036s\n",
            "122\n",
            "Epoch: 0502 loss_train: 0.2587 acc_train: 0.9667 loss_val: 0.8432 acc_val: 0.7380 time: 0.0992s\n",
            "123\n",
            "Epoch: 0503 loss_train: 0.2795 acc_train: 0.9833 loss_val: 0.8444 acc_val: 0.7360 time: 0.1007s\n",
            "124\n",
            "Epoch: 0504 loss_train: 0.2745 acc_train: 0.9833 loss_val: 0.8437 acc_val: 0.7360 time: 0.0954s\n",
            "125\n",
            "Epoch: 0505 loss_train: 0.2649 acc_train: 0.9917 loss_val: 0.8404 acc_val: 0.7380 time: 0.0997s\n",
            "126\n",
            "Epoch: 0506 loss_train: 0.2652 acc_train: 0.9750 loss_val: 0.8386 acc_val: 0.7400 time: 0.0985s\n",
            "127\n",
            "Epoch: 0507 loss_train: 0.2616 acc_train: 0.9750 loss_val: 0.8406 acc_val: 0.7400 time: 0.1000s\n",
            "128\n",
            "Epoch: 0508 loss_train: 0.2758 acc_train: 0.9583 loss_val: 0.8411 acc_val: 0.7400 time: 0.1023s\n",
            "129\n",
            "Epoch: 0509 loss_train: 0.2724 acc_train: 0.9667 loss_val: 0.8411 acc_val: 0.7380 time: 0.1007s\n",
            "130\n",
            "Epoch: 0510 loss_train: 0.2691 acc_train: 0.9833 loss_val: 0.8410 acc_val: 0.7380 time: 0.0991s\n",
            "131\n",
            "Epoch: 0511 loss_train: 0.2977 acc_train: 0.9333 loss_val: 0.8412 acc_val: 0.7380 time: 0.0969s\n",
            "132\n",
            "Epoch: 0512 loss_train: 0.2678 acc_train: 0.9833 loss_val: 0.8389 acc_val: 0.7400 time: 0.0965s\n",
            "133\n",
            "Epoch: 0513 loss_train: 0.2757 acc_train: 0.9583 loss_val: 0.8383 acc_val: 0.7420 time: 0.1050s\n",
            "134\n",
            "Epoch: 0514 loss_train: 0.2883 acc_train: 0.9750 loss_val: 0.8390 acc_val: 0.7420 time: 0.0986s\n",
            "135\n",
            "Epoch: 0515 loss_train: 0.2884 acc_train: 0.9583 loss_val: 0.8400 acc_val: 0.7400 time: 0.0955s\n",
            "136\n",
            "Epoch: 0516 loss_train: 0.2712 acc_train: 0.9667 loss_val: 0.8425 acc_val: 0.7420 time: 0.1043s\n",
            "137\n",
            "Epoch: 0517 loss_train: 0.2637 acc_train: 0.9500 loss_val: 0.8477 acc_val: 0.7400 time: 0.0988s\n",
            "138\n",
            "Epoch: 0518 loss_train: 0.2855 acc_train: 0.9500 loss_val: 0.8503 acc_val: 0.7380 time: 0.1036s\n",
            "139\n",
            "Epoch: 0519 loss_train: 0.2849 acc_train: 0.9667 loss_val: 0.8434 acc_val: 0.7380 time: 0.0997s\n",
            "140\n",
            "Epoch: 0520 loss_train: 0.2639 acc_train: 0.9750 loss_val: 0.8360 acc_val: 0.7420 time: 0.1015s\n",
            "141\n",
            "Epoch: 0521 loss_train: 0.2633 acc_train: 0.9667 loss_val: 0.8322 acc_val: 0.7420 time: 0.0990s\n",
            "142\n",
            "Epoch: 0522 loss_train: 0.2683 acc_train: 0.9667 loss_val: 0.8333 acc_val: 0.7440 time: 0.0999s\n",
            "143\n",
            "Epoch: 0523 loss_train: 0.2763 acc_train: 0.9750 loss_val: 0.8416 acc_val: 0.7460 time: 0.0969s\n",
            "144\n",
            "Epoch: 0524 loss_train: 0.2809 acc_train: 0.9667 loss_val: 0.8483 acc_val: 0.7400 time: 0.0956s\n",
            "145\n",
            "Epoch: 0525 loss_train: 0.2704 acc_train: 0.9667 loss_val: 0.8495 acc_val: 0.7400 time: 0.1049s\n",
            "146\n",
            "Epoch: 0526 loss_train: 0.2646 acc_train: 0.9667 loss_val: 0.8469 acc_val: 0.7400 time: 0.0982s\n",
            "147\n",
            "Epoch: 0527 loss_train: 0.2738 acc_train: 0.9750 loss_val: 0.8399 acc_val: 0.7420 time: 0.0995s\n",
            "148\n",
            "Epoch: 0528 loss_train: 0.2643 acc_train: 0.9833 loss_val: 0.8344 acc_val: 0.7420 time: 0.1057s\n",
            "149\n",
            "Epoch: 0529 loss_train: 0.2778 acc_train: 0.9667 loss_val: 0.8311 acc_val: 0.7440 time: 0.1015s\n",
            "150\n",
            "Epoch: 0530 loss_train: 0.2849 acc_train: 0.9500 loss_val: 0.8342 acc_val: 0.7420 time: 0.1009s\n",
            "151\n",
            "Epoch: 0531 loss_train: 0.2824 acc_train: 0.9667 loss_val: 0.8405 acc_val: 0.7420 time: 0.0956s\n",
            "152\n",
            "Epoch: 0532 loss_train: 0.2812 acc_train: 0.9667 loss_val: 0.8503 acc_val: 0.7400 time: 0.0971s\n",
            "153\n",
            "Epoch: 0533 loss_train: 0.2804 acc_train: 0.9583 loss_val: 0.8532 acc_val: 0.7380 time: 0.0960s\n",
            "154\n",
            "Epoch: 0534 loss_train: 0.2748 acc_train: 0.9583 loss_val: 0.8473 acc_val: 0.7380 time: 0.0955s\n",
            "155\n",
            "Epoch: 0535 loss_train: 0.2620 acc_train: 0.9667 loss_val: 0.8405 acc_val: 0.7420 time: 0.1009s\n",
            "156\n",
            "Epoch: 0536 loss_train: 0.2732 acc_train: 0.9750 loss_val: 0.8379 acc_val: 0.7420 time: 0.0967s\n",
            "157\n",
            "Epoch: 0537 loss_train: 0.2738 acc_train: 0.9583 loss_val: 0.8377 acc_val: 0.7420 time: 0.0975s\n",
            "158\n",
            "Epoch: 0538 loss_train: 0.2870 acc_train: 0.9667 loss_val: 0.8389 acc_val: 0.7420 time: 0.1018s\n",
            "159\n",
            "Epoch: 0539 loss_train: 0.2778 acc_train: 0.9750 loss_val: 0.8455 acc_val: 0.7400 time: 0.1033s\n",
            "160\n",
            "Epoch: 0540 loss_train: 0.2914 acc_train: 0.9583 loss_val: 0.8527 acc_val: 0.7380 time: 0.1004s\n",
            "161\n",
            "Epoch: 0541 loss_train: 0.2969 acc_train: 0.9583 loss_val: 0.8535 acc_val: 0.7360 time: 0.0954s\n",
            "162\n",
            "Epoch: 0542 loss_train: 0.2884 acc_train: 0.9583 loss_val: 0.8484 acc_val: 0.7340 time: 0.0952s\n",
            "163\n",
            "Epoch: 0543 loss_train: 0.2938 acc_train: 0.9417 loss_val: 0.8417 acc_val: 0.7380 time: 0.1034s\n",
            "164\n",
            "Epoch: 0544 loss_train: 0.2777 acc_train: 0.9667 loss_val: 0.8371 acc_val: 0.7400 time: 0.0999s\n",
            "165\n",
            "Epoch: 0545 loss_train: 0.2768 acc_train: 0.9833 loss_val: 0.8359 acc_val: 0.7400 time: 0.1015s\n",
            "166\n",
            "Epoch: 0546 loss_train: 0.2697 acc_train: 0.9833 loss_val: 0.8385 acc_val: 0.7380 time: 0.1058s\n",
            "167\n",
            "Epoch: 0547 loss_train: 0.2745 acc_train: 0.9833 loss_val: 0.8442 acc_val: 0.7380 time: 0.1004s\n",
            "168\n",
            "Epoch: 0548 loss_train: 0.2616 acc_train: 0.9917 loss_val: 0.8488 acc_val: 0.7340 time: 0.1051s\n",
            "169\n",
            "Epoch: 0549 loss_train: 0.2843 acc_train: 0.9833 loss_val: 0.8514 acc_val: 0.7340 time: 0.0991s\n",
            "170\n",
            "Epoch: 0550 loss_train: 0.2684 acc_train: 0.9417 loss_val: 0.8468 acc_val: 0.7380 time: 0.1016s\n",
            "171\n",
            "Epoch: 0551 loss_train: 0.2659 acc_train: 0.9750 loss_val: 0.8424 acc_val: 0.7420 time: 0.0956s\n",
            "172\n",
            "Epoch: 0552 loss_train: 0.2786 acc_train: 0.9750 loss_val: 0.8410 acc_val: 0.7420 time: 0.0963s\n",
            "173\n",
            "Epoch: 0553 loss_train: 0.2661 acc_train: 0.9667 loss_val: 0.8408 acc_val: 0.7400 time: 0.1009s\n",
            "174\n",
            "Epoch: 0554 loss_train: 0.2977 acc_train: 0.9333 loss_val: 0.8414 acc_val: 0.7400 time: 0.0955s\n",
            "175\n",
            "Epoch: 0555 loss_train: 0.2838 acc_train: 0.9750 loss_val: 0.8408 acc_val: 0.7400 time: 0.0951s\n",
            "176\n",
            "Epoch: 0556 loss_train: 0.2806 acc_train: 0.9833 loss_val: 0.8427 acc_val: 0.7400 time: 0.1011s\n",
            "177\n",
            "Epoch: 0557 loss_train: 0.2830 acc_train: 0.9750 loss_val: 0.8444 acc_val: 0.7400 time: 0.1103s\n",
            "178\n",
            "Epoch: 0558 loss_train: 0.2651 acc_train: 0.9583 loss_val: 0.8471 acc_val: 0.7360 time: 0.0992s\n",
            "179\n",
            "Epoch: 0559 loss_train: 0.2771 acc_train: 0.9750 loss_val: 0.8467 acc_val: 0.7400 time: 0.1063s\n",
            "180\n",
            "Epoch: 0560 loss_train: 0.2749 acc_train: 0.9833 loss_val: 0.8454 acc_val: 0.7380 time: 0.0997s\n",
            "181\n",
            "Epoch: 0561 loss_train: 0.2880 acc_train: 0.9583 loss_val: 0.8439 acc_val: 0.7380 time: 0.1030s\n",
            "182\n",
            "Epoch: 0562 loss_train: 0.2772 acc_train: 0.9583 loss_val: 0.8450 acc_val: 0.7400 time: 0.0969s\n",
            "183\n",
            "Epoch: 0563 loss_train: 0.2799 acc_train: 0.9500 loss_val: 0.8431 acc_val: 0.7420 time: 0.1005s\n",
            "184\n",
            "Epoch: 0564 loss_train: 0.2891 acc_train: 0.9667 loss_val: 0.8386 acc_val: 0.7380 time: 0.1004s\n",
            "185\n",
            "Epoch: 0565 loss_train: 0.2694 acc_train: 0.9583 loss_val: 0.8369 acc_val: 0.7380 time: 0.0989s\n",
            "186\n",
            "Epoch: 0566 loss_train: 0.2704 acc_train: 0.9500 loss_val: 0.8390 acc_val: 0.7400 time: 0.1096s\n",
            "187\n",
            "Epoch: 0567 loss_train: 0.2916 acc_train: 0.9583 loss_val: 0.8440 acc_val: 0.7400 time: 0.0965s\n",
            "188\n",
            "Epoch: 0568 loss_train: 0.2722 acc_train: 0.9917 loss_val: 0.8469 acc_val: 0.7380 time: 0.1038s\n",
            "189\n",
            "Epoch: 0569 loss_train: 0.2756 acc_train: 0.9750 loss_val: 0.8422 acc_val: 0.7380 time: 0.1105s\n",
            "190\n",
            "Epoch: 0570 loss_train: 0.2682 acc_train: 0.9667 loss_val: 0.8398 acc_val: 0.7380 time: 0.0962s\n",
            "191\n",
            "Epoch: 0571 loss_train: 0.2782 acc_train: 0.9667 loss_val: 0.8416 acc_val: 0.7380 time: 0.0953s\n",
            "192\n",
            "Epoch: 0572 loss_train: 0.2739 acc_train: 0.9833 loss_val: 0.8425 acc_val: 0.7380 time: 0.0959s\n",
            "193\n",
            "Epoch: 0573 loss_train: 0.2692 acc_train: 0.9583 loss_val: 0.8448 acc_val: 0.7360 time: 0.1010s\n",
            "194\n",
            "Epoch: 0574 loss_train: 0.2550 acc_train: 0.9750 loss_val: 0.8464 acc_val: 0.7400 time: 0.0955s\n",
            "195\n",
            "Epoch: 0575 loss_train: 0.2642 acc_train: 0.9500 loss_val: 0.8449 acc_val: 0.7460 time: 0.0953s\n",
            "196\n",
            "Epoch: 0576 loss_train: 0.2793 acc_train: 0.9417 loss_val: 0.8395 acc_val: 0.7460 time: 0.1034s\n",
            "197\n",
            "Epoch: 0577 loss_train: 0.2854 acc_train: 0.9583 loss_val: 0.8380 acc_val: 0.7440 time: 0.0987s\n",
            "198\n",
            "Epoch: 0578 loss_train: 0.2748 acc_train: 0.9583 loss_val: 0.8372 acc_val: 0.7400 time: 0.0986s\n",
            "199\n",
            "Early stop! Min loss:  0.8259364366531372 , Max accuracy:  0.748\n",
            "Early stop model validation loss:  0.8259364366531372 , accuracy:  0.746\n",
            "Optimization Finished!\n",
            "Total time elapsed: 59.0944s\n",
            "Loading 128th epoch\n",
            "Test set results: loss= 0.8143 accuracy= 0.7300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vx0BnV3iU0uG",
        "outputId": "cc7bb4f3-10b3-4c1f-d0d8-ef1f1940f146"
      },
      "source": [
        "x = [i/10 for i in range(1,11,2)]\n",
        "plt.plot(x, accs_dropout, \"bv\",linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropout\", markersize=5)\n",
        "plt.plot(x, accs_dropedge, \"ro\", linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropedge\", markersize=5)\n",
        "plt.grid()\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Consistency Regularization Coefficient(lambda)\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.ylim(0.80, 0.87)\n",
        "plt.title(f\"GRAND on {args['dataset'].upper()} dataset\")\n",
        "plt.savefig(\"Acc v CR lambda.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "wt12-gldaVG9",
        "outputId": "3faef0be-5488-449a-d17a-1298c71ad111"
      },
      "source": [
        "x = [i/10 for i in range(1,11,2)]\n",
        "plt.plot(x, accs_dropout, \"bv\",linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropout\", markersize=5)\n",
        "plt.plot(x, accs_dropedge, \"ro\", linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropedge\", markersize=5)\n",
        "plt.grid()\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Consistency Regularization Coefficient(lambda)\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.ylim(0.70, 0.85)\n",
        "plt.title(f\"GRAND on {args['dataset'].upper()} dataset\")\n",
        "plt.savefig(\"Acc v CR lambda_pubmed.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "4IVho13Kd_Xh",
        "outputId": "41414bf0-afbd-4038-d206-bec2c65f12b4"
      },
      "source": [
        "x = [i/10 for i in range(1,11,2)]\n",
        "plt.plot(x, accs_dropout, \"bv\",linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropout\", markersize=5)\n",
        "plt.plot(x, accs_dropedge, \"ro\", linestyle=\"solid\", linewidth=0.5, label=\"GRAND_dropedge\", markersize=5)\n",
        "plt.grid()\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Consistency Regularization Coefficient(lambda)\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.ylim(0.65, 0.75)\n",
        "plt.title(f\"GRAND on {args['dataset'].upper()} dataset\")\n",
        "plt.savefig(\"Acc v CR lambda_citeseer.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYy2mcLLjbk8",
        "outputId": "0243f0ce-2229-4973-e565-bb4b998788be"
      },
      "source": [
        "accs_dropedge = []\n",
        "for sample in range(1,5):\n",
        "  acc_sample = []\n",
        "  for order in range(1,11):\n",
        "    Train(sample=sample, order=order) #dropedge \n",
        "    acc_sample.append(test(order=order))\n",
        "  accs_dropedge.append(acc_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 0720 loss_train: 0.7354 acc_train: 0.8357 loss_val: 0.6835 acc_val: 0.8300 time: 0.0152s\n",
            "173\n",
            "Epoch: 0721 loss_train: 0.6995 acc_train: 0.8429 loss_val: 0.6780 acc_val: 0.8300 time: 0.0140s\n",
            "174\n",
            "Epoch: 0722 loss_train: 0.7339 acc_train: 0.8714 loss_val: 0.6734 acc_val: 0.8280 time: 0.0139s\n",
            "175\n",
            "Epoch: 0723 loss_train: 0.7493 acc_train: 0.8000 loss_val: 0.6714 acc_val: 0.8280 time: 0.0140s\n",
            "176\n",
            "Epoch: 0724 loss_train: 0.7537 acc_train: 0.8429 loss_val: 0.6711 acc_val: 0.8280 time: 0.0139s\n",
            "177\n",
            "Epoch: 0725 loss_train: 0.7571 acc_train: 0.8357 loss_val: 0.6733 acc_val: 0.8300 time: 0.0141s\n",
            "178\n",
            "Epoch: 0726 loss_train: 0.7531 acc_train: 0.8786 loss_val: 0.6766 acc_val: 0.8300 time: 0.0145s\n",
            "179\n",
            "Epoch: 0727 loss_train: 0.7488 acc_train: 0.8786 loss_val: 0.6814 acc_val: 0.8260 time: 0.0136s\n",
            "180\n",
            "Epoch: 0728 loss_train: 0.7738 acc_train: 0.8214 loss_val: 0.6867 acc_val: 0.8240 time: 0.0135s\n",
            "181\n",
            "Epoch: 0729 loss_train: 0.7207 acc_train: 0.8143 loss_val: 0.6891 acc_val: 0.8240 time: 0.0135s\n",
            "182\n",
            "Epoch: 0730 loss_train: 0.8124 acc_train: 0.8286 loss_val: 0.6868 acc_val: 0.8220 time: 0.0174s\n",
            "183\n",
            "Epoch: 0731 loss_train: 0.7650 acc_train: 0.8571 loss_val: 0.6807 acc_val: 0.8300 time: 0.0134s\n",
            "184\n",
            "Epoch: 0732 loss_train: 0.7321 acc_train: 0.8571 loss_val: 0.6747 acc_val: 0.8320 time: 0.0135s\n",
            "185\n",
            "Epoch: 0733 loss_train: 0.7569 acc_train: 0.8286 loss_val: 0.6719 acc_val: 0.8320 time: 0.0136s\n",
            "186\n",
            "Epoch: 0734 loss_train: 0.7285 acc_train: 0.8714 loss_val: 0.6703 acc_val: 0.8320 time: 0.0153s\n",
            "187\n",
            "Epoch: 0735 loss_train: 0.7328 acc_train: 0.8357 loss_val: 0.6689 acc_val: 0.8320 time: 0.0134s\n",
            "188\n",
            "Epoch: 0736 loss_train: 0.7755 acc_train: 0.8000 loss_val: 0.6674 acc_val: 0.8320 time: 0.0135s\n",
            "189\n",
            "Epoch: 0737 loss_train: 0.7501 acc_train: 0.8500 loss_val: 0.6681 acc_val: 0.8300 time: 0.0134s\n",
            "190\n",
            "Epoch: 0738 loss_train: 0.7949 acc_train: 0.8286 loss_val: 0.6721 acc_val: 0.8320 time: 0.0133s\n",
            "191\n",
            "Epoch: 0739 loss_train: 0.7354 acc_train: 0.7929 loss_val: 0.6782 acc_val: 0.8360 time: 0.0135s\n",
            "192\n",
            "Epoch: 0740 loss_train: 0.7766 acc_train: 0.8071 loss_val: 0.6890 acc_val: 0.8180 time: 0.0136s\n",
            "193\n",
            "Epoch: 0741 loss_train: 0.7729 acc_train: 0.8857 loss_val: 0.6945 acc_val: 0.8160 time: 0.0135s\n",
            "194\n",
            "Epoch: 0742 loss_train: 0.7731 acc_train: 0.8071 loss_val: 0.6935 acc_val: 0.8180 time: 0.0150s\n",
            "195\n",
            "Epoch: 0743 loss_train: 0.7451 acc_train: 0.8286 loss_val: 0.6878 acc_val: 0.8260 time: 0.0161s\n",
            "196\n",
            "Epoch: 0744 loss_train: 0.7535 acc_train: 0.8500 loss_val: 0.6823 acc_val: 0.8280 time: 0.0154s\n",
            "197\n",
            "Epoch: 0745 loss_train: 0.7936 acc_train: 0.8071 loss_val: 0.6769 acc_val: 0.8280 time: 0.0134s\n",
            "198\n",
            "Epoch: 0746 loss_train: 0.7497 acc_train: 0.8286 loss_val: 0.6725 acc_val: 0.8280 time: 0.0135s\n",
            "199\n",
            "Early stop! Min loss:  0.6579190492630005 , Max accuracy:  0.838\n",
            "Early stop model validation loss:  0.6579190492630005 , accuracy:  0.8260000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 12.4100s\n",
            "Loading 545th epoch\n",
            "Test set results: loss= 0.6185 accuracy= 0.8470\n",
            "Epoch: 0001 loss_train: 0.8130 acc_train: 0.7929 loss_val: 0.6588 acc_val: 0.8260 time: 0.0203s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.7453 acc_train: 0.8143 loss_val: 0.6627 acc_val: 0.8320 time: 0.0168s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8134 acc_train: 0.7857 loss_val: 0.6688 acc_val: 0.8280 time: 0.0172s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.7797 acc_train: 0.8643 loss_val: 0.6770 acc_val: 0.8260 time: 0.0172s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.7347 acc_train: 0.7929 loss_val: 0.6853 acc_val: 0.8200 time: 0.0171s\n",
            "2\n",
            "Epoch: 0006 loss_train: 0.7817 acc_train: 0.8500 loss_val: 0.6914 acc_val: 0.8140 time: 0.0165s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.7766 acc_train: 0.7929 loss_val: 0.6963 acc_val: 0.8160 time: 0.0166s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.7760 acc_train: 0.8357 loss_val: 0.6989 acc_val: 0.8120 time: 0.0199s\n",
            "5\n",
            "Epoch: 0009 loss_train: 0.8073 acc_train: 0.8786 loss_val: 0.6955 acc_val: 0.8140 time: 0.0174s\n",
            "6\n",
            "Epoch: 0010 loss_train: 0.7582 acc_train: 0.8286 loss_val: 0.6905 acc_val: 0.8120 time: 0.0170s\n",
            "7\n",
            "Epoch: 0011 loss_train: 0.7337 acc_train: 0.8929 loss_val: 0.6830 acc_val: 0.8220 time: 0.0167s\n",
            "8\n",
            "Epoch: 0012 loss_train: 0.7645 acc_train: 0.8571 loss_val: 0.6757 acc_val: 0.8160 time: 0.0166s\n",
            "9\n",
            "Epoch: 0013 loss_train: 0.7855 acc_train: 0.8143 loss_val: 0.6713 acc_val: 0.8200 time: 0.0166s\n",
            "10\n",
            "Epoch: 0014 loss_train: 0.7820 acc_train: 0.8643 loss_val: 0.6694 acc_val: 0.8260 time: 0.0213s\n",
            "11\n",
            "Epoch: 0015 loss_train: 0.7655 acc_train: 0.8357 loss_val: 0.6692 acc_val: 0.8260 time: 0.0201s\n",
            "12\n",
            "Epoch: 0016 loss_train: 0.7970 acc_train: 0.7643 loss_val: 0.6719 acc_val: 0.8180 time: 0.0173s\n",
            "13\n",
            "Epoch: 0017 loss_train: 0.7453 acc_train: 0.8357 loss_val: 0.6775 acc_val: 0.8160 time: 0.0162s\n",
            "14\n",
            "Epoch: 0018 loss_train: 0.7326 acc_train: 0.8286 loss_val: 0.6834 acc_val: 0.8200 time: 0.0165s\n",
            "15\n",
            "Epoch: 0019 loss_train: 0.7549 acc_train: 0.8571 loss_val: 0.6881 acc_val: 0.8180 time: 0.0203s\n",
            "16\n",
            "Epoch: 0020 loss_train: 0.7702 acc_train: 0.8000 loss_val: 0.6918 acc_val: 0.8160 time: 0.0193s\n",
            "17\n",
            "Epoch: 0021 loss_train: 0.7747 acc_train: 0.8643 loss_val: 0.6936 acc_val: 0.8140 time: 0.0172s\n",
            "18\n",
            "Epoch: 0022 loss_train: 0.7707 acc_train: 0.8643 loss_val: 0.6939 acc_val: 0.8140 time: 0.0175s\n",
            "19\n",
            "Epoch: 0023 loss_train: 0.8037 acc_train: 0.8357 loss_val: 0.6915 acc_val: 0.8120 time: 0.0171s\n",
            "20\n",
            "Epoch: 0024 loss_train: 0.8058 acc_train: 0.8214 loss_val: 0.6875 acc_val: 0.8200 time: 0.0188s\n",
            "21\n",
            "Epoch: 0025 loss_train: 0.7883 acc_train: 0.8571 loss_val: 0.6826 acc_val: 0.8240 time: 0.0170s\n",
            "22\n",
            "Epoch: 0026 loss_train: 0.7758 acc_train: 0.8143 loss_val: 0.6794 acc_val: 0.8280 time: 0.0171s\n",
            "23\n",
            "Epoch: 0027 loss_train: 0.8010 acc_train: 0.7714 loss_val: 0.6781 acc_val: 0.8320 time: 0.0170s\n",
            "24\n",
            "Epoch: 0028 loss_train: 0.7531 acc_train: 0.8214 loss_val: 0.6775 acc_val: 0.8280 time: 0.0172s\n",
            "0\n",
            "Epoch: 0029 loss_train: 0.7848 acc_train: 0.8000 loss_val: 0.6798 acc_val: 0.8180 time: 0.0167s\n",
            "1\n",
            "Epoch: 0030 loss_train: 0.7810 acc_train: 0.8286 loss_val: 0.6835 acc_val: 0.8220 time: 0.0219s\n",
            "2\n",
            "Epoch: 0031 loss_train: 0.7956 acc_train: 0.8143 loss_val: 0.6886 acc_val: 0.8220 time: 0.0167s\n",
            "3\n",
            "Epoch: 0032 loss_train: 0.8223 acc_train: 0.7929 loss_val: 0.6930 acc_val: 0.8200 time: 0.0172s\n",
            "4\n",
            "Epoch: 0033 loss_train: 0.7789 acc_train: 0.8071 loss_val: 0.6953 acc_val: 0.8180 time: 0.0181s\n",
            "5\n",
            "Epoch: 0034 loss_train: 0.7719 acc_train: 0.8357 loss_val: 0.6934 acc_val: 0.8160 time: 0.0172s\n",
            "6\n",
            "Epoch: 0035 loss_train: 0.8051 acc_train: 0.8429 loss_val: 0.6903 acc_val: 0.8220 time: 0.0187s\n",
            "7\n",
            "Epoch: 0036 loss_train: 0.7989 acc_train: 0.8429 loss_val: 0.6864 acc_val: 0.8220 time: 0.0180s\n",
            "8\n",
            "Epoch: 0037 loss_train: 0.7876 acc_train: 0.8357 loss_val: 0.6822 acc_val: 0.8260 time: 0.0192s\n",
            "9\n",
            "Epoch: 0038 loss_train: 0.7331 acc_train: 0.9000 loss_val: 0.6790 acc_val: 0.8240 time: 0.0176s\n",
            "10\n",
            "Epoch: 0039 loss_train: 0.7453 acc_train: 0.7929 loss_val: 0.6766 acc_val: 0.8260 time: 0.0185s\n",
            "11\n",
            "Epoch: 0040 loss_train: 0.8550 acc_train: 0.8071 loss_val: 0.6752 acc_val: 0.8240 time: 0.0185s\n",
            "12\n",
            "Epoch: 0041 loss_train: 0.7856 acc_train: 0.8357 loss_val: 0.6754 acc_val: 0.8240 time: 0.0208s\n",
            "13\n",
            "Epoch: 0042 loss_train: 0.7865 acc_train: 0.8500 loss_val: 0.6777 acc_val: 0.8220 time: 0.0172s\n",
            "14\n",
            "Epoch: 0043 loss_train: 0.7963 acc_train: 0.7786 loss_val: 0.6820 acc_val: 0.8180 time: 0.0171s\n",
            "15\n",
            "Epoch: 0044 loss_train: 0.7696 acc_train: 0.8071 loss_val: 0.6840 acc_val: 0.8200 time: 0.0167s\n",
            "16\n",
            "Epoch: 0045 loss_train: 0.7566 acc_train: 0.7643 loss_val: 0.6846 acc_val: 0.8200 time: 0.0178s\n",
            "17\n",
            "Epoch: 0046 loss_train: 0.7757 acc_train: 0.8286 loss_val: 0.6858 acc_val: 0.8200 time: 0.0161s\n",
            "18\n",
            "Epoch: 0047 loss_train: 0.7389 acc_train: 0.7929 loss_val: 0.6848 acc_val: 0.8180 time: 0.0206s\n",
            "19\n",
            "Epoch: 0048 loss_train: 0.7842 acc_train: 0.8357 loss_val: 0.6837 acc_val: 0.8220 time: 0.0175s\n",
            "20\n",
            "Epoch: 0049 loss_train: 0.7869 acc_train: 0.7857 loss_val: 0.6809 acc_val: 0.8220 time: 0.0172s\n",
            "21\n",
            "Epoch: 0050 loss_train: 0.8276 acc_train: 0.7786 loss_val: 0.6799 acc_val: 0.8240 time: 0.0171s\n",
            "22\n",
            "Epoch: 0051 loss_train: 0.7487 acc_train: 0.8571 loss_val: 0.6788 acc_val: 0.8260 time: 0.0181s\n",
            "23\n",
            "Epoch: 0052 loss_train: 0.7975 acc_train: 0.8286 loss_val: 0.6783 acc_val: 0.8240 time: 0.0180s\n",
            "24\n",
            "Epoch: 0053 loss_train: 0.8060 acc_train: 0.8143 loss_val: 0.6787 acc_val: 0.8200 time: 0.0176s\n",
            "25\n",
            "Epoch: 0054 loss_train: 0.8154 acc_train: 0.8786 loss_val: 0.6797 acc_val: 0.8180 time: 0.0170s\n",
            "26\n",
            "Epoch: 0055 loss_train: 0.7657 acc_train: 0.8500 loss_val: 0.6786 acc_val: 0.8220 time: 0.0165s\n",
            "27\n",
            "Epoch: 0056 loss_train: 0.8192 acc_train: 0.8357 loss_val: 0.6777 acc_val: 0.8180 time: 0.0165s\n",
            "28\n",
            "Epoch: 0057 loss_train: 0.8225 acc_train: 0.8000 loss_val: 0.6793 acc_val: 0.8220 time: 0.0165s\n",
            "29\n",
            "Epoch: 0058 loss_train: 0.7898 acc_train: 0.8286 loss_val: 0.6822 acc_val: 0.8220 time: 0.0164s\n",
            "30\n",
            "Epoch: 0059 loss_train: 0.7524 acc_train: 0.8357 loss_val: 0.6845 acc_val: 0.8200 time: 0.0172s\n",
            "31\n",
            "Epoch: 0060 loss_train: 0.7692 acc_train: 0.8357 loss_val: 0.6839 acc_val: 0.8140 time: 0.0166s\n",
            "32\n",
            "Epoch: 0061 loss_train: 0.7635 acc_train: 0.8286 loss_val: 0.6820 acc_val: 0.8160 time: 0.0167s\n",
            "33\n",
            "Epoch: 0062 loss_train: 0.7739 acc_train: 0.8571 loss_val: 0.6794 acc_val: 0.8220 time: 0.0240s\n",
            "34\n",
            "Epoch: 0063 loss_train: 0.8038 acc_train: 0.8286 loss_val: 0.6778 acc_val: 0.8200 time: 0.0173s\n",
            "35\n",
            "Epoch: 0064 loss_train: 0.7394 acc_train: 0.8357 loss_val: 0.6779 acc_val: 0.8200 time: 0.0166s\n",
            "36\n",
            "Epoch: 0065 loss_train: 0.7899 acc_train: 0.8143 loss_val: 0.6783 acc_val: 0.8180 time: 0.0167s\n",
            "37\n",
            "Epoch: 0066 loss_train: 0.7661 acc_train: 0.8286 loss_val: 0.6779 acc_val: 0.8240 time: 0.0169s\n",
            "38\n",
            "Epoch: 0067 loss_train: 0.7741 acc_train: 0.8357 loss_val: 0.6768 acc_val: 0.8220 time: 0.0195s\n",
            "39\n",
            "Epoch: 0068 loss_train: 0.8220 acc_train: 0.8143 loss_val: 0.6762 acc_val: 0.8220 time: 0.0170s\n",
            "40\n",
            "Epoch: 0069 loss_train: 0.7773 acc_train: 0.8143 loss_val: 0.6769 acc_val: 0.8200 time: 0.0166s\n",
            "41\n",
            "Epoch: 0070 loss_train: 0.7465 acc_train: 0.8786 loss_val: 0.6770 acc_val: 0.8200 time: 0.0167s\n",
            "42\n",
            "Epoch: 0071 loss_train: 0.8030 acc_train: 0.8429 loss_val: 0.6804 acc_val: 0.8220 time: 0.0166s\n",
            "43\n",
            "Epoch: 0072 loss_train: 0.7718 acc_train: 0.8071 loss_val: 0.6811 acc_val: 0.8160 time: 0.0165s\n",
            "44\n",
            "Epoch: 0073 loss_train: 0.7740 acc_train: 0.8286 loss_val: 0.6818 acc_val: 0.8160 time: 0.0207s\n",
            "45\n",
            "Epoch: 0074 loss_train: 0.8130 acc_train: 0.8143 loss_val: 0.6821 acc_val: 0.8220 time: 0.0193s\n",
            "46\n",
            "Epoch: 0075 loss_train: 0.8228 acc_train: 0.8357 loss_val: 0.6819 acc_val: 0.8160 time: 0.0173s\n",
            "47\n",
            "Epoch: 0076 loss_train: 0.8995 acc_train: 0.7857 loss_val: 0.6823 acc_val: 0.8160 time: 0.0171s\n",
            "48\n",
            "Epoch: 0077 loss_train: 0.8097 acc_train: 0.8500 loss_val: 0.6824 acc_val: 0.8120 time: 0.0181s\n",
            "49\n",
            "Epoch: 0078 loss_train: 0.7783 acc_train: 0.8500 loss_val: 0.6827 acc_val: 0.8140 time: 0.0172s\n",
            "50\n",
            "Epoch: 0079 loss_train: 0.7437 acc_train: 0.8500 loss_val: 0.6830 acc_val: 0.8140 time: 0.0171s\n",
            "51\n",
            "Epoch: 0080 loss_train: 0.7882 acc_train: 0.8500 loss_val: 0.6837 acc_val: 0.8200 time: 0.0171s\n",
            "52\n",
            "Epoch: 0081 loss_train: 0.8124 acc_train: 0.8286 loss_val: 0.6855 acc_val: 0.8180 time: 0.0171s\n",
            "53\n",
            "Epoch: 0082 loss_train: 0.7884 acc_train: 0.7714 loss_val: 0.6889 acc_val: 0.8180 time: 0.0179s\n",
            "54\n",
            "Epoch: 0083 loss_train: 0.7758 acc_train: 0.8429 loss_val: 0.6891 acc_val: 0.8180 time: 0.0174s\n",
            "55\n",
            "Epoch: 0084 loss_train: 0.7843 acc_train: 0.8214 loss_val: 0.6881 acc_val: 0.8180 time: 0.0212s\n",
            "56\n",
            "Epoch: 0085 loss_train: 0.8141 acc_train: 0.8143 loss_val: 0.6844 acc_val: 0.8220 time: 0.0171s\n",
            "57\n",
            "Epoch: 0086 loss_train: 0.7906 acc_train: 0.8429 loss_val: 0.6788 acc_val: 0.8200 time: 0.0166s\n",
            "58\n",
            "Epoch: 0087 loss_train: 0.7478 acc_train: 0.8286 loss_val: 0.6747 acc_val: 0.8220 time: 0.0165s\n",
            "59\n",
            "Epoch: 0088 loss_train: 0.7534 acc_train: 0.8571 loss_val: 0.6743 acc_val: 0.8300 time: 0.0166s\n",
            "60\n",
            "Epoch: 0089 loss_train: 0.7988 acc_train: 0.8143 loss_val: 0.6761 acc_val: 0.8220 time: 0.0173s\n",
            "61\n",
            "Epoch: 0090 loss_train: 0.8041 acc_train: 0.8143 loss_val: 0.6795 acc_val: 0.8220 time: 0.0168s\n",
            "62\n",
            "Epoch: 0091 loss_train: 0.7988 acc_train: 0.8714 loss_val: 0.6833 acc_val: 0.8260 time: 0.0172s\n",
            "63\n",
            "Epoch: 0092 loss_train: 0.7721 acc_train: 0.7786 loss_val: 0.6867 acc_val: 0.8220 time: 0.0166s\n",
            "64\n",
            "Epoch: 0093 loss_train: 0.7828 acc_train: 0.8571 loss_val: 0.6872 acc_val: 0.8200 time: 0.0166s\n",
            "65\n",
            "Epoch: 0094 loss_train: 0.7975 acc_train: 0.8714 loss_val: 0.6872 acc_val: 0.8200 time: 0.0165s\n",
            "66\n",
            "Epoch: 0095 loss_train: 0.7562 acc_train: 0.8357 loss_val: 0.6869 acc_val: 0.8220 time: 0.0219s\n",
            "67\n",
            "Epoch: 0096 loss_train: 0.7925 acc_train: 0.8429 loss_val: 0.6865 acc_val: 0.8220 time: 0.0172s\n",
            "68\n",
            "Epoch: 0097 loss_train: 0.8227 acc_train: 0.7857 loss_val: 0.6856 acc_val: 0.8200 time: 0.0166s\n",
            "69\n",
            "Epoch: 0098 loss_train: 0.7756 acc_train: 0.8071 loss_val: 0.6858 acc_val: 0.8240 time: 0.0189s\n",
            "70\n",
            "Epoch: 0099 loss_train: 0.8103 acc_train: 0.8143 loss_val: 0.6856 acc_val: 0.8220 time: 0.0173s\n",
            "71\n",
            "Epoch: 0100 loss_train: 0.8046 acc_train: 0.8071 loss_val: 0.6891 acc_val: 0.8220 time: 0.0167s\n",
            "72\n",
            "Epoch: 0101 loss_train: 0.7327 acc_train: 0.8643 loss_val: 0.6917 acc_val: 0.8160 time: 0.0165s\n",
            "73\n",
            "Epoch: 0102 loss_train: 0.7517 acc_train: 0.8286 loss_val: 0.6927 acc_val: 0.8100 time: 0.0166s\n",
            "74\n",
            "Epoch: 0103 loss_train: 0.7804 acc_train: 0.8357 loss_val: 0.6933 acc_val: 0.8100 time: 0.0165s\n",
            "75\n",
            "Epoch: 0104 loss_train: 0.7309 acc_train: 0.8357 loss_val: 0.6927 acc_val: 0.8100 time: 0.0164s\n",
            "76\n",
            "Epoch: 0105 loss_train: 0.7492 acc_train: 0.7714 loss_val: 0.6904 acc_val: 0.8140 time: 0.0165s\n",
            "77\n",
            "Epoch: 0106 loss_train: 0.7740 acc_train: 0.8071 loss_val: 0.6883 acc_val: 0.8220 time: 0.0255s\n",
            "78\n",
            "Epoch: 0107 loss_train: 0.7616 acc_train: 0.8357 loss_val: 0.6865 acc_val: 0.8200 time: 0.0179s\n",
            "79\n",
            "Epoch: 0108 loss_train: 0.7810 acc_train: 0.8429 loss_val: 0.6852 acc_val: 0.8140 time: 0.0171s\n",
            "80\n",
            "Epoch: 0109 loss_train: 0.7866 acc_train: 0.8000 loss_val: 0.6847 acc_val: 0.8180 time: 0.0172s\n",
            "81\n",
            "Epoch: 0110 loss_train: 0.8303 acc_train: 0.8357 loss_val: 0.6846 acc_val: 0.8160 time: 0.0172s\n",
            "82\n",
            "Epoch: 0111 loss_train: 0.8292 acc_train: 0.8000 loss_val: 0.6845 acc_val: 0.8180 time: 0.0173s\n",
            "83\n",
            "Epoch: 0112 loss_train: 0.8014 acc_train: 0.8143 loss_val: 0.6848 acc_val: 0.8160 time: 0.0172s\n",
            "84\n",
            "Epoch: 0113 loss_train: 0.7434 acc_train: 0.8143 loss_val: 0.6851 acc_val: 0.8260 time: 0.0174s\n",
            "85\n",
            "Epoch: 0114 loss_train: 0.8024 acc_train: 0.7929 loss_val: 0.6866 acc_val: 0.8320 time: 0.0181s\n",
            "86\n",
            "Epoch: 0115 loss_train: 0.7546 acc_train: 0.8714 loss_val: 0.6847 acc_val: 0.8260 time: 0.0172s\n",
            "0\n",
            "Epoch: 0116 loss_train: 0.7667 acc_train: 0.8429 loss_val: 0.6826 acc_val: 0.8280 time: 0.0171s\n",
            "1\n",
            "Epoch: 0117 loss_train: 0.7344 acc_train: 0.8429 loss_val: 0.6816 acc_val: 0.8300 time: 0.0196s\n",
            "2\n",
            "Epoch: 0118 loss_train: 0.7799 acc_train: 0.7929 loss_val: 0.6804 acc_val: 0.8260 time: 0.0205s\n",
            "3\n",
            "Epoch: 0119 loss_train: 0.8243 acc_train: 0.8000 loss_val: 0.6800 acc_val: 0.8280 time: 0.0205s\n",
            "4\n",
            "Epoch: 0120 loss_train: 0.7614 acc_train: 0.8000 loss_val: 0.6821 acc_val: 0.8300 time: 0.0173s\n",
            "5\n",
            "Epoch: 0121 loss_train: 0.7597 acc_train: 0.8357 loss_val: 0.6835 acc_val: 0.8220 time: 0.0172s\n",
            "6\n",
            "Epoch: 0122 loss_train: 0.7693 acc_train: 0.8571 loss_val: 0.6862 acc_val: 0.8200 time: 0.0171s\n",
            "7\n",
            "Epoch: 0123 loss_train: 0.8139 acc_train: 0.8000 loss_val: 0.6876 acc_val: 0.8160 time: 0.0175s\n",
            "8\n",
            "Epoch: 0124 loss_train: 0.7577 acc_train: 0.8500 loss_val: 0.6883 acc_val: 0.8180 time: 0.0172s\n",
            "9\n",
            "Epoch: 0125 loss_train: 0.8072 acc_train: 0.8214 loss_val: 0.6885 acc_val: 0.8160 time: 0.0170s\n",
            "10\n",
            "Epoch: 0126 loss_train: 0.7714 acc_train: 0.8500 loss_val: 0.6880 acc_val: 0.8200 time: 0.0172s\n",
            "11\n",
            "Epoch: 0127 loss_train: 0.7897 acc_train: 0.9143 loss_val: 0.6880 acc_val: 0.8180 time: 0.0173s\n",
            "12\n",
            "Epoch: 0128 loss_train: 0.7554 acc_train: 0.8714 loss_val: 0.6898 acc_val: 0.8200 time: 0.0212s\n",
            "13\n",
            "Epoch: 0129 loss_train: 0.7543 acc_train: 0.8357 loss_val: 0.6910 acc_val: 0.8140 time: 0.0171s\n",
            "14\n",
            "Epoch: 0130 loss_train: 0.7785 acc_train: 0.8929 loss_val: 0.6900 acc_val: 0.8140 time: 0.0189s\n",
            "15\n",
            "Epoch: 0131 loss_train: 0.7757 acc_train: 0.8500 loss_val: 0.6883 acc_val: 0.8140 time: 0.0172s\n",
            "16\n",
            "Epoch: 0132 loss_train: 0.7841 acc_train: 0.8071 loss_val: 0.6816 acc_val: 0.8260 time: 0.0178s\n",
            "17\n",
            "Epoch: 0133 loss_train: 0.7366 acc_train: 0.8571 loss_val: 0.6742 acc_val: 0.8240 time: 0.0167s\n",
            "18\n",
            "Epoch: 0134 loss_train: 0.7859 acc_train: 0.8286 loss_val: 0.6719 acc_val: 0.8220 time: 0.0166s\n",
            "19\n",
            "Epoch: 0135 loss_train: 0.7941 acc_train: 0.8500 loss_val: 0.6726 acc_val: 0.8220 time: 0.0170s\n",
            "20\n",
            "Epoch: 0136 loss_train: 0.7740 acc_train: 0.8000 loss_val: 0.6751 acc_val: 0.8200 time: 0.0169s\n",
            "21\n",
            "Epoch: 0137 loss_train: 0.7765 acc_train: 0.7929 loss_val: 0.6785 acc_val: 0.8240 time: 0.0169s\n",
            "22\n",
            "Epoch: 0138 loss_train: 0.7820 acc_train: 0.7571 loss_val: 0.6818 acc_val: 0.8240 time: 0.0206s\n",
            "23\n",
            "Epoch: 0139 loss_train: 0.7890 acc_train: 0.8214 loss_val: 0.6841 acc_val: 0.8240 time: 0.0193s\n",
            "24\n",
            "Epoch: 0140 loss_train: 0.7961 acc_train: 0.8143 loss_val: 0.6872 acc_val: 0.8220 time: 0.0176s\n",
            "25\n",
            "Epoch: 0141 loss_train: 0.8098 acc_train: 0.7929 loss_val: 0.6928 acc_val: 0.8240 time: 0.0175s\n",
            "26\n",
            "Epoch: 0142 loss_train: 0.7982 acc_train: 0.8214 loss_val: 0.6961 acc_val: 0.8180 time: 0.0167s\n",
            "27\n",
            "Epoch: 0143 loss_train: 0.7491 acc_train: 0.8429 loss_val: 0.6938 acc_val: 0.8160 time: 0.0166s\n",
            "28\n",
            "Epoch: 0144 loss_train: 0.7567 acc_train: 0.8214 loss_val: 0.6896 acc_val: 0.8140 time: 0.0166s\n",
            "29\n",
            "Epoch: 0145 loss_train: 0.7727 acc_train: 0.8571 loss_val: 0.6841 acc_val: 0.8220 time: 0.0165s\n",
            "30\n",
            "Epoch: 0146 loss_train: 0.8108 acc_train: 0.8214 loss_val: 0.6800 acc_val: 0.8200 time: 0.0179s\n",
            "31\n",
            "Epoch: 0147 loss_train: 0.8056 acc_train: 0.7929 loss_val: 0.6773 acc_val: 0.8220 time: 0.0167s\n",
            "32\n",
            "Epoch: 0148 loss_train: 0.7617 acc_train: 0.8643 loss_val: 0.6762 acc_val: 0.8240 time: 0.0174s\n",
            "33\n",
            "Epoch: 0149 loss_train: 0.8189 acc_train: 0.7857 loss_val: 0.6785 acc_val: 0.8260 time: 0.0191s\n",
            "34\n",
            "Epoch: 0150 loss_train: 0.7783 acc_train: 0.8143 loss_val: 0.6809 acc_val: 0.8280 time: 0.0228s\n",
            "35\n",
            "Epoch: 0151 loss_train: 0.7840 acc_train: 0.8357 loss_val: 0.6845 acc_val: 0.8240 time: 0.0181s\n",
            "36\n",
            "Epoch: 0152 loss_train: 0.7657 acc_train: 0.8286 loss_val: 0.6898 acc_val: 0.8100 time: 0.0181s\n",
            "37\n",
            "Epoch: 0153 loss_train: 0.7725 acc_train: 0.8571 loss_val: 0.6946 acc_val: 0.8080 time: 0.0174s\n",
            "38\n",
            "Epoch: 0154 loss_train: 0.7713 acc_train: 0.8143 loss_val: 0.6974 acc_val: 0.8060 time: 0.0183s\n",
            "39\n",
            "Epoch: 0155 loss_train: 0.7874 acc_train: 0.8786 loss_val: 0.6959 acc_val: 0.8140 time: 0.0180s\n",
            "40\n",
            "Epoch: 0156 loss_train: 0.7856 acc_train: 0.8143 loss_val: 0.6917 acc_val: 0.8180 time: 0.0174s\n",
            "41\n",
            "Epoch: 0157 loss_train: 0.8117 acc_train: 0.8143 loss_val: 0.6863 acc_val: 0.8220 time: 0.0171s\n",
            "42\n",
            "Epoch: 0158 loss_train: 0.7785 acc_train: 0.8429 loss_val: 0.6831 acc_val: 0.8220 time: 0.0167s\n",
            "43\n",
            "Epoch: 0159 loss_train: 0.8175 acc_train: 0.8000 loss_val: 0.6834 acc_val: 0.8200 time: 0.0169s\n",
            "44\n",
            "Epoch: 0160 loss_train: 0.8400 acc_train: 0.8357 loss_val: 0.6841 acc_val: 0.8220 time: 0.0197s\n",
            "45\n",
            "Epoch: 0161 loss_train: 0.8197 acc_train: 0.8500 loss_val: 0.6825 acc_val: 0.8240 time: 0.0195s\n",
            "46\n",
            "Epoch: 0162 loss_train: 0.7871 acc_train: 0.8286 loss_val: 0.6828 acc_val: 0.8280 time: 0.0173s\n",
            "47\n",
            "Epoch: 0163 loss_train: 0.7826 acc_train: 0.8571 loss_val: 0.6843 acc_val: 0.8300 time: 0.0173s\n",
            "48\n",
            "Epoch: 0164 loss_train: 0.7660 acc_train: 0.8500 loss_val: 0.6851 acc_val: 0.8300 time: 0.0175s\n",
            "49\n",
            "Epoch: 0165 loss_train: 0.7895 acc_train: 0.8071 loss_val: 0.6861 acc_val: 0.8300 time: 0.0171s\n",
            "50\n",
            "Epoch: 0166 loss_train: 0.7908 acc_train: 0.9000 loss_val: 0.6881 acc_val: 0.8200 time: 0.0171s\n",
            "51\n",
            "Epoch: 0167 loss_train: 0.7762 acc_train: 0.7929 loss_val: 0.6877 acc_val: 0.8220 time: 0.0173s\n",
            "52\n",
            "Epoch: 0168 loss_train: 0.7646 acc_train: 0.8571 loss_val: 0.6848 acc_val: 0.8300 time: 0.0171s\n",
            "53\n",
            "Epoch: 0169 loss_train: 0.7691 acc_train: 0.8429 loss_val: 0.6816 acc_val: 0.8180 time: 0.0204s\n",
            "54\n",
            "Epoch: 0170 loss_train: 0.7866 acc_train: 0.8357 loss_val: 0.6787 acc_val: 0.8180 time: 0.0170s\n",
            "55\n",
            "Epoch: 0171 loss_train: 0.7935 acc_train: 0.8357 loss_val: 0.6777 acc_val: 0.8200 time: 0.0247s\n",
            "56\n",
            "Epoch: 0172 loss_train: 0.7618 acc_train: 0.8571 loss_val: 0.6791 acc_val: 0.8220 time: 0.0170s\n",
            "57\n",
            "Epoch: 0173 loss_train: 0.7966 acc_train: 0.8500 loss_val: 0.6801 acc_val: 0.8240 time: 0.0172s\n",
            "58\n",
            "Epoch: 0174 loss_train: 0.7693 acc_train: 0.8357 loss_val: 0.6805 acc_val: 0.8240 time: 0.0194s\n",
            "59\n",
            "Epoch: 0175 loss_train: 0.8151 acc_train: 0.8357 loss_val: 0.6848 acc_val: 0.8280 time: 0.0175s\n",
            "60\n",
            "Epoch: 0176 loss_train: 0.7844 acc_train: 0.8357 loss_val: 0.6882 acc_val: 0.8300 time: 0.0194s\n",
            "61\n",
            "Epoch: 0177 loss_train: 0.7589 acc_train: 0.8500 loss_val: 0.6909 acc_val: 0.8240 time: 0.0184s\n",
            "62\n",
            "Epoch: 0178 loss_train: 0.7575 acc_train: 0.8214 loss_val: 0.6923 acc_val: 0.8240 time: 0.0171s\n",
            "63\n",
            "Epoch: 0179 loss_train: 0.8032 acc_train: 0.8571 loss_val: 0.6911 acc_val: 0.8220 time: 0.0168s\n",
            "64\n",
            "Epoch: 0180 loss_train: 0.7565 acc_train: 0.8214 loss_val: 0.6881 acc_val: 0.8200 time: 0.0168s\n",
            "65\n",
            "Epoch: 0181 loss_train: 0.7877 acc_train: 0.7786 loss_val: 0.6849 acc_val: 0.8300 time: 0.0164s\n",
            "66\n",
            "Epoch: 0182 loss_train: 0.7786 acc_train: 0.8643 loss_val: 0.6838 acc_val: 0.8240 time: 0.0188s\n",
            "67\n",
            "Epoch: 0183 loss_train: 0.7993 acc_train: 0.8071 loss_val: 0.6845 acc_val: 0.8200 time: 0.0165s\n",
            "68\n",
            "Epoch: 0184 loss_train: 0.8044 acc_train: 0.8571 loss_val: 0.6853 acc_val: 0.8180 time: 0.0178s\n",
            "69\n",
            "Epoch: 0185 loss_train: 0.7930 acc_train: 0.8143 loss_val: 0.6872 acc_val: 0.8160 time: 0.0166s\n",
            "70\n",
            "Epoch: 0186 loss_train: 0.7587 acc_train: 0.8286 loss_val: 0.6885 acc_val: 0.8180 time: 0.0168s\n",
            "71\n",
            "Epoch: 0187 loss_train: 0.8706 acc_train: 0.8143 loss_val: 0.6893 acc_val: 0.8240 time: 0.0166s\n",
            "72\n",
            "Epoch: 0188 loss_train: 0.8024 acc_train: 0.8429 loss_val: 0.6893 acc_val: 0.8280 time: 0.0169s\n",
            "73\n",
            "Epoch: 0189 loss_train: 0.7562 acc_train: 0.8357 loss_val: 0.6910 acc_val: 0.8320 time: 0.0167s\n",
            "74\n",
            "Epoch: 0190 loss_train: 0.8118 acc_train: 0.8500 loss_val: 0.6910 acc_val: 0.8340 time: 0.0167s\n",
            "0\n",
            "Epoch: 0191 loss_train: 0.7795 acc_train: 0.8286 loss_val: 0.6903 acc_val: 0.8320 time: 0.0167s\n",
            "0\n",
            "Epoch: 0192 loss_train: 0.7542 acc_train: 0.8500 loss_val: 0.6868 acc_val: 0.8320 time: 0.0171s\n",
            "1\n",
            "Epoch: 0193 loss_train: 0.7436 acc_train: 0.8714 loss_val: 0.6810 acc_val: 0.8300 time: 0.0190s\n",
            "2\n",
            "Epoch: 0194 loss_train: 0.7739 acc_train: 0.7857 loss_val: 0.6761 acc_val: 0.8240 time: 0.0170s\n",
            "3\n",
            "Epoch: 0195 loss_train: 0.7850 acc_train: 0.8071 loss_val: 0.6718 acc_val: 0.8240 time: 0.0166s\n",
            "4\n",
            "Epoch: 0196 loss_train: 0.8103 acc_train: 0.8143 loss_val: 0.6697 acc_val: 0.8260 time: 0.0172s\n",
            "5\n",
            "Epoch: 0197 loss_train: 0.7842 acc_train: 0.8571 loss_val: 0.6690 acc_val: 0.8260 time: 0.0168s\n",
            "6\n",
            "Epoch: 0198 loss_train: 0.7852 acc_train: 0.8357 loss_val: 0.6717 acc_val: 0.8280 time: 0.0176s\n",
            "7\n",
            "Epoch: 0199 loss_train: 0.7789 acc_train: 0.8357 loss_val: 0.6782 acc_val: 0.8240 time: 0.0180s\n",
            "8\n",
            "Epoch: 0200 loss_train: 0.7618 acc_train: 0.8286 loss_val: 0.6837 acc_val: 0.8220 time: 0.0166s\n",
            "9\n",
            "Epoch: 0201 loss_train: 0.8068 acc_train: 0.8571 loss_val: 0.6889 acc_val: 0.8240 time: 0.0168s\n",
            "10\n",
            "Epoch: 0202 loss_train: 0.7307 acc_train: 0.8857 loss_val: 0.6929 acc_val: 0.8240 time: 0.0162s\n",
            "11\n",
            "Epoch: 0203 loss_train: 0.8138 acc_train: 0.8286 loss_val: 0.6937 acc_val: 0.8240 time: 0.0171s\n",
            "12\n",
            "Epoch: 0204 loss_train: 0.7763 acc_train: 0.8143 loss_val: 0.6943 acc_val: 0.8200 time: 0.0207s\n",
            "13\n",
            "Epoch: 0205 loss_train: 0.7777 acc_train: 0.7714 loss_val: 0.6934 acc_val: 0.8240 time: 0.0176s\n",
            "14\n",
            "Epoch: 0206 loss_train: 0.7703 acc_train: 0.8643 loss_val: 0.6914 acc_val: 0.8220 time: 0.0168s\n",
            "15\n",
            "Epoch: 0207 loss_train: 0.7769 acc_train: 0.8286 loss_val: 0.6884 acc_val: 0.8240 time: 0.0166s\n",
            "16\n",
            "Epoch: 0208 loss_train: 0.7756 acc_train: 0.8500 loss_val: 0.6849 acc_val: 0.8300 time: 0.0166s\n",
            "17\n",
            "Epoch: 0209 loss_train: 0.7455 acc_train: 0.8143 loss_val: 0.6814 acc_val: 0.8300 time: 0.0166s\n",
            "18\n",
            "Epoch: 0210 loss_train: 0.7671 acc_train: 0.8214 loss_val: 0.6787 acc_val: 0.8320 time: 0.0165s\n",
            "19\n",
            "Epoch: 0211 loss_train: 0.8503 acc_train: 0.8571 loss_val: 0.6775 acc_val: 0.8320 time: 0.0167s\n",
            "20\n",
            "Epoch: 0212 loss_train: 0.7663 acc_train: 0.8571 loss_val: 0.6754 acc_val: 0.8300 time: 0.0178s\n",
            "21\n",
            "Epoch: 0213 loss_train: 0.8349 acc_train: 0.7857 loss_val: 0.6757 acc_val: 0.8280 time: 0.0184s\n",
            "22\n",
            "Epoch: 0214 loss_train: 0.7812 acc_train: 0.8786 loss_val: 0.6777 acc_val: 0.8280 time: 0.0168s\n",
            "23\n",
            "Epoch: 0215 loss_train: 0.8004 acc_train: 0.8500 loss_val: 0.6784 acc_val: 0.8260 time: 0.0212s\n",
            "24\n",
            "Epoch: 0216 loss_train: 0.8405 acc_train: 0.8071 loss_val: 0.6806 acc_val: 0.8340 time: 0.0165s\n",
            "25\n",
            "Epoch: 0217 loss_train: 0.7271 acc_train: 0.9000 loss_val: 0.6833 acc_val: 0.8300 time: 0.0165s\n",
            "0\n",
            "Epoch: 0218 loss_train: 0.7778 acc_train: 0.8500 loss_val: 0.6874 acc_val: 0.8260 time: 0.0177s\n",
            "1\n",
            "Epoch: 0219 loss_train: 0.7680 acc_train: 0.8286 loss_val: 0.6909 acc_val: 0.8200 time: 0.0166s\n",
            "2\n",
            "Epoch: 0220 loss_train: 0.7646 acc_train: 0.8500 loss_val: 0.6920 acc_val: 0.8180 time: 0.0168s\n",
            "3\n",
            "Epoch: 0221 loss_train: 0.7426 acc_train: 0.8000 loss_val: 0.6901 acc_val: 0.8200 time: 0.0190s\n",
            "4\n",
            "Epoch: 0222 loss_train: 0.8192 acc_train: 0.8000 loss_val: 0.6878 acc_val: 0.8240 time: 0.0166s\n",
            "5\n",
            "Epoch: 0223 loss_train: 0.8033 acc_train: 0.8143 loss_val: 0.6835 acc_val: 0.8200 time: 0.0172s\n",
            "6\n",
            "Epoch: 0224 loss_train: 0.7781 acc_train: 0.7929 loss_val: 0.6823 acc_val: 0.8200 time: 0.0165s\n",
            "7\n",
            "Epoch: 0225 loss_train: 0.7742 acc_train: 0.8357 loss_val: 0.6798 acc_val: 0.8200 time: 0.0165s\n",
            "8\n",
            "Epoch: 0226 loss_train: 0.7758 acc_train: 0.8429 loss_val: 0.6768 acc_val: 0.8220 time: 0.0209s\n",
            "9\n",
            "Epoch: 0227 loss_train: 0.8079 acc_train: 0.8214 loss_val: 0.6752 acc_val: 0.8260 time: 0.0189s\n",
            "10\n",
            "Epoch: 0228 loss_train: 0.8138 acc_train: 0.8000 loss_val: 0.6748 acc_val: 0.8300 time: 0.0171s\n",
            "11\n",
            "Epoch: 0229 loss_train: 0.7539 acc_train: 0.8571 loss_val: 0.6770 acc_val: 0.8300 time: 0.0172s\n",
            "12\n",
            "Epoch: 0230 loss_train: 0.7268 acc_train: 0.8500 loss_val: 0.6807 acc_val: 0.8300 time: 0.0169s\n",
            "13\n",
            "Epoch: 0231 loss_train: 0.8057 acc_train: 0.8357 loss_val: 0.6848 acc_val: 0.8240 time: 0.0170s\n",
            "14\n",
            "Epoch: 0232 loss_train: 0.8111 acc_train: 0.8643 loss_val: 0.6905 acc_val: 0.8220 time: 0.0169s\n",
            "15\n",
            "Epoch: 0233 loss_train: 0.8032 acc_train: 0.8571 loss_val: 0.6955 acc_val: 0.8100 time: 0.0170s\n",
            "16\n",
            "Epoch: 0234 loss_train: 0.7188 acc_train: 0.8929 loss_val: 0.6948 acc_val: 0.8120 time: 0.0171s\n",
            "17\n",
            "Epoch: 0235 loss_train: 0.8071 acc_train: 0.8571 loss_val: 0.6907 acc_val: 0.8160 time: 0.0180s\n",
            "18\n",
            "Epoch: 0236 loss_train: 0.7512 acc_train: 0.8786 loss_val: 0.6837 acc_val: 0.8220 time: 0.0175s\n",
            "19\n",
            "Epoch: 0237 loss_train: 0.7895 acc_train: 0.8214 loss_val: 0.6781 acc_val: 0.8240 time: 0.0215s\n",
            "20\n",
            "Epoch: 0238 loss_train: 0.8058 acc_train: 0.7786 loss_val: 0.6760 acc_val: 0.8240 time: 0.0188s\n",
            "21\n",
            "Epoch: 0239 loss_train: 0.8264 acc_train: 0.8429 loss_val: 0.6767 acc_val: 0.8260 time: 0.0175s\n",
            "22\n",
            "Epoch: 0240 loss_train: 0.7447 acc_train: 0.8643 loss_val: 0.6793 acc_val: 0.8240 time: 0.0172s\n",
            "23\n",
            "Epoch: 0241 loss_train: 0.7472 acc_train: 0.8357 loss_val: 0.6858 acc_val: 0.8260 time: 0.0185s\n",
            "24\n",
            "Epoch: 0242 loss_train: 0.7790 acc_train: 0.8714 loss_val: 0.6905 acc_val: 0.8220 time: 0.0182s\n",
            "25\n",
            "Epoch: 0243 loss_train: 0.7875 acc_train: 0.8643 loss_val: 0.6962 acc_val: 0.8140 time: 0.0188s\n",
            "26\n",
            "Epoch: 0244 loss_train: 0.8250 acc_train: 0.8214 loss_val: 0.7020 acc_val: 0.8120 time: 0.0173s\n",
            "27\n",
            "Epoch: 0245 loss_train: 0.7914 acc_train: 0.8143 loss_val: 0.7043 acc_val: 0.8080 time: 0.0173s\n",
            "28\n",
            "Epoch: 0246 loss_train: 0.7713 acc_train: 0.8214 loss_val: 0.7028 acc_val: 0.8140 time: 0.0173s\n",
            "29\n",
            "Epoch: 0247 loss_train: 0.7672 acc_train: 0.8357 loss_val: 0.7004 acc_val: 0.8100 time: 0.0170s\n",
            "30\n",
            "Epoch: 0248 loss_train: 0.7491 acc_train: 0.8500 loss_val: 0.6941 acc_val: 0.8160 time: 0.0199s\n",
            "31\n",
            "Epoch: 0249 loss_train: 0.8052 acc_train: 0.8286 loss_val: 0.6891 acc_val: 0.8160 time: 0.0190s\n",
            "32\n",
            "Epoch: 0250 loss_train: 0.7650 acc_train: 0.8143 loss_val: 0.6855 acc_val: 0.8180 time: 0.0172s\n",
            "33\n",
            "Epoch: 0251 loss_train: 0.7821 acc_train: 0.8071 loss_val: 0.6805 acc_val: 0.8220 time: 0.0186s\n",
            "34\n",
            "Epoch: 0252 loss_train: 0.7894 acc_train: 0.8571 loss_val: 0.6780 acc_val: 0.8220 time: 0.0197s\n",
            "35\n",
            "Epoch: 0253 loss_train: 0.7784 acc_train: 0.8071 loss_val: 0.6808 acc_val: 0.8240 time: 0.0191s\n",
            "36\n",
            "Epoch: 0254 loss_train: 0.7958 acc_train: 0.8429 loss_val: 0.6842 acc_val: 0.8180 time: 0.0174s\n",
            "37\n",
            "Epoch: 0255 loss_train: 0.7557 acc_train: 0.8286 loss_val: 0.6865 acc_val: 0.8200 time: 0.0172s\n",
            "38\n",
            "Epoch: 0256 loss_train: 0.8191 acc_train: 0.8143 loss_val: 0.6895 acc_val: 0.8240 time: 0.0167s\n",
            "39\n",
            "Epoch: 0257 loss_train: 0.8237 acc_train: 0.8571 loss_val: 0.6905 acc_val: 0.8220 time: 0.0165s\n",
            "40\n",
            "Epoch: 0258 loss_train: 0.7708 acc_train: 0.8214 loss_val: 0.6935 acc_val: 0.8220 time: 0.0162s\n",
            "41\n",
            "Epoch: 0259 loss_train: 0.7832 acc_train: 0.8357 loss_val: 0.6959 acc_val: 0.8120 time: 0.0190s\n",
            "42\n",
            "Epoch: 0260 loss_train: 0.7810 acc_train: 0.8786 loss_val: 0.6957 acc_val: 0.8140 time: 0.0165s\n",
            "43\n",
            "Epoch: 0261 loss_train: 0.7795 acc_train: 0.8214 loss_val: 0.6925 acc_val: 0.8140 time: 0.0167s\n",
            "44\n",
            "Epoch: 0262 loss_train: 0.7737 acc_train: 0.8000 loss_val: 0.6876 acc_val: 0.8200 time: 0.0175s\n",
            "45\n",
            "Epoch: 0263 loss_train: 0.8058 acc_train: 0.7857 loss_val: 0.6826 acc_val: 0.8180 time: 0.0188s\n",
            "46\n",
            "Epoch: 0264 loss_train: 0.8144 acc_train: 0.8000 loss_val: 0.6798 acc_val: 0.8240 time: 0.0166s\n",
            "47\n",
            "Epoch: 0265 loss_train: 0.8278 acc_train: 0.8429 loss_val: 0.6816 acc_val: 0.8240 time: 0.0166s\n",
            "48\n",
            "Epoch: 0266 loss_train: 0.7805 acc_train: 0.8357 loss_val: 0.6840 acc_val: 0.8300 time: 0.0167s\n",
            "49\n",
            "Epoch: 0267 loss_train: 0.7729 acc_train: 0.8357 loss_val: 0.6861 acc_val: 0.8280 time: 0.0165s\n",
            "50\n",
            "Epoch: 0268 loss_train: 0.8044 acc_train: 0.7714 loss_val: 0.6874 acc_val: 0.8240 time: 0.0168s\n",
            "51\n",
            "Epoch: 0269 loss_train: 0.7900 acc_train: 0.8214 loss_val: 0.6876 acc_val: 0.8220 time: 0.0167s\n",
            "52\n",
            "Epoch: 0270 loss_train: 0.7774 acc_train: 0.8500 loss_val: 0.6879 acc_val: 0.8220 time: 0.0222s\n",
            "53\n",
            "Epoch: 0271 loss_train: 0.8085 acc_train: 0.7786 loss_val: 0.6863 acc_val: 0.8220 time: 0.0167s\n",
            "54\n",
            "Epoch: 0272 loss_train: 0.7984 acc_train: 0.8143 loss_val: 0.6844 acc_val: 0.8260 time: 0.0202s\n",
            "55\n",
            "Epoch: 0273 loss_train: 0.7975 acc_train: 0.8571 loss_val: 0.6847 acc_val: 0.8240 time: 0.0169s\n",
            "56\n",
            "Epoch: 0274 loss_train: 0.7759 acc_train: 0.8571 loss_val: 0.6843 acc_val: 0.8200 time: 0.0166s\n",
            "57\n",
            "Epoch: 0275 loss_train: 0.7982 acc_train: 0.8429 loss_val: 0.6838 acc_val: 0.8200 time: 0.0170s\n",
            "58\n",
            "Epoch: 0276 loss_train: 0.7632 acc_train: 0.8143 loss_val: 0.6821 acc_val: 0.8200 time: 0.0164s\n",
            "59\n",
            "Epoch: 0277 loss_train: 0.8072 acc_train: 0.8143 loss_val: 0.6793 acc_val: 0.8220 time: 0.0167s\n",
            "60\n",
            "Epoch: 0278 loss_train: 0.7617 acc_train: 0.8357 loss_val: 0.6772 acc_val: 0.8220 time: 0.0167s\n",
            "61\n",
            "Epoch: 0279 loss_train: 0.7810 acc_train: 0.8714 loss_val: 0.6766 acc_val: 0.8200 time: 0.0161s\n",
            "62\n",
            "Epoch: 0280 loss_train: 0.7828 acc_train: 0.8500 loss_val: 0.6779 acc_val: 0.8220 time: 0.0165s\n",
            "63\n",
            "Epoch: 0281 loss_train: 0.7594 acc_train: 0.8071 loss_val: 0.6801 acc_val: 0.8260 time: 0.0216s\n",
            "64\n",
            "Epoch: 0282 loss_train: 0.7844 acc_train: 0.8429 loss_val: 0.6817 acc_val: 0.8260 time: 0.0183s\n",
            "65\n",
            "Epoch: 0283 loss_train: 0.7781 acc_train: 0.8071 loss_val: 0.6847 acc_val: 0.8220 time: 0.0166s\n",
            "66\n",
            "Epoch: 0284 loss_train: 0.7789 acc_train: 0.8214 loss_val: 0.6859 acc_val: 0.8200 time: 0.0181s\n",
            "67\n",
            "Epoch: 0285 loss_train: 0.7651 acc_train: 0.8500 loss_val: 0.6858 acc_val: 0.8220 time: 0.0189s\n",
            "68\n",
            "Epoch: 0286 loss_train: 0.7292 acc_train: 0.8786 loss_val: 0.6856 acc_val: 0.8160 time: 0.0165s\n",
            "69\n",
            "Epoch: 0287 loss_train: 0.7647 acc_train: 0.8786 loss_val: 0.6851 acc_val: 0.8140 time: 0.0162s\n",
            "70\n",
            "Epoch: 0288 loss_train: 0.8177 acc_train: 0.8071 loss_val: 0.6847 acc_val: 0.8160 time: 0.0165s\n",
            "71\n",
            "Epoch: 0289 loss_train: 0.7584 acc_train: 0.7714 loss_val: 0.6854 acc_val: 0.8180 time: 0.0165s\n",
            "72\n",
            "Epoch: 0290 loss_train: 0.7807 acc_train: 0.8571 loss_val: 0.6867 acc_val: 0.8220 time: 0.0169s\n",
            "73\n",
            "Epoch: 0291 loss_train: 0.7915 acc_train: 0.8786 loss_val: 0.6866 acc_val: 0.8240 time: 0.0165s\n",
            "74\n",
            "Epoch: 0292 loss_train: 0.8083 acc_train: 0.8286 loss_val: 0.6875 acc_val: 0.8200 time: 0.0210s\n",
            "75\n",
            "Epoch: 0293 loss_train: 0.8174 acc_train: 0.8500 loss_val: 0.6884 acc_val: 0.8200 time: 0.0176s\n",
            "76\n",
            "Epoch: 0294 loss_train: 0.8117 acc_train: 0.8214 loss_val: 0.6871 acc_val: 0.8200 time: 0.0175s\n",
            "77\n",
            "Epoch: 0295 loss_train: 0.8085 acc_train: 0.8286 loss_val: 0.6865 acc_val: 0.8200 time: 0.0179s\n",
            "78\n",
            "Epoch: 0296 loss_train: 0.8164 acc_train: 0.8500 loss_val: 0.6889 acc_val: 0.8220 time: 0.0167s\n",
            "79\n",
            "Epoch: 0297 loss_train: 0.7799 acc_train: 0.8071 loss_val: 0.6913 acc_val: 0.8260 time: 0.0176s\n",
            "80\n",
            "Epoch: 0298 loss_train: 0.7483 acc_train: 0.8286 loss_val: 0.6917 acc_val: 0.8220 time: 0.0172s\n",
            "81\n",
            "Epoch: 0299 loss_train: 0.7120 acc_train: 0.8643 loss_val: 0.6871 acc_val: 0.8200 time: 0.0170s\n",
            "82\n",
            "Epoch: 0300 loss_train: 0.7693 acc_train: 0.8500 loss_val: 0.6812 acc_val: 0.8220 time: 0.0176s\n",
            "83\n",
            "Epoch: 0301 loss_train: 0.7675 acc_train: 0.8643 loss_val: 0.6756 acc_val: 0.8260 time: 0.0171s\n",
            "84\n",
            "Epoch: 0302 loss_train: 0.7858 acc_train: 0.8143 loss_val: 0.6732 acc_val: 0.8280 time: 0.0171s\n",
            "85\n",
            "Epoch: 0303 loss_train: 0.8036 acc_train: 0.8143 loss_val: 0.6729 acc_val: 0.8260 time: 0.0206s\n",
            "86\n",
            "Epoch: 0304 loss_train: 0.7833 acc_train: 0.8000 loss_val: 0.6767 acc_val: 0.8260 time: 0.0186s\n",
            "87\n",
            "Epoch: 0305 loss_train: 0.7342 acc_train: 0.8714 loss_val: 0.6824 acc_val: 0.8240 time: 0.0181s\n",
            "88\n",
            "Epoch: 0306 loss_train: 0.7844 acc_train: 0.8357 loss_val: 0.6850 acc_val: 0.8200 time: 0.0173s\n",
            "89\n",
            "Epoch: 0307 loss_train: 0.7325 acc_train: 0.8429 loss_val: 0.6867 acc_val: 0.8220 time: 0.0172s\n",
            "90\n",
            "Epoch: 0308 loss_train: 0.7722 acc_train: 0.8357 loss_val: 0.6841 acc_val: 0.8240 time: 0.0175s\n",
            "91\n",
            "Epoch: 0309 loss_train: 0.8236 acc_train: 0.8286 loss_val: 0.6821 acc_val: 0.8260 time: 0.0173s\n",
            "92\n",
            "Epoch: 0310 loss_train: 0.8001 acc_train: 0.8214 loss_val: 0.6801 acc_val: 0.8260 time: 0.0173s\n",
            "93\n",
            "Epoch: 0311 loss_train: 0.7522 acc_train: 0.8786 loss_val: 0.6789 acc_val: 0.8240 time: 0.0176s\n",
            "94\n",
            "Epoch: 0312 loss_train: 0.7350 acc_train: 0.8786 loss_val: 0.6775 acc_val: 0.8220 time: 0.0172s\n",
            "95\n",
            "Epoch: 0313 loss_train: 0.7719 acc_train: 0.8000 loss_val: 0.6754 acc_val: 0.8220 time: 0.0192s\n",
            "96\n",
            "Epoch: 0314 loss_train: 0.8002 acc_train: 0.8143 loss_val: 0.6743 acc_val: 0.8220 time: 0.0193s\n",
            "97\n",
            "Epoch: 0315 loss_train: 0.8279 acc_train: 0.8071 loss_val: 0.6734 acc_val: 0.8180 time: 0.0172s\n",
            "98\n",
            "Epoch: 0316 loss_train: 0.8060 acc_train: 0.8214 loss_val: 0.6747 acc_val: 0.8160 time: 0.0170s\n",
            "99\n",
            "Epoch: 0317 loss_train: 0.7798 acc_train: 0.8429 loss_val: 0.6785 acc_val: 0.8100 time: 0.0165s\n",
            "100\n",
            "Epoch: 0318 loss_train: 0.7732 acc_train: 0.8286 loss_val: 0.6837 acc_val: 0.8080 time: 0.0166s\n",
            "101\n",
            "Epoch: 0319 loss_train: 0.8132 acc_train: 0.8429 loss_val: 0.6874 acc_val: 0.8100 time: 0.0163s\n",
            "102\n",
            "Epoch: 0320 loss_train: 0.7661 acc_train: 0.8429 loss_val: 0.6901 acc_val: 0.8100 time: 0.0171s\n",
            "103\n",
            "Epoch: 0321 loss_train: 0.7836 acc_train: 0.8714 loss_val: 0.6904 acc_val: 0.8120 time: 0.0167s\n",
            "104\n",
            "Epoch: 0322 loss_train: 0.7812 acc_train: 0.8143 loss_val: 0.6880 acc_val: 0.8140 time: 0.0165s\n",
            "105\n",
            "Epoch: 0323 loss_train: 0.8095 acc_train: 0.8714 loss_val: 0.6851 acc_val: 0.8160 time: 0.0196s\n",
            "106\n",
            "Epoch: 0324 loss_train: 0.7924 acc_train: 0.8071 loss_val: 0.6834 acc_val: 0.8220 time: 0.0189s\n",
            "107\n",
            "Epoch: 0325 loss_train: 0.7803 acc_train: 0.8786 loss_val: 0.6814 acc_val: 0.8260 time: 0.0219s\n",
            "108\n",
            "Epoch: 0326 loss_train: 0.7571 acc_train: 0.8500 loss_val: 0.6792 acc_val: 0.8300 time: 0.0167s\n",
            "109\n",
            "Epoch: 0327 loss_train: 0.7348 acc_train: 0.8286 loss_val: 0.6777 acc_val: 0.8300 time: 0.0170s\n",
            "110\n",
            "Epoch: 0328 loss_train: 0.7584 acc_train: 0.8857 loss_val: 0.6780 acc_val: 0.8260 time: 0.0171s\n",
            "111\n",
            "Epoch: 0329 loss_train: 0.7599 acc_train: 0.8286 loss_val: 0.6791 acc_val: 0.8220 time: 0.0168s\n",
            "112\n",
            "Epoch: 0330 loss_train: 0.7607 acc_train: 0.8000 loss_val: 0.6801 acc_val: 0.8160 time: 0.0166s\n",
            "113\n",
            "Epoch: 0331 loss_train: 0.8219 acc_train: 0.8214 loss_val: 0.6823 acc_val: 0.8160 time: 0.0165s\n",
            "114\n",
            "Epoch: 0332 loss_train: 0.7441 acc_train: 0.8357 loss_val: 0.6841 acc_val: 0.8120 time: 0.0166s\n",
            "115\n",
            "Epoch: 0333 loss_train: 0.8266 acc_train: 0.8643 loss_val: 0.6864 acc_val: 0.8100 time: 0.0166s\n",
            "116\n",
            "Epoch: 0334 loss_train: 0.7805 acc_train: 0.8357 loss_val: 0.6845 acc_val: 0.8140 time: 0.0177s\n",
            "117\n",
            "Epoch: 0335 loss_train: 0.7470 acc_train: 0.8429 loss_val: 0.6827 acc_val: 0.8200 time: 0.0167s\n",
            "118\n",
            "Epoch: 0336 loss_train: 0.7915 acc_train: 0.8643 loss_val: 0.6795 acc_val: 0.8180 time: 0.0239s\n",
            "119\n",
            "Epoch: 0337 loss_train: 0.7999 acc_train: 0.8286 loss_val: 0.6764 acc_val: 0.8240 time: 0.0178s\n",
            "120\n",
            "Epoch: 0338 loss_train: 0.8031 acc_train: 0.8214 loss_val: 0.6764 acc_val: 0.8240 time: 0.0182s\n",
            "121\n",
            "Epoch: 0339 loss_train: 0.8480 acc_train: 0.8357 loss_val: 0.6803 acc_val: 0.8240 time: 0.0167s\n",
            "122\n",
            "Epoch: 0340 loss_train: 0.7763 acc_train: 0.8286 loss_val: 0.6865 acc_val: 0.8180 time: 0.0167s\n",
            "123\n",
            "Epoch: 0341 loss_train: 0.7956 acc_train: 0.8714 loss_val: 0.6933 acc_val: 0.8160 time: 0.0193s\n",
            "124\n",
            "Epoch: 0342 loss_train: 0.7535 acc_train: 0.8571 loss_val: 0.6977 acc_val: 0.8160 time: 0.0201s\n",
            "125\n",
            "Epoch: 0343 loss_train: 0.8467 acc_train: 0.8571 loss_val: 0.7009 acc_val: 0.8180 time: 0.0179s\n",
            "126\n",
            "Epoch: 0344 loss_train: 0.7283 acc_train: 0.8857 loss_val: 0.6999 acc_val: 0.8200 time: 0.0179s\n",
            "127\n",
            "Epoch: 0345 loss_train: 0.8515 acc_train: 0.8286 loss_val: 0.6962 acc_val: 0.8140 time: 0.0172s\n",
            "128\n",
            "Epoch: 0346 loss_train: 0.8253 acc_train: 0.7643 loss_val: 0.6901 acc_val: 0.8160 time: 0.0172s\n",
            "129\n",
            "Epoch: 0347 loss_train: 0.8054 acc_train: 0.8143 loss_val: 0.6840 acc_val: 0.8180 time: 0.0218s\n",
            "130\n",
            "Epoch: 0348 loss_train: 0.8303 acc_train: 0.7929 loss_val: 0.6795 acc_val: 0.8200 time: 0.0180s\n",
            "131\n",
            "Epoch: 0349 loss_train: 0.8085 acc_train: 0.8000 loss_val: 0.6778 acc_val: 0.8200 time: 0.0185s\n",
            "132\n",
            "Epoch: 0350 loss_train: 0.7998 acc_train: 0.8143 loss_val: 0.6774 acc_val: 0.8220 time: 0.0188s\n",
            "133\n",
            "Epoch: 0351 loss_train: 0.7951 acc_train: 0.8214 loss_val: 0.6788 acc_val: 0.8220 time: 0.0170s\n",
            "134\n",
            "Epoch: 0352 loss_train: 0.7832 acc_train: 0.8571 loss_val: 0.6828 acc_val: 0.8140 time: 0.0178s\n",
            "135\n",
            "Epoch: 0353 loss_train: 0.7639 acc_train: 0.8643 loss_val: 0.6888 acc_val: 0.8160 time: 0.0172s\n",
            "136\n",
            "Epoch: 0354 loss_train: 0.8192 acc_train: 0.7857 loss_val: 0.6949 acc_val: 0.8100 time: 0.0173s\n",
            "137\n",
            "Epoch: 0355 loss_train: 0.7710 acc_train: 0.8500 loss_val: 0.6976 acc_val: 0.8080 time: 0.0172s\n",
            "138\n",
            "Epoch: 0356 loss_train: 0.7438 acc_train: 0.8643 loss_val: 0.6963 acc_val: 0.8080 time: 0.0173s\n",
            "139\n",
            "Epoch: 0357 loss_train: 0.7619 acc_train: 0.8643 loss_val: 0.6908 acc_val: 0.8140 time: 0.0178s\n",
            "140\n",
            "Epoch: 0358 loss_train: 0.7907 acc_train: 0.8571 loss_val: 0.6853 acc_val: 0.8200 time: 0.0198s\n",
            "141\n",
            "Epoch: 0359 loss_train: 0.7510 acc_train: 0.8643 loss_val: 0.6807 acc_val: 0.8120 time: 0.0172s\n",
            "142\n",
            "Epoch: 0360 loss_train: 0.7540 acc_train: 0.8500 loss_val: 0.6776 acc_val: 0.8160 time: 0.0172s\n",
            "143\n",
            "Epoch: 0361 loss_train: 0.8167 acc_train: 0.8429 loss_val: 0.6752 acc_val: 0.8200 time: 0.0168s\n",
            "144\n",
            "Epoch: 0362 loss_train: 0.7703 acc_train: 0.8500 loss_val: 0.6749 acc_val: 0.8160 time: 0.0171s\n",
            "145\n",
            "Epoch: 0363 loss_train: 0.7822 acc_train: 0.8357 loss_val: 0.6774 acc_val: 0.8180 time: 0.0173s\n",
            "146\n",
            "Epoch: 0364 loss_train: 0.8143 acc_train: 0.8000 loss_val: 0.6828 acc_val: 0.8100 time: 0.0173s\n",
            "147\n",
            "Epoch: 0365 loss_train: 0.7981 acc_train: 0.7786 loss_val: 0.6890 acc_val: 0.8100 time: 0.0173s\n",
            "148\n",
            "Epoch: 0366 loss_train: 0.7948 acc_train: 0.8429 loss_val: 0.6919 acc_val: 0.8100 time: 0.0179s\n",
            "149\n",
            "Epoch: 0367 loss_train: 0.8214 acc_train: 0.8143 loss_val: 0.6928 acc_val: 0.8140 time: 0.0161s\n",
            "150\n",
            "Epoch: 0368 loss_train: 0.7904 acc_train: 0.8571 loss_val: 0.6940 acc_val: 0.8120 time: 0.0165s\n",
            "151\n",
            "Epoch: 0369 loss_train: 0.8080 acc_train: 0.8000 loss_val: 0.6913 acc_val: 0.8180 time: 0.0231s\n",
            "152\n",
            "Epoch: 0370 loss_train: 0.8097 acc_train: 0.8071 loss_val: 0.6878 acc_val: 0.8200 time: 0.0166s\n",
            "153\n",
            "Epoch: 0371 loss_train: 0.8034 acc_train: 0.8143 loss_val: 0.6830 acc_val: 0.8220 time: 0.0167s\n",
            "154\n",
            "Epoch: 0372 loss_train: 0.7737 acc_train: 0.8929 loss_val: 0.6795 acc_val: 0.8220 time: 0.0167s\n",
            "155\n",
            "Epoch: 0373 loss_train: 0.7739 acc_train: 0.8143 loss_val: 0.6761 acc_val: 0.8280 time: 0.0166s\n",
            "156\n",
            "Epoch: 0374 loss_train: 0.7837 acc_train: 0.7929 loss_val: 0.6768 acc_val: 0.8240 time: 0.0188s\n",
            "157\n",
            "Epoch: 0375 loss_train: 0.8091 acc_train: 0.8214 loss_val: 0.6794 acc_val: 0.8240 time: 0.0193s\n",
            "158\n",
            "Epoch: 0376 loss_train: 0.7871 acc_train: 0.8714 loss_val: 0.6850 acc_val: 0.8160 time: 0.0166s\n",
            "159\n",
            "Epoch: 0377 loss_train: 0.8077 acc_train: 0.8286 loss_val: 0.6912 acc_val: 0.8120 time: 0.0186s\n",
            "160\n",
            "Epoch: 0378 loss_train: 0.6969 acc_train: 0.8214 loss_val: 0.6946 acc_val: 0.8120 time: 0.0185s\n",
            "161\n",
            "Epoch: 0379 loss_train: 0.7897 acc_train: 0.8071 loss_val: 0.6962 acc_val: 0.8080 time: 0.0167s\n",
            "162\n",
            "Epoch: 0380 loss_train: 0.7641 acc_train: 0.8357 loss_val: 0.6928 acc_val: 0.8020 time: 0.0217s\n",
            "163\n",
            "Epoch: 0381 loss_train: 0.8050 acc_train: 0.8714 loss_val: 0.6868 acc_val: 0.8100 time: 0.0166s\n",
            "164\n",
            "Epoch: 0382 loss_train: 0.7970 acc_train: 0.8214 loss_val: 0.6810 acc_val: 0.8180 time: 0.0165s\n",
            "165\n",
            "Epoch: 0383 loss_train: 0.8399 acc_train: 0.8000 loss_val: 0.6779 acc_val: 0.8200 time: 0.0167s\n",
            "166\n",
            "Epoch: 0384 loss_train: 0.7650 acc_train: 0.8357 loss_val: 0.6753 acc_val: 0.8200 time: 0.0174s\n",
            "167\n",
            "Epoch: 0385 loss_train: 0.7926 acc_train: 0.8000 loss_val: 0.6714 acc_val: 0.8220 time: 0.0165s\n",
            "168\n",
            "Epoch: 0386 loss_train: 0.8086 acc_train: 0.8214 loss_val: 0.6719 acc_val: 0.8240 time: 0.0167s\n",
            "169\n",
            "Epoch: 0387 loss_train: 0.8077 acc_train: 0.8357 loss_val: 0.6749 acc_val: 0.8260 time: 0.0166s\n",
            "170\n",
            "Epoch: 0388 loss_train: 0.7760 acc_train: 0.8357 loss_val: 0.6794 acc_val: 0.8240 time: 0.0171s\n",
            "171\n",
            "Epoch: 0389 loss_train: 0.7650 acc_train: 0.8643 loss_val: 0.6844 acc_val: 0.8200 time: 0.0167s\n",
            "172\n",
            "Epoch: 0390 loss_train: 0.7189 acc_train: 0.8429 loss_val: 0.6882 acc_val: 0.8200 time: 0.0173s\n",
            "173\n",
            "Epoch: 0391 loss_train: 0.7626 acc_train: 0.8214 loss_val: 0.6913 acc_val: 0.8160 time: 0.0206s\n",
            "174\n",
            "Epoch: 0392 loss_train: 0.7826 acc_train: 0.8143 loss_val: 0.6918 acc_val: 0.8160 time: 0.0176s\n",
            "175\n",
            "Epoch: 0393 loss_train: 0.8226 acc_train: 0.8214 loss_val: 0.6899 acc_val: 0.8200 time: 0.0167s\n",
            "176\n",
            "Epoch: 0394 loss_train: 0.7996 acc_train: 0.7857 loss_val: 0.6877 acc_val: 0.8200 time: 0.0168s\n",
            "177\n",
            "Epoch: 0395 loss_train: 0.7576 acc_train: 0.7857 loss_val: 0.6860 acc_val: 0.8200 time: 0.0173s\n",
            "178\n",
            "Epoch: 0396 loss_train: 0.7900 acc_train: 0.8071 loss_val: 0.6844 acc_val: 0.8200 time: 0.0165s\n",
            "179\n",
            "Epoch: 0397 loss_train: 0.8024 acc_train: 0.7929 loss_val: 0.6830 acc_val: 0.8180 time: 0.0164s\n",
            "180\n",
            "Epoch: 0398 loss_train: 0.7724 acc_train: 0.8643 loss_val: 0.6799 acc_val: 0.8200 time: 0.0165s\n",
            "181\n",
            "Epoch: 0399 loss_train: 0.7701 acc_train: 0.7857 loss_val: 0.6780 acc_val: 0.8240 time: 0.0167s\n",
            "182\n",
            "Epoch: 0400 loss_train: 0.7698 acc_train: 0.8500 loss_val: 0.6772 acc_val: 0.8220 time: 0.0172s\n",
            "183\n",
            "Epoch: 0401 loss_train: 0.7926 acc_train: 0.7929 loss_val: 0.6784 acc_val: 0.8160 time: 0.0173s\n",
            "184\n",
            "Epoch: 0402 loss_train: 0.8041 acc_train: 0.8357 loss_val: 0.6807 acc_val: 0.8200 time: 0.0261s\n",
            "185\n",
            "Epoch: 0403 loss_train: 0.7728 acc_train: 0.8357 loss_val: 0.6841 acc_val: 0.8200 time: 0.0173s\n",
            "186\n",
            "Epoch: 0404 loss_train: 0.7918 acc_train: 0.8286 loss_val: 0.6865 acc_val: 0.8160 time: 0.0171s\n",
            "187\n",
            "Epoch: 0405 loss_train: 0.7600 acc_train: 0.8643 loss_val: 0.6870 acc_val: 0.8240 time: 0.0171s\n",
            "188\n",
            "Epoch: 0406 loss_train: 0.7699 acc_train: 0.8357 loss_val: 0.6854 acc_val: 0.8220 time: 0.0172s\n",
            "189\n",
            "Epoch: 0407 loss_train: 0.7715 acc_train: 0.8571 loss_val: 0.6813 acc_val: 0.8260 time: 0.0183s\n",
            "190\n",
            "Epoch: 0408 loss_train: 0.7408 acc_train: 0.8571 loss_val: 0.6777 acc_val: 0.8280 time: 0.0195s\n",
            "191\n",
            "Epoch: 0409 loss_train: 0.7771 acc_train: 0.8214 loss_val: 0.6773 acc_val: 0.8300 time: 0.0172s\n",
            "192\n",
            "Epoch: 0410 loss_train: 0.7756 acc_train: 0.8286 loss_val: 0.6762 acc_val: 0.8300 time: 0.0172s\n",
            "193\n",
            "Epoch: 0411 loss_train: 0.8531 acc_train: 0.8429 loss_val: 0.6756 acc_val: 0.8300 time: 0.0179s\n",
            "194\n",
            "Epoch: 0412 loss_train: 0.7653 acc_train: 0.8929 loss_val: 0.6758 acc_val: 0.8340 time: 0.0171s\n",
            "195\n",
            "Epoch: 0413 loss_train: 0.7724 acc_train: 0.8214 loss_val: 0.6775 acc_val: 0.8300 time: 0.0194s\n",
            "0\n",
            "Epoch: 0414 loss_train: 0.7454 acc_train: 0.8500 loss_val: 0.6799 acc_val: 0.8240 time: 0.0165s\n",
            "1\n",
            "Epoch: 0415 loss_train: 0.7822 acc_train: 0.8357 loss_val: 0.6825 acc_val: 0.8300 time: 0.0168s\n",
            "2\n",
            "Epoch: 0416 loss_train: 0.7689 acc_train: 0.8071 loss_val: 0.6840 acc_val: 0.8240 time: 0.0166s\n",
            "3\n",
            "Epoch: 0417 loss_train: 0.7373 acc_train: 0.8143 loss_val: 0.6851 acc_val: 0.8220 time: 0.0166s\n",
            "4\n",
            "Epoch: 0418 loss_train: 0.8343 acc_train: 0.8071 loss_val: 0.6857 acc_val: 0.8240 time: 0.0177s\n",
            "5\n",
            "Epoch: 0419 loss_train: 0.8106 acc_train: 0.8786 loss_val: 0.6859 acc_val: 0.8140 time: 0.0165s\n",
            "6\n",
            "Epoch: 0420 loss_train: 0.8164 acc_train: 0.8000 loss_val: 0.6845 acc_val: 0.8120 time: 0.0168s\n",
            "7\n",
            "Epoch: 0421 loss_train: 0.7966 acc_train: 0.7857 loss_val: 0.6817 acc_val: 0.8120 time: 0.0170s\n",
            "8\n",
            "Epoch: 0422 loss_train: 0.8128 acc_train: 0.8643 loss_val: 0.6770 acc_val: 0.8220 time: 0.0177s\n",
            "9\n",
            "Epoch: 0423 loss_train: 0.7865 acc_train: 0.8429 loss_val: 0.6731 acc_val: 0.8300 time: 0.0165s\n",
            "10\n",
            "Epoch: 0424 loss_train: 0.7934 acc_train: 0.8571 loss_val: 0.6722 acc_val: 0.8340 time: 0.0250s\n",
            "11\n",
            "Epoch: 0425 loss_train: 0.7867 acc_train: 0.8429 loss_val: 0.6733 acc_val: 0.8320 time: 0.0182s\n",
            "0\n",
            "Epoch: 0426 loss_train: 0.7933 acc_train: 0.8357 loss_val: 0.6772 acc_val: 0.8300 time: 0.0198s\n",
            "1\n",
            "Epoch: 0427 loss_train: 0.7500 acc_train: 0.8500 loss_val: 0.6797 acc_val: 0.8320 time: 0.0180s\n",
            "2\n",
            "Epoch: 0428 loss_train: 0.7561 acc_train: 0.8214 loss_val: 0.6806 acc_val: 0.8300 time: 0.0164s\n",
            "3\n",
            "Epoch: 0429 loss_train: 0.7719 acc_train: 0.8357 loss_val: 0.6823 acc_val: 0.8240 time: 0.0167s\n",
            "4\n",
            "Epoch: 0430 loss_train: 0.8186 acc_train: 0.8143 loss_val: 0.6830 acc_val: 0.8220 time: 0.0165s\n",
            "5\n",
            "Epoch: 0431 loss_train: 0.8358 acc_train: 0.8000 loss_val: 0.6820 acc_val: 0.8220 time: 0.0162s\n",
            "6\n",
            "Epoch: 0432 loss_train: 0.7787 acc_train: 0.8357 loss_val: 0.6825 acc_val: 0.8220 time: 0.0165s\n",
            "7\n",
            "Epoch: 0433 loss_train: 0.7935 acc_train: 0.8357 loss_val: 0.6792 acc_val: 0.8220 time: 0.0166s\n",
            "8\n",
            "Epoch: 0434 loss_train: 0.7755 acc_train: 0.8929 loss_val: 0.6783 acc_val: 0.8280 time: 0.0170s\n",
            "9\n",
            "Epoch: 0435 loss_train: 0.7809 acc_train: 0.8143 loss_val: 0.6778 acc_val: 0.8300 time: 0.0232s\n",
            "10\n",
            "Epoch: 0436 loss_train: 0.7721 acc_train: 0.8429 loss_val: 0.6779 acc_val: 0.8300 time: 0.0172s\n",
            "11\n",
            "Epoch: 0437 loss_train: 0.7831 acc_train: 0.8786 loss_val: 0.6787 acc_val: 0.8280 time: 0.0171s\n",
            "12\n",
            "Epoch: 0438 loss_train: 0.7634 acc_train: 0.7429 loss_val: 0.6780 acc_val: 0.8260 time: 0.0178s\n",
            "13\n",
            "Epoch: 0439 loss_train: 0.7579 acc_train: 0.8071 loss_val: 0.6779 acc_val: 0.8260 time: 0.0173s\n",
            "14\n",
            "Epoch: 0440 loss_train: 0.8044 acc_train: 0.8357 loss_val: 0.6798 acc_val: 0.8220 time: 0.0193s\n",
            "15\n",
            "Epoch: 0441 loss_train: 0.8389 acc_train: 0.7643 loss_val: 0.6835 acc_val: 0.8200 time: 0.0172s\n",
            "16\n",
            "Epoch: 0442 loss_train: 0.8027 acc_train: 0.7786 loss_val: 0.6879 acc_val: 0.8180 time: 0.0173s\n",
            "17\n",
            "Epoch: 0443 loss_train: 0.7682 acc_train: 0.8500 loss_val: 0.6907 acc_val: 0.8140 time: 0.0172s\n",
            "18\n",
            "Epoch: 0444 loss_train: 0.7689 acc_train: 0.8643 loss_val: 0.6877 acc_val: 0.8160 time: 0.0174s\n",
            "19\n",
            "Epoch: 0445 loss_train: 0.7553 acc_train: 0.8357 loss_val: 0.6812 acc_val: 0.8200 time: 0.0172s\n",
            "20\n",
            "Epoch: 0446 loss_train: 0.7635 acc_train: 0.8500 loss_val: 0.6751 acc_val: 0.8200 time: 0.0196s\n",
            "21\n",
            "Epoch: 0447 loss_train: 0.7513 acc_train: 0.8786 loss_val: 0.6711 acc_val: 0.8160 time: 0.0168s\n",
            "22\n",
            "Epoch: 0448 loss_train: 0.8139 acc_train: 0.8357 loss_val: 0.6695 acc_val: 0.8180 time: 0.0174s\n",
            "23\n",
            "Epoch: 0449 loss_train: 0.7893 acc_train: 0.8357 loss_val: 0.6700 acc_val: 0.8180 time: 0.0174s\n",
            "24\n",
            "Epoch: 0450 loss_train: 0.7994 acc_train: 0.8357 loss_val: 0.6727 acc_val: 0.8200 time: 0.0168s\n",
            "25\n",
            "Epoch: 0451 loss_train: 0.7634 acc_train: 0.8071 loss_val: 0.6770 acc_val: 0.8240 time: 0.0166s\n",
            "26\n",
            "Epoch: 0452 loss_train: 0.7895 acc_train: 0.8429 loss_val: 0.6842 acc_val: 0.8220 time: 0.0172s\n",
            "27\n",
            "Epoch: 0453 loss_train: 0.7660 acc_train: 0.8143 loss_val: 0.6903 acc_val: 0.8220 time: 0.0166s\n",
            "28\n",
            "Epoch: 0454 loss_train: 0.7447 acc_train: 0.9000 loss_val: 0.6925 acc_val: 0.8220 time: 0.0166s\n",
            "29\n",
            "Epoch: 0455 loss_train: 0.8194 acc_train: 0.8500 loss_val: 0.6923 acc_val: 0.8200 time: 0.0166s\n",
            "30\n",
            "Epoch: 0456 loss_train: 0.7557 acc_train: 0.8429 loss_val: 0.6875 acc_val: 0.8240 time: 0.0166s\n",
            "31\n",
            "Epoch: 0457 loss_train: 0.7989 acc_train: 0.8286 loss_val: 0.6827 acc_val: 0.8260 time: 0.0211s\n",
            "32\n",
            "Epoch: 0458 loss_train: 0.7957 acc_train: 0.8000 loss_val: 0.6778 acc_val: 0.8100 time: 0.0175s\n",
            "33\n",
            "Epoch: 0459 loss_train: 0.7668 acc_train: 0.8500 loss_val: 0.6752 acc_val: 0.8100 time: 0.0172s\n",
            "34\n",
            "Epoch: 0460 loss_train: 0.7855 acc_train: 0.8857 loss_val: 0.6743 acc_val: 0.8100 time: 0.0184s\n",
            "35\n",
            "Epoch: 0461 loss_train: 0.7300 acc_train: 0.8714 loss_val: 0.6749 acc_val: 0.8140 time: 0.0179s\n",
            "36\n",
            "Epoch: 0462 loss_train: 0.7491 acc_train: 0.8500 loss_val: 0.6751 acc_val: 0.8160 time: 0.0218s\n",
            "37\n",
            "Epoch: 0463 loss_train: 0.7713 acc_train: 0.8071 loss_val: 0.6783 acc_val: 0.8200 time: 0.0215s\n",
            "38\n",
            "Epoch: 0464 loss_train: 0.7629 acc_train: 0.7857 loss_val: 0.6819 acc_val: 0.8220 time: 0.0188s\n",
            "39\n",
            "Epoch: 0465 loss_train: 0.7336 acc_train: 0.8286 loss_val: 0.6854 acc_val: 0.8180 time: 0.0179s\n",
            "40\n",
            "Epoch: 0466 loss_train: 0.7800 acc_train: 0.8357 loss_val: 0.6877 acc_val: 0.8180 time: 0.0185s\n",
            "41\n",
            "Epoch: 0467 loss_train: 0.8143 acc_train: 0.8214 loss_val: 0.6885 acc_val: 0.8180 time: 0.0219s\n",
            "42\n",
            "Epoch: 0468 loss_train: 0.8104 acc_train: 0.8357 loss_val: 0.6881 acc_val: 0.8180 time: 0.0193s\n",
            "43\n",
            "Epoch: 0469 loss_train: 0.7512 acc_train: 0.8357 loss_val: 0.6875 acc_val: 0.8140 time: 0.0182s\n",
            "44\n",
            "Epoch: 0470 loss_train: 0.7482 acc_train: 0.7929 loss_val: 0.6874 acc_val: 0.8140 time: 0.0177s\n",
            "45\n",
            "Epoch: 0471 loss_train: 0.7798 acc_train: 0.8643 loss_val: 0.6862 acc_val: 0.8100 time: 0.0176s\n",
            "46\n",
            "Epoch: 0472 loss_train: 0.7713 acc_train: 0.8571 loss_val: 0.6838 acc_val: 0.8060 time: 0.0176s\n",
            "47\n",
            "Epoch: 0473 loss_train: 0.7723 acc_train: 0.8500 loss_val: 0.6823 acc_val: 0.8120 time: 0.0168s\n",
            "48\n",
            "Epoch: 0474 loss_train: 0.7805 acc_train: 0.8071 loss_val: 0.6789 acc_val: 0.8180 time: 0.0171s\n",
            "49\n",
            "Epoch: 0475 loss_train: 0.8044 acc_train: 0.8500 loss_val: 0.6754 acc_val: 0.8240 time: 0.0163s\n",
            "50\n",
            "Epoch: 0476 loss_train: 0.8110 acc_train: 0.8786 loss_val: 0.6747 acc_val: 0.8220 time: 0.0206s\n",
            "51\n",
            "Epoch: 0477 loss_train: 0.7845 acc_train: 0.8286 loss_val: 0.6752 acc_val: 0.8220 time: 0.0180s\n",
            "52\n",
            "Epoch: 0478 loss_train: 0.8573 acc_train: 0.8143 loss_val: 0.6775 acc_val: 0.8180 time: 0.0207s\n",
            "53\n",
            "Epoch: 0479 loss_train: 0.8100 acc_train: 0.8143 loss_val: 0.6798 acc_val: 0.8140 time: 0.0171s\n",
            "54\n",
            "Epoch: 0480 loss_train: 0.8505 acc_train: 0.8071 loss_val: 0.6845 acc_val: 0.8080 time: 0.0181s\n",
            "55\n",
            "Epoch: 0481 loss_train: 0.7870 acc_train: 0.8071 loss_val: 0.6894 acc_val: 0.8080 time: 0.0174s\n",
            "56\n",
            "Epoch: 0482 loss_train: 0.7434 acc_train: 0.8357 loss_val: 0.6918 acc_val: 0.8100 time: 0.0167s\n",
            "57\n",
            "Epoch: 0483 loss_train: 0.7462 acc_train: 0.8357 loss_val: 0.6911 acc_val: 0.8100 time: 0.0171s\n",
            "58\n",
            "Epoch: 0484 loss_train: 0.8007 acc_train: 0.8571 loss_val: 0.6871 acc_val: 0.8140 time: 0.0169s\n",
            "59\n",
            "Epoch: 0485 loss_train: 0.8086 acc_train: 0.8571 loss_val: 0.6819 acc_val: 0.8180 time: 0.0168s\n",
            "60\n",
            "Epoch: 0486 loss_train: 0.7624 acc_train: 0.8714 loss_val: 0.6794 acc_val: 0.8220 time: 0.0168s\n",
            "61\n",
            "Epoch: 0487 loss_train: 0.7733 acc_train: 0.8500 loss_val: 0.6774 acc_val: 0.8220 time: 0.0166s\n",
            "62\n",
            "Epoch: 0488 loss_train: 0.8198 acc_train: 0.8214 loss_val: 0.6790 acc_val: 0.8120 time: 0.0179s\n",
            "63\n",
            "Epoch: 0489 loss_train: 0.7802 acc_train: 0.8214 loss_val: 0.6819 acc_val: 0.8080 time: 0.0199s\n",
            "64\n",
            "Epoch: 0490 loss_train: 0.8065 acc_train: 0.8357 loss_val: 0.6859 acc_val: 0.8100 time: 0.0191s\n",
            "65\n",
            "Epoch: 0491 loss_train: 0.7908 acc_train: 0.7786 loss_val: 0.6889 acc_val: 0.8100 time: 0.0173s\n",
            "66\n",
            "Epoch: 0492 loss_train: 0.8081 acc_train: 0.8214 loss_val: 0.6904 acc_val: 0.8140 time: 0.0175s\n",
            "67\n",
            "Epoch: 0493 loss_train: 0.7968 acc_train: 0.8500 loss_val: 0.6902 acc_val: 0.8100 time: 0.0175s\n",
            "68\n",
            "Epoch: 0494 loss_train: 0.7940 acc_train: 0.8714 loss_val: 0.6865 acc_val: 0.8100 time: 0.0174s\n",
            "69\n",
            "Epoch: 0495 loss_train: 0.7680 acc_train: 0.8214 loss_val: 0.6810 acc_val: 0.8160 time: 0.0176s\n",
            "70\n",
            "Epoch: 0496 loss_train: 0.8388 acc_train: 0.8071 loss_val: 0.6795 acc_val: 0.8160 time: 0.0173s\n",
            "71\n",
            "Epoch: 0497 loss_train: 0.8148 acc_train: 0.7929 loss_val: 0.6806 acc_val: 0.8140 time: 0.0166s\n",
            "72\n",
            "Epoch: 0498 loss_train: 0.8089 acc_train: 0.8429 loss_val: 0.6831 acc_val: 0.8160 time: 0.0166s\n",
            "73\n",
            "Epoch: 0499 loss_train: 0.7874 acc_train: 0.8071 loss_val: 0.6857 acc_val: 0.8120 time: 0.0187s\n",
            "74\n",
            "Epoch: 0500 loss_train: 0.8180 acc_train: 0.8214 loss_val: 0.6874 acc_val: 0.8140 time: 0.0188s\n",
            "75\n",
            "Epoch: 0501 loss_train: 0.8009 acc_train: 0.8500 loss_val: 0.6881 acc_val: 0.8120 time: 0.0179s\n",
            "76\n",
            "Epoch: 0502 loss_train: 0.7887 acc_train: 0.8143 loss_val: 0.6862 acc_val: 0.8120 time: 0.0190s\n",
            "77\n",
            "Epoch: 0503 loss_train: 0.7483 acc_train: 0.8643 loss_val: 0.6838 acc_val: 0.8100 time: 0.0194s\n",
            "78\n",
            "Epoch: 0504 loss_train: 0.7722 acc_train: 0.8143 loss_val: 0.6799 acc_val: 0.8140 time: 0.0175s\n",
            "79\n",
            "Epoch: 0505 loss_train: 0.7755 acc_train: 0.8214 loss_val: 0.6773 acc_val: 0.8180 time: 0.0173s\n",
            "80\n",
            "Epoch: 0506 loss_train: 0.7428 acc_train: 0.8714 loss_val: 0.6765 acc_val: 0.8120 time: 0.0174s\n",
            "81\n",
            "Epoch: 0507 loss_train: 0.7686 acc_train: 0.7857 loss_val: 0.6771 acc_val: 0.8140 time: 0.0166s\n",
            "82\n",
            "Epoch: 0508 loss_train: 0.7608 acc_train: 0.8643 loss_val: 0.6772 acc_val: 0.8140 time: 0.0167s\n",
            "83\n",
            "Epoch: 0509 loss_train: 0.7945 acc_train: 0.7857 loss_val: 0.6750 acc_val: 0.8160 time: 0.0184s\n",
            "84\n",
            "Epoch: 0510 loss_train: 0.7650 acc_train: 0.8571 loss_val: 0.6734 acc_val: 0.8220 time: 0.0242s\n",
            "85\n",
            "Epoch: 0511 loss_train: 0.7957 acc_train: 0.8429 loss_val: 0.6738 acc_val: 0.8260 time: 0.0170s\n",
            "86\n",
            "Epoch: 0512 loss_train: 0.7617 acc_train: 0.8357 loss_val: 0.6751 acc_val: 0.8220 time: 0.0169s\n",
            "87\n",
            "Epoch: 0513 loss_train: 0.7925 acc_train: 0.7929 loss_val: 0.6761 acc_val: 0.8220 time: 0.0170s\n",
            "88\n",
            "Epoch: 0514 loss_train: 0.8064 acc_train: 0.8143 loss_val: 0.6793 acc_val: 0.8200 time: 0.0172s\n",
            "89\n",
            "Epoch: 0515 loss_train: 0.7681 acc_train: 0.8571 loss_val: 0.6853 acc_val: 0.8100 time: 0.0174s\n",
            "90\n",
            "Epoch: 0516 loss_train: 0.7457 acc_train: 0.8571 loss_val: 0.6909 acc_val: 0.8100 time: 0.0180s\n",
            "91\n",
            "Epoch: 0517 loss_train: 0.7717 acc_train: 0.8786 loss_val: 0.6980 acc_val: 0.8040 time: 0.0165s\n",
            "92\n",
            "Epoch: 0518 loss_train: 0.7748 acc_train: 0.8143 loss_val: 0.7032 acc_val: 0.8080 time: 0.0174s\n",
            "93\n",
            "Epoch: 0519 loss_train: 0.7907 acc_train: 0.8571 loss_val: 0.7028 acc_val: 0.8020 time: 0.0167s\n",
            "94\n",
            "Epoch: 0520 loss_train: 0.8323 acc_train: 0.7357 loss_val: 0.6986 acc_val: 0.8080 time: 0.0177s\n",
            "95\n",
            "Epoch: 0521 loss_train: 0.7995 acc_train: 0.8286 loss_val: 0.6912 acc_val: 0.8120 time: 0.0207s\n",
            "96\n",
            "Epoch: 0522 loss_train: 0.7379 acc_train: 0.8071 loss_val: 0.6845 acc_val: 0.8180 time: 0.0167s\n",
            "97\n",
            "Epoch: 0523 loss_train: 0.8182 acc_train: 0.8214 loss_val: 0.6800 acc_val: 0.8260 time: 0.0167s\n",
            "98\n",
            "Epoch: 0524 loss_train: 0.7514 acc_train: 0.8143 loss_val: 0.6780 acc_val: 0.8260 time: 0.0170s\n",
            "99\n",
            "Epoch: 0525 loss_train: 0.7850 acc_train: 0.8786 loss_val: 0.6752 acc_val: 0.8200 time: 0.0168s\n",
            "100\n",
            "Epoch: 0526 loss_train: 0.7696 acc_train: 0.8286 loss_val: 0.6751 acc_val: 0.8160 time: 0.0168s\n",
            "101\n",
            "Epoch: 0527 loss_train: 0.8303 acc_train: 0.8143 loss_val: 0.6773 acc_val: 0.8160 time: 0.0167s\n",
            "102\n",
            "Epoch: 0528 loss_train: 0.7622 acc_train: 0.8714 loss_val: 0.6815 acc_val: 0.8180 time: 0.0202s\n",
            "103\n",
            "Epoch: 0529 loss_train: 0.8238 acc_train: 0.8000 loss_val: 0.6888 acc_val: 0.8200 time: 0.0168s\n",
            "104\n",
            "Epoch: 0530 loss_train: 0.7771 acc_train: 0.8143 loss_val: 0.6954 acc_val: 0.8160 time: 0.0166s\n",
            "105\n",
            "Epoch: 0531 loss_train: 0.7860 acc_train: 0.8429 loss_val: 0.6975 acc_val: 0.8120 time: 0.0173s\n",
            "106\n",
            "Epoch: 0532 loss_train: 0.7868 acc_train: 0.7929 loss_val: 0.6940 acc_val: 0.8140 time: 0.0217s\n",
            "107\n",
            "Epoch: 0533 loss_train: 0.7171 acc_train: 0.8214 loss_val: 0.6897 acc_val: 0.8120 time: 0.0187s\n",
            "108\n",
            "Epoch: 0534 loss_train: 0.8635 acc_train: 0.8000 loss_val: 0.6852 acc_val: 0.8140 time: 0.0217s\n",
            "109\n",
            "Epoch: 0535 loss_train: 0.7815 acc_train: 0.8643 loss_val: 0.6822 acc_val: 0.8200 time: 0.0175s\n",
            "110\n",
            "Epoch: 0536 loss_train: 0.7855 acc_train: 0.8429 loss_val: 0.6822 acc_val: 0.8120 time: 0.0172s\n",
            "111\n",
            "Epoch: 0537 loss_train: 0.8179 acc_train: 0.8500 loss_val: 0.6824 acc_val: 0.8160 time: 0.0183s\n",
            "112\n",
            "Epoch: 0538 loss_train: 0.7691 acc_train: 0.8571 loss_val: 0.6817 acc_val: 0.8260 time: 0.0177s\n",
            "113\n",
            "Epoch: 0539 loss_train: 0.8019 acc_train: 0.8286 loss_val: 0.6821 acc_val: 0.8220 time: 0.0180s\n",
            "114\n",
            "Epoch: 0540 loss_train: 0.8219 acc_train: 0.8357 loss_val: 0.6849 acc_val: 0.8160 time: 0.0171s\n",
            "115\n",
            "Epoch: 0541 loss_train: 0.8051 acc_train: 0.8429 loss_val: 0.6911 acc_val: 0.8200 time: 0.0175s\n",
            "116\n",
            "Epoch: 0542 loss_train: 0.7134 acc_train: 0.8786 loss_val: 0.6951 acc_val: 0.8180 time: 0.0187s\n",
            "117\n",
            "Epoch: 0543 loss_train: 0.7971 acc_train: 0.8357 loss_val: 0.6983 acc_val: 0.8120 time: 0.0202s\n",
            "118\n",
            "Epoch: 0544 loss_train: 0.7945 acc_train: 0.8143 loss_val: 0.6973 acc_val: 0.8140 time: 0.0182s\n",
            "119\n",
            "Epoch: 0545 loss_train: 0.7322 acc_train: 0.8000 loss_val: 0.6908 acc_val: 0.8160 time: 0.0177s\n",
            "120\n",
            "Epoch: 0546 loss_train: 0.8289 acc_train: 0.7929 loss_val: 0.6838 acc_val: 0.8200 time: 0.0232s\n",
            "121\n",
            "Epoch: 0547 loss_train: 0.7901 acc_train: 0.8357 loss_val: 0.6761 acc_val: 0.8140 time: 0.0189s\n",
            "122\n",
            "Epoch: 0548 loss_train: 0.7391 acc_train: 0.8714 loss_val: 0.6708 acc_val: 0.8220 time: 0.0173s\n",
            "123\n",
            "Epoch: 0549 loss_train: 0.7812 acc_train: 0.8643 loss_val: 0.6697 acc_val: 0.8200 time: 0.0172s\n",
            "124\n",
            "Epoch: 0550 loss_train: 0.7759 acc_train: 0.8214 loss_val: 0.6708 acc_val: 0.8200 time: 0.0168s\n",
            "125\n",
            "Epoch: 0551 loss_train: 0.7773 acc_train: 0.7643 loss_val: 0.6733 acc_val: 0.8220 time: 0.0175s\n",
            "126\n",
            "Epoch: 0552 loss_train: 0.7519 acc_train: 0.8571 loss_val: 0.6794 acc_val: 0.8240 time: 0.0173s\n",
            "127\n",
            "Epoch: 0553 loss_train: 0.7532 acc_train: 0.8429 loss_val: 0.6870 acc_val: 0.8220 time: 0.0205s\n",
            "128\n",
            "Epoch: 0554 loss_train: 0.7093 acc_train: 0.8000 loss_val: 0.6947 acc_val: 0.8160 time: 0.0167s\n",
            "129\n",
            "Epoch: 0555 loss_train: 0.7742 acc_train: 0.8357 loss_val: 0.7008 acc_val: 0.8180 time: 0.0170s\n",
            "130\n",
            "Epoch: 0556 loss_train: 0.8151 acc_train: 0.8286 loss_val: 0.7022 acc_val: 0.8140 time: 0.0165s\n",
            "131\n",
            "Epoch: 0557 loss_train: 0.7463 acc_train: 0.8643 loss_val: 0.6998 acc_val: 0.8140 time: 0.0167s\n",
            "132\n",
            "Epoch: 0558 loss_train: 0.7685 acc_train: 0.8429 loss_val: 0.6965 acc_val: 0.8180 time: 0.0166s\n",
            "133\n",
            "Epoch: 0559 loss_train: 0.7578 acc_train: 0.8214 loss_val: 0.6909 acc_val: 0.8200 time: 0.0168s\n",
            "134\n",
            "Epoch: 0560 loss_train: 0.7583 acc_train: 0.8000 loss_val: 0.6853 acc_val: 0.8200 time: 0.0169s\n",
            "135\n",
            "Epoch: 0561 loss_train: 0.7820 acc_train: 0.8000 loss_val: 0.6837 acc_val: 0.8220 time: 0.0178s\n",
            "136\n",
            "Epoch: 0562 loss_train: 0.7762 acc_train: 0.8571 loss_val: 0.6825 acc_val: 0.8160 time: 0.0166s\n",
            "137\n",
            "Epoch: 0563 loss_train: 0.8217 acc_train: 0.8000 loss_val: 0.6815 acc_val: 0.8200 time: 0.0169s\n",
            "138\n",
            "Epoch: 0564 loss_train: 0.8173 acc_train: 0.7929 loss_val: 0.6803 acc_val: 0.8200 time: 0.0222s\n",
            "139\n",
            "Epoch: 0565 loss_train: 0.7728 acc_train: 0.8429 loss_val: 0.6802 acc_val: 0.8280 time: 0.0171s\n",
            "140\n",
            "Epoch: 0566 loss_train: 0.7966 acc_train: 0.8286 loss_val: 0.6828 acc_val: 0.8220 time: 0.0166s\n",
            "141\n",
            "Epoch: 0567 loss_train: 0.8100 acc_train: 0.8143 loss_val: 0.6870 acc_val: 0.8240 time: 0.0166s\n",
            "142\n",
            "Epoch: 0568 loss_train: 0.7892 acc_train: 0.8000 loss_val: 0.6892 acc_val: 0.8200 time: 0.0171s\n",
            "143\n",
            "Epoch: 0569 loss_train: 0.8021 acc_train: 0.8357 loss_val: 0.6894 acc_val: 0.8200 time: 0.0169s\n",
            "144\n",
            "Epoch: 0570 loss_train: 0.7664 acc_train: 0.8714 loss_val: 0.6896 acc_val: 0.8240 time: 0.0167s\n",
            "145\n",
            "Epoch: 0571 loss_train: 0.7793 acc_train: 0.8071 loss_val: 0.6907 acc_val: 0.8160 time: 0.0167s\n",
            "146\n",
            "Epoch: 0572 loss_train: 0.7685 acc_train: 0.8357 loss_val: 0.6908 acc_val: 0.8220 time: 0.0177s\n",
            "147\n",
            "Epoch: 0573 loss_train: 0.7890 acc_train: 0.8643 loss_val: 0.6888 acc_val: 0.8200 time: 0.0166s\n",
            "148\n",
            "Epoch: 0574 loss_train: 0.7655 acc_train: 0.8214 loss_val: 0.6847 acc_val: 0.8200 time: 0.0165s\n",
            "149\n",
            "Epoch: 0575 loss_train: 0.8239 acc_train: 0.8643 loss_val: 0.6829 acc_val: 0.8200 time: 0.0196s\n",
            "150\n",
            "Epoch: 0576 loss_train: 0.8120 acc_train: 0.8214 loss_val: 0.6810 acc_val: 0.8200 time: 0.0196s\n",
            "151\n",
            "Epoch: 0577 loss_train: 0.7435 acc_train: 0.8714 loss_val: 0.6795 acc_val: 0.8240 time: 0.0186s\n",
            "152\n",
            "Epoch: 0578 loss_train: 0.8171 acc_train: 0.8643 loss_val: 0.6804 acc_val: 0.8260 time: 0.0198s\n",
            "153\n",
            "Epoch: 0579 loss_train: 0.7948 acc_train: 0.8000 loss_val: 0.6811 acc_val: 0.8260 time: 0.0189s\n",
            "154\n",
            "Epoch: 0580 loss_train: 0.7610 acc_train: 0.8714 loss_val: 0.6842 acc_val: 0.8220 time: 0.0175s\n",
            "155\n",
            "Epoch: 0581 loss_train: 0.7612 acc_train: 0.8429 loss_val: 0.6875 acc_val: 0.8240 time: 0.0172s\n",
            "156\n",
            "Epoch: 0582 loss_train: 0.7602 acc_train: 0.8643 loss_val: 0.6891 acc_val: 0.8240 time: 0.0172s\n",
            "157\n",
            "Epoch: 0583 loss_train: 0.7724 acc_train: 0.8143 loss_val: 0.6896 acc_val: 0.8260 time: 0.0175s\n",
            "158\n",
            "Epoch: 0584 loss_train: 0.7258 acc_train: 0.8714 loss_val: 0.6879 acc_val: 0.8160 time: 0.0192s\n",
            "159\n",
            "Epoch: 0585 loss_train: 0.7557 acc_train: 0.8786 loss_val: 0.6857 acc_val: 0.8200 time: 0.0172s\n",
            "160\n",
            "Epoch: 0586 loss_train: 0.7910 acc_train: 0.8000 loss_val: 0.6854 acc_val: 0.8180 time: 0.0201s\n",
            "161\n",
            "Epoch: 0587 loss_train: 0.7485 acc_train: 0.8429 loss_val: 0.6850 acc_val: 0.8180 time: 0.0171s\n",
            "162\n",
            "Epoch: 0588 loss_train: 0.7722 acc_train: 0.8643 loss_val: 0.6850 acc_val: 0.8200 time: 0.0167s\n",
            "163\n",
            "Epoch: 0589 loss_train: 0.7971 acc_train: 0.8357 loss_val: 0.6841 acc_val: 0.8200 time: 0.0173s\n",
            "164\n",
            "Epoch: 0590 loss_train: 0.7417 acc_train: 0.8714 loss_val: 0.6823 acc_val: 0.8240 time: 0.0177s\n",
            "165\n",
            "Epoch: 0591 loss_train: 0.7385 acc_train: 0.8286 loss_val: 0.6793 acc_val: 0.8280 time: 0.0171s\n",
            "166\n",
            "Epoch: 0592 loss_train: 0.7637 acc_train: 0.8429 loss_val: 0.6795 acc_val: 0.8300 time: 0.0173s\n",
            "167\n",
            "Epoch: 0593 loss_train: 0.8161 acc_train: 0.7786 loss_val: 0.6819 acc_val: 0.8260 time: 0.0172s\n",
            "168\n",
            "Epoch: 0594 loss_train: 0.7826 acc_train: 0.8000 loss_val: 0.6830 acc_val: 0.8260 time: 0.0175s\n",
            "169\n",
            "Epoch: 0595 loss_train: 0.7995 acc_train: 0.7786 loss_val: 0.6849 acc_val: 0.8260 time: 0.0170s\n",
            "170\n",
            "Epoch: 0596 loss_train: 0.7263 acc_train: 0.8500 loss_val: 0.6861 acc_val: 0.8240 time: 0.0171s\n",
            "171\n",
            "Epoch: 0597 loss_train: 0.8240 acc_train: 0.8571 loss_val: 0.6877 acc_val: 0.8180 time: 0.0198s\n",
            "172\n",
            "Epoch: 0598 loss_train: 0.7496 acc_train: 0.8429 loss_val: 0.6886 acc_val: 0.8160 time: 0.0172s\n",
            "173\n",
            "Epoch: 0599 loss_train: 0.8033 acc_train: 0.8929 loss_val: 0.6871 acc_val: 0.8220 time: 0.0178s\n",
            "174\n",
            "Epoch: 0600 loss_train: 0.8057 acc_train: 0.8571 loss_val: 0.6866 acc_val: 0.8260 time: 0.0173s\n",
            "175\n",
            "Epoch: 0601 loss_train: 0.7973 acc_train: 0.8500 loss_val: 0.6846 acc_val: 0.8240 time: 0.0172s\n",
            "176\n",
            "Epoch: 0602 loss_train: 0.7628 acc_train: 0.8500 loss_val: 0.6829 acc_val: 0.8220 time: 0.0178s\n",
            "177\n",
            "Epoch: 0603 loss_train: 0.7902 acc_train: 0.8429 loss_val: 0.6828 acc_val: 0.8200 time: 0.0172s\n",
            "178\n",
            "Epoch: 0604 loss_train: 0.7980 acc_train: 0.8786 loss_val: 0.6822 acc_val: 0.8220 time: 0.0172s\n",
            "179\n",
            "Epoch: 0605 loss_train: 0.7918 acc_train: 0.7286 loss_val: 0.6823 acc_val: 0.8220 time: 0.0173s\n",
            "180\n",
            "Epoch: 0606 loss_train: 0.7533 acc_train: 0.8500 loss_val: 0.6817 acc_val: 0.8200 time: 0.0175s\n",
            "181\n",
            "Epoch: 0607 loss_train: 0.8203 acc_train: 0.8429 loss_val: 0.6821 acc_val: 0.8180 time: 0.0167s\n",
            "182\n",
            "Epoch: 0608 loss_train: 0.8070 acc_train: 0.8071 loss_val: 0.6821 acc_val: 0.8200 time: 0.0190s\n",
            "183\n",
            "Epoch: 0609 loss_train: 0.7574 acc_train: 0.8500 loss_val: 0.6824 acc_val: 0.8220 time: 0.0191s\n",
            "184\n",
            "Epoch: 0610 loss_train: 0.7621 acc_train: 0.8643 loss_val: 0.6840 acc_val: 0.8180 time: 0.0174s\n",
            "185\n",
            "Epoch: 0611 loss_train: 0.7529 acc_train: 0.8571 loss_val: 0.6843 acc_val: 0.8160 time: 0.0172s\n",
            "186\n",
            "Epoch: 0612 loss_train: 0.7886 acc_train: 0.7786 loss_val: 0.6846 acc_val: 0.8220 time: 0.0171s\n",
            "187\n",
            "Epoch: 0613 loss_train: 0.7777 acc_train: 0.8500 loss_val: 0.6851 acc_val: 0.8180 time: 0.0169s\n",
            "188\n",
            "Epoch: 0614 loss_train: 0.8011 acc_train: 0.8714 loss_val: 0.6850 acc_val: 0.8220 time: 0.0176s\n",
            "189\n",
            "Epoch: 0615 loss_train: 0.7557 acc_train: 0.8286 loss_val: 0.6839 acc_val: 0.8200 time: 0.0168s\n",
            "190\n",
            "Epoch: 0616 loss_train: 0.8341 acc_train: 0.7857 loss_val: 0.6832 acc_val: 0.8240 time: 0.0170s\n",
            "191\n",
            "Epoch: 0617 loss_train: 0.7311 acc_train: 0.8000 loss_val: 0.6822 acc_val: 0.8180 time: 0.0172s\n",
            "192\n",
            "Epoch: 0618 loss_train: 0.7879 acc_train: 0.8571 loss_val: 0.6831 acc_val: 0.8180 time: 0.0165s\n",
            "193\n",
            "Epoch: 0619 loss_train: 0.7891 acc_train: 0.8643 loss_val: 0.6829 acc_val: 0.8180 time: 0.0188s\n",
            "194\n",
            "Epoch: 0620 loss_train: 0.8338 acc_train: 0.8571 loss_val: 0.6854 acc_val: 0.8220 time: 0.0214s\n",
            "195\n",
            "Epoch: 0621 loss_train: 0.7896 acc_train: 0.7929 loss_val: 0.6875 acc_val: 0.8140 time: 0.0170s\n",
            "196\n",
            "Epoch: 0622 loss_train: 0.7744 acc_train: 0.8286 loss_val: 0.6887 acc_val: 0.8140 time: 0.0175s\n",
            "197\n",
            "Epoch: 0623 loss_train: 0.7786 acc_train: 0.8929 loss_val: 0.6875 acc_val: 0.8180 time: 0.0180s\n",
            "198\n",
            "Epoch: 0624 loss_train: 0.7862 acc_train: 0.8071 loss_val: 0.6841 acc_val: 0.8200 time: 0.0172s\n",
            "199\n",
            "Early stop! Min loss:  0.6587629318237305 , Max accuracy:  0.834\n",
            "Early stop model validation loss:  0.6587629318237305 , accuracy:  0.8260000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 12.3687s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6190 accuracy= 0.8530\n",
            "Epoch: 0001 loss_train: 0.7833 acc_train: 0.8143 loss_val: 0.6619 acc_val: 0.8320 time: 0.0213s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.7975 acc_train: 0.8500 loss_val: 0.6676 acc_val: 0.8320 time: 0.0199s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8048 acc_train: 0.7857 loss_val: 0.6751 acc_val: 0.8280 time: 0.0203s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.8077 acc_train: 0.8571 loss_val: 0.6841 acc_val: 0.8260 time: 0.0206s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.7923 acc_train: 0.8786 loss_val: 0.6914 acc_val: 0.8140 time: 0.0274s\n",
            "2\n",
            "Epoch: 0006 loss_train: 0.8329 acc_train: 0.7929 loss_val: 0.6962 acc_val: 0.8120 time: 0.0202s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.8229 acc_train: 0.8143 loss_val: 0.6974 acc_val: 0.8120 time: 0.0196s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.7900 acc_train: 0.8500 loss_val: 0.6932 acc_val: 0.8200 time: 0.0196s\n",
            "5\n",
            "Epoch: 0009 loss_train: 0.8437 acc_train: 0.8429 loss_val: 0.6898 acc_val: 0.8220 time: 0.0197s\n",
            "6\n",
            "Epoch: 0010 loss_train: 0.8449 acc_train: 0.8286 loss_val: 0.6869 acc_val: 0.8240 time: 0.0196s\n",
            "7\n",
            "Epoch: 0011 loss_train: 0.7974 acc_train: 0.8643 loss_val: 0.6868 acc_val: 0.8260 time: 0.0196s\n",
            "8\n",
            "Epoch: 0012 loss_train: 0.7592 acc_train: 0.8643 loss_val: 0.6869 acc_val: 0.8260 time: 0.0196s\n",
            "9\n",
            "Epoch: 0013 loss_train: 0.7879 acc_train: 0.8214 loss_val: 0.6880 acc_val: 0.8240 time: 0.0195s\n",
            "10\n",
            "Epoch: 0014 loss_train: 0.8066 acc_train: 0.8571 loss_val: 0.6876 acc_val: 0.8300 time: 0.0198s\n",
            "11\n",
            "Epoch: 0015 loss_train: 0.8423 acc_train: 0.8071 loss_val: 0.6886 acc_val: 0.8240 time: 0.0224s\n",
            "12\n",
            "Epoch: 0016 loss_train: 0.7683 acc_train: 0.8429 loss_val: 0.6901 acc_val: 0.8240 time: 0.0197s\n",
            "13\n",
            "Epoch: 0017 loss_train: 0.8381 acc_train: 0.8357 loss_val: 0.6909 acc_val: 0.8260 time: 0.0198s\n",
            "14\n",
            "Epoch: 0018 loss_train: 0.8224 acc_train: 0.8214 loss_val: 0.6901 acc_val: 0.8200 time: 0.0199s\n",
            "15\n",
            "Epoch: 0019 loss_train: 0.8049 acc_train: 0.8214 loss_val: 0.6884 acc_val: 0.8240 time: 0.0235s\n",
            "16\n",
            "Epoch: 0020 loss_train: 0.8263 acc_train: 0.8500 loss_val: 0.6905 acc_val: 0.8220 time: 0.0198s\n",
            "17\n",
            "Epoch: 0021 loss_train: 0.8144 acc_train: 0.7786 loss_val: 0.6915 acc_val: 0.8220 time: 0.0198s\n",
            "18\n",
            "Epoch: 0022 loss_train: 0.8246 acc_train: 0.8571 loss_val: 0.6905 acc_val: 0.8160 time: 0.0194s\n",
            "19\n",
            "Epoch: 0023 loss_train: 0.7828 acc_train: 0.8286 loss_val: 0.6923 acc_val: 0.8140 time: 0.0207s\n",
            "20\n",
            "Epoch: 0024 loss_train: 0.7598 acc_train: 0.8786 loss_val: 0.6943 acc_val: 0.8160 time: 0.0204s\n",
            "21\n",
            "Epoch: 0025 loss_train: 0.7641 acc_train: 0.7857 loss_val: 0.6947 acc_val: 0.8180 time: 0.0234s\n",
            "22\n",
            "Epoch: 0026 loss_train: 0.7772 acc_train: 0.8571 loss_val: 0.6927 acc_val: 0.8180 time: 0.0197s\n",
            "23\n",
            "Epoch: 0027 loss_train: 0.8505 acc_train: 0.8286 loss_val: 0.6902 acc_val: 0.8220 time: 0.0207s\n",
            "24\n",
            "Epoch: 0028 loss_train: 0.8425 acc_train: 0.8500 loss_val: 0.6905 acc_val: 0.8200 time: 0.0197s\n",
            "25\n",
            "Epoch: 0029 loss_train: 0.7820 acc_train: 0.8786 loss_val: 0.6907 acc_val: 0.8200 time: 0.0270s\n",
            "26\n",
            "Epoch: 0030 loss_train: 0.7669 acc_train: 0.9071 loss_val: 0.6931 acc_val: 0.8200 time: 0.0221s\n",
            "27\n",
            "Epoch: 0031 loss_train: 0.8310 acc_train: 0.8714 loss_val: 0.6930 acc_val: 0.8200 time: 0.0205s\n",
            "28\n",
            "Epoch: 0032 loss_train: 0.8252 acc_train: 0.8071 loss_val: 0.6925 acc_val: 0.8220 time: 0.0204s\n",
            "29\n",
            "Epoch: 0033 loss_train: 0.8048 acc_train: 0.8000 loss_val: 0.6979 acc_val: 0.8220 time: 0.0204s\n",
            "30\n",
            "Epoch: 0034 loss_train: 0.7521 acc_train: 0.8429 loss_val: 0.7037 acc_val: 0.8180 time: 0.0278s\n",
            "31\n",
            "Epoch: 0035 loss_train: 0.8092 acc_train: 0.8643 loss_val: 0.7038 acc_val: 0.8160 time: 0.0207s\n",
            "32\n",
            "Epoch: 0036 loss_train: 0.8049 acc_train: 0.8000 loss_val: 0.7015 acc_val: 0.8160 time: 0.0204s\n",
            "33\n",
            "Epoch: 0037 loss_train: 0.7972 acc_train: 0.8286 loss_val: 0.6963 acc_val: 0.8160 time: 0.0201s\n",
            "34\n",
            "Epoch: 0038 loss_train: 0.7815 acc_train: 0.8000 loss_val: 0.6922 acc_val: 0.8180 time: 0.0204s\n",
            "35\n",
            "Epoch: 0039 loss_train: 0.8394 acc_train: 0.8143 loss_val: 0.6940 acc_val: 0.8200 time: 0.0219s\n",
            "36\n",
            "Epoch: 0040 loss_train: 0.7605 acc_train: 0.8286 loss_val: 0.6969 acc_val: 0.8240 time: 0.0206s\n",
            "37\n",
            "Epoch: 0041 loss_train: 0.7938 acc_train: 0.8286 loss_val: 0.6961 acc_val: 0.8300 time: 0.0210s\n",
            "38\n",
            "Epoch: 0042 loss_train: 0.7650 acc_train: 0.8357 loss_val: 0.6942 acc_val: 0.8320 time: 0.0208s\n",
            "39\n",
            "Epoch: 0043 loss_train: 0.8032 acc_train: 0.8000 loss_val: 0.6902 acc_val: 0.8280 time: 0.0213s\n",
            "0\n",
            "Epoch: 0044 loss_train: 0.8092 acc_train: 0.8214 loss_val: 0.6845 acc_val: 0.8320 time: 0.0255s\n",
            "1\n",
            "Epoch: 0045 loss_train: 0.7907 acc_train: 0.8214 loss_val: 0.6796 acc_val: 0.8260 time: 0.0197s\n",
            "0\n",
            "Epoch: 0046 loss_train: 0.7946 acc_train: 0.8571 loss_val: 0.6775 acc_val: 0.8260 time: 0.0197s\n",
            "1\n",
            "Epoch: 0047 loss_train: 0.8022 acc_train: 0.8357 loss_val: 0.6823 acc_val: 0.8300 time: 0.0195s\n",
            "2\n",
            "Epoch: 0048 loss_train: 0.7511 acc_train: 0.8357 loss_val: 0.6880 acc_val: 0.8280 time: 0.0196s\n",
            "3\n",
            "Epoch: 0049 loss_train: 0.7973 acc_train: 0.8571 loss_val: 0.6969 acc_val: 0.8320 time: 0.0215s\n",
            "4\n",
            "Epoch: 0050 loss_train: 0.8164 acc_train: 0.8500 loss_val: 0.7013 acc_val: 0.8240 time: 0.0196s\n",
            "0\n",
            "Epoch: 0051 loss_train: 0.7862 acc_train: 0.8643 loss_val: 0.7026 acc_val: 0.8200 time: 0.0199s\n",
            "1\n",
            "Epoch: 0052 loss_train: 0.7528 acc_train: 0.8429 loss_val: 0.6976 acc_val: 0.8220 time: 0.0197s\n",
            "2\n",
            "Epoch: 0053 loss_train: 0.8527 acc_train: 0.8357 loss_val: 0.6914 acc_val: 0.8260 time: 0.0242s\n",
            "3\n",
            "Epoch: 0054 loss_train: 0.7944 acc_train: 0.8643 loss_val: 0.6871 acc_val: 0.8280 time: 0.0210s\n",
            "4\n",
            "Epoch: 0055 loss_train: 0.7957 acc_train: 0.8286 loss_val: 0.6825 acc_val: 0.8300 time: 0.0204s\n",
            "5\n",
            "Epoch: 0056 loss_train: 0.8555 acc_train: 0.8071 loss_val: 0.6812 acc_val: 0.8340 time: 0.0203s\n",
            "6\n",
            "Epoch: 0057 loss_train: 0.8691 acc_train: 0.8571 loss_val: 0.6831 acc_val: 0.8340 time: 0.0212s\n",
            "0\n",
            "Epoch: 0058 loss_train: 0.8197 acc_train: 0.8000 loss_val: 0.6848 acc_val: 0.8340 time: 0.0204s\n",
            "0\n",
            "Epoch: 0059 loss_train: 0.7734 acc_train: 0.8500 loss_val: 0.6868 acc_val: 0.8340 time: 0.0205s\n",
            "0\n",
            "Epoch: 0060 loss_train: 0.7995 acc_train: 0.8286 loss_val: 0.6877 acc_val: 0.8320 time: 0.0203s\n",
            "0\n",
            "Epoch: 0061 loss_train: 0.8122 acc_train: 0.8571 loss_val: 0.6906 acc_val: 0.8280 time: 0.0203s\n",
            "1\n",
            "Epoch: 0062 loss_train: 0.7936 acc_train: 0.8000 loss_val: 0.6954 acc_val: 0.8260 time: 0.0268s\n",
            "2\n",
            "Epoch: 0063 loss_train: 0.7654 acc_train: 0.8500 loss_val: 0.6956 acc_val: 0.8260 time: 0.0215s\n",
            "3\n",
            "Epoch: 0064 loss_train: 0.8122 acc_train: 0.8714 loss_val: 0.6939 acc_val: 0.8200 time: 0.0195s\n",
            "4\n",
            "Epoch: 0065 loss_train: 0.7872 acc_train: 0.8143 loss_val: 0.6917 acc_val: 0.8200 time: 0.0196s\n",
            "5\n",
            "Epoch: 0066 loss_train: 0.8140 acc_train: 0.8500 loss_val: 0.6916 acc_val: 0.8220 time: 0.0210s\n",
            "6\n",
            "Epoch: 0067 loss_train: 0.7666 acc_train: 0.8000 loss_val: 0.6909 acc_val: 0.8220 time: 0.0242s\n",
            "7\n",
            "Epoch: 0068 loss_train: 0.8379 acc_train: 0.8214 loss_val: 0.6890 acc_val: 0.8280 time: 0.0219s\n",
            "8\n",
            "Epoch: 0069 loss_train: 0.7922 acc_train: 0.8143 loss_val: 0.6885 acc_val: 0.8280 time: 0.0198s\n",
            "9\n",
            "Epoch: 0070 loss_train: 0.7741 acc_train: 0.8286 loss_val: 0.6868 acc_val: 0.8300 time: 0.0198s\n",
            "10\n",
            "Epoch: 0071 loss_train: 0.8052 acc_train: 0.8214 loss_val: 0.6851 acc_val: 0.8280 time: 0.0196s\n",
            "11\n",
            "Epoch: 0072 loss_train: 0.7994 acc_train: 0.8143 loss_val: 0.6842 acc_val: 0.8240 time: 0.0219s\n",
            "12\n",
            "Epoch: 0073 loss_train: 0.8426 acc_train: 0.7643 loss_val: 0.6850 acc_val: 0.8240 time: 0.0207s\n",
            "13\n",
            "Epoch: 0074 loss_train: 0.8299 acc_train: 0.8214 loss_val: 0.6858 acc_val: 0.8240 time: 0.0197s\n",
            "14\n",
            "Epoch: 0075 loss_train: 0.7957 acc_train: 0.7929 loss_val: 0.6856 acc_val: 0.8280 time: 0.0197s\n",
            "15\n",
            "Epoch: 0076 loss_train: 0.7429 acc_train: 0.8571 loss_val: 0.6825 acc_val: 0.8260 time: 0.0196s\n",
            "16\n",
            "Epoch: 0077 loss_train: 0.8118 acc_train: 0.8929 loss_val: 0.6816 acc_val: 0.8260 time: 0.0196s\n",
            "17\n",
            "Epoch: 0078 loss_train: 0.7906 acc_train: 0.8286 loss_val: 0.6840 acc_val: 0.8240 time: 0.0196s\n",
            "18\n",
            "Epoch: 0079 loss_train: 0.7838 acc_train: 0.8429 loss_val: 0.6866 acc_val: 0.8220 time: 0.0197s\n",
            "19\n",
            "Epoch: 0080 loss_train: 0.7750 acc_train: 0.8286 loss_val: 0.6900 acc_val: 0.8180 time: 0.0216s\n",
            "20\n",
            "Epoch: 0081 loss_train: 0.8149 acc_train: 0.8214 loss_val: 0.6910 acc_val: 0.8160 time: 0.0228s\n",
            "21\n",
            "Epoch: 0082 loss_train: 0.7518 acc_train: 0.8643 loss_val: 0.6958 acc_val: 0.8160 time: 0.0244s\n",
            "22\n",
            "Epoch: 0083 loss_train: 0.8470 acc_train: 0.7643 loss_val: 0.7018 acc_val: 0.8140 time: 0.0208s\n",
            "23\n",
            "Epoch: 0084 loss_train: 0.7648 acc_train: 0.8643 loss_val: 0.7043 acc_val: 0.8140 time: 0.0214s\n",
            "24\n",
            "Epoch: 0085 loss_train: 0.7754 acc_train: 0.8214 loss_val: 0.7023 acc_val: 0.8140 time: 0.0203s\n",
            "25\n",
            "Epoch: 0086 loss_train: 0.8346 acc_train: 0.8286 loss_val: 0.6972 acc_val: 0.8140 time: 0.0203s\n",
            "26\n",
            "Epoch: 0087 loss_train: 0.8058 acc_train: 0.8429 loss_val: 0.6919 acc_val: 0.8180 time: 0.0206s\n",
            "27\n",
            "Epoch: 0088 loss_train: 0.8564 acc_train: 0.8429 loss_val: 0.6876 acc_val: 0.8260 time: 0.0208s\n",
            "28\n",
            "Epoch: 0089 loss_train: 0.7680 acc_train: 0.8357 loss_val: 0.6852 acc_val: 0.8260 time: 0.0210s\n",
            "29\n",
            "Epoch: 0090 loss_train: 0.7779 acc_train: 0.8500 loss_val: 0.6847 acc_val: 0.8300 time: 0.0238s\n",
            "30\n",
            "Epoch: 0091 loss_train: 0.8209 acc_train: 0.8286 loss_val: 0.6860 acc_val: 0.8240 time: 0.0221s\n",
            "31\n",
            "Epoch: 0092 loss_train: 0.8097 acc_train: 0.8500 loss_val: 0.6886 acc_val: 0.8220 time: 0.0210s\n",
            "32\n",
            "Epoch: 0093 loss_train: 0.7907 acc_train: 0.8143 loss_val: 0.6915 acc_val: 0.8180 time: 0.0215s\n",
            "33\n",
            "Epoch: 0094 loss_train: 0.7677 acc_train: 0.8357 loss_val: 0.6946 acc_val: 0.8140 time: 0.0211s\n",
            "34\n",
            "Epoch: 0095 loss_train: 0.8264 acc_train: 0.8500 loss_val: 0.6978 acc_val: 0.8120 time: 0.0195s\n",
            "35\n",
            "Epoch: 0096 loss_train: 0.7738 acc_train: 0.8429 loss_val: 0.6966 acc_val: 0.8140 time: 0.0219s\n",
            "36\n",
            "Epoch: 0097 loss_train: 0.7816 acc_train: 0.8429 loss_val: 0.6939 acc_val: 0.8100 time: 0.0200s\n",
            "37\n",
            "Epoch: 0098 loss_train: 0.7392 acc_train: 0.8857 loss_val: 0.6889 acc_val: 0.8220 time: 0.0199s\n",
            "38\n",
            "Epoch: 0099 loss_train: 0.8026 acc_train: 0.8143 loss_val: 0.6854 acc_val: 0.8200 time: 0.0224s\n",
            "39\n",
            "Epoch: 0100 loss_train: 0.8530 acc_train: 0.8000 loss_val: 0.6843 acc_val: 0.8160 time: 0.0215s\n",
            "40\n",
            "Epoch: 0101 loss_train: 0.8043 acc_train: 0.8286 loss_val: 0.6871 acc_val: 0.8200 time: 0.0196s\n",
            "41\n",
            "Epoch: 0102 loss_train: 0.8378 acc_train: 0.8500 loss_val: 0.6933 acc_val: 0.8220 time: 0.0196s\n",
            "42\n",
            "Epoch: 0103 loss_train: 0.7638 acc_train: 0.8357 loss_val: 0.7020 acc_val: 0.8160 time: 0.0195s\n",
            "43\n",
            "Epoch: 0104 loss_train: 0.8372 acc_train: 0.8357 loss_val: 0.7098 acc_val: 0.8200 time: 0.0196s\n",
            "44\n",
            "Epoch: 0105 loss_train: 0.7990 acc_train: 0.8286 loss_val: 0.7143 acc_val: 0.8080 time: 0.0211s\n",
            "45\n",
            "Epoch: 0106 loss_train: 0.7670 acc_train: 0.8857 loss_val: 0.7104 acc_val: 0.8080 time: 0.0221s\n",
            "46\n",
            "Epoch: 0107 loss_train: 0.7215 acc_train: 0.8214 loss_val: 0.7007 acc_val: 0.8140 time: 0.0209s\n",
            "47\n",
            "Epoch: 0108 loss_train: 0.8056 acc_train: 0.8571 loss_val: 0.6891 acc_val: 0.8200 time: 0.0196s\n",
            "48\n",
            "Epoch: 0109 loss_train: 0.7923 acc_train: 0.8357 loss_val: 0.6818 acc_val: 0.8280 time: 0.0226s\n",
            "49\n",
            "Epoch: 0110 loss_train: 0.7743 acc_train: 0.8429 loss_val: 0.6767 acc_val: 0.8200 time: 0.0203s\n",
            "50\n",
            "Epoch: 0111 loss_train: 0.8260 acc_train: 0.7929 loss_val: 0.6772 acc_val: 0.8220 time: 0.0215s\n",
            "51\n",
            "Epoch: 0112 loss_train: 0.7973 acc_train: 0.8357 loss_val: 0.6828 acc_val: 0.8220 time: 0.0211s\n",
            "52\n",
            "Epoch: 0113 loss_train: 0.8071 acc_train: 0.8143 loss_val: 0.6898 acc_val: 0.8200 time: 0.0202s\n",
            "53\n",
            "Epoch: 0114 loss_train: 0.8342 acc_train: 0.7643 loss_val: 0.6962 acc_val: 0.8140 time: 0.0203s\n",
            "54\n",
            "Epoch: 0115 loss_train: 0.7874 acc_train: 0.8929 loss_val: 0.6977 acc_val: 0.8120 time: 0.0201s\n",
            "55\n",
            "Epoch: 0116 loss_train: 0.7461 acc_train: 0.8857 loss_val: 0.6956 acc_val: 0.8200 time: 0.0202s\n",
            "56\n",
            "Epoch: 0117 loss_train: 0.7668 acc_train: 0.8429 loss_val: 0.6944 acc_val: 0.8200 time: 0.0204s\n",
            "57\n",
            "Epoch: 0118 loss_train: 0.7917 acc_train: 0.8357 loss_val: 0.6933 acc_val: 0.8200 time: 0.0252s\n",
            "58\n",
            "Epoch: 0119 loss_train: 0.8347 acc_train: 0.8000 loss_val: 0.6900 acc_val: 0.8220 time: 0.0224s\n",
            "59\n",
            "Epoch: 0120 loss_train: 0.8220 acc_train: 0.8286 loss_val: 0.6883 acc_val: 0.8180 time: 0.0213s\n",
            "60\n",
            "Epoch: 0121 loss_train: 0.8017 acc_train: 0.8571 loss_val: 0.6852 acc_val: 0.8220 time: 0.0201s\n",
            "61\n",
            "Epoch: 0122 loss_train: 0.8113 acc_train: 0.8571 loss_val: 0.6833 acc_val: 0.8260 time: 0.0210s\n",
            "62\n",
            "Epoch: 0123 loss_train: 0.8119 acc_train: 0.8000 loss_val: 0.6848 acc_val: 0.8280 time: 0.0207s\n",
            "63\n",
            "Epoch: 0124 loss_train: 0.7974 acc_train: 0.8143 loss_val: 0.6870 acc_val: 0.8260 time: 0.0202s\n",
            "64\n",
            "Epoch: 0125 loss_train: 0.7853 acc_train: 0.8286 loss_val: 0.6901 acc_val: 0.8280 time: 0.0198s\n",
            "65\n",
            "Epoch: 0126 loss_train: 0.8104 acc_train: 0.8214 loss_val: 0.6941 acc_val: 0.8200 time: 0.0195s\n",
            "66\n",
            "Epoch: 0127 loss_train: 0.7686 acc_train: 0.7929 loss_val: 0.6952 acc_val: 0.8200 time: 0.0199s\n",
            "67\n",
            "Epoch: 0128 loss_train: 0.8141 acc_train: 0.8214 loss_val: 0.6963 acc_val: 0.8260 time: 0.0231s\n",
            "68\n",
            "Epoch: 0129 loss_train: 0.8321 acc_train: 0.7929 loss_val: 0.6965 acc_val: 0.8200 time: 0.0209s\n",
            "69\n",
            "Epoch: 0130 loss_train: 0.7842 acc_train: 0.8214 loss_val: 0.6949 acc_val: 0.8220 time: 0.0194s\n",
            "70\n",
            "Epoch: 0131 loss_train: 0.8047 acc_train: 0.8500 loss_val: 0.6938 acc_val: 0.8200 time: 0.0207s\n",
            "71\n",
            "Epoch: 0132 loss_train: 0.8624 acc_train: 0.8071 loss_val: 0.6931 acc_val: 0.8200 time: 0.0197s\n",
            "72\n",
            "Epoch: 0133 loss_train: 0.8373 acc_train: 0.8714 loss_val: 0.6905 acc_val: 0.8240 time: 0.0197s\n",
            "73\n",
            "Epoch: 0134 loss_train: 0.8103 acc_train: 0.8071 loss_val: 0.6895 acc_val: 0.8260 time: 0.0194s\n",
            "74\n",
            "Epoch: 0135 loss_train: 0.7990 acc_train: 0.8714 loss_val: 0.6877 acc_val: 0.8260 time: 0.0194s\n",
            "75\n",
            "Epoch: 0136 loss_train: 0.8374 acc_train: 0.7714 loss_val: 0.6860 acc_val: 0.8260 time: 0.0215s\n",
            "76\n",
            "Epoch: 0137 loss_train: 0.7673 acc_train: 0.8714 loss_val: 0.6849 acc_val: 0.8220 time: 0.0235s\n",
            "77\n",
            "Epoch: 0138 loss_train: 0.7986 acc_train: 0.8429 loss_val: 0.6844 acc_val: 0.8260 time: 0.0230s\n",
            "78\n",
            "Epoch: 0139 loss_train: 0.8005 acc_train: 0.8500 loss_val: 0.6854 acc_val: 0.8280 time: 0.0195s\n",
            "79\n",
            "Epoch: 0140 loss_train: 0.8329 acc_train: 0.8571 loss_val: 0.6896 acc_val: 0.8260 time: 0.0197s\n",
            "80\n",
            "Epoch: 0141 loss_train: 0.7703 acc_train: 0.8429 loss_val: 0.6924 acc_val: 0.8260 time: 0.0209s\n",
            "81\n",
            "Epoch: 0142 loss_train: 0.7794 acc_train: 0.8500 loss_val: 0.6921 acc_val: 0.8240 time: 0.0196s\n",
            "82\n",
            "Epoch: 0143 loss_train: 0.8062 acc_train: 0.7929 loss_val: 0.6894 acc_val: 0.8220 time: 0.0194s\n",
            "83\n",
            "Epoch: 0144 loss_train: 0.8402 acc_train: 0.8000 loss_val: 0.6865 acc_val: 0.8260 time: 0.0217s\n",
            "84\n",
            "Epoch: 0145 loss_train: 0.7972 acc_train: 0.7929 loss_val: 0.6823 acc_val: 0.8300 time: 0.0196s\n",
            "85\n",
            "Epoch: 0146 loss_train: 0.7537 acc_train: 0.8643 loss_val: 0.6794 acc_val: 0.8300 time: 0.0196s\n",
            "86\n",
            "Epoch: 0147 loss_train: 0.7861 acc_train: 0.8214 loss_val: 0.6776 acc_val: 0.8200 time: 0.0277s\n",
            "87\n",
            "Epoch: 0148 loss_train: 0.7589 acc_train: 0.8429 loss_val: 0.6773 acc_val: 0.8200 time: 0.0195s\n",
            "88\n",
            "Epoch: 0149 loss_train: 0.7647 acc_train: 0.8071 loss_val: 0.6804 acc_val: 0.8200 time: 0.0199s\n",
            "89\n",
            "Epoch: 0150 loss_train: 0.7999 acc_train: 0.8000 loss_val: 0.6838 acc_val: 0.8220 time: 0.0207s\n",
            "90\n",
            "Epoch: 0151 loss_train: 0.7331 acc_train: 0.9000 loss_val: 0.6897 acc_val: 0.8220 time: 0.0196s\n",
            "91\n",
            "Epoch: 0152 loss_train: 0.8255 acc_train: 0.8643 loss_val: 0.6935 acc_val: 0.8160 time: 0.0198s\n",
            "92\n",
            "Epoch: 0153 loss_train: 0.8185 acc_train: 0.8357 loss_val: 0.6941 acc_val: 0.8200 time: 0.0208s\n",
            "93\n",
            "Epoch: 0154 loss_train: 0.8102 acc_train: 0.8143 loss_val: 0.6948 acc_val: 0.8200 time: 0.0203s\n",
            "94\n",
            "Epoch: 0155 loss_train: 0.8207 acc_train: 0.7929 loss_val: 0.6957 acc_val: 0.8200 time: 0.0210s\n",
            "95\n",
            "Epoch: 0156 loss_train: 0.8331 acc_train: 0.8357 loss_val: 0.6957 acc_val: 0.8240 time: 0.0195s\n",
            "96\n",
            "Epoch: 0157 loss_train: 0.7779 acc_train: 0.8357 loss_val: 0.6949 acc_val: 0.8260 time: 0.0222s\n",
            "97\n",
            "Epoch: 0158 loss_train: 0.8055 acc_train: 0.8500 loss_val: 0.6950 acc_val: 0.8240 time: 0.0217s\n",
            "98\n",
            "Epoch: 0159 loss_train: 0.8236 acc_train: 0.7929 loss_val: 0.6943 acc_val: 0.8240 time: 0.0202s\n",
            "99\n",
            "Epoch: 0160 loss_train: 0.8052 acc_train: 0.8357 loss_val: 0.6935 acc_val: 0.8320 time: 0.0203s\n",
            "100\n",
            "Epoch: 0161 loss_train: 0.8343 acc_train: 0.8286 loss_val: 0.6921 acc_val: 0.8340 time: 0.0204s\n",
            "101\n",
            "Epoch: 0162 loss_train: 0.8259 acc_train: 0.8643 loss_val: 0.6893 acc_val: 0.8320 time: 0.0219s\n",
            "0\n",
            "Epoch: 0163 loss_train: 0.7817 acc_train: 0.7929 loss_val: 0.6866 acc_val: 0.8220 time: 0.0205s\n",
            "1\n",
            "Epoch: 0164 loss_train: 0.7724 acc_train: 0.8286 loss_val: 0.6850 acc_val: 0.8220 time: 0.0201s\n",
            "2\n",
            "Epoch: 0165 loss_train: 0.7939 acc_train: 0.8143 loss_val: 0.6854 acc_val: 0.8160 time: 0.0209s\n",
            "3\n",
            "Epoch: 0166 loss_train: 0.8232 acc_train: 0.8214 loss_val: 0.6880 acc_val: 0.8220 time: 0.0227s\n",
            "4\n",
            "Epoch: 0167 loss_train: 0.7733 acc_train: 0.8643 loss_val: 0.6879 acc_val: 0.8180 time: 0.0202s\n",
            "5\n",
            "Epoch: 0168 loss_train: 0.7952 acc_train: 0.8500 loss_val: 0.6881 acc_val: 0.8200 time: 0.0201s\n",
            "6\n",
            "Epoch: 0169 loss_train: 0.8192 acc_train: 0.8143 loss_val: 0.6893 acc_val: 0.8120 time: 0.0224s\n",
            "7\n",
            "Epoch: 0170 loss_train: 0.7655 acc_train: 0.8000 loss_val: 0.6894 acc_val: 0.8180 time: 0.0220s\n",
            "8\n",
            "Epoch: 0171 loss_train: 0.7631 acc_train: 0.8643 loss_val: 0.6851 acc_val: 0.8220 time: 0.0199s\n",
            "9\n",
            "Epoch: 0172 loss_train: 0.8023 acc_train: 0.9000 loss_val: 0.6809 acc_val: 0.8260 time: 0.0195s\n",
            "10\n",
            "Epoch: 0173 loss_train: 0.8112 acc_train: 0.8429 loss_val: 0.6781 acc_val: 0.8320 time: 0.0195s\n",
            "11\n",
            "Epoch: 0174 loss_train: 0.7413 acc_train: 0.8429 loss_val: 0.6756 acc_val: 0.8320 time: 0.0202s\n",
            "12\n",
            "Epoch: 0175 loss_train: 0.8061 acc_train: 0.8143 loss_val: 0.6756 acc_val: 0.8240 time: 0.0195s\n",
            "13\n",
            "Epoch: 0176 loss_train: 0.7818 acc_train: 0.8357 loss_val: 0.6803 acc_val: 0.8200 time: 0.0255s\n",
            "14\n",
            "Epoch: 0177 loss_train: 0.7891 acc_train: 0.8429 loss_val: 0.6840 acc_val: 0.8120 time: 0.0211s\n",
            "15\n",
            "Epoch: 0178 loss_train: 0.7336 acc_train: 0.8857 loss_val: 0.6896 acc_val: 0.8140 time: 0.0207s\n",
            "16\n",
            "Epoch: 0179 loss_train: 0.7444 acc_train: 0.8714 loss_val: 0.6940 acc_val: 0.8160 time: 0.0205s\n",
            "17\n",
            "Epoch: 0180 loss_train: 0.8251 acc_train: 0.8071 loss_val: 0.6971 acc_val: 0.8160 time: 0.0202s\n",
            "18\n",
            "Epoch: 0181 loss_train: 0.7583 acc_train: 0.8714 loss_val: 0.6968 acc_val: 0.8120 time: 0.0199s\n",
            "19\n",
            "Epoch: 0182 loss_train: 0.7778 acc_train: 0.8357 loss_val: 0.6927 acc_val: 0.8100 time: 0.0217s\n",
            "20\n",
            "Epoch: 0183 loss_train: 0.8056 acc_train: 0.8143 loss_val: 0.6854 acc_val: 0.8180 time: 0.0196s\n",
            "21\n",
            "Epoch: 0184 loss_train: 0.8299 acc_train: 0.7929 loss_val: 0.6785 acc_val: 0.8280 time: 0.0197s\n",
            "22\n",
            "Epoch: 0185 loss_train: 0.8044 acc_train: 0.8643 loss_val: 0.6733 acc_val: 0.8300 time: 0.0227s\n",
            "23\n",
            "Epoch: 0186 loss_train: 0.8374 acc_train: 0.8214 loss_val: 0.6721 acc_val: 0.8220 time: 0.0196s\n",
            "24\n",
            "Epoch: 0187 loss_train: 0.7241 acc_train: 0.8143 loss_val: 0.6726 acc_val: 0.8160 time: 0.0197s\n",
            "25\n",
            "Epoch: 0188 loss_train: 0.8066 acc_train: 0.7714 loss_val: 0.6765 acc_val: 0.8160 time: 0.0195s\n",
            "26\n",
            "Epoch: 0189 loss_train: 0.8279 acc_train: 0.7714 loss_val: 0.6823 acc_val: 0.8140 time: 0.0212s\n",
            "27\n",
            "Epoch: 0190 loss_train: 0.7882 acc_train: 0.8286 loss_val: 0.6884 acc_val: 0.8140 time: 0.0195s\n",
            "28\n",
            "Epoch: 0191 loss_train: 0.7755 acc_train: 0.8000 loss_val: 0.6933 acc_val: 0.8120 time: 0.0200s\n",
            "29\n",
            "Epoch: 0192 loss_train: 0.7664 acc_train: 0.8286 loss_val: 0.6974 acc_val: 0.8180 time: 0.0195s\n",
            "30\n",
            "Epoch: 0193 loss_train: 0.8614 acc_train: 0.8357 loss_val: 0.6952 acc_val: 0.8180 time: 0.0195s\n",
            "31\n",
            "Epoch: 0194 loss_train: 0.8142 acc_train: 0.8143 loss_val: 0.6906 acc_val: 0.8180 time: 0.0198s\n",
            "32\n",
            "Epoch: 0195 loss_train: 0.7987 acc_train: 0.8214 loss_val: 0.6880 acc_val: 0.8220 time: 0.0209s\n",
            "33\n",
            "Epoch: 0196 loss_train: 0.8325 acc_train: 0.8286 loss_val: 0.6856 acc_val: 0.8240 time: 0.0200s\n",
            "34\n",
            "Epoch: 0197 loss_train: 0.8084 acc_train: 0.8714 loss_val: 0.6828 acc_val: 0.8260 time: 0.0213s\n",
            "35\n",
            "Epoch: 0198 loss_train: 0.7939 acc_train: 0.7857 loss_val: 0.6825 acc_val: 0.8260 time: 0.0216s\n",
            "36\n",
            "Epoch: 0199 loss_train: 0.8596 acc_train: 0.8286 loss_val: 0.6856 acc_val: 0.8200 time: 0.0202s\n",
            "37\n",
            "Epoch: 0200 loss_train: 0.7758 acc_train: 0.8786 loss_val: 0.6877 acc_val: 0.8180 time: 0.0191s\n",
            "38\n",
            "Epoch: 0201 loss_train: 0.8092 acc_train: 0.8643 loss_val: 0.6908 acc_val: 0.8160 time: 0.0195s\n",
            "39\n",
            "Epoch: 0202 loss_train: 0.8009 acc_train: 0.7929 loss_val: 0.6920 acc_val: 0.8140 time: 0.0197s\n",
            "40\n",
            "Epoch: 0203 loss_train: 0.8139 acc_train: 0.8286 loss_val: 0.6907 acc_val: 0.8160 time: 0.0196s\n",
            "41\n",
            "Epoch: 0204 loss_train: 0.7862 acc_train: 0.8429 loss_val: 0.6887 acc_val: 0.8200 time: 0.0252s\n",
            "42\n",
            "Epoch: 0205 loss_train: 0.8146 acc_train: 0.8214 loss_val: 0.6859 acc_val: 0.8220 time: 0.0198s\n",
            "43\n",
            "Epoch: 0206 loss_train: 0.7267 acc_train: 0.9000 loss_val: 0.6833 acc_val: 0.8260 time: 0.0205s\n",
            "44\n",
            "Epoch: 0207 loss_train: 0.8299 acc_train: 0.8143 loss_val: 0.6820 acc_val: 0.8260 time: 0.0197s\n",
            "45\n",
            "Epoch: 0208 loss_train: 0.7886 acc_train: 0.7714 loss_val: 0.6821 acc_val: 0.8300 time: 0.0197s\n",
            "46\n",
            "Epoch: 0209 loss_train: 0.8188 acc_train: 0.8357 loss_val: 0.6830 acc_val: 0.8300 time: 0.0198s\n",
            "47\n",
            "Epoch: 0210 loss_train: 0.7676 acc_train: 0.8571 loss_val: 0.6861 acc_val: 0.8300 time: 0.0199s\n",
            "48\n",
            "Epoch: 0211 loss_train: 0.8024 acc_train: 0.7929 loss_val: 0.6903 acc_val: 0.8260 time: 0.0206s\n",
            "49\n",
            "Epoch: 0212 loss_train: 0.8350 acc_train: 0.8214 loss_val: 0.6962 acc_val: 0.8220 time: 0.0197s\n",
            "50\n",
            "Epoch: 0213 loss_train: 0.7899 acc_train: 0.8643 loss_val: 0.7005 acc_val: 0.8180 time: 0.0196s\n",
            "51\n",
            "Epoch: 0214 loss_train: 0.8030 acc_train: 0.8571 loss_val: 0.7047 acc_val: 0.8140 time: 0.0219s\n",
            "52\n",
            "Epoch: 0215 loss_train: 0.7669 acc_train: 0.8214 loss_val: 0.7058 acc_val: 0.8160 time: 0.0204s\n",
            "53\n",
            "Epoch: 0216 loss_train: 0.8495 acc_train: 0.8143 loss_val: 0.7056 acc_val: 0.8140 time: 0.0206s\n",
            "54\n",
            "Epoch: 0217 loss_train: 0.8226 acc_train: 0.8143 loss_val: 0.7009 acc_val: 0.8140 time: 0.0213s\n",
            "55\n",
            "Epoch: 0218 loss_train: 0.8712 acc_train: 0.7857 loss_val: 0.6930 acc_val: 0.8240 time: 0.0204s\n",
            "56\n",
            "Epoch: 0219 loss_train: 0.8448 acc_train: 0.7714 loss_val: 0.6875 acc_val: 0.8260 time: 0.0202s\n",
            "57\n",
            "Epoch: 0220 loss_train: 0.8205 acc_train: 0.8071 loss_val: 0.6858 acc_val: 0.8280 time: 0.0207s\n",
            "58\n",
            "Epoch: 0221 loss_train: 0.8024 acc_train: 0.8214 loss_val: 0.6855 acc_val: 0.8280 time: 0.0203s\n",
            "59\n",
            "Epoch: 0222 loss_train: 0.8085 acc_train: 0.8857 loss_val: 0.6866 acc_val: 0.8280 time: 0.0202s\n",
            "60\n",
            "Epoch: 0223 loss_train: 0.8130 acc_train: 0.8357 loss_val: 0.6871 acc_val: 0.8280 time: 0.0237s\n",
            "61\n",
            "Epoch: 0224 loss_train: 0.7744 acc_train: 0.8714 loss_val: 0.6873 acc_val: 0.8300 time: 0.0198s\n",
            "62\n",
            "Epoch: 0225 loss_train: 0.7989 acc_train: 0.7857 loss_val: 0.6881 acc_val: 0.8240 time: 0.0214s\n",
            "63\n",
            "Epoch: 0226 loss_train: 0.8124 acc_train: 0.8571 loss_val: 0.6900 acc_val: 0.8140 time: 0.0208s\n",
            "64\n",
            "Epoch: 0227 loss_train: 0.7879 acc_train: 0.7857 loss_val: 0.6913 acc_val: 0.8080 time: 0.0217s\n",
            "65\n",
            "Epoch: 0228 loss_train: 0.8232 acc_train: 0.8357 loss_val: 0.6926 acc_val: 0.8080 time: 0.0202s\n",
            "66\n",
            "Epoch: 0229 loss_train: 0.8243 acc_train: 0.8071 loss_val: 0.6912 acc_val: 0.8140 time: 0.0205s\n",
            "67\n",
            "Epoch: 0230 loss_train: 0.7970 acc_train: 0.7929 loss_val: 0.6901 acc_val: 0.8180 time: 0.0197s\n",
            "68\n",
            "Epoch: 0231 loss_train: 0.8130 acc_train: 0.8214 loss_val: 0.6888 acc_val: 0.8200 time: 0.0204s\n",
            "69\n",
            "Epoch: 0232 loss_train: 0.7412 acc_train: 0.8429 loss_val: 0.6883 acc_val: 0.8260 time: 0.0203s\n",
            "70\n",
            "Epoch: 0233 loss_train: 0.7840 acc_train: 0.8429 loss_val: 0.6884 acc_val: 0.8220 time: 0.0228s\n",
            "71\n",
            "Epoch: 0234 loss_train: 0.7646 acc_train: 0.8500 loss_val: 0.6883 acc_val: 0.8240 time: 0.0200s\n",
            "72\n",
            "Epoch: 0235 loss_train: 0.8134 acc_train: 0.8143 loss_val: 0.6884 acc_val: 0.8240 time: 0.0196s\n",
            "73\n",
            "Epoch: 0236 loss_train: 0.8019 acc_train: 0.8071 loss_val: 0.6899 acc_val: 0.8240 time: 0.0197s\n",
            "74\n",
            "Epoch: 0237 loss_train: 0.7619 acc_train: 0.8643 loss_val: 0.6897 acc_val: 0.8260 time: 0.0199s\n",
            "75\n",
            "Epoch: 0238 loss_train: 0.8239 acc_train: 0.8143 loss_val: 0.6901 acc_val: 0.8240 time: 0.0196s\n",
            "76\n",
            "Epoch: 0239 loss_train: 0.8060 acc_train: 0.8429 loss_val: 0.6905 acc_val: 0.8180 time: 0.0200s\n",
            "77\n",
            "Epoch: 0240 loss_train: 0.7744 acc_train: 0.8643 loss_val: 0.6922 acc_val: 0.8200 time: 0.0195s\n",
            "78\n",
            "Epoch: 0241 loss_train: 0.7692 acc_train: 0.9000 loss_val: 0.6921 acc_val: 0.8160 time: 0.0196s\n",
            "79\n",
            "Epoch: 0242 loss_train: 0.7982 acc_train: 0.8571 loss_val: 0.6905 acc_val: 0.8160 time: 0.0252s\n",
            "80\n",
            "Epoch: 0243 loss_train: 0.7984 acc_train: 0.7929 loss_val: 0.6877 acc_val: 0.8180 time: 0.0211s\n",
            "81\n",
            "Epoch: 0244 loss_train: 0.7761 acc_train: 0.8214 loss_val: 0.6827 acc_val: 0.8200 time: 0.0226s\n",
            "82\n",
            "Epoch: 0245 loss_train: 0.7824 acc_train: 0.8214 loss_val: 0.6790 acc_val: 0.8220 time: 0.0203s\n",
            "83\n",
            "Epoch: 0246 loss_train: 0.7873 acc_train: 0.8357 loss_val: 0.6778 acc_val: 0.8260 time: 0.0210s\n",
            "84\n",
            "Epoch: 0247 loss_train: 0.8172 acc_train: 0.8286 loss_val: 0.6818 acc_val: 0.8280 time: 0.0204s\n",
            "85\n",
            "Epoch: 0248 loss_train: 0.8551 acc_train: 0.8214 loss_val: 0.6856 acc_val: 0.8300 time: 0.0202s\n",
            "86\n",
            "Epoch: 0249 loss_train: 0.7749 acc_train: 0.8429 loss_val: 0.6899 acc_val: 0.8240 time: 0.0198s\n",
            "87\n",
            "Epoch: 0250 loss_train: 0.7774 acc_train: 0.8571 loss_val: 0.6926 acc_val: 0.8220 time: 0.0203s\n",
            "88\n",
            "Epoch: 0251 loss_train: 0.8064 acc_train: 0.8357 loss_val: 0.6946 acc_val: 0.8160 time: 0.0226s\n",
            "89\n",
            "Epoch: 0252 loss_train: 0.8560 acc_train: 0.7857 loss_val: 0.6985 acc_val: 0.8140 time: 0.0220s\n",
            "90\n",
            "Epoch: 0253 loss_train: 0.7858 acc_train: 0.8286 loss_val: 0.6985 acc_val: 0.8220 time: 0.0196s\n",
            "91\n",
            "Epoch: 0254 loss_train: 0.8287 acc_train: 0.8286 loss_val: 0.6984 acc_val: 0.8160 time: 0.0215s\n",
            "92\n",
            "Epoch: 0255 loss_train: 0.7922 acc_train: 0.8286 loss_val: 0.6988 acc_val: 0.8160 time: 0.0199s\n",
            "93\n",
            "Epoch: 0256 loss_train: 0.7828 acc_train: 0.8286 loss_val: 0.6972 acc_val: 0.8160 time: 0.0197s\n",
            "94\n",
            "Epoch: 0257 loss_train: 0.7981 acc_train: 0.8714 loss_val: 0.6952 acc_val: 0.8120 time: 0.0194s\n",
            "95\n",
            "Epoch: 0258 loss_train: 0.8029 acc_train: 0.8143 loss_val: 0.6924 acc_val: 0.8140 time: 0.0196s\n",
            "96\n",
            "Epoch: 0259 loss_train: 0.7751 acc_train: 0.8286 loss_val: 0.6897 acc_val: 0.8220 time: 0.0196s\n",
            "97\n",
            "Epoch: 0260 loss_train: 0.8525 acc_train: 0.8000 loss_val: 0.6885 acc_val: 0.8220 time: 0.0198s\n",
            "98\n",
            "Epoch: 0261 loss_train: 0.8452 acc_train: 0.8000 loss_val: 0.6882 acc_val: 0.8180 time: 0.0235s\n",
            "99\n",
            "Epoch: 0262 loss_train: 0.7735 acc_train: 0.8286 loss_val: 0.6868 acc_val: 0.8200 time: 0.0199s\n",
            "100\n",
            "Epoch: 0263 loss_train: 0.8008 acc_train: 0.8143 loss_val: 0.6855 acc_val: 0.8240 time: 0.0198s\n",
            "101\n",
            "Epoch: 0264 loss_train: 0.7783 acc_train: 0.8071 loss_val: 0.6820 acc_val: 0.8260 time: 0.0199s\n",
            "102\n",
            "Epoch: 0265 loss_train: 0.7949 acc_train: 0.8429 loss_val: 0.6807 acc_val: 0.8200 time: 0.0202s\n",
            "103\n",
            "Epoch: 0266 loss_train: 0.8358 acc_train: 0.8000 loss_val: 0.6827 acc_val: 0.8240 time: 0.0196s\n",
            "104\n",
            "Epoch: 0267 loss_train: 0.8437 acc_train: 0.8429 loss_val: 0.6851 acc_val: 0.8200 time: 0.0196s\n",
            "105\n",
            "Epoch: 0268 loss_train: 0.7706 acc_train: 0.8929 loss_val: 0.6863 acc_val: 0.8200 time: 0.0197s\n",
            "106\n",
            "Epoch: 0269 loss_train: 0.7814 acc_train: 0.8286 loss_val: 0.6888 acc_val: 0.8140 time: 0.0201s\n",
            "107\n",
            "Epoch: 0270 loss_train: 0.8272 acc_train: 0.8143 loss_val: 0.6931 acc_val: 0.8100 time: 0.0195s\n",
            "108\n",
            "Epoch: 0271 loss_train: 0.7917 acc_train: 0.8714 loss_val: 0.6958 acc_val: 0.8140 time: 0.0232s\n",
            "109\n",
            "Epoch: 0272 loss_train: 0.7701 acc_train: 0.8286 loss_val: 0.6966 acc_val: 0.8180 time: 0.0209s\n",
            "110\n",
            "Epoch: 0273 loss_train: 0.7969 acc_train: 0.8357 loss_val: 0.6953 acc_val: 0.8160 time: 0.0200s\n",
            "111\n",
            "Epoch: 0274 loss_train: 0.7764 acc_train: 0.8357 loss_val: 0.6942 acc_val: 0.8160 time: 0.0195s\n",
            "112\n",
            "Epoch: 0275 loss_train: 0.8322 acc_train: 0.8286 loss_val: 0.6897 acc_val: 0.8180 time: 0.0196s\n",
            "113\n",
            "Epoch: 0276 loss_train: 0.7990 acc_train: 0.8500 loss_val: 0.6833 acc_val: 0.8180 time: 0.0195s\n",
            "114\n",
            "Epoch: 0277 loss_train: 0.8168 acc_train: 0.8357 loss_val: 0.6803 acc_val: 0.8160 time: 0.0196s\n",
            "115\n",
            "Epoch: 0278 loss_train: 0.7977 acc_train: 0.8357 loss_val: 0.6794 acc_val: 0.8220 time: 0.0198s\n",
            "116\n",
            "Epoch: 0279 loss_train: 0.8132 acc_train: 0.8500 loss_val: 0.6800 acc_val: 0.8140 time: 0.0196s\n",
            "117\n",
            "Epoch: 0280 loss_train: 0.7616 acc_train: 0.8500 loss_val: 0.6846 acc_val: 0.8160 time: 0.0194s\n",
            "118\n",
            "Epoch: 0281 loss_train: 0.7940 acc_train: 0.8429 loss_val: 0.6899 acc_val: 0.8100 time: 0.0228s\n",
            "119\n",
            "Epoch: 0282 loss_train: 0.7897 acc_train: 0.8357 loss_val: 0.6937 acc_val: 0.8120 time: 0.0206s\n",
            "120\n",
            "Epoch: 0283 loss_train: 0.7883 acc_train: 0.8643 loss_val: 0.6939 acc_val: 0.8140 time: 0.0210s\n",
            "121\n",
            "Epoch: 0284 loss_train: 0.7885 acc_train: 0.8214 loss_val: 0.6915 acc_val: 0.8140 time: 0.0210s\n",
            "122\n",
            "Epoch: 0285 loss_train: 0.8101 acc_train: 0.8143 loss_val: 0.6896 acc_val: 0.8160 time: 0.0233s\n",
            "123\n",
            "Epoch: 0286 loss_train: 0.8227 acc_train: 0.8000 loss_val: 0.6868 acc_val: 0.8180 time: 0.0207s\n",
            "124\n",
            "Epoch: 0287 loss_train: 0.8079 acc_train: 0.8286 loss_val: 0.6876 acc_val: 0.8220 time: 0.0216s\n",
            "125\n",
            "Epoch: 0288 loss_train: 0.7893 acc_train: 0.8214 loss_val: 0.6882 acc_val: 0.8200 time: 0.0205s\n",
            "126\n",
            "Epoch: 0289 loss_train: 0.8078 acc_train: 0.8071 loss_val: 0.6874 acc_val: 0.8200 time: 0.0207s\n",
            "127\n",
            "Epoch: 0290 loss_train: 0.8050 acc_train: 0.8500 loss_val: 0.6853 acc_val: 0.8180 time: 0.0272s\n",
            "128\n",
            "Epoch: 0291 loss_train: 0.8135 acc_train: 0.8143 loss_val: 0.6844 acc_val: 0.8220 time: 0.0209s\n",
            "129\n",
            "Epoch: 0292 loss_train: 0.7638 acc_train: 0.8714 loss_val: 0.6852 acc_val: 0.8200 time: 0.0212s\n",
            "130\n",
            "Epoch: 0293 loss_train: 0.8132 acc_train: 0.8357 loss_val: 0.6883 acc_val: 0.8080 time: 0.0203s\n",
            "131\n",
            "Epoch: 0294 loss_train: 0.7908 acc_train: 0.8143 loss_val: 0.6901 acc_val: 0.8100 time: 0.0205s\n",
            "132\n",
            "Epoch: 0295 loss_train: 0.7630 acc_train: 0.8286 loss_val: 0.6930 acc_val: 0.8100 time: 0.0204s\n",
            "133\n",
            "Epoch: 0296 loss_train: 0.7653 acc_train: 0.8786 loss_val: 0.6962 acc_val: 0.8080 time: 0.0204s\n",
            "134\n",
            "Epoch: 0297 loss_train: 0.8228 acc_train: 0.7857 loss_val: 0.6959 acc_val: 0.8080 time: 0.0201s\n",
            "135\n",
            "Epoch: 0298 loss_train: 0.7499 acc_train: 0.8500 loss_val: 0.6929 acc_val: 0.8100 time: 0.0203s\n",
            "136\n",
            "Epoch: 0299 loss_train: 0.8247 acc_train: 0.8000 loss_val: 0.6917 acc_val: 0.8100 time: 0.0294s\n",
            "137\n",
            "Epoch: 0300 loss_train: 0.7625 acc_train: 0.8214 loss_val: 0.6903 acc_val: 0.8060 time: 0.0204s\n",
            "138\n",
            "Epoch: 0301 loss_train: 0.8352 acc_train: 0.8000 loss_val: 0.6886 acc_val: 0.8080 time: 0.0204s\n",
            "139\n",
            "Epoch: 0302 loss_train: 0.8213 acc_train: 0.8357 loss_val: 0.6865 acc_val: 0.8100 time: 0.0215s\n",
            "140\n",
            "Epoch: 0303 loss_train: 0.8137 acc_train: 0.7929 loss_val: 0.6853 acc_val: 0.8140 time: 0.0208s\n",
            "141\n",
            "Epoch: 0304 loss_train: 0.8197 acc_train: 0.7857 loss_val: 0.6848 acc_val: 0.8160 time: 0.0216s\n",
            "142\n",
            "Epoch: 0305 loss_train: 0.8100 acc_train: 0.8286 loss_val: 0.6863 acc_val: 0.8200 time: 0.0217s\n",
            "143\n",
            "Epoch: 0306 loss_train: 0.7802 acc_train: 0.8643 loss_val: 0.6875 acc_val: 0.8180 time: 0.0201s\n",
            "144\n",
            "Epoch: 0307 loss_train: 0.8289 acc_train: 0.7786 loss_val: 0.6902 acc_val: 0.8140 time: 0.0196s\n",
            "145\n",
            "Epoch: 0308 loss_train: 0.8230 acc_train: 0.9000 loss_val: 0.6925 acc_val: 0.8060 time: 0.0220s\n",
            "146\n",
            "Epoch: 0309 loss_train: 0.8147 acc_train: 0.7857 loss_val: 0.6919 acc_val: 0.8100 time: 0.0206s\n",
            "147\n",
            "Epoch: 0310 loss_train: 0.7978 acc_train: 0.8143 loss_val: 0.6914 acc_val: 0.8100 time: 0.0196s\n",
            "148\n",
            "Epoch: 0311 loss_train: 0.7952 acc_train: 0.8214 loss_val: 0.6911 acc_val: 0.8120 time: 0.0199s\n",
            "149\n",
            "Epoch: 0312 loss_train: 0.7755 acc_train: 0.8286 loss_val: 0.6910 acc_val: 0.8140 time: 0.0200s\n",
            "150\n",
            "Epoch: 0313 loss_train: 0.8126 acc_train: 0.7857 loss_val: 0.6917 acc_val: 0.8160 time: 0.0196s\n",
            "151\n",
            "Epoch: 0314 loss_train: 0.7853 acc_train: 0.8500 loss_val: 0.6930 acc_val: 0.8160 time: 0.0196s\n",
            "152\n",
            "Epoch: 0315 loss_train: 0.8356 acc_train: 0.7929 loss_val: 0.6946 acc_val: 0.8200 time: 0.0228s\n",
            "153\n",
            "Epoch: 0316 loss_train: 0.7957 acc_train: 0.8071 loss_val: 0.6971 acc_val: 0.8140 time: 0.0219s\n",
            "154\n",
            "Epoch: 0317 loss_train: 0.7663 acc_train: 0.8643 loss_val: 0.6967 acc_val: 0.8140 time: 0.0203s\n",
            "155\n",
            "Epoch: 0318 loss_train: 0.8061 acc_train: 0.8286 loss_val: 0.6954 acc_val: 0.8100 time: 0.0218s\n",
            "156\n",
            "Epoch: 0319 loss_train: 0.8229 acc_train: 0.7929 loss_val: 0.6936 acc_val: 0.8100 time: 0.0197s\n",
            "157\n",
            "Epoch: 0320 loss_train: 0.7437 acc_train: 0.8500 loss_val: 0.6900 acc_val: 0.8100 time: 0.0195s\n",
            "158\n",
            "Epoch: 0321 loss_train: 0.8150 acc_train: 0.8714 loss_val: 0.6874 acc_val: 0.8120 time: 0.0209s\n",
            "159\n",
            "Epoch: 0322 loss_train: 0.7847 acc_train: 0.7857 loss_val: 0.6873 acc_val: 0.8100 time: 0.0196s\n",
            "160\n",
            "Epoch: 0323 loss_train: 0.8016 acc_train: 0.7929 loss_val: 0.6872 acc_val: 0.8120 time: 0.0205s\n",
            "161\n",
            "Epoch: 0324 loss_train: 0.8152 acc_train: 0.8286 loss_val: 0.6855 acc_val: 0.8100 time: 0.0196s\n",
            "162\n",
            "Epoch: 0325 loss_train: 0.7727 acc_train: 0.8500 loss_val: 0.6833 acc_val: 0.8180 time: 0.0194s\n",
            "163\n",
            "Epoch: 0326 loss_train: 0.8434 acc_train: 0.8286 loss_val: 0.6823 acc_val: 0.8200 time: 0.0202s\n",
            "164\n",
            "Epoch: 0327 loss_train: 0.7964 acc_train: 0.8714 loss_val: 0.6839 acc_val: 0.8240 time: 0.0249s\n",
            "165\n",
            "Epoch: 0328 loss_train: 0.7941 acc_train: 0.8429 loss_val: 0.6865 acc_val: 0.8240 time: 0.0244s\n",
            "166\n",
            "Epoch: 0329 loss_train: 0.7232 acc_train: 0.8429 loss_val: 0.6899 acc_val: 0.8220 time: 0.0220s\n",
            "167\n",
            "Epoch: 0330 loss_train: 0.8050 acc_train: 0.8143 loss_val: 0.6951 acc_val: 0.8220 time: 0.0209s\n",
            "168\n",
            "Epoch: 0331 loss_train: 0.7844 acc_train: 0.8643 loss_val: 0.6990 acc_val: 0.8160 time: 0.0211s\n",
            "169\n",
            "Epoch: 0332 loss_train: 0.8868 acc_train: 0.7786 loss_val: 0.7006 acc_val: 0.8140 time: 0.0205s\n",
            "170\n",
            "Epoch: 0333 loss_train: 0.7958 acc_train: 0.8357 loss_val: 0.7002 acc_val: 0.8120 time: 0.0206s\n",
            "171\n",
            "Epoch: 0334 loss_train: 0.8625 acc_train: 0.8571 loss_val: 0.6970 acc_val: 0.8120 time: 0.0206s\n",
            "172\n",
            "Epoch: 0335 loss_train: 0.8046 acc_train: 0.8571 loss_val: 0.6938 acc_val: 0.8120 time: 0.0205s\n",
            "173\n",
            "Epoch: 0336 loss_train: 0.7876 acc_train: 0.8643 loss_val: 0.6916 acc_val: 0.8200 time: 0.0256s\n",
            "174\n",
            "Epoch: 0337 loss_train: 0.7733 acc_train: 0.8286 loss_val: 0.6889 acc_val: 0.8180 time: 0.0204s\n",
            "175\n",
            "Epoch: 0338 loss_train: 0.7704 acc_train: 0.8571 loss_val: 0.6874 acc_val: 0.8180 time: 0.0203s\n",
            "176\n",
            "Epoch: 0339 loss_train: 0.7798 acc_train: 0.8286 loss_val: 0.6855 acc_val: 0.8180 time: 0.0202s\n",
            "177\n",
            "Epoch: 0340 loss_train: 0.7699 acc_train: 0.8500 loss_val: 0.6849 acc_val: 0.8220 time: 0.0208s\n",
            "178\n",
            "Epoch: 0341 loss_train: 0.7990 acc_train: 0.8143 loss_val: 0.6842 acc_val: 0.8220 time: 0.0203s\n",
            "179\n",
            "Epoch: 0342 loss_train: 0.8132 acc_train: 0.8857 loss_val: 0.6883 acc_val: 0.8200 time: 0.0204s\n",
            "180\n",
            "Epoch: 0343 loss_train: 0.7894 acc_train: 0.8143 loss_val: 0.6942 acc_val: 0.8200 time: 0.0201s\n",
            "181\n",
            "Epoch: 0344 loss_train: 0.7660 acc_train: 0.8286 loss_val: 0.7009 acc_val: 0.8140 time: 0.0200s\n",
            "182\n",
            "Epoch: 0345 loss_train: 0.8143 acc_train: 0.8643 loss_val: 0.7050 acc_val: 0.8120 time: 0.0207s\n",
            "183\n",
            "Epoch: 0346 loss_train: 0.8032 acc_train: 0.8643 loss_val: 0.7078 acc_val: 0.8120 time: 0.0270s\n",
            "184\n",
            "Epoch: 0347 loss_train: 0.8404 acc_train: 0.8357 loss_val: 0.7081 acc_val: 0.8100 time: 0.0203s\n",
            "185\n",
            "Epoch: 0348 loss_train: 0.7516 acc_train: 0.8000 loss_val: 0.7045 acc_val: 0.8140 time: 0.0208s\n",
            "186\n",
            "Epoch: 0349 loss_train: 0.8162 acc_train: 0.7929 loss_val: 0.6977 acc_val: 0.8160 time: 0.0209s\n",
            "187\n",
            "Epoch: 0350 loss_train: 0.7789 acc_train: 0.7929 loss_val: 0.6918 acc_val: 0.8200 time: 0.0219s\n",
            "188\n",
            "Epoch: 0351 loss_train: 0.7815 acc_train: 0.8071 loss_val: 0.6882 acc_val: 0.8200 time: 0.0207s\n",
            "189\n",
            "Epoch: 0352 loss_train: 0.7749 acc_train: 0.8286 loss_val: 0.6855 acc_val: 0.8220 time: 0.0203s\n",
            "190\n",
            "Epoch: 0353 loss_train: 0.8247 acc_train: 0.8071 loss_val: 0.6857 acc_val: 0.8200 time: 0.0199s\n",
            "191\n",
            "Epoch: 0354 loss_train: 0.8055 acc_train: 0.8143 loss_val: 0.6874 acc_val: 0.8200 time: 0.0195s\n",
            "192\n",
            "Epoch: 0355 loss_train: 0.8040 acc_train: 0.8714 loss_val: 0.6949 acc_val: 0.8160 time: 0.0246s\n",
            "193\n",
            "Epoch: 0356 loss_train: 0.7877 acc_train: 0.8429 loss_val: 0.7010 acc_val: 0.8120 time: 0.0197s\n",
            "194\n",
            "Epoch: 0357 loss_train: 0.8345 acc_train: 0.7929 loss_val: 0.7041 acc_val: 0.8120 time: 0.0196s\n",
            "195\n",
            "Epoch: 0358 loss_train: 0.7997 acc_train: 0.8000 loss_val: 0.7092 acc_val: 0.8140 time: 0.0196s\n",
            "196\n",
            "Epoch: 0359 loss_train: 0.7725 acc_train: 0.8643 loss_val: 0.7114 acc_val: 0.8120 time: 0.0233s\n",
            "197\n",
            "Epoch: 0360 loss_train: 0.7794 acc_train: 0.8214 loss_val: 0.7070 acc_val: 0.8120 time: 0.0262s\n",
            "198\n",
            "Epoch: 0361 loss_train: 0.8343 acc_train: 0.8214 loss_val: 0.6998 acc_val: 0.8120 time: 0.0197s\n",
            "199\n",
            "Early stop! Min loss:  0.6619359254837036 , Max accuracy:  0.834\n",
            "Early stop model validation loss:  0.6619359254837036 , accuracy:  0.8320000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 8.2585s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6220 accuracy= 0.8540\n",
            "Epoch: 0001 loss_train: 0.8395 acc_train: 0.8071 loss_val: 0.6668 acc_val: 0.8300 time: 0.0232s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8509 acc_train: 0.8000 loss_val: 0.6729 acc_val: 0.8300 time: 0.0291s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8286 acc_train: 0.8286 loss_val: 0.6808 acc_val: 0.8340 time: 0.0225s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.8375 acc_train: 0.7786 loss_val: 0.6902 acc_val: 0.8260 time: 0.0230s\n",
            "0\n",
            "Epoch: 0005 loss_train: 0.7648 acc_train: 0.8786 loss_val: 0.6983 acc_val: 0.8200 time: 0.0227s\n",
            "1\n",
            "Epoch: 0006 loss_train: 0.7724 acc_train: 0.8214 loss_val: 0.7012 acc_val: 0.8200 time: 0.0228s\n",
            "2\n",
            "Epoch: 0007 loss_train: 0.8700 acc_train: 0.8214 loss_val: 0.7036 acc_val: 0.8200 time: 0.0226s\n",
            "3\n",
            "Epoch: 0008 loss_train: 0.7391 acc_train: 0.8571 loss_val: 0.7027 acc_val: 0.8200 time: 0.0227s\n",
            "4\n",
            "Epoch: 0009 loss_train: 0.8317 acc_train: 0.8714 loss_val: 0.6992 acc_val: 0.8200 time: 0.0230s\n",
            "5\n",
            "Epoch: 0010 loss_train: 0.8718 acc_train: 0.8071 loss_val: 0.6950 acc_val: 0.8260 time: 0.0230s\n",
            "6\n",
            "Epoch: 0011 loss_train: 0.8484 acc_train: 0.8071 loss_val: 0.6907 acc_val: 0.8300 time: 0.0267s\n",
            "7\n",
            "Epoch: 0012 loss_train: 0.8264 acc_train: 0.7643 loss_val: 0.6884 acc_val: 0.8280 time: 0.0228s\n",
            "8\n",
            "Epoch: 0013 loss_train: 0.8014 acc_train: 0.8071 loss_val: 0.6867 acc_val: 0.8340 time: 0.0226s\n",
            "9\n",
            "Epoch: 0014 loss_train: 0.8642 acc_train: 0.8071 loss_val: 0.6883 acc_val: 0.8340 time: 0.0228s\n",
            "0\n",
            "Epoch: 0015 loss_train: 0.8031 acc_train: 0.7929 loss_val: 0.6934 acc_val: 0.8260 time: 0.0227s\n",
            "0\n",
            "Epoch: 0016 loss_train: 0.8296 acc_train: 0.8143 loss_val: 0.7000 acc_val: 0.8200 time: 0.0228s\n",
            "1\n",
            "Epoch: 0017 loss_train: 0.8369 acc_train: 0.8214 loss_val: 0.7054 acc_val: 0.8160 time: 0.0227s\n",
            "2\n",
            "Epoch: 0018 loss_train: 0.8399 acc_train: 0.8143 loss_val: 0.7077 acc_val: 0.8100 time: 0.0227s\n",
            "3\n",
            "Epoch: 0019 loss_train: 0.8170 acc_train: 0.8500 loss_val: 0.7083 acc_val: 0.8120 time: 0.0255s\n",
            "4\n",
            "Epoch: 0020 loss_train: 0.8508 acc_train: 0.8429 loss_val: 0.7087 acc_val: 0.8120 time: 0.0243s\n",
            "5\n",
            "Epoch: 0021 loss_train: 0.8433 acc_train: 0.8000 loss_val: 0.7078 acc_val: 0.8140 time: 0.0238s\n",
            "6\n",
            "Epoch: 0022 loss_train: 0.8169 acc_train: 0.8500 loss_val: 0.7052 acc_val: 0.8180 time: 0.0251s\n",
            "7\n",
            "Epoch: 0023 loss_train: 0.8075 acc_train: 0.8786 loss_val: 0.7021 acc_val: 0.8240 time: 0.0256s\n",
            "8\n",
            "Epoch: 0024 loss_train: 0.8131 acc_train: 0.8357 loss_val: 0.6984 acc_val: 0.8300 time: 0.0242s\n",
            "9\n",
            "Epoch: 0025 loss_train: 0.8164 acc_train: 0.8286 loss_val: 0.6971 acc_val: 0.8300 time: 0.0231s\n",
            "10\n",
            "Epoch: 0026 loss_train: 0.8493 acc_train: 0.8571 loss_val: 0.6989 acc_val: 0.8280 time: 0.0227s\n",
            "11\n",
            "Epoch: 0027 loss_train: 0.8400 acc_train: 0.8071 loss_val: 0.7022 acc_val: 0.8280 time: 0.0318s\n",
            "12\n",
            "Epoch: 0028 loss_train: 0.8386 acc_train: 0.8143 loss_val: 0.7069 acc_val: 0.8280 time: 0.0235s\n",
            "13\n",
            "Epoch: 0029 loss_train: 0.8619 acc_train: 0.8071 loss_val: 0.7121 acc_val: 0.8140 time: 0.0256s\n",
            "14\n",
            "Epoch: 0030 loss_train: 0.8395 acc_train: 0.8214 loss_val: 0.7170 acc_val: 0.8060 time: 0.0235s\n",
            "15\n",
            "Epoch: 0031 loss_train: 0.8364 acc_train: 0.8143 loss_val: 0.7187 acc_val: 0.8060 time: 0.0244s\n",
            "16\n",
            "Epoch: 0032 loss_train: 0.7846 acc_train: 0.8357 loss_val: 0.7176 acc_val: 0.8080 time: 0.0232s\n",
            "17\n",
            "Epoch: 0033 loss_train: 0.8009 acc_train: 0.8357 loss_val: 0.7132 acc_val: 0.8100 time: 0.0254s\n",
            "18\n",
            "Epoch: 0034 loss_train: 0.8324 acc_train: 0.8143 loss_val: 0.7071 acc_val: 0.8080 time: 0.0244s\n",
            "19\n",
            "Epoch: 0035 loss_train: 0.8396 acc_train: 0.8357 loss_val: 0.7037 acc_val: 0.8180 time: 0.0298s\n",
            "20\n",
            "Epoch: 0036 loss_train: 0.8444 acc_train: 0.8000 loss_val: 0.7017 acc_val: 0.8180 time: 0.0283s\n",
            "21\n",
            "Epoch: 0037 loss_train: 0.8345 acc_train: 0.8357 loss_val: 0.7020 acc_val: 0.8200 time: 0.0260s\n",
            "22\n",
            "Epoch: 0038 loss_train: 0.8830 acc_train: 0.8143 loss_val: 0.7063 acc_val: 0.8180 time: 0.0235s\n",
            "23\n",
            "Epoch: 0039 loss_train: 0.8411 acc_train: 0.8071 loss_val: 0.7133 acc_val: 0.8200 time: 0.0233s\n",
            "24\n",
            "Epoch: 0040 loss_train: 0.7979 acc_train: 0.8071 loss_val: 0.7182 acc_val: 0.8240 time: 0.0239s\n",
            "25\n",
            "Epoch: 0041 loss_train: 0.8749 acc_train: 0.8429 loss_val: 0.7218 acc_val: 0.8200 time: 0.0253s\n",
            "26\n",
            "Epoch: 0042 loss_train: 0.8108 acc_train: 0.8214 loss_val: 0.7232 acc_val: 0.8180 time: 0.0240s\n",
            "27\n",
            "Epoch: 0043 loss_train: 0.8486 acc_train: 0.7857 loss_val: 0.7214 acc_val: 0.8120 time: 0.0313s\n",
            "28\n",
            "Epoch: 0044 loss_train: 0.8167 acc_train: 0.8071 loss_val: 0.7187 acc_val: 0.8060 time: 0.0239s\n",
            "29\n",
            "Epoch: 0045 loss_train: 0.8135 acc_train: 0.7929 loss_val: 0.7166 acc_val: 0.8040 time: 0.0231s\n",
            "30\n",
            "Epoch: 0046 loss_train: 0.8666 acc_train: 0.7929 loss_val: 0.7150 acc_val: 0.8060 time: 0.0226s\n",
            "31\n",
            "Epoch: 0047 loss_train: 0.8176 acc_train: 0.8357 loss_val: 0.7099 acc_val: 0.8080 time: 0.0226s\n",
            "32\n",
            "Epoch: 0048 loss_train: 0.7966 acc_train: 0.8286 loss_val: 0.7060 acc_val: 0.8020 time: 0.0235s\n",
            "33\n",
            "Epoch: 0049 loss_train: 0.8167 acc_train: 0.8571 loss_val: 0.7016 acc_val: 0.8140 time: 0.0232s\n",
            "34\n",
            "Epoch: 0050 loss_train: 0.8643 acc_train: 0.7929 loss_val: 0.6986 acc_val: 0.8180 time: 0.0228s\n",
            "35\n",
            "Epoch: 0051 loss_train: 0.8422 acc_train: 0.8000 loss_val: 0.6974 acc_val: 0.8200 time: 0.0245s\n",
            "36\n",
            "Epoch: 0052 loss_train: 0.8194 acc_train: 0.8571 loss_val: 0.6938 acc_val: 0.8260 time: 0.0260s\n",
            "37\n",
            "Epoch: 0053 loss_train: 0.8437 acc_train: 0.8071 loss_val: 0.6923 acc_val: 0.8260 time: 0.0227s\n",
            "38\n",
            "Epoch: 0054 loss_train: 0.8340 acc_train: 0.8143 loss_val: 0.6919 acc_val: 0.8240 time: 0.0226s\n",
            "39\n",
            "Epoch: 0055 loss_train: 0.7859 acc_train: 0.7714 loss_val: 0.6952 acc_val: 0.8240 time: 0.0226s\n",
            "40\n",
            "Epoch: 0056 loss_train: 0.8219 acc_train: 0.8357 loss_val: 0.7014 acc_val: 0.8180 time: 0.0254s\n",
            "41\n",
            "Epoch: 0057 loss_train: 0.8433 acc_train: 0.8429 loss_val: 0.7080 acc_val: 0.8160 time: 0.0250s\n",
            "42\n",
            "Epoch: 0058 loss_train: 0.8278 acc_train: 0.8286 loss_val: 0.7149 acc_val: 0.8120 time: 0.0226s\n",
            "43\n",
            "Epoch: 0059 loss_train: 0.7685 acc_train: 0.8357 loss_val: 0.7180 acc_val: 0.8100 time: 0.0227s\n",
            "44\n",
            "Epoch: 0060 loss_train: 0.8383 acc_train: 0.7643 loss_val: 0.7188 acc_val: 0.8080 time: 0.0254s\n",
            "45\n",
            "Epoch: 0061 loss_train: 0.8377 acc_train: 0.7643 loss_val: 0.7154 acc_val: 0.8020 time: 0.0233s\n",
            "46\n",
            "Epoch: 0062 loss_train: 0.7809 acc_train: 0.8714 loss_val: 0.7111 acc_val: 0.8020 time: 0.0238s\n",
            "47\n",
            "Epoch: 0063 loss_train: 0.8341 acc_train: 0.8357 loss_val: 0.7067 acc_val: 0.8040 time: 0.0238s\n",
            "48\n",
            "Epoch: 0064 loss_train: 0.8175 acc_train: 0.8143 loss_val: 0.7013 acc_val: 0.8200 time: 0.0233s\n",
            "49\n",
            "Epoch: 0065 loss_train: 0.7847 acc_train: 0.7786 loss_val: 0.6979 acc_val: 0.8280 time: 0.0234s\n",
            "50\n",
            "Epoch: 0066 loss_train: 0.8290 acc_train: 0.8071 loss_val: 0.6952 acc_val: 0.8200 time: 0.0242s\n",
            "51\n",
            "Epoch: 0067 loss_train: 0.7738 acc_train: 0.8571 loss_val: 0.6946 acc_val: 0.8200 time: 0.0254s\n",
            "52\n",
            "Epoch: 0068 loss_train: 0.8832 acc_train: 0.8071 loss_val: 0.6978 acc_val: 0.8240 time: 0.0297s\n",
            "53\n",
            "Epoch: 0069 loss_train: 0.8189 acc_train: 0.8429 loss_val: 0.7020 acc_val: 0.8180 time: 0.0235s\n",
            "54\n",
            "Epoch: 0070 loss_train: 0.8697 acc_train: 0.8071 loss_val: 0.7062 acc_val: 0.8220 time: 0.0237s\n",
            "55\n",
            "Epoch: 0071 loss_train: 0.8309 acc_train: 0.8357 loss_val: 0.7116 acc_val: 0.8180 time: 0.0245s\n",
            "56\n",
            "Epoch: 0072 loss_train: 0.8617 acc_train: 0.7643 loss_val: 0.7177 acc_val: 0.8140 time: 0.0235s\n",
            "57\n",
            "Epoch: 0073 loss_train: 0.8559 acc_train: 0.8286 loss_val: 0.7229 acc_val: 0.8100 time: 0.0235s\n",
            "58\n",
            "Epoch: 0074 loss_train: 0.8392 acc_train: 0.8071 loss_val: 0.7239 acc_val: 0.8120 time: 0.0234s\n",
            "59\n",
            "Epoch: 0075 loss_train: 0.7849 acc_train: 0.8500 loss_val: 0.7239 acc_val: 0.8100 time: 0.0259s\n",
            "60\n",
            "Epoch: 0076 loss_train: 0.8774 acc_train: 0.8286 loss_val: 0.7199 acc_val: 0.8120 time: 0.0291s\n",
            "61\n",
            "Epoch: 0077 loss_train: 0.8250 acc_train: 0.8357 loss_val: 0.7158 acc_val: 0.8140 time: 0.0238s\n",
            "62\n",
            "Epoch: 0078 loss_train: 0.8444 acc_train: 0.8643 loss_val: 0.7121 acc_val: 0.8140 time: 0.0235s\n",
            "63\n",
            "Epoch: 0079 loss_train: 0.8133 acc_train: 0.8357 loss_val: 0.7089 acc_val: 0.8200 time: 0.0243s\n",
            "64\n",
            "Epoch: 0080 loss_train: 0.7902 acc_train: 0.8143 loss_val: 0.7054 acc_val: 0.8180 time: 0.0233s\n",
            "65\n",
            "Epoch: 0081 loss_train: 0.8264 acc_train: 0.8429 loss_val: 0.7028 acc_val: 0.8240 time: 0.0230s\n",
            "66\n",
            "Epoch: 0082 loss_train: 0.7939 acc_train: 0.8357 loss_val: 0.7003 acc_val: 0.8300 time: 0.0228s\n",
            "67\n",
            "Epoch: 0083 loss_train: 0.8418 acc_train: 0.7714 loss_val: 0.7035 acc_val: 0.8260 time: 0.0232s\n",
            "68\n",
            "Epoch: 0084 loss_train: 0.8269 acc_train: 0.7786 loss_val: 0.7057 acc_val: 0.8240 time: 0.0238s\n",
            "69\n",
            "Epoch: 0085 loss_train: 0.8176 acc_train: 0.8429 loss_val: 0.7103 acc_val: 0.8180 time: 0.0247s\n",
            "70\n",
            "Epoch: 0086 loss_train: 0.8921 acc_train: 0.7929 loss_val: 0.7147 acc_val: 0.8140 time: 0.0238s\n",
            "71\n",
            "Epoch: 0087 loss_train: 0.8805 acc_train: 0.7571 loss_val: 0.7183 acc_val: 0.8100 time: 0.0233s\n",
            "72\n",
            "Epoch: 0088 loss_train: 0.8058 acc_train: 0.8143 loss_val: 0.7194 acc_val: 0.8080 time: 0.0247s\n",
            "73\n",
            "Epoch: 0089 loss_train: 0.8170 acc_train: 0.8143 loss_val: 0.7194 acc_val: 0.8040 time: 0.0233s\n",
            "74\n",
            "Epoch: 0090 loss_train: 0.8591 acc_train: 0.8071 loss_val: 0.7206 acc_val: 0.8080 time: 0.0228s\n",
            "75\n",
            "Epoch: 0091 loss_train: 0.8917 acc_train: 0.8286 loss_val: 0.7176 acc_val: 0.8100 time: 0.0222s\n",
            "76\n",
            "Epoch: 0092 loss_train: 0.8339 acc_train: 0.8286 loss_val: 0.7127 acc_val: 0.8140 time: 0.0232s\n",
            "77\n",
            "Epoch: 0093 loss_train: 0.8232 acc_train: 0.8571 loss_val: 0.7081 acc_val: 0.8220 time: 0.0258s\n",
            "78\n",
            "Epoch: 0094 loss_train: 0.8220 acc_train: 0.8143 loss_val: 0.7061 acc_val: 0.8220 time: 0.0233s\n",
            "79\n",
            "Epoch: 0095 loss_train: 0.8302 acc_train: 0.8286 loss_val: 0.7043 acc_val: 0.8200 time: 0.0236s\n",
            "80\n",
            "Epoch: 0096 loss_train: 0.8756 acc_train: 0.7643 loss_val: 0.7050 acc_val: 0.8200 time: 0.0227s\n",
            "81\n",
            "Epoch: 0097 loss_train: 0.8967 acc_train: 0.8071 loss_val: 0.7097 acc_val: 0.8160 time: 0.0229s\n",
            "82\n",
            "Epoch: 0098 loss_train: 0.8178 acc_train: 0.8429 loss_val: 0.7129 acc_val: 0.8120 time: 0.0229s\n",
            "83\n",
            "Epoch: 0099 loss_train: 0.8276 acc_train: 0.8429 loss_val: 0.7136 acc_val: 0.8180 time: 0.0226s\n",
            "84\n",
            "Epoch: 0100 loss_train: 0.8232 acc_train: 0.8286 loss_val: 0.7139 acc_val: 0.8220 time: 0.0231s\n",
            "85\n",
            "Epoch: 0101 loss_train: 0.7919 acc_train: 0.8429 loss_val: 0.7108 acc_val: 0.8220 time: 0.0234s\n",
            "86\n",
            "Epoch: 0102 loss_train: 0.8368 acc_train: 0.8786 loss_val: 0.7075 acc_val: 0.8240 time: 0.0257s\n",
            "87\n",
            "Epoch: 0103 loss_train: 0.8041 acc_train: 0.8143 loss_val: 0.7037 acc_val: 0.8240 time: 0.0227s\n",
            "88\n",
            "Epoch: 0104 loss_train: 0.8452 acc_train: 0.8357 loss_val: 0.7029 acc_val: 0.8200 time: 0.0227s\n",
            "89\n",
            "Epoch: 0105 loss_train: 0.8255 acc_train: 0.8500 loss_val: 0.7028 acc_val: 0.8220 time: 0.0227s\n",
            "90\n",
            "Epoch: 0106 loss_train: 0.8186 acc_train: 0.8000 loss_val: 0.7035 acc_val: 0.8200 time: 0.0227s\n",
            "91\n",
            "Epoch: 0107 loss_train: 0.8356 acc_train: 0.8429 loss_val: 0.7048 acc_val: 0.8220 time: 0.0232s\n",
            "92\n",
            "Epoch: 0108 loss_train: 0.8157 acc_train: 0.8429 loss_val: 0.7067 acc_val: 0.8100 time: 0.0237s\n",
            "93\n",
            "Epoch: 0109 loss_train: 0.8289 acc_train: 0.8214 loss_val: 0.7073 acc_val: 0.8120 time: 0.0228s\n",
            "94\n",
            "Epoch: 0110 loss_train: 0.8185 acc_train: 0.7714 loss_val: 0.7066 acc_val: 0.8140 time: 0.0280s\n",
            "95\n",
            "Epoch: 0111 loss_train: 0.8122 acc_train: 0.7857 loss_val: 0.7054 acc_val: 0.8140 time: 0.0230s\n",
            "96\n",
            "Epoch: 0112 loss_train: 0.8078 acc_train: 0.8714 loss_val: 0.7025 acc_val: 0.8180 time: 0.0229s\n",
            "97\n",
            "Epoch: 0113 loss_train: 0.8411 acc_train: 0.8000 loss_val: 0.7005 acc_val: 0.8240 time: 0.0232s\n",
            "98\n",
            "Epoch: 0114 loss_train: 0.8495 acc_train: 0.8000 loss_val: 0.7008 acc_val: 0.8200 time: 0.0239s\n",
            "99\n",
            "Epoch: 0115 loss_train: 0.8078 acc_train: 0.8571 loss_val: 0.7013 acc_val: 0.8240 time: 0.0259s\n",
            "100\n",
            "Epoch: 0116 loss_train: 0.8237 acc_train: 0.8214 loss_val: 0.7011 acc_val: 0.8240 time: 0.0233s\n",
            "101\n",
            "Epoch: 0117 loss_train: 0.8582 acc_train: 0.8214 loss_val: 0.7013 acc_val: 0.8220 time: 0.0228s\n",
            "102\n",
            "Epoch: 0118 loss_train: 0.8558 acc_train: 0.8214 loss_val: 0.7048 acc_val: 0.8200 time: 0.0232s\n",
            "103\n",
            "Epoch: 0119 loss_train: 0.8468 acc_train: 0.7929 loss_val: 0.7114 acc_val: 0.8180 time: 0.0294s\n",
            "104\n",
            "Epoch: 0120 loss_train: 0.8475 acc_train: 0.7714 loss_val: 0.7151 acc_val: 0.8080 time: 0.0229s\n",
            "105\n",
            "Epoch: 0121 loss_train: 0.8233 acc_train: 0.8286 loss_val: 0.7149 acc_val: 0.8080 time: 0.0253s\n",
            "106\n",
            "Epoch: 0122 loss_train: 0.8043 acc_train: 0.7929 loss_val: 0.7117 acc_val: 0.8100 time: 0.0244s\n",
            "107\n",
            "Epoch: 0123 loss_train: 0.8607 acc_train: 0.8357 loss_val: 0.7096 acc_val: 0.8140 time: 0.0234s\n",
            "108\n",
            "Epoch: 0124 loss_train: 0.8274 acc_train: 0.8214 loss_val: 0.7096 acc_val: 0.8180 time: 0.0235s\n",
            "109\n",
            "Epoch: 0125 loss_train: 0.8211 acc_train: 0.8429 loss_val: 0.7086 acc_val: 0.8200 time: 0.0238s\n",
            "110\n",
            "Epoch: 0126 loss_train: 0.7906 acc_train: 0.8286 loss_val: 0.7069 acc_val: 0.8240 time: 0.0263s\n",
            "111\n",
            "Epoch: 0127 loss_train: 0.8053 acc_train: 0.7786 loss_val: 0.7045 acc_val: 0.8220 time: 0.0274s\n",
            "112\n",
            "Epoch: 0128 loss_train: 0.8091 acc_train: 0.7929 loss_val: 0.7016 acc_val: 0.8200 time: 0.0243s\n",
            "113\n",
            "Epoch: 0129 loss_train: 0.8803 acc_train: 0.8214 loss_val: 0.7013 acc_val: 0.8240 time: 0.0240s\n",
            "114\n",
            "Epoch: 0130 loss_train: 0.8003 acc_train: 0.8429 loss_val: 0.7023 acc_val: 0.8240 time: 0.0236s\n",
            "115\n",
            "Epoch: 0131 loss_train: 0.7852 acc_train: 0.8571 loss_val: 0.7058 acc_val: 0.8160 time: 0.0247s\n",
            "116\n",
            "Epoch: 0132 loss_train: 0.8734 acc_train: 0.8143 loss_val: 0.7110 acc_val: 0.8140 time: 0.0252s\n",
            "117\n",
            "Epoch: 0133 loss_train: 0.7840 acc_train: 0.8214 loss_val: 0.7171 acc_val: 0.8080 time: 0.0236s\n",
            "118\n",
            "Epoch: 0134 loss_train: 0.8148 acc_train: 0.8286 loss_val: 0.7217 acc_val: 0.8040 time: 0.0257s\n",
            "119\n",
            "Epoch: 0135 loss_train: 0.8091 acc_train: 0.8357 loss_val: 0.7222 acc_val: 0.8040 time: 0.0300s\n",
            "120\n",
            "Epoch: 0136 loss_train: 0.8158 acc_train: 0.8143 loss_val: 0.7204 acc_val: 0.8060 time: 0.0238s\n",
            "121\n",
            "Epoch: 0137 loss_train: 0.8134 acc_train: 0.7786 loss_val: 0.7156 acc_val: 0.8140 time: 0.0236s\n",
            "122\n",
            "Epoch: 0138 loss_train: 0.7967 acc_train: 0.7929 loss_val: 0.7089 acc_val: 0.8180 time: 0.0232s\n",
            "123\n",
            "Epoch: 0139 loss_train: 0.8600 acc_train: 0.8429 loss_val: 0.7035 acc_val: 0.8220 time: 0.0235s\n",
            "124\n",
            "Epoch: 0140 loss_train: 0.8432 acc_train: 0.8286 loss_val: 0.7001 acc_val: 0.8200 time: 0.0233s\n",
            "125\n",
            "Epoch: 0141 loss_train: 0.7762 acc_train: 0.8571 loss_val: 0.6998 acc_val: 0.8200 time: 0.0226s\n",
            "126\n",
            "Epoch: 0142 loss_train: 0.8097 acc_train: 0.8500 loss_val: 0.6993 acc_val: 0.8220 time: 0.0301s\n",
            "127\n",
            "Epoch: 0143 loss_train: 0.8440 acc_train: 0.7929 loss_val: 0.6995 acc_val: 0.8180 time: 0.0270s\n",
            "128\n",
            "Epoch: 0144 loss_train: 0.8080 acc_train: 0.8214 loss_val: 0.6995 acc_val: 0.8140 time: 0.0235s\n",
            "129\n",
            "Epoch: 0145 loss_train: 0.8488 acc_train: 0.8286 loss_val: 0.6978 acc_val: 0.8160 time: 0.0233s\n",
            "130\n",
            "Epoch: 0146 loss_train: 0.8053 acc_train: 0.8857 loss_val: 0.6978 acc_val: 0.8160 time: 0.0235s\n",
            "131\n",
            "Epoch: 0147 loss_train: 0.8638 acc_train: 0.8071 loss_val: 0.7016 acc_val: 0.8120 time: 0.0234s\n",
            "132\n",
            "Epoch: 0148 loss_train: 0.7631 acc_train: 0.8786 loss_val: 0.7066 acc_val: 0.8100 time: 0.0232s\n",
            "133\n",
            "Epoch: 0149 loss_train: 0.7898 acc_train: 0.8429 loss_val: 0.7107 acc_val: 0.8120 time: 0.0227s\n",
            "134\n",
            "Epoch: 0150 loss_train: 0.8462 acc_train: 0.8500 loss_val: 0.7128 acc_val: 0.8100 time: 0.0239s\n",
            "135\n",
            "Epoch: 0151 loss_train: 0.9047 acc_train: 0.7571 loss_val: 0.7149 acc_val: 0.8080 time: 0.0250s\n",
            "136\n",
            "Epoch: 0152 loss_train: 0.8014 acc_train: 0.8143 loss_val: 0.7124 acc_val: 0.8140 time: 0.0227s\n",
            "137\n",
            "Epoch: 0153 loss_train: 0.8667 acc_train: 0.8071 loss_val: 0.7120 acc_val: 0.8140 time: 0.0247s\n",
            "138\n",
            "Epoch: 0154 loss_train: 0.8327 acc_train: 0.8357 loss_val: 0.7128 acc_val: 0.8120 time: 0.0231s\n",
            "139\n",
            "Epoch: 0155 loss_train: 0.8296 acc_train: 0.7786 loss_val: 0.7144 acc_val: 0.8100 time: 0.0228s\n",
            "140\n",
            "Epoch: 0156 loss_train: 0.8074 acc_train: 0.7786 loss_val: 0.7119 acc_val: 0.8100 time: 0.0237s\n",
            "141\n",
            "Epoch: 0157 loss_train: 0.8414 acc_train: 0.7857 loss_val: 0.7093 acc_val: 0.8120 time: 0.0225s\n",
            "142\n",
            "Epoch: 0158 loss_train: 0.8307 acc_train: 0.8000 loss_val: 0.7058 acc_val: 0.8180 time: 0.0228s\n",
            "143\n",
            "Epoch: 0159 loss_train: 0.8159 acc_train: 0.8214 loss_val: 0.7048 acc_val: 0.8200 time: 0.0251s\n",
            "144\n",
            "Epoch: 0160 loss_train: 0.8488 acc_train: 0.7786 loss_val: 0.7048 acc_val: 0.8200 time: 0.0239s\n",
            "145\n",
            "Epoch: 0161 loss_train: 0.8029 acc_train: 0.8214 loss_val: 0.7047 acc_val: 0.8160 time: 0.0226s\n",
            "146\n",
            "Epoch: 0162 loss_train: 0.8634 acc_train: 0.7857 loss_val: 0.7050 acc_val: 0.8160 time: 0.0221s\n",
            "147\n",
            "Epoch: 0163 loss_train: 0.8172 acc_train: 0.8214 loss_val: 0.7067 acc_val: 0.8140 time: 0.0229s\n",
            "148\n",
            "Epoch: 0164 loss_train: 0.8159 acc_train: 0.8143 loss_val: 0.7070 acc_val: 0.8140 time: 0.0233s\n",
            "149\n",
            "Epoch: 0165 loss_train: 0.8187 acc_train: 0.8214 loss_val: 0.7077 acc_val: 0.8140 time: 0.0222s\n",
            "150\n",
            "Epoch: 0166 loss_train: 0.7938 acc_train: 0.8143 loss_val: 0.7048 acc_val: 0.8120 time: 0.0236s\n",
            "151\n",
            "Epoch: 0167 loss_train: 0.8679 acc_train: 0.8071 loss_val: 0.7032 acc_val: 0.8100 time: 0.0245s\n",
            "152\n",
            "Epoch: 0168 loss_train: 0.7946 acc_train: 0.7857 loss_val: 0.7034 acc_val: 0.8100 time: 0.0253s\n",
            "153\n",
            "Epoch: 0169 loss_train: 0.8330 acc_train: 0.8714 loss_val: 0.7049 acc_val: 0.8140 time: 0.0240s\n",
            "154\n",
            "Epoch: 0170 loss_train: 0.8640 acc_train: 0.7857 loss_val: 0.7058 acc_val: 0.8140 time: 0.0239s\n",
            "155\n",
            "Epoch: 0171 loss_train: 0.8415 acc_train: 0.7786 loss_val: 0.7079 acc_val: 0.8120 time: 0.0237s\n",
            "156\n",
            "Epoch: 0172 loss_train: 0.8381 acc_train: 0.8286 loss_val: 0.7085 acc_val: 0.8100 time: 0.0238s\n",
            "157\n",
            "Epoch: 0173 loss_train: 0.8335 acc_train: 0.8071 loss_val: 0.7098 acc_val: 0.8080 time: 0.0235s\n",
            "158\n",
            "Epoch: 0174 loss_train: 0.7867 acc_train: 0.9071 loss_val: 0.7099 acc_val: 0.8100 time: 0.0237s\n",
            "159\n",
            "Epoch: 0175 loss_train: 0.8507 acc_train: 0.8357 loss_val: 0.7077 acc_val: 0.8140 time: 0.0250s\n",
            "160\n",
            "Epoch: 0176 loss_train: 0.8498 acc_train: 0.8000 loss_val: 0.7065 acc_val: 0.8140 time: 0.0273s\n",
            "161\n",
            "Epoch: 0177 loss_train: 0.8035 acc_train: 0.8357 loss_val: 0.7078 acc_val: 0.8100 time: 0.0251s\n",
            "162\n",
            "Epoch: 0178 loss_train: 0.8247 acc_train: 0.8143 loss_val: 0.7091 acc_val: 0.8140 time: 0.0255s\n",
            "163\n",
            "Epoch: 0179 loss_train: 0.7957 acc_train: 0.8500 loss_val: 0.7070 acc_val: 0.8140 time: 0.0241s\n",
            "164\n",
            "Epoch: 0180 loss_train: 0.8485 acc_train: 0.7929 loss_val: 0.7032 acc_val: 0.8140 time: 0.0249s\n",
            "165\n",
            "Epoch: 0181 loss_train: 0.8078 acc_train: 0.8071 loss_val: 0.7001 acc_val: 0.8140 time: 0.0253s\n",
            "166\n",
            "Epoch: 0182 loss_train: 0.7832 acc_train: 0.7500 loss_val: 0.6963 acc_val: 0.8200 time: 0.0242s\n",
            "167\n",
            "Epoch: 0183 loss_train: 0.8101 acc_train: 0.8214 loss_val: 0.6950 acc_val: 0.8200 time: 0.0256s\n",
            "168\n",
            "Epoch: 0184 loss_train: 0.8055 acc_train: 0.8714 loss_val: 0.6967 acc_val: 0.8260 time: 0.0254s\n",
            "169\n",
            "Epoch: 0185 loss_train: 0.8418 acc_train: 0.7929 loss_val: 0.6985 acc_val: 0.8240 time: 0.0232s\n",
            "170\n",
            "Epoch: 0186 loss_train: 0.7642 acc_train: 0.8857 loss_val: 0.7000 acc_val: 0.8240 time: 0.0232s\n",
            "171\n",
            "Epoch: 0187 loss_train: 0.8198 acc_train: 0.7929 loss_val: 0.7019 acc_val: 0.8280 time: 0.0232s\n",
            "172\n",
            "Epoch: 0188 loss_train: 0.8024 acc_train: 0.8357 loss_val: 0.7028 acc_val: 0.8180 time: 0.0242s\n",
            "173\n",
            "Epoch: 0189 loss_train: 0.8201 acc_train: 0.8143 loss_val: 0.7051 acc_val: 0.8120 time: 0.0246s\n",
            "174\n",
            "Epoch: 0190 loss_train: 0.8566 acc_train: 0.7857 loss_val: 0.7081 acc_val: 0.8120 time: 0.0236s\n",
            "175\n",
            "Epoch: 0191 loss_train: 0.8528 acc_train: 0.7857 loss_val: 0.7099 acc_val: 0.8080 time: 0.0239s\n",
            "176\n",
            "Epoch: 0192 loss_train: 0.8052 acc_train: 0.8357 loss_val: 0.7092 acc_val: 0.8080 time: 0.0335s\n",
            "177\n",
            "Epoch: 0193 loss_train: 0.7862 acc_train: 0.8214 loss_val: 0.7064 acc_val: 0.8120 time: 0.0259s\n",
            "178\n",
            "Epoch: 0194 loss_train: 0.8553 acc_train: 0.7643 loss_val: 0.7030 acc_val: 0.8160 time: 0.0234s\n",
            "179\n",
            "Epoch: 0195 loss_train: 0.8579 acc_train: 0.8286 loss_val: 0.6990 acc_val: 0.8140 time: 0.0235s\n",
            "180\n",
            "Epoch: 0196 loss_train: 0.8293 acc_train: 0.8071 loss_val: 0.6976 acc_val: 0.8180 time: 0.0241s\n",
            "181\n",
            "Epoch: 0197 loss_train: 0.8373 acc_train: 0.8143 loss_val: 0.7008 acc_val: 0.8200 time: 0.0236s\n",
            "182\n",
            "Epoch: 0198 loss_train: 0.8773 acc_train: 0.8500 loss_val: 0.7069 acc_val: 0.8160 time: 0.0241s\n",
            "183\n",
            "Epoch: 0199 loss_train: 0.8615 acc_train: 0.8000 loss_val: 0.7162 acc_val: 0.8180 time: 0.0235s\n",
            "184\n",
            "Epoch: 0200 loss_train: 0.8239 acc_train: 0.8071 loss_val: 0.7218 acc_val: 0.8160 time: 0.0273s\n",
            "185\n",
            "Epoch: 0201 loss_train: 0.8303 acc_train: 0.8429 loss_val: 0.7238 acc_val: 0.8160 time: 0.0250s\n",
            "186\n",
            "Epoch: 0202 loss_train: 0.8117 acc_train: 0.8357 loss_val: 0.7189 acc_val: 0.8160 time: 0.0237s\n",
            "187\n",
            "Epoch: 0203 loss_train: 0.8300 acc_train: 0.8214 loss_val: 0.7110 acc_val: 0.8160 time: 0.0238s\n",
            "188\n",
            "Epoch: 0204 loss_train: 0.8732 acc_train: 0.8643 loss_val: 0.7045 acc_val: 0.8160 time: 0.0234s\n",
            "189\n",
            "Epoch: 0205 loss_train: 0.8457 acc_train: 0.8643 loss_val: 0.7024 acc_val: 0.8160 time: 0.0242s\n",
            "190\n",
            "Epoch: 0206 loss_train: 0.8075 acc_train: 0.7714 loss_val: 0.7046 acc_val: 0.8180 time: 0.0226s\n",
            "191\n",
            "Epoch: 0207 loss_train: 0.8757 acc_train: 0.7786 loss_val: 0.7102 acc_val: 0.8200 time: 0.0231s\n",
            "192\n",
            "Epoch: 0208 loss_train: 0.8386 acc_train: 0.8071 loss_val: 0.7133 acc_val: 0.8220 time: 0.0242s\n",
            "193\n",
            "Epoch: 0209 loss_train: 0.8449 acc_train: 0.8286 loss_val: 0.7156 acc_val: 0.8200 time: 0.0273s\n",
            "194\n",
            "Epoch: 0210 loss_train: 0.7883 acc_train: 0.8571 loss_val: 0.7172 acc_val: 0.8180 time: 0.0236s\n",
            "195\n",
            "Epoch: 0211 loss_train: 0.8111 acc_train: 0.8071 loss_val: 0.7148 acc_val: 0.8180 time: 0.0241s\n",
            "196\n",
            "Epoch: 0212 loss_train: 0.7911 acc_train: 0.8000 loss_val: 0.7097 acc_val: 0.8260 time: 0.0241s\n",
            "197\n",
            "Epoch: 0213 loss_train: 0.8961 acc_train: 0.8500 loss_val: 0.7057 acc_val: 0.8220 time: 0.0232s\n",
            "198\n",
            "Epoch: 0214 loss_train: 0.8627 acc_train: 0.7714 loss_val: 0.7021 acc_val: 0.8180 time: 0.0228s\n",
            "199\n",
            "Early stop! Min loss:  0.6668131947517395 , Max accuracy:  0.834\n",
            "Early stop model validation loss:  0.6668131947517395 , accuracy:  0.8300000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 5.6089s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6270 accuracy= 0.8560\n",
            "Epoch: 0001 loss_train: 0.8449 acc_train: 0.7286 loss_val: 0.6686 acc_val: 0.8240 time: 0.0281s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8560 acc_train: 0.8000 loss_val: 0.6713 acc_val: 0.8260 time: 0.0287s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8474 acc_train: 0.7786 loss_val: 0.6752 acc_val: 0.8240 time: 0.0265s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.8362 acc_train: 0.8286 loss_val: 0.6848 acc_val: 0.8220 time: 0.0275s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.8825 acc_train: 0.7929 loss_val: 0.6947 acc_val: 0.8140 time: 0.0267s\n",
            "2\n",
            "Epoch: 0006 loss_train: 0.8662 acc_train: 0.7929 loss_val: 0.7079 acc_val: 0.8180 time: 0.0261s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.8137 acc_train: 0.8000 loss_val: 0.7183 acc_val: 0.8160 time: 0.0256s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.8062 acc_train: 0.7786 loss_val: 0.7253 acc_val: 0.8220 time: 0.0260s\n",
            "5\n",
            "Epoch: 0009 loss_train: 0.8633 acc_train: 0.7857 loss_val: 0.7247 acc_val: 0.8240 time: 0.0259s\n",
            "6\n",
            "Epoch: 0010 loss_train: 0.8675 acc_train: 0.8214 loss_val: 0.7199 acc_val: 0.8200 time: 0.0275s\n",
            "7\n",
            "Epoch: 0011 loss_train: 0.8831 acc_train: 0.7571 loss_val: 0.7138 acc_val: 0.8220 time: 0.0259s\n",
            "8\n",
            "Epoch: 0012 loss_train: 0.8293 acc_train: 0.8500 loss_val: 0.7045 acc_val: 0.8360 time: 0.0258s\n",
            "9\n",
            "Epoch: 0013 loss_train: 0.8828 acc_train: 0.7714 loss_val: 0.6980 acc_val: 0.8360 time: 0.0274s\n",
            "0\n",
            "Epoch: 0014 loss_train: 0.8335 acc_train: 0.8857 loss_val: 0.6931 acc_val: 0.8280 time: 0.0306s\n",
            "0\n",
            "Epoch: 0015 loss_train: 0.8096 acc_train: 0.8857 loss_val: 0.6902 acc_val: 0.8320 time: 0.0268s\n",
            "1\n",
            "Epoch: 0016 loss_train: 0.8211 acc_train: 0.8071 loss_val: 0.6909 acc_val: 0.8240 time: 0.0265s\n",
            "2\n",
            "Epoch: 0017 loss_train: 0.8151 acc_train: 0.8571 loss_val: 0.6965 acc_val: 0.8200 time: 0.0303s\n",
            "3\n",
            "Epoch: 0018 loss_train: 0.8184 acc_train: 0.7500 loss_val: 0.7028 acc_val: 0.8200 time: 0.0259s\n",
            "4\n",
            "Epoch: 0019 loss_train: 0.7977 acc_train: 0.8286 loss_val: 0.7101 acc_val: 0.8160 time: 0.0256s\n",
            "5\n",
            "Epoch: 0020 loss_train: 0.8616 acc_train: 0.8143 loss_val: 0.7182 acc_val: 0.8220 time: 0.0260s\n",
            "6\n",
            "Epoch: 0021 loss_train: 0.8493 acc_train: 0.8643 loss_val: 0.7224 acc_val: 0.8220 time: 0.0260s\n",
            "7\n",
            "Epoch: 0022 loss_train: 0.8804 acc_train: 0.7786 loss_val: 0.7247 acc_val: 0.8200 time: 0.0269s\n",
            "8\n",
            "Epoch: 0023 loss_train: 0.8583 acc_train: 0.8071 loss_val: 0.7248 acc_val: 0.8220 time: 0.0280s\n",
            "9\n",
            "Epoch: 0024 loss_train: 0.8634 acc_train: 0.8214 loss_val: 0.7218 acc_val: 0.8260 time: 0.0258s\n",
            "10\n",
            "Epoch: 0025 loss_train: 0.8472 acc_train: 0.8000 loss_val: 0.7183 acc_val: 0.8300 time: 0.0292s\n",
            "11\n",
            "Epoch: 0026 loss_train: 0.8398 acc_train: 0.8071 loss_val: 0.7169 acc_val: 0.8260 time: 0.0256s\n",
            "12\n",
            "Epoch: 0027 loss_train: 0.8215 acc_train: 0.8500 loss_val: 0.7156 acc_val: 0.8200 time: 0.0256s\n",
            "13\n",
            "Epoch: 0028 loss_train: 0.8336 acc_train: 0.8500 loss_val: 0.7146 acc_val: 0.8220 time: 0.0263s\n",
            "14\n",
            "Epoch: 0029 loss_train: 0.8336 acc_train: 0.8071 loss_val: 0.7136 acc_val: 0.8260 time: 0.0260s\n",
            "15\n",
            "Epoch: 0030 loss_train: 0.8614 acc_train: 0.8071 loss_val: 0.7156 acc_val: 0.8240 time: 0.0256s\n",
            "16\n",
            "Epoch: 0031 loss_train: 0.8578 acc_train: 0.7786 loss_val: 0.7175 acc_val: 0.8200 time: 0.0262s\n",
            "17\n",
            "Epoch: 0032 loss_train: 0.8999 acc_train: 0.8143 loss_val: 0.7234 acc_val: 0.8200 time: 0.0288s\n",
            "18\n",
            "Epoch: 0033 loss_train: 0.8692 acc_train: 0.7929 loss_val: 0.7298 acc_val: 0.8160 time: 0.0268s\n",
            "19\n",
            "Epoch: 0034 loss_train: 0.8246 acc_train: 0.8071 loss_val: 0.7345 acc_val: 0.8200 time: 0.0264s\n",
            "20\n",
            "Epoch: 0035 loss_train: 0.8449 acc_train: 0.8214 loss_val: 0.7339 acc_val: 0.8200 time: 0.0279s\n",
            "21\n",
            "Epoch: 0036 loss_train: 0.8697 acc_train: 0.8143 loss_val: 0.7299 acc_val: 0.8200 time: 0.0268s\n",
            "22\n",
            "Epoch: 0037 loss_train: 0.8610 acc_train: 0.8429 loss_val: 0.7262 acc_val: 0.8220 time: 0.0265s\n",
            "23\n",
            "Epoch: 0038 loss_train: 0.8635 acc_train: 0.8143 loss_val: 0.7190 acc_val: 0.8200 time: 0.0272s\n",
            "24\n",
            "Epoch: 0039 loss_train: 0.8396 acc_train: 0.8500 loss_val: 0.7137 acc_val: 0.8180 time: 0.0284s\n",
            "25\n",
            "Epoch: 0040 loss_train: 0.8292 acc_train: 0.8071 loss_val: 0.7098 acc_val: 0.8200 time: 0.0284s\n",
            "26\n",
            "Epoch: 0041 loss_train: 0.8462 acc_train: 0.8429 loss_val: 0.7080 acc_val: 0.8200 time: 0.0256s\n",
            "27\n",
            "Epoch: 0042 loss_train: 0.8654 acc_train: 0.8286 loss_val: 0.7099 acc_val: 0.8180 time: 0.0259s\n",
            "28\n",
            "Epoch: 0043 loss_train: 0.8512 acc_train: 0.7643 loss_val: 0.7144 acc_val: 0.8220 time: 0.0259s\n",
            "29\n",
            "Epoch: 0044 loss_train: 0.8537 acc_train: 0.8143 loss_val: 0.7194 acc_val: 0.8180 time: 0.0263s\n",
            "30\n",
            "Epoch: 0045 loss_train: 0.8741 acc_train: 0.8643 loss_val: 0.7229 acc_val: 0.8180 time: 0.0262s\n",
            "31\n",
            "Epoch: 0046 loss_train: 0.8490 acc_train: 0.8357 loss_val: 0.7264 acc_val: 0.8220 time: 0.0289s\n",
            "32\n",
            "Epoch: 0047 loss_train: 0.8322 acc_train: 0.8143 loss_val: 0.7281 acc_val: 0.8220 time: 0.0280s\n",
            "33\n",
            "Epoch: 0048 loss_train: 0.8284 acc_train: 0.8143 loss_val: 0.7284 acc_val: 0.8260 time: 0.0257s\n",
            "34\n",
            "Epoch: 0049 loss_train: 0.8437 acc_train: 0.8000 loss_val: 0.7282 acc_val: 0.8240 time: 0.0291s\n",
            "35\n",
            "Epoch: 0050 loss_train: 0.8416 acc_train: 0.8500 loss_val: 0.7260 acc_val: 0.8200 time: 0.0257s\n",
            "36\n",
            "Epoch: 0051 loss_train: 0.7946 acc_train: 0.8429 loss_val: 0.7215 acc_val: 0.8180 time: 0.0258s\n",
            "37\n",
            "Epoch: 0052 loss_train: 0.8845 acc_train: 0.7714 loss_val: 0.7167 acc_val: 0.8180 time: 0.0259s\n",
            "38\n",
            "Epoch: 0053 loss_train: 0.8527 acc_train: 0.7643 loss_val: 0.7134 acc_val: 0.8220 time: 0.0268s\n",
            "39\n",
            "Epoch: 0054 loss_train: 0.8883 acc_train: 0.8357 loss_val: 0.7127 acc_val: 0.8220 time: 0.0259s\n",
            "40\n",
            "Epoch: 0055 loss_train: 0.8579 acc_train: 0.8429 loss_val: 0.7142 acc_val: 0.8180 time: 0.0286s\n",
            "41\n",
            "Epoch: 0056 loss_train: 0.8380 acc_train: 0.7857 loss_val: 0.7172 acc_val: 0.8160 time: 0.0260s\n",
            "42\n",
            "Epoch: 0057 loss_train: 0.8292 acc_train: 0.8143 loss_val: 0.7182 acc_val: 0.8240 time: 0.0259s\n",
            "43\n",
            "Epoch: 0058 loss_train: 0.9048 acc_train: 0.7500 loss_val: 0.7196 acc_val: 0.8220 time: 0.0268s\n",
            "44\n",
            "Epoch: 0059 loss_train: 0.8915 acc_train: 0.7929 loss_val: 0.7210 acc_val: 0.8240 time: 0.0260s\n",
            "45\n",
            "Epoch: 0060 loss_train: 0.8315 acc_train: 0.8286 loss_val: 0.7217 acc_val: 0.8220 time: 0.0258s\n",
            "46\n",
            "Epoch: 0061 loss_train: 0.8393 acc_train: 0.7429 loss_val: 0.7257 acc_val: 0.8240 time: 0.0257s\n",
            "47\n",
            "Epoch: 0062 loss_train: 0.8252 acc_train: 0.7786 loss_val: 0.7257 acc_val: 0.8200 time: 0.0283s\n",
            "48\n",
            "Epoch: 0063 loss_train: 0.8030 acc_train: 0.8643 loss_val: 0.7243 acc_val: 0.8220 time: 0.0266s\n",
            "49\n",
            "Epoch: 0064 loss_train: 0.8532 acc_train: 0.8143 loss_val: 0.7214 acc_val: 0.8200 time: 0.0274s\n",
            "50\n",
            "Epoch: 0065 loss_train: 0.8560 acc_train: 0.8071 loss_val: 0.7178 acc_val: 0.8260 time: 0.0305s\n",
            "51\n",
            "Epoch: 0066 loss_train: 0.9112 acc_train: 0.8071 loss_val: 0.7189 acc_val: 0.8220 time: 0.0267s\n",
            "52\n",
            "Epoch: 0067 loss_train: 0.7905 acc_train: 0.8214 loss_val: 0.7218 acc_val: 0.8180 time: 0.0263s\n",
            "53\n",
            "Epoch: 0068 loss_train: 0.8706 acc_train: 0.8643 loss_val: 0.7251 acc_val: 0.8200 time: 0.0271s\n",
            "54\n",
            "Epoch: 0069 loss_train: 0.8768 acc_train: 0.7786 loss_val: 0.7269 acc_val: 0.8200 time: 0.0271s\n",
            "55\n",
            "Epoch: 0070 loss_train: 0.8467 acc_train: 0.7786 loss_val: 0.7270 acc_val: 0.8220 time: 0.0292s\n",
            "56\n",
            "Epoch: 0071 loss_train: 0.8867 acc_train: 0.7643 loss_val: 0.7279 acc_val: 0.8160 time: 0.0273s\n",
            "57\n",
            "Epoch: 0072 loss_train: 0.8524 acc_train: 0.7857 loss_val: 0.7265 acc_val: 0.8200 time: 0.0271s\n",
            "58\n",
            "Epoch: 0073 loss_train: 0.8188 acc_train: 0.8214 loss_val: 0.7266 acc_val: 0.8200 time: 0.0281s\n",
            "59\n",
            "Epoch: 0074 loss_train: 0.8879 acc_train: 0.7857 loss_val: 0.7267 acc_val: 0.8180 time: 0.0271s\n",
            "60\n",
            "Epoch: 0075 loss_train: 0.8271 acc_train: 0.8000 loss_val: 0.7258 acc_val: 0.8180 time: 0.0258s\n",
            "61\n",
            "Epoch: 0076 loss_train: 0.8821 acc_train: 0.8214 loss_val: 0.7252 acc_val: 0.8180 time: 0.0255s\n",
            "62\n",
            "Epoch: 0077 loss_train: 0.9185 acc_train: 0.7929 loss_val: 0.7255 acc_val: 0.8220 time: 0.0277s\n",
            "63\n",
            "Epoch: 0078 loss_train: 0.8378 acc_train: 0.8500 loss_val: 0.7261 acc_val: 0.8200 time: 0.0256s\n",
            "64\n",
            "Epoch: 0079 loss_train: 0.9110 acc_train: 0.7857 loss_val: 0.7295 acc_val: 0.8200 time: 0.0254s\n",
            "65\n",
            "Epoch: 0080 loss_train: 0.8832 acc_train: 0.7786 loss_val: 0.7340 acc_val: 0.8220 time: 0.0258s\n",
            "66\n",
            "Epoch: 0081 loss_train: 0.7956 acc_train: 0.8429 loss_val: 0.7364 acc_val: 0.8180 time: 0.0257s\n",
            "67\n",
            "Epoch: 0082 loss_train: 0.8239 acc_train: 0.8143 loss_val: 0.7372 acc_val: 0.8180 time: 0.0254s\n",
            "68\n",
            "Epoch: 0083 loss_train: 0.8408 acc_train: 0.8500 loss_val: 0.7341 acc_val: 0.8180 time: 0.0256s\n",
            "69\n",
            "Epoch: 0084 loss_train: 0.9073 acc_train: 0.8429 loss_val: 0.7335 acc_val: 0.8140 time: 0.0307s\n",
            "70\n",
            "Epoch: 0085 loss_train: 0.8627 acc_train: 0.8286 loss_val: 0.7326 acc_val: 0.8180 time: 0.0273s\n",
            "71\n",
            "Epoch: 0086 loss_train: 0.8231 acc_train: 0.8643 loss_val: 0.7308 acc_val: 0.8140 time: 0.0255s\n",
            "72\n",
            "Epoch: 0087 loss_train: 0.8192 acc_train: 0.8143 loss_val: 0.7262 acc_val: 0.8140 time: 0.0261s\n",
            "73\n",
            "Epoch: 0088 loss_train: 0.8701 acc_train: 0.8643 loss_val: 0.7220 acc_val: 0.8200 time: 0.0254s\n",
            "74\n",
            "Epoch: 0089 loss_train: 0.8588 acc_train: 0.8714 loss_val: 0.7197 acc_val: 0.8220 time: 0.0260s\n",
            "75\n",
            "Epoch: 0090 loss_train: 0.8496 acc_train: 0.8143 loss_val: 0.7162 acc_val: 0.8160 time: 0.0257s\n",
            "76\n",
            "Epoch: 0091 loss_train: 0.8577 acc_train: 0.8214 loss_val: 0.7153 acc_val: 0.8160 time: 0.0258s\n",
            "77\n",
            "Epoch: 0092 loss_train: 0.8855 acc_train: 0.7714 loss_val: 0.7190 acc_val: 0.8180 time: 0.0297s\n",
            "78\n",
            "Epoch: 0093 loss_train: 0.8199 acc_train: 0.7857 loss_val: 0.7218 acc_val: 0.8180 time: 0.0264s\n",
            "79\n",
            "Epoch: 0094 loss_train: 0.8795 acc_train: 0.8357 loss_val: 0.7253 acc_val: 0.8180 time: 0.0270s\n",
            "80\n",
            "Epoch: 0095 loss_train: 0.8374 acc_train: 0.8143 loss_val: 0.7283 acc_val: 0.8200 time: 0.0267s\n",
            "81\n",
            "Epoch: 0096 loss_train: 0.8680 acc_train: 0.7714 loss_val: 0.7296 acc_val: 0.8220 time: 0.0266s\n",
            "82\n",
            "Epoch: 0097 loss_train: 0.8239 acc_train: 0.9000 loss_val: 0.7304 acc_val: 0.8240 time: 0.0262s\n",
            "83\n",
            "Epoch: 0098 loss_train: 0.8803 acc_train: 0.8000 loss_val: 0.7283 acc_val: 0.8240 time: 0.0267s\n",
            "84\n",
            "Epoch: 0099 loss_train: 0.8221 acc_train: 0.8571 loss_val: 0.7233 acc_val: 0.8220 time: 0.0272s\n",
            "85\n",
            "Epoch: 0100 loss_train: 0.8489 acc_train: 0.8071 loss_val: 0.7181 acc_val: 0.8280 time: 0.0278s\n",
            "86\n",
            "Epoch: 0101 loss_train: 0.9050 acc_train: 0.8286 loss_val: 0.7145 acc_val: 0.8280 time: 0.0269s\n",
            "87\n",
            "Epoch: 0102 loss_train: 0.7850 acc_train: 0.8286 loss_val: 0.7141 acc_val: 0.8280 time: 0.0299s\n",
            "88\n",
            "Epoch: 0103 loss_train: 0.8957 acc_train: 0.8143 loss_val: 0.7144 acc_val: 0.8320 time: 0.0263s\n",
            "89\n",
            "Epoch: 0104 loss_train: 0.8691 acc_train: 0.8071 loss_val: 0.7168 acc_val: 0.8240 time: 0.0264s\n",
            "90\n",
            "Epoch: 0105 loss_train: 0.8432 acc_train: 0.8357 loss_val: 0.7215 acc_val: 0.8160 time: 0.0265s\n",
            "91\n",
            "Epoch: 0106 loss_train: 0.8326 acc_train: 0.8286 loss_val: 0.7266 acc_val: 0.8100 time: 0.0262s\n",
            "92\n",
            "Epoch: 0107 loss_train: 0.8604 acc_train: 0.8071 loss_val: 0.7275 acc_val: 0.8100 time: 0.0280s\n",
            "93\n",
            "Epoch: 0108 loss_train: 0.8479 acc_train: 0.8000 loss_val: 0.7245 acc_val: 0.8100 time: 0.0256s\n",
            "94\n",
            "Epoch: 0109 loss_train: 0.8236 acc_train: 0.8143 loss_val: 0.7219 acc_val: 0.8180 time: 0.0257s\n",
            "95\n",
            "Epoch: 0110 loss_train: 0.8367 acc_train: 0.8143 loss_val: 0.7221 acc_val: 0.8160 time: 0.0257s\n",
            "96\n",
            "Epoch: 0111 loss_train: 0.8554 acc_train: 0.7857 loss_val: 0.7215 acc_val: 0.8220 time: 0.0256s\n",
            "97\n",
            "Epoch: 0112 loss_train: 0.8556 acc_train: 0.8143 loss_val: 0.7222 acc_val: 0.8280 time: 0.0256s\n",
            "98\n",
            "Epoch: 0113 loss_train: 0.8396 acc_train: 0.8286 loss_val: 0.7217 acc_val: 0.8320 time: 0.0257s\n",
            "99\n",
            "Epoch: 0114 loss_train: 0.8296 acc_train: 0.8071 loss_val: 0.7217 acc_val: 0.8300 time: 0.0263s\n",
            "100\n",
            "Epoch: 0115 loss_train: 0.8642 acc_train: 0.7786 loss_val: 0.7203 acc_val: 0.8260 time: 0.0275s\n",
            "101\n",
            "Epoch: 0116 loss_train: 0.8450 acc_train: 0.8643 loss_val: 0.7191 acc_val: 0.8260 time: 0.0256s\n",
            "102\n",
            "Epoch: 0117 loss_train: 0.8716 acc_train: 0.8071 loss_val: 0.7194 acc_val: 0.8200 time: 0.0260s\n",
            "103\n",
            "Epoch: 0118 loss_train: 0.8591 acc_train: 0.8214 loss_val: 0.7201 acc_val: 0.8220 time: 0.0266s\n",
            "104\n",
            "Epoch: 0119 loss_train: 0.8462 acc_train: 0.8571 loss_val: 0.7190 acc_val: 0.8180 time: 0.0263s\n",
            "105\n",
            "Epoch: 0120 loss_train: 0.8494 acc_train: 0.8071 loss_val: 0.7194 acc_val: 0.8140 time: 0.0280s\n",
            "106\n",
            "Epoch: 0121 loss_train: 0.9301 acc_train: 0.8143 loss_val: 0.7210 acc_val: 0.8200 time: 0.0258s\n",
            "107\n",
            "Epoch: 0122 loss_train: 0.8983 acc_train: 0.7643 loss_val: 0.7262 acc_val: 0.8140 time: 0.0263s\n",
            "108\n",
            "Epoch: 0123 loss_train: 0.8231 acc_train: 0.7929 loss_val: 0.7313 acc_val: 0.8100 time: 0.0289s\n",
            "109\n",
            "Epoch: 0124 loss_train: 0.8344 acc_train: 0.8857 loss_val: 0.7339 acc_val: 0.8100 time: 0.0259s\n",
            "110\n",
            "Epoch: 0125 loss_train: 0.9440 acc_train: 0.7714 loss_val: 0.7326 acc_val: 0.8100 time: 0.0257s\n",
            "111\n",
            "Epoch: 0126 loss_train: 0.8280 acc_train: 0.8500 loss_val: 0.7286 acc_val: 0.8120 time: 0.0267s\n",
            "112\n",
            "Epoch: 0127 loss_train: 0.8116 acc_train: 0.8286 loss_val: 0.7254 acc_val: 0.8120 time: 0.0262s\n",
            "113\n",
            "Epoch: 0128 loss_train: 0.8976 acc_train: 0.7571 loss_val: 0.7231 acc_val: 0.8120 time: 0.0255s\n",
            "114\n",
            "Epoch: 0129 loss_train: 0.8651 acc_train: 0.8357 loss_val: 0.7219 acc_val: 0.8120 time: 0.0258s\n",
            "115\n",
            "Epoch: 0130 loss_train: 0.8235 acc_train: 0.8429 loss_val: 0.7212 acc_val: 0.8100 time: 0.0256s\n",
            "116\n",
            "Epoch: 0131 loss_train: 0.8551 acc_train: 0.7714 loss_val: 0.7219 acc_val: 0.8060 time: 0.0271s\n",
            "117\n",
            "Epoch: 0132 loss_train: 0.8873 acc_train: 0.8000 loss_val: 0.7254 acc_val: 0.8080 time: 0.0257s\n",
            "118\n",
            "Epoch: 0133 loss_train: 0.8724 acc_train: 0.7643 loss_val: 0.7302 acc_val: 0.8120 time: 0.0257s\n",
            "119\n",
            "Epoch: 0134 loss_train: 0.8601 acc_train: 0.8286 loss_val: 0.7341 acc_val: 0.8120 time: 0.0255s\n",
            "120\n",
            "Epoch: 0135 loss_train: 0.8378 acc_train: 0.8286 loss_val: 0.7385 acc_val: 0.8100 time: 0.0256s\n",
            "121\n",
            "Epoch: 0136 loss_train: 0.8515 acc_train: 0.8357 loss_val: 0.7385 acc_val: 0.8120 time: 0.0259s\n",
            "122\n",
            "Epoch: 0137 loss_train: 0.8572 acc_train: 0.8571 loss_val: 0.7368 acc_val: 0.8120 time: 0.0256s\n",
            "123\n",
            "Epoch: 0138 loss_train: 0.8027 acc_train: 0.8571 loss_val: 0.7321 acc_val: 0.8120 time: 0.0326s\n",
            "124\n",
            "Epoch: 0139 loss_train: 0.8202 acc_train: 0.8214 loss_val: 0.7279 acc_val: 0.8120 time: 0.0281s\n",
            "125\n",
            "Epoch: 0140 loss_train: 0.8116 acc_train: 0.8500 loss_val: 0.7198 acc_val: 0.8100 time: 0.0265s\n",
            "126\n",
            "Epoch: 0141 loss_train: 0.8728 acc_train: 0.7714 loss_val: 0.7125 acc_val: 0.8160 time: 0.0264s\n",
            "127\n",
            "Epoch: 0142 loss_train: 0.8913 acc_train: 0.8143 loss_val: 0.7121 acc_val: 0.8160 time: 0.0263s\n",
            "128\n",
            "Epoch: 0143 loss_train: 0.8254 acc_train: 0.8429 loss_val: 0.7113 acc_val: 0.8140 time: 0.0256s\n",
            "129\n",
            "Epoch: 0144 loss_train: 0.8452 acc_train: 0.8071 loss_val: 0.7109 acc_val: 0.8100 time: 0.0270s\n",
            "130\n",
            "Epoch: 0145 loss_train: 0.8008 acc_train: 0.8500 loss_val: 0.7107 acc_val: 0.8080 time: 0.0255s\n",
            "131\n",
            "Epoch: 0146 loss_train: 0.8868 acc_train: 0.7786 loss_val: 0.7111 acc_val: 0.8100 time: 0.0282s\n",
            "132\n",
            "Epoch: 0147 loss_train: 0.8262 acc_train: 0.8286 loss_val: 0.7116 acc_val: 0.8180 time: 0.0275s\n",
            "133\n",
            "Epoch: 0148 loss_train: 0.8873 acc_train: 0.7857 loss_val: 0.7150 acc_val: 0.8180 time: 0.0277s\n",
            "134\n",
            "Epoch: 0149 loss_train: 0.8295 acc_train: 0.8214 loss_val: 0.7201 acc_val: 0.8100 time: 0.0265s\n",
            "135\n",
            "Epoch: 0150 loss_train: 0.8248 acc_train: 0.8286 loss_val: 0.7220 acc_val: 0.8040 time: 0.0281s\n",
            "136\n",
            "Epoch: 0151 loss_train: 0.8641 acc_train: 0.8000 loss_val: 0.7257 acc_val: 0.8100 time: 0.0264s\n",
            "137\n",
            "Epoch: 0152 loss_train: 0.8013 acc_train: 0.8214 loss_val: 0.7254 acc_val: 0.8080 time: 0.0264s\n",
            "138\n",
            "Epoch: 0153 loss_train: 0.7992 acc_train: 0.8357 loss_val: 0.7248 acc_val: 0.8140 time: 0.0298s\n",
            "139\n",
            "Epoch: 0154 loss_train: 0.9127 acc_train: 0.7714 loss_val: 0.7214 acc_val: 0.8120 time: 0.0292s\n",
            "140\n",
            "Epoch: 0155 loss_train: 0.8673 acc_train: 0.8571 loss_val: 0.7191 acc_val: 0.8120 time: 0.0307s\n",
            "141\n",
            "Epoch: 0156 loss_train: 0.8687 acc_train: 0.7857 loss_val: 0.7192 acc_val: 0.8140 time: 0.0270s\n",
            "142\n",
            "Epoch: 0157 loss_train: 0.8537 acc_train: 0.8786 loss_val: 0.7190 acc_val: 0.8160 time: 0.0266s\n",
            "143\n",
            "Epoch: 0158 loss_train: 0.7497 acc_train: 0.8643 loss_val: 0.7220 acc_val: 0.8180 time: 0.0263s\n",
            "144\n",
            "Epoch: 0159 loss_train: 0.8526 acc_train: 0.8357 loss_val: 0.7240 acc_val: 0.8160 time: 0.0268s\n",
            "145\n",
            "Epoch: 0160 loss_train: 0.8546 acc_train: 0.8571 loss_val: 0.7233 acc_val: 0.8200 time: 0.0283s\n",
            "146\n",
            "Epoch: 0161 loss_train: 0.8499 acc_train: 0.8286 loss_val: 0.7228 acc_val: 0.8180 time: 0.0282s\n",
            "147\n",
            "Epoch: 0162 loss_train: 0.8463 acc_train: 0.8500 loss_val: 0.7232 acc_val: 0.8200 time: 0.0276s\n",
            "148\n",
            "Epoch: 0163 loss_train: 0.8509 acc_train: 0.8071 loss_val: 0.7245 acc_val: 0.8200 time: 0.0258s\n",
            "149\n",
            "Epoch: 0164 loss_train: 0.8718 acc_train: 0.7786 loss_val: 0.7259 acc_val: 0.8200 time: 0.0258s\n",
            "150\n",
            "Epoch: 0165 loss_train: 0.9014 acc_train: 0.7857 loss_val: 0.7253 acc_val: 0.8160 time: 0.0255s\n",
            "151\n",
            "Epoch: 0166 loss_train: 0.8757 acc_train: 0.7071 loss_val: 0.7244 acc_val: 0.8200 time: 0.0256s\n",
            "152\n",
            "Epoch: 0167 loss_train: 0.8369 acc_train: 0.8429 loss_val: 0.7220 acc_val: 0.8180 time: 0.0267s\n",
            "153\n",
            "Epoch: 0168 loss_train: 0.8268 acc_train: 0.8357 loss_val: 0.7186 acc_val: 0.8200 time: 0.0305s\n",
            "154\n",
            "Epoch: 0169 loss_train: 0.8420 acc_train: 0.8429 loss_val: 0.7170 acc_val: 0.8180 time: 0.0263s\n",
            "155\n",
            "Epoch: 0170 loss_train: 0.8814 acc_train: 0.7214 loss_val: 0.7167 acc_val: 0.8220 time: 0.0275s\n",
            "156\n",
            "Epoch: 0171 loss_train: 0.8141 acc_train: 0.8357 loss_val: 0.7166 acc_val: 0.8220 time: 0.0257s\n",
            "157\n",
            "Epoch: 0172 loss_train: 0.8697 acc_train: 0.7714 loss_val: 0.7188 acc_val: 0.8220 time: 0.0261s\n",
            "158\n",
            "Epoch: 0173 loss_train: 0.8205 acc_train: 0.8143 loss_val: 0.7211 acc_val: 0.8280 time: 0.0275s\n",
            "159\n",
            "Epoch: 0174 loss_train: 0.8704 acc_train: 0.7786 loss_val: 0.7244 acc_val: 0.8220 time: 0.0257s\n",
            "160\n",
            "Epoch: 0175 loss_train: 0.8155 acc_train: 0.8429 loss_val: 0.7269 acc_val: 0.8220 time: 0.0259s\n",
            "161\n",
            "Epoch: 0176 loss_train: 0.7909 acc_train: 0.8214 loss_val: 0.7248 acc_val: 0.8220 time: 0.0280s\n",
            "162\n",
            "Epoch: 0177 loss_train: 0.8824 acc_train: 0.7714 loss_val: 0.7249 acc_val: 0.8200 time: 0.0260s\n",
            "163\n",
            "Epoch: 0178 loss_train: 0.8098 acc_train: 0.8500 loss_val: 0.7235 acc_val: 0.8160 time: 0.0258s\n",
            "164\n",
            "Epoch: 0179 loss_train: 0.8818 acc_train: 0.8000 loss_val: 0.7240 acc_val: 0.8160 time: 0.0273s\n",
            "165\n",
            "Epoch: 0180 loss_train: 0.8444 acc_train: 0.8071 loss_val: 0.7235 acc_val: 0.8120 time: 0.0256s\n",
            "166\n",
            "Epoch: 0181 loss_train: 0.8260 acc_train: 0.8071 loss_val: 0.7253 acc_val: 0.8160 time: 0.0264s\n",
            "167\n",
            "Epoch: 0182 loss_train: 0.8293 acc_train: 0.8500 loss_val: 0.7272 acc_val: 0.8140 time: 0.0256s\n",
            "168\n",
            "Epoch: 0183 loss_train: 0.8779 acc_train: 0.8143 loss_val: 0.7291 acc_val: 0.8180 time: 0.0256s\n",
            "169\n",
            "Epoch: 0184 loss_train: 0.8243 acc_train: 0.8143 loss_val: 0.7299 acc_val: 0.8200 time: 0.0281s\n",
            "170\n",
            "Epoch: 0185 loss_train: 0.8483 acc_train: 0.7929 loss_val: 0.7279 acc_val: 0.8180 time: 0.0267s\n",
            "171\n",
            "Epoch: 0186 loss_train: 0.8600 acc_train: 0.8429 loss_val: 0.7250 acc_val: 0.8220 time: 0.0267s\n",
            "172\n",
            "Epoch: 0187 loss_train: 0.8807 acc_train: 0.8000 loss_val: 0.7231 acc_val: 0.8240 time: 0.0265s\n",
            "173\n",
            "Epoch: 0188 loss_train: 0.8779 acc_train: 0.8071 loss_val: 0.7235 acc_val: 0.8200 time: 0.0266s\n",
            "174\n",
            "Epoch: 0189 loss_train: 0.9047 acc_train: 0.8000 loss_val: 0.7245 acc_val: 0.8220 time: 0.0283s\n",
            "175\n",
            "Epoch: 0190 loss_train: 0.7784 acc_train: 0.8357 loss_val: 0.7254 acc_val: 0.8160 time: 0.0309s\n",
            "176\n",
            "Epoch: 0191 loss_train: 0.8661 acc_train: 0.8000 loss_val: 0.7287 acc_val: 0.8160 time: 0.0298s\n",
            "177\n",
            "Epoch: 0192 loss_train: 0.8307 acc_train: 0.8000 loss_val: 0.7303 acc_val: 0.8120 time: 0.0265s\n",
            "178\n",
            "Epoch: 0193 loss_train: 0.9136 acc_train: 0.7857 loss_val: 0.7334 acc_val: 0.8120 time: 0.0284s\n",
            "179\n",
            "Epoch: 0194 loss_train: 0.8861 acc_train: 0.8000 loss_val: 0.7354 acc_val: 0.8120 time: 0.0268s\n",
            "180\n",
            "Epoch: 0195 loss_train: 0.8082 acc_train: 0.8357 loss_val: 0.7362 acc_val: 0.8140 time: 0.0262s\n",
            "181\n",
            "Epoch: 0196 loss_train: 0.9129 acc_train: 0.7429 loss_val: 0.7340 acc_val: 0.8100 time: 0.0275s\n",
            "182\n",
            "Epoch: 0197 loss_train: 0.9258 acc_train: 0.8143 loss_val: 0.7319 acc_val: 0.8160 time: 0.0259s\n",
            "183\n",
            "Epoch: 0198 loss_train: 0.7706 acc_train: 0.8143 loss_val: 0.7289 acc_val: 0.8220 time: 0.0262s\n",
            "184\n",
            "Epoch: 0199 loss_train: 0.8327 acc_train: 0.7857 loss_val: 0.7235 acc_val: 0.8180 time: 0.0293s\n",
            "185\n",
            "Epoch: 0200 loss_train: 0.8332 acc_train: 0.8357 loss_val: 0.7180 acc_val: 0.8160 time: 0.0267s\n",
            "186\n",
            "Epoch: 0201 loss_train: 0.8077 acc_train: 0.8071 loss_val: 0.7138 acc_val: 0.8120 time: 0.0267s\n",
            "187\n",
            "Epoch: 0202 loss_train: 0.8620 acc_train: 0.8214 loss_val: 0.7133 acc_val: 0.8080 time: 0.0281s\n",
            "188\n",
            "Epoch: 0203 loss_train: 0.8261 acc_train: 0.8143 loss_val: 0.7159 acc_val: 0.8080 time: 0.0272s\n",
            "189\n",
            "Epoch: 0204 loss_train: 0.8040 acc_train: 0.8500 loss_val: 0.7188 acc_val: 0.8080 time: 0.0273s\n",
            "190\n",
            "Epoch: 0205 loss_train: 0.8829 acc_train: 0.8214 loss_val: 0.7242 acc_val: 0.8040 time: 0.0268s\n",
            "191\n",
            "Epoch: 0206 loss_train: 0.8772 acc_train: 0.7786 loss_val: 0.7301 acc_val: 0.8040 time: 0.0292s\n",
            "192\n",
            "Epoch: 0207 loss_train: 0.8649 acc_train: 0.8357 loss_val: 0.7332 acc_val: 0.8120 time: 0.0264s\n",
            "193\n",
            "Epoch: 0208 loss_train: 0.8512 acc_train: 0.8286 loss_val: 0.7354 acc_val: 0.8140 time: 0.0277s\n",
            "194\n",
            "Epoch: 0209 loss_train: 0.8639 acc_train: 0.7714 loss_val: 0.7360 acc_val: 0.8180 time: 0.0267s\n",
            "195\n",
            "Epoch: 0210 loss_train: 0.8572 acc_train: 0.7786 loss_val: 0.7344 acc_val: 0.8200 time: 0.0269s\n",
            "196\n",
            "Epoch: 0211 loss_train: 0.8208 acc_train: 0.8571 loss_val: 0.7295 acc_val: 0.8200 time: 0.0264s\n",
            "197\n",
            "Epoch: 0212 loss_train: 0.8139 acc_train: 0.8143 loss_val: 0.7223 acc_val: 0.8140 time: 0.0269s\n",
            "198\n",
            "Epoch: 0213 loss_train: 0.8349 acc_train: 0.8214 loss_val: 0.7194 acc_val: 0.8160 time: 0.0277s\n",
            "199\n",
            "Early stop! Min loss:  0.6685618162155151 , Max accuracy:  0.836\n",
            "Early stop model validation loss:  0.6685618162155151 , accuracy:  0.8240000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 6.1672s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6300 accuracy= 0.8550\n",
            "Epoch: 0001 loss_train: 0.8671 acc_train: 0.8214 loss_val: 0.6761 acc_val: 0.8280 time: 0.0350s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8228 acc_train: 0.8214 loss_val: 0.6843 acc_val: 0.8220 time: 0.0285s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8898 acc_train: 0.7786 loss_val: 0.6992 acc_val: 0.8200 time: 0.0286s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.8487 acc_train: 0.7929 loss_val: 0.7139 acc_val: 0.8120 time: 0.0288s\n",
            "2\n",
            "Epoch: 0005 loss_train: 0.9126 acc_train: 0.7714 loss_val: 0.7271 acc_val: 0.8100 time: 0.0289s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.8623 acc_train: 0.8000 loss_val: 0.7348 acc_val: 0.8080 time: 0.0293s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.8499 acc_train: 0.8429 loss_val: 0.7333 acc_val: 0.8120 time: 0.0305s\n",
            "5\n",
            "Epoch: 0008 loss_train: 0.8330 acc_train: 0.8071 loss_val: 0.7278 acc_val: 0.8160 time: 0.0292s\n",
            "6\n",
            "Epoch: 0009 loss_train: 0.8578 acc_train: 0.8143 loss_val: 0.7206 acc_val: 0.8280 time: 0.0291s\n",
            "7\n",
            "Epoch: 0010 loss_train: 0.8112 acc_train: 0.8071 loss_val: 0.7154 acc_val: 0.8240 time: 0.0319s\n",
            "0\n",
            "Epoch: 0011 loss_train: 0.8883 acc_train: 0.7786 loss_val: 0.7135 acc_val: 0.8300 time: 0.0292s\n",
            "1\n",
            "Epoch: 0012 loss_train: 0.8192 acc_train: 0.8071 loss_val: 0.7104 acc_val: 0.8300 time: 0.0291s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.8693 acc_train: 0.8500 loss_val: 0.7092 acc_val: 0.8320 time: 0.0302s\n",
            "0\n",
            "Epoch: 0014 loss_train: 0.7972 acc_train: 0.8429 loss_val: 0.7091 acc_val: 0.8260 time: 0.0338s\n",
            "0\n",
            "Epoch: 0015 loss_train: 0.9010 acc_train: 0.8286 loss_val: 0.7135 acc_val: 0.8240 time: 0.0324s\n",
            "1\n",
            "Epoch: 0016 loss_train: 0.9066 acc_train: 0.7786 loss_val: 0.7232 acc_val: 0.8160 time: 0.0295s\n",
            "2\n",
            "Epoch: 0017 loss_train: 0.8399 acc_train: 0.7786 loss_val: 0.7338 acc_val: 0.8120 time: 0.0301s\n",
            "3\n",
            "Epoch: 0018 loss_train: 0.8895 acc_train: 0.7929 loss_val: 0.7438 acc_val: 0.8160 time: 0.0290s\n",
            "4\n",
            "Epoch: 0019 loss_train: 0.8375 acc_train: 0.8643 loss_val: 0.7492 acc_val: 0.8120 time: 0.0288s\n",
            "5\n",
            "Epoch: 0020 loss_train: 0.8991 acc_train: 0.7286 loss_val: 0.7486 acc_val: 0.8140 time: 0.0293s\n",
            "6\n",
            "Epoch: 0021 loss_train: 0.8632 acc_train: 0.7929 loss_val: 0.7453 acc_val: 0.8180 time: 0.0328s\n",
            "7\n",
            "Epoch: 0022 loss_train: 0.8618 acc_train: 0.8214 loss_val: 0.7373 acc_val: 0.8200 time: 0.0296s\n",
            "8\n",
            "Epoch: 0023 loss_train: 0.8260 acc_train: 0.8643 loss_val: 0.7293 acc_val: 0.8260 time: 0.0301s\n",
            "9\n",
            "Epoch: 0024 loss_train: 0.9441 acc_train: 0.7429 loss_val: 0.7259 acc_val: 0.8240 time: 0.0296s\n",
            "10\n",
            "Epoch: 0025 loss_train: 0.8341 acc_train: 0.8500 loss_val: 0.7274 acc_val: 0.8280 time: 0.0299s\n",
            "11\n",
            "Epoch: 0026 loss_train: 0.8508 acc_train: 0.7429 loss_val: 0.7325 acc_val: 0.8140 time: 0.0299s\n",
            "12\n",
            "Epoch: 0027 loss_train: 0.8216 acc_train: 0.8071 loss_val: 0.7386 acc_val: 0.8180 time: 0.0297s\n",
            "13\n",
            "Epoch: 0028 loss_train: 0.8665 acc_train: 0.8357 loss_val: 0.7462 acc_val: 0.8120 time: 0.0316s\n",
            "14\n",
            "Epoch: 0029 loss_train: 0.8586 acc_train: 0.8071 loss_val: 0.7526 acc_val: 0.8100 time: 0.0297s\n",
            "15\n",
            "Epoch: 0030 loss_train: 0.8888 acc_train: 0.7500 loss_val: 0.7573 acc_val: 0.8100 time: 0.0296s\n",
            "16\n",
            "Epoch: 0031 loss_train: 0.8550 acc_train: 0.8143 loss_val: 0.7568 acc_val: 0.8100 time: 0.0297s\n",
            "17\n",
            "Epoch: 0032 loss_train: 0.8097 acc_train: 0.8071 loss_val: 0.7488 acc_val: 0.8040 time: 0.0288s\n",
            "18\n",
            "Epoch: 0033 loss_train: 0.8280 acc_train: 0.8429 loss_val: 0.7379 acc_val: 0.8120 time: 0.0289s\n",
            "19\n",
            "Epoch: 0034 loss_train: 0.8964 acc_train: 0.7714 loss_val: 0.7284 acc_val: 0.8240 time: 0.0291s\n",
            "20\n",
            "Epoch: 0035 loss_train: 0.8583 acc_train: 0.8214 loss_val: 0.7231 acc_val: 0.8280 time: 0.0303s\n",
            "21\n",
            "Epoch: 0036 loss_train: 0.8496 acc_train: 0.8286 loss_val: 0.7209 acc_val: 0.8300 time: 0.0309s\n",
            "22\n",
            "Epoch: 0037 loss_train: 0.8823 acc_train: 0.8143 loss_val: 0.7220 acc_val: 0.8260 time: 0.0288s\n",
            "23\n",
            "Epoch: 0038 loss_train: 0.9020 acc_train: 0.7786 loss_val: 0.7288 acc_val: 0.8280 time: 0.0289s\n",
            "24\n",
            "Epoch: 0039 loss_train: 0.8447 acc_train: 0.8286 loss_val: 0.7389 acc_val: 0.8160 time: 0.0287s\n",
            "25\n",
            "Epoch: 0040 loss_train: 0.8720 acc_train: 0.7786 loss_val: 0.7514 acc_val: 0.8100 time: 0.0288s\n",
            "26\n",
            "Epoch: 0041 loss_train: 0.8509 acc_train: 0.7857 loss_val: 0.7603 acc_val: 0.8040 time: 0.0292s\n",
            "27\n",
            "Epoch: 0042 loss_train: 0.9099 acc_train: 0.7714 loss_val: 0.7682 acc_val: 0.8080 time: 0.0350s\n",
            "28\n",
            "Epoch: 0043 loss_train: 0.8608 acc_train: 0.8071 loss_val: 0.7720 acc_val: 0.8080 time: 0.0302s\n",
            "29\n",
            "Epoch: 0044 loss_train: 0.8814 acc_train: 0.8571 loss_val: 0.7646 acc_val: 0.8120 time: 0.0301s\n",
            "30\n",
            "Epoch: 0045 loss_train: 0.8596 acc_train: 0.8071 loss_val: 0.7509 acc_val: 0.8120 time: 0.0290s\n",
            "31\n",
            "Epoch: 0046 loss_train: 0.8556 acc_train: 0.7786 loss_val: 0.7392 acc_val: 0.8080 time: 0.0306s\n",
            "32\n",
            "Epoch: 0047 loss_train: 0.8891 acc_train: 0.7857 loss_val: 0.7296 acc_val: 0.8160 time: 0.0295s\n",
            "33\n",
            "Epoch: 0048 loss_train: 0.8799 acc_train: 0.8357 loss_val: 0.7274 acc_val: 0.8180 time: 0.0290s\n",
            "34\n",
            "Epoch: 0049 loss_train: 0.8763 acc_train: 0.7857 loss_val: 0.7285 acc_val: 0.8200 time: 0.0314s\n",
            "35\n",
            "Epoch: 0050 loss_train: 0.9041 acc_train: 0.7786 loss_val: 0.7308 acc_val: 0.8260 time: 0.0289s\n",
            "36\n",
            "Epoch: 0051 loss_train: 0.8701 acc_train: 0.7429 loss_val: 0.7331 acc_val: 0.8240 time: 0.0304s\n",
            "37\n",
            "Epoch: 0052 loss_train: 0.8923 acc_train: 0.8143 loss_val: 0.7384 acc_val: 0.8260 time: 0.0287s\n",
            "38\n",
            "Epoch: 0053 loss_train: 0.8632 acc_train: 0.8429 loss_val: 0.7426 acc_val: 0.8160 time: 0.0289s\n",
            "39\n",
            "Epoch: 0054 loss_train: 0.8229 acc_train: 0.8714 loss_val: 0.7438 acc_val: 0.8100 time: 0.0306s\n",
            "40\n",
            "Epoch: 0055 loss_train: 0.8301 acc_train: 0.8214 loss_val: 0.7438 acc_val: 0.8140 time: 0.0288s\n",
            "41\n",
            "Epoch: 0056 loss_train: 0.9425 acc_train: 0.8429 loss_val: 0.7412 acc_val: 0.8120 time: 0.0320s\n",
            "42\n",
            "Epoch: 0057 loss_train: 0.8547 acc_train: 0.7786 loss_val: 0.7410 acc_val: 0.8100 time: 0.0306s\n",
            "43\n",
            "Epoch: 0058 loss_train: 0.9239 acc_train: 0.7571 loss_val: 0.7385 acc_val: 0.8080 time: 0.0309s\n",
            "44\n",
            "Epoch: 0059 loss_train: 0.8681 acc_train: 0.8071 loss_val: 0.7345 acc_val: 0.8080 time: 0.0296s\n",
            "45\n",
            "Epoch: 0060 loss_train: 0.8780 acc_train: 0.7786 loss_val: 0.7348 acc_val: 0.8100 time: 0.0298s\n",
            "46\n",
            "Epoch: 0061 loss_train: 0.8691 acc_train: 0.8500 loss_val: 0.7368 acc_val: 0.8120 time: 0.0293s\n",
            "47\n",
            "Epoch: 0062 loss_train: 0.9207 acc_train: 0.8143 loss_val: 0.7398 acc_val: 0.8100 time: 0.0297s\n",
            "48\n",
            "Epoch: 0063 loss_train: 0.8467 acc_train: 0.8429 loss_val: 0.7434 acc_val: 0.8100 time: 0.0331s\n",
            "49\n",
            "Epoch: 0064 loss_train: 0.8486 acc_train: 0.7929 loss_val: 0.7438 acc_val: 0.8120 time: 0.0302s\n",
            "50\n",
            "Epoch: 0065 loss_train: 0.9059 acc_train: 0.8000 loss_val: 0.7437 acc_val: 0.8080 time: 0.0297s\n",
            "51\n",
            "Epoch: 0066 loss_train: 0.8635 acc_train: 0.8357 loss_val: 0.7414 acc_val: 0.8120 time: 0.0299s\n",
            "52\n",
            "Epoch: 0067 loss_train: 0.9370 acc_train: 0.8071 loss_val: 0.7385 acc_val: 0.8100 time: 0.0293s\n",
            "53\n",
            "Epoch: 0068 loss_train: 0.9081 acc_train: 0.7929 loss_val: 0.7394 acc_val: 0.8080 time: 0.0286s\n",
            "54\n",
            "Epoch: 0069 loss_train: 0.8964 acc_train: 0.8214 loss_val: 0.7416 acc_val: 0.8080 time: 0.0288s\n",
            "55\n",
            "Epoch: 0070 loss_train: 0.8765 acc_train: 0.7500 loss_val: 0.7449 acc_val: 0.8040 time: 0.0331s\n",
            "56\n",
            "Epoch: 0071 loss_train: 0.8289 acc_train: 0.8071 loss_val: 0.7490 acc_val: 0.8060 time: 0.0289s\n",
            "57\n",
            "Epoch: 0072 loss_train: 0.8764 acc_train: 0.8071 loss_val: 0.7488 acc_val: 0.8100 time: 0.0288s\n",
            "58\n",
            "Epoch: 0073 loss_train: 0.8299 acc_train: 0.8000 loss_val: 0.7489 acc_val: 0.8120 time: 0.0329s\n",
            "59\n",
            "Epoch: 0074 loss_train: 0.8760 acc_train: 0.8429 loss_val: 0.7484 acc_val: 0.8140 time: 0.0298s\n",
            "60\n",
            "Epoch: 0075 loss_train: 0.8983 acc_train: 0.7643 loss_val: 0.7467 acc_val: 0.8120 time: 0.0302s\n",
            "61\n",
            "Epoch: 0076 loss_train: 0.8499 acc_train: 0.8214 loss_val: 0.7435 acc_val: 0.8140 time: 0.0297s\n",
            "62\n",
            "Epoch: 0077 loss_train: 0.9032 acc_train: 0.7786 loss_val: 0.7427 acc_val: 0.8120 time: 0.0328s\n",
            "63\n",
            "Epoch: 0078 loss_train: 0.8516 acc_train: 0.8143 loss_val: 0.7420 acc_val: 0.8120 time: 0.0304s\n",
            "64\n",
            "Epoch: 0079 loss_train: 0.8920 acc_train: 0.8357 loss_val: 0.7440 acc_val: 0.8100 time: 0.0290s\n",
            "65\n",
            "Epoch: 0080 loss_train: 0.9154 acc_train: 0.7643 loss_val: 0.7459 acc_val: 0.8100 time: 0.0289s\n",
            "66\n",
            "Epoch: 0081 loss_train: 0.8777 acc_train: 0.7714 loss_val: 0.7464 acc_val: 0.8120 time: 0.0288s\n",
            "67\n",
            "Epoch: 0082 loss_train: 0.8733 acc_train: 0.8429 loss_val: 0.7450 acc_val: 0.8120 time: 0.0284s\n",
            "68\n",
            "Epoch: 0083 loss_train: 0.8729 acc_train: 0.8357 loss_val: 0.7452 acc_val: 0.8060 time: 0.0287s\n",
            "69\n",
            "Epoch: 0084 loss_train: 0.9197 acc_train: 0.7929 loss_val: 0.7497 acc_val: 0.8060 time: 0.0306s\n",
            "70\n",
            "Epoch: 0085 loss_train: 0.8468 acc_train: 0.8214 loss_val: 0.7519 acc_val: 0.8060 time: 0.0288s\n",
            "71\n",
            "Epoch: 0086 loss_train: 0.8848 acc_train: 0.7643 loss_val: 0.7527 acc_val: 0.8060 time: 0.0289s\n",
            "72\n",
            "Epoch: 0087 loss_train: 0.8807 acc_train: 0.7929 loss_val: 0.7549 acc_val: 0.8040 time: 0.0288s\n",
            "73\n",
            "Epoch: 0088 loss_train: 0.8628 acc_train: 0.7714 loss_val: 0.7567 acc_val: 0.8060 time: 0.0320s\n",
            "74\n",
            "Epoch: 0089 loss_train: 0.8233 acc_train: 0.8571 loss_val: 0.7553 acc_val: 0.8080 time: 0.0289s\n",
            "75\n",
            "Epoch: 0090 loss_train: 0.8897 acc_train: 0.7929 loss_val: 0.7511 acc_val: 0.8080 time: 0.0288s\n",
            "76\n",
            "Epoch: 0091 loss_train: 0.8843 acc_train: 0.7500 loss_val: 0.7458 acc_val: 0.8140 time: 0.0321s\n",
            "77\n",
            "Epoch: 0092 loss_train: 0.8863 acc_train: 0.7571 loss_val: 0.7413 acc_val: 0.8140 time: 0.0295s\n",
            "78\n",
            "Epoch: 0093 loss_train: 0.8896 acc_train: 0.7571 loss_val: 0.7361 acc_val: 0.8140 time: 0.0308s\n",
            "79\n",
            "Epoch: 0094 loss_train: 0.8767 acc_train: 0.8214 loss_val: 0.7293 acc_val: 0.8140 time: 0.0302s\n",
            "80\n",
            "Epoch: 0095 loss_train: 0.8995 acc_train: 0.8000 loss_val: 0.7290 acc_val: 0.8200 time: 0.0305s\n",
            "81\n",
            "Epoch: 0096 loss_train: 0.8740 acc_train: 0.7857 loss_val: 0.7299 acc_val: 0.8160 time: 0.0297s\n",
            "82\n",
            "Epoch: 0097 loss_train: 0.8538 acc_train: 0.7714 loss_val: 0.7307 acc_val: 0.8120 time: 0.0297s\n",
            "83\n",
            "Epoch: 0098 loss_train: 0.8735 acc_train: 0.7786 loss_val: 0.7329 acc_val: 0.8120 time: 0.0316s\n",
            "84\n",
            "Epoch: 0099 loss_train: 0.8499 acc_train: 0.7714 loss_val: 0.7349 acc_val: 0.8080 time: 0.0293s\n",
            "85\n",
            "Epoch: 0100 loss_train: 0.8759 acc_train: 0.7786 loss_val: 0.7393 acc_val: 0.8160 time: 0.0295s\n",
            "86\n",
            "Epoch: 0101 loss_train: 0.9479 acc_train: 0.7643 loss_val: 0.7434 acc_val: 0.8120 time: 0.0297s\n",
            "87\n",
            "Epoch: 0102 loss_train: 0.8060 acc_train: 0.8071 loss_val: 0.7426 acc_val: 0.8100 time: 0.0288s\n",
            "88\n",
            "Epoch: 0103 loss_train: 0.8294 acc_train: 0.8929 loss_val: 0.7391 acc_val: 0.8120 time: 0.0295s\n",
            "89\n",
            "Epoch: 0104 loss_train: 0.8734 acc_train: 0.8214 loss_val: 0.7364 acc_val: 0.8200 time: 0.0325s\n",
            "90\n",
            "Epoch: 0105 loss_train: 0.8875 acc_train: 0.7786 loss_val: 0.7362 acc_val: 0.8200 time: 0.0340s\n",
            "91\n",
            "Epoch: 0106 loss_train: 0.8608 acc_train: 0.8143 loss_val: 0.7363 acc_val: 0.8180 time: 0.0291s\n",
            "92\n",
            "Epoch: 0107 loss_train: 0.8704 acc_train: 0.8357 loss_val: 0.7379 acc_val: 0.8180 time: 0.0288s\n",
            "93\n",
            "Epoch: 0108 loss_train: 0.9094 acc_train: 0.7929 loss_val: 0.7413 acc_val: 0.8100 time: 0.0290s\n",
            "94\n",
            "Epoch: 0109 loss_train: 0.8604 acc_train: 0.7643 loss_val: 0.7448 acc_val: 0.8080 time: 0.0299s\n",
            "95\n",
            "Epoch: 0110 loss_train: 0.8203 acc_train: 0.8286 loss_val: 0.7477 acc_val: 0.8080 time: 0.0285s\n",
            "96\n",
            "Epoch: 0111 loss_train: 0.8715 acc_train: 0.7857 loss_val: 0.7496 acc_val: 0.8120 time: 0.0287s\n",
            "97\n",
            "Epoch: 0112 loss_train: 0.9085 acc_train: 0.7714 loss_val: 0.7500 acc_val: 0.8080 time: 0.0332s\n",
            "98\n",
            "Epoch: 0113 loss_train: 0.8920 acc_train: 0.7643 loss_val: 0.7473 acc_val: 0.8040 time: 0.0306s\n",
            "99\n",
            "Epoch: 0114 loss_train: 0.8956 acc_train: 0.7857 loss_val: 0.7477 acc_val: 0.8040 time: 0.0287s\n",
            "100\n",
            "Epoch: 0115 loss_train: 0.8584 acc_train: 0.8143 loss_val: 0.7491 acc_val: 0.8140 time: 0.0288s\n",
            "101\n",
            "Epoch: 0116 loss_train: 0.9072 acc_train: 0.8143 loss_val: 0.7506 acc_val: 0.8180 time: 0.0285s\n",
            "102\n",
            "Epoch: 0117 loss_train: 0.8744 acc_train: 0.8071 loss_val: 0.7508 acc_val: 0.8260 time: 0.0288s\n",
            "103\n",
            "Epoch: 0118 loss_train: 0.8567 acc_train: 0.7714 loss_val: 0.7503 acc_val: 0.8200 time: 0.0287s\n",
            "104\n",
            "Epoch: 0119 loss_train: 0.9013 acc_train: 0.8071 loss_val: 0.7502 acc_val: 0.8200 time: 0.0317s\n",
            "105\n",
            "Epoch: 0120 loss_train: 0.8735 acc_train: 0.8429 loss_val: 0.7509 acc_val: 0.8180 time: 0.0316s\n",
            "106\n",
            "Epoch: 0121 loss_train: 0.8323 acc_train: 0.8286 loss_val: 0.7508 acc_val: 0.8120 time: 0.0296s\n",
            "107\n",
            "Epoch: 0122 loss_train: 0.8686 acc_train: 0.8071 loss_val: 0.7497 acc_val: 0.8120 time: 0.0300s\n",
            "108\n",
            "Epoch: 0123 loss_train: 0.8636 acc_train: 0.8429 loss_val: 0.7471 acc_val: 0.8040 time: 0.0307s\n",
            "109\n",
            "Epoch: 0124 loss_train: 0.8504 acc_train: 0.7643 loss_val: 0.7445 acc_val: 0.8020 time: 0.0302s\n",
            "110\n",
            "Epoch: 0125 loss_train: 0.8484 acc_train: 0.8286 loss_val: 0.7398 acc_val: 0.8060 time: 0.0286s\n",
            "111\n",
            "Epoch: 0126 loss_train: 0.8951 acc_train: 0.8214 loss_val: 0.7389 acc_val: 0.8120 time: 0.0304s\n",
            "112\n",
            "Epoch: 0127 loss_train: 0.8564 acc_train: 0.8286 loss_val: 0.7403 acc_val: 0.8140 time: 0.0291s\n",
            "113\n",
            "Epoch: 0128 loss_train: 0.9006 acc_train: 0.7571 loss_val: 0.7439 acc_val: 0.8160 time: 0.0294s\n",
            "114\n",
            "Epoch: 0129 loss_train: 0.8927 acc_train: 0.8071 loss_val: 0.7478 acc_val: 0.8100 time: 0.0307s\n",
            "115\n",
            "Epoch: 0130 loss_train: 0.8817 acc_train: 0.7857 loss_val: 0.7514 acc_val: 0.8120 time: 0.0287s\n",
            "116\n",
            "Epoch: 0131 loss_train: 0.9644 acc_train: 0.7714 loss_val: 0.7530 acc_val: 0.8100 time: 0.0288s\n",
            "117\n",
            "Epoch: 0132 loss_train: 0.8657 acc_train: 0.8214 loss_val: 0.7539 acc_val: 0.8120 time: 0.0286s\n",
            "118\n",
            "Epoch: 0133 loss_train: 0.8572 acc_train: 0.8286 loss_val: 0.7538 acc_val: 0.8100 time: 0.0320s\n",
            "119\n",
            "Epoch: 0134 loss_train: 0.8433 acc_train: 0.7929 loss_val: 0.7553 acc_val: 0.8140 time: 0.0292s\n",
            "120\n",
            "Epoch: 0135 loss_train: 0.7985 acc_train: 0.7714 loss_val: 0.7553 acc_val: 0.8200 time: 0.0287s\n",
            "121\n",
            "Epoch: 0136 loss_train: 0.8402 acc_train: 0.8143 loss_val: 0.7574 acc_val: 0.8140 time: 0.0323s\n",
            "122\n",
            "Epoch: 0137 loss_train: 0.8469 acc_train: 0.8214 loss_val: 0.7551 acc_val: 0.8080 time: 0.0289s\n",
            "123\n",
            "Epoch: 0138 loss_train: 0.8608 acc_train: 0.8500 loss_val: 0.7524 acc_val: 0.8120 time: 0.0289s\n",
            "124\n",
            "Epoch: 0139 loss_train: 0.8419 acc_train: 0.8071 loss_val: 0.7509 acc_val: 0.8140 time: 0.0289s\n",
            "125\n",
            "Epoch: 0140 loss_train: 0.7872 acc_train: 0.8714 loss_val: 0.7479 acc_val: 0.8160 time: 0.0310s\n",
            "126\n",
            "Epoch: 0141 loss_train: 0.8970 acc_train: 0.8500 loss_val: 0.7407 acc_val: 0.8140 time: 0.0308s\n",
            "127\n",
            "Epoch: 0142 loss_train: 0.8729 acc_train: 0.8071 loss_val: 0.7347 acc_val: 0.8140 time: 0.0291s\n",
            "128\n",
            "Epoch: 0143 loss_train: 0.9379 acc_train: 0.7714 loss_val: 0.7329 acc_val: 0.8180 time: 0.0288s\n",
            "129\n",
            "Epoch: 0144 loss_train: 0.8744 acc_train: 0.8286 loss_val: 0.7346 acc_val: 0.8140 time: 0.0289s\n",
            "130\n",
            "Epoch: 0145 loss_train: 0.8129 acc_train: 0.8214 loss_val: 0.7366 acc_val: 0.8100 time: 0.0290s\n",
            "131\n",
            "Epoch: 0146 loss_train: 0.8932 acc_train: 0.7857 loss_val: 0.7393 acc_val: 0.8120 time: 0.0291s\n",
            "132\n",
            "Epoch: 0147 loss_train: 0.8616 acc_train: 0.8286 loss_val: 0.7428 acc_val: 0.8080 time: 0.0319s\n",
            "133\n",
            "Epoch: 0148 loss_train: 0.8912 acc_train: 0.8071 loss_val: 0.7486 acc_val: 0.8060 time: 0.0302s\n",
            "134\n",
            "Epoch: 0149 loss_train: 0.8666 acc_train: 0.8286 loss_val: 0.7545 acc_val: 0.8020 time: 0.0300s\n",
            "135\n",
            "Epoch: 0150 loss_train: 0.8824 acc_train: 0.7929 loss_val: 0.7544 acc_val: 0.8000 time: 0.0296s\n",
            "136\n",
            "Epoch: 0151 loss_train: 0.9022 acc_train: 0.7857 loss_val: 0.7523 acc_val: 0.8040 time: 0.0296s\n",
            "137\n",
            "Epoch: 0152 loss_train: 0.8611 acc_train: 0.7357 loss_val: 0.7493 acc_val: 0.8100 time: 0.0296s\n",
            "138\n",
            "Epoch: 0153 loss_train: 0.9110 acc_train: 0.7929 loss_val: 0.7468 acc_val: 0.8140 time: 0.0296s\n",
            "139\n",
            "Epoch: 0154 loss_train: 0.8987 acc_train: 0.7571 loss_val: 0.7433 acc_val: 0.8160 time: 0.0313s\n",
            "140\n",
            "Epoch: 0155 loss_train: 0.8330 acc_train: 0.8429 loss_val: 0.7395 acc_val: 0.8220 time: 0.0291s\n",
            "141\n",
            "Epoch: 0156 loss_train: 0.8818 acc_train: 0.7643 loss_val: 0.7379 acc_val: 0.8220 time: 0.0303s\n",
            "142\n",
            "Epoch: 0157 loss_train: 0.8466 acc_train: 0.8286 loss_val: 0.7374 acc_val: 0.8220 time: 0.0309s\n",
            "143\n",
            "Epoch: 0158 loss_train: 0.8585 acc_train: 0.8071 loss_val: 0.7376 acc_val: 0.8220 time: 0.0304s\n",
            "144\n",
            "Epoch: 0159 loss_train: 0.9794 acc_train: 0.8000 loss_val: 0.7403 acc_val: 0.8200 time: 0.0290s\n",
            "145\n",
            "Epoch: 0160 loss_train: 0.8930 acc_train: 0.8000 loss_val: 0.7436 acc_val: 0.8080 time: 0.0289s\n",
            "146\n",
            "Epoch: 0161 loss_train: 0.9375 acc_train: 0.7500 loss_val: 0.7462 acc_val: 0.8080 time: 0.0305s\n",
            "147\n",
            "Epoch: 0162 loss_train: 0.8441 acc_train: 0.8286 loss_val: 0.7497 acc_val: 0.8040 time: 0.0286s\n",
            "148\n",
            "Epoch: 0163 loss_train: 0.8982 acc_train: 0.7857 loss_val: 0.7498 acc_val: 0.8020 time: 0.0288s\n",
            "149\n",
            "Epoch: 0164 loss_train: 0.9198 acc_train: 0.7643 loss_val: 0.7470 acc_val: 0.8020 time: 0.0288s\n",
            "150\n",
            "Epoch: 0165 loss_train: 0.8217 acc_train: 0.8214 loss_val: 0.7438 acc_val: 0.8020 time: 0.0285s\n",
            "151\n",
            "Epoch: 0166 loss_train: 0.8880 acc_train: 0.8071 loss_val: 0.7400 acc_val: 0.8080 time: 0.0289s\n",
            "152\n",
            "Epoch: 0167 loss_train: 0.8477 acc_train: 0.7643 loss_val: 0.7381 acc_val: 0.8120 time: 0.0286s\n",
            "153\n",
            "Epoch: 0168 loss_train: 0.8925 acc_train: 0.8143 loss_val: 0.7389 acc_val: 0.8120 time: 0.0343s\n",
            "154\n",
            "Epoch: 0169 loss_train: 0.8848 acc_train: 0.8286 loss_val: 0.7422 acc_val: 0.8100 time: 0.0305s\n",
            "155\n",
            "Epoch: 0170 loss_train: 0.9200 acc_train: 0.7857 loss_val: 0.7500 acc_val: 0.8080 time: 0.0298s\n",
            "156\n",
            "Epoch: 0171 loss_train: 0.8473 acc_train: 0.8429 loss_val: 0.7568 acc_val: 0.8120 time: 0.0312s\n",
            "157\n",
            "Epoch: 0172 loss_train: 0.8868 acc_train: 0.7929 loss_val: 0.7609 acc_val: 0.8120 time: 0.0300s\n",
            "158\n",
            "Epoch: 0173 loss_train: 0.8499 acc_train: 0.7571 loss_val: 0.7615 acc_val: 0.8120 time: 0.0291s\n",
            "159\n",
            "Epoch: 0174 loss_train: 0.8532 acc_train: 0.8643 loss_val: 0.7568 acc_val: 0.8080 time: 0.0290s\n",
            "160\n",
            "Epoch: 0175 loss_train: 0.8969 acc_train: 0.8000 loss_val: 0.7498 acc_val: 0.8100 time: 0.0308s\n",
            "161\n",
            "Epoch: 0176 loss_train: 0.8534 acc_train: 0.8429 loss_val: 0.7413 acc_val: 0.8120 time: 0.0287s\n",
            "162\n",
            "Epoch: 0177 loss_train: 0.8611 acc_train: 0.7929 loss_val: 0.7343 acc_val: 0.8180 time: 0.0288s\n",
            "163\n",
            "Epoch: 0178 loss_train: 0.8537 acc_train: 0.7857 loss_val: 0.7306 acc_val: 0.8160 time: 0.0294s\n",
            "164\n",
            "Epoch: 0179 loss_train: 0.8590 acc_train: 0.7714 loss_val: 0.7289 acc_val: 0.8140 time: 0.0298s\n",
            "165\n",
            "Epoch: 0180 loss_train: 0.9204 acc_train: 0.8286 loss_val: 0.7325 acc_val: 0.8140 time: 0.0290s\n",
            "166\n",
            "Epoch: 0181 loss_train: 0.9128 acc_train: 0.7500 loss_val: 0.7368 acc_val: 0.8120 time: 0.0288s\n",
            "167\n",
            "Epoch: 0182 loss_train: 0.8883 acc_train: 0.7857 loss_val: 0.7430 acc_val: 0.8140 time: 0.0322s\n",
            "168\n",
            "Epoch: 0183 loss_train: 0.9509 acc_train: 0.7071 loss_val: 0.7504 acc_val: 0.8120 time: 0.0297s\n",
            "169\n",
            "Epoch: 0184 loss_train: 0.9092 acc_train: 0.7571 loss_val: 0.7593 acc_val: 0.8100 time: 0.0301s\n",
            "170\n",
            "Epoch: 0185 loss_train: 0.8904 acc_train: 0.7786 loss_val: 0.7645 acc_val: 0.8060 time: 0.0298s\n",
            "171\n",
            "Epoch: 0186 loss_train: 0.9187 acc_train: 0.7429 loss_val: 0.7657 acc_val: 0.8080 time: 0.0303s\n",
            "172\n",
            "Epoch: 0187 loss_train: 0.8763 acc_train: 0.8571 loss_val: 0.7630 acc_val: 0.8100 time: 0.0302s\n",
            "173\n",
            "Epoch: 0188 loss_train: 0.8868 acc_train: 0.8000 loss_val: 0.7573 acc_val: 0.8140 time: 0.0297s\n",
            "174\n",
            "Epoch: 0189 loss_train: 0.8640 acc_train: 0.7929 loss_val: 0.7518 acc_val: 0.8160 time: 0.0325s\n",
            "175\n",
            "Epoch: 0190 loss_train: 0.8468 acc_train: 0.8857 loss_val: 0.7458 acc_val: 0.8100 time: 0.0298s\n",
            "176\n",
            "Epoch: 0191 loss_train: 0.8103 acc_train: 0.8429 loss_val: 0.7430 acc_val: 0.8120 time: 0.0288s\n",
            "177\n",
            "Epoch: 0192 loss_train: 0.8685 acc_train: 0.7857 loss_val: 0.7423 acc_val: 0.8140 time: 0.0289s\n",
            "178\n",
            "Epoch: 0193 loss_train: 0.8283 acc_train: 0.7857 loss_val: 0.7422 acc_val: 0.8140 time: 0.0287s\n",
            "179\n",
            "Epoch: 0194 loss_train: 0.8655 acc_train: 0.8357 loss_val: 0.7431 acc_val: 0.8100 time: 0.0292s\n",
            "180\n",
            "Epoch: 0195 loss_train: 0.8599 acc_train: 0.7786 loss_val: 0.7431 acc_val: 0.8140 time: 0.0296s\n",
            "181\n",
            "Epoch: 0196 loss_train: 0.9154 acc_train: 0.7571 loss_val: 0.7442 acc_val: 0.8120 time: 0.0319s\n",
            "182\n",
            "Epoch: 0197 loss_train: 0.8979 acc_train: 0.7929 loss_val: 0.7461 acc_val: 0.8160 time: 0.0314s\n",
            "183\n",
            "Epoch: 0198 loss_train: 0.8385 acc_train: 0.8500 loss_val: 0.7516 acc_val: 0.8100 time: 0.0308s\n",
            "184\n",
            "Epoch: 0199 loss_train: 0.8961 acc_train: 0.7929 loss_val: 0.7572 acc_val: 0.8080 time: 0.0333s\n",
            "185\n",
            "Epoch: 0200 loss_train: 0.9044 acc_train: 0.7714 loss_val: 0.7625 acc_val: 0.8060 time: 0.0317s\n",
            "186\n",
            "Epoch: 0201 loss_train: 0.8530 acc_train: 0.8000 loss_val: 0.7612 acc_val: 0.8040 time: 0.0300s\n",
            "187\n",
            "Epoch: 0202 loss_train: 0.8202 acc_train: 0.8571 loss_val: 0.7584 acc_val: 0.8100 time: 0.0303s\n",
            "188\n",
            "Epoch: 0203 loss_train: 0.8246 acc_train: 0.8214 loss_val: 0.7561 acc_val: 0.8060 time: 0.0324s\n",
            "189\n",
            "Epoch: 0204 loss_train: 0.8665 acc_train: 0.7929 loss_val: 0.7504 acc_val: 0.8060 time: 0.0289s\n",
            "190\n",
            "Epoch: 0205 loss_train: 0.8947 acc_train: 0.7429 loss_val: 0.7483 acc_val: 0.8080 time: 0.0288s\n",
            "191\n",
            "Epoch: 0206 loss_train: 0.8155 acc_train: 0.8286 loss_val: 0.7469 acc_val: 0.8080 time: 0.0288s\n",
            "192\n",
            "Epoch: 0207 loss_train: 0.8826 acc_train: 0.8071 loss_val: 0.7475 acc_val: 0.8060 time: 0.0288s\n",
            "193\n",
            "Epoch: 0208 loss_train: 0.8783 acc_train: 0.8286 loss_val: 0.7502 acc_val: 0.8080 time: 0.0288s\n",
            "194\n",
            "Epoch: 0209 loss_train: 0.8370 acc_train: 0.8143 loss_val: 0.7542 acc_val: 0.8060 time: 0.0312s\n",
            "195\n",
            "Epoch: 0210 loss_train: 0.9090 acc_train: 0.8000 loss_val: 0.7557 acc_val: 0.8080 time: 0.0317s\n",
            "196\n",
            "Epoch: 0211 loss_train: 0.8655 acc_train: 0.8571 loss_val: 0.7567 acc_val: 0.8020 time: 0.0287s\n",
            "197\n",
            "Epoch: 0212 loss_train: 0.9098 acc_train: 0.8214 loss_val: 0.7553 acc_val: 0.8100 time: 0.0287s\n",
            "198\n",
            "Epoch: 0213 loss_train: 0.9419 acc_train: 0.7714 loss_val: 0.7553 acc_val: 0.8080 time: 0.0290s\n",
            "199\n",
            "Early stop! Min loss:  0.6760566830635071 , Max accuracy:  0.8320000000000001\n",
            "Early stop model validation loss:  0.6760566830635071 , accuracy:  0.8280000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 6.8434s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6377 accuracy= 0.8490\n",
            "Epoch: 0001 loss_train: 0.9086 acc_train: 0.8071 loss_val: 0.6855 acc_val: 0.8220 time: 0.0354s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.8954 acc_train: 0.8143 loss_val: 0.6947 acc_val: 0.8240 time: 0.0417s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.8863 acc_train: 0.7571 loss_val: 0.7064 acc_val: 0.8220 time: 0.0337s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.9773 acc_train: 0.8143 loss_val: 0.7178 acc_val: 0.8200 time: 0.0333s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.8635 acc_train: 0.8214 loss_val: 0.7292 acc_val: 0.8160 time: 0.0336s\n",
            "2\n",
            "Epoch: 0006 loss_train: 1.0068 acc_train: 0.8143 loss_val: 0.7372 acc_val: 0.8200 time: 0.0326s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.8624 acc_train: 0.8357 loss_val: 0.7387 acc_val: 0.8180 time: 0.0349s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.8842 acc_train: 0.8214 loss_val: 0.7376 acc_val: 0.8220 time: 0.0379s\n",
            "5\n",
            "Epoch: 0009 loss_train: 0.8376 acc_train: 0.8571 loss_val: 0.7338 acc_val: 0.8220 time: 0.0327s\n",
            "6\n",
            "Epoch: 0010 loss_train: 0.8932 acc_train: 0.7714 loss_val: 0.7291 acc_val: 0.8220 time: 0.0328s\n",
            "7\n",
            "Epoch: 0011 loss_train: 0.9090 acc_train: 0.8143 loss_val: 0.7267 acc_val: 0.8240 time: 0.0333s\n",
            "8\n",
            "Epoch: 0012 loss_train: 1.0979 acc_train: 0.8429 loss_val: 0.7261 acc_val: 0.8180 time: 0.0317s\n",
            "0\n",
            "Epoch: 0013 loss_train: 0.8388 acc_train: 0.8357 loss_val: 0.7259 acc_val: 0.8200 time: 0.0318s\n",
            "1\n",
            "Epoch: 0014 loss_train: 0.8728 acc_train: 0.8286 loss_val: 0.7261 acc_val: 0.8200 time: 0.0347s\n",
            "2\n",
            "Epoch: 0015 loss_train: 0.8799 acc_train: 0.7643 loss_val: 0.7276 acc_val: 0.8180 time: 0.0339s\n",
            "3\n",
            "Epoch: 0016 loss_train: 0.9119 acc_train: 0.7929 loss_val: 0.7302 acc_val: 0.8160 time: 0.0328s\n",
            "4\n",
            "Epoch: 0017 loss_train: 0.9082 acc_train: 0.8643 loss_val: 0.7340 acc_val: 0.8120 time: 0.0324s\n",
            "5\n",
            "Epoch: 0018 loss_train: 0.9154 acc_train: 0.7714 loss_val: 0.7401 acc_val: 0.8160 time: 0.0352s\n",
            "6\n",
            "Epoch: 0019 loss_train: 0.9199 acc_train: 0.7143 loss_val: 0.7462 acc_val: 0.8180 time: 0.0327s\n",
            "7\n",
            "Epoch: 0020 loss_train: 0.8726 acc_train: 0.7714 loss_val: 0.7554 acc_val: 0.8160 time: 0.0375s\n",
            "8\n",
            "Epoch: 0021 loss_train: 0.8861 acc_train: 0.8143 loss_val: 0.7611 acc_val: 0.8160 time: 0.0317s\n",
            "9\n",
            "Epoch: 0022 loss_train: 0.8578 acc_train: 0.7714 loss_val: 0.7615 acc_val: 0.8180 time: 0.0318s\n",
            "10\n",
            "Epoch: 0023 loss_train: 0.8954 acc_train: 0.7714 loss_val: 0.7596 acc_val: 0.8180 time: 0.0318s\n",
            "11\n",
            "Epoch: 0024 loss_train: 0.8970 acc_train: 0.7929 loss_val: 0.7578 acc_val: 0.8140 time: 0.0320s\n",
            "12\n",
            "Epoch: 0025 loss_train: 0.8481 acc_train: 0.8143 loss_val: 0.7574 acc_val: 0.8120 time: 0.0315s\n",
            "13\n",
            "Epoch: 0026 loss_train: 0.8865 acc_train: 0.8214 loss_val: 0.7548 acc_val: 0.8120 time: 0.0337s\n",
            "14\n",
            "Epoch: 0027 loss_train: 0.8420 acc_train: 0.7929 loss_val: 0.7544 acc_val: 0.8080 time: 0.0343s\n",
            "15\n",
            "Epoch: 0028 loss_train: 0.8868 acc_train: 0.7643 loss_val: 0.7545 acc_val: 0.8080 time: 0.0319s\n",
            "16\n",
            "Epoch: 0029 loss_train: 0.9531 acc_train: 0.8214 loss_val: 0.7560 acc_val: 0.8120 time: 0.0317s\n",
            "17\n",
            "Epoch: 0030 loss_train: 0.8915 acc_train: 0.8000 loss_val: 0.7581 acc_val: 0.8160 time: 0.0318s\n",
            "18\n",
            "Epoch: 0031 loss_train: 0.8773 acc_train: 0.8071 loss_val: 0.7601 acc_val: 0.8120 time: 0.0317s\n",
            "19\n",
            "Epoch: 0032 loss_train: 0.9719 acc_train: 0.7214 loss_val: 0.7619 acc_val: 0.8120 time: 0.0317s\n",
            "20\n",
            "Epoch: 0033 loss_train: 0.8880 acc_train: 0.7714 loss_val: 0.7608 acc_val: 0.8120 time: 0.0359s\n",
            "21\n",
            "Epoch: 0034 loss_train: 0.8715 acc_train: 0.7571 loss_val: 0.7619 acc_val: 0.8140 time: 0.0334s\n",
            "22\n",
            "Epoch: 0035 loss_train: 0.8646 acc_train: 0.7929 loss_val: 0.7613 acc_val: 0.8160 time: 0.0330s\n",
            "23\n",
            "Epoch: 0036 loss_train: 0.8492 acc_train: 0.8429 loss_val: 0.7616 acc_val: 0.8200 time: 0.0328s\n",
            "24\n",
            "Epoch: 0037 loss_train: 0.9237 acc_train: 0.8357 loss_val: 0.7613 acc_val: 0.8100 time: 0.0328s\n",
            "25\n",
            "Epoch: 0038 loss_train: 0.8540 acc_train: 0.7786 loss_val: 0.7601 acc_val: 0.8100 time: 0.0340s\n",
            "26\n",
            "Epoch: 0039 loss_train: 0.8971 acc_train: 0.8429 loss_val: 0.7592 acc_val: 0.8120 time: 0.0349s\n",
            "27\n",
            "Epoch: 0040 loss_train: 0.9024 acc_train: 0.8357 loss_val: 0.7595 acc_val: 0.8080 time: 0.0320s\n",
            "28\n",
            "Epoch: 0041 loss_train: 0.9196 acc_train: 0.8357 loss_val: 0.7631 acc_val: 0.8100 time: 0.0316s\n",
            "29\n",
            "Epoch: 0042 loss_train: 0.8785 acc_train: 0.7714 loss_val: 0.7681 acc_val: 0.8140 time: 0.0320s\n",
            "30\n",
            "Epoch: 0043 loss_train: 0.9119 acc_train: 0.7571 loss_val: 0.7707 acc_val: 0.8160 time: 0.0317s\n",
            "31\n",
            "Epoch: 0044 loss_train: 0.8815 acc_train: 0.8071 loss_val: 0.7709 acc_val: 0.8220 time: 0.0354s\n",
            "32\n",
            "Epoch: 0045 loss_train: 0.8921 acc_train: 0.8143 loss_val: 0.7696 acc_val: 0.8220 time: 0.0346s\n",
            "33\n",
            "Epoch: 0046 loss_train: 0.8611 acc_train: 0.8429 loss_val: 0.7665 acc_val: 0.8180 time: 0.0335s\n",
            "34\n",
            "Epoch: 0047 loss_train: 0.8793 acc_train: 0.7786 loss_val: 0.7628 acc_val: 0.8220 time: 0.0319s\n",
            "35\n",
            "Epoch: 0048 loss_train: 0.8773 acc_train: 0.7929 loss_val: 0.7603 acc_val: 0.8160 time: 0.0322s\n",
            "36\n",
            "Epoch: 0049 loss_train: 0.9211 acc_train: 0.7286 loss_val: 0.7610 acc_val: 0.8220 time: 0.0326s\n",
            "37\n",
            "Epoch: 0050 loss_train: 0.9119 acc_train: 0.8000 loss_val: 0.7632 acc_val: 0.8140 time: 0.0318s\n",
            "38\n",
            "Epoch: 0051 loss_train: 0.9307 acc_train: 0.8143 loss_val: 0.7662 acc_val: 0.8120 time: 0.0335s\n",
            "39\n",
            "Epoch: 0052 loss_train: 0.8735 acc_train: 0.8357 loss_val: 0.7683 acc_val: 0.8100 time: 0.0327s\n",
            "40\n",
            "Epoch: 0053 loss_train: 0.8937 acc_train: 0.8714 loss_val: 0.7684 acc_val: 0.8160 time: 0.0319s\n",
            "41\n",
            "Epoch: 0054 loss_train: 0.9109 acc_train: 0.8000 loss_val: 0.7649 acc_val: 0.8180 time: 0.0317s\n",
            "42\n",
            "Epoch: 0055 loss_train: 0.8879 acc_train: 0.7929 loss_val: 0.7592 acc_val: 0.8200 time: 0.0320s\n",
            "43\n",
            "Epoch: 0056 loss_train: 0.8738 acc_train: 0.7714 loss_val: 0.7548 acc_val: 0.8240 time: 0.0318s\n",
            "44\n",
            "Epoch: 0057 loss_train: 0.9014 acc_train: 0.7714 loss_val: 0.7483 acc_val: 0.8200 time: 0.0343s\n",
            "0\n",
            "Epoch: 0058 loss_train: 0.8764 acc_train: 0.7929 loss_val: 0.7451 acc_val: 0.8220 time: 0.0355s\n",
            "1\n",
            "Epoch: 0059 loss_train: 0.9147 acc_train: 0.7500 loss_val: 0.7461 acc_val: 0.8220 time: 0.0342s\n",
            "2\n",
            "Epoch: 0060 loss_train: 0.9286 acc_train: 0.7929 loss_val: 0.7501 acc_val: 0.8240 time: 0.0331s\n",
            "3\n",
            "Epoch: 0061 loss_train: 0.8966 acc_train: 0.7857 loss_val: 0.7575 acc_val: 0.8300 time: 0.0329s\n",
            "0\n",
            "Epoch: 0062 loss_train: 0.8727 acc_train: 0.8286 loss_val: 0.7654 acc_val: 0.8260 time: 0.0319s\n",
            "0\n",
            "Epoch: 0063 loss_train: 0.8593 acc_train: 0.8357 loss_val: 0.7742 acc_val: 0.8220 time: 0.0352s\n",
            "1\n",
            "Epoch: 0064 loss_train: 0.9021 acc_train: 0.7786 loss_val: 0.7824 acc_val: 0.8160 time: 0.0352s\n",
            "2\n",
            "Epoch: 0065 loss_train: 0.8917 acc_train: 0.8500 loss_val: 0.7849 acc_val: 0.8120 time: 0.0330s\n",
            "3\n",
            "Epoch: 0066 loss_train: 0.8868 acc_train: 0.7857 loss_val: 0.7811 acc_val: 0.8040 time: 0.0329s\n",
            "4\n",
            "Epoch: 0067 loss_train: 0.8729 acc_train: 0.7571 loss_val: 0.7733 acc_val: 0.8140 time: 0.0331s\n",
            "5\n",
            "Epoch: 0068 loss_train: 0.8510 acc_train: 0.7857 loss_val: 0.7661 acc_val: 0.8160 time: 0.0333s\n",
            "6\n",
            "Epoch: 0069 loss_train: 0.8425 acc_train: 0.8286 loss_val: 0.7571 acc_val: 0.8200 time: 0.0347s\n",
            "7\n",
            "Epoch: 0070 loss_train: 0.8992 acc_train: 0.7857 loss_val: 0.7498 acc_val: 0.8240 time: 0.0332s\n",
            "8\n",
            "Epoch: 0071 loss_train: 0.8839 acc_train: 0.7786 loss_val: 0.7474 acc_val: 0.8260 time: 0.0320s\n",
            "9\n",
            "Epoch: 0072 loss_train: 0.9374 acc_train: 0.8071 loss_val: 0.7488 acc_val: 0.8260 time: 0.0319s\n",
            "10\n",
            "Epoch: 0073 loss_train: 0.8796 acc_train: 0.7786 loss_val: 0.7530 acc_val: 0.8200 time: 0.0387s\n",
            "11\n",
            "Epoch: 0074 loss_train: 0.9259 acc_train: 0.8000 loss_val: 0.7624 acc_val: 0.8200 time: 0.0325s\n",
            "12\n",
            "Epoch: 0075 loss_train: 0.9073 acc_train: 0.7857 loss_val: 0.7708 acc_val: 0.8200 time: 0.0390s\n",
            "13\n",
            "Epoch: 0076 loss_train: 0.9404 acc_train: 0.8071 loss_val: 0.7770 acc_val: 0.8140 time: 0.0330s\n",
            "14\n",
            "Epoch: 0077 loss_train: 0.8706 acc_train: 0.8214 loss_val: 0.7785 acc_val: 0.8000 time: 0.0328s\n",
            "15\n",
            "Epoch: 0078 loss_train: 0.8714 acc_train: 0.7714 loss_val: 0.7768 acc_val: 0.8020 time: 0.0346s\n",
            "16\n",
            "Epoch: 0079 loss_train: 0.9111 acc_train: 0.7786 loss_val: 0.7705 acc_val: 0.8060 time: 0.0328s\n",
            "17\n",
            "Epoch: 0080 loss_train: 0.9165 acc_train: 0.7929 loss_val: 0.7610 acc_val: 0.8140 time: 0.0339s\n",
            "18\n",
            "Epoch: 0081 loss_train: 0.9091 acc_train: 0.7929 loss_val: 0.7528 acc_val: 0.8200 time: 0.0381s\n",
            "19\n",
            "Epoch: 0082 loss_train: 0.9087 acc_train: 0.8143 loss_val: 0.7464 acc_val: 0.8180 time: 0.0328s\n",
            "20\n",
            "Epoch: 0083 loss_train: 0.8660 acc_train: 0.7571 loss_val: 0.7428 acc_val: 0.8180 time: 0.0328s\n",
            "21\n",
            "Epoch: 0084 loss_train: 0.9308 acc_train: 0.8214 loss_val: 0.7437 acc_val: 0.8180 time: 0.0346s\n",
            "22\n",
            "Epoch: 0085 loss_train: 0.9092 acc_train: 0.7786 loss_val: 0.7478 acc_val: 0.8240 time: 0.0343s\n",
            "23\n",
            "Epoch: 0086 loss_train: 0.9107 acc_train: 0.8000 loss_val: 0.7555 acc_val: 0.8200 time: 0.0329s\n",
            "24\n",
            "Epoch: 0087 loss_train: 0.8979 acc_train: 0.8500 loss_val: 0.7637 acc_val: 0.8200 time: 0.0388s\n",
            "25\n",
            "Epoch: 0088 loss_train: 0.8570 acc_train: 0.7786 loss_val: 0.7723 acc_val: 0.8140 time: 0.0328s\n",
            "26\n",
            "Epoch: 0089 loss_train: 0.9263 acc_train: 0.7857 loss_val: 0.7785 acc_val: 0.8100 time: 0.0327s\n",
            "27\n",
            "Epoch: 0090 loss_train: 0.9129 acc_train: 0.8429 loss_val: 0.7778 acc_val: 0.8080 time: 0.0334s\n",
            "28\n",
            "Epoch: 0091 loss_train: 0.8671 acc_train: 0.7643 loss_val: 0.7739 acc_val: 0.8180 time: 0.0327s\n",
            "29\n",
            "Epoch: 0092 loss_train: 0.8891 acc_train: 0.8000 loss_val: 0.7662 acc_val: 0.8080 time: 0.0328s\n",
            "30\n",
            "Epoch: 0093 loss_train: 0.8801 acc_train: 0.8214 loss_val: 0.7591 acc_val: 0.8140 time: 0.0378s\n",
            "31\n",
            "Epoch: 0094 loss_train: 0.8946 acc_train: 0.7643 loss_val: 0.7571 acc_val: 0.8060 time: 0.0315s\n",
            "32\n",
            "Epoch: 0095 loss_train: 0.9032 acc_train: 0.8143 loss_val: 0.7578 acc_val: 0.8080 time: 0.0316s\n",
            "33\n",
            "Epoch: 0096 loss_train: 0.8781 acc_train: 0.8357 loss_val: 0.7595 acc_val: 0.8080 time: 0.0317s\n",
            "34\n",
            "Epoch: 0097 loss_train: 0.9252 acc_train: 0.7929 loss_val: 0.7593 acc_val: 0.8100 time: 0.0316s\n",
            "35\n",
            "Epoch: 0098 loss_train: 0.8472 acc_train: 0.7786 loss_val: 0.7560 acc_val: 0.8140 time: 0.0319s\n",
            "36\n",
            "Epoch: 0099 loss_train: 0.9100 acc_train: 0.8000 loss_val: 0.7550 acc_val: 0.8220 time: 0.0357s\n",
            "37\n",
            "Epoch: 0100 loss_train: 0.9016 acc_train: 0.8286 loss_val: 0.7538 acc_val: 0.8200 time: 0.0352s\n",
            "38\n",
            "Epoch: 0101 loss_train: 0.8483 acc_train: 0.8286 loss_val: 0.7513 acc_val: 0.8200 time: 0.0361s\n",
            "39\n",
            "Epoch: 0102 loss_train: 0.8891 acc_train: 0.8214 loss_val: 0.7501 acc_val: 0.8200 time: 0.0337s\n",
            "40\n",
            "Epoch: 0103 loss_train: 0.9206 acc_train: 0.7786 loss_val: 0.7511 acc_val: 0.8200 time: 0.0315s\n",
            "41\n",
            "Epoch: 0104 loss_train: 0.8828 acc_train: 0.7857 loss_val: 0.7537 acc_val: 0.8200 time: 0.0321s\n",
            "42\n",
            "Epoch: 0105 loss_train: 0.8687 acc_train: 0.7929 loss_val: 0.7590 acc_val: 0.8220 time: 0.0351s\n",
            "43\n",
            "Epoch: 0106 loss_train: 0.8791 acc_train: 0.8357 loss_val: 0.7612 acc_val: 0.8200 time: 0.0341s\n",
            "44\n",
            "Epoch: 0107 loss_train: 0.9665 acc_train: 0.7929 loss_val: 0.7630 acc_val: 0.8140 time: 0.0325s\n",
            "45\n",
            "Epoch: 0108 loss_train: 0.8559 acc_train: 0.8214 loss_val: 0.7656 acc_val: 0.8080 time: 0.0315s\n",
            "46\n",
            "Epoch: 0109 loss_train: 0.8691 acc_train: 0.7857 loss_val: 0.7662 acc_val: 0.8000 time: 0.0317s\n",
            "47\n",
            "Epoch: 0110 loss_train: 0.9307 acc_train: 0.8000 loss_val: 0.7658 acc_val: 0.8020 time: 0.0318s\n",
            "48\n",
            "Epoch: 0111 loss_train: 0.8717 acc_train: 0.7929 loss_val: 0.7656 acc_val: 0.8060 time: 0.0327s\n",
            "49\n",
            "Epoch: 0112 loss_train: 0.9077 acc_train: 0.7643 loss_val: 0.7638 acc_val: 0.8060 time: 0.0398s\n",
            "50\n",
            "Epoch: 0113 loss_train: 0.9174 acc_train: 0.7643 loss_val: 0.7624 acc_val: 0.8060 time: 0.0335s\n",
            "51\n",
            "Epoch: 0114 loss_train: 0.9221 acc_train: 0.8071 loss_val: 0.7623 acc_val: 0.8200 time: 0.0331s\n",
            "52\n",
            "Epoch: 0115 loss_train: 0.8843 acc_train: 0.8143 loss_val: 0.7643 acc_val: 0.8220 time: 0.0328s\n",
            "53\n",
            "Epoch: 0116 loss_train: 0.8891 acc_train: 0.8000 loss_val: 0.7655 acc_val: 0.8240 time: 0.0329s\n",
            "54\n",
            "Epoch: 0117 loss_train: 0.9243 acc_train: 0.8000 loss_val: 0.7649 acc_val: 0.8220 time: 0.0368s\n",
            "55\n",
            "Epoch: 0118 loss_train: 0.8887 acc_train: 0.8214 loss_val: 0.7639 acc_val: 0.8220 time: 0.0345s\n",
            "56\n",
            "Epoch: 0119 loss_train: 0.8794 acc_train: 0.7643 loss_val: 0.7629 acc_val: 0.8240 time: 0.0346s\n",
            "57\n",
            "Epoch: 0120 loss_train: 0.8848 acc_train: 0.8214 loss_val: 0.7654 acc_val: 0.8120 time: 0.0316s\n",
            "58\n",
            "Epoch: 0121 loss_train: 0.8321 acc_train: 0.8000 loss_val: 0.7686 acc_val: 0.8120 time: 0.0316s\n",
            "59\n",
            "Epoch: 0122 loss_train: 0.8828 acc_train: 0.8143 loss_val: 0.7694 acc_val: 0.8140 time: 0.0316s\n",
            "60\n",
            "Epoch: 0123 loss_train: 0.8579 acc_train: 0.8500 loss_val: 0.7679 acc_val: 0.8120 time: 0.0338s\n",
            "61\n",
            "Epoch: 0124 loss_train: 0.8824 acc_train: 0.8143 loss_val: 0.7656 acc_val: 0.8120 time: 0.0342s\n",
            "62\n",
            "Epoch: 0125 loss_train: 0.8721 acc_train: 0.7857 loss_val: 0.7650 acc_val: 0.8160 time: 0.0333s\n",
            "63\n",
            "Epoch: 0126 loss_train: 0.8721 acc_train: 0.8000 loss_val: 0.7632 acc_val: 0.8160 time: 0.0317s\n",
            "64\n",
            "Epoch: 0127 loss_train: 0.8577 acc_train: 0.8571 loss_val: 0.7624 acc_val: 0.8180 time: 0.0317s\n",
            "65\n",
            "Epoch: 0128 loss_train: 0.8892 acc_train: 0.7286 loss_val: 0.7630 acc_val: 0.8160 time: 0.0317s\n",
            "66\n",
            "Epoch: 0129 loss_train: 0.8594 acc_train: 0.7786 loss_val: 0.7627 acc_val: 0.8200 time: 0.0330s\n",
            "67\n",
            "Epoch: 0130 loss_train: 0.8864 acc_train: 0.7857 loss_val: 0.7617 acc_val: 0.8260 time: 0.0375s\n",
            "68\n",
            "Epoch: 0131 loss_train: 0.9464 acc_train: 0.7429 loss_val: 0.7611 acc_val: 0.8140 time: 0.0327s\n",
            "69\n",
            "Epoch: 0132 loss_train: 0.8918 acc_train: 0.7786 loss_val: 0.7628 acc_val: 0.8120 time: 0.0320s\n",
            "70\n",
            "Epoch: 0133 loss_train: 0.8450 acc_train: 0.8214 loss_val: 0.7659 acc_val: 0.8100 time: 0.0318s\n",
            "71\n",
            "Epoch: 0134 loss_train: 0.8924 acc_train: 0.8214 loss_val: 0.7720 acc_val: 0.8060 time: 0.0321s\n",
            "72\n",
            "Epoch: 0135 loss_train: 0.8465 acc_train: 0.7857 loss_val: 0.7748 acc_val: 0.8080 time: 0.0318s\n",
            "73\n",
            "Epoch: 0136 loss_train: 0.8482 acc_train: 0.8071 loss_val: 0.7763 acc_val: 0.8080 time: 0.0350s\n",
            "74\n",
            "Epoch: 0137 loss_train: 0.8893 acc_train: 0.7357 loss_val: 0.7765 acc_val: 0.8060 time: 0.0331s\n",
            "75\n",
            "Epoch: 0138 loss_train: 0.9625 acc_train: 0.7214 loss_val: 0.7756 acc_val: 0.8080 time: 0.0319s\n",
            "76\n",
            "Epoch: 0139 loss_train: 0.9096 acc_train: 0.7857 loss_val: 0.7719 acc_val: 0.8200 time: 0.0319s\n",
            "77\n",
            "Epoch: 0140 loss_train: 0.9231 acc_train: 0.7429 loss_val: 0.7695 acc_val: 0.8220 time: 0.0319s\n",
            "78\n",
            "Epoch: 0141 loss_train: 0.8508 acc_train: 0.8357 loss_val: 0.7664 acc_val: 0.8220 time: 0.0322s\n",
            "79\n",
            "Epoch: 0142 loss_train: 0.9085 acc_train: 0.7857 loss_val: 0.7633 acc_val: 0.8220 time: 0.0358s\n",
            "80\n",
            "Epoch: 0143 loss_train: 0.8882 acc_train: 0.8214 loss_val: 0.7648 acc_val: 0.8160 time: 0.0330s\n",
            "81\n",
            "Epoch: 0144 loss_train: 0.9023 acc_train: 0.7857 loss_val: 0.7676 acc_val: 0.8200 time: 0.0332s\n",
            "82\n",
            "Epoch: 0145 loss_train: 0.8972 acc_train: 0.7786 loss_val: 0.7728 acc_val: 0.8160 time: 0.0331s\n",
            "83\n",
            "Epoch: 0146 loss_train: 0.9298 acc_train: 0.8071 loss_val: 0.7752 acc_val: 0.8120 time: 0.0333s\n",
            "84\n",
            "Epoch: 0147 loss_train: 0.8557 acc_train: 0.7929 loss_val: 0.7740 acc_val: 0.8200 time: 0.0337s\n",
            "85\n",
            "Epoch: 0148 loss_train: 0.9015 acc_train: 0.7714 loss_val: 0.7704 acc_val: 0.8180 time: 0.0383s\n",
            "86\n",
            "Epoch: 0149 loss_train: 0.9134 acc_train: 0.8357 loss_val: 0.7688 acc_val: 0.8140 time: 0.0320s\n",
            "87\n",
            "Epoch: 0150 loss_train: 0.8580 acc_train: 0.8143 loss_val: 0.7678 acc_val: 0.8180 time: 0.0318s\n",
            "88\n",
            "Epoch: 0151 loss_train: 0.9154 acc_train: 0.7714 loss_val: 0.7671 acc_val: 0.8200 time: 0.0332s\n",
            "89\n",
            "Epoch: 0152 loss_train: 0.8978 acc_train: 0.7786 loss_val: 0.7656 acc_val: 0.8240 time: 0.0321s\n",
            "90\n",
            "Epoch: 0153 loss_train: 0.9095 acc_train: 0.8000 loss_val: 0.7613 acc_val: 0.8220 time: 0.0335s\n",
            "91\n",
            "Epoch: 0154 loss_train: 0.9089 acc_train: 0.7357 loss_val: 0.7594 acc_val: 0.8160 time: 0.0347s\n",
            "92\n",
            "Epoch: 0155 loss_train: 0.9076 acc_train: 0.7857 loss_val: 0.7588 acc_val: 0.8200 time: 0.0320s\n",
            "93\n",
            "Epoch: 0156 loss_train: 0.8893 acc_train: 0.8000 loss_val: 0.7614 acc_val: 0.8160 time: 0.0322s\n",
            "94\n",
            "Epoch: 0157 loss_train: 0.8418 acc_train: 0.8214 loss_val: 0.7629 acc_val: 0.8200 time: 0.0323s\n",
            "95\n",
            "Epoch: 0158 loss_train: 0.9061 acc_train: 0.8071 loss_val: 0.7650 acc_val: 0.8180 time: 0.0319s\n",
            "96\n",
            "Epoch: 0159 loss_train: 0.9093 acc_train: 0.7643 loss_val: 0.7675 acc_val: 0.8180 time: 0.0365s\n",
            "97\n",
            "Epoch: 0160 loss_train: 0.8900 acc_train: 0.7857 loss_val: 0.7688 acc_val: 0.8180 time: 0.0355s\n",
            "98\n",
            "Epoch: 0161 loss_train: 0.9082 acc_train: 0.7786 loss_val: 0.7684 acc_val: 0.8200 time: 0.0321s\n",
            "99\n",
            "Epoch: 0162 loss_train: 0.9372 acc_train: 0.7500 loss_val: 0.7689 acc_val: 0.8180 time: 0.0318s\n",
            "100\n",
            "Epoch: 0163 loss_train: 0.8604 acc_train: 0.8429 loss_val: 0.7703 acc_val: 0.8180 time: 0.0316s\n",
            "101\n",
            "Epoch: 0164 loss_train: 0.9350 acc_train: 0.7357 loss_val: 0.7732 acc_val: 0.8200 time: 0.0318s\n",
            "102\n",
            "Epoch: 0165 loss_train: 0.9208 acc_train: 0.8214 loss_val: 0.7719 acc_val: 0.8140 time: 0.0319s\n",
            "103\n",
            "Epoch: 0166 loss_train: 0.9265 acc_train: 0.8071 loss_val: 0.7730 acc_val: 0.8140 time: 0.0350s\n",
            "104\n",
            "Epoch: 0167 loss_train: 0.8835 acc_train: 0.7643 loss_val: 0.7712 acc_val: 0.8080 time: 0.0331s\n",
            "105\n",
            "Epoch: 0168 loss_train: 0.8492 acc_train: 0.8143 loss_val: 0.7676 acc_val: 0.8120 time: 0.0335s\n",
            "106\n",
            "Epoch: 0169 loss_train: 0.8737 acc_train: 0.7429 loss_val: 0.7648 acc_val: 0.8160 time: 0.0353s\n",
            "107\n",
            "Epoch: 0170 loss_train: 0.9278 acc_train: 0.7786 loss_val: 0.7623 acc_val: 0.8100 time: 0.0329s\n",
            "108\n",
            "Epoch: 0171 loss_train: 0.8574 acc_train: 0.8286 loss_val: 0.7607 acc_val: 0.8120 time: 0.0327s\n",
            "109\n",
            "Epoch: 0172 loss_train: 0.8297 acc_train: 0.8714 loss_val: 0.7626 acc_val: 0.8120 time: 0.0378s\n",
            "110\n",
            "Epoch: 0173 loss_train: 0.8621 acc_train: 0.8571 loss_val: 0.7635 acc_val: 0.8120 time: 0.0332s\n",
            "111\n",
            "Epoch: 0174 loss_train: 0.9208 acc_train: 0.8286 loss_val: 0.7672 acc_val: 0.8120 time: 0.0322s\n",
            "112\n",
            "Epoch: 0175 loss_train: 0.8377 acc_train: 0.8071 loss_val: 0.7693 acc_val: 0.8120 time: 0.0319s\n",
            "113\n",
            "Epoch: 0176 loss_train: 0.8507 acc_train: 0.7571 loss_val: 0.7703 acc_val: 0.8120 time: 0.0320s\n",
            "114\n",
            "Epoch: 0177 loss_train: 0.9445 acc_train: 0.7357 loss_val: 0.7677 acc_val: 0.8140 time: 0.0333s\n",
            "115\n",
            "Epoch: 0178 loss_train: 0.9004 acc_train: 0.8500 loss_val: 0.7657 acc_val: 0.8120 time: 0.0341s\n",
            "116\n",
            "Epoch: 0179 loss_train: 0.8836 acc_train: 0.8000 loss_val: 0.7662 acc_val: 0.8140 time: 0.0321s\n",
            "117\n",
            "Epoch: 0180 loss_train: 0.8723 acc_train: 0.8500 loss_val: 0.7675 acc_val: 0.8140 time: 0.0318s\n",
            "118\n",
            "Epoch: 0181 loss_train: 0.8957 acc_train: 0.7571 loss_val: 0.7692 acc_val: 0.8140 time: 0.0318s\n",
            "119\n",
            "Epoch: 0182 loss_train: 0.9800 acc_train: 0.8143 loss_val: 0.7698 acc_val: 0.8160 time: 0.0318s\n",
            "120\n",
            "Epoch: 0183 loss_train: 0.9038 acc_train: 0.8071 loss_val: 0.7692 acc_val: 0.8160 time: 0.0317s\n",
            "121\n",
            "Epoch: 0184 loss_train: 0.8686 acc_train: 0.7857 loss_val: 0.7721 acc_val: 0.8080 time: 0.0342s\n",
            "122\n",
            "Epoch: 0185 loss_train: 0.8981 acc_train: 0.8000 loss_val: 0.7758 acc_val: 0.8040 time: 0.0337s\n",
            "123\n",
            "Epoch: 0186 loss_train: 0.8386 acc_train: 0.8500 loss_val: 0.7823 acc_val: 0.8040 time: 0.0323s\n",
            "124\n",
            "Epoch: 0187 loss_train: 0.9864 acc_train: 0.7571 loss_val: 0.7885 acc_val: 0.8060 time: 0.0332s\n",
            "125\n",
            "Epoch: 0188 loss_train: 0.9171 acc_train: 0.7857 loss_val: 0.7910 acc_val: 0.8020 time: 0.0353s\n",
            "126\n",
            "Epoch: 0189 loss_train: 0.8649 acc_train: 0.8571 loss_val: 0.7869 acc_val: 0.8060 time: 0.0317s\n",
            "127\n",
            "Epoch: 0190 loss_train: 0.9118 acc_train: 0.7857 loss_val: 0.7772 acc_val: 0.8080 time: 0.0324s\n",
            "128\n",
            "Epoch: 0191 loss_train: 0.8992 acc_train: 0.8000 loss_val: 0.7694 acc_val: 0.8060 time: 0.0354s\n",
            "129\n",
            "Epoch: 0192 loss_train: 0.8343 acc_train: 0.8429 loss_val: 0.7634 acc_val: 0.8180 time: 0.0329s\n",
            "130\n",
            "Epoch: 0193 loss_train: 0.9072 acc_train: 0.7857 loss_val: 0.7607 acc_val: 0.8200 time: 0.0330s\n",
            "131\n",
            "Epoch: 0194 loss_train: 0.8497 acc_train: 0.8286 loss_val: 0.7586 acc_val: 0.8200 time: 0.0327s\n",
            "132\n",
            "Epoch: 0195 loss_train: 0.8898 acc_train: 0.8071 loss_val: 0.7590 acc_val: 0.8160 time: 0.0329s\n",
            "133\n",
            "Epoch: 0196 loss_train: 0.8960 acc_train: 0.7786 loss_val: 0.7643 acc_val: 0.8240 time: 0.0342s\n",
            "134\n",
            "Epoch: 0197 loss_train: 0.8844 acc_train: 0.7714 loss_val: 0.7701 acc_val: 0.8260 time: 0.0347s\n",
            "135\n",
            "Epoch: 0198 loss_train: 0.8605 acc_train: 0.8071 loss_val: 0.7768 acc_val: 0.8180 time: 0.0335s\n",
            "136\n",
            "Epoch: 0199 loss_train: 0.9183 acc_train: 0.8071 loss_val: 0.7832 acc_val: 0.8140 time: 0.0337s\n",
            "137\n",
            "Epoch: 0200 loss_train: 0.8715 acc_train: 0.7643 loss_val: 0.7860 acc_val: 0.8100 time: 0.0327s\n",
            "138\n",
            "Epoch: 0201 loss_train: 0.9196 acc_train: 0.7643 loss_val: 0.7871 acc_val: 0.8040 time: 0.0320s\n",
            "139\n",
            "Epoch: 0202 loss_train: 0.9186 acc_train: 0.7714 loss_val: 0.7865 acc_val: 0.8000 time: 0.0328s\n",
            "140\n",
            "Epoch: 0203 loss_train: 0.8661 acc_train: 0.8357 loss_val: 0.7850 acc_val: 0.7980 time: 0.0345s\n",
            "141\n",
            "Epoch: 0204 loss_train: 0.8749 acc_train: 0.8071 loss_val: 0.7838 acc_val: 0.7980 time: 0.0324s\n",
            "142\n",
            "Epoch: 0205 loss_train: 0.9001 acc_train: 0.7143 loss_val: 0.7809 acc_val: 0.8020 time: 0.0332s\n",
            "143\n",
            "Epoch: 0206 loss_train: 0.9481 acc_train: 0.7643 loss_val: 0.7811 acc_val: 0.8100 time: 0.0318s\n",
            "144\n",
            "Epoch: 0207 loss_train: 0.8867 acc_train: 0.8143 loss_val: 0.7777 acc_val: 0.8160 time: 0.0318s\n",
            "145\n",
            "Epoch: 0208 loss_train: 0.8171 acc_train: 0.7857 loss_val: 0.7745 acc_val: 0.8140 time: 0.0315s\n",
            "146\n",
            "Epoch: 0209 loss_train: 0.9274 acc_train: 0.7429 loss_val: 0.7726 acc_val: 0.8120 time: 0.0344s\n",
            "147\n",
            "Epoch: 0210 loss_train: 0.8761 acc_train: 0.8286 loss_val: 0.7680 acc_val: 0.8060 time: 0.0318s\n",
            "148\n",
            "Epoch: 0211 loss_train: 0.9379 acc_train: 0.8000 loss_val: 0.7656 acc_val: 0.8100 time: 0.0320s\n",
            "149\n",
            "Epoch: 0212 loss_train: 0.9349 acc_train: 0.6786 loss_val: 0.7674 acc_val: 0.8080 time: 0.0322s\n",
            "150\n",
            "Epoch: 0213 loss_train: 0.8998 acc_train: 0.7500 loss_val: 0.7715 acc_val: 0.8060 time: 0.0312s\n",
            "151\n",
            "Epoch: 0214 loss_train: 0.8833 acc_train: 0.8071 loss_val: 0.7739 acc_val: 0.8060 time: 0.0315s\n",
            "152\n",
            "Epoch: 0215 loss_train: 0.8321 acc_train: 0.7857 loss_val: 0.7731 acc_val: 0.8020 time: 0.0353s\n",
            "153\n",
            "Epoch: 0216 loss_train: 0.8446 acc_train: 0.8071 loss_val: 0.7723 acc_val: 0.8080 time: 0.0357s\n",
            "154\n",
            "Epoch: 0217 loss_train: 0.8975 acc_train: 0.8643 loss_val: 0.7709 acc_val: 0.8060 time: 0.0340s\n",
            "155\n",
            "Epoch: 0218 loss_train: 0.8338 acc_train: 0.8286 loss_val: 0.7702 acc_val: 0.8080 time: 0.0331s\n",
            "156\n",
            "Epoch: 0219 loss_train: 0.8599 acc_train: 0.8214 loss_val: 0.7683 acc_val: 0.8060 time: 0.0328s\n",
            "157\n",
            "Epoch: 0220 loss_train: 0.9142 acc_train: 0.7500 loss_val: 0.7666 acc_val: 0.8100 time: 0.0332s\n",
            "158\n",
            "Epoch: 0221 loss_train: 0.9110 acc_train: 0.7571 loss_val: 0.7654 acc_val: 0.8180 time: 0.0368s\n",
            "159\n",
            "Epoch: 0222 loss_train: 0.9275 acc_train: 0.7357 loss_val: 0.7667 acc_val: 0.8140 time: 0.0368s\n",
            "160\n",
            "Epoch: 0223 loss_train: 0.8909 acc_train: 0.8214 loss_val: 0.7700 acc_val: 0.8160 time: 0.0340s\n",
            "161\n",
            "Epoch: 0224 loss_train: 0.9846 acc_train: 0.6714 loss_val: 0.7748 acc_val: 0.8180 time: 0.0336s\n",
            "162\n",
            "Epoch: 0225 loss_train: 0.8983 acc_train: 0.7643 loss_val: 0.7784 acc_val: 0.8140 time: 0.0327s\n",
            "163\n",
            "Epoch: 0226 loss_train: 0.8749 acc_train: 0.7643 loss_val: 0.7806 acc_val: 0.8160 time: 0.0322s\n",
            "164\n",
            "Epoch: 0227 loss_train: 0.8496 acc_train: 0.8357 loss_val: 0.7787 acc_val: 0.8200 time: 0.0393s\n",
            "165\n",
            "Epoch: 0228 loss_train: 0.9026 acc_train: 0.8071 loss_val: 0.7786 acc_val: 0.8160 time: 0.0320s\n",
            "166\n",
            "Epoch: 0229 loss_train: 0.8522 acc_train: 0.8071 loss_val: 0.7749 acc_val: 0.8100 time: 0.0325s\n",
            "167\n",
            "Epoch: 0230 loss_train: 0.8743 acc_train: 0.7929 loss_val: 0.7700 acc_val: 0.8120 time: 0.0320s\n",
            "168\n",
            "Epoch: 0231 loss_train: 0.8993 acc_train: 0.7929 loss_val: 0.7660 acc_val: 0.8100 time: 0.0318s\n",
            "169\n",
            "Epoch: 0232 loss_train: 0.9149 acc_train: 0.7643 loss_val: 0.7662 acc_val: 0.8120 time: 0.0320s\n",
            "170\n",
            "Epoch: 0233 loss_train: 0.8613 acc_train: 0.8357 loss_val: 0.7648 acc_val: 0.8140 time: 0.0335s\n",
            "171\n",
            "Epoch: 0234 loss_train: 0.8865 acc_train: 0.7929 loss_val: 0.7656 acc_val: 0.8160 time: 0.0333s\n",
            "172\n",
            "Epoch: 0235 loss_train: 0.9541 acc_train: 0.7143 loss_val: 0.7702 acc_val: 0.8160 time: 0.0320s\n",
            "173\n",
            "Epoch: 0236 loss_train: 0.9282 acc_train: 0.7929 loss_val: 0.7730 acc_val: 0.8180 time: 0.0323s\n",
            "174\n",
            "Epoch: 0237 loss_train: 0.8840 acc_train: 0.8143 loss_val: 0.7776 acc_val: 0.8160 time: 0.0334s\n",
            "175\n",
            "Epoch: 0238 loss_train: 0.9036 acc_train: 0.7857 loss_val: 0.7781 acc_val: 0.8120 time: 0.0320s\n",
            "176\n",
            "Epoch: 0239 loss_train: 0.8895 acc_train: 0.8214 loss_val: 0.7768 acc_val: 0.8120 time: 0.0327s\n",
            "177\n",
            "Epoch: 0240 loss_train: 0.9157 acc_train: 0.7929 loss_val: 0.7737 acc_val: 0.8160 time: 0.0344s\n",
            "178\n",
            "Epoch: 0241 loss_train: 0.9150 acc_train: 0.8214 loss_val: 0.7716 acc_val: 0.8200 time: 0.0319s\n",
            "179\n",
            "Epoch: 0242 loss_train: 0.9000 acc_train: 0.7571 loss_val: 0.7711 acc_val: 0.8240 time: 0.0316s\n",
            "180\n",
            "Epoch: 0243 loss_train: 0.8614 acc_train: 0.8071 loss_val: 0.7695 acc_val: 0.8220 time: 0.0324s\n",
            "181\n",
            "Epoch: 0244 loss_train: 0.8918 acc_train: 0.8214 loss_val: 0.7688 acc_val: 0.8240 time: 0.0319s\n",
            "182\n",
            "Epoch: 0245 loss_train: 0.8741 acc_train: 0.8357 loss_val: 0.7714 acc_val: 0.8180 time: 0.0361s\n",
            "183\n",
            "Epoch: 0246 loss_train: 0.8634 acc_train: 0.8429 loss_val: 0.7743 acc_val: 0.8160 time: 0.0372s\n",
            "184\n",
            "Epoch: 0247 loss_train: 0.9144 acc_train: 0.8071 loss_val: 0.7766 acc_val: 0.8180 time: 0.0328s\n",
            "185\n",
            "Epoch: 0248 loss_train: 0.8741 acc_train: 0.8071 loss_val: 0.7779 acc_val: 0.8140 time: 0.0328s\n",
            "186\n",
            "Epoch: 0249 loss_train: 0.8688 acc_train: 0.8000 loss_val: 0.7787 acc_val: 0.8160 time: 0.0329s\n",
            "187\n",
            "Epoch: 0250 loss_train: 0.8959 acc_train: 0.7929 loss_val: 0.7799 acc_val: 0.8140 time: 0.0321s\n",
            "188\n",
            "Epoch: 0251 loss_train: 0.8543 acc_train: 0.8357 loss_val: 0.7784 acc_val: 0.8160 time: 0.0324s\n",
            "189\n",
            "Epoch: 0252 loss_train: 0.9571 acc_train: 0.7143 loss_val: 0.7795 acc_val: 0.8180 time: 0.0364s\n",
            "190\n",
            "Epoch: 0253 loss_train: 0.8805 acc_train: 0.8143 loss_val: 0.7791 acc_val: 0.8200 time: 0.0327s\n",
            "191\n",
            "Epoch: 0254 loss_train: 0.9249 acc_train: 0.7786 loss_val: 0.7769 acc_val: 0.8240 time: 0.0329s\n",
            "192\n",
            "Epoch: 0255 loss_train: 0.8375 acc_train: 0.8571 loss_val: 0.7723 acc_val: 0.8240 time: 0.0329s\n",
            "193\n",
            "Epoch: 0256 loss_train: 0.8642 acc_train: 0.7929 loss_val: 0.7651 acc_val: 0.8260 time: 0.0324s\n",
            "194\n",
            "Epoch: 0257 loss_train: 0.8248 acc_train: 0.8000 loss_val: 0.7583 acc_val: 0.8240 time: 0.0356s\n",
            "195\n",
            "Epoch: 0258 loss_train: 0.9061 acc_train: 0.7714 loss_val: 0.7537 acc_val: 0.8200 time: 0.0346s\n",
            "196\n",
            "Epoch: 0259 loss_train: 0.9049 acc_train: 0.7643 loss_val: 0.7527 acc_val: 0.8180 time: 0.0328s\n",
            "197\n",
            "Epoch: 0260 loss_train: 0.8442 acc_train: 0.7857 loss_val: 0.7541 acc_val: 0.8180 time: 0.0343s\n",
            "198\n",
            "Epoch: 0261 loss_train: 0.9050 acc_train: 0.8143 loss_val: 0.7580 acc_val: 0.8200 time: 0.0334s\n",
            "199\n",
            "Early stop! Min loss:  0.6854670643806458 , Max accuracy:  0.8300000000000001\n",
            "Early stop model validation loss:  0.6854670643806458 , accuracy:  0.8220000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 9.2291s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6473 accuracy= 0.8480\n",
            "Epoch: 0001 loss_train: 0.8912 acc_train: 0.8500 loss_val: 0.7005 acc_val: 0.8240 time: 0.0357s\n",
            "0\n",
            "Epoch: 0002 loss_train: 0.9101 acc_train: 0.8429 loss_val: 0.7132 acc_val: 0.8160 time: 0.0389s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.9508 acc_train: 0.8143 loss_val: 0.7254 acc_val: 0.8120 time: 0.0361s\n",
            "1\n",
            "Epoch: 0004 loss_train: 0.8719 acc_train: 0.7571 loss_val: 0.7357 acc_val: 0.8100 time: 0.0350s\n",
            "2\n",
            "Epoch: 0005 loss_train: 1.2206 acc_train: 0.8143 loss_val: 0.7437 acc_val: 0.8120 time: 0.0347s\n",
            "3\n",
            "Epoch: 0006 loss_train: 0.8804 acc_train: 0.8357 loss_val: 0.7494 acc_val: 0.8140 time: 0.0347s\n",
            "4\n",
            "Epoch: 0007 loss_train: 0.8887 acc_train: 0.8214 loss_val: 0.7511 acc_val: 0.8140 time: 0.0349s\n",
            "5\n",
            "Epoch: 0008 loss_train: 0.9259 acc_train: 0.8143 loss_val: 0.7512 acc_val: 0.8180 time: 0.0373s\n",
            "6\n",
            "Epoch: 0009 loss_train: 1.6355 acc_train: 0.7286 loss_val: 0.7497 acc_val: 0.8180 time: 0.0354s\n",
            "7\n",
            "Epoch: 0010 loss_train: 0.8970 acc_train: 0.8214 loss_val: 0.7495 acc_val: 0.8180 time: 0.0347s\n",
            "8\n",
            "Epoch: 0011 loss_train: 0.9178 acc_train: 0.8429 loss_val: 0.7481 acc_val: 0.8140 time: 0.0359s\n",
            "9\n",
            "Epoch: 0012 loss_train: 0.9084 acc_train: 0.8000 loss_val: 0.7473 acc_val: 0.8140 time: 0.0372s\n",
            "10\n",
            "Epoch: 0013 loss_train: 0.9163 acc_train: 0.8357 loss_val: 0.7483 acc_val: 0.8160 time: 0.0346s\n",
            "11\n",
            "Epoch: 0014 loss_train: 0.9219 acc_train: 0.8286 loss_val: 0.7506 acc_val: 0.8140 time: 0.0389s\n",
            "12\n",
            "Epoch: 0015 loss_train: 0.8893 acc_train: 0.7286 loss_val: 0.7549 acc_val: 0.8080 time: 0.0351s\n",
            "13\n",
            "Epoch: 0016 loss_train: 0.9900 acc_train: 0.6714 loss_val: 0.7582 acc_val: 0.8060 time: 0.0348s\n",
            "14\n",
            "Epoch: 0017 loss_train: 0.9472 acc_train: 0.7857 loss_val: 0.7599 acc_val: 0.8060 time: 0.0368s\n",
            "15\n",
            "Epoch: 0018 loss_train: 0.9412 acc_train: 0.8000 loss_val: 0.7584 acc_val: 0.8080 time: 0.0349s\n",
            "16\n",
            "Epoch: 0019 loss_train: 0.9210 acc_train: 0.8000 loss_val: 0.7575 acc_val: 0.8120 time: 0.0348s\n",
            "17\n",
            "Epoch: 0020 loss_train: 0.9131 acc_train: 0.7857 loss_val: 0.7592 acc_val: 0.8140 time: 0.0396s\n",
            "18\n",
            "Epoch: 0021 loss_train: 0.9494 acc_train: 0.7643 loss_val: 0.7622 acc_val: 0.8080 time: 0.0365s\n",
            "19\n",
            "Epoch: 0022 loss_train: 0.8825 acc_train: 0.8000 loss_val: 0.7655 acc_val: 0.8080 time: 0.0363s\n",
            "20\n",
            "Epoch: 0023 loss_train: 0.8526 acc_train: 0.7786 loss_val: 0.7673 acc_val: 0.8100 time: 0.0362s\n",
            "21\n",
            "Epoch: 0024 loss_train: 0.9245 acc_train: 0.7286 loss_val: 0.7686 acc_val: 0.8120 time: 0.0361s\n",
            "22\n",
            "Epoch: 0025 loss_train: 0.9462 acc_train: 0.8143 loss_val: 0.7716 acc_val: 0.8140 time: 0.0356s\n",
            "23\n",
            "Epoch: 0026 loss_train: 0.9427 acc_train: 0.7571 loss_val: 0.7763 acc_val: 0.8120 time: 0.0409s\n",
            "24\n",
            "Epoch: 0027 loss_train: 0.8986 acc_train: 0.7571 loss_val: 0.7801 acc_val: 0.8120 time: 0.0349s\n",
            "25\n",
            "Epoch: 0028 loss_train: 1.0134 acc_train: 0.7071 loss_val: 0.7840 acc_val: 0.8060 time: 0.0353s\n",
            "26\n",
            "Epoch: 0029 loss_train: 0.9360 acc_train: 0.7857 loss_val: 0.7866 acc_val: 0.8100 time: 0.0352s\n",
            "27\n",
            "Epoch: 0030 loss_train: 0.8738 acc_train: 0.7929 loss_val: 0.7887 acc_val: 0.8120 time: 0.0348s\n",
            "28\n",
            "Epoch: 0031 loss_train: 0.8925 acc_train: 0.7929 loss_val: 0.7903 acc_val: 0.8120 time: 0.0372s\n",
            "29\n",
            "Epoch: 0032 loss_train: 0.9033 acc_train: 0.8143 loss_val: 0.7903 acc_val: 0.8140 time: 0.0383s\n",
            "30\n",
            "Epoch: 0033 loss_train: 0.9123 acc_train: 0.8143 loss_val: 0.7875 acc_val: 0.8120 time: 0.0360s\n",
            "31\n",
            "Epoch: 0034 loss_train: 0.8786 acc_train: 0.7857 loss_val: 0.7858 acc_val: 0.8040 time: 0.0359s\n",
            "32\n",
            "Epoch: 0035 loss_train: 0.8497 acc_train: 0.8286 loss_val: 0.7846 acc_val: 0.8060 time: 0.0363s\n",
            "33\n",
            "Epoch: 0036 loss_train: 0.8943 acc_train: 0.8429 loss_val: 0.7834 acc_val: 0.8080 time: 0.0359s\n",
            "34\n",
            "Epoch: 0037 loss_train: 0.9501 acc_train: 0.8000 loss_val: 0.7825 acc_val: 0.8060 time: 0.0363s\n",
            "35\n",
            "Epoch: 0038 loss_train: 0.9164 acc_train: 0.8000 loss_val: 0.7811 acc_val: 0.8060 time: 0.0411s\n",
            "36\n",
            "Epoch: 0039 loss_train: 0.8867 acc_train: 0.8214 loss_val: 0.7808 acc_val: 0.8060 time: 0.0352s\n",
            "37\n",
            "Epoch: 0040 loss_train: 0.9390 acc_train: 0.7714 loss_val: 0.7817 acc_val: 0.8120 time: 0.0351s\n",
            "38\n",
            "Epoch: 0041 loss_train: 0.9069 acc_train: 0.7429 loss_val: 0.7834 acc_val: 0.8160 time: 0.0350s\n",
            "39\n",
            "Epoch: 0042 loss_train: 0.9836 acc_train: 0.7500 loss_val: 0.7870 acc_val: 0.8200 time: 0.0348s\n",
            "40\n",
            "Epoch: 0043 loss_train: 0.9137 acc_train: 0.7786 loss_val: 0.7907 acc_val: 0.8140 time: 0.0360s\n",
            "41\n",
            "Epoch: 0044 loss_train: 0.9053 acc_train: 0.7357 loss_val: 0.7944 acc_val: 0.8120 time: 0.0374s\n",
            "42\n",
            "Epoch: 0045 loss_train: 0.8982 acc_train: 0.7857 loss_val: 0.7975 acc_val: 0.8100 time: 0.0365s\n",
            "43\n",
            "Epoch: 0046 loss_train: 0.9127 acc_train: 0.7714 loss_val: 0.7983 acc_val: 0.8080 time: 0.0349s\n",
            "44\n",
            "Epoch: 0047 loss_train: 0.9076 acc_train: 0.8357 loss_val: 0.7986 acc_val: 0.8000 time: 0.0347s\n",
            "45\n",
            "Epoch: 0048 loss_train: 0.9261 acc_train: 0.8286 loss_val: 0.7948 acc_val: 0.8000 time: 0.0352s\n",
            "46\n",
            "Epoch: 0049 loss_train: 0.9014 acc_train: 0.7643 loss_val: 0.7904 acc_val: 0.8000 time: 0.0346s\n",
            "47\n",
            "Epoch: 0050 loss_train: 0.9486 acc_train: 0.8286 loss_val: 0.7903 acc_val: 0.8000 time: 0.0376s\n",
            "48\n",
            "Epoch: 0051 loss_train: 0.9623 acc_train: 0.7500 loss_val: 0.7898 acc_val: 0.8020 time: 0.0366s\n",
            "49\n",
            "Epoch: 0052 loss_train: 0.8966 acc_train: 0.7786 loss_val: 0.7910 acc_val: 0.8000 time: 0.0360s\n",
            "50\n",
            "Epoch: 0053 loss_train: 0.9593 acc_train: 0.8000 loss_val: 0.7928 acc_val: 0.8060 time: 0.0360s\n",
            "51\n",
            "Epoch: 0054 loss_train: 0.8863 acc_train: 0.7786 loss_val: 0.7943 acc_val: 0.8100 time: 0.0359s\n",
            "52\n",
            "Epoch: 0055 loss_train: 0.9523 acc_train: 0.8143 loss_val: 0.7939 acc_val: 0.8120 time: 0.0370s\n",
            "53\n",
            "Epoch: 0056 loss_train: 0.8723 acc_train: 0.7786 loss_val: 0.7919 acc_val: 0.8140 time: 0.0385s\n",
            "54\n",
            "Epoch: 0057 loss_train: 0.8554 acc_train: 0.8500 loss_val: 0.7898 acc_val: 0.8180 time: 0.0373s\n",
            "55\n",
            "Epoch: 0058 loss_train: 0.9753 acc_train: 0.7643 loss_val: 0.7865 acc_val: 0.8180 time: 0.0350s\n",
            "56\n",
            "Epoch: 0059 loss_train: 0.9152 acc_train: 0.7429 loss_val: 0.7830 acc_val: 0.8180 time: 0.0348s\n",
            "57\n",
            "Epoch: 0060 loss_train: 0.8987 acc_train: 0.8143 loss_val: 0.7810 acc_val: 0.8140 time: 0.0346s\n",
            "58\n",
            "Epoch: 0061 loss_train: 0.9521 acc_train: 0.7857 loss_val: 0.7828 acc_val: 0.8100 time: 0.0355s\n",
            "59\n",
            "Epoch: 0062 loss_train: 0.9781 acc_train: 0.7429 loss_val: 0.7877 acc_val: 0.8000 time: 0.0412s\n",
            "60\n",
            "Epoch: 0063 loss_train: 1.0059 acc_train: 0.8357 loss_val: 0.7911 acc_val: 0.7980 time: 0.0373s\n",
            "61\n",
            "Epoch: 0064 loss_train: 0.9350 acc_train: 0.8071 loss_val: 0.7933 acc_val: 0.8020 time: 0.0415s\n",
            "62\n",
            "Epoch: 0065 loss_train: 0.9664 acc_train: 0.7786 loss_val: 0.7963 acc_val: 0.8020 time: 0.0365s\n",
            "63\n",
            "Epoch: 0066 loss_train: 0.9277 acc_train: 0.8214 loss_val: 0.8019 acc_val: 0.8000 time: 0.0361s\n",
            "64\n",
            "Epoch: 0067 loss_train: 0.9559 acc_train: 0.7429 loss_val: 0.8081 acc_val: 0.7980 time: 0.0361s\n",
            "65\n",
            "Epoch: 0068 loss_train: 0.9238 acc_train: 0.7071 loss_val: 0.8122 acc_val: 0.7980 time: 0.0381s\n",
            "66\n",
            "Epoch: 0069 loss_train: 0.9487 acc_train: 0.7571 loss_val: 0.8110 acc_val: 0.8040 time: 0.0375s\n",
            "67\n",
            "Epoch: 0070 loss_train: 0.9229 acc_train: 0.8786 loss_val: 0.8087 acc_val: 0.8080 time: 0.0365s\n",
            "68\n",
            "Epoch: 0071 loss_train: 0.9414 acc_train: 0.7643 loss_val: 0.8059 acc_val: 0.8080 time: 0.0351s\n",
            "69\n",
            "Epoch: 0072 loss_train: 0.9631 acc_train: 0.7571 loss_val: 0.8026 acc_val: 0.8160 time: 0.0352s\n",
            "70\n",
            "Epoch: 0073 loss_train: 0.8902 acc_train: 0.7714 loss_val: 0.7979 acc_val: 0.8120 time: 0.0348s\n",
            "71\n",
            "Epoch: 0074 loss_train: 0.9471 acc_train: 0.7786 loss_val: 0.7930 acc_val: 0.8120 time: 0.0371s\n",
            "72\n",
            "Epoch: 0075 loss_train: 0.9553 acc_train: 0.7214 loss_val: 0.7926 acc_val: 0.8020 time: 0.0363s\n",
            "73\n",
            "Epoch: 0076 loss_train: 0.8786 acc_train: 0.8357 loss_val: 0.7969 acc_val: 0.7980 time: 0.0350s\n",
            "74\n",
            "Epoch: 0077 loss_train: 0.9594 acc_train: 0.8286 loss_val: 0.8041 acc_val: 0.7920 time: 0.0349s\n",
            "75\n",
            "Epoch: 0078 loss_train: 0.9020 acc_train: 0.7714 loss_val: 0.8133 acc_val: 0.7920 time: 0.0349s\n",
            "76\n",
            "Epoch: 0079 loss_train: 0.9197 acc_train: 0.7643 loss_val: 0.8198 acc_val: 0.7860 time: 0.0348s\n",
            "77\n",
            "Epoch: 0080 loss_train: 0.9119 acc_train: 0.7429 loss_val: 0.8214 acc_val: 0.7840 time: 0.0393s\n",
            "78\n",
            "Epoch: 0081 loss_train: 0.8895 acc_train: 0.8143 loss_val: 0.8197 acc_val: 0.7920 time: 0.0353s\n",
            "79\n",
            "Epoch: 0082 loss_train: 0.9085 acc_train: 0.8071 loss_val: 0.8151 acc_val: 0.7920 time: 0.0351s\n",
            "80\n",
            "Epoch: 0083 loss_train: 0.8887 acc_train: 0.8429 loss_val: 0.8062 acc_val: 0.7960 time: 0.0347s\n",
            "81\n",
            "Epoch: 0084 loss_train: 0.9182 acc_train: 0.8357 loss_val: 0.7993 acc_val: 0.8120 time: 0.0347s\n",
            "82\n",
            "Epoch: 0085 loss_train: 0.9295 acc_train: 0.7786 loss_val: 0.7952 acc_val: 0.8060 time: 0.0350s\n",
            "83\n",
            "Epoch: 0086 loss_train: 0.8936 acc_train: 0.8571 loss_val: 0.7964 acc_val: 0.8060 time: 0.0376s\n",
            "84\n",
            "Epoch: 0087 loss_train: 0.9010 acc_train: 0.8000 loss_val: 0.7979 acc_val: 0.8040 time: 0.0363s\n",
            "85\n",
            "Epoch: 0088 loss_train: 0.9238 acc_train: 0.7643 loss_val: 0.8015 acc_val: 0.8060 time: 0.0369s\n",
            "86\n",
            "Epoch: 0089 loss_train: 0.9358 acc_train: 0.7214 loss_val: 0.8062 acc_val: 0.8020 time: 0.0379s\n",
            "87\n",
            "Epoch: 0090 loss_train: 0.9416 acc_train: 0.7571 loss_val: 0.8100 acc_val: 0.7920 time: 0.0363s\n",
            "88\n",
            "Epoch: 0091 loss_train: 0.9535 acc_train: 0.8071 loss_val: 0.8104 acc_val: 0.7860 time: 0.0387s\n",
            "89\n",
            "Epoch: 0092 loss_train: 0.9851 acc_train: 0.7714 loss_val: 0.8122 acc_val: 0.7880 time: 0.0375s\n",
            "90\n",
            "Epoch: 0093 loss_train: 0.9391 acc_train: 0.7500 loss_val: 0.8136 acc_val: 0.7860 time: 0.0351s\n",
            "91\n",
            "Epoch: 0094 loss_train: 0.9019 acc_train: 0.8071 loss_val: 0.8105 acc_val: 0.7940 time: 0.0348s\n",
            "92\n",
            "Epoch: 0095 loss_train: 0.8799 acc_train: 0.8071 loss_val: 0.8063 acc_val: 0.7920 time: 0.0354s\n",
            "93\n",
            "Epoch: 0096 loss_train: 0.8769 acc_train: 0.7500 loss_val: 0.8032 acc_val: 0.8000 time: 0.0350s\n",
            "94\n",
            "Epoch: 0097 loss_train: 0.9262 acc_train: 0.8000 loss_val: 0.8024 acc_val: 0.8040 time: 0.0350s\n",
            "95\n",
            "Epoch: 0098 loss_train: 0.9217 acc_train: 0.8071 loss_val: 0.8004 acc_val: 0.8120 time: 0.0380s\n",
            "96\n",
            "Epoch: 0099 loss_train: 0.8892 acc_train: 0.8000 loss_val: 0.8024 acc_val: 0.8040 time: 0.0349s\n",
            "97\n",
            "Epoch: 0100 loss_train: 0.9280 acc_train: 0.7857 loss_val: 0.8072 acc_val: 0.7980 time: 0.0348s\n",
            "98\n",
            "Epoch: 0101 loss_train: 0.8882 acc_train: 0.8143 loss_val: 0.8086 acc_val: 0.7980 time: 0.0353s\n",
            "99\n",
            "Epoch: 0102 loss_train: 0.8959 acc_train: 0.8357 loss_val: 0.8055 acc_val: 0.7960 time: 0.0356s\n",
            "100\n",
            "Epoch: 0103 loss_train: 0.9582 acc_train: 0.8000 loss_val: 0.8005 acc_val: 0.7980 time: 0.0354s\n",
            "101\n",
            "Epoch: 0104 loss_train: 0.8792 acc_train: 0.7857 loss_val: 0.7956 acc_val: 0.8000 time: 0.0377s\n",
            "102\n",
            "Epoch: 0105 loss_train: 0.9621 acc_train: 0.7714 loss_val: 0.7904 acc_val: 0.8000 time: 0.0348s\n",
            "103\n",
            "Epoch: 0106 loss_train: 0.9053 acc_train: 0.7786 loss_val: 0.7882 acc_val: 0.7960 time: 0.0350s\n",
            "104\n",
            "Epoch: 0107 loss_train: 0.8505 acc_train: 0.8286 loss_val: 0.7877 acc_val: 0.8020 time: 0.0352s\n",
            "105\n",
            "Epoch: 0108 loss_train: 0.9766 acc_train: 0.8000 loss_val: 0.7893 acc_val: 0.8000 time: 0.0347s\n",
            "106\n",
            "Epoch: 0109 loss_train: 0.9129 acc_train: 0.8143 loss_val: 0.7972 acc_val: 0.8000 time: 0.0349s\n",
            "107\n",
            "Epoch: 0110 loss_train: 0.9029 acc_train: 0.7571 loss_val: 0.8046 acc_val: 0.8020 time: 0.0373s\n",
            "108\n",
            "Epoch: 0111 loss_train: 0.9165 acc_train: 0.8143 loss_val: 0.8095 acc_val: 0.8080 time: 0.0362s\n",
            "109\n",
            "Epoch: 0112 loss_train: 0.8834 acc_train: 0.7714 loss_val: 0.8097 acc_val: 0.8040 time: 0.0358s\n",
            "110\n",
            "Epoch: 0113 loss_train: 0.8807 acc_train: 0.8643 loss_val: 0.8035 acc_val: 0.8040 time: 0.0362s\n",
            "111\n",
            "Epoch: 0114 loss_train: 0.8776 acc_train: 0.7643 loss_val: 0.7941 acc_val: 0.8040 time: 0.0368s\n",
            "112\n",
            "Epoch: 0115 loss_train: 0.9085 acc_train: 0.8357 loss_val: 0.7877 acc_val: 0.8040 time: 0.0371s\n",
            "113\n",
            "Epoch: 0116 loss_train: 0.8668 acc_train: 0.8643 loss_val: 0.7836 acc_val: 0.8000 time: 0.0386s\n",
            "114\n",
            "Epoch: 0117 loss_train: 0.8750 acc_train: 0.8000 loss_val: 0.7828 acc_val: 0.8040 time: 0.0394s\n",
            "115\n",
            "Epoch: 0118 loss_train: 0.9381 acc_train: 0.7786 loss_val: 0.7823 acc_val: 0.8040 time: 0.0350s\n",
            "116\n",
            "Epoch: 0119 loss_train: 0.9369 acc_train: 0.7500 loss_val: 0.7811 acc_val: 0.8020 time: 0.0351s\n",
            "117\n",
            "Epoch: 0120 loss_train: 0.9299 acc_train: 0.8143 loss_val: 0.7836 acc_val: 0.7980 time: 0.0360s\n",
            "118\n",
            "Epoch: 0121 loss_train: 0.8972 acc_train: 0.8143 loss_val: 0.7870 acc_val: 0.7980 time: 0.0349s\n",
            "119\n",
            "Epoch: 0122 loss_train: 0.8826 acc_train: 0.7429 loss_val: 0.7910 acc_val: 0.8000 time: 0.0391s\n",
            "120\n",
            "Epoch: 0123 loss_train: 0.9271 acc_train: 0.7929 loss_val: 0.7960 acc_val: 0.8020 time: 0.0363s\n",
            "121\n",
            "Epoch: 0124 loss_train: 0.8734 acc_train: 0.8071 loss_val: 0.7982 acc_val: 0.8060 time: 0.0365s\n",
            "122\n",
            "Epoch: 0125 loss_train: 0.8392 acc_train: 0.8143 loss_val: 0.7967 acc_val: 0.8060 time: 0.0361s\n",
            "123\n",
            "Epoch: 0126 loss_train: 0.8455 acc_train: 0.8357 loss_val: 0.7898 acc_val: 0.8040 time: 0.0359s\n",
            "124\n",
            "Epoch: 0127 loss_train: 0.8451 acc_train: 0.8643 loss_val: 0.7826 acc_val: 0.8060 time: 0.0376s\n",
            "125\n",
            "Epoch: 0128 loss_train: 0.9481 acc_train: 0.7857 loss_val: 0.7784 acc_val: 0.8100 time: 0.0378s\n",
            "126\n",
            "Epoch: 0129 loss_train: 0.9274 acc_train: 0.8000 loss_val: 0.7765 acc_val: 0.8080 time: 0.0349s\n",
            "127\n",
            "Epoch: 0130 loss_train: 0.9177 acc_train: 0.8357 loss_val: 0.7787 acc_val: 0.8060 time: 0.0348s\n",
            "128\n",
            "Epoch: 0131 loss_train: 0.8769 acc_train: 0.8143 loss_val: 0.7836 acc_val: 0.8120 time: 0.0363s\n",
            "129\n",
            "Epoch: 0132 loss_train: 0.8887 acc_train: 0.7429 loss_val: 0.7910 acc_val: 0.8040 time: 0.0359s\n",
            "130\n",
            "Epoch: 0133 loss_train: 0.9114 acc_train: 0.8000 loss_val: 0.7968 acc_val: 0.8040 time: 0.0349s\n",
            "131\n",
            "Epoch: 0134 loss_train: 0.9257 acc_train: 0.7357 loss_val: 0.7987 acc_val: 0.8060 time: 0.0372s\n",
            "132\n",
            "Epoch: 0135 loss_train: 0.9428 acc_train: 0.7857 loss_val: 0.7997 acc_val: 0.8040 time: 0.0349s\n",
            "133\n",
            "Epoch: 0136 loss_train: 0.9121 acc_train: 0.8071 loss_val: 0.8009 acc_val: 0.8060 time: 0.0359s\n",
            "134\n",
            "Epoch: 0137 loss_train: 0.8966 acc_train: 0.8214 loss_val: 0.7995 acc_val: 0.8020 time: 0.0354s\n",
            "135\n",
            "Epoch: 0138 loss_train: 0.9283 acc_train: 0.8286 loss_val: 0.7993 acc_val: 0.8040 time: 0.0349s\n",
            "136\n",
            "Epoch: 0139 loss_train: 0.9168 acc_train: 0.7643 loss_val: 0.7955 acc_val: 0.8060 time: 0.0350s\n",
            "137\n",
            "Epoch: 0140 loss_train: 0.9425 acc_train: 0.8000 loss_val: 0.7889 acc_val: 0.8140 time: 0.0399s\n",
            "138\n",
            "Epoch: 0141 loss_train: 0.8684 acc_train: 0.8143 loss_val: 0.7809 acc_val: 0.8120 time: 0.0370s\n",
            "139\n",
            "Epoch: 0142 loss_train: 0.9006 acc_train: 0.7786 loss_val: 0.7765 acc_val: 0.8120 time: 0.0374s\n",
            "140\n",
            "Epoch: 0143 loss_train: 0.8299 acc_train: 0.8143 loss_val: 0.7755 acc_val: 0.8160 time: 0.0358s\n",
            "141\n",
            "Epoch: 0144 loss_train: 0.9298 acc_train: 0.7571 loss_val: 0.7773 acc_val: 0.8200 time: 0.0386s\n",
            "142\n",
            "Epoch: 0145 loss_train: 0.8906 acc_train: 0.8143 loss_val: 0.7820 acc_val: 0.8200 time: 0.0380s\n",
            "143\n",
            "Epoch: 0146 loss_train: 0.8384 acc_train: 0.7571 loss_val: 0.7856 acc_val: 0.8180 time: 0.0393s\n",
            "144\n",
            "Epoch: 0147 loss_train: 0.9141 acc_train: 0.8071 loss_val: 0.7905 acc_val: 0.8120 time: 0.0371s\n",
            "145\n",
            "Epoch: 0148 loss_train: 0.8610 acc_train: 0.8357 loss_val: 0.7908 acc_val: 0.8120 time: 0.0363s\n",
            "146\n",
            "Epoch: 0149 loss_train: 0.8911 acc_train: 0.7714 loss_val: 0.7929 acc_val: 0.8100 time: 0.0364s\n",
            "147\n",
            "Epoch: 0150 loss_train: 0.9253 acc_train: 0.7571 loss_val: 0.7923 acc_val: 0.8040 time: 0.0373s\n",
            "148\n",
            "Epoch: 0151 loss_train: 0.9095 acc_train: 0.7643 loss_val: 0.7924 acc_val: 0.8040 time: 0.0376s\n",
            "149\n",
            "Epoch: 0152 loss_train: 0.8648 acc_train: 0.7429 loss_val: 0.7884 acc_val: 0.8100 time: 0.0417s\n",
            "150\n",
            "Epoch: 0153 loss_train: 0.8915 acc_train: 0.8286 loss_val: 0.7834 acc_val: 0.8220 time: 0.0347s\n",
            "151\n",
            "Epoch: 0154 loss_train: 0.8916 acc_train: 0.7500 loss_val: 0.7786 acc_val: 0.8220 time: 0.0345s\n",
            "152\n",
            "Epoch: 0155 loss_train: 0.8761 acc_train: 0.8500 loss_val: 0.7753 acc_val: 0.8240 time: 0.0350s\n",
            "153\n",
            "Epoch: 0156 loss_train: 0.9520 acc_train: 0.7500 loss_val: 0.7750 acc_val: 0.8220 time: 0.0349s\n",
            "0\n",
            "Epoch: 0157 loss_train: 0.8968 acc_train: 0.8214 loss_val: 0.7753 acc_val: 0.8240 time: 0.0348s\n",
            "1\n",
            "Epoch: 0158 loss_train: 0.9055 acc_train: 0.7571 loss_val: 0.7776 acc_val: 0.8260 time: 0.0417s\n",
            "0\n",
            "Epoch: 0159 loss_train: 0.9042 acc_train: 0.7357 loss_val: 0.7810 acc_val: 0.8220 time: 0.0364s\n",
            "0\n",
            "Epoch: 0160 loss_train: 0.9008 acc_train: 0.8429 loss_val: 0.7866 acc_val: 0.8200 time: 0.0375s\n",
            "1\n",
            "Epoch: 0161 loss_train: 0.9176 acc_train: 0.7286 loss_val: 0.7896 acc_val: 0.8180 time: 0.0359s\n",
            "2\n",
            "Epoch: 0162 loss_train: 0.9083 acc_train: 0.8286 loss_val: 0.7930 acc_val: 0.8140 time: 0.0364s\n",
            "3\n",
            "Epoch: 0163 loss_train: 0.8517 acc_train: 0.7857 loss_val: 0.7961 acc_val: 0.8100 time: 0.0355s\n",
            "4\n",
            "Epoch: 0164 loss_train: 0.9286 acc_train: 0.8214 loss_val: 0.7960 acc_val: 0.8080 time: 0.0399s\n",
            "5\n",
            "Epoch: 0165 loss_train: 0.8682 acc_train: 0.8143 loss_val: 0.7918 acc_val: 0.8100 time: 0.0365s\n",
            "6\n",
            "Epoch: 0166 loss_train: 0.9162 acc_train: 0.8214 loss_val: 0.7895 acc_val: 0.8100 time: 0.0374s\n",
            "7\n",
            "Epoch: 0167 loss_train: 0.9553 acc_train: 0.7214 loss_val: 0.7879 acc_val: 0.8100 time: 0.0358s\n",
            "8\n",
            "Epoch: 0168 loss_train: 0.9509 acc_train: 0.7571 loss_val: 0.7859 acc_val: 0.8140 time: 0.0346s\n",
            "9\n",
            "Epoch: 0169 loss_train: 0.8920 acc_train: 0.7571 loss_val: 0.7864 acc_val: 0.8100 time: 0.0364s\n",
            "10\n",
            "Epoch: 0170 loss_train: 0.8987 acc_train: 0.8714 loss_val: 0.7861 acc_val: 0.8080 time: 0.0405s\n",
            "11\n",
            "Epoch: 0171 loss_train: 0.9469 acc_train: 0.7071 loss_val: 0.7863 acc_val: 0.8120 time: 0.0361s\n",
            "12\n",
            "Epoch: 0172 loss_train: 0.9056 acc_train: 0.7857 loss_val: 0.7857 acc_val: 0.8140 time: 0.0373s\n",
            "13\n",
            "Epoch: 0173 loss_train: 0.9247 acc_train: 0.7714 loss_val: 0.7830 acc_val: 0.8140 time: 0.0356s\n",
            "14\n",
            "Epoch: 0174 loss_train: 0.9543 acc_train: 0.7500 loss_val: 0.7841 acc_val: 0.8180 time: 0.0348s\n",
            "15\n",
            "Epoch: 0175 loss_train: 0.8848 acc_train: 0.7571 loss_val: 0.7867 acc_val: 0.8160 time: 0.0350s\n",
            "16\n",
            "Epoch: 0176 loss_train: 0.9134 acc_train: 0.7929 loss_val: 0.7890 acc_val: 0.8080 time: 0.0368s\n",
            "17\n",
            "Epoch: 0177 loss_train: 0.9369 acc_train: 0.8000 loss_val: 0.7917 acc_val: 0.8100 time: 0.0352s\n",
            "18\n",
            "Epoch: 0178 loss_train: 0.9638 acc_train: 0.7357 loss_val: 0.7936 acc_val: 0.8060 time: 0.0348s\n",
            "19\n",
            "Epoch: 0179 loss_train: 0.9058 acc_train: 0.7500 loss_val: 0.7956 acc_val: 0.8100 time: 0.0350s\n",
            "20\n",
            "Epoch: 0180 loss_train: 0.8762 acc_train: 0.7714 loss_val: 0.7945 acc_val: 0.8060 time: 0.0347s\n",
            "21\n",
            "Epoch: 0181 loss_train: 0.8985 acc_train: 0.7929 loss_val: 0.7931 acc_val: 0.8040 time: 0.0353s\n",
            "22\n",
            "Epoch: 0182 loss_train: 0.9192 acc_train: 0.7571 loss_val: 0.7933 acc_val: 0.8020 time: 0.0383s\n",
            "23\n",
            "Epoch: 0183 loss_train: 0.8551 acc_train: 0.7857 loss_val: 0.7930 acc_val: 0.8020 time: 0.0350s\n",
            "24\n",
            "Epoch: 0184 loss_train: 0.9063 acc_train: 0.8071 loss_val: 0.7944 acc_val: 0.7980 time: 0.0348s\n",
            "25\n",
            "Epoch: 0185 loss_train: 0.8815 acc_train: 0.8214 loss_val: 0.7931 acc_val: 0.8040 time: 0.0348s\n",
            "26\n",
            "Epoch: 0186 loss_train: 0.9184 acc_train: 0.7786 loss_val: 0.7908 acc_val: 0.8100 time: 0.0362s\n",
            "27\n",
            "Epoch: 0187 loss_train: 0.9069 acc_train: 0.7857 loss_val: 0.7906 acc_val: 0.8080 time: 0.0363s\n",
            "28\n",
            "Epoch: 0188 loss_train: 0.8864 acc_train: 0.7857 loss_val: 0.7925 acc_val: 0.8100 time: 0.0370s\n",
            "29\n",
            "Epoch: 0189 loss_train: 0.8860 acc_train: 0.7500 loss_val: 0.7937 acc_val: 0.8040 time: 0.0356s\n",
            "30\n",
            "Epoch: 0190 loss_train: 0.9337 acc_train: 0.7643 loss_val: 0.7951 acc_val: 0.8040 time: 0.0349s\n",
            "31\n",
            "Epoch: 0191 loss_train: 0.9263 acc_train: 0.8071 loss_val: 0.7946 acc_val: 0.8020 time: 0.0355s\n",
            "32\n",
            "Epoch: 0192 loss_train: 0.8977 acc_train: 0.7857 loss_val: 0.7976 acc_val: 0.8040 time: 0.0361s\n",
            "33\n",
            "Epoch: 0193 loss_train: 0.9339 acc_train: 0.7929 loss_val: 0.8020 acc_val: 0.8000 time: 0.0362s\n",
            "34\n",
            "Epoch: 0194 loss_train: 0.8930 acc_train: 0.8071 loss_val: 0.8070 acc_val: 0.8000 time: 0.0385s\n",
            "35\n",
            "Epoch: 0195 loss_train: 0.9020 acc_train: 0.7929 loss_val: 0.8099 acc_val: 0.8020 time: 0.0367s\n",
            "36\n",
            "Epoch: 0196 loss_train: 0.8679 acc_train: 0.8357 loss_val: 0.8087 acc_val: 0.8000 time: 0.0385s\n",
            "37\n",
            "Epoch: 0197 loss_train: 0.8956 acc_train: 0.8500 loss_val: 0.7998 acc_val: 0.8080 time: 0.0371s\n",
            "38\n",
            "Epoch: 0198 loss_train: 0.9378 acc_train: 0.7571 loss_val: 0.7922 acc_val: 0.8120 time: 0.0368s\n",
            "39\n",
            "Epoch: 0199 loss_train: 0.9143 acc_train: 0.7929 loss_val: 0.7885 acc_val: 0.8120 time: 0.0366s\n",
            "40\n",
            "Epoch: 0200 loss_train: 0.9032 acc_train: 0.8000 loss_val: 0.7897 acc_val: 0.8120 time: 0.0433s\n",
            "41\n",
            "Epoch: 0201 loss_train: 0.9310 acc_train: 0.7714 loss_val: 0.7918 acc_val: 0.8100 time: 0.0366s\n",
            "42\n",
            "Epoch: 0202 loss_train: 0.9345 acc_train: 0.7786 loss_val: 0.7944 acc_val: 0.8100 time: 0.0364s\n",
            "43\n",
            "Epoch: 0203 loss_train: 0.9367 acc_train: 0.7929 loss_val: 0.7992 acc_val: 0.8140 time: 0.0362s\n",
            "44\n",
            "Epoch: 0204 loss_train: 0.8842 acc_train: 0.8286 loss_val: 0.8037 acc_val: 0.8100 time: 0.0357s\n",
            "45\n",
            "Epoch: 0205 loss_train: 0.9417 acc_train: 0.8071 loss_val: 0.8052 acc_val: 0.8100 time: 0.0348s\n",
            "46\n",
            "Epoch: 0206 loss_train: 0.8818 acc_train: 0.8071 loss_val: 0.8042 acc_val: 0.8000 time: 0.0374s\n",
            "47\n",
            "Epoch: 0207 loss_train: 0.8895 acc_train: 0.8071 loss_val: 0.8024 acc_val: 0.8000 time: 0.0350s\n",
            "48\n",
            "Epoch: 0208 loss_train: 0.9105 acc_train: 0.8071 loss_val: 0.7959 acc_val: 0.8040 time: 0.0346s\n",
            "49\n",
            "Epoch: 0209 loss_train: 0.9079 acc_train: 0.8214 loss_val: 0.7858 acc_val: 0.8060 time: 0.0347s\n",
            "50\n",
            "Epoch: 0210 loss_train: 0.9078 acc_train: 0.7571 loss_val: 0.7795 acc_val: 0.8080 time: 0.0347s\n",
            "51\n",
            "Epoch: 0211 loss_train: 0.9224 acc_train: 0.7714 loss_val: 0.7753 acc_val: 0.8100 time: 0.0350s\n",
            "52\n",
            "Epoch: 0212 loss_train: 0.9163 acc_train: 0.7786 loss_val: 0.7753 acc_val: 0.8120 time: 0.0399s\n",
            "53\n",
            "Epoch: 0213 loss_train: 0.9331 acc_train: 0.7214 loss_val: 0.7792 acc_val: 0.8080 time: 0.0354s\n",
            "54\n",
            "Epoch: 0214 loss_train: 0.9381 acc_train: 0.7214 loss_val: 0.7845 acc_val: 0.8100 time: 0.0374s\n",
            "55\n",
            "Epoch: 0215 loss_train: 0.9390 acc_train: 0.7429 loss_val: 0.7907 acc_val: 0.8120 time: 0.0354s\n",
            "56\n",
            "Epoch: 0216 loss_train: 0.8625 acc_train: 0.7857 loss_val: 0.7942 acc_val: 0.8180 time: 0.0349s\n",
            "57\n",
            "Epoch: 0217 loss_train: 0.8807 acc_train: 0.7714 loss_val: 0.7961 acc_val: 0.8140 time: 0.0352s\n",
            "58\n",
            "Epoch: 0218 loss_train: 0.9172 acc_train: 0.7929 loss_val: 0.8012 acc_val: 0.8100 time: 0.0382s\n",
            "59\n",
            "Epoch: 0219 loss_train: 0.9061 acc_train: 0.7929 loss_val: 0.8008 acc_val: 0.8020 time: 0.0353s\n",
            "60\n",
            "Epoch: 0220 loss_train: 1.1632 acc_train: 0.7643 loss_val: 0.7990 acc_val: 0.8040 time: 0.0349s\n",
            "61\n",
            "Epoch: 0221 loss_train: 0.8893 acc_train: 0.8000 loss_val: 0.7934 acc_val: 0.8040 time: 0.0349s\n",
            "62\n",
            "Epoch: 0222 loss_train: 0.8995 acc_train: 0.7857 loss_val: 0.7884 acc_val: 0.8020 time: 0.0381s\n",
            "63\n",
            "Epoch: 0223 loss_train: 0.9277 acc_train: 0.7429 loss_val: 0.7820 acc_val: 0.8040 time: 0.0350s\n",
            "64\n",
            "Epoch: 0224 loss_train: 0.9267 acc_train: 0.7714 loss_val: 0.7785 acc_val: 0.8060 time: 0.0374s\n",
            "65\n",
            "Epoch: 0225 loss_train: 0.9086 acc_train: 0.7571 loss_val: 0.7798 acc_val: 0.8040 time: 0.0362s\n",
            "66\n",
            "Epoch: 0226 loss_train: 0.8540 acc_train: 0.8357 loss_val: 0.7810 acc_val: 0.7980 time: 0.0363s\n",
            "67\n",
            "Epoch: 0227 loss_train: 0.9065 acc_train: 0.7357 loss_val: 0.7817 acc_val: 0.7940 time: 0.0373s\n",
            "68\n",
            "Epoch: 0228 loss_train: 0.8598 acc_train: 0.8286 loss_val: 0.7825 acc_val: 0.7980 time: 0.0363s\n",
            "69\n",
            "Epoch: 0229 loss_train: 0.9042 acc_train: 0.8000 loss_val: 0.7829 acc_val: 0.8020 time: 0.0366s\n",
            "70\n",
            "Epoch: 0230 loss_train: 0.8923 acc_train: 0.7929 loss_val: 0.7837 acc_val: 0.8000 time: 0.0376s\n",
            "71\n",
            "Epoch: 0231 loss_train: 0.9629 acc_train: 0.7786 loss_val: 0.7901 acc_val: 0.8040 time: 0.0361s\n",
            "72\n",
            "Epoch: 0232 loss_train: 0.8697 acc_train: 0.8143 loss_val: 0.7938 acc_val: 0.8100 time: 0.0359s\n",
            "73\n",
            "Epoch: 0233 loss_train: 0.9135 acc_train: 0.8143 loss_val: 0.7970 acc_val: 0.8100 time: 0.0357s\n",
            "74\n",
            "Epoch: 0234 loss_train: 0.9443 acc_train: 0.7786 loss_val: 0.7967 acc_val: 0.8040 time: 0.0351s\n",
            "75\n",
            "Epoch: 0235 loss_train: 0.8968 acc_train: 0.7357 loss_val: 0.7951 acc_val: 0.8080 time: 0.0374s\n",
            "76\n",
            "Epoch: 0236 loss_train: 0.8776 acc_train: 0.7857 loss_val: 0.7938 acc_val: 0.8040 time: 0.0403s\n",
            "77\n",
            "Epoch: 0237 loss_train: 0.9064 acc_train: 0.8214 loss_val: 0.7922 acc_val: 0.8020 time: 0.0362s\n",
            "78\n",
            "Epoch: 0238 loss_train: 0.8574 acc_train: 0.8286 loss_val: 0.7918 acc_val: 0.8000 time: 0.0350s\n",
            "79\n",
            "Epoch: 0239 loss_train: 0.8788 acc_train: 0.8143 loss_val: 0.7904 acc_val: 0.8000 time: 0.0350s\n",
            "80\n",
            "Epoch: 0240 loss_train: 0.8820 acc_train: 0.7571 loss_val: 0.7888 acc_val: 0.7960 time: 0.0362s\n",
            "81\n",
            "Epoch: 0241 loss_train: 0.8651 acc_train: 0.8071 loss_val: 0.7860 acc_val: 0.8020 time: 0.0350s\n",
            "82\n",
            "Epoch: 0242 loss_train: 0.9332 acc_train: 0.7643 loss_val: 0.7877 acc_val: 0.8060 time: 0.0366s\n",
            "83\n",
            "Epoch: 0243 loss_train: 0.8908 acc_train: 0.8071 loss_val: 0.7882 acc_val: 0.8080 time: 0.0354s\n",
            "84\n",
            "Epoch: 0244 loss_train: 0.9094 acc_train: 0.7357 loss_val: 0.7882 acc_val: 0.8120 time: 0.0365s\n",
            "85\n",
            "Epoch: 0245 loss_train: 0.8622 acc_train: 0.7714 loss_val: 0.7889 acc_val: 0.8100 time: 0.0348s\n",
            "86\n",
            "Epoch: 0246 loss_train: 0.9041 acc_train: 0.8286 loss_val: 0.7881 acc_val: 0.8120 time: 0.0347s\n",
            "87\n",
            "Epoch: 0247 loss_train: 0.9673 acc_train: 0.7571 loss_val: 0.7893 acc_val: 0.8100 time: 0.0348s\n",
            "88\n",
            "Epoch: 0248 loss_train: 0.9076 acc_train: 0.7857 loss_val: 0.7912 acc_val: 0.8100 time: 0.0373s\n",
            "89\n",
            "Epoch: 0249 loss_train: 0.9399 acc_train: 0.7857 loss_val: 0.7894 acc_val: 0.8120 time: 0.0388s\n",
            "90\n",
            "Epoch: 0250 loss_train: 0.9548 acc_train: 0.7857 loss_val: 0.7885 acc_val: 0.8040 time: 0.0347s\n",
            "91\n",
            "Epoch: 0251 loss_train: 0.8805 acc_train: 0.8071 loss_val: 0.7867 acc_val: 0.8020 time: 0.0355s\n",
            "92\n",
            "Epoch: 0252 loss_train: 0.9003 acc_train: 0.8071 loss_val: 0.7880 acc_val: 0.8020 time: 0.0349s\n",
            "93\n",
            "Epoch: 0253 loss_train: 0.9479 acc_train: 0.7929 loss_val: 0.7874 acc_val: 0.8060 time: 0.0347s\n",
            "94\n",
            "Epoch: 0254 loss_train: 0.8670 acc_train: 0.8071 loss_val: 0.7872 acc_val: 0.8060 time: 0.0378s\n",
            "95\n",
            "Epoch: 0255 loss_train: 0.9271 acc_train: 0.7643 loss_val: 0.7915 acc_val: 0.8020 time: 0.0373s\n",
            "96\n",
            "Epoch: 0256 loss_train: 0.9624 acc_train: 0.7500 loss_val: 0.7961 acc_val: 0.7960 time: 0.0359s\n",
            "97\n",
            "Epoch: 0257 loss_train: 0.8948 acc_train: 0.7857 loss_val: 0.7986 acc_val: 0.7980 time: 0.0360s\n",
            "98\n",
            "Epoch: 0258 loss_train: 0.8767 acc_train: 0.8143 loss_val: 0.7997 acc_val: 0.7960 time: 0.0363s\n",
            "99\n",
            "Epoch: 0259 loss_train: 0.9338 acc_train: 0.7786 loss_val: 0.8028 acc_val: 0.7980 time: 0.0361s\n",
            "100\n",
            "Epoch: 0260 loss_train: 0.9512 acc_train: 0.8286 loss_val: 0.8030 acc_val: 0.8060 time: 0.0396s\n",
            "101\n",
            "Epoch: 0261 loss_train: 0.9244 acc_train: 0.7929 loss_val: 0.7996 acc_val: 0.8060 time: 0.0372s\n",
            "102\n",
            "Epoch: 0262 loss_train: 0.8921 acc_train: 0.7286 loss_val: 0.7926 acc_val: 0.8040 time: 0.0374s\n",
            "103\n",
            "Epoch: 0263 loss_train: 0.8484 acc_train: 0.8286 loss_val: 0.7856 acc_val: 0.8100 time: 0.0377s\n",
            "104\n",
            "Epoch: 0264 loss_train: 0.9106 acc_train: 0.8286 loss_val: 0.7812 acc_val: 0.8120 time: 0.0397s\n",
            "105\n",
            "Epoch: 0265 loss_train: 0.9219 acc_train: 0.7643 loss_val: 0.7788 acc_val: 0.8140 time: 0.0372s\n",
            "106\n",
            "Epoch: 0266 loss_train: 0.8796 acc_train: 0.7786 loss_val: 0.7816 acc_val: 0.8100 time: 0.0400s\n",
            "107\n",
            "Epoch: 0267 loss_train: 0.8880 acc_train: 0.8000 loss_val: 0.7861 acc_val: 0.8100 time: 0.0369s\n",
            "108\n",
            "Epoch: 0268 loss_train: 0.8840 acc_train: 0.8143 loss_val: 0.7936 acc_val: 0.8020 time: 0.0380s\n",
            "109\n",
            "Epoch: 0269 loss_train: 0.9153 acc_train: 0.7571 loss_val: 0.7974 acc_val: 0.8040 time: 0.0374s\n",
            "110\n",
            "Epoch: 0270 loss_train: 0.9271 acc_train: 0.8429 loss_val: 0.7969 acc_val: 0.8020 time: 0.0366s\n",
            "111\n",
            "Epoch: 0271 loss_train: 0.8893 acc_train: 0.7929 loss_val: 0.7938 acc_val: 0.8020 time: 0.0380s\n",
            "112\n",
            "Epoch: 0272 loss_train: 0.9151 acc_train: 0.8000 loss_val: 0.7905 acc_val: 0.8040 time: 0.0359s\n",
            "113\n",
            "Epoch: 0273 loss_train: 0.8808 acc_train: 0.8214 loss_val: 0.7841 acc_val: 0.8060 time: 0.0356s\n",
            "114\n",
            "Epoch: 0274 loss_train: 0.8835 acc_train: 0.8143 loss_val: 0.7770 acc_val: 0.8100 time: 0.0398s\n",
            "115\n",
            "Epoch: 0275 loss_train: 0.8555 acc_train: 0.7571 loss_val: 0.7715 acc_val: 0.8080 time: 0.0359s\n",
            "116\n",
            "Epoch: 0276 loss_train: 0.9219 acc_train: 0.8143 loss_val: 0.7727 acc_val: 0.8060 time: 0.0361s\n",
            "117\n",
            "Epoch: 0277 loss_train: 0.8850 acc_train: 0.8071 loss_val: 0.7769 acc_val: 0.8060 time: 0.0387s\n",
            "118\n",
            "Epoch: 0278 loss_train: 0.9068 acc_train: 0.8000 loss_val: 0.7829 acc_val: 0.8020 time: 0.0364s\n",
            "119\n",
            "Epoch: 0279 loss_train: 0.8992 acc_train: 0.7571 loss_val: 0.7883 acc_val: 0.8000 time: 0.0358s\n",
            "120\n",
            "Epoch: 0280 loss_train: 0.8975 acc_train: 0.7929 loss_val: 0.7941 acc_val: 0.7960 time: 0.0352s\n",
            "121\n",
            "Epoch: 0281 loss_train: 0.8847 acc_train: 0.7786 loss_val: 0.7974 acc_val: 0.8020 time: 0.0353s\n",
            "122\n",
            "Epoch: 0282 loss_train: 0.8853 acc_train: 0.8286 loss_val: 0.7985 acc_val: 0.8060 time: 0.0365s\n",
            "123\n",
            "Epoch: 0283 loss_train: 0.8878 acc_train: 0.7714 loss_val: 0.7964 acc_val: 0.8120 time: 0.0391s\n",
            "124\n",
            "Epoch: 0284 loss_train: 0.8996 acc_train: 0.7929 loss_val: 0.7932 acc_val: 0.8120 time: 0.0366s\n",
            "125\n",
            "Epoch: 0285 loss_train: 0.7994 acc_train: 0.9071 loss_val: 0.7868 acc_val: 0.8140 time: 0.0360s\n",
            "126\n",
            "Epoch: 0286 loss_train: 0.8844 acc_train: 0.7929 loss_val: 0.7824 acc_val: 0.8140 time: 0.0351s\n",
            "127\n",
            "Epoch: 0287 loss_train: 0.9081 acc_train: 0.7786 loss_val: 0.7779 acc_val: 0.8180 time: 0.0360s\n",
            "128\n",
            "Epoch: 0288 loss_train: 0.9018 acc_train: 0.8286 loss_val: 0.7747 acc_val: 0.8140 time: 0.0350s\n",
            "129\n",
            "Epoch: 0289 loss_train: 0.8768 acc_train: 0.7571 loss_val: 0.7758 acc_val: 0.8120 time: 0.0368s\n",
            "130\n",
            "Epoch: 0290 loss_train: 0.9487 acc_train: 0.8357 loss_val: 0.7799 acc_val: 0.8080 time: 0.0354s\n",
            "131\n",
            "Epoch: 0291 loss_train: 0.9407 acc_train: 0.8071 loss_val: 0.7838 acc_val: 0.8040 time: 0.0353s\n",
            "132\n",
            "Epoch: 0292 loss_train: 0.9339 acc_train: 0.8000 loss_val: 0.7907 acc_val: 0.8040 time: 0.0354s\n",
            "133\n",
            "Epoch: 0293 loss_train: 0.8491 acc_train: 0.8357 loss_val: 0.7939 acc_val: 0.8020 time: 0.0354s\n",
            "134\n",
            "Epoch: 0294 loss_train: 0.9283 acc_train: 0.7929 loss_val: 0.7955 acc_val: 0.8060 time: 0.0354s\n",
            "135\n",
            "Epoch: 0295 loss_train: 0.9308 acc_train: 0.7929 loss_val: 0.7963 acc_val: 0.8140 time: 0.0376s\n",
            "136\n",
            "Epoch: 0296 loss_train: 0.8858 acc_train: 0.7929 loss_val: 0.7955 acc_val: 0.8160 time: 0.0375s\n",
            "137\n",
            "Epoch: 0297 loss_train: 0.9073 acc_train: 0.7857 loss_val: 0.7935 acc_val: 0.8120 time: 0.0351s\n",
            "138\n",
            "Epoch: 0298 loss_train: 0.8750 acc_train: 0.8000 loss_val: 0.7918 acc_val: 0.8120 time: 0.0352s\n",
            "139\n",
            "Epoch: 0299 loss_train: 0.9326 acc_train: 0.7857 loss_val: 0.7901 acc_val: 0.8160 time: 0.0359s\n",
            "140\n",
            "Epoch: 0300 loss_train: 0.8813 acc_train: 0.7929 loss_val: 0.7895 acc_val: 0.8200 time: 0.0353s\n",
            "141\n",
            "Epoch: 0301 loss_train: 0.8983 acc_train: 0.7714 loss_val: 0.7854 acc_val: 0.8160 time: 0.0385s\n",
            "142\n",
            "Epoch: 0302 loss_train: 0.9814 acc_train: 0.7357 loss_val: 0.7824 acc_val: 0.8140 time: 0.0352s\n",
            "143\n",
            "Epoch: 0303 loss_train: 0.9077 acc_train: 0.7857 loss_val: 0.7809 acc_val: 0.8180 time: 0.0350s\n",
            "144\n",
            "Epoch: 0304 loss_train: 0.8801 acc_train: 0.7500 loss_val: 0.7801 acc_val: 0.8240 time: 0.0346s\n",
            "145\n",
            "Epoch: 0305 loss_train: 0.9135 acc_train: 0.7357 loss_val: 0.7789 acc_val: 0.8160 time: 0.0354s\n",
            "146\n",
            "Epoch: 0306 loss_train: 0.8969 acc_train: 0.7286 loss_val: 0.7796 acc_val: 0.8120 time: 0.0351s\n",
            "147\n",
            "Epoch: 0307 loss_train: 0.9417 acc_train: 0.7143 loss_val: 0.7795 acc_val: 0.8120 time: 0.0378s\n",
            "148\n",
            "Epoch: 0308 loss_train: 0.9138 acc_train: 0.8000 loss_val: 0.7803 acc_val: 0.8100 time: 0.0365s\n",
            "149\n",
            "Epoch: 0309 loss_train: 0.9449 acc_train: 0.8000 loss_val: 0.7820 acc_val: 0.8100 time: 0.0361s\n",
            "150\n",
            "Epoch: 0310 loss_train: 0.9046 acc_train: 0.7429 loss_val: 0.7848 acc_val: 0.8060 time: 0.0365s\n",
            "151\n",
            "Epoch: 0311 loss_train: 0.9574 acc_train: 0.7714 loss_val: 0.7876 acc_val: 0.8040 time: 0.0362s\n",
            "152\n",
            "Epoch: 0312 loss_train: 0.9088 acc_train: 0.8286 loss_val: 0.7921 acc_val: 0.8060 time: 0.0394s\n",
            "153\n",
            "Epoch: 0313 loss_train: 0.8816 acc_train: 0.7643 loss_val: 0.7951 acc_val: 0.8040 time: 0.0384s\n",
            "154\n",
            "Epoch: 0314 loss_train: 0.9580 acc_train: 0.8000 loss_val: 0.7955 acc_val: 0.8060 time: 0.0355s\n",
            "155\n",
            "Epoch: 0315 loss_train: 0.8679 acc_train: 0.8500 loss_val: 0.7942 acc_val: 0.8100 time: 0.0349s\n",
            "156\n",
            "Epoch: 0316 loss_train: 0.8941 acc_train: 0.8000 loss_val: 0.7928 acc_val: 0.8160 time: 0.0371s\n",
            "157\n",
            "Epoch: 0317 loss_train: 0.8734 acc_train: 0.8357 loss_val: 0.7883 acc_val: 0.8180 time: 0.0352s\n",
            "158\n",
            "Epoch: 0318 loss_train: 0.9484 acc_train: 0.7500 loss_val: 0.7889 acc_val: 0.8120 time: 0.0354s\n",
            "159\n",
            "Epoch: 0319 loss_train: 0.8850 acc_train: 0.8357 loss_val: 0.7899 acc_val: 0.8120 time: 0.0384s\n",
            "160\n",
            "Epoch: 0320 loss_train: 0.9105 acc_train: 0.8000 loss_val: 0.7929 acc_val: 0.8080 time: 0.0351s\n",
            "161\n",
            "Epoch: 0321 loss_train: 0.9340 acc_train: 0.7786 loss_val: 0.7969 acc_val: 0.8040 time: 0.0358s\n",
            "162\n",
            "Epoch: 0322 loss_train: 0.9538 acc_train: 0.7000 loss_val: 0.7971 acc_val: 0.8100 time: 0.0354s\n",
            "163\n",
            "Epoch: 0323 loss_train: 0.9403 acc_train: 0.7786 loss_val: 0.7928 acc_val: 0.8080 time: 0.0347s\n",
            "164\n",
            "Epoch: 0324 loss_train: 0.9159 acc_train: 0.7857 loss_val: 0.7904 acc_val: 0.8160 time: 0.0348s\n",
            "165\n",
            "Epoch: 0325 loss_train: 0.8619 acc_train: 0.8143 loss_val: 0.7885 acc_val: 0.8120 time: 0.0386s\n",
            "166\n",
            "Epoch: 0326 loss_train: 0.9142 acc_train: 0.8071 loss_val: 0.7869 acc_val: 0.7980 time: 0.0366s\n",
            "167\n",
            "Epoch: 0327 loss_train: 0.9335 acc_train: 0.8143 loss_val: 0.7869 acc_val: 0.7980 time: 0.0384s\n",
            "168\n",
            "Epoch: 0328 loss_train: 0.9186 acc_train: 0.7714 loss_val: 0.7902 acc_val: 0.8000 time: 0.0366s\n",
            "169\n",
            "Epoch: 0329 loss_train: 0.8709 acc_train: 0.8214 loss_val: 0.7875 acc_val: 0.8000 time: 0.0366s\n",
            "170\n",
            "Epoch: 0330 loss_train: 0.9011 acc_train: 0.7000 loss_val: 0.7825 acc_val: 0.8040 time: 0.0359s\n",
            "171\n",
            "Epoch: 0331 loss_train: 0.8751 acc_train: 0.8214 loss_val: 0.7786 acc_val: 0.8140 time: 0.0396s\n",
            "172\n",
            "Epoch: 0332 loss_train: 0.8630 acc_train: 0.8286 loss_val: 0.7763 acc_val: 0.8200 time: 0.0360s\n",
            "173\n",
            "Epoch: 0333 loss_train: 0.8978 acc_train: 0.8000 loss_val: 0.7760 acc_val: 0.8220 time: 0.0415s\n",
            "174\n",
            "Epoch: 0334 loss_train: 0.9143 acc_train: 0.7714 loss_val: 0.7783 acc_val: 0.8240 time: 0.0370s\n",
            "175\n",
            "Epoch: 0335 loss_train: 0.9333 acc_train: 0.7571 loss_val: 0.7799 acc_val: 0.8180 time: 0.0360s\n",
            "176\n",
            "Epoch: 0336 loss_train: 0.8570 acc_train: 0.8000 loss_val: 0.7856 acc_val: 0.8140 time: 0.0353s\n",
            "177\n",
            "Epoch: 0337 loss_train: 0.9225 acc_train: 0.8286 loss_val: 0.7954 acc_val: 0.8020 time: 0.0388s\n",
            "178\n",
            "Epoch: 0338 loss_train: 0.8295 acc_train: 0.8286 loss_val: 0.8014 acc_val: 0.7960 time: 0.0371s\n",
            "179\n",
            "Epoch: 0339 loss_train: 0.8800 acc_train: 0.8500 loss_val: 0.8002 acc_val: 0.7940 time: 0.0344s\n",
            "180\n",
            "Epoch: 0340 loss_train: 0.9109 acc_train: 0.8143 loss_val: 0.7945 acc_val: 0.8040 time: 0.0347s\n",
            "181\n",
            "Epoch: 0341 loss_train: 0.9132 acc_train: 0.7857 loss_val: 0.7907 acc_val: 0.8100 time: 0.0348s\n",
            "182\n",
            "Epoch: 0342 loss_train: 0.9136 acc_train: 0.8357 loss_val: 0.7888 acc_val: 0.8040 time: 0.0350s\n",
            "183\n",
            "Epoch: 0343 loss_train: 0.9297 acc_train: 0.7786 loss_val: 0.7849 acc_val: 0.8060 time: 0.0381s\n",
            "184\n",
            "Epoch: 0344 loss_train: 0.8951 acc_train: 0.8214 loss_val: 0.7810 acc_val: 0.8140 time: 0.0348s\n",
            "185\n",
            "Epoch: 0345 loss_train: 0.9210 acc_train: 0.8000 loss_val: 0.7817 acc_val: 0.8120 time: 0.0360s\n",
            "186\n",
            "Epoch: 0346 loss_train: 0.8910 acc_train: 0.7500 loss_val: 0.7811 acc_val: 0.8120 time: 0.0347s\n",
            "187\n",
            "Epoch: 0347 loss_train: 0.9380 acc_train: 0.7357 loss_val: 0.7826 acc_val: 0.8120 time: 0.0361s\n",
            "188\n",
            "Epoch: 0348 loss_train: 0.9201 acc_train: 0.7714 loss_val: 0.7862 acc_val: 0.8080 time: 0.0357s\n",
            "189\n",
            "Epoch: 0349 loss_train: 0.9103 acc_train: 0.7786 loss_val: 0.7879 acc_val: 0.8080 time: 0.0382s\n",
            "190\n",
            "Epoch: 0350 loss_train: 0.9428 acc_train: 0.8357 loss_val: 0.7906 acc_val: 0.8100 time: 0.0360s\n",
            "191\n",
            "Epoch: 0351 loss_train: 0.9213 acc_train: 0.7714 loss_val: 0.7920 acc_val: 0.8140 time: 0.0362s\n",
            "192\n",
            "Epoch: 0352 loss_train: 0.9097 acc_train: 0.8214 loss_val: 0.7928 acc_val: 0.8200 time: 0.0362s\n",
            "193\n",
            "Epoch: 0353 loss_train: 0.8904 acc_train: 0.7857 loss_val: 0.7966 acc_val: 0.8120 time: 0.0382s\n",
            "194\n",
            "Epoch: 0354 loss_train: 0.8835 acc_train: 0.7786 loss_val: 0.7980 acc_val: 0.8140 time: 0.0360s\n",
            "195\n",
            "Epoch: 0355 loss_train: 0.8931 acc_train: 0.7929 loss_val: 0.7979 acc_val: 0.8100 time: 0.0379s\n",
            "196\n",
            "Epoch: 0356 loss_train: 0.9464 acc_train: 0.7714 loss_val: 0.7990 acc_val: 0.8040 time: 0.0351s\n",
            "197\n",
            "Epoch: 0357 loss_train: 0.8629 acc_train: 0.6929 loss_val: 0.8018 acc_val: 0.7960 time: 0.0352s\n",
            "198\n",
            "Epoch: 0358 loss_train: 0.8963 acc_train: 0.8000 loss_val: 0.7985 acc_val: 0.7980 time: 0.0347s\n",
            "199\n",
            "Early stop! Min loss:  0.7004872560501099 , Max accuracy:  0.8260000000000001\n",
            "Early stop model validation loss:  0.7004872560501099 , accuracy:  0.8240000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 13.8100s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6624 accuracy= 0.8430\n",
            "Epoch: 0001 loss_train: 0.9363 acc_train: 0.7429 loss_val: 0.7056 acc_val: 0.8240 time: 0.0385s\n",
            "0\n",
            "Epoch: 0002 loss_train: 1.0091 acc_train: 0.7929 loss_val: 0.7118 acc_val: 0.8280 time: 0.0390s\n",
            "0\n",
            "Epoch: 0003 loss_train: 0.9448 acc_train: 0.7714 loss_val: 0.7213 acc_val: 0.8240 time: 0.0413s\n",
            "0\n",
            "Epoch: 0004 loss_train: 0.9421 acc_train: 0.7500 loss_val: 0.7312 acc_val: 0.8220 time: 0.0401s\n",
            "1\n",
            "Epoch: 0005 loss_train: 0.9484 acc_train: 0.8143 loss_val: 0.7393 acc_val: 0.8220 time: 0.0425s\n",
            "2\n",
            "Epoch: 0006 loss_train: 0.9595 acc_train: 0.8143 loss_val: 0.7431 acc_val: 0.8200 time: 0.0395s\n",
            "3\n",
            "Epoch: 0007 loss_train: 0.9158 acc_train: 0.7857 loss_val: 0.7470 acc_val: 0.8200 time: 0.0418s\n",
            "4\n",
            "Epoch: 0008 loss_train: 0.9480 acc_train: 0.7429 loss_val: 0.7498 acc_val: 0.8180 time: 0.0406s\n",
            "5\n",
            "Epoch: 0009 loss_train: 0.9246 acc_train: 0.7714 loss_val: 0.7513 acc_val: 0.8180 time: 0.0403s\n",
            "6\n",
            "Epoch: 0010 loss_train: 0.9416 acc_train: 0.7929 loss_val: 0.7530 acc_val: 0.8220 time: 0.0414s\n",
            "7\n",
            "Epoch: 0011 loss_train: 0.9259 acc_train: 0.8143 loss_val: 0.7515 acc_val: 0.8160 time: 0.0398s\n",
            "8\n",
            "Epoch: 0012 loss_train: 0.9785 acc_train: 0.7357 loss_val: 0.7522 acc_val: 0.8200 time: 0.0393s\n",
            "9\n",
            "Epoch: 0013 loss_train: 0.8951 acc_train: 0.8143 loss_val: 0.7509 acc_val: 0.8220 time: 0.0384s\n",
            "10\n",
            "Epoch: 0014 loss_train: 0.9246 acc_train: 0.8571 loss_val: 0.7499 acc_val: 0.8180 time: 0.0390s\n",
            "11\n",
            "Epoch: 0015 loss_train: 0.8591 acc_train: 0.7929 loss_val: 0.7520 acc_val: 0.8220 time: 0.0380s\n",
            "12\n",
            "Epoch: 0016 loss_train: 0.9324 acc_train: 0.7571 loss_val: 0.7578 acc_val: 0.8200 time: 0.0401s\n",
            "13\n",
            "Epoch: 0017 loss_train: 0.9005 acc_train: 0.7643 loss_val: 0.7649 acc_val: 0.8180 time: 0.0393s\n",
            "14\n",
            "Epoch: 0018 loss_train: 0.9281 acc_train: 0.8214 loss_val: 0.7687 acc_val: 0.8200 time: 0.0412s\n",
            "15\n",
            "Epoch: 0019 loss_train: 0.9735 acc_train: 0.7643 loss_val: 0.7714 acc_val: 0.8180 time: 0.0418s\n",
            "16\n",
            "Epoch: 0020 loss_train: 0.9016 acc_train: 0.7857 loss_val: 0.7747 acc_val: 0.8080 time: 0.0381s\n",
            "17\n",
            "Epoch: 0021 loss_train: 0.9505 acc_train: 0.7929 loss_val: 0.7750 acc_val: 0.8140 time: 0.0376s\n",
            "18\n",
            "Epoch: 0022 loss_train: 0.8961 acc_train: 0.7357 loss_val: 0.7769 acc_val: 0.8140 time: 0.0386s\n",
            "19\n",
            "Epoch: 0023 loss_train: 0.9286 acc_train: 0.7643 loss_val: 0.7805 acc_val: 0.8120 time: 0.0420s\n",
            "20\n",
            "Epoch: 0024 loss_train: 0.9884 acc_train: 0.7500 loss_val: 0.7794 acc_val: 0.8100 time: 0.0387s\n",
            "21\n",
            "Epoch: 0025 loss_train: 0.8969 acc_train: 0.7929 loss_val: 0.7752 acc_val: 0.8100 time: 0.0394s\n",
            "22\n",
            "Epoch: 0026 loss_train: 0.9021 acc_train: 0.8214 loss_val: 0.7735 acc_val: 0.8100 time: 0.0392s\n",
            "23\n",
            "Epoch: 0027 loss_train: 0.9673 acc_train: 0.7429 loss_val: 0.7756 acc_val: 0.8140 time: 0.0393s\n",
            "24\n",
            "Epoch: 0028 loss_train: 0.9480 acc_train: 0.7500 loss_val: 0.7795 acc_val: 0.8220 time: 0.0398s\n",
            "25\n",
            "Epoch: 0029 loss_train: 0.9746 acc_train: 0.7643 loss_val: 0.7861 acc_val: 0.8160 time: 0.0376s\n",
            "26\n",
            "Epoch: 0030 loss_train: 0.9178 acc_train: 0.8071 loss_val: 0.7930 acc_val: 0.8100 time: 0.0377s\n",
            "27\n",
            "Epoch: 0031 loss_train: 0.9251 acc_train: 0.7429 loss_val: 0.7994 acc_val: 0.8080 time: 0.0382s\n",
            "28\n",
            "Epoch: 0032 loss_train: 0.8888 acc_train: 0.8429 loss_val: 0.8062 acc_val: 0.8040 time: 0.0396s\n",
            "29\n",
            "Epoch: 0033 loss_train: 0.9136 acc_train: 0.8214 loss_val: 0.8158 acc_val: 0.8060 time: 0.0404s\n",
            "30\n",
            "Epoch: 0034 loss_train: 0.9239 acc_train: 0.7357 loss_val: 0.8194 acc_val: 0.8040 time: 0.0379s\n",
            "31\n",
            "Epoch: 0035 loss_train: 1.0316 acc_train: 0.7857 loss_val: 0.8195 acc_val: 0.8060 time: 0.0378s\n",
            "32\n",
            "Epoch: 0036 loss_train: 0.9441 acc_train: 0.7929 loss_val: 0.8188 acc_val: 0.8060 time: 0.0388s\n",
            "33\n",
            "Epoch: 0037 loss_train: 0.9707 acc_train: 0.7571 loss_val: 0.8177 acc_val: 0.8100 time: 0.0382s\n",
            "34\n",
            "Epoch: 0038 loss_train: 1.0001 acc_train: 0.7500 loss_val: 0.8170 acc_val: 0.8040 time: 0.0409s\n",
            "35\n",
            "Epoch: 0039 loss_train: 0.9734 acc_train: 0.7643 loss_val: 0.8141 acc_val: 0.8040 time: 0.0407s\n",
            "36\n",
            "Epoch: 0040 loss_train: 0.9690 acc_train: 0.7214 loss_val: 0.8106 acc_val: 0.8120 time: 0.0388s\n",
            "37\n",
            "Epoch: 0041 loss_train: 0.9494 acc_train: 0.8000 loss_val: 0.8047 acc_val: 0.8160 time: 0.0385s\n",
            "38\n",
            "Epoch: 0042 loss_train: 0.9412 acc_train: 0.7071 loss_val: 0.8008 acc_val: 0.8140 time: 0.0397s\n",
            "39\n",
            "Epoch: 0043 loss_train: 0.9354 acc_train: 0.8071 loss_val: 0.7963 acc_val: 0.8120 time: 0.0398s\n",
            "40\n",
            "Epoch: 0044 loss_train: 1.0082 acc_train: 0.7571 loss_val: 0.7955 acc_val: 0.8140 time: 0.0451s\n",
            "41\n",
            "Epoch: 0045 loss_train: 0.9717 acc_train: 0.7643 loss_val: 0.7967 acc_val: 0.8120 time: 0.0393s\n",
            "42\n",
            "Epoch: 0046 loss_train: 0.8952 acc_train: 0.7429 loss_val: 0.8006 acc_val: 0.8120 time: 0.0390s\n",
            "43\n",
            "Epoch: 0047 loss_train: 0.9496 acc_train: 0.7429 loss_val: 0.8076 acc_val: 0.8100 time: 0.0396s\n",
            "44\n",
            "Epoch: 0048 loss_train: 0.9655 acc_train: 0.7357 loss_val: 0.8130 acc_val: 0.8040 time: 0.0395s\n",
            "45\n",
            "Epoch: 0049 loss_train: 0.9244 acc_train: 0.7429 loss_val: 0.8137 acc_val: 0.8080 time: 0.0412s\n",
            "46\n",
            "Epoch: 0050 loss_train: 0.8860 acc_train: 0.7929 loss_val: 0.8117 acc_val: 0.8080 time: 0.0374s\n",
            "47\n",
            "Epoch: 0051 loss_train: 0.8937 acc_train: 0.7786 loss_val: 0.8103 acc_val: 0.8040 time: 0.0377s\n",
            "48\n",
            "Epoch: 0052 loss_train: 0.8973 acc_train: 0.8071 loss_val: 0.8095 acc_val: 0.8000 time: 0.0379s\n",
            "49\n",
            "Epoch: 0053 loss_train: 0.9148 acc_train: 0.7429 loss_val: 0.8092 acc_val: 0.8000 time: 0.0379s\n",
            "50\n",
            "Epoch: 0054 loss_train: 0.9435 acc_train: 0.7500 loss_val: 0.8060 acc_val: 0.8000 time: 0.0400s\n",
            "51\n",
            "Epoch: 0055 loss_train: 0.9149 acc_train: 0.7857 loss_val: 0.8059 acc_val: 0.8040 time: 0.0377s\n",
            "52\n",
            "Epoch: 0056 loss_train: 0.9359 acc_train: 0.8071 loss_val: 0.8091 acc_val: 0.8040 time: 0.0379s\n",
            "53\n",
            "Epoch: 0057 loss_train: 0.8505 acc_train: 0.8429 loss_val: 0.8127 acc_val: 0.8020 time: 0.0378s\n",
            "54\n",
            "Epoch: 0058 loss_train: 0.9406 acc_train: 0.7071 loss_val: 0.8219 acc_val: 0.8020 time: 0.0377s\n",
            "55\n",
            "Epoch: 0059 loss_train: 0.9109 acc_train: 0.8286 loss_val: 0.8277 acc_val: 0.8000 time: 0.0478s\n",
            "56\n",
            "Epoch: 0060 loss_train: 0.9366 acc_train: 0.7786 loss_val: 0.8251 acc_val: 0.7980 time: 0.0433s\n",
            "57\n",
            "Epoch: 0061 loss_train: 0.9749 acc_train: 0.8500 loss_val: 0.8201 acc_val: 0.7980 time: 0.0404s\n",
            "58\n",
            "Epoch: 0062 loss_train: 0.9564 acc_train: 0.7500 loss_val: 0.8135 acc_val: 0.8020 time: 0.0407s\n",
            "59\n",
            "Epoch: 0063 loss_train: 0.9310 acc_train: 0.7571 loss_val: 0.8106 acc_val: 0.8000 time: 0.0434s\n",
            "60\n",
            "Epoch: 0064 loss_train: 0.9298 acc_train: 0.8214 loss_val: 0.8034 acc_val: 0.8040 time: 0.0435s\n",
            "61\n",
            "Epoch: 0065 loss_train: 0.8954 acc_train: 0.7429 loss_val: 0.8002 acc_val: 0.8040 time: 0.0410s\n",
            "62\n",
            "Epoch: 0066 loss_train: 0.9462 acc_train: 0.7429 loss_val: 0.7981 acc_val: 0.8020 time: 0.0392s\n",
            "63\n",
            "Epoch: 0067 loss_train: 1.0117 acc_train: 0.7857 loss_val: 0.7977 acc_val: 0.8000 time: 0.0393s\n",
            "64\n",
            "Epoch: 0068 loss_train: 0.9067 acc_train: 0.8000 loss_val: 0.7997 acc_val: 0.8020 time: 0.0420s\n",
            "65\n",
            "Epoch: 0069 loss_train: 0.9197 acc_train: 0.7929 loss_val: 0.8035 acc_val: 0.8020 time: 0.0423s\n",
            "66\n",
            "Epoch: 0070 loss_train: 0.9013 acc_train: 0.7786 loss_val: 0.8085 acc_val: 0.8040 time: 0.0404s\n",
            "67\n",
            "Epoch: 0071 loss_train: 0.9357 acc_train: 0.7429 loss_val: 0.8160 acc_val: 0.8060 time: 0.0392s\n",
            "68\n",
            "Epoch: 0072 loss_train: 0.9557 acc_train: 0.7571 loss_val: 0.8225 acc_val: 0.8080 time: 0.0407s\n",
            "69\n",
            "Epoch: 0073 loss_train: 0.8799 acc_train: 0.7714 loss_val: 0.8237 acc_val: 0.8140 time: 0.0392s\n",
            "70\n",
            "Epoch: 0074 loss_train: 0.9624 acc_train: 0.7429 loss_val: 0.8229 acc_val: 0.8080 time: 0.0389s\n",
            "71\n",
            "Epoch: 0075 loss_train: 0.8998 acc_train: 0.8143 loss_val: 0.8220 acc_val: 0.8040 time: 0.0411s\n",
            "72\n",
            "Epoch: 0076 loss_train: 0.9224 acc_train: 0.7857 loss_val: 0.8168 acc_val: 0.8020 time: 0.0383s\n",
            "73\n",
            "Epoch: 0077 loss_train: 0.9449 acc_train: 0.8214 loss_val: 0.8158 acc_val: 0.8000 time: 0.0393s\n",
            "74\n",
            "Epoch: 0078 loss_train: 0.9488 acc_train: 0.7429 loss_val: 0.8147 acc_val: 0.8020 time: 0.0375s\n",
            "75\n",
            "Epoch: 0079 loss_train: 0.8926 acc_train: 0.8357 loss_val: 0.8122 acc_val: 0.7980 time: 0.0377s\n",
            "76\n",
            "Epoch: 0080 loss_train: 0.9453 acc_train: 0.7643 loss_val: 0.8104 acc_val: 0.7980 time: 0.0404s\n",
            "77\n",
            "Epoch: 0081 loss_train: 0.8696 acc_train: 0.8214 loss_val: 0.8091 acc_val: 0.8080 time: 0.0385s\n",
            "78\n",
            "Epoch: 0082 loss_train: 0.9153 acc_train: 0.8071 loss_val: 0.8094 acc_val: 0.8040 time: 0.0383s\n",
            "79\n",
            "Epoch: 0083 loss_train: 0.9112 acc_train: 0.7857 loss_val: 0.8116 acc_val: 0.8060 time: 0.0382s\n",
            "80\n",
            "Epoch: 0084 loss_train: 0.9326 acc_train: 0.8286 loss_val: 0.8164 acc_val: 0.8060 time: 0.0381s\n",
            "81\n",
            "Epoch: 0085 loss_train: 0.9158 acc_train: 0.7929 loss_val: 0.8185 acc_val: 0.8060 time: 0.0396s\n",
            "82\n",
            "Epoch: 0086 loss_train: 0.9044 acc_train: 0.8071 loss_val: 0.8190 acc_val: 0.8060 time: 0.0416s\n",
            "83\n",
            "Epoch: 0087 loss_train: 0.9207 acc_train: 0.8000 loss_val: 0.8197 acc_val: 0.8060 time: 0.0380s\n",
            "84\n",
            "Epoch: 0088 loss_train: 0.9130 acc_train: 0.7643 loss_val: 0.8192 acc_val: 0.8060 time: 0.0381s\n",
            "85\n",
            "Epoch: 0089 loss_train: 0.9612 acc_train: 0.7500 loss_val: 0.8155 acc_val: 0.8080 time: 0.0378s\n",
            "86\n",
            "Epoch: 0090 loss_train: 0.8840 acc_train: 0.8286 loss_val: 0.8122 acc_val: 0.8100 time: 0.0393s\n",
            "87\n",
            "Epoch: 0091 loss_train: 0.9178 acc_train: 0.7786 loss_val: 0.8086 acc_val: 0.8100 time: 0.0414s\n",
            "88\n",
            "Epoch: 0092 loss_train: 0.8940 acc_train: 0.7286 loss_val: 0.8075 acc_val: 0.8060 time: 0.0430s\n",
            "89\n",
            "Epoch: 0093 loss_train: 0.9055 acc_train: 0.8000 loss_val: 0.8078 acc_val: 0.8040 time: 0.0406s\n",
            "90\n",
            "Epoch: 0094 loss_train: 0.9216 acc_train: 0.7929 loss_val: 0.8079 acc_val: 0.8020 time: 0.0393s\n",
            "91\n",
            "Epoch: 0095 loss_train: 0.9420 acc_train: 0.7857 loss_val: 0.8088 acc_val: 0.8000 time: 0.0392s\n",
            "92\n",
            "Epoch: 0096 loss_train: 0.8757 acc_train: 0.8214 loss_val: 0.8084 acc_val: 0.8060 time: 0.0433s\n",
            "93\n",
            "Epoch: 0097 loss_train: 0.9060 acc_train: 0.8000 loss_val: 0.8080 acc_val: 0.8060 time: 0.0398s\n",
            "94\n",
            "Epoch: 0098 loss_train: 0.9401 acc_train: 0.7714 loss_val: 0.8101 acc_val: 0.8080 time: 0.0385s\n",
            "95\n",
            "Epoch: 0099 loss_train: 0.9001 acc_train: 0.8286 loss_val: 0.8121 acc_val: 0.8100 time: 0.0381s\n",
            "96\n",
            "Epoch: 0100 loss_train: 0.9745 acc_train: 0.7214 loss_val: 0.8157 acc_val: 0.8080 time: 0.0379s\n",
            "97\n",
            "Epoch: 0101 loss_train: 0.9133 acc_train: 0.7929 loss_val: 0.8147 acc_val: 0.8100 time: 0.0387s\n",
            "98\n",
            "Epoch: 0102 loss_train: 0.8928 acc_train: 0.8214 loss_val: 0.8118 acc_val: 0.8140 time: 0.0414s\n",
            "99\n",
            "Epoch: 0103 loss_train: 0.8919 acc_train: 0.8000 loss_val: 0.8071 acc_val: 0.8160 time: 0.0417s\n",
            "100\n",
            "Epoch: 0104 loss_train: 0.9404 acc_train: 0.7214 loss_val: 0.8061 acc_val: 0.8140 time: 0.0390s\n",
            "101\n",
            "Epoch: 0105 loss_train: 0.9638 acc_train: 0.7500 loss_val: 0.8049 acc_val: 0.8120 time: 0.0399s\n",
            "102\n",
            "Epoch: 0106 loss_train: 1.2443 acc_train: 0.7429 loss_val: 0.8068 acc_val: 0.8120 time: 0.0385s\n",
            "103\n",
            "Epoch: 0107 loss_train: 1.0348 acc_train: 0.7786 loss_val: 0.8123 acc_val: 0.8100 time: 0.0400s\n",
            "104\n",
            "Epoch: 0108 loss_train: 0.8956 acc_train: 0.8071 loss_val: 0.8203 acc_val: 0.8000 time: 0.0396s\n",
            "105\n",
            "Epoch: 0109 loss_train: 0.9481 acc_train: 0.8214 loss_val: 0.8260 acc_val: 0.7980 time: 0.0391s\n",
            "106\n",
            "Epoch: 0110 loss_train: 0.8953 acc_train: 0.7929 loss_val: 0.8266 acc_val: 0.8000 time: 0.0396s\n",
            "107\n",
            "Epoch: 0111 loss_train: 0.9609 acc_train: 0.8214 loss_val: 0.8230 acc_val: 0.8040 time: 0.0376s\n",
            "108\n",
            "Epoch: 0112 loss_train: 0.9724 acc_train: 0.7357 loss_val: 0.8191 acc_val: 0.8100 time: 0.0404s\n",
            "109\n",
            "Epoch: 0113 loss_train: 0.8776 acc_train: 0.8000 loss_val: 0.8161 acc_val: 0.8160 time: 0.0380s\n",
            "110\n",
            "Epoch: 0114 loss_train: 0.9233 acc_train: 0.7500 loss_val: 0.8132 acc_val: 0.8220 time: 0.0379s\n",
            "111\n",
            "Epoch: 0115 loss_train: 0.9369 acc_train: 0.8000 loss_val: 0.8114 acc_val: 0.8240 time: 0.0389s\n",
            "112\n",
            "Epoch: 0116 loss_train: 1.0155 acc_train: 0.8143 loss_val: 0.8086 acc_val: 0.8240 time: 0.0378s\n",
            "113\n",
            "Epoch: 0117 loss_train: 0.9336 acc_train: 0.8143 loss_val: 0.8076 acc_val: 0.8220 time: 0.0437s\n",
            "114\n",
            "Epoch: 0118 loss_train: 0.9097 acc_train: 0.8000 loss_val: 0.8071 acc_val: 0.8180 time: 0.0397s\n",
            "115\n",
            "Epoch: 0119 loss_train: 0.8640 acc_train: 0.7571 loss_val: 0.8093 acc_val: 0.8160 time: 0.0380s\n",
            "116\n",
            "Epoch: 0120 loss_train: 0.9897 acc_train: 0.7929 loss_val: 0.8122 acc_val: 0.8140 time: 0.0378s\n",
            "117\n",
            "Epoch: 0121 loss_train: 0.9612 acc_train: 0.7571 loss_val: 0.8158 acc_val: 0.8100 time: 0.0379s\n",
            "118\n",
            "Epoch: 0122 loss_train: 1.0329 acc_train: 0.8429 loss_val: 0.8130 acc_val: 0.8120 time: 0.0379s\n",
            "119\n",
            "Epoch: 0123 loss_train: 0.9261 acc_train: 0.7786 loss_val: 0.8069 acc_val: 0.8100 time: 0.0408s\n",
            "120\n",
            "Epoch: 0124 loss_train: 0.9137 acc_train: 0.8071 loss_val: 0.8022 acc_val: 0.8200 time: 0.0393s\n",
            "121\n",
            "Epoch: 0125 loss_train: 0.9423 acc_train: 0.8571 loss_val: 0.8003 acc_val: 0.8240 time: 0.0397s\n",
            "122\n",
            "Epoch: 0126 loss_train: 0.9356 acc_train: 0.8000 loss_val: 0.7995 acc_val: 0.8240 time: 0.0408s\n",
            "123\n",
            "Epoch: 0127 loss_train: 0.8633 acc_train: 0.8500 loss_val: 0.8003 acc_val: 0.8160 time: 0.0395s\n",
            "124\n",
            "Epoch: 0128 loss_train: 0.9920 acc_train: 0.7500 loss_val: 0.8052 acc_val: 0.8180 time: 0.0406s\n",
            "125\n",
            "Epoch: 0129 loss_train: 0.9965 acc_train: 0.7857 loss_val: 0.8149 acc_val: 0.8140 time: 0.0391s\n",
            "126\n",
            "Epoch: 0130 loss_train: 0.8977 acc_train: 0.7929 loss_val: 0.8224 acc_val: 0.8120 time: 0.0389s\n",
            "127\n",
            "Epoch: 0131 loss_train: 0.8758 acc_train: 0.7571 loss_val: 0.8312 acc_val: 0.8060 time: 0.0392s\n",
            "128\n",
            "Epoch: 0132 loss_train: 0.9466 acc_train: 0.7500 loss_val: 0.8339 acc_val: 0.8080 time: 0.0412s\n",
            "129\n",
            "Epoch: 0133 loss_train: 0.9875 acc_train: 0.7571 loss_val: 0.8326 acc_val: 0.8120 time: 0.0418s\n",
            "130\n",
            "Epoch: 0134 loss_train: 1.0016 acc_train: 0.7786 loss_val: 0.8227 acc_val: 0.8140 time: 0.0410s\n",
            "131\n",
            "Epoch: 0135 loss_train: 0.8759 acc_train: 0.7714 loss_val: 0.8128 acc_val: 0.8180 time: 0.0385s\n",
            "132\n",
            "Epoch: 0136 loss_train: 0.9446 acc_train: 0.7429 loss_val: 0.8068 acc_val: 0.8160 time: 0.0378s\n",
            "133\n",
            "Epoch: 0137 loss_train: 0.9084 acc_train: 0.7857 loss_val: 0.8060 acc_val: 0.8120 time: 0.0380s\n",
            "134\n",
            "Epoch: 0138 loss_train: 0.9286 acc_train: 0.7929 loss_val: 0.8064 acc_val: 0.8100 time: 0.0388s\n",
            "135\n",
            "Epoch: 0139 loss_train: 0.9851 acc_train: 0.8214 loss_val: 0.8073 acc_val: 0.8120 time: 0.0404s\n",
            "136\n",
            "Epoch: 0140 loss_train: 0.9859 acc_train: 0.6857 loss_val: 0.8100 acc_val: 0.8080 time: 0.0381s\n",
            "137\n",
            "Epoch: 0141 loss_train: 0.9603 acc_train: 0.7357 loss_val: 0.8151 acc_val: 0.8080 time: 0.0416s\n",
            "138\n",
            "Epoch: 0142 loss_train: 0.9772 acc_train: 0.8000 loss_val: 0.8218 acc_val: 0.8020 time: 0.0374s\n",
            "139\n",
            "Epoch: 0143 loss_train: 0.9599 acc_train: 0.7643 loss_val: 0.8284 acc_val: 0.8040 time: 0.0379s\n",
            "140\n",
            "Epoch: 0144 loss_train: 0.9556 acc_train: 0.7571 loss_val: 0.8277 acc_val: 0.8040 time: 0.0397s\n",
            "141\n",
            "Epoch: 0145 loss_train: 0.9405 acc_train: 0.7500 loss_val: 0.8205 acc_val: 0.8140 time: 0.0406s\n",
            "142\n",
            "Epoch: 0146 loss_train: 0.9138 acc_train: 0.8000 loss_val: 0.8137 acc_val: 0.8180 time: 0.0395s\n",
            "143\n",
            "Epoch: 0147 loss_train: 0.9375 acc_train: 0.8071 loss_val: 0.8107 acc_val: 0.8200 time: 0.0404s\n",
            "144\n",
            "Epoch: 0148 loss_train: 0.9127 acc_train: 0.7786 loss_val: 0.8106 acc_val: 0.8200 time: 0.0382s\n",
            "145\n",
            "Epoch: 0149 loss_train: 0.9162 acc_train: 0.7643 loss_val: 0.8137 acc_val: 0.8180 time: 0.0394s\n",
            "146\n",
            "Epoch: 0150 loss_train: 0.9123 acc_train: 0.8000 loss_val: 0.8194 acc_val: 0.8100 time: 0.0400s\n",
            "147\n",
            "Epoch: 0151 loss_train: 0.9128 acc_train: 0.7714 loss_val: 0.8233 acc_val: 0.8100 time: 0.0379s\n",
            "148\n",
            "Epoch: 0152 loss_train: 0.9949 acc_train: 0.7000 loss_val: 0.8245 acc_val: 0.8040 time: 0.0386s\n",
            "149\n",
            "Epoch: 0153 loss_train: 0.9706 acc_train: 0.8214 loss_val: 0.8233 acc_val: 0.8040 time: 0.0379s\n",
            "150\n",
            "Epoch: 0154 loss_train: 0.9423 acc_train: 0.7357 loss_val: 0.8238 acc_val: 0.8040 time: 0.0381s\n",
            "151\n",
            "Epoch: 0155 loss_train: 0.8876 acc_train: 0.7857 loss_val: 0.8251 acc_val: 0.8080 time: 0.0409s\n",
            "152\n",
            "Epoch: 0156 loss_train: 0.8619 acc_train: 0.8214 loss_val: 0.8289 acc_val: 0.8120 time: 0.0394s\n",
            "153\n",
            "Epoch: 0157 loss_train: 0.9045 acc_train: 0.7929 loss_val: 0.8290 acc_val: 0.8140 time: 0.0391s\n",
            "154\n",
            "Epoch: 0158 loss_train: 0.9217 acc_train: 0.7857 loss_val: 0.8265 acc_val: 0.8120 time: 0.0410s\n",
            "155\n",
            "Epoch: 0159 loss_train: 0.9514 acc_train: 0.8429 loss_val: 0.8237 acc_val: 0.8060 time: 0.0380s\n",
            "156\n",
            "Epoch: 0160 loss_train: 0.9635 acc_train: 0.7643 loss_val: 0.8209 acc_val: 0.8120 time: 0.0423s\n",
            "157\n",
            "Epoch: 0161 loss_train: 0.9501 acc_train: 0.7714 loss_val: 0.8190 acc_val: 0.8140 time: 0.0391s\n",
            "158\n",
            "Epoch: 0162 loss_train: 0.9593 acc_train: 0.7929 loss_val: 0.8174 acc_val: 0.8160 time: 0.0392s\n",
            "159\n",
            "Epoch: 0163 loss_train: 0.9441 acc_train: 0.8214 loss_val: 0.8180 acc_val: 0.8180 time: 0.0395s\n",
            "160\n",
            "Epoch: 0164 loss_train: 0.8929 acc_train: 0.8214 loss_val: 0.8201 acc_val: 0.8180 time: 0.0401s\n",
            "161\n",
            "Epoch: 0165 loss_train: 0.9744 acc_train: 0.7857 loss_val: 0.8211 acc_val: 0.8160 time: 0.0628s\n",
            "162\n",
            "Epoch: 0166 loss_train: 0.9266 acc_train: 0.8286 loss_val: 0.8226 acc_val: 0.8080 time: 0.0418s\n",
            "163\n",
            "Epoch: 0167 loss_train: 0.9462 acc_train: 0.7357 loss_val: 0.8262 acc_val: 0.8100 time: 0.0409s\n",
            "164\n",
            "Epoch: 0168 loss_train: 0.9121 acc_train: 0.7786 loss_val: 0.8267 acc_val: 0.8180 time: 0.0416s\n",
            "165\n",
            "Epoch: 0169 loss_train: 0.9686 acc_train: 0.7071 loss_val: 0.8235 acc_val: 0.8140 time: 0.0392s\n",
            "166\n",
            "Epoch: 0170 loss_train: 0.9699 acc_train: 0.7500 loss_val: 0.8221 acc_val: 0.8140 time: 0.0435s\n",
            "167\n",
            "Epoch: 0171 loss_train: 0.9541 acc_train: 0.7857 loss_val: 0.8229 acc_val: 0.8140 time: 0.0386s\n",
            "168\n",
            "Epoch: 0172 loss_train: 1.0075 acc_train: 0.7214 loss_val: 0.8243 acc_val: 0.8080 time: 0.0405s\n",
            "169\n",
            "Epoch: 0173 loss_train: 1.0393 acc_train: 0.7357 loss_val: 0.8241 acc_val: 0.8120 time: 0.0385s\n",
            "170\n",
            "Epoch: 0174 loss_train: 0.9710 acc_train: 0.7357 loss_val: 0.8241 acc_val: 0.8120 time: 0.0385s\n",
            "171\n",
            "Epoch: 0175 loss_train: 0.9100 acc_train: 0.8143 loss_val: 0.8201 acc_val: 0.8140 time: 0.0435s\n",
            "172\n",
            "Epoch: 0176 loss_train: 0.9408 acc_train: 0.7929 loss_val: 0.8162 acc_val: 0.8160 time: 0.0410s\n",
            "173\n",
            "Epoch: 0177 loss_train: 0.8968 acc_train: 0.7929 loss_val: 0.8101 acc_val: 0.8120 time: 0.0385s\n",
            "174\n",
            "Epoch: 0178 loss_train: 0.9384 acc_train: 0.7500 loss_val: 0.8075 acc_val: 0.8100 time: 0.0385s\n",
            "175\n",
            "Epoch: 0179 loss_train: 0.9391 acc_train: 0.7143 loss_val: 0.8067 acc_val: 0.8100 time: 0.0380s\n",
            "176\n",
            "Epoch: 0180 loss_train: 0.9025 acc_train: 0.8000 loss_val: 0.8057 acc_val: 0.8240 time: 0.0389s\n",
            "177\n",
            "Epoch: 0181 loss_train: 0.9055 acc_train: 0.8000 loss_val: 0.8067 acc_val: 0.8200 time: 0.0410s\n",
            "178\n",
            "Epoch: 0182 loss_train: 0.9166 acc_train: 0.7714 loss_val: 0.8099 acc_val: 0.8240 time: 0.0394s\n",
            "179\n",
            "Epoch: 0183 loss_train: 0.9677 acc_train: 0.7500 loss_val: 0.8157 acc_val: 0.8140 time: 0.0382s\n",
            "180\n",
            "Epoch: 0184 loss_train: 0.9123 acc_train: 0.7643 loss_val: 0.8280 acc_val: 0.8140 time: 0.0386s\n",
            "181\n",
            "Epoch: 0185 loss_train: 0.8917 acc_train: 0.8071 loss_val: 0.8385 acc_val: 0.8160 time: 0.0389s\n",
            "182\n",
            "Epoch: 0186 loss_train: 0.9559 acc_train: 0.7643 loss_val: 0.8428 acc_val: 0.8140 time: 0.0443s\n",
            "183\n",
            "Epoch: 0187 loss_train: 0.9762 acc_train: 0.7571 loss_val: 0.8409 acc_val: 0.8100 time: 0.0419s\n",
            "184\n",
            "Epoch: 0188 loss_train: 0.9637 acc_train: 0.7429 loss_val: 0.8347 acc_val: 0.8040 time: 0.0402s\n",
            "185\n",
            "Epoch: 0189 loss_train: 0.9019 acc_train: 0.8286 loss_val: 0.8251 acc_val: 0.8000 time: 0.0424s\n",
            "186\n",
            "Epoch: 0190 loss_train: 0.9738 acc_train: 0.8071 loss_val: 0.8162 acc_val: 0.8080 time: 0.0404s\n",
            "187\n",
            "Epoch: 0191 loss_train: 0.9351 acc_train: 0.7643 loss_val: 0.8105 acc_val: 0.8140 time: 0.0461s\n",
            "188\n",
            "Epoch: 0192 loss_train: 1.0435 acc_train: 0.7429 loss_val: 0.8067 acc_val: 0.8180 time: 0.0397s\n",
            "189\n",
            "Epoch: 0193 loss_train: 0.8867 acc_train: 0.8143 loss_val: 0.8054 acc_val: 0.8140 time: 0.0393s\n",
            "190\n",
            "Epoch: 0194 loss_train: 1.0794 acc_train: 0.7643 loss_val: 0.8071 acc_val: 0.8140 time: 0.0391s\n",
            "191\n",
            "Epoch: 0195 loss_train: 0.9812 acc_train: 0.7357 loss_val: 0.8099 acc_val: 0.8120 time: 0.0394s\n",
            "192\n",
            "Epoch: 0196 loss_train: 0.9343 acc_train: 0.7714 loss_val: 0.8153 acc_val: 0.8200 time: 0.0435s\n",
            "193\n",
            "Epoch: 0197 loss_train: 0.9252 acc_train: 0.7929 loss_val: 0.8213 acc_val: 0.8140 time: 0.0394s\n",
            "194\n",
            "Epoch: 0198 loss_train: 0.9659 acc_train: 0.8286 loss_val: 0.8279 acc_val: 0.8040 time: 0.0395s\n",
            "195\n",
            "Epoch: 0199 loss_train: 0.9030 acc_train: 0.8000 loss_val: 0.8288 acc_val: 0.8040 time: 0.0407s\n",
            "196\n",
            "Epoch: 0200 loss_train: 0.9642 acc_train: 0.7357 loss_val: 0.8305 acc_val: 0.8020 time: 0.0397s\n",
            "197\n",
            "Epoch: 0201 loss_train: 0.9072 acc_train: 0.8214 loss_val: 0.8296 acc_val: 0.8000 time: 0.0409s\n",
            "198\n",
            "Epoch: 0202 loss_train: 0.9323 acc_train: 0.8000 loss_val: 0.8221 acc_val: 0.8040 time: 0.0385s\n",
            "199\n",
            "Early stop! Min loss:  0.705600917339325 , Max accuracy:  0.8280000000000001\n",
            "Early stop model validation loss:  0.705600917339325 , accuracy:  0.8240000000000001\n",
            "Optimization Finished!\n",
            "Total time elapsed: 8.4559s\n",
            "Loading 0th epoch\n",
            "Test set results: loss= 0.6689 accuracy= 0.8430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hUwjsOKvkEvj",
        "outputId": "096fa11b-ddb8-4332-ce38-68d1fedcb64c"
      },
      "source": [
        "x = [i for i in range(1, 11)]\n",
        "plt.plot(x, accs_dropedge[0], \"r*\", linestyle=\"solid\", linewidth=0.5, label=\"S = 1\", markersize=5)\n",
        "plt.plot(x, accs_dropedge[1], \"g^\", linestyle=\"solid\", linewidth=0.5, label=\"S = 2\", markersize=5)\n",
        "plt.plot(x, accs_dropedge[2], \"bo\", linestyle=\"solid\", linewidth=0.5, label=\"S = 3\", markersize=5)\n",
        "plt.plot(x, accs_dropedge[3], \"mp\", linestyle=\"solid\", linewidth=0.5, label=\"S = 4\", markersize=5)\n",
        "plt.plot(x, [0.791 for _ in range(10)], linestyle=\"dashed\", label=\"GAT\")\n",
        "plt.plot(x, [0.79 for _ in range(10)], linestyle=\"dashed\", label=\"GCN\")\n",
        "plt.xticks(np.arange(1, len(x)+1, 1))\n",
        "plt.grid()\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Propagation Steps(K)\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "# plt.ylim(0.74, 0.87)\n",
        "plt.title(f\"GRAND_dropout on {args['dataset'].upper()} dataset\")\n",
        "plt.savefig(f\"{args['dataset']}.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}